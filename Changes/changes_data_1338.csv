id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ffuel-ostf~master~Ica69326fceb8daf62d62ab1315bf0e04942527c5,openstack/fuel-ostf,master,Ica69326fceb8daf62d62ab1315bf0e04942527c5,test create sample and check statistics,MERGED,2014-01-16 10:15:43.000000000,2014-02-03 11:17:53.000000000,2014-02-03 11:17:53.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 6719}, {'_account_id': 8293}, {'_account_id': 8839}, {'_account_id': 8971}, {'_account_id': 9439}]","[{'number': 1, 'created': '2014-01-16 10:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e0293031e3210265bc0f481011218e445ecbd175', 'message': 'test create sample and check statistics\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 2, 'created': '2014-01-16 10:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/fa8035acc034d7e30a5a3c8300131c4e6fe8637f', 'message': 'test create sample and check statistics\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 3, 'created': '2014-01-16 10:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/f48dc711f8f21390a6e9942da433c9ec4120d431', 'message': 'test create sample and check statistics\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 4, 'created': '2014-01-16 12:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/0f22ff9aa0c41f3df413ae29d192823b1dd85281', 'message': 'test create sample and check statistics\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 5, 'created': '2014-01-16 13:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/5d65254ce56601fc16af07b0cb37ef90b2bb0abc', 'message': 'Closes-bug: bug 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 6, 'created': '2014-01-16 13:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b2fccc7beffda8d0b1195396f5286bb103cf0700', 'message': 'Closes-bug: bug 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 7, 'created': '2014-01-16 13:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/4df9005d632872b4e82ee19f0dd92a5d0e89e8bf', 'message': 'pull-request title\n\nmulti-line pull-request description (if needed)\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 8, 'created': '2014-01-16 14:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/a10170bc87464b07b7276dfe5975bc6d47e08c86', 'message': 'test create sample and check statistics\n\nnmanager: new method create sample\nnew test:create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 9, 'created': '2014-01-17 10:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/991d9c1bff38de91acf0d419cc2f5473c8192981', 'message': 'test create sample and check statistics\n\nnmanager: new method create sample\nNew test: ceilometer create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 10, 'created': '2014-01-21 11:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/86e05e83586d069393b58a6882810c0134987a3a', 'message': 'test create sample and check statistics\n\nnmanager: new method create sample\nNew test: ceilometer create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 11, 'created': '2014-01-21 12:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/566b0144dd712baad371c258768f07a649e5a8e9', 'message': 'test create sample and check statistics\n\nceilometermanager: new method create sample\nNew test: ceilometer create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 12, 'created': '2014-01-24 14:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7312b8bce865f9acd03e403b3bbb4d92925174e6', 'message': 'test create sample and check statistics\n\nceilometermanager: new method create sample\nNew test: ceilometer create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}, {'number': 13, 'created': '2014-01-27 13:01:49.000000000', 'files': ['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/bd5704d9377a06f69721c67b8b6f3469b95cbb28', 'message': 'test create sample and check statistics\n\nceilometermanager: new method create sample\nNew test: ceilometer create, check sample, check statistic\n\nCloses-bug: 1269799\n\nChange-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5\n'}]",17,67095,bd5704d9377a06f69721c67b8b6f3469b95cbb28,60,7,13,8293,,,0,"test create sample and check statistics

ceilometermanager: new method create sample
New test: ceilometer create, check sample, check statistic

Closes-bug: 1269799

Change-Id: Ica69326fceb8daf62d62ab1315bf0e04942527c5
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/95/67095/10 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py']",3,e0293031e3210265bc0f481011218e445ecbd175,bug/1269799," self.counter_name = rand_name('hdd-write-1') self.counter_type = 'gauge' self.counter_unit = 'B' self.counter_volume = 1 self.resource_metadata = {""user"": ""example_metadata""} def show_resources(self, resource_id): """""" This method list resources """""" return self.ceilometer_client.resources.list(resource_id) def create_sample(self, resource_id, counter_name, counter_type, counter_unit, counter_volume, resource_metadata): """""" This method provide creation of sample """""" return self.ceilometer_client.samples.create(resource_id=resource_id, counter_name=counter_name, counter_type=counter_type, counter_unit=counter_unit, counter_volume=counter_volume, resource_metadata=resource_metadata) ",,112,9
openstack%2Fpython-ironicclient~master~Ibc2005d4cb9a43ac20ec0624f95dce002b0e02b2,openstack/python-ironicclient,master,Ibc2005d4cb9a43ac20ec0624f95dce002b0e02b2,Fix empty node-set-power-state output in CLI,ABANDONED,2014-01-07 14:14:30.000000000,2014-02-03 11:13:31.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 7419}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-07 14:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/103ad7dc325e7018128fa105198c9f8420fd6608', 'message': 'Fix empty node-set-power-state output\n\nCloses-Bug: #1266775\nChange-Id: Ibc2005d4cb9a43ac20ec0624f95dce002b0e02b2\n'}, {'number': 2, 'created': '2014-01-09 10:08:16.000000000', 'files': ['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/v1/test_node.py', 'ironicclient/tests/v1/test_node_shell.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/190f291edc1bee1f731819f0bea6bcee61511374', 'message': ""Fix empty node-set-power-state output in CLI\n\nWith the NodeStates object returned by API, printing the output has 2\nissues:\n- the current power state has the key 'power_state' instead of 'current'\n- it does not contain the target_power_state requested by the user\n\nCloses-Bug: #1266775\nChange-Id: Ibc2005d4cb9a43ac20ec0624f95dce002b0e02b2\n""}]",18,65277,190f291edc1bee1f731819f0bea6bcee61511374,20,6,2,7419,,,0,"Fix empty node-set-power-state output in CLI

With the NodeStates object returned by API, printing the output has 2
issues:
- the current power state has the key 'power_state' instead of 'current'
- it does not contain the target_power_state requested by the user

Closes-Bug: #1266775
Change-Id: Ibc2005d4cb9a43ac20ec0624f95dce002b0e02b2
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/77/65277/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/v1/test_node.py']",3,103ad7dc325e7018128fa105198c9f8420fd6608,fix_node_set_power_state_output," power_state = self.mgr.set_power_state(NODE1['uuid'], 'power on')"," power_state = self.mgr.set_power_state(NODE1['uuid'], ""on"")",9,8
openstack%2Fnova~master~I7ee48ef87082301f7f4ea0633b39275847cbd7e1,openstack/nova,master,I7ee48ef87082301f7f4ea0633b39275847cbd7e1,Fix the test parameter order for v3 evacuate test,MERGED,2014-01-17 06:16:10.000000000,2014-02-03 10:55:23.000000000,2014-02-03 10:55:19.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 6873}, {'_account_id': 7602}, {'_account_id': 7882}, {'_account_id': 9046}, {'_account_id': 9533}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-17 06:16:10.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_evacuate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d1b72ee77294401ad51230a671ae16c5eff8030', 'message': 'Fix the test parameter order for v3 evacuate test\n\nOn assertEqual(), the order of parameters should be ""expected"" and\n""observed"". However the parameters of some evacuate tests are invalid.\nThis patch fixes them.\n\nChange-Id: I7ee48ef87082301f7f4ea0633b39275847cbd7e1\n'}]",0,67379,6d1b72ee77294401ad51230a671ae16c5eff8030,17,11,1,6167,,,0,"Fix the test parameter order for v3 evacuate test

On assertEqual(), the order of parameters should be ""expected"" and
""observed"". However the parameters of some evacuate tests are invalid.
This patch fixes them.

Change-Id: I7ee48ef87082301f7f4ea0633b39275847cbd7e1
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/67379/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/plugins/v3/test_evacuate.py'],1,6d1b72ee77294401ad51230a671ae16c5eff8030,cleanup," self.assertEqual(400, res.status_int) self.assertEqual(400, res.status_int) self.assertEqual(404, res.status_int) self.assertEqual(200, resp.status_int) self.assertEqual(200, resp.status_int) self.assertEqual(400, res.status_int) self.assertEqual(200, resp.status_int) self.assertEqual(200, res.status_int) self.assertEqual(400, res.status_int) self.assertEqual(403, res.status_int)"," self.assertEqual(res.status_int, 400) self.assertEqual(res.status_int, 400) self.assertEqual(res.status_int, 404) self.assertEqual(resp.status_int, 200) self.assertEqual(resp.status_int, 200) self.assertEqual(res.status_int, 400) self.assertEqual(resp.status_int, 200) self.assertEqual(res.status_int, 200) self.assertEqual(res.status_int, 400) self.assertEqual(res.status_int, 403)",10,10
openstack%2Ffuel-web~master~I925b1764d0262781a4dd5bea8917bdbba39a029d,openstack/fuel-web,master,I925b1764d0262781a4dd5bea8917bdbba39a029d,Making Interfaces button available for deployed nodes,MERGED,2014-01-30 12:55:27.000000000,2014-02-03 10:34:39.000000000,2014-02-03 10:34:39.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-01-30 12:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1e4a7d6d20816e7f1359efdd9d3d423b0d9ac10a', 'message': 'Making Interfaces button available for deployed nodes\n\nChange-Id: I925b1764d0262781a4dd5bea8917bdbba39a029d\nCloses-bug: 1273599\n'}, {'number': 2, 'created': '2014-01-30 15:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9b3f114149f596cb12ac4b399e6044505965962e', 'message': 'Making Interfaces button available for deployed nodes\n\nChange-Id: I925b1764d0262781a4dd5bea8917bdbba39a029d\nCloses-bug: 1273599\n'}, {'number': 3, 'created': '2014-01-30 17:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f36f4789cb3e3512d5522fc2d5e48430efaeef20', 'message': 'Making Interfaces button available for deployed nodes\n\nChange-Id: I925b1764d0262781a4dd5bea8917bdbba39a029d\nCloses-bug: 1273599\n'}, {'number': 4, 'created': '2014-02-03 09:50:09.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/nodes_tab.js', 'nailgun/static/css/styles.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bc0c1b563da9a0e4a867c50837a0345f72b6cd73', 'message': 'Making Interfaces button available for deployed nodes\n\nChange-Id: I925b1764d0262781a4dd5bea8917bdbba39a029d\nCloses-bug: 1273599\n'}]",9,70112,bc0c1b563da9a0e4a867c50837a0345f72b6cd73,30,5,4,9091,,,0,"Making Interfaces button available for deployed nodes

Change-Id: I925b1764d0262781a4dd5bea8917bdbba39a029d
Closes-bug: 1273599
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/12/70112/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/nodes_tab.js', 'nailgun/static/i18n/translation.json', 'nailgun/static/css/styles.less']",3,1e4a7d6d20816e7f1359efdd9d3d423b0d9ac10a,bug/1273599, width: 290px; } , width: 305px; },5,5
openstack%2Fnova~stable%2Fhavana~Ib61811fffcbc80385efc3166c9e366fdaa6432bd,openstack/nova,stable/havana,Ib61811fffcbc80385efc3166c9e366fdaa6432bd,VMware: fix bug when more than one datacenter exists,MERGED,2013-12-17 09:41:22.000000000,2014-02-03 10:30:06.000000000,2014-02-02 06:46:21.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1955}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 9555}]","[{'number': 1, 'created': '2013-12-17 09:41:22.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/fake.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/33c77d3f60cf72f4e97a1f70ba4e1aeae27760d3', 'message': ""VMware: fix bug when more than one datacenter exists\n\nIn the case that there was more than one datacenter defined on the VC,\nthen spawning an instance would result in an exception. The reason for this\nwas that the nova compute would not set the correct datacenter for the\nselected datastore.\n\nThe fix also takes care of the correct folder selection. This too was a\nresult of not selecting the correct folder for the data center.\n\nThe 'fake' configuration was updated to contain an additional data\ncenter with its on datastore.\n\nCloses-Bug: #1180044\nCloses-Bug: #1214850\n\nCo-authored-by: Shawn Harsock <hartsocks@vmware.com>\n\n(cherry picked from commit a25b2ac5f440f7ace4678b21ada6ebf5ce5dff3c)\n\nConflicts:\n\n\tnova/tests/virt/vmwareapi/test_vmwareapi.py\n\tnova/virt/vmwareapi/fake.py\n\nChange-Id: Ib61811fffcbc80385efc3166c9e366fdaa6432bd\n""}]",2,62587,33c77d3f60cf72f4e97a1f70ba4e1aeae27760d3,18,6,1,1653,,,0,"VMware: fix bug when more than one datacenter exists

In the case that there was more than one datacenter defined on the VC,
then spawning an instance would result in an exception. The reason for this
was that the nova compute would not set the correct datacenter for the
selected datastore.

The fix also takes care of the correct folder selection. This too was a
result of not selecting the correct folder for the data center.

The 'fake' configuration was updated to contain an additional data
center with its on datastore.

Closes-Bug: #1180044
Closes-Bug: #1214850

Co-authored-by: Shawn Harsock <hartsocks@vmware.com>

(cherry picked from commit a25b2ac5f440f7ace4678b21ada6ebf5ce5dff3c)

Conflicts:

	nova/tests/virt/vmwareapi/test_vmwareapi.py
	nova/virt/vmwareapi/fake.py

Change-Id: Ib61811fffcbc80385efc3166c9e366fdaa6432bd
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/62587/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/fake.py']",4,33c77d3f60cf72f4e97a1f70ba4e1aeae27760d3,more-than-one-dc,"def reset(vc=False): cleanup() create_network() create_host_network_system() create_host_storage_system() create_host() ds_ref1 = create_datastore('ds1', 1024, 500) if vc: create_host() ds_ref2 = create_datastore('ds2', 1024, 500) create_datacenter('dc1', ds_ref1) if vc: create_datacenter('dc2', ds_ref2) create_res_pool() if vc: create_cluster('test_cluster', ds_ref1) create_cluster('test_cluster2', ds_ref2) def cleanup(): """"""Clear the db contents."""""" def __init__(self, name=""fake-ds"", capacity=1024, free=500): def __init__(self, name=""ha-datacenter"", ds_ref=None): datastore = DataObject() datastore.ManagedObjectReference = [ds_ref] self.set(""datastore"", datastore)def create_datacenter(name, ds_ref=None): data_center = Datacenter(name, ds_ref)def create_datastore(name, capacity, free): data_store = Datastore(name, capacity, free) return data_store.objdef create_cluster(name, ds_ref): cluster._add_datastore(ds_ref)","def reset(): create_network() create_host_network_system() create_host_storage_system() create_host() create_host() create_datacenter() create_datastore() create_res_pool() create_cluster('test_cluster') create_cluster('test_cluster2') def cleanup(): """"""Clear the db contents."""""" for c in _CLASSES: _db_content[c] = {} def __init__(self, name=""fake-ds""): def __init__(self, name=""ha-datacenter""):def create_datacenter(): data_center = Datacenter()def create_datastore(): data_store = Datastore()def create_cluster(name): cluster._add_datastore(_get_object_refs(""Datastore"")[0])",147,70
openstack%2Fblazar-nova~master~I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d,openstack/blazar-nova,master,I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d,Reservation extensions to Nova API,MERGED,2013-12-19 12:17:18.000000000,2014-02-03 10:10:06.000000000,2014-02-03 10:10:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2928}, {'_account_id': 3012}, {'_account_id': 6582}, {'_account_id': 6786}, {'_account_id': 7075}, {'_account_id': 7166}, {'_account_id': 7494}, {'_account_id': 7535}]","[{'number': 1, 'created': '2013-12-19 12:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/a802f14479c5b4ce8382b7c34dcd4e02c895503f', 'message': 'Reservation extensions to Nova API.\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 2, 'created': '2013-12-20 16:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/b85862639100ca7103e1c62abe0ba4c2d7ed8ffe', 'message': 'Reservation extensions to Nova API.\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 3, 'created': '2013-12-26 09:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/5d2c6104c3e63195ddf6c17a82ca91f847cae1b5', 'message': 'Reservation extensions to Nova API.\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 4, 'created': '2013-12-26 09:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/530eb13489ce4bca2add0eaa679ae33b8739bed6', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 5, 'created': '2013-12-26 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/19b04c338769058ce406d09ed1a2f7a9f2859e62', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: bp nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 6, 'created': '2013-12-26 13:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/bc08ea0b786f852de6a81ff3e2cbff51f314ccb1', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 7, 'created': '2013-12-26 17:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/e4997633066085b1a2df117fd0b68fae09e05b87', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 8, 'created': '2013-12-26 17:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/d05f70f8c9c4c93d0e4fbbc03a7ee409569f8403', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 9, 'created': '2014-01-13 08:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/e2611b927215105655e1fe6895888153d6181071', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 10, 'created': '2014-01-13 09:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/f3cc1cd1ab4b3498e1c6780e256b796517c7c3cd', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 11, 'created': '2014-01-14 09:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/51bed7613b59a614298d9c6e89dc838386bf2c69', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 12, 'created': '2014-01-14 12:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/754819daea5f53d088903f444113e08cdac1af57', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 13, 'created': '2014-01-14 14:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/324597be068cb45f756875a188be64008e2b8d35', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 14, 'created': '2014-01-15 15:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/d31a49c93d2fc937002238734ff4b69989f84c8a', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 15, 'created': '2014-01-23 11:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/7f15f031d0459acf58b8bb027e92ac6c8b7b8be1', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 16, 'created': '2014-01-29 19:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/5d12ec3237b8d2b741bb2c2365b1faad9bdffec4', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}, {'number': 17, 'created': '2014-02-03 09:16:05.000000000', 'files': ['climatenova/api/extensions/default_reservation.py', 'climatenova/tests/api/__init__.py', 'climatenova/tests/api/extensions/test_reservation.py', 'test-requirements.txt', 'climatenova/api/extensions/__init__.py', 'climatenova/tests/api/extensions/test_default_reservation.py', 'climatenova/api/extensions/reservation.py', 'climatenova/tests/api/extensions/__init__.py', 'README.md', 'climatenova/api/__init__.py', 'etc/nova.conf.example'], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/7a6bca02c30da7fb70e75e4ae6c1530b3adadb15', 'message': 'Reservation extensions to Nova API\n\n* ReservationController: sends lease creation request to Climate\n  if instance should be reserved.\n* DefaultReservationController: adds hints to server creation request\n  if every VM should be reserved for some amount of time.\n\nImplements: blueprint nova-api-extensions\n\nChange-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d\n'}]",28,63097,7a6bca02c30da7fb70e75e4ae6c1530b3adadb15,68,10,17,3012,,,0,"Reservation extensions to Nova API

* ReservationController: sends lease creation request to Climate
  if instance should be reserved.
* DefaultReservationController: adds hints to server creation request
  if every VM should be reserved for some amount of time.

Implements: blueprint nova-api-extensions

Change-Id: I4aee23c5d8c76ee6f1cb0fee1bc54e784a83345d
",git fetch https://review.opendev.org/openstack/blazar-nova refs/changes/97/63097/9 && git format-patch -1 --stdout FETCH_HEAD,"['climate/extensions/__init__.py', 'requirements.txt', 'climate/extensions/default_reservation.py', 'climate/extensions/reservation.py', 'README.md']",5,a802f14479c5b4ce8382b7c34dcd4e02c895503f,bp/nova-api-extensions,Climate Nova related changes. Includes filters for Host Reservation and Nova API extensions for the VM reservation feature.,Climate Nova filter,236,1
openstack%2Fkeystone~stable%2Fhavana~I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48,openstack/keystone,stable/havana,I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48,list_revoked_tokens sql speedup for havana,MERGED,2014-01-29 15:43:09.000000000,2014-02-03 09:37:08.000000000,2014-02-01 19:25:18.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 67}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2218}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 6593}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-01-29 15:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0e01dfe45403d3637c2a7a8f0ed88ac240923f32', 'message': 'Narrow columns used in list_revoked_tokens sql\n\nCurrently the SQL backend lists revoked tokens by selecting all of the\ncolumns, including the massive ""extra"" column. This places a significant\nburden on the client library and wastes resources. We only need the\nid/expired columns to satisfy the API call.\n\nIn tests this query was several orders of magnitude faster with just two\nthousand un-expired revoked tokens.\n\nChange-Id: I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48\nCloses-Bug: #1253755\n(cherry picked from commit ab7221246af394f24e47484e822b8dcda37411aa)\n'}, {'number': 2, 'created': '2014-01-29 16:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/371cb54bf995f78dea6923f9640fc8772b55a53f', 'message': 'list_revoked_tokens sql speedup for havana\n\nThis consists of the following 3 patches:\n\n    Narrow columns used in list_revoked_tokens sql\n\n    Currently the SQL backend lists revoked tokens by selecting all of the\n    columns, including the massive ""extra"" column. This places a significant\n    burden on the client library and wastes resources. We only need the\n    id/expired columns to satisfy the API call.\n\n    In tests this query was several orders of magnitude faster with just two\n    thousand un-expired revoked tokens.\n    (cherry picked from commit ab7221246af394f24e47484e822b8dcda37411aa)\n\n    Add index to cover revoked token list\n\n    The individual expires and valid indexes do not fully cover the most\n    common query, which is the one that lists revoked tokens.\n\n    Because valid is only ever used in conjunction with expires, we do not\n    need it to have its own index now that there is a covering compound\n    index for expires and valid.\n\n    Note that he expires index is still useful alone for purging old tokens\n    as we do not filter for valid in that case.\n    (cherry picked from commit dd2c80c566f20a97a22e0d7d5a514be84772a955)\n\n    Remove unused token.valid index\n\n    Because valid is only ever used in conjunction with expires, we do not\n    need it to have its own index now that there is a covering compound\n    index for expires and valid.\n\n    Note that he expires index is still useful alone for purging old tokens\n    as we do not filter for valid in that case.\n    (cherry picked from commit 5d8a1a41420aa20d2aa21da6311c9d55b9e373b6)\n\nChange-Id: I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48\nCloses-Bug: #1253755\n'}, {'number': 3, 'created': '2014-01-30 12:40:32.000000000', 'files': ['keystone/token/backends/sql.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_backend_sql.py', 'keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py', 'keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2414bab51d134b713b2767435ed29755538d150a', 'message': 'list_revoked_tokens sql speedup for havana\n\nThis consists of the following 3 patches:\n\n    Narrow columns used in list_revoked_tokens sql\n\n    Currently the SQL backend lists revoked tokens by selecting all of the\n    columns, including the massive ""extra"" column. This places a significant\n    burden on the client library and wastes resources. We only need the\n    id/expired columns to satisfy the API call.\n\n    In tests this query was several orders of magnitude faster with just two\n    thousand un-expired revoked tokens.\n    (cherry picked from commit ab7221246af394f24e47484e822b8dcda37411aa)\n\n    Add index to cover revoked token list\n\n    The individual expires and valid indexes do not fully cover the most\n    common query, which is the one that lists revoked tokens.\n\n    Because valid is only ever used in conjunction with expires, we do not\n    need it to have its own index now that there is a covering compound\n    index for expires and valid.\n\n    Note that he expires index is still useful alone for purging old tokens\n    as we do not filter for valid in that case.\n    (cherry picked from commit dd2c80c566f20a97a22e0d7d5a514be84772a955)\n\n    Remove unused token.valid index\n\n    Because valid is only ever used in conjunction with expires, we do not\n    need it to have its own index now that there is a covering compound\n    index for expires and valid.\n\n    Note that he expires index is still useful alone for purging old tokens\n    as we do not filter for valid in that case.\n    (cherry picked from commit 5d8a1a41420aa20d2aa21da6311c9d55b9e373b6)\n\nChange-Id: I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48\nCloses-Bug: #1253755\n'}]",0,69884,2414bab51d134b713b2767435ed29755538d150a,23,10,3,6593,,,0,"list_revoked_tokens sql speedup for havana

This consists of the following 3 patches:

    Narrow columns used in list_revoked_tokens sql

    Currently the SQL backend lists revoked tokens by selecting all of the
    columns, including the massive ""extra"" column. This places a significant
    burden on the client library and wastes resources. We only need the
    id/expired columns to satisfy the API call.

    In tests this query was several orders of magnitude faster with just two
    thousand un-expired revoked tokens.
    (cherry picked from commit ab7221246af394f24e47484e822b8dcda37411aa)

    Add index to cover revoked token list

    The individual expires and valid indexes do not fully cover the most
    common query, which is the one that lists revoked tokens.

    Because valid is only ever used in conjunction with expires, we do not
    need it to have its own index now that there is a covering compound
    index for expires and valid.

    Note that he expires index is still useful alone for purging old tokens
    as we do not filter for valid in that case.
    (cherry picked from commit dd2c80c566f20a97a22e0d7d5a514be84772a955)

    Remove unused token.valid index

    Because valid is only ever used in conjunction with expires, we do not
    need it to have its own index now that there is a covering compound
    index for expires and valid.

    Note that he expires index is still useful alone for purging old tokens
    as we do not filter for valid in that case.
    (cherry picked from commit 5d8a1a41420aa20d2aa21da6311c9d55b9e373b6)

Change-Id: I04d62b98d5d760a3fbc3c8db61530f7ebccb0a48
Closes-Bug: #1253755
",git fetch https://review.opendev.org/openstack/keystone refs/changes/84/69884/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/backends/sql.py', 'keystone/tests/test_backend_sql.py']",2,0e01dfe45403d3637c2a7a8f0ed88ac240923f32,,"from keystone.openstack.common.fixture import moxstuboutfrom keystone.token.backends import sql as token_sql def test_token_revocation_list_uses_right_columns(self): # This query used to be heavy with too many columns. We want # to make sure it is only running with the minimum columns # necessary. fixture = self.useFixture(moxstubout.MoxStubout()) self.mox = fixture.mox tok = token_sql.Token() session = tok.get_session() q = session.query(token_sql.TokenModel.id, token_sql.TokenModel.expires) self.mox.StubOutWithMock(session, 'query') session.query(token_sql.TokenModel.id, token_sql.TokenModel.expires).AndReturn(q) self.mox.StubOutWithMock(tok, 'get_session') tok.get_session().AndReturn(session) self.mox.ReplayAll() tok.list_revoked_tokens()", pass,22,4
openstack%2Fglance~master~I4c80c64e2d1afaf518886b51a50300a576ee6317,openstack/glance,master,I4c80c64e2d1afaf518886b51a50300a576ee6317,Don't override transport_url with old configs,MERGED,2014-01-28 14:31:08.000000000,2014-02-03 09:03:18.000000000,2014-02-03 09:03:17.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-01-28 14:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/16d6b1f7313ab896f57becc4316f2a8f67305148', 'message': ""Don't override transport_url with old configs\n\nThe backwards compatibility support turned out being a forward\ncompatibility blocker. This aptch attempts to first load the notifier\ntransport using the transport_url and then, if the transport_url was not\nconfigured, it loads the transport by using the old strategy config\nparams.\n\nCloses-bug: #1263945\n\nChange-Id: I4c80c64e2d1afaf518886b51a50300a576ee6317\n""}, {'number': 2, 'created': '2014-01-28 16:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d1729540565c148d79c4b6ffc091a597ffcc9a22', 'message': ""Don't override transport_url with old configs\n\nThe backwards compatibility support turned out being a forward\ncompatibility blocker. This aptch attempts to first load the notifier\ntransport using the transport_url and then, if the transport_url was not\nconfigured, it loads the transport by using the old strategy config\nparams.\n\nCloses-bug: #1263945\n\nChange-Id: I4c80c64e2d1afaf518886b51a50300a576ee6317\n""}, {'number': 3, 'created': '2014-01-28 18:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a0eacb19772894e988215ecaf285cfbc6040a039', 'message': ""Don't override transport_url with old configs\n\nThe backwards compatibility support turned out being a forward\ncompatibility blocker. This aptch attempts to first load the notifier\ntransport using the transport_url and then, if the transport_url was not\nconfigured, it loads the transport by using the old strategy config\nparams.\n\nCloses-bug: #1263945\n\nChange-Id: I4c80c64e2d1afaf518886b51a50300a576ee6317\n""}, {'number': 4, 'created': '2014-01-29 08:23:30.000000000', 'files': ['glance/tests/unit/test_notifier.py', 'glance/notifier.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/7e13cf73f1869599c1218cf58468c21bb22dd5bf', 'message': ""Don't override transport_url with old configs\n\nThe backwards compatibility support turned out being a forward\ncompatibility blocker. This patch attempts to first load the notifier\ntransport using the transport_url and then, if the transport_url was not\nconfigured, it loads the transport by using the old strategy config\nparams.\n\nCloses-bug: #1263945\n\nChange-Id: I4c80c64e2d1afaf518886b51a50300a576ee6317\n""}]",3,69614,7e13cf73f1869599c1218cf58468c21bb22dd5bf,21,5,4,6159,,,0,"Don't override transport_url with old configs

The backwards compatibility support turned out being a forward
compatibility blocker. This patch attempts to first load the notifier
transport using the transport_url and then, if the transport_url was not
configured, it loads the transport by using the old strategy config
params.

Closes-bug: #1263945

Change-Id: I4c80c64e2d1afaf518886b51a50300a576ee6317
",git fetch https://review.opendev.org/openstack/glance refs/changes/14/69614/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_notifier.py', 'glance/notifier.py']",2,16d6b1f7313ab896f57becc4316f2a8f67305148,oslo.messaging," # NOTE(flaper87): Assume the user has configured # the transport url. self._transport = messaging.get_transport(CONF) # NOTE(flaper87): This needs to be checked # here because the `get_transport` call # registers `transport_url` into ConfigOpts. if not CONF.transport_url: # NOTE(flaper87): The next 3 lines help # with the migration to oslo.messaging. # Without them, gate tests won't know # what driver should be loaded. # Once this patch lands, devstack will be # updated and then these lines will be removed. url = None if _strategy in ['rabbit', 'qpid']: url = _strategy + '://' self._transport = messaging.get_transport(CONF, url) "," # NOTE(flaper87): The next 3 lines help # with the migration to oslo.messaging. # Without them, gate tests won't know # what driver should be loaded. # Once this patch lands, devstack will be # updated and then these lines will be removed. url = None if _strategy in ['rabbit', 'qpid']: url = _strategy + '://' self._transport = messaging.get_transport(CONF, url)",34,12
openstack%2Fmanila~master~Ibf3d45c6a37493cc0ced7cc6e6c552f27b6e4338,openstack/manila,master,Ibf3d45c6a37493cc0ced7cc6e6c552f27b6e4338,Fix bad calls to model_query(),MERGED,2014-01-31 17:38:26.000000000,2014-02-03 08:39:12.000000000,2014-02-03 08:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 8863}]","[{'number': 1, 'created': '2014-01-31 17:38:26.000000000', 'files': ['manila/tests/api/v1/test_share_metadata.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/test_quota.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/6de896e5c5fb8bb8dd22497b35ba9aebdb5add62', 'message': ""Fix bad calls to model_query()\n\nmodel_query() function was changed recently\nto use 'model' object as a second positional\nargument, so all callers need to adhere to\nthis requirement.\nFix 'bad' model_query().\nRemove 'skips' from tests that were failing\ndue to bad model_query() calls.\nCloses-Bug: #1275026\n\nChange-Id: Ibf3d45c6a37493cc0ced7cc6e6c552f27b6e4338\n""}]",0,70383,6de896e5c5fb8bb8dd22497b35ba9aebdb5add62,7,4,1,9069,,,0,"Fix bad calls to model_query()

model_query() function was changed recently
to use 'model' object as a second positional
argument, so all callers need to adhere to
this requirement.
Fix 'bad' model_query().
Remove 'skips' from tests that were failing
due to bad model_query() calls.
Closes-Bug: #1275026

Change-Id: Ibf3d45c6a37493cc0ced7cc6e6c552f27b6e4338
",git fetch https://review.opendev.org/openstack/manila refs/changes/83/70383/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/api/v1/test_share_metadata.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/test_quota.py']",3,6de896e5c5fb8bb8dd22497b35ba9aebdb5add62,fix_model_query,, @test.skip_test('Skip due to failure after DB migration #10') @test.skip_test('Skip due to failure after DB migration #10') @test.skip_test('Skip due to failure after DB migration #10') @test.skip_test('Skip due to failure after DB migration #10') @test.skip_test('Skip due to failure after DB migration #10') @test.skip_test('Skip due to failure after DB migration #10'),7,16
openstack%2Foperations-guide~master~I1a678d58b5043025eeef32bac7a0bc8cc99ff89c,openstack/operations-guide,master,I1a678d58b5043025eeef32bac7a0bc8cc99ff89c,Add doc-test.conf,MERGED,2014-02-03 07:14:36.000000000,2014-02-03 08:21:19.000000000,2014-02-03 08:21:19.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-03 07:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/638eb886743df6880b64d017c939b479425e3129', 'message': 'Add doc-test.conf\n\nThe file is need for v0.5 of the gating tools.\n\nChange-Id: I1a678d58b5043025eeef32bac7a0bc8cc99ff89c\n'}, {'number': 2, 'created': '2014-02-03 07:16:19.000000000', 'files': ['doc-test.conf'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ea88d0d5587e7b2804c93d08fae04dc598cab6a7', 'message': 'Add doc-test.conf\n\nThe file is need for v0.5 of the gating tools.\n\nblueprint draft-docs-on-docs-draft\nChange-Id: I1a678d58b5043025eeef32bac7a0bc8cc99ff89c\n'}]",0,70659,ea88d0d5587e7b2804c93d08fae04dc598cab6a7,7,3,2,6547,,,0,"Add doc-test.conf

The file is need for v0.5 of the gating tools.

blueprint draft-docs-on-docs-draft
Change-Id: I1a678d58b5043025eeef32bac7a0bc8cc99ff89c
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/59/70659/2 && git format-patch -1 --stdout FETCH_HEAD,['doc-test.conf'],1,638eb886743df6880b64d017c939b479425e3129,bp/draft-docs-on-docs-draft,[DEFAULT] #file_exception = st-training-guides.xml # ,,3,0
openstack%2Fcinder~master~I3709789d33ff7b07eaeaf725f5183105443d0abc,openstack/cinder,master,I3709789d33ff7b07eaeaf725f5183105443d0abc,Add support for special char in volume metadata,MERGED,2014-01-29 18:08:31.000000000,2014-02-03 08:03:26.000000000,2014-02-03 08:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 8912}]","[{'number': 1, 'created': '2014-01-29 18:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d2272dbdc96b21a02cef8121d0ee8a7b6861bced', 'message': 'Add support for special char in volume metadata\n\nUsing special characters such as ""&"" in volume metadata caused SAX\nparser to split text into multiple child nodes, as stated in the\nspecs for SAX parsers. In this case extract_text would return\n\'None\' because text was return iff there was exactly\none child node. Concatenating the values of child nodes accounts\nfor SAX parsers splitting contigous characters into\nmultiple chunks.\n\nChange-Id: I3709789d33ff7b07eaeaf725f5183105443d0abc\nCloses-Bug: #1268513\n'}, {'number': 2, 'created': '2014-01-30 20:01:15.000000000', 'files': ['cinder/tests/api/openstack/test_wsgi.py', 'cinder/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d028b77a4bde48ed2729f370773c9d510156686', 'message': 'Add support for special char in volume metadata\n\nUsing special characters such as ""&"" in volume metadata caused SAX\nparser to split text into multiple child nodes, as stated in the\nspecs for SAX parsers. In this case extract_text would return\n\'None\' because text was return if there was exactly\none child node. Concatenating the values of child nodes accounts\nfor SAX parsers splitting contigous characters into\nmultiple chunks.\n\nChange-Id: I3709789d33ff7b07eaeaf725f5183105443d0abc\nCloses-Bug: #1268513\n'}]",1,69933,7d028b77a4bde48ed2729f370773c9d510156686,14,6,2,8912,,,0,"Add support for special char in volume metadata

Using special characters such as ""&"" in volume metadata caused SAX
parser to split text into multiple child nodes, as stated in the
specs for SAX parsers. In this case extract_text would return
'None' because text was return if there was exactly
one child node. Concatenating the values of child nodes accounts
for SAX parsers splitting contigous characters into
multiple chunks.

Change-Id: I3709789d33ff7b07eaeaf725f5183105443d0abc
Closes-Bug: #1268513
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/69933/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/openstack/wsgi.py'],1,d2272dbdc96b21a02cef8121d0ee8a7b6861bced,bug/1268513, text = [] # Cannot assume entire text will be in a single child node because SAX # parsers may split contiguous character data into multiple chunks for child in node.childNodes: if child.nodeType == child.TEXT_NODE: text.append(child.nodeValue) return ''.join(text)," if len(node.childNodes) == 1: child = node.childNodes[0] if child.nodeType == child.TEXT_NODE: return child.nodeValue return """"",6,4
openstack%2Fcinder~master~Ifa15df5d9c4517f75a1a050ff5aa34225f33931b,openstack/cinder,master,Ifa15df5d9c4517f75a1a050ff5aa34225f33931b,Remove a catching exception during delete_volume,MERGED,2014-02-01 13:46:18.000000000,2014-02-03 08:03:18.000000000,2014-02-03 08:03:18.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 6676}, {'_account_id': 8124}, {'_account_id': 8157}]","[{'number': 1, 'created': '2014-02-01 13:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/73cd9f2a2a8385989c2d63500de525a660c74b8e', 'message': 'Remove a catching exception during delete_volume\n\nGlanceMetadataNotFound Exception was catching during\na call to volume_glance_metadata_delete_by_volume().\nThis exception is never thrown by the implementation.\nThis catching has been removed and replaced by a test in\norder to log a debug when metadata were retrieved.\n\nChange-Id: Ifa15df5d9c4517f75a1a050ff5aa34225f33931b\nCloses-Bug: #1274601\n'}, {'number': 2, 'created': '2014-02-01 14:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9da9815db9ea95d052dc1971ba9c638115f9beed', 'message': 'Remove a catching exception during delete_volume\n\nGlanceMetadataNotFound Exception was catching during\na call to volume_glance_metadata_delete_by_volume().\nThis exception is never thrown by the implementation.\nThis catching has been removed and replaced by a test in\norder to log a debug when metadata were retrieved.\n\nChange-Id: Ifa15df5d9c4517f75a1a050ff5aa34225f33931b\nCloses-Bug: #1274601\n'}, {'number': 3, 'created': '2014-02-01 14:48:21.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d311066dd43bdc4598fa76837d78ecfac16f5e58', 'message': 'Remove a catching exception during delete_volume\n\nGlanceMetadataNotFound Exception was catching during\na call to volume_glance_metadata_delete_by_volume().\nThis exception is never thrown by the implementation.\nThis catching has been removed.\n\nChange-Id: Ifa15df5d9c4517f75a1a050ff5aa34225f33931b\nCloses-Bug: #1274601\n'}]",6,70531,d311066dd43bdc4598fa76837d78ecfac16f5e58,19,6,3,8157,,,0,"Remove a catching exception during delete_volume

GlanceMetadataNotFound Exception was catching during
a call to volume_glance_metadata_delete_by_volume().
This exception is never thrown by the implementation.
This catching has been removed.

Change-Id: Ifa15df5d9c4517f75a1a050ff5aa34225f33931b
Closes-Bug: #1274601
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/70531/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,73cd9f2a2a8385989c2d63500de525a660c74b8e,bug/1274601," metadatas = self.db.volume_glance_metadata_delete_by_volume(context, volume_id) if metadatas:"," try: self.db.volume_glance_metadata_delete_by_volume(context, volume_id) except exception.GlanceMetadataNotFound: LOG.debug(_(""no glance metadata found for volume %s""), volume_ref['id'])",3,5
openstack%2Ftempest~master~Ic7372817777256ce723843ffd3e0bc670261aa78,openstack/tempest,master,Ic7372817777256ce723843ffd3e0bc670261aa78,"Remove suffix ""JSON"" from Nova v3 API test classes",MERGED,2014-01-30 04:45:57.000000000,2014-02-03 07:30:04.000000000,2014-02-03 07:30:03.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8085}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-01-30 04:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/351ef3a9c03e74447635c280111a1ab56de9e3f2', 'message': 'Remove suffix ""JSON"" from Nova v3 API test classes\n\nWe have decided that XML support is removed from Nova v3 API and\nthe tests also has been removed from Tempest already.\nThen the suffix ""JSON"" of Nova v3 API test classes does not have\nany meanings.\n\nThis patch removes them for cleanup. This is made because of a\ncomment of Ie3c595fb77143e58e30404c42f358d6443a52c0b .\n\nPart of bp:remove-v3-xml-api\n\nChange-Id: Ic7372817777256ce723843ffd3e0bc670261aa78\n'}, {'number': 2, 'created': '2014-02-03 03:23:55.000000000', 'files': ['tempest/api/compute/v3/admin/test_servers.py', 'tempest/api/compute/v3/admin/test_instance_usage_audit_log.py', 'tempest/api/compute/v3/images/test_list_image_filters.py', 'tempest/api/compute/v3/servers/test_server_metadata.py', 'tempest/api/compute/v3/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/servers/test_servers_negative.py', 'tempest/api/compute/v3/servers/test_list_server_filters.py', 'tempest/api/compute/v3/admin/test_availability_zone.py', 'tempest/api/compute/v3/images/test_images.py', 'tempest/api/compute/v3/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/v3/admin/test_simple_tenant_usage_negative.py', 'tempest/api/compute/v3/servers/test_servers.py', 'tempest/api/compute/v3/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/admin/test_hypervisor_negative.py', 'tempest/api/compute/v3/test_extensions.py', 'tempest/api/compute/v3/keypairs/test_keypairs.py', 'tempest/api/compute/v3/admin/test_aggregates.py', 'tempest/api/compute/v3/admin/test_flavors_extra_specs.py', 'tempest/api/compute/v3/admin/test_hypervisor.py', 'tempest/api/compute/v3/admin/test_services.py', 'tempest/api/compute/v3/certificates/test_certificates.py', 'tempest/api/compute/v3/images/test_image_metadata.py', 'tempest/api/compute/v3/servers/test_list_servers_negative.py', 'tempest/api/compute/v3/admin/test_hosts.py', 'tempest/api/compute/v3/admin/test_services_negative.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/api/compute/v3/admin/test_servers_negative.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py', 'tempest/api/compute/v3/servers/test_server_rescue.py', 'tempest/api/compute/v3/test_quotas.py', 'tempest/api/compute/v3/test_version.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/v3/admin/test_simple_tenant_usage.py', 'tempest/api/compute/v3/images/test_image_metadata_negative.py', 'tempest/api/compute/v3/servers/test_create_server.py', 'tempest/api/compute/v3/admin/test_instance_usage_audit_log_negative.py', 'tempest/api/compute/v3/admin/test_quotas.py', 'tempest/api/compute/v3/images/test_images_oneserver.py', 'tempest/api/compute/v3/keypairs/test_keypairs_negative.py', 'tempest/api/compute/v3/admin/test_flavors_access.py', 'tempest/api/compute/v3/admin/test_hosts_negative.py', 'tempest/api/compute/v3/servers/test_multiple_create.py', 'tempest/api/compute/v3/servers/test_instance_actions.py', 'tempest/api/compute/v3/admin/test_aggregates_negative.py', 'tempest/api/compute/v3/admin/test_availability_zone_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f508ed04ecb44c5f1ec4e4e577acfc1de8c2f26', 'message': 'Remove suffix ""JSON"" from Nova v3 API test classes\n\nWe have decided that XML support is removed from Nova v3 API and\nthe tests also has been removed from Tempest already.\nThen the suffix ""JSON"" of Nova v3 API test classes does not have\nany meanings.\n\nThis patch removes them for cleanup. This is made because of a\ncomment of Ie3c595fb77143e58e30404c42f358d6443a52c0b .\n\nPart of bp:remove-v3-xml-api\n\nChange-Id: Ic7372817777256ce723843ffd3e0bc670261aa78\n'}]",0,70052,7f508ed04ecb44c5f1ec4e4e577acfc1de8c2f26,19,7,2,6167,,,0,"Remove suffix ""JSON"" from Nova v3 API test classes

We have decided that XML support is removed from Nova v3 API and
the tests also has been removed from Tempest already.
Then the suffix ""JSON"" of Nova v3 API test classes does not have
any meanings.

This patch removes them for cleanup. This is made because of a
comment of Ie3c595fb77143e58e30404c42f358d6443a52c0b .

Part of bp:remove-v3-xml-api

Change-Id: Ic7372817777256ce723843ffd3e0bc670261aa78
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/70052/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/admin/test_servers.py', 'tempest/api/compute/v3/admin/test_instance_usage_audit_log.py', 'tempest/api/compute/v3/images/test_list_image_filters.py', 'tempest/api/compute/v3/servers/test_server_metadata.py', 'tempest/api/compute/v3/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/servers/test_servers_negative.py', 'tempest/api/compute/v3/servers/test_list_server_filters.py', 'tempest/api/compute/v3/admin/test_availability_zone.py', 'tempest/api/compute/v3/images/test_images.py', 'tempest/api/compute/v3/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/v3/admin/test_simple_tenant_usage_negative.py', 'tempest/api/compute/v3/servers/test_servers.py', 'tempest/api/compute/v3/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/admin/test_hypervisor_negative.py', 'tempest/api/compute/v3/test_extensions.py', 'tempest/api/compute/v3/keypairs/test_keypairs.py', 'tempest/api/compute/v3/admin/test_aggregates.py', 'tempest/api/compute/v3/admin/test_flavors_extra_specs.py', 'tempest/api/compute/v3/admin/test_hypervisor.py', 'tempest/api/compute/v3/admin/test_services.py', 'tempest/api/compute/v3/certificates/test_certificates.py', 'tempest/api/compute/v3/images/test_image_metadata.py', 'tempest/api/compute/v3/servers/test_list_servers_negative.py', 'tempest/api/compute/v3/admin/test_hosts.py', 'tempest/api/compute/v3/admin/test_services_negative.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/api/compute/v3/admin/test_servers_negative.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py', 'tempest/api/compute/v3/servers/test_server_rescue.py', 'tempest/api/compute/v3/test_quotas.py', 'tempest/api/compute/v3/test_version.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/v3/admin/test_simple_tenant_usage.py', 'tempest/api/compute/v3/images/test_image_metadata_negative.py', 'tempest/api/compute/v3/servers/test_create_server.py', 'tempest/api/compute/v3/admin/test_instance_usage_audit_log_negative.py', 'tempest/api/compute/v3/admin/test_quotas.py', 'tempest/api/compute/v3/images/test_images_oneserver.py', 'tempest/api/compute/v3/keypairs/test_keypairs_negative.py', 'tempest/api/compute/v3/admin/test_flavors_access.py', 'tempest/api/compute/v3/admin/test_hosts_negative.py', 'tempest/api/compute/v3/servers/test_multiple_create.py', 'tempest/api/compute/v3/servers/test_instance_actions.py', 'tempest/api/compute/v3/admin/test_aggregates_negative.py', 'tempest/api/compute/v3/admin/test_availability_zone_negative.py']",46,351ef3a9c03e74447635c280111a1ab56de9e3f2,bp/remove-v3-xml-api,"class AZAdminNegativeV3Test(base.BaseV3ComputeAdminTest): super(AZAdminNegativeV3Test, cls).setUpClass()","class AZAdminNegativeV3TestJSON(base.BaseV3ComputeAdminTest): super(AZAdminNegativeV3TestJSON, cls).setUpClass()",108,108
openstack%2Ftempest~master~I3db0381d48919c62f3f3c6d60fc14cf4dee9c4a3,openstack/tempest,master,I3db0381d48919c62f3f3c6d60fc14cf4dee9c4a3,Fix attach_interfaces tests,MERGED,2014-01-22 17:07:22.000000000,2014-02-03 07:29:55.000000000,2014-02-03 07:29:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4393}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 6761}, {'_account_id': 7020}, {'_account_id': 8576}]","[{'number': 1, 'created': '2014-01-22 17:07:22.000000000', 'files': ['tempest/services/compute/json/interfaces_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/90485ede9ecc25df46958d436e3a67c4c3faa861', 'message': 'Fix attach_interfaces tests\n\nTempest\'s interfaces_client was not calling Nova ""os-interface"" API correctly.\nThe POST parameter interfaceAttachment was ill formed.\n\nChange-Id: I3db0381d48919c62f3f3c6d60fc14cf4dee9c4a3\nCloses-Bug: #1271642\n'}]",0,68437,90485ede9ecc25df46958d436e3a67c4c3faa861,11,8,1,7350,,,0,"Fix attach_interfaces tests

Tempest's interfaces_client was not calling Nova ""os-interface"" API correctly.
The POST parameter interfaceAttachment was ill formed.

Change-Id: I3db0381d48919c62f3f3c6d60fc14cf4dee9c4a3
Closes-Bug: #1271642
",git fetch https://review.opendev.org/openstack/tempest refs/changes/37/68437/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/compute/json/interfaces_client.py'],1,90485ede9ecc25df46958d436e3a67c4c3faa861,master, post_body['interfaceAttachment']['port_id'] = port_id if network_id: post_body['interfaceAttachment']['net_id'] = network_id if fixed_ip: fip = dict(ip_address=fixed_ip) post_body['interfaceAttachment']['fixed_ips'] = [fip], post_body['port_id'] = port_id if network_id: post_body['net_id'] = network_id if fixed_ip: post_body['fixed_ips'] = [dict(ip_address=fixed_ip)],4,3
openstack%2Foperations-guide~master~I424f8b8f6c38a0b08f80fc0e72d3cd52785abba5,openstack/operations-guide,master,I424f8b8f6c38a0b08f80fc0e72d3cd52785abba5,Fix path used in generatepot,MERGED,2014-02-03 02:47:34.000000000,2014-02-03 07:20:34.000000000,2014-02-03 07:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-03 02:47:34.000000000', 'files': ['tools/generatepot'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/e43b39ad6555aa01f56c4799f8cf8115b7cf01be', 'message': 'Fix path used in generatepot\n\nThe generatepot script used to generate POT files for translation\nstill used an old pre-restructure path.\nThis patch fixes to use the new path ""doc"".\n\nChange-Id: I424f8b8f6c38a0b08f80fc0e72d3cd52785abba5\nCloses-Bug: #1275596\n'}]",0,70641,e43b39ad6555aa01f56c4799f8cf8115b7cf01be,5,2,1,841,,,0,"Fix path used in generatepot

The generatepot script used to generate POT files for translation
still used an old pre-restructure path.
This patch fixes to use the new path ""doc"".

Change-Id: I424f8b8f6c38a0b08f80fc0e72d3cd52785abba5
Closes-Bug: #1275596
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/41/70641/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/generatepot'],1,e43b39ad6555aa01f56c4799f8cf8115b7cf01be,bug/1275596,"root = ""./doc""","root = ""./doc/src/docbkx""",1,1
openstack-attic%2Fidentity-api~master~I13b653d56cb6b694470ba10fd33606503f204091,openstack-attic/identity-api,master,I13b653d56cb6b694470ba10fd33606503f204091,Store password in the credentials adding a password type,ABANDONED,2013-11-11 19:51:02.000000000,2014-02-03 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 994}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7052}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-11-11 19:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/83c68627ee71bdf8a62583707168eefa6e3564b6', 'message': 'Store password in the credentials adding a password type\n\nEnable creation of multiple passwords for a user adding the\ncredentials tupe password and a optional `expires_at` and\n`status` to track current and expired credentials.\n\nA credential having the same `id` as the `user_id` is\nconsidered the main credential for that user.\n\nblueprint password-rotation\n\nChange-Id: I13b653d56cb6b694470ba10fd33606503f204091\n'}, {'number': 2, 'created': '2013-11-11 21:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/d847716b8ad6efa41a3ebb07fe562402a5a33e0e', 'message': 'Store password in the credentials adding a password type\n\nEnable creation of multiple passwords for a user adding the\ncredentials tupe password and a optional `expires_at` and\n`status` to track current and expired credentials.\n\nA credential having the same `id` as the `user_id` is\nconsidered the main credential for that user.\n\nblueprint password-rotation\n\nChange-Id: I13b653d56cb6b694470ba10fd33606503f204091\n'}, {'number': 3, 'created': '2013-11-11 22:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/5b8e71536cb5c257522db3eda2a34df6a2b30053', 'message': 'Store password in the credentials adding a password type\n\nEnable creation of multiple passwords for a user adding the\ncredentials tupe password and a optional `expires_at` and\n`status` to track current and expired credentials.\n\nA credential having the same `id` as the `user_id` is\nconsidered the main credential for that user.\n\nblueprint password-rotation\n\nChange-Id: I13b653d56cb6b694470ba10fd33606503f204091\n'}, {'number': 4, 'created': '2013-11-11 23:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/2619e9e1223fe9948d01bd12739861906c7c03b3', 'message': 'Store password in the credentials adding a password type\n\nEnable creation of multiple passwords for a user adding the\ncredentials tupe password and a optional `expires_at` and\n`status` to track current and expired credentials.\n\nA credential having the same `id` as the `user_id` is\nconsidered the main credential for that user.\n\nblueprint password-rotation\n\nChange-Id: I13b653d56cb6b694470ba10fd33606503f204091\n'}, {'number': 5, 'created': '2013-11-12 18:12:47.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/bd9b510eb26b80165270598fd3cde0fcf67f457d', 'message': 'Store password in the credentials adding a password type\n\nEnable creation of multiple passwords for a user adding the\ncredentials tupe password and a optional `expires_at` and\n`status` to track current and expired credentials.\n\nA credential having the same `id` as the `user_id` is\nconsidered the main credential for that user.\n\nblueprint password-rotation\n\nChange-Id: I13b653d56cb6b694470ba10fd33606503f204091\n'}]",25,55906,bd9b510eb26b80165270598fd3cde0fcf67f457d,13,10,5,7052,,,0,"Store password in the credentials adding a password type

Enable creation of multiple passwords for a user adding the
credentials tupe password and a optional `expires_at` and
`status` to track current and expired credentials.

A credential having the same `id` as the `user_id` is
considered the main credential for that user.

blueprint password-rotation

Change-Id: I13b653d56cb6b694470ba10fd33606503f204091
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/06/55906/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3.md'],1,83c68627ee71bdf8a62583707168eefa6e3564b6,bp/password-rotation,"- Credential based password storage for multiple password and expiration date support. Representing the credential type, such as `password`, `ec2` or `cert`. A specific implementation may determine the list of supported types.- `expires_at` (string, ISO 8601 extended format date time with microseconds) *New in version 3.2* Timestamp indicating when this credential ceases from being `active` and need to be replaced/re-issued. A typical usage, for the credential type `password`, is to set a password expiration date. - `status` (string) *New in version 3.2* References the current status of the credentials in case an expiration timestamp has been set. In this case the `status` field can have the following values: `active` or `expired`. *New in version 3.2* Example of entities with type password: Active Credential { ""credential"": { ""blob"": ""secrete"", ""id"": ""0ca8f6"", ""expires_at"": ""2014-01-01T00:00:00Z"", ""links"": { ""self"": ""http://identity:35357/v3/credentials/80239a"" }, ""project_id"": ""263fd9"", ""status"": ""active"" ""type"": ""password"", ""user_id"": ""0ca8f6"" } } *Note*: when the `user_id` and credential `id` are the same, it means that the specific credentia is the main credential for the given user. Additional credentials can be added referencing them to the user using the `user_id`, but having a different credential `id`. A credential rotation can be performed simply swapping the credential `id` to `user_id`, for the new credential, and `user_id` to `id` for the old one. Expired Credential { ""credential"": { ""blob"": ""segreto"", ""id"": ""80238a"", ""expires_at"": ""2013-01-01T00:00:00Z"", ""links"": { ""self"": ""http://identity:35357/v3/credentials/80238a"" }, ""project_id"": ""263fd9"", ""status"": ""expired"" ""type"": ""password"", ""user_id"": ""0ca8f6"" } } #### Change user password: `POST /users/{user_id}/password` Request: { ""user"": { ""password"": ""..."", ""original_password"": ""..."" } } Response: Status: 204 No Content *New in version 3.2* The `password` credential type has been added to support password based authentication method. Password is not stored in the user entity anymore and instead in the credential `blob` when the credential type is set to `password`. Example:: Request: { ""credential"": { ""blob"": ""--password string--"", ""expires_at"": ""--optional--"", ""project_id"": ""--optional--"", ""type"": ""password"", ""user_id"": ""--user--id--"" } } Response: { ""credential"": { ""blob"": ""secrete"", ""id"": ""--credential-id--"", ""expires_at"": ""-- "", ""links"": { ""self"": ""http://identity:35357/v3/credentials/--credential-id--"" }, ""project_id"": ""--project-id--"", ""status"": ""active"" ""type"": ""password"", ""user_id"": ""--user--id--"" } } "," Representing the credential type, such as `ec2` or `cert`. A specific implementation may determine the list of supported types.",105,2
openstack%2Fhorizon~master~I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e,openstack/horizon,master,I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e,Inclusion of exception message to UI error,ABANDONED,2013-12-13 16:09:12.000000000,2014-02-03 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5280}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 6966}, {'_account_id': 7585}, {'_account_id': 8648}, {'_account_id': 8746}, {'_account_id': 9214}, {'_account_id': 9225}, {'_account_id': 9275}, {'_account_id': 9313}, {'_account_id': 9317}, {'_account_id': 9412}, {'_account_id': 9449}, {'_account_id': 9450}, {'_account_id': 9659}, {'_account_id': 9692}]","[{'number': 1, 'created': '2013-12-13 16:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/426ad5d6cb4c37b499175de04a35caf7feb1c3ad', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}, {'number': 2, 'created': '2013-12-13 19:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6ed5c953a7d3f064a696ff2c29bc778f2ec1dc35', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}, {'number': 3, 'created': '2013-12-16 18:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a5753142e9164218ffc6f089cf0ed3fe25759325', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}, {'number': 4, 'created': '2013-12-30 20:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b110f497c60fc5a94578eb41d458567a02a01b74', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}, {'number': 5, 'created': '2014-01-02 20:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9637af6997a2c2322c5697835077ec5fa3807e0d', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}, {'number': 6, 'created': '2014-01-03 12:27:34.000000000', 'files': ['horizon/tables/actions.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8cbfaad101184ee8500cbf9e8c32ec22643f37b5', 'message': 'Inclusion of exception message to UI error\n\nIn order to show more information about errors to users, the exception messages\nhave been included in the UI messages. This solve the ambiguous explanation at\ndeleting security groups in use.\n\nChange-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e\nCloses-Bug:#1210540\n'}]",13,62026,8cbfaad101184ee8500cbf9e8c32ec22643f37b5,52,22,6,9449,,,0,"Inclusion of exception message to UI error

In order to show more information about errors to users, the exception messages
have been included in the UI messages. This solve the ambiguous explanation at
deleting security groups in use.

Change-Id: I8536e3f1dd365a4ba2dffcd4000dd284f2c5a92e
Closes-Bug:#1210540
",git fetch https://review.opendev.org/openstack/horizon refs/changes/26/62026/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/tables/actions.py'],1,426ad5d6cb4c37b499175de04a35caf7feb1c3ad,bug/1210540," exception_msg = ex.message.strip() if exception_msg.__len__() > 0: msg += "". "" + exception_msg",,3,0
openstack%2Fkeystone~master~I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe,openstack/keystone,master,I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe,Remove side effects caused by dict parameters passed by reference,ABANDONED,2014-01-20 20:12:51.000000000,2014-02-03 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 356}, {'_account_id': 6486}, {'_account_id': 6738}, {'_account_id': 9293}]","[{'number': 1, 'created': '2014-01-20 20:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0fa1a991c193972bf4059ef518bfa49fccbebeb8', 'message': 'cleans up dict.copy() calls\n\nThere were a couple method calls that had side effects on dicts passed in.  Added a few tests to confirm that the original dict was not modified by the call, and fixed a couple methods that did have side effects.  Removed a couple of dict.copy() calls in parameter lists for method calls.\n\nChange-Id: I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe\nCloses-Bug: #928042\n'}, {'number': 2, 'created': '2014-01-20 22:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8bf717901f7462babceeaea1fed6f030554a9c8', 'message': 'Remove side effects caused by dict parameters passed by reference\n\nMethods that have dicts supplied as parameters may have adverse side\neffects if the method changes the supplied parameter (and does not\ndocument that behavior). This patch fixes methods that modified supplied\ndict parameters by using dict.copy() to make a copy of the supplied dict\nparameter.\n\nChange-Id: I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe\nCloses-Bug: #928042\n'}, {'number': 3, 'created': '2014-01-21 01:35:49.000000000', 'files': ['keystone/catalog/backends/kvs.py', 'keystone/common/controller.py', 'keystone/identity/controllers.py', 'keystone/tests/test_backend_sql.py', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/176efcfb9a4241f6b31ff8746ed75d2b1d1b665e', 'message': 'Remove side effects caused by dict parameters passed by reference\n\nMethods that have dicts supplied as parameters may have adverse side\neffects if the method changes the supplied parameter (and does not\ndocument that behavior). This patch fixes methods that modified supplied\ndict parameters by using dict.copy() to make a copy of the supplied dict\nparameter.\n\nChange-Id: I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe\nCloses-Bug: #928042\n'}]",2,67925,176efcfb9a4241f6b31ff8746ed75d2b1d1b665e,13,6,3,9293,,,0,"Remove side effects caused by dict parameters passed by reference

Methods that have dicts supplied as parameters may have adverse side
effects if the method changes the supplied parameter (and does not
document that behavior). This patch fixes methods that modified supplied
dict parameters by using dict.copy() to make a copy of the supplied dict
parameter.

Change-Id: I1664f59f3cb68a2b4616511481ff7d4c1a9f1cfe
Closes-Bug: #928042
",git fetch https://review.opendev.org/openstack/keystone refs/changes/25/67925/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/catalog/backends/kvs.py', 'keystone/common/controller.py', 'keystone/identity/controllers.py', 'keystone/tests/test_backend_sql.py', 'keystone/tests/test_backend.py']",5,0fa1a991c193972bf4059ef518bfa49fccbebeb8,bug/928042," original_new_region = new_region.copy() new_region) self.assertDictEqual(new_region, original_new_region) expected_region = new_region original_new_region = new_region.copy() new_region) self.assertDictEqual(new_region, original_new_region) original_new_region = new_region.copy() self.assertDictEqual(new_region, original_new_region) original_new_service = new_service.copy() new_service) self.assertDictEqual(new_service, original_new_service) original_service = service.copy() self.catalog_api.create_service(service['id'], service) self.assertDictEqual(service, original_service) original_endpoint = endpoint.copy() self.catalog_api.create_endpoint(endpoint['id'], endpoint) self.assertDictEqual(endpoint, original_endpoint)"," new_region.copy()) expected_region = new_region.copy() new_region.copy()) new_service.copy()) self.catalog_api.create_service(service['id'], service.copy()) self.catalog_api.create_endpoint(endpoint['id'], endpoint.copy())",44,26
openstack%2Ftripleo-image-elements~master~Iff5020eb9ef76f8c040c723e31c795dc4a34e54a,openstack/tripleo-image-elements,master,Iff5020eb9ef76f8c040c723e31c795dc4a34e54a,Make os-collect-config preserve state.,ABANDONED,2014-01-16 23:33:22.000000000,2014-02-03 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-16 23:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f5abeb6fe3a62c16a89e8cafb379ba7b1757c738', 'message': 'Make os-collect-config preserve state.\n\nChange-Id: Iff5020eb9ef76f8c040c723e31c795dc4a34e54a\n'}, {'number': 2, 'created': '2014-01-22 20:28:01.000000000', 'files': ['elements/os-apply-config/os-refresh-config/configure.d/50-os-config-applier', 'elements/os-collect-config/install.d/10-os-collect-config', 'elements/os-collect-config/os-apply-config/etc/os-collect-config.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4f195d885486b586d01bffd9c6210f4477cc499f', 'message': 'Make os-collect-config preserve state.\n\nThis is needed specifically to ensure that we have a configuration to\napply when nodes are rebooted for an update and the cache is needed\nto enable them to collect new configs. An example of this may be that\ntheir Heat-created user has been changed in cfn but their heat_local\ndata source will still reflect the original user/access keys.\n\nChange-Id: Iff5020eb9ef76f8c040c723e31c795dc4a34e54a\n'}]",1,67329,4f195d885486b586d01bffd9c6210f4477cc499f,15,6,2,6488,,,0,"Make os-collect-config preserve state.

This is needed specifically to ensure that we have a configuration to
apply when nodes are rebooted for an update and the cache is needed
to enable them to collect new configs. An example of this may be that
their Heat-created user has been changed in cfn but their heat_local
data source will still reflect the original user/access keys.

Change-Id: Iff5020eb9ef76f8c040c723e31c795dc4a34e54a
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/29/67329/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/os-apply-config/os-refresh-config/configure.d/50-os-config-applier', 'elements/os-collect-config/install.d/10-os-collect-config', 'elements/os-collect-config/os-apply-config/etc/os-collect-config.conf']",3,f5abeb6fe3a62c16a89e8cafb379ba7b1757c738,67329,{{^cachedir}} cachedir = /mnt/state/var/lib/os-collect-config {{/cachedir}},,9,1
openstack%2Fswift~master~Ifb25ed7c4a42b11f74d865787f63fea4e0beb745,openstack/swift,master,Ifb25ed7c4a42b11f74d865787f63fea4e0beb745,Attempt to fix periodic memcache timeout test,MERGED,2014-01-31 18:59:49.000000000,2014-02-03 05:48:45.000000000,2014-02-01 02:55:20.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-01-31 18:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4eeca1ef56da262ed49fa4b2e902cf19cf4de53f', 'message': 'Attempt to fix periodic memcache timeout test\n\nNot sure this will really fix the issue, but made a small change that\nseemed to make more sense for the flow of the test.\n\nChange-Id: Ifb25ed7c4a42b11f74d865787f63fea4e0beb745\n'}, {'number': 2, 'created': '2014-01-31 19:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dbc686c3f9401fe5541088098dac7393eb8e5005', 'message': 'Attempt to fix periodic memcache timeout test\n\nNot sure this will really fix the issue, but made a small change that\nseemed to make more sense for the flow of the test.\n\nFixes: 1272503\nChange-Id: Ifb25ed7c4a42b11f74d865787f63fea4e0beb745\n'}, {'number': 3, 'created': '2014-01-31 19:54:31.000000000', 'files': ['test/unit/common/test_memcached.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/15c04f6869c3ae4bb8906b3783551df0e718d462', 'message': 'Attempt to fix periodic memcache timeout test\n\nNot sure this will really fix the issue, but made a small change that\nseemed to make more sense for the flow of the test.\n\nCloses-Bug: #1272503\nChange-Id: Ifb25ed7c4a42b11f74d865787f63fea4e0beb745\n'}]",5,70400,15c04f6869c3ae4bb8906b3783551df0e718d462,13,4,3,917,,,0,"Attempt to fix periodic memcache timeout test

Not sure this will really fix the issue, but made a small change that
seemed to make more sense for the flow of the test.

Closes-Bug: #1272503
Change-Id: Ifb25ed7c4a42b11f74d865787f63fea4e0beb745
",git fetch https://review.opendev.org/openstack/swift refs/changes/00/70400/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_memcached.py'],1,4eeca1ef56da262ed49fa4b2e902cf19cf4de53f,," self.assertEqual(pending['1.2.3.5:11211'], 10)"," sleep(0) self.assertEqual(pending['1.2.3.5:11211'], 8)",1,2
openstack%2Fheat~master~Ic827295e773d893d9af6d7cf1c687aee69e98298,openstack/heat,master,Ic827295e773d893d9af6d7cf1c687aee69e98298,Fix handle_create of NetDHCPAgent for updating,MERGED,2014-01-27 09:58:17.000000000,2014-02-03 04:13:38.000000000,2014-02-03 04:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7135}, {'_account_id': 9000}]","[{'number': 1, 'created': '2014-01-27 09:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c0001f7010c1d62d8c9c5c6f81ae9e62567d6f75', 'message': 'Fix handle_create of NetDHCPAgent for updating\n\nWhen NetDHCPAgent is updated with new network_id which is already\nassociated with the dhcp_agent_id, UPDATE_FAILED occurs in Heat. Fix\nhandle_create to check associating information to avoid this situation.\n\nChange-Id: Ic827295e773d893d9af6d7cf1c687aee69e98298\nCloses-bug: #1272258\n'}, {'number': 2, 'created': '2014-01-28 06:43:29.000000000', 'files': ['heat/engine/resources/neutron/net.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/223bca7b344c848e17e54e1624485968b8a52dfc', 'message': 'Fix handle_create of NetDHCPAgent for updating\n\nWhen NetDHCPAgent is updated with new network_id which is already\nassociated with the dhcp_agent_id, UPDATE_FAILED occurs in Heat. Fix\nhandle_create to check associating information to avoid this situation.\n\nCloses-bug: #1272258\nChange-Id: Ic827295e773d893d9af6d7cf1c687aee69e98298\n'}]",0,69311,223bca7b344c848e17e54e1624485968b8a52dfc,11,5,2,9000,,,0,"Fix handle_create of NetDHCPAgent for updating

When NetDHCPAgent is updated with new network_id which is already
associated with the dhcp_agent_id, UPDATE_FAILED occurs in Heat. Fix
handle_create to check associating information to avoid this situation.

Closes-bug: #1272258
Change-Id: Ic827295e773d893d9af6d7cf1c687aee69e98298
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/69311/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/net.py', 'heat/tests/test_neutron.py']",2,c0001f7010c1d62d8c9c5c6f81ae9e62567d6f75,bug/1272258," self.m.StubOutWithMock(neutronclient.Client, 'list_dhcp_agent_hosting_networks') neutronclient.Client.list_dhcp_agent_hosting_networks( u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn({'agents': []}) neutronclient.Client.add_network_to_dhcp_agent( u'9f0df05b-4846-4d3d-971e-a2e1a06b1622', {'network_id': u'66a426ef-8b77-4e25-8098-b3a7c0964b93'} ).AndReturn(None) neutronclient.Client.remove_network_from_dhcp_agent( u'9f0df05b-4846-4d3d-971e-a2e1a06b1622', u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn(None) neutronclient.Client.remove_network_from_dhcp_agent( u'9f0df05b-4846-4d3d-971e-a2e1a06b1622', u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndRaise(qe.NeutronClientException(status_code=404)) self.m.ReplayAll() t = template_format.parse(neutron_dhcp_agent_template) stack = utils.parse_stack(t) rsrc = net.NetDHCPAgent('test_net_dhcp_agent', t['Resources']['network_dhcp_agent'], stack) scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.assertIsNone(scheduler.TaskRunner(rsrc.delete)()) rsrc.state_set(rsrc.CREATE, rsrc.COMPLETE, 'to delete again') self.assertIsNone(scheduler.TaskRunner(rsrc.delete)()) self.m.VerifyAll() def test_net_dhcp_agent_2(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.list_dhcp_agent_hosting_networks( u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn({'agents': [{'id': '9f0df05b-4846-4d3d-971e-a2e1a06b1622'}]}) neutronclient.Client.remove_network_from_dhcp_agent( u'9f0df05b-4846-4d3d-971e-a2e1a06b1622', u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn(None) neutronclient.Client.remove_network_from_dhcp_agent( u'9f0df05b-4846-4d3d-971e-a2e1a06b1622', u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndRaise(qe.NeutronClientException(status_code=404)) self.m.ReplayAll() t = template_format.parse(neutron_dhcp_agent_template) stack = utils.parse_stack(t) rsrc = net.NetDHCPAgent('test_net_dhcp_agent', t['Resources']['network_dhcp_agent'], stack) scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.assertIsNone(scheduler.TaskRunner(rsrc.delete)()) rsrc.state_set(rsrc.CREATE, rsrc.COMPLETE, 'to delete again') self.assertIsNone(scheduler.TaskRunner(rsrc.delete)()) self.m.VerifyAll() def test_net_dhcp_agent_3(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.list_dhcp_agent_hosting_networks( u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn({'agents': [{'id': '4510684e-63d8-40fa-979b-123f2239eb6c'}]}) neutronclient.Client.list_dhcp_agent_hosting_networks( u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn({'agents': []}) neutronclient.Client.list_dhcp_agent_hosting_networks( u'66a426ef-8b77-4e25-8098-b3a7c0964b93' ).AndReturn({'agents': []})",,90,2
openstack%2Fheat~master~I5bcaab04dffb0cfacc30c3925f6286a0273054c4,openstack/heat,master,I5bcaab04dffb0cfacc30c3925f6286a0273054c4,heat.conf.sample enforce_token_bind,ABANDONED,2014-02-02 19:47:30.000000000,2014-02-03 03:38:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-02-02 19:47:30.000000000', 'files': ['etc/heat/heat.conf.sample'], 'web_link': 'https://opendev.org/openstack/heat/commit/3671e4c9dae0fd0a8e7cb7c2b28224e21d3eec39', 'message': 'heat.conf.sample enforce_token_bind\n\nAdded by a recent keystoneclient commit.\n\nChange-Id: I5bcaab04dffb0cfacc30c3925f6286a0273054c4\n'}]",0,70625,3671e4c9dae0fd0a8e7cb7c2b28224e21d3eec39,2,1,1,4571,,,0,"heat.conf.sample enforce_token_bind

Added by a recent keystoneclient commit.

Change-Id: I5bcaab04dffb0cfacc30c3925f6286a0273054c4
",git fetch https://review.opendev.org/openstack/heat refs/changes/25/70625/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/heat/heat.conf.sample'],1,3671e4c9dae0fd0a8e7cb7c2b28224e21d3eec39,bug/1190149,"# Used to control the use and type of token binding. Can be # set to: ""disabled"" to not check token binding. ""permissive"" # (default) to validate binding information if the bind type # is of a form known to the server and ignore it if not. # ""strict"" like ""permissive"" but if the bind type is unknown # the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a # binding method that must be present in tokens. (string # value) #enforce_token_bind=permissive ",,11,0
openstack%2Fdevstack~master~I6f912d29c143b3acbc43da222cf8b4c3fafb2c8d,openstack/devstack,master,I6f912d29c143b3acbc43da222cf8b4c3fafb2c8d,Pipeline filter is 'authtoken' and not 'tokenauth',MERGED,2014-01-31 23:08:19.000000000,2014-02-03 03:33:36.000000000,2014-02-01 05:09:08.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 970}]","[{'number': 1, 'created': '2014-01-31 23:08:19.000000000', 'files': ['lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1272bc5e93f171c8d7193475547c43b9032b5c39', 'message': ""Pipeline filter is 'authtoken' and not 'tokenauth'\n\nThe pipeline fileter in the api-paste.ini for the keystone\nmiddleware was renamed to 'authtoken'. Trove install is not\nable to authenticate against keystone unless this is renamed\n\nChange-Id: I6f912d29c143b3acbc43da222cf8b4c3fafb2c8d\n""}]",0,70466,1272bc5e93f171c8d7193475547c43b9032b5c39,8,3,1,5293,,,0,"Pipeline filter is 'authtoken' and not 'tokenauth'

The pipeline fileter in the api-paste.ini for the keystone
middleware was renamed to 'authtoken'. Trove install is not
able to authenticate against keystone unless this is renamed

Change-Id: I6f912d29c143b3acbc43da222cf8b4c3fafb2c8d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/66/70466/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/trove'],1,1272bc5e93f171c8d7193475547c43b9032b5c39,bug/fix-trove-api-paste, iniset $TROVE_API_PASTE_INI filter:authtoken auth_host $KEYSTONE_AUTH_HOST iniset $TROVE_API_PASTE_INI filter:authtoken auth_port $KEYSTONE_AUTH_PORT iniset $TROVE_API_PASTE_INI filter:authtoken auth_protocol $KEYSTONE_AUTH_PROTOCOL iniset $TROVE_API_PASTE_INI filter:authtoken cafile $KEYSTONE_SSL_CA iniset $TROVE_API_PASTE_INI filter:authtoken admin_tenant_name $SERVICE_TENANT_NAME iniset $TROVE_API_PASTE_INI filter:authtoken admin_user trove iniset $TROVE_API_PASTE_INI filter:authtoken admin_password $SERVICE_PASSWORD iniset $TROVE_API_PASTE_INI filter:authtoken signing_dir $TROVE_AUTH_CACHE_DIR, iniset $TROVE_API_PASTE_INI filter:tokenauth auth_host $KEYSTONE_AUTH_HOST iniset $TROVE_API_PASTE_INI filter:tokenauth auth_port $KEYSTONE_AUTH_PORT iniset $TROVE_API_PASTE_INI filter:tokenauth auth_protocol $KEYSTONE_AUTH_PROTOCOL iniset $TROVE_API_PASTE_INI filter:tokenauth cafile $KEYSTONE_SSL_CA iniset $TROVE_API_PASTE_INI filter:tokenauth admin_tenant_name $SERVICE_TENANT_NAME iniset $TROVE_API_PASTE_INI filter:tokenauth admin_user trove iniset $TROVE_API_PASTE_INI filter:tokenauth admin_password $SERVICE_PASSWORD iniset $TROVE_API_PASTE_INI filter:tokenauth signing_dir $TROVE_AUTH_CACHE_DIR,8,8
openstack%2Ftripleo-image-elements~master~Id234c44d09742d81ba15793ca3c9041efb09b377,openstack/tripleo-image-elements,master,Id234c44d09742d81ba15793ca3c9041efb09b377,Stop adding qpid to heat requirements.,MERGED,2014-02-03 01:47:22.000000000,2014-02-03 02:29:17.000000000,2014-02-03 02:29:17.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-02-03 01:47:22.000000000', 'files': ['elements/heat/install.d/heat-source-install/05-heat'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/230c6f4198b9dd6dd6576a03e12869729b038a5b', 'message': 'Stop adding qpid to heat requirements.\n\nNow heat has it itself, it makes pip blow up.\n\nChange-Id: Id234c44d09742d81ba15793ca3c9041efb09b377\n'}]",0,70637,230c6f4198b9dd6dd6576a03e12869729b038a5b,5,3,1,4190,,,0,"Stop adding qpid to heat requirements.

Now heat has it itself, it makes pip blow up.

Change-Id: Id234c44d09742d81ba15793ca3c9041efb09b377
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/37/70637/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/heat/install.d/heat-source-install/05-heat'],1,230c6f4198b9dd6dd6576a03e12869729b038a5b,,,"# for BUG: https://bugs.launchpad.net/heat/+bug/1225191 echo ""qpid-python"" | tee -a /opt/stack/heat/requirements.txt ",0,3
openstack%2Ftripleo-heat-templates~master~If444e4449e3d62cb954de48bc3b55b16dcc8886f,openstack/tripleo-heat-templates,master,If444e4449e3d62cb954de48bc3b55b16dcc8886f,Remove InstanceType and ImageId from cinder template,MERGED,2014-01-28 14:49:14.000000000,2014-02-03 01:13:20.000000000,2014-02-03 01:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 8449}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-28 14:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a05b641d4568d12c2b9654aa0e38e6b200d5f74', 'message': ""Remove InstanceType and ImageId from cinder template\n\nInstanceType and ImageId properties belong to an\nAWS::AutoScaling::LaunchConfiguration, for example as used for\nNovaCompute0Config in nova-compute-instance.yaml. However this\ntemplate doesn't use a LaunchConfig but params instead. AFAICT\nwe don't need these here (and they cause HEAT template validation\nanyway)\n\nChange-Id: If444e4449e3d62cb954de48bc3b55b16dcc8886f\n""}, {'number': 2, 'created': '2014-01-28 14:50:29.000000000', 'files': ['block-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4f423ed6aec34a2f4274cd48d20dccb6080f6068', 'message': ""Remove InstanceType and ImageId from cinder template\n\nInstanceType and ImageId properties belong to an\nAWS::AutoScaling::LaunchConfiguration, for example as used for\nNovaCompute0Config in nova-compute-instance.yaml. However this\ntemplate doesn't use a LaunchConfig but params instead. AFAICT\nwe don't need these here (and they cause HEAT template validation\nto fail)\n\nChange-Id: If444e4449e3d62cb954de48bc3b55b16dcc8886f\n""}]",0,69618,4f423ed6aec34a2f4274cd48d20dccb6080f6068,9,5,2,8449,,,0,"Remove InstanceType and ImageId from cinder template

InstanceType and ImageId properties belong to an
AWS::AutoScaling::LaunchConfiguration, for example as used for
NovaCompute0Config in nova-compute-instance.yaml. However this
template doesn't use a LaunchConfig but params instead. AFAICT
we don't need these here (and they cause HEAT template validation
to fail)

Change-Id: If444e4449e3d62cb954de48bc3b55b16dcc8886f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/69618/2 && git format-patch -1 --stdout FETCH_HEAD,['block-storage.yaml'],1,9a05b641d4568d12c2b9654aa0e38e6b200d5f74,fix_cinder_yaml, control: {Ref: NeutronPublicInterface} , InstanceType: '0' ImageId: '0' control: {Ref: NeutronPublicInterface},1,3
openstack%2Ftripleo-image-elements~master~I1c2cb22773ab8b39e4bbe028474665df81ac08a1,openstack/tripleo-image-elements,master,I1c2cb22773ab8b39e4bbe028474665df81ac08a1,Fixes tgtd restart in cinder element,MERGED,2014-01-30 14:59:53.000000000,2014-02-03 00:42:51.000000000,2014-02-03 00:42:51.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-30 14:59:53.000000000', 'files': ['elements/cinder-volume/os-refresh-config/post-configure.d/74-cinder-volume'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/03a7edf6fe568e2879807d37853e202b3adfce70', 'message': 'Fixes tgtd restart in cinder element\n\nIn a previous patch, the restart of tgtd was erroneously removed\nand causes the cinder-volume service to create a symlink to a\nvolume but return an error to the cinder-scheduler.  This ""volume""\nmust then be manually removed and tgtd service restarted before\ncinder-volume works properly.\n\nThis patch adds the restart of tgtd again and allows cinder to\nwork as advertised without additional intervention.\n\nChange-Id: I1c2cb22773ab8b39e4bbe028474665df81ac08a1\n'}]",0,70128,03a7edf6fe568e2879807d37853e202b3adfce70,6,3,1,8532,,,0,"Fixes tgtd restart in cinder element

In a previous patch, the restart of tgtd was erroneously removed
and causes the cinder-volume service to create a symlink to a
volume but return an error to the cinder-scheduler.  This ""volume""
must then be manually removed and tgtd service restarted before
cinder-volume works properly.

This patch adds the restart of tgtd again and allows cinder to
work as advertised without additional intervention.

Change-Id: I1c2cb22773ab8b39e4bbe028474665df81ac08a1
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/28/70128/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/cinder-volume/os-refresh-config/post-configure.d/74-cinder-volume'],1,03a7edf6fe568e2879807d37853e202b3adfce70,fixes-tgtd-restart-cinder,os-svc-restart tgtd os-svc-restart cinder-volume,service cinder-volume restart,2,1
openstack%2Ftripleo-image-elements~master~I29d8f310a47ea2b5d4148cf3fa32485dea3424e8,openstack/tripleo-image-elements,master,I29d8f310a47ea2b5d4148cf3fa32485dea3424e8,Fixes heat-cfntools install,MERGED,2014-01-29 20:44:15.000000000,2014-02-03 00:41:45.000000000,2014-02-03 00:41:45.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6966}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-01-29 20:44:15.000000000', 'files': ['elements/heat-cfntools/install.d/05-heat-cfntools'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b7a517458c8192c34f375ccd773983b56f1aca1d', 'message': ""Fixes heat-cfntools install\n\nWhen using heat-cfntools with diskimage-builder, the pip install\nof heat-cfntools package is skipped because it's already in the\nsystem site-packages directory.  Unfortunately it doesn't copy\nthe scripts from the heat-cfntools bin directory into the venv\nbin directory and the diskimage-builder command will fail.\n\nThis patch adds gcc to the install-packages line and removes\nthe --system-site-packages flag from the virtualenv creation.\nThis ensures the heat-cfntools package is properly installed.\n\nChange-Id: I29d8f310a47ea2b5d4148cf3fa32485dea3424e8\n""}]",0,69968,b7a517458c8192c34f375ccd773983b56f1aca1d,7,4,1,8532,,,0,"Fixes heat-cfntools install

When using heat-cfntools with diskimage-builder, the pip install
of heat-cfntools package is skipped because it's already in the
system site-packages directory.  Unfortunately it doesn't copy
the scripts from the heat-cfntools bin directory into the venv
bin directory and the diskimage-builder command will fail.

This patch adds gcc to the install-packages line and removes
the --system-site-packages flag from the virtualenv creation.
This ensures the heat-cfntools package is properly installed.

Change-Id: I29d8f310a47ea2b5d4148cf3fa32485dea3424e8
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/68/69968/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/heat-cfntools/install.d/05-heat-cfntools'],1,b7a517458c8192c34f375ccd773983b56f1aca1d,fixes-heat-cfn-tools-install, python-pip python-psutil python-virtualenv gccvirtualenv $VENV, python-pip python-psutil python-virtualenvvirtualenv $VENV --system-site-packages,2,2
openstack%2Ftripleo-image-elements~master~Ica0863fff794b994938ecd494f5e5f6caf070143,openstack/tripleo-image-elements,master,Ica0863fff794b994938ecd494f5e5f6caf070143,Fixes authentication for cinder,MERGED,2014-01-28 14:55:37.000000000,2014-02-03 00:38:50.000000000,2014-02-03 00:38:50.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 6966}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-28 14:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bc8e778a5c0730ddaac6ad97a169a6a217f3de21', 'message': 'Fixes authentication for cinder\n\nThis patch adds additional keystone auth configuration that allows\nthe cinder client to access the cinder-api.  Previous to this patch\nthe error log displayed the following message when the cinder client\nattempted to run any command.\n\n""keystoneclient.middleware.auth_token [-] Authorization failed""\n\nChange-Id: Ica0863fff794b994938ecd494f5e5f6caf070143\n'}, {'number': 3, 'created': '2014-01-28 21:06:42.000000000', 'files': ['elements/cinder/os-apply-config/etc/cinder/cinder.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/98d02ef6b66814453bbeb3a139a54be021b5803e', 'message': 'Fixes authentication for cinder\n\nThis patch adds additional keystone auth configuration that allows\nthe cinder client to access the cinder-api.  Previous to this patch\nthe error log displayed the following message when the cinder client\nattempted to run any command.\n\n""keystoneclient.middleware.auth_token [-] Authorization failed""\n\nChange-Id: Ica0863fff794b994938ecd494f5e5f6caf070143\n'}, {'number': 2, 'created': '2014-01-28 21:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/810d80328d58f18bace3a3b09ef04b5a211112a6', 'message': 'Fixes authentication for cinder\n\nThis patch adds additional keystone auth configuration that allows\nthe cinder client to access the cinder-api.  Previous to this patch\nthe error log displayed the following message when the cinder client\nattempted to run any command.\n\n""keystoneclient.middleware.auth_token [-] Authorization failed""\n\nChange-Id: Ica0863fff794b994938ecd494f5e5f6caf070143\n'}]",1,69619,98d02ef6b66814453bbeb3a139a54be021b5803e,14,6,3,8532,,,0,"Fixes authentication for cinder

This patch adds additional keystone auth configuration that allows
the cinder client to access the cinder-api.  Previous to this patch
the error log displayed the following message when the cinder client
attempted to run any command.

""keystoneclient.middleware.auth_token [-] Authorization failed""

Change-Id: Ica0863fff794b994938ecd494f5e5f6caf070143
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/19/69619/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/cinder/os-apply-config/etc/cinder/cinder.conf'],1,bc8e778a5c0730ddaac6ad97a169a6a217f3de21,fix-authentication-issue-for-cinder,auth_port = 35357 auth_protocol = http,,2,0
openstack%2Ftripleo-image-elements~master~Ia1b81cfa658b352ec7799fd67dfa1dd9d14463cd,openstack/tripleo-image-elements,master,Ia1b81cfa658b352ec7799fd67dfa1dd9d14463cd,Install openstack-neutron-ml2,MERGED,2014-01-29 15:14:23.000000000,2014-02-03 00:36:57.000000000,2014-02-03 00:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-29 15:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1fa9bd51c5cbea22bfc5b04ae9c2defd161ff78e', 'message': ""Install openstack-neutron-ml2\n\nopenstack-neutron-ml2 is the package we should actually be installing\nhere.  openstack-neutron-ml2 requires openstack-neutron, so technically\nwe don't need to list openstack-neutron at all, but I left it in as it's\nmore visually expicity of what's happening.\n\nChange-Id: Ia1b81cfa658b352ec7799fd67dfa1dd9d14463cd\n""}, {'number': 2, 'created': '2014-01-31 00:39:43.000000000', 'files': ['elements/neutron/install.d/neutron-package-install/76-neutron'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a21df0bcaadd4be6ec8ebab4f957ee2f6fcbcf1d', 'message': ""Install openstack-neutron-ml2\n\nopenstack-neutron-ml2 is the package we should actually be installing\nhere.  openstack-neutron-ml2 requires openstack-neutron, so technically\nwe don't need to list openstack-neutron at all, but I left it in as it's\nmore visually expicity of what's happening.\n\nChange-Id: Ia1b81cfa658b352ec7799fd67dfa1dd9d14463cd\n""}]",0,69880,a21df0bcaadd4be6ec8ebab4f957ee2f6fcbcf1d,11,5,2,7144,,,0,"Install openstack-neutron-ml2

openstack-neutron-ml2 is the package we should actually be installing
here.  openstack-neutron-ml2 requires openstack-neutron, so technically
we don't need to list openstack-neutron at all, but I left it in as it's
more visually expicity of what's happening.

Change-Id: Ia1b81cfa658b352ec7799fd67dfa1dd9d14463cd
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/80/69880/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/neutron/install.d/neutron-package-install/76-neutron'],1,1fa9bd51c5cbea22bfc5b04ae9c2defd161ff78e,packages,install-packages openstack-neutron openstack-neutron-ml2,install-packages openstack-neutron,1,1
openstack%2Fheat~master~I398c1d35295223cbc6969b386129c6fc9acbefc7,openstack/heat,master,I398c1d35295223cbc6969b386129c6fc9acbefc7,Add qpid-python to requirements,MERGED,2014-01-28 19:30:28.000000000,2014-02-02 23:37:50.000000000,2014-02-02 23:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-01-28 19:30:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/c8a25ef8d164825b3521814ffb16c0411a9d05ea', 'message': 'Add qpid-python to requirements\n\nQpid is a supported messaging library, and without this it is\nnecessary to install it manually in order to use Qpid in some\nenvironments, notably the one used by TripleO.\n\nChange-Id: I398c1d35295223cbc6969b386129c6fc9acbefc7\nCloses-Bug: #1225191\n'}]",0,69704,c8a25ef8d164825b3521814ffb16c0411a9d05ea,8,4,1,6928,,,0,"Add qpid-python to requirements

Qpid is a supported messaging library, and without this it is
necessary to install it manually in order to use Qpid in some
environments, notably the one used by TripleO.

Change-Id: I398c1d35295223cbc6969b386129c6fc9acbefc7
Closes-Bug: #1225191
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/69704/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c8a25ef8d164825b3521814ffb16c0411a9d05ea,qpid-requirements,qpid-python,,1,0
openstack%2Ftripleo-heat-templates~master~I78cf31f0443f3d9f274758f5471a5bca9155635d,openstack/tripleo-heat-templates,master,I78cf31f0443f3d9f274758f5471a5bca9155635d,Remove image parameter changing from merge,MERGED,2014-01-31 19:13:41.000000000,2014-02-02 22:24:59.000000000,2014-02-02 22:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2014-01-31 19:13:41.000000000', 'files': ['examples/source2_lib_result.yaml', 'examples/source_lib_result.yaml', 'examples/source_include_subkey_result.yaml', 'tripleo_heat_merge/merge.py', 'undercloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f9ef45798719254ce66b6374c5f803b04ec86721', 'message': ""Remove image parameter changing from merge\n\nThe merge tool originally was meant to merge somewhat different things,\nand thus this was helpful in the early versions. However, at this point\nwe want parameters to be more stable and we don't generally merge things\nthat have their own image parameter.\n\nMeanwhile this feature caused problems as we change resource names.\n\nThis is a backward incompatible change of default behavior, but the old\nbehavior can be had again by passing --change-image-params.\n\nChange-Id: I78cf31f0443f3d9f274758f5471a5bca9155635d\n""}]",0,70406,f9ef45798719254ce66b6374c5f803b04ec86721,5,2,1,6488,,,0,"Remove image parameter changing from merge

The merge tool originally was meant to merge somewhat different things,
and thus this was helpful in the early versions. However, at this point
we want parameters to be more stable and we don't generally merge things
that have their own image parameter.

Meanwhile this feature caused problems as we change resource names.

This is a backward incompatible change of default behavior, but the old
behavior can be had again by passing --change-image-params.

Change-Id: I78cf31f0443f3d9f274758f5471a5bca9155635d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/70406/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/source2_lib_result.yaml', 'examples/source_lib_result.yaml', 'examples/source_include_subkey_result.yaml', 'tripleo_heat_merge/merge.py', 'undercloud-source.yaml']",5,f9ef45798719254ce66b6374c5f803b04ec86721,, undercloudImage: Ref: undercloudImage, Image: Ref: Image,27,19
openstack%2Fnova~master~Iacb6fcfb66379fbae900e8e9909377bf5ce18409,openstack/nova,master,Iacb6fcfb66379fbae900e8e9909377bf5ce18409,libvirt: Configuration element for sVirt support,MERGED,2014-01-02 12:57:12.000000000,2014-02-02 22:06:55.000000000,2014-02-02 22:06:52.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 8802}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-02 12:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0413ba41a6296e6f2ec71e20bb836adc6114cc33', 'message': 'libvirt: Configuration element for sVirt support\n\nThis configuration is need to allow users to enable sVirt support,\nwhich is by default disabled for lxc.\n\nIn addition to a dynamic configuration, the users will be able to\nprovide a base label\n\nChange-Id: Iacb6fcfb66379fbae900e8e9909377bf5ce18409\n'}, {'number': 2, 'created': '2014-01-07 22:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca88315224ce514522d913937e767cab0d9e4f56', 'message': 'libvirt: Configuration element for sVirt support\n\nThis configuration is need to allow users to enable sVirt support,\nwhich is by default disabled for lxc.\n\nIn addition to a dynamic configuration, the users will be able to\nprovide a base label\n\nPartially implements: blueprint libvirt-enable-lxc-svirt\nChange-Id: Iacb6fcfb66379fbae900e8e9909377bf5ce18409\n'}, {'number': 3, 'created': '2014-01-08 18:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ee4e132c062a7c001a32e3aec11123f102f6924', 'message': 'libvirt: Configuration element for sVirt support\n\nThis configuration is need to allow users to enable sVirt support,\nwhich is by default disabled for lxc.\n\nIn addition to a dynamic configuration, the users will be able to\nprovide a base label\n\nPartially implements: blueprint libvirt-enable-lxc-svirt\nChange-Id: Iacb6fcfb66379fbae900e8e9909377bf5ce18409\n'}, {'number': 4, 'created': '2014-01-14 16:43:33.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cc535f1d34bd48305a9f4d89ab44e8e86a9094c1', 'message': 'libvirt: Configuration element for sVirt support\n\nThis configuration is need to allow users to enable sVirt support,\nwhich is by default disabled for lxc.\n\nIn addition to a dynamic configuration, the users will be able to\nprovide a base label\n\nPartially implements: blueprint libvirt-enable-lxc-svirt\nChange-Id: Iacb6fcfb66379fbae900e8e9909377bf5ce18409\n'}]",12,64671,cc535f1d34bd48305a9f4d89ab44e8e86a9094c1,33,5,4,8802,,,0,"libvirt: Configuration element for sVirt support

This configuration is need to allow users to enable sVirt support,
which is by default disabled for lxc.

In addition to a dynamic configuration, the users will be able to
provide a base label

Partially implements: blueprint libvirt-enable-lxc-svirt
Change-Id: Iacb6fcfb66379fbae900e8e9909377bf5ce18409
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/64671/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py']",2,0413ba41a6296e6f2ec71e20bb836adc6114cc33,lxc_sec," self.svirt_type = None self.baselabel = None def _format_svirt(self, root): if self.svirt_type: seclable = etree.Element(""seclabel"") seclable.set('type', self.svirt_type) if self.svirt_type != 'none' and self.baselabel: seclable.append(self._text_node(""baselabel"", self.baselabel)) root.append(seclable) self._format_svirt(root)",,54,0
openstack%2Ftripleo-incubator~master~I21c1e40558f2a2e798f7807c40ac9ac17a3a650d,openstack/tripleo-incubator,master,I21c1e40558f2a2e798f7807c40ac9ac17a3a650d,Use relative path for keystone-manage,MERGED,2014-01-28 19:51:45.000000000,2014-02-02 21:44:58.000000000,2014-02-02 21:44:58.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7582}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-28 19:51:45.000000000', 'files': ['scripts/init-keystone'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/914d8947f5f8500632fb2dd2b0d8bec442f1766f', 'message': ""Use relative path for keystone-manage\n\nTo support package based installs, we shouldn't specify the full path to\nkeystone-manage anymore.\n\nDepends on: Change-Id: I5f26faf4ac95f75e8e1f72b9a98c9309f4ed7324\n\nDo not merge until the dependent change is committed.\n\nChange-Id: I21c1e40558f2a2e798f7807c40ac9ac17a3a650d\n""}]",0,69709,914d8947f5f8500632fb2dd2b0d8bec442f1766f,9,4,1,7144,,,0,"Use relative path for keystone-manage

To support package based installs, we shouldn't specify the full path to
keystone-manage anymore.

Depends on: Change-Id: I5f26faf4ac95f75e8e1f72b9a98c9309f4ed7324

Do not merge until the dependent change is committed.

Change-Id: I21c1e40558f2a2e798f7807c40ac9ac17a3a650d
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/09/69709/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/init-keystone'],1,914d8947f5f8500632fb2dd2b0d8bec442f1766f,init-keystone,ssh -o StrictHostKeyChecking=no -t $HOST sudo keystone-manage pki_setup --keystone-user keystone --keystone-group keystone,ssh -o StrictHostKeyChecking=no -t $HOST sudo /opt/stack/venvs/keystone/bin/keystone-manage pki_setup --keystone-user keystone --keystone-group keystone,1,1
openstack%2Ftripleo-incubator~master~Ie6eb30ef494a1aa246428f95ff0c1d45e204ff75,openstack/tripleo-incubator,master,Ie6eb30ef494a1aa246428f95ff0c1d45e204ff75,Make wait_for print out command on timeout.,MERGED,2014-01-29 17:25:31.000000000,2014-02-02 21:32:57.000000000,2014-02-02 21:32:57.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 8532}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-01-29 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/99aec2b9f47787e4a19ceff49adc352afa753586', 'message': 'Make wait_for print out command on timeout.\n\nWe use it in some places in succession without expected output between,\nso it is hard to know what is timing out.\n\nChange-Id: Ie6eb30ef494a1aa246428f95ff0c1d45e204ff75\n'}, {'number': 2, 'created': '2014-01-31 20:24:38.000000000', 'files': ['scripts/wait_for'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d585a168f1e422d74398ded5fb4a58ebafd33265', 'message': 'Make wait_for print out command on timeout.\n\nWe use it in some places in succession without expected output between,\nso it is hard to know what is timing out.\n\nChange-Id: Ie6eb30ef494a1aa246428f95ff0c1d45e204ff75\n'}]",1,69915,d585a168f1e422d74398ded5fb4a58ebafd33265,13,6,2,6488,,,0,"Make wait_for print out command on timeout.

We use it in some places in succession without expected output between,
so it is hard to know what is timing out.

Change-Id: Ie6eb30ef494a1aa246428f95ff0c1d45e204ff75
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/15/69915/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/wait_for'],1,99aec2b9f47787e4a19ceff49adc352afa753586,69915,"SECONDS=$((LOOPS * SLEEPTIME)) printf 'Timing out after %d seconds:\nCOMMAND=%s\nOUTPUT=%s\n' \ ""$SECONDS"" ""$COMMAND"" ""$OUTPUT""","echo ""Timing out - last probe output:""",3,1
openstack%2Fcinder~master~Iab0954c2d0af73bce28be7fa319b8b34ca20e720,openstack/cinder,master,Iab0954c2d0af73bce28be7fa319b8b34ca20e720,Stop volume_type_encryption creation when in use,MERGED,2014-01-29 20:56:39.000000000,2014-02-02 20:10:15.000000000,2014-02-02 20:10:14.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 4355}, {'_account_id': 6802}, {'_account_id': 7198}, {'_account_id': 7764}]","[{'number': 1, 'created': '2014-01-29 20:56:39.000000000', 'files': ['cinder/tests/api/contrib/test_volume_type_encryption.py', 'cinder/api/contrib/volume_type_encryption.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9afbd3fbba201ee606cf6e3b57675d3fbf9514b2', 'message': 'Stop volume_type_encryption creation when in use\n\nThis bug fix addresses bug #1274252.  It requires a volume\ntype to have no volumes with the type before allowing it\nto be made encrypted.  This prevents a situation where\nnon-encrypted volumes could have an encrypted volume type.\nThis fix also adds a unit test to confirm functionality.\n\nChange-Id: Iab0954c2d0af73bce28be7fa319b8b34ca20e720\nCloses-Bug: #1274252\n'}]",0,69975,9afbd3fbba201ee606cf6e3b57675d3fbf9514b2,7,6,1,7012,,,0,"Stop volume_type_encryption creation when in use

This bug fix addresses bug #1274252.  It requires a volume
type to have no volumes with the type before allowing it
to be made encrypted.  This prevents a situation where
non-encrypted volumes could have an encrypted volume type.
This fix also adds a unit test to confirm functionality.

Change-Id: Iab0954c2d0af73bce28be7fa319b8b34ca20e720
Closes-Bug: #1274252
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/69975/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/contrib/test_volume_type_encryption.py', 'cinder/api/contrib/volume_type_encryption.py']",2,9afbd3fbba201ee606cf6e3b57675d3fbf9514b2,bug/1274252," if self._encrypted_type_in_use(context, type_id): expl = _('Cannot create encryption specs. Volume type in use.') raise webob.exc.HTTPBadRequest(explanation=expl) ",,64,17
openstack%2Fnova~master~I38cc103c4d9922527a56b169e4906b242df6473a,openstack/nova,master,I38cc103c4d9922527a56b169e4906b242df6473a,Wait for files to be accessible when migrating,ABANDONED,2013-08-29 21:21:43.000000000,2014-02-02 20:08:19.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5754}, {'_account_id': 7040}, {'_account_id': 7133}, {'_account_id': 7711}, {'_account_id': 7808}, {'_account_id': 8172}, {'_account_id': 8430}]","[{'number': 1, 'created': '2013-08-29 21:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2323d232d88e1103ff8b8b2e0bbde3823ba0985', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait until the disk\nimages are accessible from the destination host before performing any\noperation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 2, 'created': '2013-09-04 17:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/973e10a825eb40216bcade7753c87d31105c07e0', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 3, 'created': '2013-09-05 15:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/319fa9a673b79571baf996541639b1877f16fa62', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 4, 'created': '2013-09-05 16:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9428e16ea55bf891c949c1dea7c2ad4120c29623', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 5, 'created': '2013-09-05 16:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6344a59c733e47abf4e1fae4737ef5eabac1f03', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 6, 'created': '2013-09-06 09:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f0faea21760018deddd8b441e8bfedd7eb1c3ba', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 7, 'created': '2013-09-27 17:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd04850072659ee316fa7870d2427cf8ce0fb29c', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 8, 'created': '2013-09-27 18:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84e033e2b442106c931b84a927a34a2c6b6d3600', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 9, 'created': '2013-10-08 07:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/534c772e02399eb88e14ddd60ef2dc83aea07292', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 10, 'created': '2013-10-10 16:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eeade7183f71ad0d5d9966817699b6a2489e0107', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}, {'number': 11, 'created': '2013-10-10 17:46:32.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d96e824f6930088073a4a1462b08f0a220595f93', 'message': ""Wait for files to be accessible when migrating\n\nSometimes, when using shared storage for the instances directory,\nresizing an instance can fail because the destination host can't access\nyet to the new instance directory created from the source. This\ndifferences between the source and destination hosts is caused by the\ntime it can take to refresh the cache on the client side.\n\nFor the NFS case, this means that a file modified/created in the server\nmay take up to 60 seconds to be accessible from the client.\n\nWith this patch, the 'finish_migration' call will wait for a maximum of\n90 seconds or until the disk images are accessible from the destination\nhost before performing any operation on them.\n\nFixes bug #1218372\n\nChange-Id: I38cc103c4d9922527a56b169e4906b242df6473a\n""}]",23,44359,d96e824f6930088073a4a1462b08f0a220595f93,66,14,11,7808,,,0,"Wait for files to be accessible when migrating

Sometimes, when using shared storage for the instances directory,
resizing an instance can fail because the destination host can't access
yet to the new instance directory created from the source. This
differences between the source and destination hosts is caused by the
time it can take to refresh the cache on the client side.

For the NFS case, this means that a file modified/created in the server
may take up to 60 seconds to be accessible from the client.

With this patch, the 'finish_migration' call will wait for a maximum of
90 seconds or until the disk images are accessible from the destination
host before performing any operation on them.

Fixes bug #1218372

Change-Id: I38cc103c4d9922527a56b169e4906b242df6473a
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/44359/7 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,b2323d232d88e1103ff8b8b2e0bbde3823ba0985,bug/1218372," def _wait_for_file_available(self, path): try: utils.execute('touch', path) raise loopingcall.LoopingCallDone() except processutils.ProcessExecutionError: pass # NOTE(xqueralt): Wait for the file to be accessible by the # process to prevent failures when using shared storage and # the client can't see the new files created in the server. timer = loopingcall.FixedIntervalLoopingCall( self._wait_for_file_available, info['path']) timer.start(interval=2.0).wait() ",,14,0
openstack%2Fsahara~master~I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c,openstack/sahara,master,I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c,Update oslo-incubator db.sqlalchemy module,MERGED,2014-01-29 17:41:41.000000000,2014-02-02 19:23:44.000000000,2014-02-02 19:23:44.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:41.000000000', 'files': ['savanna/openstack/common/db/sqlalchemy/provision.py', 'savanna/openstack/common/db/sqlalchemy/models.py', 'savanna/openstack/common/test.py', 'savanna/openstack/common/db/sqlalchemy/migration.py', 'savanna/openstack/common/db/sqlalchemy/utils.py', 'savanna/openstack/common/db/sqlalchemy/session.py', 'savanna/openstack/common/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1ee2bb2e28e1409a9bf70aec7c2f47834adc79c5', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * Use dialect rather than a particular DB API driver\n * Move helper DB functions to db.sqlalchemy.utils\n * Small edits on help strings\n * Transition from migrate to alembic\n * Fix mocking of utcnow() for model datetime cols\n * Add a db check for CHARSET=utf8\n * Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\n\nChange-Id: I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c\n'}]",0,69928,1ee2bb2e28e1409a9bf70aec7c2f47834adc79c5,11,7,1,7555,,,0,"Update oslo-incubator db.sqlalchemy module

Changes -
 * Use dialect rather than a particular DB API driver
 * Move helper DB functions to db.sqlalchemy.utils
 * Small edits on help strings
 * Transition from migrate to alembic
 * Fix mocking of utcnow() for model datetime cols
 * Add a db check for CHARSET=utf8
 * Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers

Change-Id: I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/28/69928/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/openstack/common/db/sqlalchemy/models.py', 'savanna/openstack/common/db/sqlalchemy/provision.py', 'savanna/openstack/common/test.py', 'savanna/openstack/common/db/sqlalchemy/migration.py', 'savanna/openstack/common/db/sqlalchemy/utils.py', 'savanna/openstack/common/db/sqlalchemy/session.py', 'savanna/openstack/common/db/sqlalchemy/test_migrations.py']",7,1ee2bb2e28e1409a9bf70aec7c2f47834adc79c5,,"from savanna.openstack.common.db.sqlalchemy import utils return utils.is_backend_avail(backend='mysql', user=user, passwd=passwd, database=database) return utils.is_backend_avail(backend='postgres', user=user, passwd=passwd, database=database) (user, password, database, host) = utils.get_db_connection_info(conn_pieces) utils.get_db_connection_info(conn_pieces)","def _get_connect_string(backend, user, passwd, database): """"""Get database connection Try to get a connection with a very specific set of values, if we get these then we'll run the tests, otherwise they are skipped """""" if backend == ""postgres"": backend = ""postgresql+psycopg2"" elif backend == ""mysql"": backend = ""mysql+mysqldb"" else: raise Exception(""Unrecognized backend: '%s'"" % backend) return (""%(backend)s://%(user)s:%(passwd)s@localhost/%(database)s"" % {'backend': backend, 'user': user, 'passwd': passwd, 'database': database}) def _is_backend_avail(backend, user, passwd, database): try: connect_uri = _get_connect_string(backend, user, passwd, database) engine = sqlalchemy.create_engine(connect_uri) connection = engine.connect() except Exception: # intentionally catch all to handle exceptions even if we don't # have any backend code loaded. return False else: connection.close() engine.dispose() return True return _is_backend_avail('mysql', user, passwd, database) return _is_backend_avail('postgres', user, passwd, database)def get_db_connection_info(conn_pieces): database = conn_pieces.path.strip('/') loc_pieces = conn_pieces.netloc.split('@') host = loc_pieces[1] auth_pieces = loc_pieces[0].split(':') user = auth_pieces[0] password = """" if len(auth_pieces) > 1: password = auth_pieces[1].strip() return (user, password, database, host) (user, password, database, host) = get_db_connection_info(conn_pieces) get_db_connection_info(conn_pieces)",108,62
openstack%2Ftempest~master~I1477e093a56210c0c9a65fa32900c2c0b876d9a4,openstack/tempest,master,I1477e093a56210c0c9a65fa32900c2c0b876d9a4,Cleanup exceptions,MERGED,2014-01-27 06:38:54.000000000,2014-02-02 19:16:53.000000000,2014-02-02 19:16:52.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}]","[{'number': 1, 'created': '2014-01-27 06:38:54.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/services/compute/xml/servers_client.py', 'tempest/scenario/manager.py', 'tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a0e786af523646b21dc3af58b15ac2899d2dbb3b', 'message': ""Cleanup exceptions\n\nThere are some invalid usages about exceptions. They put some invalid\nerror messages to the log like this.\n  --------------------------\n  BuildErrorException: Server %(server_id)s failed to build and is in\n  ERROR status)\n  --------------------------\nThis commit fixes them.\n\nNOTE: 'RateLimitExceeded' is only used in tempest/common/rest_client.py.\n This was refactored in I6c38c343618f92e0e79843aaa662a3d24026702b . But\n the class was not. And the last usage of 'SQLException' was removed in\n I0fac7b030c51985f9d6d93129bf9bab75c18cd11 . But the class was not.\n\nChange-Id: I1477e093a56210c0c9a65fa32900c2c0b876d9a4\n""}]",0,69285,a0e786af523646b21dc3af58b15ac2899d2dbb3b,6,3,1,5689,,,0,"Cleanup exceptions

There are some invalid usages about exceptions. They put some invalid
error messages to the log like this.
  --------------------------
  BuildErrorException: Server %(server_id)s failed to build and is in
  ERROR status)
  --------------------------
This commit fixes them.

NOTE: 'RateLimitExceeded' is only used in tempest/common/rest_client.py.
 This was refactored in I6c38c343618f92e0e79843aaa662a3d24026702b . But
 the class was not. And the last usage of 'SQLException' was removed in
 I0fac7b030c51985f9d6d93129bf9bab75c18cd11 . But the class was not.

Change-Id: I1477e093a56210c0c9a65fa32900c2c0b876d9a4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/69285/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/rest_client.py', 'tempest/services/compute/xml/servers_client.py', 'tempest/scenario/manager.py', 'tempest/exceptions.py']",4,a0e786af523646b21dc3af58b15ac2899d2dbb3b,exception-msg-cleanup," message = ""Rate limit exceeded"""," message = (""Rate limit exceeded.\nMessage: %(message)s\n"" ""Details: %(details)s"")class SQLException(TempestException): message = ""SQL error: %(message)s"" ",8,10
openstack%2Fsahara~master~I1352bf8d4a2a5fe064a793168b83adf677e75298,openstack/sahara,master,I1352bf8d4a2a5fe064a793168b83adf677e75298,Update oslo-incubator py3kcompat module,MERGED,2014-01-29 17:41:41.000000000,2014-02-02 19:13:12.000000000,2014-02-02 19:13:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:41.000000000', 'files': ['savanna/openstack/common/py3kcompat/urlutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/478f66ffd6b968b29ceb1668a532d4d2ad1b899a', 'message': 'Update oslo-incubator py3kcompat module\n\nChanges -\n * Add method quote_plus in module py3kcompat.urlutils\n\nChange-Id: I1352bf8d4a2a5fe064a793168b83adf677e75298\n'}]",0,69927,478f66ffd6b968b29ceb1668a532d4d2ad1b899a,11,7,1,7555,,,0,"Update oslo-incubator py3kcompat module

Changes -
 * Add method quote_plus in module py3kcompat.urlutils

Change-Id: I1352bf8d4a2a5fe064a793168b83adf677e75298
",git fetch https://review.opendev.org/openstack/sahara refs/changes/27/69927/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/py3kcompat/urlutils.py'],1,478f66ffd6b968b29ceb1668a532d4d2ad1b899a,, quote_plus = urllib.parse.quote_plus quote_plus = urllib.quote_plus,,2,0
openstack%2Fsahara~master~Ibc5115b06e9b7d844158d777aeb6ddc424141af5,openstack/sahara,master,Ibc5115b06e9b7d844158d777aeb6ddc424141af5,Update oslo-incubator middleware.base module,MERGED,2014-01-29 17:41:40.000000000,2014-02-02 19:13:05.000000000,2014-02-02 19:13:05.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:40.000000000', 'files': ['savanna/openstack/common/middleware/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2e329f48e1f0db0d2989b7d64e0738f5795343b6', 'message': 'Update oslo-incubator middleware.base module\n\nChanges -\n * Trivial: Make vertical white space after license header consistent\n\nChange-Id: Ibc5115b06e9b7d844158d777aeb6ddc424141af5\n'}]",0,69926,2e329f48e1f0db0d2989b7d64e0738f5795343b6,11,7,1,7555,,,0,"Update oslo-incubator middleware.base module

Changes -
 * Trivial: Make vertical white space after license header consistent

Change-Id: Ibc5115b06e9b7d844158d777aeb6ddc424141af5
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/69926/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/middleware/base.py'],1,2e329f48e1f0db0d2989b7d64e0738f5795343b6,,,,1,0
openstack%2Fsahara~master~I05672d658a1caf700c1accc597611ca795008ce3,openstack/sahara,master,I05672d658a1caf700c1accc597611ca795008ce3,Update oslo-incubator processutils module,MERGED,2014-01-29 17:41:40.000000000,2014-02-02 19:12:59.000000000,2014-02-02 19:12:59.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:40.000000000', 'files': ['savanna/openstack/common/processutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ed76b405b9d5e12a783ea5a3416211828caa4beb', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Catch OSError in processutils\n * Fix i18n problem in processutils module\n\nChange-Id: I05672d658a1caf700c1accc597611ca795008ce3\n'}]",0,69925,ed76b405b9d5e12a783ea5a3416211828caa4beb,11,7,1,7555,,,0,"Update oslo-incubator processutils module

Changes -
 * Catch OSError in processutils
 * Fix i18n problem in processutils module

Change-Id: I05672d658a1caf700c1accc597611ca795008ce3
",git fetch https://review.opendev.org/openstack/sahara refs/changes/25/69925/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/processutils.py'],1,ed76b405b9d5e12a783ea5a3416211828caa4beb,,"import errnoimport six description = _(""Unexpected error while running command."") message = _('%(description)s\n' 'Command: %(cmd)s\n' 'Exit code: %(exit_code)s\n' 'Stdout: %(stdout)r\n' 'Stderr: %(stderr)r') % {'description': description, 'cmd': cmd, 'exit_code': exit_code, 'stdout': stdout, 'stderr': stderr} message=_('Command requested root, but did not ' 'specify a root helper.')) for _i in six.moves.range(20): # NOTE(russellb) 20 is an arbitrary number of retries to # prevent any chance of looping forever here. try: if process_input is not None: result = obj.communicate(process_input) else: result = obj.communicate() except OSError as e: if e.errno in (errno.EAGAIN, errno.EINTR): continue raise break"," description = ""Unexpected error while running command."" message = (""%s\nCommand: %s\nExit code: %s\nStdout: %r\nStderr: %r"" % (description, cmd, exit_code, stdout, stderr)) message=('Command requested root, but did not specify a root ' 'helper.')) if process_input is not None: result = obj.communicate(process_input) else: result = obj.communicate()",27,9
openstack%2Fsahara~master~Ia4799eb97bbf1c1da4e90f862f8d09a1cfd986d2,openstack/sahara,master,Ia4799eb97bbf1c1da4e90f862f8d09a1cfd986d2,Update oslo-incubator service module,MERGED,2014-01-29 17:41:40.000000000,2014-02-02 19:12:58.000000000,2014-02-02 19:12:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:40.000000000', 'files': ['savanna/openstack/common/service.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/bbde9209e22d9803d4d789e1a677fa58295cb7e8', 'message': 'Update oslo-incubator service module\n\nChanges -\n * Simplify launch method\n * service: replace eventlet event by threading\n\nChange-Id: Ia4799eb97bbf1c1da4e90f862f8d09a1cfd986d2\n'}]",0,69924,bbde9209e22d9803d4d789e1a677fa58295cb7e8,12,8,1,7555,,,0,"Update oslo-incubator service module

Changes -
 * Simplify launch method
 * service: replace eventlet event by threading

Change-Id: Ia4799eb97bbf1c1da4e90f862f8d09a1cfd986d2
",git fetch https://review.opendev.org/openstack/sahara refs/changes/24/69924/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/service.py'],1,bbde9209e22d9803d4d789e1a677fa58295cb7e8,,"import threading self._done = threading.Event() self._done = threading.Event() self._done.set() self.done = threading.Event() self.done.set() self.done = threading.Event()def launch(service, workers=1): if workers is None or workers == 1: else: launcher = ProcessLauncher() launcher.launch_service(service, workers=workers) ","from eventlet import event self._done = event.Event() # NOTE(Fengqian): docs for Event.reset() recommend against using it self._done = event.Event() if not self._done.ready(): self._done.send() self.done = event.Event() if not self.done.ready(): self.done.send() self.done = event.Event()def launch(service, workers=None): if workers: launcher = ProcessLauncher() launcher.launch_service(service, workers=workers) else:",13,15
openstack%2Fsahara~master~Ib7c8dc88e9a4a9936087cfe7938a213d95277fdc,openstack/sahara,master,Ib7c8dc88e9a4a9936087cfe7938a213d95277fdc,Update oslo-incubator threadgroup module,MERGED,2014-01-29 17:41:40.000000000,2014-02-02 19:12:56.000000000,2014-02-02 19:12:56.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:40.000000000', 'files': ['savanna/openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/aa42a392138ec04d0466dbc7809c383ebe8a618a', 'message': 'Update oslo-incubator threadgroup module\n\nChanges -\n * Simple typo correction\n * threadgroup: use threading rather than greenthread\n\nChange-Id: Ib7c8dc88e9a4a9936087cfe7938a213d95277fdc\n'}]",0,69923,aa42a392138ec04d0466dbc7809c383ebe8a618a,12,8,1,7555,,,0,"Update oslo-incubator threadgroup module

Changes -
 * Simple typo correction
 * threadgroup: use threading rather than greenthread

Change-Id: Ib7c8dc88e9a4a9936087cfe7938a213d95277fdc
",git fetch https://review.opendev.org/openstack/sahara refs/changes/23/69923/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/threadgroup.py'],1,aa42a392138ec04d0466dbc7809c383ebe8a618a,,"import threading """"""The point of the ThreadGroup class is to: current = threading.current_thread() current = threading.current_thread()","from eventlet import greenthread """"""The point of the ThreadGroup classis to: current = greenthread.getcurrent() current = greenthread.getcurrent()",4,4
openstack%2Fsahara~master~I94038cfe875dea27640ae58a598e2692a529dd80,openstack/sahara,master,I94038cfe875dea27640ae58a598e2692a529dd80,Update oslo-incubator log module,MERGED,2014-01-29 17:41:40.000000000,2014-02-02 19:12:50.000000000,2014-02-02 19:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:40.000000000', 'files': ['savanna/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/13ad1358558c1f22aedf9295ac9904c9612f0318', 'message': ""Update oslo-incubator log module\n\nChanges -\n * default connectionpool to WARN log level\n * Backport 'ident' from python 3.3 for Oslo's SysLogHandler\n * remove extra newlines that eventlet seems to add\n * Small edits on help strings\n * Add error type to unhandled exception log message\n * Logging excepthook: print exception info if debug=True\n * Fix spelling errors in comments\n\nChange-Id: I94038cfe875dea27640ae58a598e2692a529dd80\n""}]",0,69922,13ad1358558c1f22aedf9295ac9904c9612f0318,13,8,1,7555,,,0,"Update oslo-incubator log module

Changes -
 * default connectionpool to WARN log level
 * Backport 'ident' from python 3.3 for Oslo's SysLogHandler
 * remove extra newlines that eventlet seems to add
 * Small edits on help strings
 * Add error type to unhandled exception log message
 * Logging excepthook: print exception info if debug=True
 * Fix spelling errors in comments

Change-Id: I94038cfe875dea27640ae58a598e2692a529dd80
",git fetch https://review.opendev.org/openstack/sahara refs/changes/22/69922/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/log.py'],1,13ad1358558c1f22aedf9295ac9904c9612f0318,," help='Use syslog for logging. ' 'Existing syslog format is DEPRECATED during I, ' 'and then will be changed in J to honor RFC5424'), cfg.BoolOpt('use-syslog-rfc-format', # TODO(bogdando) remove or use True after existing # syslog format deprecation in J default=False, help='(Optional) Use syslog rfc5424 format for logging. ' 'If enabled, will add APP-NAME (RFC5424) before the ' 'MSG part of the syslog message. The old format ' 'without APP-NAME is deprecated in I, ' 'and will be removed in J.'), help='Syslog facility to receive log lines') help='Format string to use for log messages with context'), help='Format string to use for log messages without context'), help='Data to append to log format when level is DEBUG'), help='Prefix each line of exception output with this format'), 'requests.packages.urllib3.connectionpool=WARN' help='List of logger=LEVEL pairs'), help='Publish error events'), help='Make deprecations fatal'), if CONF.verbose or CONF.debug: getLogger(product_name).critical( """".join(traceback.format_exception_only(exc_type, value)), **extra)class RFCSysLogHandler(logging.handlers.SysLogHandler): def __init__(self, *args, **kwargs): self.binary_name = _get_binary_name() super(RFCSysLogHandler, self).__init__(*args, **kwargs) def format(self, record): msg = super(RFCSysLogHandler, self).format(record) msg = self.binary_name + ' ' + msg return msg # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) self.logger.log(self.level, msg.rstrip()) # NOTE(sdague): default the fancier formatting params # Cache this on the record, Logger will respect our formatted copy"," help='Use syslog for logging.'), help='syslog facility to receive log lines') help='format string to use for log messages with context'), help='format string to use for log messages without context'), help='data to append to log format when level is DEBUG'), help='prefix each line of exception output with this format'), help='list of logger=LEVEL pairs'), help='publish error events'), help='make deprecations fatal'), if CONF.verbose: getLogger(product_name).critical(str(value), **extra) syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) self.logger.log(self.level, msg) # NOTE(sdague): default the fancier formating params # Cache this on the record, Logger will respect our formated copy",47,16
openstack%2Fsahara~master~I79750992a88b00344269e5c060978feba2b6a23f,openstack/sahara,master,I79750992a88b00344269e5c060978feba2b6a23f,Update oslo-incubator timeutils module,MERGED,2014-01-29 17:41:39.000000000,2014-02-02 19:01:55.000000000,2014-02-02 19:01:54.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:39.000000000', 'files': ['savanna/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/aa9241a56527a360ed2ce9518b5ed8abdc0b87a0', 'message': 'Update oslo-incubator timeutils module\n\nChanges -\n * Fix spelling errors in comments\n\nChange-Id: I79750992a88b00344269e5c060978feba2b6a23f\n'}]",0,69921,aa9241a56527a360ed2ce9518b5ed8abdc0b87a0,13,8,1,7555,,,0,"Update oslo-incubator timeutils module

Changes -
 * Fix spelling errors in comments

Change-Id: I79750992a88b00344269e5c060978feba2b6a23f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/21/69921/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/timeutils.py'],1,aa9241a56527a360ed2ce9518b5ed8abdc0b87a0,," """"""Returns a iso8601 formatted date from timestamp."""""""," """"""Returns a iso8601 formated date from timestamp.""""""",1,1
openstack%2Fsahara~master~I713f5acc02720731b004c89316f8c449e0dbd574,openstack/sahara,master,I713f5acc02720731b004c89316f8c449e0dbd574,Update oslo-incubator gettextutils module,MERGED,2014-01-29 17:41:39.000000000,2014-02-02 19:01:54.000000000,2014-02-02 19:01:53.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8091}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-29 17:41:39.000000000', 'files': ['savanna/openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1fdb6daee502601ba770eb3bf381536702818fc4', 'message': 'Update oslo-incubator gettextutils module\n\nChanges -\n * Fix E501 in individual openstack projects\n * Make Message keep string interpolation args\n * Add support for locales missing from babel\n\nChange-Id: I713f5acc02720731b004c89316f8c449e0dbd574\n'}]",0,69920,1fdb6daee502601ba770eb3bf381536702818fc4,20,7,1,7555,,,0,"Update oslo-incubator gettextutils module

Changes -
 * Fix E501 in individual openstack projects
 * Make Message keep string interpolation args
 * Add support for locales missing from babel

Change-Id: I713f5acc02720731b004c89316f8c449e0dbd574
",git fetch https://review.opendev.org/openstack/sahara refs/changes/20/69920/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/gettextutils.py'],1,1fdb6daee502601ba770eb3bf381536702818fc4,," def __new__(cls, msgid, msgtext=None, params=None, domain='savanna', *args): params = self._sanitize_mod_params(other) unicode_mod = super(Message, self).__mod__(params) params=params, # Save our existing parameters as defaults to protect # ourselves from losing values if we are called through an # (erroneous) chain that builds a valid Message with # arguments, and then does something like ""msg % kwds"" # where kwds is an empty dictionary. src = {} if isinstance(self.params, dict): src.update(self.params) src.update(dict_param) for key in keys: params[key] = self._copy_param(src[key]) # NOTE(luisg): Babel>=1.0,<1.3 has a bug where some OpenStack supported # locales (e.g. 'zh_CN', and 'zh_TW') aren't supported even though they # are perfectly legitimate locales: # https://github.com/mitsuhiko/babel/issues/37 # In Babel 1.3 they fixed the bug and they support these locales, but # they are still not explicitly ""listed"" by locale_identifiers(). # That is why we add the locales here explicitly if necessary so that # they are listed as supported. aliases = {'zh': 'zh_CN', 'zh_Hant_HK': 'zh_HK', 'zh_Hant': 'zh_TW', 'fil': 'tl_PH'} for (locale, alias) in six.iteritems(aliases): if locale in language_list and alias not in language_list: language_list.append(alias) "," def __new__(cls, msgid, msgtext=None, params=None, domain='savanna', *args): unicode_mod = super(Message, self).__mod__(other) params=self._sanitize_mod_params(other), for key in keys: params[key] = self._copy_param(dict_param[key])",33,4
openstack%2Frequirements~stable%2Fhavana~Id3b06be8ee203c3d15ccc2d846df0d0d8c4145ea,openstack/requirements,stable/havana,Id3b06be8ee203c3d15ccc2d846df0d0d8c4145ea,glance requires pyOpenSSL>=0.11,MERGED,2014-01-15 15:19:27.000000000,2014-02-02 17:52:32.000000000,2014-02-02 17:52:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1955}, {'_account_id': 6593}, {'_account_id': 7680}, {'_account_id': 8494}]","[{'number': 1, 'created': '2014-01-15 15:19:27.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e0416fa18b50a6ec63aac5de6a13bc69545d4c91', 'message': 'glance requires pyOpenSSL>=0.11\n\nglance uses  OpenSSL.crypto.sign() and OpenSSL.crypto.verify(), which are new in pyOpenSSL 0.11\nFix global requirement first, then glance will use it\n\nChange-Id: Id3b06be8ee203c3d15ccc2d846df0d0d8c4145ea\nPartial-Bug: #1268966\n'}]",0,66868,e0416fa18b50a6ec63aac5de6a13bc69545d4c91,15,6,1,8494,,,0,"glance requires pyOpenSSL>=0.11

glance uses  OpenSSL.crypto.sign() and OpenSSL.crypto.verify(), which are new in pyOpenSSL 0.11
Fix global requirement first, then glance will use it

Change-Id: Id3b06be8ee203c3d15ccc2d846df0d0d8c4145ea
Partial-Bug: #1268966
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/66868/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e0416fa18b50a6ec63aac5de6a13bc69545d4c91,havana/Bug/1268966,pyOpenSSL>=0.11,pyOpenSSL,1,1
openstack%2Foperations-guide~master~I38b6bcdc282b23d09a3a2dc409e85caf60e1dafe,openstack/operations-guide,master,I38b6bcdc282b23d09a3a2dc409e85caf60e1dafe,Rename README to README.rst,MERGED,2014-02-02 11:23:45.000000000,2014-02-02 17:06:21.000000000,2014-02-02 17:06:21.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:23:45.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/490a1bd561e9c5f2fb35e86ac23b3e35b094abd0', 'message': ""Rename README to README.rst\n\nThe file uses already the RST format in most cases. Let's rename\nit so that it gets displayed nicely on github. Reformat a few\npieces to follow RST format.\n\nChange-Id: I38b6bcdc282b23d09a3a2dc409e85caf60e1dafe\n""}]",0,70584,490a1bd561e9c5f2fb35e86ac23b3e35b094abd0,7,4,1,6547,,,0,"Rename README to README.rst

The file uses already the RST format in most cases. Let's rename
it so that it gets displayed nicely on github. Reformat a few
pieces to follow RST format.

Change-Id: I38b6bcdc282b23d09a3a2dc409e85caf60e1dafe
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/84/70584/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,490a1bd561e9c5f2fb35e86ac23b3e35b094abd0,README,OpenStack Operations Guide +++++++++++++++++++ * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,"* ""tox -e checkniceness"" - to run the niceness tests * ""tox -e checksyntax"" - to run syntax checks * ""tox -e checkdeletions"" - to check that no deleted files are referenced * ""tox -e checkbuild"" - to actually build the manual",9,4
openstack%2Fopenstack-manuals~master~I4267e02e540b4283b273092d8566894a2c422444,openstack/openstack-manuals,master,I4267e02e540b4283b273092d8566894a2c422444,Ignore publish-docs directory,MERGED,2014-02-02 14:29:54.000000000,2014-02-02 16:30:16.000000000,2014-02-02 16:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-02-02 14:29:54.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64f06adfba15f97002421376a3fd5484e7ae5547', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I4267e02e540b4283b273092d8566894a2c422444\n'}]",0,70591,64f06adfba15f97002421376a3fd5484e7ae5547,6,3,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I4267e02e540b4283b273092d8566894a2c422444
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/91/70591/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,64f06adfba15f97002421376a3fd5484e7ae5547,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack%2Fapi-site~master~I621d1c63716d3cc04ea5678def5ecba13e29c807,openstack/api-site,master,I621d1c63716d3cc04ea5678def5ecba13e29c807,Ignore publish-docs directory,MERGED,2014-02-02 15:35:30.000000000,2014-02-02 16:27:10.000000000,2014-02-02 16:27:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 15:35:30.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/api-site/commit/f58bf159b7fa7ab8e1f4c2bf61f4d603c679c551', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I621d1c63716d3cc04ea5678def5ecba13e29c807\n'}]",0,70600,f58bf159b7fa7ab8e1f4c2bf61f4d603c679c551,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I621d1c63716d3cc04ea5678def5ecba13e29c807
",git fetch https://review.opendev.org/openstack/api-site refs/changes/00/70600/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,f58bf159b7fa7ab8e1f4c2bf61f4d603c679c551,bp/draft-docs-on-docs-draft,# Build results publish-docs/ target/ ,target/,4,1
openstack%2Foperations-guide~master~I6afea2e9b44bc97b3d9f9138e4523be14aba4a1b,openstack/operations-guide,master,I6afea2e9b44bc97b3d9f9138e4523be14aba4a1b,Ignore publish-docs directory,MERGED,2014-02-02 16:17:45.000000000,2014-02-02 16:23:57.000000000,2014-02-02 16:23:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:17:45.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/66a6f7b5957e2f43b9b77ced12013a28ea11cf9a', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I6afea2e9b44bc97b3d9f9138e4523be14aba4a1b\n'}]",0,70609,66a6f7b5957e2f43b9b77ced12013a28ea11cf9a,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I6afea2e9b44bc97b3d9f9138e4523be14aba4a1b
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/09/70609/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,66a6f7b5957e2f43b9b77ced12013a28ea11cf9a,bp/draft-docs-on-docs-draft,# Build directories target/ publish-docs/ ,target/,4,1
openstack-attic%2Fobject-api~master~I5068eaa8105b003a43d7e909de447920d649451b,openstack-attic/object-api,master,I5068eaa8105b003a43d7e909de447920d649451b,Ignore publish-docs directory,MERGED,2014-02-02 16:13:41.000000000,2014-02-02 16:23:05.000000000,2014-02-02 16:23:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:13:41.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/4cdc0ea94ae21c564c94170c863c2612eeda431f', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I5068eaa8105b003a43d7e909de447920d649451b\n'}]",0,70607,4cdc0ea94ae21c564c94170c863c2612eeda431f,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I5068eaa8105b003a43d7e909de447920d649451b
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/07/70607/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,4cdc0ea94ae21c564c94170c863c2612eeda431f,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack-attic%2Fcompute-api~master~Ib65ea472a4503a19c10ceabd8835b17e069d0dde,openstack-attic/compute-api,master,Ib65ea472a4503a19c10ceabd8835b17e069d0dde,Ignore publish-docs directory,MERGED,2014-02-02 15:42:16.000000000,2014-02-02 16:22:54.000000000,2014-02-02 16:22:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 15:42:16.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/b57800525801e935cfccabe7de712f07a3b9f792', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: Ib65ea472a4503a19c10ceabd8835b17e069d0dde\n'}]",0,70601,b57800525801e935cfccabe7de712f07a3b9f792,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: Ib65ea472a4503a19c10ceabd8835b17e069d0dde
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/01/70601/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,b57800525801e935cfccabe7de712f07a3b9f792,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack-attic%2Fnetconn-api~master~I196f21001be86b054639260fb802782b467f3550,openstack-attic/netconn-api,master,I196f21001be86b054639260fb802782b467f3550,Ignore publish-docs directory,MERGED,2014-02-02 16:13:13.000000000,2014-02-02 16:22:00.000000000,2014-02-02 16:22:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:13:13.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/3b5997381332ac272384822a16359b9fa13ffc98', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I196f21001be86b054639260fb802782b467f3550\n'}]",0,70606,3b5997381332ac272384822a16359b9fa13ffc98,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I196f21001be86b054639260fb802782b467f3550
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/06/70606/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,3b5997381332ac272384822a16359b9fa13ffc98,bp/draft-docs-on-docs-draft, # Build resultspublish-docs/,,3,0
openstack-attic%2Fvolume-api~master~I4ec693956c52623fc388928f1af159e1a3a464ec,openstack-attic/volume-api,master,I4ec693956c52623fc388928f1af159e1a3a464ec,Ignore publish-docs directory,MERGED,2014-02-02 16:14:13.000000000,2014-02-02 16:21:17.000000000,2014-02-02 16:21:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:14:13.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/6ec1e70df4ba0bbfa51b9af7610bebe605e9ce2e', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: I4ec693956c52623fc388928f1af159e1a3a464ec\n'}]",0,70608,6ec1e70df4ba0bbfa51b9af7610bebe605e9ce2e,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: I4ec693956c52623fc388928f1af159e1a3a464ec
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/08/70608/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,6ec1e70df4ba0bbfa51b9af7610bebe605e9ce2e,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack-attic%2Fidentity-api~master~Ia4bff14e89f632accee8485ec2644a82317b952a,openstack-attic/identity-api,master,Ia4bff14e89f632accee8485ec2644a82317b952a,Ignore publish-docs directory,MERGED,2014-02-02 16:12:03.000000000,2014-02-02 16:20:59.000000000,2014-02-02 16:20:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:12:03.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/4f3612f6fa8e573afe208deb8aa81cf04705fba4', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: Ia4bff14e89f632accee8485ec2644a82317b952a\n'}]",0,70605,4f3612f6fa8e573afe208deb8aa81cf04705fba4,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: Ia4bff14e89f632accee8485ec2644a82317b952a
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/05/70605/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,4f3612f6fa8e573afe208deb8aa81cf04705fba4,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack-attic%2Fdatabase-api~master~Ia5c7a1524a5676779d3ccb229167bdd76f552618,openstack-attic/database-api,master,Ia5c7a1524a5676779d3ccb229167bdd76f552618,Ignore publish-docs directory,MERGED,2014-02-02 16:04:04.000000000,2014-02-02 16:18:55.000000000,2014-02-02 16:18:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:04:04.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/database-api/commit/4c04d7523406e5eebd9335247d7e9b4bb76441de', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: Ia5c7a1524a5676779d3ccb229167bdd76f552618\n'}]",0,70603,4c04d7523406e5eebd9335247d7e9b4bb76441de,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: Ia5c7a1524a5676779d3ccb229167bdd76f552618
",git fetch https://review.opendev.org/openstack-attic/database-api refs/changes/03/70603/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,4c04d7523406e5eebd9335247d7e9b4bb76441de,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack-attic%2Fimage-api~master~Icdfd7675c11c8de03ca4c0f7d99b2c06bf100966,openstack-attic/image-api,master,Icdfd7675c11c8de03ca4c0f7d99b2c06bf100966,Ignore publish-docs directory,MERGED,2014-02-02 16:11:16.000000000,2014-02-02 16:18:54.000000000,2014-02-02 16:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 16:11:16.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/391b704291a1eeee585d5c2cee4ddbbff0baa53f', 'message': 'Ignore publish-docs directory\n\nIgnore publish-docs directory. This is the directory used by\nopenstack-doc-test to copy draft documents to.\n\nblueprint draft-docs-on-docs-draft\n\nChange-Id: Icdfd7675c11c8de03ca4c0f7d99b2c06bf100966\n'}]",0,70604,391b704291a1eeee585d5c2cee4ddbbff0baa53f,5,2,1,6547,,,0,"Ignore publish-docs directory

Ignore publish-docs directory. This is the directory used by
openstack-doc-test to copy draft documents to.

blueprint draft-docs-on-docs-draft

Change-Id: Icdfd7675c11c8de03ca4c0f7d99b2c06bf100966
",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/04/70604/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,391b704291a1eeee585d5c2cee4ddbbff0baa53f,bp/draft-docs-on-docs-draft,publish-docs/,,1,0
openstack%2Fopenstack-manuals~master~Id287eacb02ec8ed84af15274161df3be2abbd648,openstack/openstack-manuals,master,Id287eacb02ec8ed84af15274161df3be2abbd648,Applies consistent cluster terminology to section,MERGED,2014-02-02 07:41:30.000000000,2014-02-02 15:22:02.000000000,2014-02-02 15:22:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 07:41:30.000000000', 'files': ['doc/admin-guide-cloud/section_networking_high_avail.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f85e817bf3e709c535f46970852dbe8869c3019a', 'message': 'Applies consistent cluster terminology to section\n\nSection contained a number of variations for the clustering terms\n""active/active"" and ""active/passive"". This patch standardises usage\nin this section.\n\nChange-Id: Id287eacb02ec8ed84af15274161df3be2abbd648\nPartial-Bug: #1217503\n'}]",0,70566,f85e817bf3e709c535f46970852dbe8869c3019a,7,4,1,10203,,,0,"Applies consistent cluster terminology to section

Section contained a number of variations for the clustering terms
""active/active"" and ""active/passive"". This patch standardises usage
in this section.

Change-Id: Id287eacb02ec8ed84af15274161df3be2abbd648
Partial-Bug: #1217503
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/66/70566/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/section_networking_high_avail.xml'],1,f85e817bf3e709c535f46970852dbe8869c3019a,Conventions-1217503, active/active fashion. You can run the <systemitem configuration (active/passive or active/active for, active-active fashion. You can run the <systemitem configuration (Active / Passive or Active / Active for,2,2
openstack%2Fopenstack-manuals~master~I24e64fc1192e485b3bd7e374cf11afdbacfcb7e6,openstack/openstack-manuals,master,I24e64fc1192e485b3bd7e374cf11afdbacfcb7e6,Fix formatting and output of 'nova help',MERGED,2014-02-02 09:26:17.000000000,2014-02-02 15:15:22.000000000,2014-02-02 15:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-02-02 09:26:17.000000000', 'files': ['doc/common/section_cli_nova_customize_flavors.xml', 'doc/admin-guide-cloud/ch_compute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/80afa027aa3cbb6731a2469930ea843f6c72bf39', 'message': ""Fix formatting and output of 'nova help'\n\nUpdate the 'nova help' output samples with the latest client version in\nthe cloud admin guide.\n\nChange-Id: I24e64fc1192e485b3bd7e374cf11afdbacfcb7e6\n""}]",0,70572,80afa027aa3cbb6731a2469930ea843f6c72bf39,6,3,1,7923,,,0,"Fix formatting and output of 'nova help'

Update the 'nova help' output samples with the latest client version in
the cloud admin guide.

Change-Id: I24e64fc1192e485b3bd7e374cf11afdbacfcb7e6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/70572/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/section_cli_nova_customize_flavors.xml', 'doc/admin-guide-cloud/ch_compute.xml']",2,80afa027aa3cbb6731a2469930ea843f6c72bf39,formatting-fix, <screen><prompt>$</prompt> <userinput>nova help</userinput> <computeroutput>usage: nova [--version] [--debug] [--os-cache] [--timings] [--timeout &lt;seconds&gt;] [--os-username &lt;auth-user-name&gt;] [--os-password &lt;auth-password&gt;] [--os-tenant-name &lt;auth-tenant-name&gt;] [--os-tenant-id &lt;auth-tenant-id&gt;] [--os-auth-url &lt;auth-url&gt;] [--os-region-name &lt;region-name&gt;] [--os-auth-system &lt;auth-system&gt;] [--service-type &lt;service-type&gt;] [--service-name &lt;service-name&gt;] [--volume-service-name &lt;volume-service-name&gt;] [--endpoint-type &lt;endpoint-type&gt;] [--os-compute-api-version &lt;compute-api-ver&gt;] [--os-cacert &lt;ca-certificate&gt;] [--insecure] [--bypass-url &lt;bypass-url&gt;] &lt;subcommand&gt; ...</computeroutput></screen>, <screen><prompt>$</prompt> <userinput>nova help</userinput><computeroutput>usage: nova [--debug] [--os-username OS_USERNAME] [--os-password OS_PASSWORD] [--os-tenant-name_name OS_TENANT_NAME] [--os-auth-url OS_AUTH_URL] [--os-region-name OS_REGION_NAME] [--service-type SERVICE_TYPE] [--service-name SERVICE_NAME] [--endpoint-type ENDPOINT_TYPE] [--version VERSION] &lt;subcommand&gt; ...</computeroutput></screen>,23,16
openstack-attic%2Fdatabase-api~master~I0cda675b828a0af5bede9d0b99a7fb876bfbdf5e,openstack-attic/database-api,master,I0cda675b828a0af5bede9d0b99a7fb876bfbdf5e,Add xml:ids to resources,MERGED,2014-01-31 19:15:15.000000000,2014-02-02 12:35:49.000000000,2014-02-02 12:35:49.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 2448}, {'_account_id': 5293}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 19:15:15.000000000', 'files': ['apidocs/src/xsd/dbaas.wadl'], 'web_link': 'https://opendev.org/openstack-attic/database-api/commit/a755948f3fdb85deb7410cdf2c3f7bf9199452a1', 'message': 'Add xml:ids to resources\n\nAdd xml:ids to resources. This is a new requirement that has to do\nwith the generation of PDFs from WADL files  without this, the paths\nare not unique across WADL files\n\nRelated-Bug: #1275007\n\nChange-Id: I0cda675b828a0af5bede9d0b99a7fb876bfbdf5e\n'}]",0,70407,a755948f3fdb85deb7410cdf2c3f7bf9199452a1,7,5,1,6547,,,0,"Add xml:ids to resources

Add xml:ids to resources. This is a new requirement that has to do
with the generation of PDFs from WADL files  without this, the paths
are not unique across WADL files

Related-Bug: #1275007

Change-Id: I0cda675b828a0af5bede9d0b99a7fb876bfbdf5e
",git fetch https://review.opendev.org/openstack-attic/database-api refs/changes/07/70407/1 && git format-patch -1 --stdout FETCH_HEAD,['apidocs/src/xsd/dbaas.wadl'],1,a755948f3fdb85deb7410cdf2c3f7bf9199452a1,," <resources base=""https://ord.databases.api.rackspacecloud.com"" xml:id=""dbaas"">"," <resources base=""https://ord.databases.api.rackspacecloud.com"">",2,1
openstack-attic%2Fcompute-api~master~I3cbf36745a6c39c2a06d5522ffd7424e80f3f278,openstack-attic/compute-api,master,I3cbf36745a6c39c2a06d5522ffd7424e80f3f278,Fix bullet list format in README.rst,MERGED,2014-02-02 11:16:00.000000000,2014-02-02 11:36:41.000000000,2014-02-02 11:36:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:16:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/dd2aed2f95cb717ae57a3ec3b596d5bf52d6655b', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I3cbf36745a6c39c2a06d5522ffd7424e80f3f278\n'}]",0,70577,dd2aed2f95cb717ae57a3ec3b596d5bf52d6655b,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I3cbf36745a6c39c2a06d5522ffd7424e80f3f278
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/77/70577/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,dd2aed2f95cb717ae57a3ec3b596d5bf52d6655b,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fnetconn-api~master~If0b6935144dcead9b329b55f0a9af41469085565,openstack-attic/netconn-api,master,If0b6935144dcead9b329b55f0a9af41469085565,Fix bullet list format in README.rst,MERGED,2014-02-02 11:20:00.000000000,2014-02-02 11:30:56.000000000,2014-02-02 11:30:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:20:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/e24f28b32e288a5451d827029b97bacd672e1de6', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: If0b6935144dcead9b329b55f0a9af41469085565\n'}]",0,70583,e24f28b32e288a5451d827029b97bacd672e1de6,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: If0b6935144dcead9b329b55f0a9af41469085565
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/83/70583/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e24f28b32e288a5451d827029b97bacd672e1de6,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fdatabase-api~master~I5e6e539915f13d7ff9a9a3c35cd67edc26ef6efa,openstack-attic/database-api,master,I5e6e539915f13d7ff9a9a3c35cd67edc26ef6efa,Fix bullet list format in README.rst,MERGED,2014-02-02 11:16:37.000000000,2014-02-02 11:29:07.000000000,2014-02-02 11:29:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:16:37.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/database-api/commit/b7b2153e8def8edab4743dc7e8148ea456ce5520', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I5e6e539915f13d7ff9a9a3c35cd67edc26ef6efa\n'}]",0,70578,b7b2153e8def8edab4743dc7e8148ea456ce5520,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I5e6e539915f13d7ff9a9a3c35cd67edc26ef6efa
",git fetch https://review.opendev.org/openstack-attic/database-api refs/changes/78/70578/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b7b2153e8def8edab4743dc7e8148ea456ce5520,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fidentity-api~master~I72664bdc2acc8507d2ca262661317780f9d0c090,openstack-attic/identity-api,master,I72664bdc2acc8507d2ca262661317780f9d0c090,Fix bullet list format in README.rst,MERGED,2014-02-02 11:17:27.000000000,2014-02-02 11:27:35.000000000,2014-02-02 11:27:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:17:27.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/4f9e8187ed8070554f790320cbacff78c4a7f6d4', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I72664bdc2acc8507d2ca262661317780f9d0c090\n'}]",0,70579,4f9e8187ed8070554f790320cbacff78c4a7f6d4,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I72664bdc2acc8507d2ca262661317780f9d0c090
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/79/70579/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4f9e8187ed8070554f790320cbacff78c4a7f6d4,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fimage-api~master~I648dc062047ca14d1ce006d913809520039d8ad7,openstack-attic/image-api,master,I648dc062047ca14d1ce006d913809520039d8ad7,Fix bullet list format in README.rst,MERGED,2014-02-02 11:18:13.000000000,2014-02-02 11:27:28.000000000,2014-02-02 11:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:18:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/248627055f2ac7cdac3ea3bf46174c49743d5bdb', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I648dc062047ca14d1ce006d913809520039d8ad7\n'}]",0,70580,248627055f2ac7cdac3ea3bf46174c49743d5bdb,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I648dc062047ca14d1ce006d913809520039d8ad7
",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/80/70580/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,248627055f2ac7cdac3ea3bf46174c49743d5bdb,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fvolume-api~master~I9107b86a412c7f400edd7c3ab3938abce59746fb,openstack-attic/volume-api,master,I9107b86a412c7f400edd7c3ab3938abce59746fb,Fix bullet list format in README.rst,MERGED,2014-02-02 11:19:25.000000000,2014-02-02 11:27:25.000000000,2014-02-02 11:27:25.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:19:25.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/f29fb0e207f4bb87f7d465385e11ae5ce2aa6587', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I9107b86a412c7f400edd7c3ab3938abce59746fb\n'}]",0,70582,f29fb0e207f4bb87f7d465385e11ae5ce2aa6587,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I9107b86a412c7f400edd7c3ab3938abce59746fb
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/82/70582/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,f29fb0e207f4bb87f7d465385e11ae5ce2aa6587,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack-attic%2Fobject-api~master~I30a056dcb1f61eb3049d920ec90df89e5fd48a63,openstack-attic/object-api,master,I30a056dcb1f61eb3049d920ec90df89e5fd48a63,Fix bullet list format in README.rst,MERGED,2014-02-02 11:18:45.000000000,2014-02-02 11:27:21.000000000,2014-02-02 11:27:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-02-02 11:18:45.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/3b2b591fc29209ff9e286c58a3e4b4bfe083cceb', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I30a056dcb1f61eb3049d920ec90df89e5fd48a63\n'}]",0,70581,3b2b591fc29209ff9e286c58a3e4b4bfe083cceb,6,3,1,6547,,,0,"Fix bullet list format in README.rst

Change-Id: I30a056dcb1f61eb3049d920ec90df89e5fd48a63
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/81/70581/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3b2b591fc29209ff9e286c58a3e4b4bfe083cceb,fix-bullet-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack%2Fapi-site~master~I3680bd972a2c3247f1a07c84752ca65ce7a54c7b,openstack/api-site,master,I3680bd972a2c3247f1a07c84752ca65ce7a54c7b,Fix bullet list format in README.rst,MERGED,2014-02-02 10:16:54.000000000,2014-02-02 11:26:06.000000000,2014-02-02 11:26:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 10:16:54.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/29c74c3d98cb264a81388a167324f8e4ed80e7a8', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I3680bd972a2c3247f1a07c84752ca65ce7a54c7b\n'}]",0,70575,29c74c3d98cb264a81388a167324f8e4ed80e7a8,5,2,1,7923,,,0,"Fix bullet list format in README.rst

Change-Id: I3680bd972a2c3247f1a07c84752ca65ce7a54c7b
",git fetch https://review.opendev.org/openstack/api-site refs/changes/75/70575/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,29c74c3d98cb264a81388a167324f8e4ed80e7a8,, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack%2Fnova~master~Ib613e6300f2c215be90f924afbd223a3da053a69,openstack/nova,master,Ib613e6300f2c215be90f924afbd223a3da053a69,Port to oslo.messaging,MERGED,2013-08-02 13:47:53.000000000,2014-02-02 11:08:41.000000000,2014-02-02 11:08:37.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 5638}, {'_account_id': 7040}, {'_account_id': 7494}, {'_account_id': 8810}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-08-02 13:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84b9aded53f98fb942052977cd02ca05ddddc259', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules, except cells\n\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 2, 'created': '2013-08-05 15:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eea271416d6aef4a107e158c5659a0fe9895e811', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 3, 'created': '2013-08-06 06:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5eb992314144aa0666f0460c0ff9baa5635642d7', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 4, 'created': '2013-08-06 06:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35304ee606cf3749d8f92597a9f45610136773cf', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 5, 'created': '2013-08-06 07:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48551736104b1b5a8bfbfa8c15b2be4dcf5f83b6', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 6, 'created': '2013-08-06 07:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f33e6a1ede5eb89e30041a44e74e148df0309f06', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 7, 'created': '2013-08-06 12:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/365220d54b2753a1155a25549ba9ec8ab844bf30', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 8, 'created': '2013-08-06 13:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82460557905f130c5b173007103a1b8196eca685', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n\ntodo items:\n\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 9, 'created': '2013-08-07 12:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d6ccca3a6aa3167f738f2d83adbe97c96f2d900', 'message': 'Start porting to oslo.messaging\n\nThis is nowhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n\ntodo items:\n\n  * add dependency on oslo.messaging\n  * set up backwards compat entry points\n  * figure out a plan for request contexts\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n  * notifications\n  * check_for_lock\n  * thread local context and logging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 10, 'created': '2013-08-09 12:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e75a8c6cb38d3eec627f5c894b1f009c24705f0', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n\ntodo items:\n\n  * add dependency on oslo.messaging\n  * check the transport URLs used by cells are compatible with\n    oslo.messaging\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 11, 'created': '2013-08-09 16:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b046aa7c2e324f2cb3914e9fdf580cac6485d314', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n\ntodo items:\n\n  * add dependency on oslo.messaging\n  * cells! See the 6 FIXME(markmc)s under nova/cells\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 12, 'created': '2013-08-11 21:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d7732033ed675418ca8d6acc3c50db5d914404a', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete.\n\nSo far:\n\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n\ntodo items:\n\n  * add dependency on oslo.messaging\n  * cells! See the 6 FIXME(markmc)s under nova/cells\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 13, 'created': '2013-08-13 16:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e90b2646b649257a9365418fe79bbdee27cc0f73', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete. Except for the mere matter of unit\ntests and the like :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a3\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 14, 'created': '2013-08-13 17:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d25b9700d9eca31bdf3e8bdcc89ecd6ead262947', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete. Except for the mere matter of unit\ntests and the like :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a3\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n\nblueprint: oslo.messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 15, 'created': '2013-08-13 19:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a91276dba8d1048fb4003fe12cf5da3407f1286', 'message': 'Start porting to oslo.messaging\n\nThis is somewhere near complete. Except for the mere matter of unit\ntests and the like :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a3\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 16, 'created': '2013-08-16 22:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b3a8b78664776867a5a881a21d02e67d18c3231', 'message': 'Start porting to oslo.messaging\n\nThis is almost complete. Some unit test failures remain.\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a3\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 17, 'created': '2013-08-17 07:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68d7bbd97bd132d8933167e8d8675ade88a08b37', 'message': 'Start porting to oslo.messaging\n\nThis is almost complete. Some unit test failures remain.\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a3\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 18, 'created': '2013-08-17 17:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a26bab25006ad7e8a37a6391bac8945d939f805', 'message': 'Start porting to oslo.messaging\n\nThis is almost complete. Some unit test failures remain.\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a6\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 19, 'created': '2013-08-19 10:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4218572a4200912e838e60e5d4d5171884aff24', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, but there are a bunch of changes to the\ntests which I think can be split out into separate patches.\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 20, 'created': '2013-08-19 10:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27583cf11ac39771ea70cee80f7453404c5b7d6c', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, but there are a bunch of changes to the\ntests which I think can be split out into separate patches.\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 21, 'created': '2013-08-19 22:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e86b6ed020c80e4b4d53bd7a9608ce70ffbdc368', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, except I need to clean up the commit\nmessage :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 22, 'created': '2013-08-19 22:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c930e7f7f62a804cb42fcb5e9dd4869b3560aa2', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, except I need to clean up the commit\nmessage :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 23, 'created': '2013-08-20 06:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0285d07b0deacdaba2e0e45e417c35b79079c1a3', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, except I need to clean up the commit\nmessage :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 24, 'created': '2013-08-20 08:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a025e811685c1419e8496059f71119115aa6e78d', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, except I need to clean up the commit\nmessage :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 25, 'created': '2013-08-20 10:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e52fc738b49d6603044cd7dee00fa5caa01be63e', 'message': 'Port to oslo.messaging\n\nThis is pretty complete now, except I need to clean up the commit\nmessage :)\n\nSo far:\n\n  * require oslo.messaging>=1.2.0a9\n  * construct a messaging.Transport at startup and clean it up at\n    shutdown\n  * add a rpc.get_client() helper method\n  * port all of the client rpcapi modules\n  * port from RpcDispatcher to RPCServer\n  * add target attributes to all endpoints\n  * s/client_exceptions/expected_exceptions/\n  * request context serializer\n  * entry points for rpc_backend backwards compat\n  * added check_for_lock() integration\n  * notifications ported\n  * use the TransportURL API for cells\n  * use messaging.ConfFixture\n  * tricky stuff with cells proxy_rpc_to_manager()\n  * a fake Notifier implementation for tests\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n'}, {'number': 26, 'created': '2013-08-21 15:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90172f857409fe8cd90a1ea95e93b15d52ea5c7a', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers, hook\n    up check_for_lock() and specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapuslated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 27, 'created': '2013-08-21 19:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54cdaa3174625a3315463169d48f3186a69e370e', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers, hook\n    up check_for_lock() and specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapuslated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 28, 'created': '2013-08-23 18:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/059333d9219af382a099ef0ec334b4d4799a8728', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers, hook\n    up check_for_lock() and specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapuslated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 29, 'created': '2013-08-25 10:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ff757c8d15abb78a3bd7d1a79e5cbb539957025', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers, hook\n    up check_for_lock() and specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapuslated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 30, 'created': '2013-08-25 10:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc79d903ddeb3c507a5a4cbd63ba8937963260e1', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers, hook\n    up check_for_lock() and specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapuslated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 31, 'created': '2013-08-26 13:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/355757bcb456ff31796b8c2a0fb4ee3b287c7e3f', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 32, 'created': '2013-08-27 21:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4355c4a77a8e7f5aca559f6845d24ff24a46ac08', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 33, 'created': '2013-08-27 23:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06ee7d0ebdd27338f06cc2acf70553ab0b034189', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 34, 'created': '2013-08-29 08:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c69c5355b0c06d19dcf5329c9eba8280decabb80', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 35, 'created': '2013-08-29 09:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9feed99fd7bcf7dd58d31ca5ea43cb84549cc98e', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify(). We maintain a global NOTIFIER object and create\n    specializations of it with specific publisher IDs in order to avoid\n    notification driver loading overhead.\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 36, 'created': '2013-08-29 23:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e6104b406648c901a684445a32c10f514e6c8d8', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 37, 'created': '2013-08-30 00:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7cb1d22d0ff4592ee96cd8bc6396f12749a3bb2', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 38, 'created': '2013-08-30 06:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2a0fee1c67e19a117c896f0e0d78b5164072611', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 39, 'created': '2013-09-02 16:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e490bbc82410c460e422597c67f2965016feaa2a', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 40, 'created': '2013-09-03 18:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a78f4b645464b86c6fd63eb8d9fccfbbfbfae98', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 41, 'created': '2013-09-03 20:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a276f6500a92a93d449a018fabce78f490b6611', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a10 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 42, 'created': '2013-09-03 20:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/014092365d72f602b7349229b2b81e0f0f4ea5dd', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 43, 'created': '2013-09-03 21:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c73712ead478d6b0d2cd16fa143d2cb5be953bc8', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 44, 'created': '2013-09-04 06:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7e98ae862d0c9bc8f54e99cfcfffbce2b5d9f04', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 45, 'created': '2013-09-04 16:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ec3c616f49b2ff31f83f97bfd0d1071fe515540', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 46, 'created': '2013-09-04 16:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ac59ee68029a508574e0761ec0921255064b462', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 47, 'created': '2013-09-04 20:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2785ec76bf98360637197bccc29196a61aa00e04', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 48, 'created': '2013-09-05 05:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/672fe590df4c53aa7caedde067eb86a17d1566b1', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 49, 'created': '2013-09-05 14:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a4a9bddc08dcaf44959290ce58a6bf8c9274756', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed after havana-3.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 50, 'created': '2013-10-05 13:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db2ac5e7085f4d962677b9440d57c893cac62a0f', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 51, 'created': '2013-10-05 13:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d687e9d546a41b2582442d2b9826ba59a2daaa06', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 52, 'created': '2013-10-11 10:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/057d34003fd6cef4fa65ac7861eefcea24b47a17', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 53, 'created': '2013-10-14 06:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fce9733b7a144e38f2415b67ec3ad9bb42361efd', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 54, 'created': '2013-10-14 08:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9b930d84c17459ed1231cb384695e71719d89e0', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 55, 'created': '2013-10-16 19:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10198a8eb44f3418d4f6668663edef1eb2bea3bd', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 56, 'created': '2013-10-16 20:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea7394cc2ab76f4417d09b5361e25bed338fe3c3', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 57, 'created': '2013-10-17 06:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/598b89569168dfa33647269707abe1a877626896', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering.\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 58, 'created': '2013-10-18 13:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fcd14b789714a90bfe9d98bb7b18789f5e06d71', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 59, 'created': '2013-10-18 15:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/344688e1f816acc2778d5432ddc4ba41877e988f', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 60, 'created': '2013-10-21 09:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/691948bf459bb0ad2aa2c4124890d7995cb190fe', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 61, 'created': '2013-10-21 09:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf0bb67a03c3832937e2e50187d6716d003652f7', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 62, 'created': '2013-10-21 11:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dbb9be97c084243a4258fd5fbb60ce38b7340eea', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 63, 'created': '2013-10-21 13:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54d509c5243a444fd12d3f1c7edea8b699e5b6a6', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.2.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 64, 'created': '2013-10-25 16:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/357e6a159e4ca9d45766dcd7816b5a773224d12e', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 65, 'created': '2013-10-31 14:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3269fbbbc77dec68b59395c2df251b61d07eb46', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 66, 'created': '2013-10-31 15:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79770eb4325b086fd429e1a9b8e1e0dec7c1a059', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 67, 'created': '2013-10-31 22:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40d2385b11f7964d50ed04780064a97ba27c1d7a', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 68, 'created': '2013-11-12 06:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/705c5d491af9486b13134ccb27b8a88c952e9fc0', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 69, 'created': '2013-11-13 06:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd715384f1fb297dfffce037444710226089abf7', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.2.0a11 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * setup.cfg contains entry point aliases for backwards compatibility\n    purposes. I don't love this and, in future, we may allow such\n    aliases to be passed to get_transport() and Notifier().\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 70, 'created': '2014-01-21 08:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/447951a8f750e6fe15ed473ac7e3ea23f94ceff2', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging 1.3.0a3 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * All of the messaging options are now removed from nova.conf.sample\n    because the sample config file generator doesn't yet know how to\n    pick up these.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 71, 'created': '2014-01-22 07:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e663f447a075640597910afa98047ef99c6a687', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a3 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * All of the messaging options are temporarily removed from\n    nova.conf.sample because oslo.messaging does not yet advertise its\n    config options via the oslo.config.opts entry point. See review\n    Ic28351258652d2ea38974e2f4d1aa6b1d3dd7192. However, we do note\n    in tools/config/README how to run the generator to query the\n    entry point.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 72, 'created': '2014-01-22 07:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/023bcb2198ebba886998d12aa8f0757853ff3565', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a3 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * All of the messaging options are temporarily removed from\n    nova.conf.sample because oslo.messaging does not yet advertise its\n    config options via the oslo.config.opts entry point. See review\n    Ic28351258652d2ea38974e2f4d1aa6b1d3dd7192. However, we do note\n    in tools/config/README how to run the generator to query the\n    entry point.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 73, 'created': '2014-01-29 07:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6be76a444385d4b809b80a090d97f2b73f5e2b2', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a3 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 74, 'created': '2014-01-29 10:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90583a835eedf345590d0d077ee25909c1f83635', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 75, 'created': '2014-01-31 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b81e454bac2cad1514b641a3e13e19a263cd3876', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 76, 'created': '2014-02-01 07:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14ea13a8a6f59fa0cfc3c7ade5c6f90898a8b785', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 77, 'created': '2014-02-01 09:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aaf0a340489e28efd792008bcc38739b37976da5', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}, {'number': 78, 'created': '2014-02-01 09:53:50.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_multiple_create.py', 'nova/tests/test_manager.py', 'nova/scheduler/utils.py', 'nova/openstack/common/rpc/common.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/openstack/common/notifier/no_op_notifier.py', 'nova/openstack/common/rpc/dispatcher.py', 'nova/openstack/common/rpc/impl_kombu.py', 'nova/network/rpcapi.py', 'nova/tests/api/openstack/compute/plugins/v3/test_cells.py', 'nova/openstack/common/notifier/rabbit_notifier.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/test_quota.py', 'nova/cells/rpcapi.py', 'nova/openstack/common/rpc/matchmaker_redis.py', 'nova/tests/scheduler/test_rpcapi.py', 'nova/tests/api/openstack/compute/contrib/test_scheduler_hints.py', 'nova/conductor/api.py', 'nova/tests/console/test_console.py', 'nova/tests/scheduler/test_scheduler_utils.py', 'nova/openstack/common/rpc/impl_zmq.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/tests/compute/test_compute_api.py', 'nova/compute/cells_api.py', 'nova/tests/api/openstack/compute/contrib/test_certificates.py', 'nova/openstack/common/rpc/__init__.py', 'nova/config.py', 'nova/compute/resource_tracker.py', 'nova/objects/base.py', 'nova/openstack/common/rpc/impl_fake.py', 'nova/tests/api/openstack/compute/plugins/v3/test_certificates.py', 'nova/rpcclient.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/cells/driver.py', 'nova/openstack/common/rpc/matchmaker.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/tests/compute/test_compute.py', 'nova/notifications.py', 'nova/virt/libvirt/driver.py', 'requirements.txt', 'nova/openstack/common/notifier/__init__.py', 'nova/console/rpcapi.py', 'nova/tests/compute/test_rpcapi.py', 'nova/utils.py', 'nova/openstack/common/notifier/log_notifier.py', 'nova/openstack/common/notifier/rpc_notifier2.py', 'nova/compute/api.py', 'nova/openstack/common/rpc/serializer.py', 'nova/tests/compute/test_host_api.py', 'nova/scheduler/rpcapi.py', 'nova/cert/manager.py', 'nova/openstack/common/notifier/api.py', 'nova/tests/cells/test_cells_rpc_driver.py', 'nova/tests/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/network/floating_ips.py', 'nova/tests/api/openstack/compute/plugins/v3/test_user_data.py', 'nova/conductor/rpcapi.py', 'nova/tests/api/openstack/compute/contrib/test_cells.py', 'nova/openstack/common/rpc/zmq_receiver.py', 'nova/manager.py', 'nova/cert/rpcapi.py', 'nova/tests/test_service.py', 'nova/scheduler/manager.py', 'nova/tests/test_test.py', 'nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/network/manager.py', 'nova/tests/conductor/test_conductor.py', 'nova/openstack/common/notifier/rpc_notifier.py', 'nova/scheduler/driver.py', 'nova/tests/fake_notifier.py', 'nova/tests/network/test_rpcapi.py', 'nova/baserpc.py', 'nova/cells/state.py', 'nova/console/manager.py', 'nova/tests/cert/test_rpcapi.py', 'nova/tests/compute/test_compute_utils.py', 'nova/notifier.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/consoleauth/rpcapi.py', 'nova/tests/api/openstack/compute/contrib/test_disk_config.py', 'nova/openstack/common/rpc/impl_qpid.py', 'nova/cells/rpc_driver.py', 'nova/cmd/manage.py', 'nova/openstack/common/rpc/proxy.py', 'etc/nova/nova.conf.sample', 'nova/tests/scheduler/test_scheduler.py', 'nova/tests/network/test_manager.py', 'setup.cfg', 'nova/cmd/dhcpbridge.py', 'nova/tests/api/openstack/compute/plugins/v3/test_config_drive.py', 'nova/tests/objects/test_objects.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'tools/config/oslo.config.generator.rc', 'nova/tests/cast_as_call.py', 'nova/openstack/common/notifier/test_notifier.py', 'nova/tests/api/openstack/compute/plugins/v3/test_scheduler_hints.py', 'nova/cells/manager.py', 'nova/tests/console/test_rpcapi.py', 'nova/openstack/common/rpc/amqp.py', 'nova/test.py', 'nova/compute/utils.py', 'nova/openstack/common/rpc/service.py', 'nova/consoleauth/manager.py', 'nova/rpc.py', 'nova/api/openstack/compute/servers.py', 'nova/service.py', 'nova/tests/consoleauth/test_rpcapi.py', 'nova/openstack/common/rpc/matchmaker_ring.py', 'nova/console/api.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/cmd/rpc_zmq_receiver.py', 'nova/tests/conf_fixture.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1a91aacb85922f8d74733979691f0bf26249debc', 'message': ""Port to oslo.messaging\n\nThe oslo.messaging library takes the existing RPC code from oslo and\nwraps it in a sane API with well defined semantics around which we can\nmake a commitment to retain compatibility in future.\n\nThe patch is large, but the changes can be summarized as:\n\n  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be\n    pushed before the icehouse release candidates.\n\n  * The new rpc module has init() and cleanup() methods which manage the\n    global oslo.messaging transport state. The TRANSPORT and NOTIFIER\n    globals are conceptually similar to the current RPCIMPL global,\n    except we're free to create and use alternate Transport objects\n    in e.g. the cells code.\n\n  * The rpc.get_{client,server,notifier}() methods are just helpers\n    which wrap the global messaging state, specifiy serializers and\n    specify the use of the eventlet executor.\n\n  * In oslo.messaging, a request context is expected to be a dict so\n    we add a RequestContextSerializer which can serialize to and from\n    dicts using RequestContext.{to,from}_dict()\n\n  * The allowed_rpc_exception_modules configuration option is replaced\n    by an allowed_remote_exmods get_transport() parameter. This is not\n    something that users ever need to configure, but it is something\n    each project using oslo.messaging needs to be able to customize.\n\n  * The nova.rpcclient module is removed; it was only a helper class\n    to allow us split a lot of the more tedious changes out of this\n    patch.\n\n  * Finalizing the port from RpcProxy to RPCClient is straightforward.\n    We put the default topic, version and namespace into a Target and\n    contstruct the client using that.\n\n  * Porting endpoint classes (like ComputeManager) just involves setting\n    a target attribute on the class.\n\n  * The @client_exceptions() decorator has been renamed to\n    @expected_exceptions since it's used on the server side to designate\n    exceptions we expect the decorated method to raise.\n\n  * We maintain a global NOTIFIER object and create specializations of\n    it with specific publisher IDs in order to avoid notification driver\n    loading overhead.\n\n  * rpc.py contains transport aliases for backwards compatibility\n    purposes. setup.cfg also contains notification driver aliases for\n    backwards compat.\n\n  * The messaging options are moved about in nova.conf.sample because\n    the options are advertised via a oslo.config.opts entry point and\n    picked up by the generator.\n\n  * We use messaging.ConfFixture in tests to override oslo.messaging\n    config options, rather than making assumptions about the options\n    registered by the library.\n\nThe porting of cells code is particularly tricky:\n\n  * messaging.TransportURL parse() and str() replaces the\n    [un]parse_transport_url() methods. Note the complication that an\n    oslo.messaging transport URL can actually have multiple hosts in\n    order to support message broker clustering. Also the complication\n    of transport aliases in rpc.get_transport_url().\n\n  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying\n    the on-the-wire message format over this call, but you can't supply\n    such messages to oslo.messaging's cast()/call() methods. Rather than\n    change the inter-cell RPC API to suit oslo.messaging, we instead\n    just unpack the topic, server, method and args from the message on\n    the remote side.\n\n    cells_api.RPCClientCellsProxy is a mock RPCClient implementation\n    which allows us to wrap up a RPC in the message format currently\n    used for inter-cell RPCs.\n\n  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for\n    exception serialization, but this format is an implementation detail\n    of oslo.messaging's transport drivers. So, we need to duplicate the\n    exception serialization code in cells.messaging. We may find a way\n    to reconcile this in future - for example a ExceptionSerializer\n    class might work, but with the current format it might be difficult\n    for the deserializer to generically detect a serialized exception.\n\n  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()\n    need close review, but they're pretty straightforward ports of code\n    to listen on some specialized topics and connect to a remote cell\n    using its transport URL.\n\nblueprint: oslo-messaging\nChange-Id: Ib613e6300f2c215be90f924afbd223a3da053a69\n""}]",85,39929,1a91aacb85922f8d74733979691f0bf26249debc,354,21,78,1247,,,0,"Port to oslo.messaging

The oslo.messaging library takes the existing RPC code from oslo and
wraps it in a sane API with well defined semantics around which we can
make a commitment to retain compatibility in future.

The patch is large, but the changes can be summarized as:

  * oslo.messaging>=1.3.0a4 is required; a proper 1.3.0 release will be
    pushed before the icehouse release candidates.

  * The new rpc module has init() and cleanup() methods which manage the
    global oslo.messaging transport state. The TRANSPORT and NOTIFIER
    globals are conceptually similar to the current RPCIMPL global,
    except we're free to create and use alternate Transport objects
    in e.g. the cells code.

  * The rpc.get_{client,server,notifier}() methods are just helpers
    which wrap the global messaging state, specifiy serializers and
    specify the use of the eventlet executor.

  * In oslo.messaging, a request context is expected to be a dict so
    we add a RequestContextSerializer which can serialize to and from
    dicts using RequestContext.{to,from}_dict()

  * The allowed_rpc_exception_modules configuration option is replaced
    by an allowed_remote_exmods get_transport() parameter. This is not
    something that users ever need to configure, but it is something
    each project using oslo.messaging needs to be able to customize.

  * The nova.rpcclient module is removed; it was only a helper class
    to allow us split a lot of the more tedious changes out of this
    patch.

  * Finalizing the port from RpcProxy to RPCClient is straightforward.
    We put the default topic, version and namespace into a Target and
    contstruct the client using that.

  * Porting endpoint classes (like ComputeManager) just involves setting
    a target attribute on the class.

  * The @client_exceptions() decorator has been renamed to
    @expected_exceptions since it's used on the server side to designate
    exceptions we expect the decorated method to raise.

  * We maintain a global NOTIFIER object and create specializations of
    it with specific publisher IDs in order to avoid notification driver
    loading overhead.

  * rpc.py contains transport aliases for backwards compatibility
    purposes. setup.cfg also contains notification driver aliases for
    backwards compat.

  * The messaging options are moved about in nova.conf.sample because
    the options are advertised via a oslo.config.opts entry point and
    picked up by the generator.

  * We use messaging.ConfFixture in tests to override oslo.messaging
    config options, rather than making assumptions about the options
    registered by the library.

The porting of cells code is particularly tricky:

  * messaging.TransportURL parse() and str() replaces the
    [un]parse_transport_url() methods. Note the complication that an
    oslo.messaging transport URL can actually have multiple hosts in
    order to support message broker clustering. Also the complication
    of transport aliases in rpc.get_transport_url().

  * proxy_rpc_to_manager() is fairly nasty. Right now, we're proxying
    the on-the-wire message format over this call, but you can't supply
    such messages to oslo.messaging's cast()/call() methods. Rather than
    change the inter-cell RPC API to suit oslo.messaging, we instead
    just unpack the topic, server, method and args from the message on
    the remote side.

    cells_api.RPCClientCellsProxy is a mock RPCClient implementation
    which allows us to wrap up a RPC in the message format currently
    used for inter-cell RPCs.

  * Similarly, proxy_rpc_to_manager uses the on-the-wire format for
    exception serialization, but this format is an implementation detail
    of oslo.messaging's transport drivers. So, we need to duplicate the
    exception serialization code in cells.messaging. We may find a way
    to reconcile this in future - for example a ExceptionSerializer
    class might work, but with the current format it might be difficult
    for the deserializer to generically detect a serialized exception.

  * CellsRPCDriver.start_servers() and InterCellRPCAPI._get_client()
    need close review, but they're pretty straightforward ports of code
    to listen on some specialized topics and connect to a remote cell
    using its transport URL.

blueprint: oslo-messaging
Change-Id: Ib613e6300f2c215be90f924afbd223a3da053a69
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/39929/77 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/scheduler/rpcapi.py', 'nova/consoleauth/rpcapi.py', 'nova/rpc.py', 'nova/baserpc.py', 'nova/openstack/common/rpc/proxy.py', 'nova/conductor/rpcapi.py', 'nova/network/rpcapi.py', 'nova/console/rpcapi.py', 'nova/cert/rpcapi.py', 'nova/compute/rpcapi.py', 'nova/config.py']",12,84b9aded53f98fb942052977cd02ca05ddddc259,bp/oslo.messaging,from nova import rpc rpc.init(cfg.CONF),from nova.openstack.common import rpc,787,973
openstack%2Fceilometer~stable%2Fhavana~I5fccf51b820330595a627fd0001beec2d5f7c6e3,openstack/ceilometer,stable/havana,I5fccf51b820330595a627fd0001beec2d5f7c6e3,Fix the Alarm documentation of Web API V2,MERGED,2014-01-21 14:14:21.000000000,2014-02-02 10:23:13.000000000,2014-02-02 10:23:12.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 6676}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-01-21 14:14:21.000000000', 'files': ['ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92e498561b3cbebd076e758d35ea51193168194c', 'message': 'Fix the Alarm documentation of Web API V2\n\nCorrect the Alarm example on the API documentation to contain a\nvalid Alarm sample and complete the Note section with information\nabout the connection between the type and rules fields of the\nAlarm.\n\nFixes bug #1245362\n\nChange-Id: I5fccf51b820330595a627fd0001beec2d5f7c6e3\n'}]",0,68120,92e498561b3cbebd076e758d35ea51193168194c,15,5,1,9562,,,0,"Fix the Alarm documentation of Web API V2

Correct the Alarm example on the API documentation to contain a
valid Alarm sample and complete the Note section with information
about the connection between the type and rules fields of the
Alarm.

Fixes bug #1245362

Change-Id: I5fccf51b820330595a627fd0001beec2d5f7c6e3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/20/68120/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/controllers/v2.py'],1,92e498561b3cbebd076e758d35ea51193168194c,bug/1245362," .. note:: combination_rule and threshold_rule are mutually exclusive. The *type* of the alarm should be set to *threshold* or *combination* and the appropriate rule should be filled. type='combination', combination_rule=AlarmCombinationRule.sample(),"," type='threshold', combination_rule=None,",7,2
openstack%2Fopenstack-manuals~master~I8a6fa088efab2fe501c2d318dbee94ecf047e888,openstack/openstack-manuals,master,I8a6fa088efab2fe501c2d318dbee94ecf047e888,Fix bullet list format in README.rst,MERGED,2014-02-02 09:45:44.000000000,2014-02-02 10:14:00.000000000,2014-02-02 10:12:38.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-02 09:45:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/272f148975e8fd70b28e04776e64c0d2da8a1a30', 'message': 'Fix bullet list format in README.rst\n\nChange-Id: I8a6fa088efab2fe501c2d318dbee94ecf047e888\n'}]",0,70573,272f148975e8fd70b28e04776e64c0d2da8a1a30,6,2,1,7923,,,0,"Fix bullet list format in README.rst

Change-Id: I8a6fa088efab2fe501c2d318dbee94ecf047e888
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/73/70573/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,272f148975e8fd70b28e04776e64c0d2da8a1a30,readme-tox-list, * ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,* ``tox -e checkniceness`` - to run the niceness tests * ``tox -e checksyntax`` - to run syntax checks * ``tox -e checkdeletions`` - to check that no deleted files are referenced * ``tox -e checkbuild`` - to actually build the manual,5,4
openstack%2Fpython-cinderclient~master~Icf9684ab0fabf0168662c3ff4047db54a2670d11,openstack/python-cinderclient,master,Icf9684ab0fabf0168662c3ff4047db54a2670d11,Update release notes for push to pypi,MERGED,2014-01-31 15:34:00.000000000,2014-02-02 08:41:19.000000000,2014-02-02 08:41:19.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}]","[{'number': 1, 'created': '2014-01-31 15:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e69f31c6ded03bca5ef8b9badce88e8b7fab265b', 'message': 'Update release notes for push to pypi\n\nNeed to get a 1.08 out, so just modifying the release notes\nfor the push version.\n\nChange-Id: Icf9684ab0fabf0168662c3ff4047db54a2670d11\n'}, {'number': 2, 'created': '2014-02-02 07:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/8b42dc9213449047230d19af6b9e23ea81fbd0b1', 'message': 'Update release notes for push to pypi\n\nNeed to get a 1.08 out, so just modifying the release notes\nfor the push version.\n\nChange-Id: Icf9684ab0fabf0168662c3ff4047db54a2670d11\n'}, {'number': 3, 'created': '2014-02-02 07:25:37.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/305f7609397d1b10d161794a309ecb5dd49d545d', 'message': 'Update release notes for push to pypi\n\nNeed to get a 1.08 out, so just modifying the release notes\nfor the push version.\n\nChange-Id: Icf9684ab0fabf0168662c3ff4047db54a2670d11\n'}]",0,70364,305f7609397d1b10d161794a309ecb5dd49d545d,19,3,3,2243,,,0,"Update release notes for push to pypi

Need to get a 1.08 out, so just modifying the release notes
for the push version.

Change-Id: Icf9684ab0fabf0168662c3ff4047db54a2670d11
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/64/70364/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,e69f31c6ded03bca5ef8b9badce88e8b7fab265b,bump_version_for_pypi_release, 1.0.8 -----,MASTER ------,3,2
openstack%2Fnova~master~I5dd07f876471b5faf8fb1016e25a861124b7cb6f,openstack/nova,master,I5dd07f876471b5faf8fb1016e25a861124b7cb6f,Fixing availability-zone not take effect error,MERGED,2013-12-04 08:45:33.000000000,2014-02-02 08:08:44.000000000,2014-02-02 08:08:40.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4690}, {'_account_id': 7138}, {'_account_id': 7494}, {'_account_id': 8412}, {'_account_id': 8651}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-04 08:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73d2bab26bb6074ed610f47f05c4f4117efb87d0', 'message': 'Fixing availability-zone not take effect error\n\nwhen add/remove a host to one aggregate or update aggregate\nmetadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""\nproperty of sone instances in the host can not show correctly.\n\nThe cause is that when getting availability_zone of one instance\n, it will try to get the value from cache first, but unfortunately\nthe cache does not update or reset in time, and it will keep one\nhour if we do not change it.\n\nThis patch will add update or reset after adding/removing a host\nto one aggregate or updating aggregate metadata incluing\navailability_zone.\n\nChange-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f\nCloses-bug: #1240374\n'}, {'number': 2, 'created': '2013-12-04 09:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e63d4e06c1dd78450c3ac2c3a32bc8d7eea76e79', 'message': 'Fixing availability-zone not take effect error\n\nwhen add/remove a host to one aggregate or update aggregate\nmetadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""\nproperty of sone instances in the host can not show correctly.\n\nThe cause is that when getting availability_zone of one instance\n, it will try to get the value from cache first, but unfortunately\nthe cache does not update or reset in time, and it will keep one\nhour if we do not change it.\n\nThis patch will add update or reset after adding/removing a host\nto one aggregate or updating aggregate metadata incluing\navailability_zone.\n\nChange-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f\nCloses-bug: #1240374\n'}, {'number': 3, 'created': '2013-12-09 14:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16f1293815fd06e50c4fd51ec24cd7d464f860b0', 'message': 'Fixing availability-zone not take effect error\n\nwhen add/remove a host to one aggregate or update aggregate\nmetadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""\nproperty of some instances in the host can not show correctly.\n\nThe cause is that when getting availability_zone of one instance\n, it will try to get the value from cache first, but unfortunately\nthe cache does not update or reset in time, and it will keep one\nhour if we do not change it.\n\nThis patch will add update or reset after adding/removing a host\nto one aggregate or updating aggregate metadata incluing\navailability_zone.\n\nChange-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f\nCloses-bug: #1240374\n'}, {'number': 4, 'created': '2013-12-19 05:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bfff41d8d9f0210e38542d0084c057b411032cd', 'message': 'Fixing availability-zone not take effect error\n\nwhen add/remove a host to one aggregate or update aggregate\nmetadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""\nproperty of some instances in the host can not show correctly.\n\nThe cause is that when getting availability_zone of one instance,\nit will try to get the value from cache first, but unfortunately\nthe cache does not update or reset in time, and it will keep one\nhour if we do not change it.\n\nThis patch will add update or reset after adding/removing a host\nto one aggregate or updating aggregate metadata including\navailability_zone.\n\nChange-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f\nCloses-bug: #1240374\n'}, {'number': 5, 'created': '2013-12-26 09:51:54.000000000', 'files': ['nova/tests/test_availability_zones.py', 'nova/availability_zones.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/db0831ec96a6806035c51d94ade1e51eafb42162', 'message': 'Fixing availability-zone not take effect error\n\nwhen add/remove a host to one aggregate or update aggregate\nmetadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""\nproperty of some instances in the host can not show correctly.\n\nThe cause is that when getting availability_zone of one instance,\nit will try to get the value from cache first, but unfortunately\nthe cache does not update or reset in time, and it will keep one\nhour if we do not change it.\n\nThis patch will add update or reset after adding/removing a host\nto one aggregate or updating aggregate metadata including\navailability_zone.\n\nChange-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f\nCloses-bug: #1240374\n'}]",17,59922,db0831ec96a6806035c51d94ade1e51eafb42162,32,10,5,8651,,,0,"Fixing availability-zone not take effect error

when add/remove a host to one aggregate or update aggregate
metadata incluing availability_zone, ""OS-EXT-AZ:availability_zone""
property of some instances in the host can not show correctly.

The cause is that when getting availability_zone of one instance,
it will try to get the value from cache first, but unfortunately
the cache does not update or reset in time, and it will keep one
hour if we do not change it.

This patch will add update or reset after adding/removing a host
to one aggregate or updating aggregate metadata including
availability_zone.

Change-Id: I5dd07f876471b5faf8fb1016e25a861124b7cb6f
Closes-bug: #1240374
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/59922/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_availability_zones.py', 'nova/availability_zones.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",4,73d2bab26bb6074ed610f47f05c4f4117efb87d0,bug/1240374," 'foo_key2': 'foo_value2', 'availability_zone': 'fake_zone'} availability_zones._get_cache().add('fake_key', 'fake_value') self.assertIsNone(availability_zones._get_cache().get('fake_key')) self.mox.StubOutWithMock(availability_zones, 'update_host_availability_zone_cache') availability_zones.update_host_availability_zone_cache(self.context, fake_host) self.mox.ReplayAll() self.mox.StubOutWithMock(availability_zones, 'update_host_availability_zone_cache') availability_zones.update_host_availability_zone_cache(self.context, host_to_remove) self.mox.ReplayAll() "," 'foo_key2': 'foo_value2', }",53,13
openstack%2Fnova~master~I5097d271df0d6ad419f530787d890288163d06c5,openstack/nova,master,I5097d271df0d6ad419f530787d890288163d06c5,baremetal: set capabilites explicitly,MERGED,2013-12-15 11:58:08.000000000,2014-02-02 07:24:13.000000000,2014-02-02 07:24:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 6722}, {'_account_id': 7179}, {'_account_id': 7770}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-15 11:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5145fc057cbff42c300441d2995445c497008b73', 'message': ""baremetal: set capabilites explicitly\n\nComputeDriver, base class of compute drivers, has dict capabilities\nto show if the compute driver implements some functions. Compute\nmanger will check this with capabilities['has_imagecache'] or\ncapabilities['supports_recreate'] directly. If use compute driver\nbaremetal, there is code path leading KeyError. Let set capabilites\nexplicitly to avoid this.\n\nChange-Id: I5097d271df0d6ad419f530787d890288163d06c5\n""}, {'number': 2, 'created': '2013-12-17 08:40:02.000000000', 'files': ['nova/tests/virt/baremetal/test_driver.py', 'nova/virt/baremetal/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2cefa191a439c9a833c96650b2bd54c73e001c0f', 'message': ""baremetal: set capabilites explicitly\n\nComputeDriver, base class of compute drivers, has dict capabilities\nto show if the compute driver implements some functions. Compute\nmanger will check this with capabilities['has_imagecache'] or\ncapabilities['supports_recreate'] directly. If use compute driver\nbaremetal, there is code path leading KeyError. Let set capabilites\nexplicitly to avoid this.\n\nPartial-Bug: #1261636\n\nChange-Id: I5097d271df0d6ad419f530787d890288163d06c5\n""}]",4,62230,2cefa191a439c9a833c96650b2bd54c73e001c0f,27,8,2,6722,,,0,"baremetal: set capabilites explicitly

ComputeDriver, base class of compute drivers, has dict capabilities
to show if the compute driver implements some functions. Compute
manger will check this with capabilities['has_imagecache'] or
capabilities['supports_recreate'] directly. If use compute driver
baremetal, there is code path leading KeyError. Let set capabilites
explicitly to avoid this.

Partial-Bug: #1261636

Change-Id: I5097d271df0d6ad419f530787d890288163d06c5
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/62230/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/baremetal/test_driver.py', 'nova/virt/baremetal/driver.py']",2,5145fc057cbff42c300441d2995445c497008b73,baremetal," ""supports_recreate"": False,",,5,0
openstack%2Fnova~master~I9139a172d9c84f13030f896fb5414cacf5877ee1,openstack/nova,master,I9139a172d9c84f13030f896fb5414cacf5877ee1,Remove unused variable,MERGED,2014-01-19 07:39:35.000000000,2014-02-02 07:20:49.000000000,2014-02-02 07:20:45.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4573}, {'_account_id': 6062}, {'_account_id': 6348}, {'_account_id': 6676}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}, {'_account_id': 9645}]","[{'number': 1, 'created': '2014-01-19 07:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b2ffe20affe3fdd79f0e340b932049b595e4774', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}, {'number': 3, 'created': '2014-01-19 07:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/599b3db8f6ca305c645f565291e0d649e8fa1f99', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}, {'number': 2, 'created': '2014-01-19 07:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e3c4d161ca751793d6a17aa686da548854e622b', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}, {'number': 5, 'created': '2014-01-19 07:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f77ec37bbdb44c51b500deec522cd445a1d2cf2f', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}, {'number': 4, 'created': '2014-01-19 07:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d470a465a462ea08ca62712eae3d7e8943ce5ef2', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}, {'number': 6, 'created': '2014-01-19 07:39:35.000000000', 'files': ['nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/458f357d39b74a587335af1a0d7011653c54e2a8', 'message': 'Remove unused variable\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1\n'}]",0,67694,458f357d39b74a587335af1a0d7011653c54e2a8,89,13,6,1653,,,0,"Remove unused variable

Related to blueprint nova-network-objects

Change-Id: I9139a172d9c84f13030f896fb5414cacf5877ee1
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/67694/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,2b2ffe20affe3fdd79f0e340b932049b595e4774,bp/nova-network-objects,, net = {} net['vpn_public_address'] = address,0,2
openstack%2Fcinder~stable%2Fhavana~If7bc8259b031d0406346caafb8f688e65a38dba6,openstack/cinder,stable/havana,If7bc8259b031d0406346caafb8f688e65a38dba6,GlusterFS: Use correct base argument when deleting attached snaps,MERGED,2014-01-04 14:12:55.000000000,2014-02-02 06:47:04.000000000,2014-02-02 06:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6159}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-01-04 14:12:55.000000000', 'files': ['cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5ef9c9b92812b5a66218fecd5ace8515b149ea1a', 'message': ""GlusterFS: Use correct base argument when deleting attached snaps\n\nWhen deleting the most recent snapshot, the 'file_to_merge' field\nwhich translates into the base= field for libvirt's blockRebase\ncall in Nova must be set depending on whether other snapshots exist.\n\nIf there are no other snapshots, base = None, which results in\nlibvirt clearing the qcow2 backing file pointer for the active\ndisk image.\n\nIf there are other snapshots, pass the parent of the file being\ndeleted as the new base file.  The snapshot info pointer for the\nprior base file must also be updated in this case.\n\nCloses-Bug: #1262880\n\n(cherry picked from commit 186221779a92002ff9fa13c254710c0abb3803be)\nConflicts:\n\tcinder/tests/test_glusterfs.py\n\nChange-Id: If7bc8259b031d0406346caafb8f688e65a38dba6\n""}]",0,64950,5ef9c9b92812b5a66218fecd5ace8515b149ea1a,24,7,1,4523,,,0,"GlusterFS: Use correct base argument when deleting attached snaps

When deleting the most recent snapshot, the 'file_to_merge' field
which translates into the base= field for libvirt's blockRebase
call in Nova must be set depending on whether other snapshots exist.

If there are no other snapshots, base = None, which results in
libvirt clearing the qcow2 backing file pointer for the active
disk image.

If there are other snapshots, pass the parent of the file being
deleted as the new base file.  The snapshot info pointer for the
prior base file must also be updated in this case.

Closes-Bug: #1262880

(cherry picked from commit 186221779a92002ff9fa13c254710c0abb3803be)
Conflicts:
	cinder/tests/test_glusterfs.py

Change-Id: If7bc8259b031d0406346caafb8f688e65a38dba6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/64950/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_glusterfs.py']",2,5ef9c9b92812b5a66218fecd5ace8515b149ea1a,gluster_stable," """"""Delete the newest snapshot, with only one snap present."""""" vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = image_utils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) 'file_to_merge': None, """"""Delete the middle of 3 snapshots."""""" vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = image_utils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) "," """"""Delete the newest snapshot."""""" 'file_to_merge': volume_file, """"""Delete the middle snapshot.""""""",38,5
openstack%2Fcinder~master~Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb,openstack/cinder,master,Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb,Nexenta iSCSI driver: rm nexenta_sparse config option,ABANDONED,2013-12-20 01:00:24.000000000,2014-02-02 06:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2401}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 7236}]","[{'number': 1, 'created': '2013-12-20 01:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ce1cfddc3b34340c7c68fa148ff89c184725f11', 'message': 'Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option\n\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n'}, {'number': 2, 'created': '2013-12-20 02:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f553e337cd3e8710ece77debf5f2c44eac0374c6', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 3, 'created': '2013-12-30 19:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/088453f47dda55c525c512459319a98012001030', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 4, 'created': '2014-01-22 18:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0bb8306df0737d6090fbd8e2dc4081674ace7f4', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 5, 'created': '2014-01-23 18:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/390d1f4c321af398e1e50781f7717ffbe4e48edb', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 6, 'created': '2014-01-23 21:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bf33145ed96e310c33f72e802b755f9d4d991a49', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 7, 'created': '2014-01-23 23:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/292e166c07a6886d3c3706d24a2c92f5383e7d09', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}, {'number': 8, 'created': '2014-01-24 18:31:29.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/nexenta/options.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/tests/test_nexenta.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d72d3791fd18e0614a63871181280e0afa809807', 'message': ""Nexenta iSCSI driver: rm nexenta_sparse config option\n\nRemove nexenta_sparse config option, because Nexenta NFS driver\ndefine the same option but it's called nexenta_sparsed_volumes,\nso now this option is used in both drivers.\n\nAdd DocImpact\nChange-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb\n""}]",8,63258,d72d3791fd18e0614a63871181280e0afa809807,30,7,8,2401,,,0,"Nexenta iSCSI driver: rm nexenta_sparse config option

Remove nexenta_sparse config option, because Nexenta NFS driver
define the same option but it's called nexenta_sparsed_volumes,
so now this option is used in both drivers.

Add DocImpact
Change-Id: Ie6165ea5c6ed0331c52f2d767e2321491e4ea3cb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/63258/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/nexenta/options.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/tests/test_nexenta.py']",5,1ce1cfddc3b34340c7c68fa148ff89c184725f11,nexenta-isci-sparsed-volumes, self.configuration.nexenta_sparsed_volumes = True, self.configuration.nexenta_sparse = True,14,20
openstack%2Ftrove~master~I3100cd1a998d5968db2c57a3ba9a6d1fe7944568,openstack/trove,master,I3100cd1a998d5968db2c57a3ba9a6d1fe7944568,Updated from global requirements,ABANDONED,2014-01-21 20:30:05.000000000,2014-02-02 06:03:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}]","[{'number': 1, 'created': '2014-01-21 20:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ddec32227d3354732e064514247a159641ff3f3b', 'message': 'Updated from global requirements\n\nChange-Id: I3100cd1a998d5968db2c57a3ba9a6d1fe7944568\n'}, {'number': 2, 'created': '2014-01-24 22:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5188cde6a0700d4a54d70285c4598c7a3342aee2', 'message': 'Updated from global requirements\n\nChange-Id: I3100cd1a998d5968db2c57a3ba9a6d1fe7944568\n'}, {'number': 3, 'created': '2014-01-25 05:49:57.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/9e9d4199ee426cca8cecd4673da3d8744355be0a', 'message': 'Updated from global requirements\n\nChange-Id: I3100cd1a998d5968db2c57a3ba9a6d1fe7944568\n'}]",0,68253,9e9d4199ee426cca8cecd4673da3d8744355be0a,12,2,3,3,,,0,"Updated from global requirements

Change-Id: I3100cd1a998d5968db2c57a3ba9a6d1fe7944568
",git fetch https://review.opendev.org/openstack/trove refs/changes/53/68253/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,ddec32227d3354732e064514247a159641ff3f3b,openstack/requirements,,wsgi_interceptmockito,1,4
openstack%2Fglance~master~Ia3dc97b947c9d58d4982eac449da22296135f3bc,openstack/glance,master,Ia3dc97b947c9d58d4982eac449da22296135f3bc,Updated from global requirements,ABANDONED,2014-01-21 20:24:13.000000000,2014-02-02 06:03:11.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-21 20:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ea16fb6d41d0fa66e62134d91a3136a2f46ca1a2', 'message': 'Updated from global requirements\n\nChange-Id: Ia3dc97b947c9d58d4982eac449da22296135f3bc\n'}, {'number': 2, 'created': '2014-01-24 22:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a4992d0bd3d80edb8f2112db6013881b476cb4cd', 'message': 'Updated from global requirements\n\nChange-Id: Ia3dc97b947c9d58d4982eac449da22296135f3bc\n'}, {'number': 3, 'created': '2014-01-25 05:42:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/glance/commit/6600fd69a06b942e875bcf2ebddfb2ded3ce2337', 'message': 'Updated from global requirements\n\nChange-Id: Ia3dc97b947c9d58d4982eac449da22296135f3bc\n'}]",0,68239,6600fd69a06b942e875bcf2ebddfb2ded3ce2337,8,1,3,3,,,0,"Updated from global requirements

Change-Id: Ia3dc97b947c9d58d4982eac449da22296135f3bc
",git fetch https://review.opendev.org/openstack/glance refs/changes/39/68239/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ea16fb6d41d0fa66e62134d91a3136a2f46ca1a2,openstack/requirements,"SQLAlchemy>=0.7.8,<=0.8.99boto>=2.12.0,!=2.13.0 sqlalchemy-migrate>=0.8.2","SQLAlchemy>=0.7.8,<=0.7.99boto>=2.4.0,!=2.13.0 sqlalchemy-migrate>=0.7.2oslo.messaging>=1.2.0a11",3,4
openstack%2Foslo-incubator~master~I39f92ab66c943e3762f6996f197ea42664f4b109,openstack/oslo-incubator,master,I39f92ab66c943e3762f6996f197ea42664f4b109,Make sessionmaker cope with a slave engine,ABANDONED,2014-01-25 11:02:07.000000000,2014-02-02 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-01-25 11:02:07.000000000', 'files': ['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/468d87081a13d8b581f116d51fe39a1c6783941e', 'message': ""Make sessionmaker cope with a slave engine\n\noslo.db uses a notion of a 'slave' engine, which is an additional DB\nconnection. This connection can be used in order to decrease the load\non the master DB connection (all reads are passed to the slave DB\nconnection).\n\nAs we no longer store global engine instances in oslo.db, API must\nbe updated to make it possible to use a slave engine.\n\nRelated-Bug: #1263908\n\nChange-Id: I39f92ab66c943e3762f6996f197ea42664f4b109\n""}]",0,69123,468d87081a13d8b581f116d51fe39a1c6783941e,4,2,1,6849,,,0,"Make sessionmaker cope with a slave engine

oslo.db uses a notion of a 'slave' engine, which is an additional DB
connection. This connection can be used in order to decrease the load
on the master DB connection (all reads are passed to the slave DB
connection).

As we no longer store global engine instances in oslo.db, API must
be updated to make it possible to use a slave engine.

Related-Bug: #1263908

Change-Id: I39f92ab66c943e3762f6996f197ea42664f4b109
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/23/69123/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py']",2,468d87081a13d8b581f116d51fe39a1c6783941e,remove_global_engine," def __init__(self, *args, **kwargs): self.slave_engine = kwargs.pop('slave_engine', None) super(Session, self).__init__(*args, **kwargs) def get_bind(self, mapper=None, clause=None): is_sql_write = clause is not None and ( 'insert' in str(clause).lower() or 'update' in str(clause).lower()) if self._flushing or is_sql_write: # always return master db on writes return self.bind else: # return slave db on reads (if exists, otherwise return master) return self.slave_engine or self.bind def get_maker(engine, autocommit=True, expire_on_commit=False, slave_engine=None): query_cls=Query, slave_engine=slave_engine)"," def get_maker(engine, autocommit=True, expire_on_commit=False): query_cls=Query)",59,2
openstack%2Fpython-novaclient~master~I37e36efee3f430e145c69a6bb8730d36f108a356,openstack/python-novaclient,master,I37e36efee3f430e145c69a6bb8730d36f108a356,Fix missing info typo in boot,ABANDONED,2014-01-22 17:08:32.000000000,2014-02-02 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-01-22 17:08:32.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/bea344b65a96bd047e1e3b73e9e4c446a1f9883f', 'message': 'Fix missing info typo in boot\n\n96eea0f1566e10b9de98752aea4f0716c881c993 removed the definition of `info`\nwhich is used to poll for the server state.\n\nThe fix is to pass in `server._info` into the poll function.\n\nChange-Id: I37e36efee3f430e145c69a6bb8730d36f108a356\n'}]",0,68438,bea344b65a96bd047e1e3b73e9e4c446a1f9883f,6,4,1,475,,,0,"Fix missing info typo in boot

96eea0f1566e10b9de98752aea4f0716c881c993 removed the definition of `info`
which is used to poll for the server state.

The fix is to pass in `server._info` into the poll function.

Change-Id: I37e36efee3f430e145c69a6bb8730d36f108a356
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/38/68438/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,bea344b65a96bd047e1e3b73e9e4c446a1f9883f,," _poll_for_status(cs.servers.get, server._info['id'], 'building', ['active'])"," _poll_for_status(cs.servers.get, info['id'], 'building', ['active'])",2,1
openstack%2Fnova~master~I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1,openstack/nova,master,I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1,updates jsonschema min_version requirement,ABANDONED,2013-11-29 14:46:01.000000000,2014-02-02 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1528}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 6896}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-29 14:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2eaa1fe97aa41a2f9ed3b13a38a4b8ae3176882d', 'message': 'updates jsonschema min_version requirement\n\nFixes bug 1256344\n\nChange-Id: I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1\n'}, {'number': 2, 'created': '2014-01-17 18:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/873541296e16a7d5a80dd746b0a39098f41dfa96', 'message': 'updates jsonschema min_version requirement\n\nFixes bug 1256344\n\nChange-Id: I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1\n'}, {'number': 3, 'created': '2014-01-24 12:46:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/be4ff1b662e579e28868ca83f6b352d0c1b3528d', 'message': 'updates jsonschema min_version requirement\n\nFixes bug 1256344\n\n(Pulled from gate, the requirements change did not land, and\nthis never had clean check results.)\n\nChange-Id: I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1\n'}]",1,59189,be4ff1b662e579e28868ca83f6b352d0c1b3528d,27,7,3,6896,,,0,"updates jsonschema min_version requirement

Fixes bug 1256344

(Pulled from gate, the requirements change did not land, and
this never had clean check results.)

Change-Id: I5f21ddb3702754f88b9bbc9fd59d9fc747c22ac1
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/59189/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2eaa1fe97aa41a2f9ed3b13a38a4b8ae3176882d,bug/1256344,jsonschema>=2.0.0,"jsonschema>=1.3.0,!=1.4.0",1,1
openstack%2Fheat~master~Ia8b389bbad9f8c865fcc8f213b1e170b6e663ea6,openstack/heat,master,Ia8b389bbad9f8c865fcc8f213b1e170b6e663ea6,Make doctest being gated,ABANDONED,2013-11-29 11:21:26.000000000,2014-02-02 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 7135}, {'_account_id': 8641}]","[{'number': 1, 'created': '2013-11-29 11:21:26.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/640b5de961affdb47f0791d3e79e76072b089be9', 'message': 'Make doctest being gated\n\nChange-Id: Ia8b389bbad9f8c865fcc8f213b1e170b6e663ea6\n'}]",0,59159,640b5de961affdb47f0791d3e79e76072b089be9,27,3,1,7135,,,0,"Make doctest being gated

Change-Id: Ia8b389bbad9f8c865fcc8f213b1e170b6e663ea6
",git fetch https://review.opendev.org/openstack/heat refs/changes/59/59159/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,640b5de961affdb47f0791d3e79e76072b089be9,bug/1252543,"builders = html,man,doctest",,1,0
openstack%2Fswift~master~Ia4e96f84c929c404c0a2312f15b4f2704f5856a3,openstack/swift,master,Ia4e96f84c929c404c0a2312f15b4f2704f5856a3,Make decoded JSON strings always unicode,ABANDONED,2014-01-20 19:42:31.000000000,2014-02-02 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-01-20 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3a313a23a4fa9e052269af3877fd2d3d39c01e32', 'message': ""Make decoded JSON strings always unicode\n\nSwift purports to work with simplejson or with stdlib's json, but the\ntwo have slightly differing decode results for ASCII-only strings:\nsimplejson hands back str objects, while json hands back\nunicodes. However, if the first arg to simplejson.load()/loads() is a\nunicode, then simplejson behaves like stdlib json.\n\nThis commit creates swift.common.json to provide the same interface as\nstdlib json even when simplejson is being used under the hood; thus,\nwe get consistent deserialization whether we're using simplejson,\nsimplejson (sans C extensions), or stdlib json.\n\nChange-Id: Ia4e96f84c929c404c0a2312f15b4f2704f5856a3\n""}, {'number': 2, 'created': '2014-01-20 20:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3018d3aef01cb4a546c48cf7bd41681cb6a1db87', 'message': ""Make decoded JSON strings always unicode\n\nSwift purports to work with simplejson or with stdlib's json, but the\ntwo have slightly differing decode results for ASCII-only strings:\nsimplejson hands back str objects, while json hands back\nunicodes. However, if the first arg to simplejson.load()/loads() is a\nunicode, then simplejson behaves like stdlib json.\n\nThis commit creates swift.common.json to provide the same interface as\nstdlib json even when simplejson is being used under the hood; thus,\nwe get consistent deserialization whether we're using simplejson,\nsimplejson (sans C extensions), or stdlib json.\n\nChange-Id: Ia4e96f84c929c404c0a2312f15b4f2704f5856a3\n""}, {'number': 3, 'created': '2014-01-23 20:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/74e5f439b98d28ca760f04717d22481f59eed903', 'message': ""Make decoded JSON strings always unicode\n\nREVIEWERS: don't bother yet. There's some devstack-only thing that's\ngetting goofed up by this, and I'm still trying to hunt it down.\n\nSwift purports to work with simplejson or with stdlib's json, but the\ntwo have slightly differing decode results for ASCII-only strings:\nsimplejson hands back str objects, while json hands back\nunicodes. However, if the first arg to simplejson.load()/loads() is a\nunicode, then simplejson behaves like stdlib json.\n\nThis commit creates swift.common.json to provide the same interface as\nstdlib json even when simplejson is being used under the hood; thus,\nwe get consistent deserialization whether we're using simplejson,\nsimplejson (sans C extensions), or stdlib json.\n\nChange-Id: Ia4e96f84c929c404c0a2312f15b4f2704f5856a3\n""}, {'number': 4, 'created': '2014-01-25 21:19:28.000000000', 'files': ['swift/common/middleware/staticweb.py', 'swift/common/memcached.py', 'test/unit/common/middleware/test_recon.py', 'swift/account/utils.py', 'test/unit/proxy/controllers/test_base.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/proxy/controllers/obj.py', 'swift/common/db.py', 'swift/container/server.py', 'swift/common/middleware/bulk.py', 'swift/common/middleware/recon.py', 'test/unit/proxy/controllers/test_info.py', 'swift/common/middleware/slo.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'swift/common/direct_client.py', 'test/unit/common/middleware/test_staticweb.py', 'swift/common/bufferedhttp.py', '.functests', 'swift/proxy/controllers/info.py', 'test/unit/account/test_server.py', 'test/unit/common/test_db_replicator.py', 'test/unit/proxy/test_server.py', 'swift/obj/auditor.py', 'test/unit/common/test_db.py', 'test/unit/common/middleware/test_list_endpoints.py', 'swift/common/utils.py', 'swift/common/middleware/list_endpoints.py', 'swift/common/db_replicator.py', 'swift/common/json.py', 'swift/common/ring/ring.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e94dce0eeb6b0599748ff8759db4884d5539a363', 'message': ""Make decoded JSON strings always unicode\n\nREVIEWERS: don't bother yet. There's some devstack-only thing that's\ngetting goofed up by this, and I'm still trying to hunt it down.\n\nSwift purports to work with simplejson or with stdlib's json, but the\ntwo have slightly differing decode results for ASCII-only strings:\nsimplejson hands back str objects, while json hands back\nunicodes. However, if the first arg to simplejson.load()/loads() is a\nunicode, then simplejson behaves like stdlib json.\n\nThis commit creates swift.common.json to provide the same interface as\nstdlib json even when simplejson is being used under the hood; thus,\nwe get consistent deserialization whether we're using simplejson,\nsimplejson (sans C extensions), or stdlib json.\n\nChange-Id: Ia4e96f84c929c404c0a2312f15b4f2704f5856a3\n""}]",1,67920,e94dce0eeb6b0599748ff8759db4884d5539a363,29,4,4,2622,,,0,"Make decoded JSON strings always unicode

REVIEWERS: don't bother yet. There's some devstack-only thing that's
getting goofed up by this, and I'm still trying to hunt it down.

Swift purports to work with simplejson or with stdlib's json, but the
two have slightly differing decode results for ASCII-only strings:
simplejson hands back str objects, while json hands back
unicodes. However, if the first arg to simplejson.load()/loads() is a
unicode, then simplejson behaves like stdlib json.

This commit creates swift.common.json to provide the same interface as
stdlib json even when simplejson is being used under the hood; thus,
we get consistent deserialization whether we're using simplejson,
simplejson (sans C extensions), or stdlib json.

Change-Id: Ia4e96f84c929c404c0a2312f15b4f2704f5856a3
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/67920/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/staticweb.py', 'swift/common/memcached.py', 'test/unit/common/middleware/test_recon.py', 'swift/account/utils.py', 'test/unit/proxy/controllers/test_base.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/proxy/controllers/obj.py', 'swift/common/db.py', 'swift/container/server.py', 'swift/common/middleware/bulk.py', 'swift/common/middleware/recon.py', 'test/unit/proxy/controllers/test_info.py', 'swift/common/middleware/slo.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'swift/common/direct_client.py', 'test/unit/common/middleware/test_staticweb.py', 'swift/proxy/controllers/info.py', 'test/unit/account/test_server.py', 'test/unit/common/test_db_replicator.py', 'test/unit/proxy/test_server.py', 'swift/obj/auditor.py', 'test/unit/common/test_db.py', 'test/unit/common/middleware/test_list_endpoints.py', 'swift/common/utils.py', 'swift/common/middleware/list_endpoints.py', 'swift/common/db_replicator.py', 'swift/common/json.py', 'swift/common/ring/ring.py']",30,3a313a23a4fa9e052269af3877fd2d3d39c01e32,json-sanity,"from swift.common import json from swift.common.utils import hash_path, validate_configuration","from swift.common.utils import hash_path, validate_configuration, json",152,93
openstack%2Fcinder~stable%2Fhavana~I8686a1be09dbb7984072538bff6c026bb84eeb52,openstack/cinder,stable/havana,I8686a1be09dbb7984072538bff6c026bb84eeb52,GlusterFS: Complete snapshot_delete when info doesn't exist,MERGED,2014-01-04 14:12:54.000000000,2014-02-02 05:58:46.000000000,2014-02-02 05:58:45.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-01-04 14:12:54.000000000', 'files': ['cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5122593add816c0d20affe2f3d703a1657ceb0fc', 'message': ""GlusterFS: Complete snapshot_delete when info doesn't exist\n\nThe snapshot_delete operation will fail if the snapshot info file\ndoesn't contain a record for the snapshot, or does not exist.\nThis happens in cases such as when snapshot_create fails to commit\nanything to disk.\n\nThe driver should allow the manager to delete the snapshot\nin this case, as there is no action required for the driver\nto delete anything.\n\nCloses-Bug: #1252864\n\n(cherry picked from commit d8a11168c908fe6c6a07fbb30a5bc88a6df6e939)\n\nChange-Id: I8686a1be09dbb7984072538bff6c026bb84eeb52\n""}]",0,64949,5122593add816c0d20affe2f3d703a1657ceb0fc,21,6,1,4523,,,0,"GlusterFS: Complete snapshot_delete when info doesn't exist

The snapshot_delete operation will fail if the snapshot info file
doesn't contain a record for the snapshot, or does not exist.
This happens in cases such as when snapshot_create fails to commit
anything to disk.

The driver should allow the manager to delete the snapshot
in this case, as there is no action required for the driver
to delete anything.

Closes-Bug: #1252864

(cherry picked from commit d8a11168c908fe6c6a07fbb30a5bc88a6df6e939)

Change-Id: I8686a1be09dbb7984072538bff6c026bb84eeb52
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/64949/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_glusterfs.py']",2,5122593add816c0d20affe2f3d703a1657ceb0fc,gluster_stable," drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(info_file_dict) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(info_file_dict) def test_delete_snapshot_not_in_info(self): """"""Snapshot not in info file / info file doesn't exist. Snapshot creation failed so nothing is on-disk. Driver should allow operation to succeed so the manager can remove the snapshot record. (Scenario: Snapshot object created in Cinder db but not on backing storage.) """""" (mox, drv) = self._mox, self._driver hashed = drv._get_hash_str(self.TEST_EXPORT1) volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) volume_filename = 'volume-%s' % self.VOLUME_UUID volume_path = os.path.join(volume_dir, volume_filename) info_path = '%s%s' % (volume_path, '.info') mox.StubOutWithMock(drv, '_read_file') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(drv, '_ensure_share_writable') snap_ref = {'name': 'test snap', 'volume_id': self.VOLUME_UUID, 'volume': self._simple_volume(), 'id': self.SNAP_UUID_2} drv._ensure_share_writable(volume_dir) drv._read_info_file(info_path, empty_if_missing=True).AndReturn({}) mox.ReplayAll() drv.delete_snapshot(snap_ref) mox.VerifyAll() drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info)", drv._read_info_file(info_path).AndReturn(info_file_dict) drv._read_info_file(info_path).AndReturn(info_file_dict) drv._read_info_file(info_path).AndReturn(snap_info) drv._read_info_file(info_path).AndReturn(snap_info) drv._read_info_file(info_path).AndReturn(snap_info),63,7
openstack%2Fcinder~stable%2Fhavana~I4a9ea40df9681ca6931ad6b390aa21b09d6cfec9,openstack/cinder,stable/havana,I4a9ea40df9681ca6931ad6b390aa21b09d6cfec9,GlusterFS: Ensure Cinder can write to shares,MERGED,2013-12-04 16:01:00.000000000,2014-02-02 05:58:46.000000000,2014-02-02 04:49:21.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6159}, {'_account_id': 7198}, {'_account_id': 7236}, {'_account_id': 8574}]","[{'number': 1, 'created': '2013-12-04 16:01:00.000000000', 'files': ['cinder/volume/drivers/glusterfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/test_utils.py', 'cinder/utils.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d39b2d2d808a79280201f6dc00aa93f576d70acd', 'message': 'GlusterFS: Ensure Cinder can write to shares\n\nEnsure the Cinder user can write to the GlusterFS share.  This\nis required for snapshot functionality, and means the admin\ndoes not have to set this permission manually.\n\nConflicts:\n\tcinder/tests/test_glusterfs.py\n\nCloses-Bug: #1236966\nChange-Id: I4a9ea40df9681ca6931ad6b390aa21b09d6cfec9\n(cherry picked from commit 371fa540600b20b97eae389e1f976145866cadae)\n'}]",1,60012,d39b2d2d808a79280201f6dc00aa93f576d70acd,15,9,1,4523,,,0,"GlusterFS: Ensure Cinder can write to shares

Ensure the Cinder user can write to the GlusterFS share.  This
is required for snapshot functionality, and means the admin
does not have to set this permission manually.

Conflicts:
	cinder/tests/test_glusterfs.py

Closes-Bug: #1236966
Change-Id: I4a9ea40df9681ca6931ad6b390aa21b09d6cfec9
(cherry picked from commit 371fa540600b20b97eae389e1f976145866cadae)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/60012/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/glusterfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/test_utils.py', 'cinder/utils.py', 'cinder/tests/test_glusterfs.py']",5,d39b2d2d808a79280201f6dc00aa93f576d70acd,bug/1251425,"import tempfilefrom cinder import utils mox.StubOutWithMock(utils, 'get_file_mode') mox.StubOutWithMock(utils, 'get_file_gid') mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_ensure_share_writable') utils.get_file_gid(self.TEST_MNT_POINT).AndReturn(333333) utils.get_file_mode(self.TEST_MNT_POINT).AndReturn(0o777) drv._ensure_share_writable(self.TEST_MNT_POINT) drv._execute('chgrp', IgnoreArg(), self.TEST_MNT_POINT, run_as_root=True) def _fake_load_shares_config(self, conf): self._driver.shares = {'127.7.7.7:/gluster1': None} def _fake_NamedTemporaryFile(self, prefix=None, dir=None): raise OSError('Permission denied!') def test_setup_set_share_permissions(self): mox = self._mox drv = self._driver glusterfs.CONF.glusterfs_shares_config = self.TEST_SHARES_CONFIG_FILE self.stubs.Set(drv, '_load_shares_config', self._fake_load_shares_config) self.stubs.Set(tempfile, 'NamedTemporaryFile', self._fake_NamedTemporaryFile) mox.StubOutWithMock(os.path, 'exists') mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(utils, 'get_file_gid') mox.StubOutWithMock(utils, 'get_file_mode') mox.StubOutWithMock(os, 'getegid') drv._execute('mount.glusterfs', check_exit_code=False) drv._execute('mkdir', '-p', mox_lib.IgnoreArg()) os.path.exists(self.TEST_SHARES_CONFIG_FILE).AndReturn(True) drv._execute('mount', '-t', 'glusterfs', '127.7.7.7:/gluster1', mox_lib.IgnoreArg(), run_as_root=True) utils.get_file_gid(mox_lib.IgnoreArg()).AndReturn(33333) # perms not writable utils.get_file_mode(mox_lib.IgnoreArg()).AndReturn(0o000) os.getegid().AndReturn(888) drv._execute('chgrp', 888, mox_lib.IgnoreArg(), run_as_root=True) drv._execute('chmod', 'g+w', mox_lib.IgnoreArg(), run_as_root=True) mox.ReplayAll() drv.do_setup(IsA(context.RequestContext)) mox.VerifyAll() volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) mox.StubOutWithMock(drv, '_ensure_share_writable') drv._ensure_share_writable(volume_dir) volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) mox.StubOutWithMock(drv, '_ensure_share_writable') drv._ensure_share_writable(volume_dir) volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) mox.StubOutWithMock(drv, '_ensure_share_writable') drv._ensure_share_writable(volume_dir) volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) mox.StubOutWithMock(drv, '_ensure_share_writable') drv._ensure_share_writable(volume_dir) ",,183,0
openstack%2Fnova~stable%2Fhavana~I66eb0c0ab926e0a8d1e2c9cfe1f7fd579ea3aa27,openstack/nova,stable/havana,I66eb0c0ab926e0a8d1e2c9cfe1f7fd579ea3aa27,Fix interface-attach removes existing interfaces from db,MERGED,2013-11-26 15:39:03.000000000,2014-02-02 03:04:54.000000000,2014-02-02 03:04:50.000000000,"[{'_account_id': 3}, {'_account_id': 1313}, {'_account_id': 1653}, {'_account_id': 1955}, {'_account_id': 4395}, {'_account_id': 5652}, {'_account_id': 7677}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-11-26 15:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bed99045e839819b9342a8b75cb7c681af5ff97e', 'message': 'Fix interface-attach removes existing interfaces from db\n\nThe following commit 394c693e359ed4f19cc2f7d975b1f9ee5500b7f6 changed\nallocate_port_for_instance() to only return the ports that were created\nrather than all of the ports on the instance which broke the attach-interface\ncode.\n\nThis patch fixes this issue by remove the sync decorators from:\nallocate_for_instance, allocate_port_for_instance, and\ndeallocate_port_for_instance to just _build_instance_nw_info which\nis called in all these cases instead.\n\nCloses-bug: #1223859\n\n(cherry picked from commit 1957339df302e2da75e0dbe78b5d566194ab2c08)\n\nConflicts:\n\tnova/network/neutronv2/api.py\n\nChange-Id: I66eb0c0ab926e0a8d1e2c9cfe1f7fd579ea3aa27\n'}, {'number': 2, 'created': '2013-11-26 22:52:41.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/api/openstack/compute/contrib/test_neutron_security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/16e6de10d50ed896be558dfd4bbb0da386de9519', 'message': 'Fix interface-attach removes existing interfaces from db\n\nThe following commit 394c693e359ed4f19cc2f7d975b1f9ee5500b7f6 changed\nallocate_port_for_instance() to only return the ports that were created\nrather than all of the ports on the instance which broke the attach-interface\ncode.\n\nThis patch fixes this issue by remove the sync decorators from:\nallocate_for_instance, allocate_port_for_instance, and\ndeallocate_port_for_instance to just _build_instance_nw_info which\nis called in all these cases instead.\n\nCloses-bug: #1223859\n\n(cherry picked from commit 1957339df302e2da75e0dbe78b5d566194ab2c08)\n\nConflicts:\n\tnova/network/neutronv2/api.py\n\nChange-Id: I66eb0c0ab926e0a8d1e2c9cfe1f7fd579ea3aa27\n'}]",1,58545,16e6de10d50ed896be558dfd4bbb0da386de9519,22,8,2,7677,,,0,"Fix interface-attach removes existing interfaces from db

The following commit 394c693e359ed4f19cc2f7d975b1f9ee5500b7f6 changed
allocate_port_for_instance() to only return the ports that were created
rather than all of the ports on the instance which broke the attach-interface
code.

This patch fixes this issue by remove the sync decorators from:
allocate_for_instance, allocate_port_for_instance, and
deallocate_port_for_instance to just _build_instance_nw_info which
is called in all these cases instead.

Closes-bug: #1223859

(cherry picked from commit 1957339df302e2da75e0dbe78b5d566194ab2c08)

Conflicts:
	nova/network/neutronv2/api.py

Change-Id: I66eb0c0ab926e0a8d1e2c9cfe1f7fd579ea3aa27
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/58545/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/api/openstack/compute/contrib/test_neutron_security_groups.py']",3,bed99045e839819b9342a8b75cb7c681af5ff97e,," 'info_cache': {'network_info': []},",,81,5
openstack%2Fdevstack~master~I6438c0efb297cfa5d3dbb5f00701b24f01c39d14,openstack/devstack,master,I6438c0efb297cfa5d3dbb5f00701b24f01c39d14,use ext4 for guest default ephemeral,MERGED,2014-02-01 22:06:57.000000000,2014-02-02 03:04:41.000000000,2014-02-02 03:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-02-01 22:06:57.000000000', 'files': ['lib/nova_plugins/hypervisor-libvirt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6bf1f1fb332c93cb4b74cf6b6511d2f9818a501d', 'message': ""use ext4 for guest default ephemeral\n\nthis isn't upstream default because of compatibility questions\nwith really old host on providers. However there is no reason not\nto do it in devstack.\n\nChange-Id: I6438c0efb297cfa5d3dbb5f00701b24f01c39d14\n""}]",0,70555,6bf1f1fb332c93cb4b74cf6b6511d2f9818a501d,5,2,1,2750,,,0,"use ext4 for guest default ephemeral

this isn't upstream default because of compatibility questions
with really old host on providers. However there is no reason not
to do it in devstack.

Change-Id: I6438c0efb297cfa5d3dbb5f00701b24f01c39d14
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/70555/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova_plugins/hypervisor-libvirt'],1,6bf1f1fb332c93cb4b74cf6b6511d2f9818a501d,ext4," iniset $NOVA_CONF DEFAULT default_ephemeral_format ""ext4""",,1,0
openstack%2Fneutron~master~Ie2d7da6f3825083a5f25d0df2571e6a020ad686c,openstack/neutron,master,Ie2d7da6f3825083a5f25d0df2571e6a020ad686c,Fixes for review comments and add urllib3 package,ABANDONED,2014-02-01 02:34:01.000000000,2014-02-02 01:55:08.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}]","[{'number': 1, 'created': '2014-02-01 02:34:01.000000000', 'files': ['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/logging_module.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'requirements.txt', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/lib/credentials.py', 'neutron/plugins/oneconvergence/lib/dummynvsdlib.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/856d05d3c8c1f355eb55c719fe6faa3d65c1daa0', 'message': 'Fixes for review comments and add urllib3 package\n\nFixes for review comments. Fix pep8 errors. Fix log messages for\ni8n.\n\nAdd urllib3 package to requirements. urllib3 is added to provide\nconnection pooling capability for the requests forwarded to the\nNVSD controller REST API server.\n\nChange-Id: Ie2d7da6f3825083a5f25d0df2571e6a020ad686c\n'}]",0,70502,856d05d3c8c1f355eb55c719fe6faa3d65c1daa0,12,9,1,9722,,,0,"Fixes for review comments and add urllib3 package

Fixes for review comments. Fix pep8 errors. Fix log messages for
i8n.

Add urllib3 package to requirements. urllib3 is added to provide
connection pooling capability for the requests forwarded to the
NVSD controller REST API server.

Change-Id: Ie2d7da6f3825083a5f25d0df2571e6a020ad686c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/70502/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/logging_module.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'requirements.txt', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/lib/credentials.py', 'neutron/plugins/oneconvergence/lib/dummynvsdlib.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py']",13,856d05d3c8c1f355eb55c719fe6faa3d65c1daa0,bp/oc-nvsd-neutron-plugin,"""""""Intermidiate NVSD Library.""""""from neutron.plugins.oneconvergence.lib import plugin_helper METHODS = {""POST"": ""create"", ""PUT"": ""update"", ""DELETE"": ""delete"", ""GET"": ""get""} class NVSDApi(object): self.nvsdcontroller = plugin_helper.initialize_plugin_helper() def send_request(self, method, uri, body=None, resource=None, tenant_id=' ', resource_id=None): """"""Issue a request to NVSD controller."""""" def build_error_msg(method, resource, tenant_id, resource_id): if method is ""POST"": msg = _(""Could not create a %(resource)s under tenant "" ""%(tenant_id)s"") % {'resource': resource, 'tenant_id': tenant_id} else: if resource_id is not None: msg = _(""Failed to %(method)s %(resource)s "" ""id=%(resource_id)s"") % {'method': METHODS[method], 'resource': resource, 'resource_id': resource_id } else: msg = _(""Failed to %(method)s %(resource)s"") % { 'method': METHODS[method], 'resource': resource} return msg try: result = self.nvsdcontroller.request(method, uri, body=body) except nvsdexception.NVSDAPIException as e: msg = build_error_msg(method, resource, tenant_id, resource_id) self.log.emit('error', tenant_id, msg) raise type(e)(reason=msg) except n_exception.NeutronException as e: msg = build_error_msg(method, resource, tenant_id, resource_id) self.log.emit('error', tenant_id, msg) raise e return result response = self.send_request(""POST"", uri, body=json.dumps(network_obj), resource='network', tenant_id=tenant_id) msg = _(""Network %(id)s created under tenant %(tenant_id)s"") % { 'id': nvsd_net['id'], 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""GET"", path, resource='network', tenant_id=tenant_id, resource_id=network_id) msg = _(""Network %(id)s retrieved under tenant %(tenant_id)s"") % { 'id': network_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""PUT"", uri, body=json.dumps(network_update), resource='network', tenant_id=tenant_id, resource_id=network_id) msg = _(""Network %(id)s updated under tenant %(tenant_id)s"") % { 'id': network_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""DELETE"", path, resource='network', tenant_id=tenant_id, resource_id=network_id) msg = _(""Network %(id)s deleted under tenant %(tenant_id)s"") % { 'id': network_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""POST"", uri, body=json.dumps(subnet), resource='subnet', tenant_id=tenant_id) msg = _(""Subnet %(id)s created under tenant %(tenant_id)s"") % { 'id': subnet['id'], 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""DELETE"", uri, resource='subnet', tenant_id=tenant_id, resource_id=subnet_id) msg = _(""Subnet %(id)s deleted under tenant %(tenant_id)s"") % { 'id': subnet_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""PUT"", uri, body=json.dumps(subnet_update), resource='subnet', tenant_id=tenant_id, resource_id=subnet_id) msg = _(""Subnet %(id)s updated under tenant %(tenant_id)s"") % { 'id': subnet_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""GET"", uri, resource='subnet', tenant_id=tenant_id, resource_id=subnet_id) msg = _(""Subnet %(id)s retrieved under tenant %(tenant_id)s"") % { 'id': subnet_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""POST"", path, body=json.dumps(lport), resource='port', tenant_id=tenant_id) msg = _(""Port %(id)s created under tenant %(tenant_id)s"") % { 'id': port['id'], 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""PUT"", uri, body=json.dumps(lport), resource='port', tenant_id=tenant_id, resource_id=port_id) msg = _(""Port %(id)s updated under tenant %(tenant_id)s"") % { 'id': port_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) self.send_request(""DELETE"", uri, resource='port', tenant_id=tenant_id, resource_id=port_id) msg = _(""Port %(id)s deleted under tenant %(tenant_id)s"") % { 'id': port_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""GET"", uri, resource='port', tenant_id=tenant_id, resource_id=port_id) nvsd_port = json.loads(response.body) msg = _(""Port %(id)s retrieved under tenant %(tenant_id)s"") % { 'id': port_id, 'tenant_id': tenant_id} self.log.emit('debug', tenant_id, msg) response = self.send_request(""GET"", uri, resource='ports', tenant_id=tenant_id)",""""""" Intermidiate NVSD Library """"""from neutron.api.v2 import attributesfrom neutron.plugins.oneconvergence.lib.plugin_helper import \ initialize_plugin_helper class NVSDApi: self.nvsdcontroller = initialize_plugin_helper() def send_request(self, *args): """"""Issue a request to nvsd controller"""""" return self.nvsdcontroller.request(*args) try: response = self.send_request(""POST"", uri, json.dumps(network_obj)) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in create network for"" "" tenant %s "" % tenant_id) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s created"" ""under tenant %s"" % (nvsd_net['id'], tenant_id)) try: self.send_request(""GET"", path) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for tenant"" "" %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get network %s"" % network_id) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s retrieved under tenant"" "" %s"" % (network_id, tenant_id)) try: response = self.send_request(""PUT"", uri, json.dumps(network_update)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for updation"" ""for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update network %s \ tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s updated under tenant"" "" %s"" % (network_id, tenant_id)) try: self.send_request(""DELETE"", path) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for deletion"" "" for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in delete network %s"" "" tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s deleted under tenant %s"" """" % (network_id, tenant_id)) try: response = self.send_request(""POST"", uri, json.dumps(subnet)) except nvsdexception.NVSDAPIException(): self.log.emit('error', tenant_id, ""Error in creating subnet"") raise nvsdexception.NVSDAPIException() self.log.emit('debug', tenant_id, ""Subnet %s created"" ""under tenant %s"" % (subnet['id'], tenant_id)) try: self.send_request(""DELETE"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""delete subnet %s tenant %s"" % (subnet_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet %s deleted"" ""under tenant %s"" % (subnet_id, tenant_id)) try: response = self.send_request(""PUT"", uri, json.dumps(subnet_update)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Not found in update Subnet %s \ or Network %s for tenant %s"" % (subnet_id, network_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update subnet %s \ for tenant %s"" % (subnet_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet %s updated"" ""under tenant %s"" % (subnet_id, tenant_id)) try: response = self.send_request(""GET"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""get subnet %s tenant %s"" % (subnet_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet is %s fetched"" ""under tenant %s"" % (subnet_id, tenant_id)) try: self.send_request(""POST"", path, json.dumps(lport)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found in create port"" "" tenant %s"" % (network_id, tenant_id)) raise nvsdexception.NotFoundException() except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in create port"" "" tenant %s"" % tenant_id) raise nvsdexception.NVSDAPIException() self.log.emit('debug', tenant_id, ""Port %s created"" ""under tenant %s"" % (port[""id""], tenant_id)) try: self.send_request(""PUT"", uri, json.dumps(lport)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Not found in update Port %s or \ Network %s for tenant %s"" % (port_id, network_id, tenant_id)) raise n_exception.PortNotFound(port_id=port_id, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update port %s \ for tenant %s"" % (port_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port %s updated"" ""under tenant %s"" % (port_id, tenant_id)) try: self.send_request(""DELETE"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""delete port %s tenant %s"" % (port_id, tenant_id)) raise n_exception.PortNotFound(port_id=port_id, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port %s deleted"" ""under tenant %s"" % (port_id, tenant_id)) try: response = self.send_request(""GET"", uri) nvsd_port = json.loads(response.body) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""get port %s, network %s, tenant %s"" % ( port_id, network_id, tenant_id)) raise n_exception.PortNotFound(port_id=nvsd_port, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get port %s"" "" Network- %s tenant- %s"" % ( port_id, network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port is %s fetched"" ""under tenant %s"" % (port_id, tenant_id)) try: response = self.send_request(""GET"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found in get ports"" "", Network %s for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get ports, Network %s"" "" for tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException()",258,375
openstack%2Fceilometer~stable%2Fhavana~Ibef4a95acada411af385ff75ccb36c5724068b59,openstack/ceilometer,stable/havana,Ibef4a95acada411af385ff75ccb36c5724068b59,Replace mongo aggregation with plain ol' map-reduce,MERGED,2014-01-15 14:51:04.000000000,2014-02-02 01:35:07.000000000,2014-02-02 01:35:07.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-01-15 14:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c4e01f1c0e4cb6c6f500c9749512273f27b96a6', 'message': ""Replace mongo aggregation with plain ol' map-reduce\n\nFixes bug 1262571\n\nPreviously, the mongodb storage driver an aggregation pipeline\nover the meter collection in order to construct a list of resources\nadorned with first & last sample timestamps etc.\n\nHowever mongodb aggregation framework performs sorting in-memory,\nin this case operating over a potentially very large collection.\nIt is also hardcoded to abort any sorts in an aggregation pipeline\nthat will consume more than 10% of physical memory, which is\nobserved in this case.\n\nNow, we avoid the aggregation framework altogether and instead\nuse an equivalent map-reduce.\n\nChange-Id: Ibef4a95acada411af385ff75ccb36c5724068b59\n(cherry picked from commit ba6641afacfc52e7391d2095751ee96d62a64c25)\n""}, {'number': 2, 'created': '2014-01-16 15:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e2c47036408e8d5f12523cce8d33b18b23164180', 'message': ""Replace mongo aggregation with plain ol' map-reduce\n\nFixes bug 1262571\n\nPreviously, the mongodb storage driver an aggregation pipeline\nover the meter collection in order to construct a list of resources\nadorned with first & last sample timestamps etc.\n\nHowever mongodb aggregation framework performs sorting in-memory,\nin this case operating over a potentially very large collection.\nIt is also hardcoded to abort any sorts in an aggregation pipeline\nthat will consume more than 10% of physical memory, which is\nobserved in this case.\n\nNow, we avoid the aggregation framework altogether and instead\nuse an equivalent map-reduce.\n\nChange-Id: Ibef4a95acada411af385ff75ccb36c5724068b59\n(cherry picked from commit ba6641afacfc52e7391d2095751ee96d62a64c25)\n""}, {'number': 3, 'created': '2014-01-16 16:07:08.000000000', 'files': ['ceilometer/storage/impl_mongodb.py', 'tests/api/v2/test_list_resources_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7e8cd818ba2e559dc9573f33c0809f3e210fd9e7', 'message': ""Replace mongo aggregation with plain ol' map-reduce\n\nFixes bug 1262571\n\nPreviously, the mongodb storage driver an aggregation pipeline\nover the meter collection in order to construct a list of resources\nadorned with first & last sample timestamps etc.\n\nHowever mongodb aggregation framework performs sorting in-memory,\nin this case operating over a potentially very large collection.\nIt is also hardcoded to abort any sorts in an aggregation pipeline\nthat will consume more than 10% of physical memory, which is\nobserved in this case.\n\nNow, we avoid the aggregation framework altogether and instead\nuse an equivalent map-reduce.\n\nChange-Id: Ibef4a95acada411af385ff75ccb36c5724068b59\n(cherry picked from commit ba6641afacfc52e7391d2095751ee96d62a64c25)\n""}]",0,66861,7e8cd818ba2e559dc9573f33c0809f3e210fd9e7,25,7,3,2284,,,0,"Replace mongo aggregation with plain ol' map-reduce

Fixes bug 1262571

Previously, the mongodb storage driver an aggregation pipeline
over the meter collection in order to construct a list of resources
adorned with first & last sample timestamps etc.

However mongodb aggregation framework performs sorting in-memory,
in this case operating over a potentially very large collection.
It is also hardcoded to abort any sorts in an aggregation pipeline
that will consume more than 10% of physical memory, which is
observed in this case.

Now, we avoid the aggregation framework altogether and instead
use an equivalent map-reduce.

Change-Id: Ibef4a95acada411af385ff75ccb36c5724068b59
(cherry picked from commit ba6641afacfc52e7391d2095751ee96d62a64c25)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/66861/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_mongodb.py', 'tests/api/v2/test_list_resources_scenarios.py']",2,5c4e01f1c0e4cb6c6f500c9749512273f27b96a6,," datetime.datetime(2012, 7, 2, 10, 40), 'tag': 'self.sample-%s' % timestamp, self._verify_sample_timestamps(data[0], timestamps[-1], timestamps[1])"," datetime.datetime(2012, 7, 2, 10, 40), 'tag': 'self.sample', self._verify_sample_timestamps(data[0], timestamps[0], timestamps[-1])",60,30
openstack%2Fcookbook-openstack-dashboard~master~I1a5f22b719db453d55d7f080cf0e1b102e11bacf,openstack/cookbook-openstack-dashboard,master,I1a5f22b719db453d55d7f080cf0e1b102e11bacf,refactor chefspec tests to be faster and more efficient,MERGED,2014-01-27 11:59:33.000000000,2014-02-02 01:00:01.000000000,2014-02-02 01:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 425}, {'_account_id': 1032}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-27 11:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/112b6d3db3fa530e10af57b864adde2b4bfa450d', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 2, 'created': '2014-01-27 14:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/1e95392b1bc1b6674dfb06adf29a958f6e44e787', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 3, 'created': '2014-01-28 15:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/98230e363578a136045dd90dc5112a4e67cca7fd', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 4, 'created': '2014-01-28 15:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/f4d8d6e34e05d48efea6cefd334fdc3d224b3768', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 5, 'created': '2014-01-28 16:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/da2c0211b897a719a3cc9cab32a09e6a0b340451', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 6, 'created': '2014-01-28 16:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/334462e77b29243c6f064d003f2b868cf5b1a77d', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}, {'number': 7, 'created': '2014-01-29 16:52:30.000000000', 'files': ['spec/server-redhat_spec.rb', 'spec/spec_helper.rb', 'spec/server-opensuse_spec.rb', 'spec/default_spec.rb', 'spec/server_spec.rb', 'spec/server-fedora_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/f41e92dbbf209d6c04cabeb6cd84f4204bc0de6c', 'message': 'refactor chefspec tests to be faster and more efficient\n\nChange-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf\nImplements: blueprint refactor-spec-files\n'}]",44,69336,f41e92dbbf209d6c04cabeb6cd84f4204bc0de6c,27,7,7,425,,,0,"refactor chefspec tests to be faster and more efficient

Change-Id: I1a5f22b719db453d55d7f080cf0e1b102e11bacf
Implements: blueprint refactor-spec-files
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/36/69336/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/server-redhat_spec.rb', 'spec/spec_helper.rb', 'spec/server-opensuse_spec.rb', 'spec/default_spec.rb', 'spec/server_spec.rb', 'spec/server-fedora_spec.rb']",6,112b6d3db3fa530e10af57b864adde2b4bfa450d,bp/refactor-spec-files, let(:runner) { ChefSpec::Runner.new(FEDORA_OPTS) } let(:node) { runner.node } let(:chef_run) do runner.converge(described_recipe) include_context 'non_redhat_stubs' include_context 'dashboard_stubs' expect(chef_run).to delete_file(file) resource = chef_run.find_resource( resource = chef_run.find_resource( expect(chef_run).not_to run_execute(cmd), before { dashboard_stubs } before do non_redhat_stubs @chef_run = ::ChefSpec::Runner.new ::FEDORA_OPTS @chef_run.converge 'openstack-dashboard::server' expect(@chef_run).to delete_file file resource = @chef_run.find_resource( resource = @chef_run.find_resource( expect(@chef_run).not_to run_execute(cmd),179,209
openstack%2Fnova~master~I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454,openstack/nova,master,I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454,Make nova-network use FixedIP for get_by_address() queries,MERGED,2014-01-16 16:15:26.000000000,2014-02-02 00:36:16.000000000,2014-02-02 00:36:12.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-16 16:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90a182f6f5bb1e99947bdee8f31c93f9deecec75', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 2, 'created': '2014-01-16 18:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/362a209c93f268674cf9cc93dd1b8631a08fb6ce', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 3, 'created': '2014-01-16 20:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/952a5a549fa755de1da32f7caaaa6b333b2a4c53', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 4, 'created': '2014-01-17 01:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97da333c8d75846109acfa299a453e19b662f85d', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 5, 'created': '2014-01-17 15:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d49bd30fbf84f0297b845fb222a94345f032427', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 6, 'created': '2014-01-17 16:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb62cfdc4dc9b88e2b9a70613b3761d1404fcf31', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 7, 'created': '2014-01-17 22:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad605c525c028728bad9d4be9034a17cf0423fe2', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 8, 'created': '2014-01-18 01:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3daede401ff8a91a76bd6847b575827896983879', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 9, 'created': '2014-01-28 18:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f12aef3461e5d0c29120a513d062ac2d548a4ea', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 10, 'created': '2014-01-30 17:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94f6c13b5dc39282db3ee1000f0bfdb9ae7ffe0e', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 11, 'created': '2014-01-31 14:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d9e10b3d83922f3a9d6cae83f61e60bea26afe2', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}, {'number': 12, 'created': '2014-01-31 18:17:05.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9fc3f085cfbf70955ab70f56cf5349c417b187c7', 'message': 'Make nova-network use FixedIP for get_by_address() queries\n\nThis makes nova-network use the FixedIP object for get_by_address()\nqueries.\n\nThis also fixes a bug in test_manager that incorrectly had\nfixed_ip.network_id as a UUID string in the fake IP objects.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454\n'}]",0,67209,9fc3f085cfbf70955ab70f56cf5349c417b187c7,44,8,12,4393,,,0,"Make nova-network use FixedIP for get_by_address() queries

This makes nova-network use the FixedIP object for get_by_address()
queries.

This also fixes a bug in test_manager that incorrectly had
fixed_ip.network_id as a UUID string in the fake IP objects.

Related to blueprint nova-network-objects

Change-Id: I732e4d7df76e5ae7bd010dfa6b0d8f8dd0c69454
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/67209/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,90a182f6f5bb1e99947bdee8f31c93f9deecec75,bp/nova-network-objects,"from nova.objects import fixed_ip as fixed_ip_objfrom nova.tests.objects import test_fixed_ip 'network_id': 0, 'network_id': 1, ip = dict(test_fixed_ip.fake_fixed_ip, **fixed_ips[1]) ip['network'] = dict(test_network.fake_network, **networks[1]) mox.IgnoreArg(), columns_to_join=mox.IgnoreArg() ).AndReturn(ip) ip = dict(test_fixed_ip.fake_fixed_ip, **fixed_ips[0]) ip['network'] = dict(test_network.fake_network, **networks[0]) mox.IgnoreArg(), columns_to_join=mox.IgnoreArg() ).AndReturn(ip) db_fixed1 = dict(test_fixed_ip.fake_fixed_ip, network_id=networks[1]['id'], network=dict(test_network.fake_network, **networks[1]), instance_uuid=None) mox.IgnoreArg(), columns_to_join=mox.IgnoreArg() ).AndReturn(db_fixed1) db_fixed2 = dict(test_fixed_ip.fake_fixed_ip, network_id=networks[0]['id'], network=dict(test_network.fake_network, **networks[0]), instance_uuid=None) mox.IgnoreArg(), columns_to_join=mox.IgnoreArg() ).AndReturn(db_fixed2) @mock.patch('nova.db.fixed_ip_get_by_address') @mock.patch('nova.db.network_get') def test_ip_association_and_allocation_of_other_project(self, net_get, fixed_get): net_get.return_value = dict(networks[1]) fixed_get.return_value = dict(test_fixed_ip.fake_fixed_ip, address=fix_addr, instance_uuid=instance.uuid, network=dict(test_network.fake_network, **networks[1])) @mock.patch('nova.db.fixed_ip_get_by_address') @mock.patch('nova.db.network_get') @mock.patch('nova.db.fixed_ip_update') def test_deallocate_fixed(self, fixed_update, net_get, fixed_get): net_get.return_value = dict(test_network.fake_network, **networks[1]) fix_addr = db.fixed_ip_associate_pool(elevated, 1, instance['uuid']) fixed_get.return_value = dict(test_fixed_ip.fake_fixed_ip, address=fix_addr.address, instance_uuid=instance.uuid, allocated=True, virtual_interface_id=3, network=dict(test_network.fake_network, **networks[1])) linux_net.release_dhcp(networks[1]['bridge'], fix_addr.address, 'fake_mac') self.network.deallocate_fixed_ip(context1, fix_addr.address, 'fake') fixed_update.assert_called_once_with(context1, fix_addr.address, {'allocated': False, 'virtual_interface_id': None}) elevated = context1.elevated() network = db.network_create_safe(elevated, networks[0]) 'network_id': network.id, @mock.patch('nova.db.fixed_ip_get_by_address') @mock.patch('nova.db.network_get') def test_deallocate_fixed_no_vif(self, net_get, fixed_get): net_get.return_value = dict(test_network.fake_network, **networks[1]) fixed_get.return_value = dict(test_fixed_ip.fake_fixed_ip, allocated=True, virtual_interface_id=3, instance_uuid=instance.uuid, network=dict(test_network.fake_network, **networks[1])) @mock.patch('nova.db.fixed_ip_get_by_address') @mock.patch('nova.db.network_get') @mock.patch('nova.db.fixed_ip_update') def test_fixed_ip_cleanup_fail(self, fixed_update, net_get, fixed_get): net_get.return_value = dict(test_network.fake_network, **networks[1]) fix_addr = fixed_ip_obj.FixedIP.associate_pool(elevated, 1, instance['uuid']) fixed_get.return_value = dict(test_fixed_ip.fake_fixed_ip, address=fix_addr.address, allocated=True, virtual_interface_id=3, instance_uuid=instance.uuid, network=dict(test_network.fake_network, **networks[1])) context1, str(fix_addr.address), 'fake') self.assertFalse(fixed_update.called)"," 'network_id': FAKEUUID, 'network_id': 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb', self.mox.StubOutWithMock(db, 'network_get') db.network_get(mox.IgnoreArg(), mox.IgnoreArg(), project_only=mox.IgnoreArg() ).AndReturn(dict(test_network.fake_network, **networks[1])) db.network_get(mox.IgnoreArg(), mox.IgnoreArg(), project_only=mox.IgnoreArg() ).AndReturn(dict(test_network.fake_network, **networks[0])) ip = fixed_ips[1].copy() mox.IgnoreArg()).AndReturn(ip) ip = fixed_ips[0].copy() mox.IgnoreArg()).AndReturn(ip) fixed_ips[1]['network_id'] = networks[1]['id'] fixed_ips[1]['instance_uuid'] = None mox.IgnoreArg()).AndReturn(fixed_ips[1]) fixed_ips[0]['network_id'] = networks[0]['id'] fixed_ips[0]['instance_uuid'] = None mox.IgnoreArg()).AndReturn(fixed_ips[0]) def test_ip_association_and_allocation_of_other_project(self): def network_get(_context, network_id, project_only=""allow_none""): return dict(test_network.fake_network, **networks[network_id]) self.stubs.Set(db, 'network_get', network_get) def test_deallocate_fixed(self): def network_get(_context, network_id, project_only=""allow_none""): return dict(test_network.fake_network, **networks[network_id]) self.stubs.Set(db, 'network_get', network_get) _fix_addr = db.fixed_ip_associate_pool(elevated, 1, instance['uuid']) fix_addr = _fix_addr.address values = {'allocated': True, 'virtual_interface_id': 3} db.fixed_ip_update(elevated, fix_addr, values) fixed = db.fixed_ip_get_by_address(elevated, fix_addr) network = db.network_get(elevated, fixed['network_id']) linux_net.release_dhcp(network['bridge'], fixed['address'], 'fake_mac') self.network.deallocate_fixed_ip(context1, fix_addr, 'fake') fixed = db.fixed_ip_get_by_address(elevated, fix_addr) self.assertFalse(fixed['allocated']) def network_get(_context, network_id, project_only=""allow_none""): return dict(test_network.fake_network, **networks[network_id]) self.stubs.Set(db, 'network_get', network_get) elevated = context1.elevated() 'network_id': 0, def test_deallocate_fixed_no_vif(self): def network_get(_context, network_id, project_only=""allow_none""): return dict(test_network.fake_network, **networks[network_id]) self.stubs.Set(db, 'network_get', network_get) values = {'allocated': True, 'virtual_interface_id': 3} db.fixed_ip_update(elevated, fix_addr.address, values) def test_fixed_ip_cleanup_fail(self): def network_get(_context, network_id, project_only=""allow_none""): return dict(test_network.fake_network, **networks[network_id]) self.stubs.Set(db, 'network_get', network_get) _fix_addr = db.fixed_ip_associate_pool(elevated, 1, instance['uuid']) fix_addr = _fix_addr.address values = {'allocated': True, 'virtual_interface_id': 3} db.fixed_ip_update(elevated, fix_addr, values) context1, fix_addr, 'fake') fixed = db.fixed_ip_get_by_address(elevated, fix_addr) self.assertTrue(fixed['allocated'])",128,109
openstack%2Fnova~master~I2f13f7a0463486e51c2317e02c2e7b378ac9e55d,openstack/nova,master,I2f13f7a0463486e51c2317e02c2e7b378ac9e55d,Add FixedIP.floating_ips dynamic property,MERGED,2014-01-16 16:15:24.000000000,2014-02-02 00:26:14.000000000,2014-02-02 00:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-16 16:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e96e73359969e14fd77c81392a93024b13bbdbfa', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 2, 'created': '2014-01-16 18:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d00108709c05e910332ba542daacb0e9d01ccc4', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 3, 'created': '2014-01-16 20:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5684e8ff87d712b0722efce106c46efd97b5f332', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 4, 'created': '2014-01-17 01:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7654dff0878648cda06de067a5de457a463b57d', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 5, 'created': '2014-01-17 15:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63e40ddbd5c6d03bc8253210b1603aae40bd31e5', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 6, 'created': '2014-01-17 16:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5086e836ca4b7e2f5b64fb8e867368624f4cb48', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 7, 'created': '2014-01-17 22:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc1a36a281078201cf7e3c7e2d49be077cc6ce0b', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 8, 'created': '2014-01-18 01:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4114245795ba88b21edb00e88928220eec90ff6', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 9, 'created': '2014-01-20 16:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9263d606ed46c63f21add541f9a7f7f525c9132e', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 10, 'created': '2014-01-27 16:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc740d9698afd81872d97adbcb2cc831794d690a', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 11, 'created': '2014-01-28 18:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/360fc48e1f02a0c07d69321e145cca01707d16f8', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 12, 'created': '2014-01-30 17:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e94ff117bd4db3fcb2339a7d1754b5cb0928244', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 13, 'created': '2014-01-31 14:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9241ebe914434f9b05d6b280757d81491848980', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}, {'number': 14, 'created': '2014-01-31 18:17:02.000000000', 'files': ['nova/objects/fixed_ip.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/afc227c25e77f72ac6eb88a1c1c67ce343b55c6b', 'message': ""Add FixedIP.floating_ips dynamic property\n\nThis adds a lazy-loading FixedIP.floating_ips property which mimics\nthe use of the backref between the two objects in the SQLAlchemy\nmodel. This doesn't introduce a new database query because it was\nbeing used as a lazy-load in network manager already.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d\n""}]",1,67208,afc227c25e77f72ac6eb88a1c1c67ce343b55c6b,66,7,14,4393,,,0,"Add FixedIP.floating_ips dynamic property

This adds a lazy-loading FixedIP.floating_ips property which mimics
the use of the backref between the two objects in the SQLAlchemy
model. This doesn't introduce a new database query because it was
being used as a lazy-load in network manager already.

Related to blueprint nova-network-objects

Change-Id: I2f13f7a0463486e51c2317e02c2e7b378ac9e55d
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/67208/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/fixed_ip.py'],1,e96e73359969e14fd77c81392a93024b13bbdbfa,bp/nova-network-objects," @property def floating_ips(self): # NOTE(danms): avoid circular import from nova.objects import floating_ip return floating_ip.FloatingIPList.get_by_fixed_ip_id(self._context, self.id) ",,7,0
openstack%2Fnova~master~I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6,openstack/nova,master,I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6,Add FloatingIP object implementation,MERGED,2014-01-15 23:07:44.000000000,2014-02-02 00:11:06.000000000,2014-02-02 00:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-15 23:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac30a30cd35798d40cfc10f12d58f2623bb48a95', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 2, 'created': '2014-01-16 16:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6de77d83e9a84dfb7190a274264735e842252a3', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 3, 'created': '2014-01-16 18:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4e28a44956f626199c8b2a426cdfdd1347f305b', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 4, 'created': '2014-01-16 20:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/958682cb86ac17e3b63fb57db11e27949ff79a6a', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 5, 'created': '2014-01-17 01:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd3fa07f5b53576d8808f885e8368e63a365ea46', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 6, 'created': '2014-01-17 15:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/055f2a5d70ebfe0d3d44911f19298450cb81f774', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 7, 'created': '2014-01-17 16:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebf71ce9b0e4380de65e8322b500b047b7a034de', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 8, 'created': '2014-01-17 22:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee073e21307f667389ca5b5c7c41f86a3456eb8c', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 9, 'created': '2014-01-18 01:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f57ecd73673ab7ff9fafa14ade9dd93b2c3eb966', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 10, 'created': '2014-01-20 16:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09cee157d61b851a6dc71fd73caf9c21fb626a06', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 11, 'created': '2014-01-27 16:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c185098e0277287b2835f8b2a9a1dc86a943c2e3', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 12, 'created': '2014-01-27 23:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/50e82b5298ae829d40018576ed3a35a774e18c72', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 13, 'created': '2014-01-28 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03d7cfc92f633c2a407e93d744fed5b06d44bfd1', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 14, 'created': '2014-01-30 17:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8efa4a1f30c8fc83e5d66ad6fe6f639b5cfc5548', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 15, 'created': '2014-01-31 14:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48899f8685ed4f188281bb96a94ed4b3669b7833', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}, {'number': 16, 'created': '2014-01-31 18:17:11.000000000', 'files': ['nova/objects/floating_ip.py', 'nova/tests/objects/test_floating_ip.py', 'nova/objects/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e1c33e2ec7f6a59495ee274bdf95e740bedc1e0f', 'message': 'Add FloatingIP object implementation\n\nThis adds a FloatingIP object for use by nova-network.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6\n'}]",5,66972,e1c33e2ec7f6a59495ee274bdf95e740bedc1e0f,65,8,16,4393,,,0,"Add FloatingIP object implementation

This adds a FloatingIP object for use by nova-network.

Related to blueprint nova-network-objects

Change-Id: I22832c7d22af2fbd45bac790286ad2f4ce2e1fd6
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/66972/14 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/floating_ip.py', 'nova/tests/objects/test_floating_ip.py', 'nova/objects/__init__.py']",3,ac30a30cd35798d40cfc10f12d58f2623bb48a95,bp/nova-network-objects, __import__('nova.objects.floating_ip'),,325,0
openstack%2Fnova~master~I262b316e3c509f3a5ea6629e74b62011c7d35ba4,openstack/nova,master,I262b316e3c509f3a5ea6629e74b62011c7d35ba4,Add FixedIP Object implementation,MERGED,2014-01-15 21:10:11.000000000,2014-02-02 00:10:12.000000000,2014-02-02 00:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-15 21:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/247e382ecdcae4cf037e4c268510510dbae6ef03', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 2, 'created': '2014-01-15 21:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d57280ca96ba3938525fc5b9a079f808f29bf41', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 3, 'created': '2014-01-16 16:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6e65598c8af756002802092aefd58bfc7639ec4', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 4, 'created': '2014-01-16 18:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b44fecf9c3ecb4d3a49ec0454a1efce0883ce7b9', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 5, 'created': '2014-01-16 20:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f06c4d6d896c2dde3cfa92dfd4c931eaa6c78b62', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 6, 'created': '2014-01-17 01:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9440e4b109cbf9e487f947a60eea9096d3a36ca3', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 7, 'created': '2014-01-17 15:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b9369fed1d2e3d09d7372118d814d3a27e8f522', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 8, 'created': '2014-01-17 16:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a288e2d480f0384e9e7669707143f3eb39ed3f9b', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 9, 'created': '2014-01-20 16:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c0b9ffe3cc1a7eb007e97fb8417fb9894b330cb', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 10, 'created': '2014-01-27 16:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e9066c2b06c0ff60333851b2679d6dfd0f204d8', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 11, 'created': '2014-01-27 23:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c59fee80aa257e5299dd47c678437a313a978ea0', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 12, 'created': '2014-01-28 18:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b207378814d355f4b35b7966247756f9142e0dd', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 13, 'created': '2014-01-30 17:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c6cfeaa57310c5a8707cbb9ee13cca0c64c99d4', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 14, 'created': '2014-01-31 14:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21c3d5b5e8e395c3b8df8e2a0394181e002e346a', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}, {'number': 15, 'created': '2014-01-31 18:16:51.000000000', 'files': ['nova/tests/objects/test_fixed_ip.py', 'nova/objects/__init__.py', 'nova/objects/fixed_ip.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/92f281e7a04f27c90cfccc11261880213718ae8b', 'message': 'Add FixedIP Object implementation\n\nThis adds the FixedIP object implementation to allow nova-network\nto perform these operations with an object.\n\nRelated to nova-network-objects\n\nChange-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4\n'}]",19,66941,92f281e7a04f27c90cfccc11261880213718ae8b,68,9,15,4393,,,0,"Add FixedIP Object implementation

This adds the FixedIP object implementation to allow nova-network
to perform these operations with an object.

Related to nova-network-objects

Change-Id: I262b316e3c509f3a5ea6629e74b62011c7d35ba4
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/66941/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_fixed_ip.py', 'nova/objects/__init__.py', 'nova/objects/fixed_ip.py']",3,247e382ecdcae4cf037e4c268510510dbae6ef03,bp/nova-network-objects,"# Copyright 2014 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import db from nova import exception from nova.objects import base as obj_base from nova.objects import instance as instance_obj from nova.objects import fields from nova.objects import network as network_obj OPTIONAL_ATTRS = ['instance', 'network'] class FixedIP(obj_base.NovaPersistentObject, obj_base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'id': fields.IntegerField(), 'address': fields.IPV4Address(), 'network_id': fields.IntegerField(nullable=True), 'virtual_interface_id': fields.IntegerField(nullable=True), 'instance_uuid': fields.UUIDField(nullable=True), 'allocated': fields.BooleanField(), 'leased': fields.BooleanField(), 'reserved': fields.BooleanField(), 'host': fields.StringField(nullable=True), 'instance': fields.ObjectField('Instance', nullable=True), 'network': fields.ObjectField('Network', nullable=True), } @staticmethod def _from_db_object(context, fixedip, db_fixedip, expected_attrs=None): if expected_attrs is None: expected_attrs = [] for field in fixedip.fields: if field not in OPTIONAL_ATTRS: fixedip[field] = db_fixedip[field] if 'instance' in expected_attrs: fixedip._instance = instance_obj.Instance._from_db_object( context, instance_obj.Instance(), db_fixedip['instance']) if 'network' in expected_attrs: fixedip._network = network_obj.Network._from_db_object( context, network_obj.Network(), db_fixedip['network']) fixedip._context = context fixedip.obj_reset_changes() return fixedip @obj_base.remotable_classmethod def get_by_id(cls, context, id, expected_attrs=None): if expected_attrs is None: expected_attrs = [] get_network = 'network' in expected_attrs db_fixedip = db.fixed_ip_get(context, id, get_network=get_network) return cls._from_db_object(context, cls(), db_fixedip, expected_attrs) @obj_base.remotable_classmethod def get_by_address(cls, context, address, expected_attrs=None): if expected_attrs is None: expected_attrs = [] if expected_attrs: # NOTE(danms): Right now, db/api only has all-or-nothing, so # if they ask for one, give 'em both expected_attrs = ['instance', 'network'] db_fixedip = db.fixed_ip_get_by_address_detailed(context, address) else: db_fixedip = db.fixed_ip_get_by_address(context, address) return cls._from_db_object(context, cls(), db_fixedip, expected_attrs) @obj_base.remotable_classmethod def get_by_floating_address(cls, context, address): db_fixedip = db.fixed_ip_get_by_floating_address(context, address) return cls._from_db_object(context, cls(), db_fixedip) @obj_base.remotable_classmethod def get_by_network_and_host(cls, context, network_id, host): db_fixedip = db.fixed_ip_get_by_network_host(context, network_id, host) return cls._from_db_object(context, cls(), db_fixedip) @obj_base.remotable_classmethod def associate(cls, context, address, instance_uuid, network_id=None, reserved=False): db_fixedip = db.fixed_ip_associate(context, address, instance_uuid, network_id=network_id, reserved=reserved) return cls._from_db_object(context, cls(), db_fixedip) @obj_base.remotable_classmethod def associate_pool(cls, context, network_id, instance_uuid=None, host=None): db_fixedip = db.fixed_ip_associate_pool(context, network_id, instance_uuid=instance_uuid, host=host) return cls._from_db_object(context, cls(), db_fixedip) @obj_base.remotable_classmethod def disassociate_by_address(cls, context, address): db.fixed_ip_disassociate(context, address) @obj_base.remotable def create(self, context): updates = self.obj_get_changes() if 'id' in updates: raise exception.ObjectActionError(action='create', reason='already created') if 'address' in updates: updates['address'] = str(updates['address']) db_fixedip = db.fixed_ip_create(context, updates) self._from_db_object(context, self, db_fixedip) @obj_base.remotable def save(self, context): updates = self.obj_get_changes() if 'address' in updates: raise exception.ObjectActionError(action='save', reason='address is not mutable') db_fixedip = db.fixed_ip_update(context, str(self.address), updates) self._from_db_object(context, self, db_fixedip) @obj_base.remotable def disassociate(self, context): db.fixed_ip_disassociate(context, str(self.address)) self.instance_uuid = None self.obj_reset_changes(['instance']) class FixedIPList(obj_base.ObjectListBase, obj_base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'objects': fields.ListOfObjectsField('FixedIP'), } child_version = { '1.0': '1.0', } @obj_base.remotable_classmethod def get_all(cls, context): db_fixedips = db.fixed_ip_get_all(context) return obj_base.obj_make_list(context, cls(), FixedIP, db_fixedips) @obj_base.remotable_classmethod def get_by_instance_uuid(cls, context, instance_uuid): db_fixedips = db.fixed_ip_get_by_instance(context, instance_uuid) return obj_base.obj_make_list(context, cls(), FixedIP, db_fixedips) @obj_base.remotable_classmethod def get_by_host(cls, context, host): db_fixedips = db.fixed_ip_get_by_host(context, host) return obj_base.obj_make_list(context, cls(), FixedIP, db_fixedips) @obj_base.remotable_classmethod def get_by_virtual_interface_id(cls, context, vif_id): db_fixedips = db.fixed_ips_by_virtual_interface(context, vif_id) return obj_base.obj_make_list(context, cls(), FixedIP, db_fixedips) ",,382,0
openstack%2Fneutron~master~I3b1109e38f3b08876c79972440da7e282d8df05b,openstack/neutron,master,I3b1109e38f3b08876c79972440da7e282d8df05b,Fixes for review comments,ABANDONED,2014-02-01 01:37:30.000000000,2014-02-01 23:47:22.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}]","[{'number': 1, 'created': '2014-02-01 01:37:30.000000000', 'files': ['neutron/plugins/oneconvergence/lib/credentials.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/53a5fd5f5144076890d40123819e296f226e685e', 'message': 'Fixes for review comments\n\nFix PEP8 errors. Fixes for review comments.\n\nChange-Id: I3b1109e38f3b08876c79972440da7e282d8df05b\n'}]",0,70492,53a5fd5f5144076890d40123819e296f226e685e,9,7,1,9722,,,0,"Fixes for review comments

Fix PEP8 errors. Fixes for review comments.

Change-Id: I3b1109e38f3b08876c79972440da7e282d8df05b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/70492/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/oneconvergence/lib/credentials.py'],1,53a5fd5f5144076890d40123819e296f226e685e,bp/oc-nvsd-neutron-plugin,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2014 OneConvergence, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """""" Check Tenant Creds"""""" from neutron.common import exceptions as qexception def check_tenantcreds(context, tenant_id): """""" Check whether a given tenant admin or not"""""" if ((context.tenant_id != tenant_id and context.is_admin is not True)): raise qexception.AdminRequired return True ",0,27
openstack%2Fneutron~master~Ie5c08afb7f1306d890790f87ee701bd24c5daaba,openstack/neutron,master,Ie5c08afb7f1306d890790f87ee701bd24c5daaba,Fixes for review comments,ABANDONED,2014-02-01 01:37:30.000000000,2014-02-01 23:46:58.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}]","[{'number': 1, 'created': '2014-02-01 01:37:30.000000000', 'files': ['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/lib/dummynvsdlib.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/logging_module.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55d3389d7f7c014203bb3d3c7accd49ed0e5f341', 'message': 'Fixes for review comments\n\nFixes for review comments. Fix PEP8 errors.\n\nChange-Id: Ie5c08afb7f1306d890790f87ee701bd24c5daaba\n'}]",0,70493,55d3389d7f7c014203bb3d3c7accd49ed0e5f341,9,7,1,9722,,,0,"Fixes for review comments

Fixes for review comments. Fix PEP8 errors.

Change-Id: Ie5c08afb7f1306d890790f87ee701bd24c5daaba
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/70493/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/lib/dummynvsdlib.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/logging_module.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py']",10,55d3389d7f7c014203bb3d3c7accd49ed0e5f341,bp/oc-nvsd-neutron-plugin,"""""""Library to talk to NVSD controller.""""""import neutron.plugins.oneconvergence.lib.exception as exception import neutron.plugins.oneconvergence.lib.logging_module as logging_module """"""Encapsulates the NVSD Controller details."""""" self.log = logging_module.Logger( """"""Login to NVSD Controller."""""" self.log.emit('error', ' ', ""Login failed"") self.log.emit('error', ' ', ""Unable to establish connection"" "" with Controller %s"" % self.api_url) msg = ""Response is Null, Request timed out while login, \ retrying after 1 second"" self.log.emit('error', ' ', msg) self.log.emit('debug', ' ', ""Login Successful %s %s"" % ( self.api_url, response.status)) self.log.emit('debug', ' ', ""AuthToken = %s"" % self.auth_token) else: self.log.emit('error', ' ', ""login failed"") """"""Logout of NVSD Controller."""""" self.log.emit('error', ' ', ""No Token, session logged out"") except Exception: self.log.emit('error', ' ', ""Problem in logout"") self.log.emit('debug', ' ', ""Logged out"") else: self.log.emit('error', ' ', ""logout failed"") """"""Issue a request to NVSD controller."""""" self.log.emit('warning', ' ', ""No Token, Re-login"") self.log.emit('debug', ' ', msg) self.log.emit('error', ' ', ""%s"" % (traceback.format_exc())) self.log.emit('error', ' ', msg) self.log.emit('error', ' ', msg) self.log.emit('error', ' ', msg) self.log.emit('error', ' ', msg) self.log.emit('error', ' ', ""%s"" % response.reason) elif status not in (httplib.OK, httplib.CREATED, httplib.NO_CONTENT): self.log.emit('error', ' ', msg) if request_ok is False: self.log.emit('error', ' ', msg) self.log.emit('debug', ' ', msg) """"""Resource Not Found."""""" raise exception.NotFoundException() """"""Bad Request."""""" raise exception.BadRequestException() """"""Internal Server Error."""""" raise exception.InternalServerError() """"""Server Exception."""""" raise exception.ServerException() """"""Forbidden."""""" raise exception.ForbiddenException() """"""Generic Exception."""""" raise exception.NVSDAPIException()",""""""" Library to talk to NVSD controller """"""import neutron.plugins.oneconvergence.lib.logging_module as logging_module import neutron.plugins.oneconvergence.lib.exception as exception """""" Encapsulates the NVSD Controller details """""" global log log = logging_module.Logger( """""" Login to NVSD Controller """""" log.emit('error', ' ', ""Login failed"") log.emit('error', ' ', ""Unable to establish connection"" "" with Controller %s"" % self.api_url) log.emit('error', ' ', ""Response is Null, Request timed "" ""out while login, retrying after 1 second"") log.emit('debug', ' ', ""Login Successful %s %s"" "" "" % (self.api_url, response.status)) log.emit('debug', ' ', ""AuthToken = %s"" % self.auth_token) else: log.emit('error', ' ', ""login failed"") """""" Logout of NVSD Controller """""" log.emit('error', ' ', ""No Token, session logged out"") except: log.emit('error', ' ', ""Problem in logout"") log.emit('debug', ' ', ""Logged out"") else: log.emit('error', ' ', ""logout failed"") """"""Issues request to controller."""""" log.emit('warning', ' ', ""No Token, Re-login"") log.emit('debug', ' ', msg) log.emit('error', ' ', ""%s"" % (traceback.format_exc())) log.emit('error', ' ', msg) log.emit('error', ' ', msg) log.emit('error', ' ', msg) log.emit('error', ' ', msg) log.emit('error', ' ', ""%s"" % response.reason) elif ((status != httplib.OK and status != httplib.CREATED and status != httplib.NO_CONTENT)): log.emit('error', ' ', msg) if (request_ok is False): log.emit('error', ' ', msg) log.emit('debug', ' ', msg) """""" Resource Not Found """""" raise exception.NotFoundException(reason=reason) """""" Bad Request """""" raise exception.BadRequestException(reason=reason) """""" Internal Server Error """""" raise exception.InternalServerError(reason=reason) """""" Server Exception """""" raise exception.ServerException(reason=reason) """""" Forbidden """""" raise exception.ForbiddenException(reason=reason) """""" Generic Exception"""""" raise exception.NVSDAPIException(reason=reason)",184,297
openstack%2Fneutron~master~I3ad43a6e1a39dd55359738fe189a5acb9337e4d6,openstack/neutron,master,I3ad43a6e1a39dd55359738fe189a5acb9337e4d6,Add i8n support for log messages,ABANDONED,2014-02-01 01:37:30.000000000,2014-02-01 23:46:43.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}]","[{'number': 1, 'created': '2014-02-01 01:37:30.000000000', 'files': ['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8b10d3918df50f2366abbc1183451236965db44', 'message': 'Add i8n support for log messages\n\nFix log messages for i8n. Fix pep8 errors in the unit test files.\n\nChange-Id: I3ad43a6e1a39dd55359738fe189a5acb9337e4d6\n'}]",0,70494,f8b10d3918df50f2366abbc1183451236965db44,9,7,1,9722,,,0,"Add i8n support for log messages

Fix log messages for i8n. Fix pep8 errors in the unit test files.

Change-Id: I3ad43a6e1a39dd55359738fe189a5acb9337e4d6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/70494/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/oneconvergence/NeutronPlugin.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py']",6,f8b10d3918df50f2366abbc1183451236965db44,bp/oc-nvsd-neutron-plugin," self.log.emit('error', ' ', _(""Login failed"")) self.log.emit('error', ' ', _(""Unable to establish connection"" "" with Controller %s"") % self.api_url) msg = _(""Response is Null, Request timed out while "" ""login, retrying after 1 second"") self.log.emit('debug', ' ', _(""Login Successful %(uri)s "" ""%(status)s"") % {'uri': self.api_url, 'status': response.status}) self.log.emit('debug', ' ', _(""AuthToken = %s"") % self.auth_token) else: self.log.emit('error', ' ', _(""login failed"")) self.log.emit('error', ' ', _(""Problem in logout"")) self.log.emit('debug', ' ', _(""Logged out"")) else: self.log.emit('error', ' ', _(""logout failed"")) self.log.emit('warning', ' ', _(""No Token, Re-login"")) msg = _(""request: %(method)s %(uri)s successful"") % { 'method': method, 'uri': self.api_url + uri} self.log.emit('error', ' ', _(""%s"") % (traceback.format_exc())) msg = _(""request: Request failed from Controller side"") msg = _(""request: Invalid server response"") elif isinstance(e, httplib.HTTPException): msg = _(""request: HTTP exception"") msg = _(""request: bad request exception from Controller"") msg = _(""Response is Null, Request timed out: %(method)s to "" ""%(uri)s"") % {'method': method, 'uri': uri} msg = _(""Request %(method)s %(uri)s body = %(body)s failed with "" ""status %(status)s"") % {'method': method, 'uri': uri, 'body': body, 'status': status} self.log.emit('error', ' ', _(""%s"") % response.reason) self.error_codes[status]() msg = _(""%(method)s to %(url)s, unexpected response code: "" ""%(status)d"") % {'method': method, 'url': url, 'status': status} msg = _(""Request failed from Controller side with "" ""Status=%s"") % status msg = _(""Success: %(method)s %(url)s status=%(status)s"") % { 'method': method, 'url': self.api_url + uri, 'status': status} def four_zero_four(self): def four_zero_nine(self): def five_zero_zero(self): def five_zero_three(self): def four_zero_three(self): def zero(self):"," self.log.emit('error', ' ', ""Login failed"") self.log.emit('error', ' ', ""Unable to establish connection"" "" with Controller %s"" % self.api_url) msg = ""Response is Null, Request timed out while login, \ retrying after 1 second"" #raise exception.RequestTimeout() self.log.emit('debug', ' ', ""Login Successful %s %s"" % ( self.api_url, response.status)) self.log.emit('debug', ' ', ""AuthToken = %s"" % self.auth_token) else: self.log.emit('error', ' ', ""login failed"") self.log.emit('error', ' ', ""Problem in logout"") self.log.emit('debug', ' ', ""Logged out"") else: self.log.emit('error', ' ', ""logout failed"") self.log.emit('warning', ' ', ""No Token, Re-login"") msg = ""request(): %s %s successful"" % (method, self.api_url + uri) self.log.emit('error', ' ', ""%s"" % (traceback.format_exc())) msg = ""request(): Request failed from Controller side"" msg = ""request():Invalid server response"" elif isinstance(e, httplib.HTTPException): msg = ""request(): HTTP exception"" msg = ""request():bad request exception from Controller"" msg = ""Response is Null, Request timed out: %s to %s"" % (method, uri) msg = ""Request %s %s body = %s failed with status---------%s "" % ( method, uri, body, status) self.log.emit('error', ' ', ""%s"" % response.reason) self.error_codes[status](self, response.reason) msg = ""%s to %s, unexpected response code: %d"" % ( method, url, status) msg = ""Request failed from Controller side with Status=%s"" % status msg = ""Success: %s %s status=%s"" % (method, self.api_url + uri, status) def four_zero_four(self, reason=None): def four_zero_nine(self, reason=None): def five_zero_zero(self, reason=None): def five_zero_three(self, reason=None): def four_zero_three(self, reason=None): def zero(self, reason=None):",115,93
openstack%2Fneutron~master~Id1c12b11a1d20c8ea54cdd6933634ce3d59d22d0,openstack/neutron,master,Id1c12b11a1d20c8ea54cdd6933634ce3d59d22d0,Add urllib3 package,ABANDONED,2014-02-01 01:37:31.000000000,2014-02-01 23:46:19.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}]","[{'number': 1, 'created': '2014-02-01 01:37:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/63a767cc935fa9321f5c2f4d0173279d8531ba40', 'message': 'Add urllib3 package\n\nAdd urllib3 package to requirements. urllib3 is added to provide\nconnection pooling capability for the requests forwarded to the\nNVSD controller REST API server.\n\nChange-Id: Id1c12b11a1d20c8ea54cdd6933634ce3d59d22d0\n'}]",0,70495,63a767cc935fa9321f5c2f4d0173279d8531ba40,12,9,1,9722,,,0,"Add urllib3 package

Add urllib3 package to requirements. urllib3 is added to provide
connection pooling capability for the requests forwarded to the
NVSD controller REST API server.

Change-Id: Id1c12b11a1d20c8ea54cdd6933634ce3d59d22d0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/70495/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,63a767cc935fa9321f5c2f4d0173279d8531ba40,bp/oc-nvsd-neutron-plugin,urllib3,,1,0
openstack%2Fnova~master~If3e1314cefdc1abcdd5eca44bcc2282cac664f05,openstack/nova,master,If3e1314cefdc1abcdd5eca44bcc2282cac664f05,Removes XML namespace definitions from V3 API plugins,MERGED,2014-01-31 04:32:48.000000000,2014-02-01 23:02:31.000000000,2014-02-01 23:02:27.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 04:32:48.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/plugins/v3/access_ips.py', 'nova/api/openstack/compute/plugins/v3/flavor_rxtx.py', 'nova/api/openstack/compute/plugins/v3/lock_server.py', 'nova/api/openstack/compute/plugins/v3/shelve.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/console_output.py', 'doc/v3/api_samples/extension-info/extensions-get-resp.json', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py', 'nova/api/openstack/compute/plugins/v3/extension_info.py', 'nova/api/openstack/compute/plugins/v3/agents.py', 'nova/api/openstack/compute/plugins/v3/rescue.py', 'nova/tests/integrated/v3/api_samples/extension-info/extensions-get-resp.json.tpl', 'nova/api/openstack/compute/plugins/v3/consoles.py', 'nova/api/openstack/compute/plugins/v3/keypairs.py', 'nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/api/openstack/compute/plugins/v3/instance_usage_audit_log.py', 'nova/api/openstack/compute/plugins/v3/extended_server_attributes.py', 'nova/api/openstack/compute/plugins/v3/extended_volumes.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/quota_classes.py', 'nova/api/openstack/compute/plugins/v3/pci.py', 'nova/api/openstack/compute/plugins/v3/extended_status.py', 'nova/api/openstack/compute/plugins/v3/versions.py', 'nova/api/openstack/extensions.py', 'nova/api/openstack/compute/plugins/v3/certificates.py', 'nova/api/openstack/compute/plugins/v3/config_drive.py', 'nova/api/openstack/compute/plugins/v3/server_usage.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/api/openstack/compute/plugins/v3/admin_password.py', 'nova/api/openstack/compute/plugins/v3/hide_server_addresses.py', 'nova/api/openstack/compute/plugins/v3/user_data.py', 'nova/api/openstack/compute/plugins/v3/extended_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/server_metadata.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/plugins/v3/services.py', 'nova/api/openstack/compute/plugins/__init__.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/flavors.py', 'doc/v3/api_samples/extension-info/extensions-list-resp.json', 'nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/api/openstack/compute/plugins/v3/instance_actions.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/ips.py', 'nova/tests/api/openstack/compute/plugins/v3/test_extension_info.py', 'nova/api/openstack/compute/plugins/v3/evacuate.py', 'nova/api/openstack/compute/plugins/v3/multinic.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/server_password.py', 'nova/api/openstack/compute/plugins/v3/deferred_delete.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/plugins/v3/multiple_create.py', 'nova/tests/integrated/v3/api_samples/extension-info/extensions-list-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/0db1e4ed2a8ecb3dc856c744e2451a10a37678d1', 'message': 'Removes XML namespace definitions from V3 API plugins\n\nRemoves the XML namespace definitions from the V3 API\nplugins declarations. Deliberately avoids removing\nthe XML namespace definition from admin_actions to avoid\nyet another rebase of the admin_actions split series.\n\nFixes up associated tests and requirement for V3 API extensions\nto define a namespace property.\n\nPartially implements blueprint remove-v3-xml-api\n\nChange-Id: If3e1314cefdc1abcdd5eca44bcc2282cac664f05\n'}]",0,70292,0db1e4ed2a8ecb3dc856c744e2451a10a37678d1,10,6,1,5292,,,0,"Removes XML namespace definitions from V3 API plugins

Removes the XML namespace definitions from the V3 API
plugins declarations. Deliberately avoids removing
the XML namespace definition from admin_actions to avoid
yet another rebase of the admin_actions split series.

Fixes up associated tests and requirement for V3 API extensions
to define a namespace property.

Partially implements blueprint remove-v3-xml-api

Change-Id: If3e1314cefdc1abcdd5eca44bcc2282cac664f05
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/70292/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/plugins/v3/access_ips.py', 'nova/api/openstack/compute/plugins/v3/flavor_rxtx.py', 'nova/api/openstack/compute/plugins/v3/lock_server.py', 'nova/api/openstack/compute/plugins/v3/shelve.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/console_output.py', 'doc/v3/api_samples/extension-info/extensions-get-resp.json', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py', 'nova/api/openstack/compute/plugins/v3/extension_info.py', 'nova/api/openstack/compute/plugins/v3/agents.py', 'nova/api/openstack/compute/plugins/v3/rescue.py', 'nova/tests/integrated/v3/api_samples/extension-info/extensions-get-resp.json.tpl', 'nova/api/openstack/compute/plugins/v3/consoles.py', 'nova/api/openstack/compute/plugins/v3/keypairs.py', 'nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/api/openstack/compute/plugins/v3/instance_usage_audit_log.py', 'nova/api/openstack/compute/plugins/v3/extended_server_attributes.py', 'nova/api/openstack/compute/plugins/v3/extended_volumes.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/quota_classes.py', 'nova/api/openstack/compute/plugins/v3/pci.py', 'nova/api/openstack/compute/plugins/v3/extended_status.py', 'nova/api/openstack/compute/plugins/v3/versions.py', 'nova/api/openstack/extensions.py', 'nova/api/openstack/compute/plugins/v3/certificates.py', 'nova/api/openstack/compute/plugins/v3/config_drive.py', 'nova/api/openstack/compute/plugins/v3/server_usage.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/api/openstack/compute/plugins/v3/admin_password.py', 'nova/api/openstack/compute/plugins/v3/hide_server_addresses.py', 'nova/api/openstack/compute/plugins/v3/user_data.py', 'nova/api/openstack/compute/plugins/v3/extended_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/server_metadata.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/plugins/v3/services.py', 'nova/api/openstack/compute/plugins/__init__.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/flavors.py', 'doc/v3/api_samples/extension-info/extensions-list-resp.json', 'nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/api/openstack/compute/plugins/v3/instance_actions.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/ips.py', 'nova/tests/api/openstack/compute/plugins/v3/test_extension_info.py', 'nova/api/openstack/compute/plugins/v3/evacuate.py', 'nova/api/openstack/compute/plugins/v3/multinic.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/server_password.py', 'nova/api/openstack/compute/plugins/v3/deferred_delete.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/plugins/v3/multiple_create.py', 'nova/tests/integrated/v3/api_samples/extension-info/extensions-list-resp.json.tpl']",59,0db1e4ed2a8ecb3dc856c744e2451a10a37678d1,bp/remove-v3-xml-api,} ," ""namespace"": ""http://docs.openstack.org/compute/core/extension_info/api/v3"", ""namespace"": ""http://docs.openstack.org/compute/core/flavors/v3"",}",7,102
openstack%2Fnova~master~Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c,openstack/nova,master,Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c,Adds suspend server extension for V3 API,MERGED,2013-11-28 06:00:19.000000000,2014-02-01 22:31:52.000000000,2014-02-01 22:31:49.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7040}, {'_account_id': 7494}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-28 06:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d71c42271cab0ce971011b495047f57fd1f2d42b', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 2, 'created': '2013-11-28 06:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1545bf076b27bfbfc7a0676c56e4ba21cec48fe1', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 3, 'created': '2013-11-29 04:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/054aa1ce9bf6656e3dc6172c32d3fb043d4814f4', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 4, 'created': '2013-12-01 11:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3f9754b81505048abe911ad4ad524b9b1e22ecf', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 5, 'created': '2013-12-01 13:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7d4f643658da0a79f7a41581d848e09861d4f9d', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 6, 'created': '2013-12-01 13:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ba9d4b5b05e65a5300de3af541073742d30fa33', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 7, 'created': '2013-12-16 04:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f9a8530e8878a6856f51ea90a8642efba9b23b3', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 8, 'created': '2014-01-04 10:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a427825afe64a623ff64d1810f17a495f9d9d02d', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 9, 'created': '2014-01-10 15:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba8b186b5c2d6b1321b89354ec72f7eefd7010a0', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 10, 'created': '2014-01-16 15:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee3adbc36443d5193a6fe75ba110d4ddf2351cb2', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 11, 'created': '2014-01-28 15:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40afe99774cc8771a237097c7fc92454c851eef8', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 12, 'created': '2014-01-29 03:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccf75e2dc102c64fb45e1f65fbc8563caf92bae8', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-admin-actions-split\nDocImpact: Adds os-suspend-server extension and moves suspend/resume\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 13, 'created': '2014-01-29 03:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d62b94c53a2e76a8a497542bf0cd76707d49908a', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-admin-actions-split\nDocImpact: Adds os-suspend-server extension and moves suspend/resume\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 14, 'created': '2014-01-30 03:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31924a84be966cd536f69b6e3ad4d3039cd85b5f', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-admin-actions-split\nDocImpact: Adds os-suspend-server extension and moves suspend/resume\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}, {'number': 15, 'created': '2014-01-31 04:41:31.000000000', 'files': ['nova/tests/integrated/v3/test_admin_actions.py', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'doc/v3/api_samples/os-suspend-server/server-resume.json', 'nova/api/openstack/compute/plugins/v3/suspend_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'doc/v3/api_samples/os-suspend-server/server-post-resp.json', 'etc/nova/policy.json', 'nova/tests/integrated/v3/test_suspend_server.py', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-resp.json.tpl', 'doc/v3/api_samples/os-suspend-server/server-suspend.json', 'nova/tests/api/openstack/compute/plugins/v3/test_suspend_server.py', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-req.json.tpl', 'doc/v3/api_samples/os-suspend-server/server-post-req.json', 'setup.cfg', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-resume.json.tpl', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-suspend.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/496cf4871c374e6694333dbec2f754678d79edbd', 'message': 'Adds suspend server extension for V3 API\n\nMoves the suspend/resume server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-admin-actions-split\nDocImpact: Adds os-suspend-server extension and moves suspend/resume\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c\n'}]",4,58921,496cf4871c374e6694333dbec2f754678d79edbd,73,11,15,5292,,,0,"Adds suspend server extension for V3 API

Moves the suspend/resume server functionality out of admin_actions into
its own extension. This part of the blueprint v3-admin-actions-split
allows more selective enablement of features contained in the admin
actions extension.

Note that XML api samples are no longer generated because
bp remove-v3-xml-api has been approved.

Partially implements bp v3-admin-actions-split
DocImpact: Adds os-suspend-server extension and moves suspend/resume
functionality out of os-admin-actions into this new extension

Change-Id: Ie2ad1c6085d65fee397d6ad5b5c9f3bd8e82ad3c
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/58921/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-resp.xml.tpl', 'nova/api/openstack/compute/plugins/v3/suspend_server.py', 'etc/nova/policy.json', 'doc/v3/api_samples/os-suspend-server/server-post-resp.xml', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-suspend.json.tpl', 'doc/v3/api_samples/os-admin-actions/admin-actions-suspend.xml', 'nova/tests/integrated/v3/test_admin_actions.py', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'doc/v3/api_samples/os-suspend-server/server-resume.json', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'doc/v3/api_samples/os-suspend-server/server-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-req.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-resume.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-suspend.xml.tpl', 'nova/tests/integrated/v3/test_suspend_server.py', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-post-resp.json.tpl', 'doc/v3/api_samples/os-suspend-server/server-resume.xml', 'doc/v3/api_samples/os-suspend-server/server-suspend.json', 'doc/v3/api_samples/os-suspend-server/server-post-req.xml', 'nova/tests/api/openstack/compute/plugins/v3/test_suspend_server.py', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/os-suspend-server/server-post-req.json', 'doc/v3/api_samples/os-suspend-server/server-suspend.xml', 'setup.cfg', 'nova/tests/integrated/v3/api_samples/os-suspend-server/server-resume.json.tpl']",26,d71c42271cab0ce971011b495047f57fd1f2d42b,bp/v3-admin-actions-split,,,306,58
openstack%2Fnova~master~Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77,openstack/nova,master,Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77,Adds pause server extension for V3 API,MERGED,2013-11-26 03:55:49.000000000,2014-02-01 22:20:08.000000000,2014-02-01 22:20:05.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-26 03:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfc7af2da8bd814c57930312fdbd81e802e17be2', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements v3-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 2, 'created': '2013-11-26 12:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/407698007ef6b54537d5017413178c6c6d233e66', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 3, 'created': '2013-11-28 05:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1225b1001e107f8eff362d1f24eb99c44dcae6ae', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 4, 'created': '2013-11-28 06:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a268c8ad249714c6b94cb9446742672b1d374fd', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 5, 'created': '2013-11-29 04:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9dd4e75d1a687fdb1e53a2a93559039a7356e34e', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 6, 'created': '2013-12-01 11:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd66f4922691c5beff29a68dd62371f3b2dbb4b3', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 7, 'created': '2013-12-16 04:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5526592434e874bacce45e3a0fecb20cdffa7e48', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 8, 'created': '2014-01-04 10:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb45a92ef37e82c8367a94bb5efa613cffb2d5c2', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 9, 'created': '2014-01-10 15:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ab1c8dfaa40aedf43a4d06964c2aab1ab8b7221', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 10, 'created': '2014-01-16 15:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d63e8f67786b89b14d55f38b5f762141ce7a0986', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 11, 'created': '2014-01-28 15:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b04a404400f6b1dcd41b1037a1fc7ace529eaef', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 12, 'created': '2014-01-29 02:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/028e6d8f6ee4e29f663faf89e27b2f8394c78448', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-pause-server extension and moves pause/unpause\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 13, 'created': '2014-01-29 22:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c681a108f9283a86518d701a71e675d13064ec99', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-pause-server extension and moves pause/unpause\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 14, 'created': '2014-01-30 03:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed1560b5fbfa7f9a2adf81b00e0c5e935c9aad18', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-pause-server extension and moves pause/unpause\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}, {'number': 15, 'created': '2014-01-31 04:40:03.000000000', 'files': ['nova/tests/integrated/v3/test_admin_actions.py', 'nova/api/openstack/compute/plugins/v3/pause_server.py', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/plugins/v3/test_pause_server.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/pause-server.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-req.json.tpl', 'doc/v3/api_samples/os-pause-server/unpause-server.json', 'etc/nova/policy.json', 'nova/tests/integrated/v3/test_pause_server.py', 'nova/tests/api/openstack/compute/plugins/v3/admin_only_action_common.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-resp.json.tpl', 'doc/v3/api_samples/os-pause-server/server-post-req.json', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/os-pause-server/pause-server.json', 'setup.cfg', 'nova/tests/integrated/v3/api_samples/os-pause-server/unpause-server.json.tpl', 'doc/v3/api_samples/os-pause-server/server-post-resp.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/6609dcf36b950ac2c83792d64b7d0e4b443e60ca', 'message': 'Adds pause server extension for V3 API\n\nMoves the pause/unpause server functionality out of admin_actions into\nits own extension. This part of the blueprint v3-api-admin-actions-split\nallows more selective enablement of features contained in the admin\nactions extension.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-pause-server extension and moves pause/unpause\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77\n'}]",23,58432,6609dcf36b950ac2c83792d64b7d0e4b443e60ca,91,10,15,5292,,,0,"Adds pause server extension for V3 API

Moves the pause/unpause server functionality out of admin_actions into
its own extension. This part of the blueprint v3-api-admin-actions-split
allows more selective enablement of features contained in the admin
actions extension.

Note that XML api samples are no longer generated because
bp remove-v3-xml-api has been approved.

Partially implements bp v3-api-admin-actions-split
DocImpact: Adds os-pause-server extension and moves pause/unpause
functionality out of os-admin-actions into this new extension

Change-Id: Ib9cce57e2ff1270a82b9d7e39b23ec6b532b9e77
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/58432/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/pause_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_pause_server.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/pause-server.json.tpl', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-req.json.tpl', 'etc/nova/policy.json', 'doc/v3/api_samples/os-pause-server/server-post-resp.xml', 'nova/tests/api/openstack/compute/plugins/v3/admin_only_action_common.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/pause-server.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-pause-server/unpause-server.xml.tpl', 'doc/v3/api_samples/os-pause-server/server-post-req.json', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-resp.xml.tpl', 'nova/tests/integrated/v3/test_admin_actions.py', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'doc/v3/api_samples/os-pause-server/unpause-server.json', 'nova/tests/integrated/v3/test_pause_server.py', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-resp.json.tpl', 'doc/v3/api_samples/os-pause-server/pause-server.xml', 'doc/v3/api_samples/os-pause-server/server-post-req.xml', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/os-pause-server/unpause-server.xml', 'doc/v3/api_samples/os-pause-server/pause-server.json', 'setup.cfg', 'nova/tests/integrated/v3/api_samples/os-pause-server/unpause-server.json.tpl', 'doc/v3/api_samples/os-pause-server/server-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-pause-server/server-post-req.xml.tpl']",26,bfc7af2da8bd814c57930312fdbd81e802e17be2,bp/v3-api-admin-actions-split,"<?xml version=""1.0"" encoding=""UTF-8""?> <server xmlns=""http://docs.openstack.org/compute/api/v1.1"" image_ref=""%(glance_host)s/images/%(image_id)s"" flavor_ref=""%(host)s/flavors/1"" name=""new-server-test""> <metadata> <meta key=""My Server Name"">Apache1</meta> </metadata> <personality> <file path=""/etc/banner.txt""> ICAgICAgDQoiQSBjbG91ZCBkb2VzIG5vdCBrbm93IHdoeSBp dCBtb3ZlcyBpbiBqdXN0IHN1Y2ggYSBkaXJlY3Rpb24gYW5k IGF0IHN1Y2ggYSBzcGVlZC4uLkl0IGZlZWxzIGFuIGltcHVs c2lvbi4uLnRoaXMgaXMgdGhlIHBsYWNlIHRvIGdvIG5vdy4g QnV0IHRoZSBza3kga25vd3MgdGhlIHJlYXNvbnMgYW5kIHRo ZSBwYXR0ZXJucyBiZWhpbmQgYWxsIGNsb3VkcywgYW5kIHlv dSB3aWxsIGtub3csIHRvbywgd2hlbiB5b3UgbGlmdCB5b3Vy c2VsZiBoaWdoIGVub3VnaCB0byBzZWUgYmV5b25kIGhvcml6 b25zLiINCg0KLVJpY2hhcmQgQmFjaA== </file> </personality> </server> ",,369,54
openstack%2Fkeystone~master~I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243,openstack/keystone,master,I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243,Sync oslo's policy module,MERGED,2014-01-29 05:22:15.000000000,2014-02-01 21:26:35.000000000,2014-02-01 21:26:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-29 05:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3ca08e626f39a3b413a378e79c91aa949699829e', 'message': ""Sync oslo's policy module\n\nI made some changes to the policy module in oslo to use six.moves.urllib\ninstead of py3kcompat.urlutils. This change will help us on our way to\nbeing more Python3 friendly.\n\nChange-Id: I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243\n""}, {'number': 2, 'created': '2014-01-29 20:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/26c24b77b58370cd18077f65d23d9db512026aee', 'message': ""Sync oslo's policy module\n\nI made some changes to the policy module in oslo to use six.moves.urllib\ninstead of py3kcompat.urlutils. This change will help us on our way to\nbeing more Python3 friendly.\n\nOur test_policy tests had to be updated because we are stubbing\nimplementation details in policy.\n\nChange-Id: I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243\n""}, {'number': 3, 'created': '2014-01-31 17:59:30.000000000', 'files': ['keystone/tests/test_policy.py', 'keystone/openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1288f694d51c13d12e6d61a1349b758ac8eab893', 'message': ""Sync oslo's policy module\n\nI made some changes to the policy module in oslo to use six.moves.urllib\ninstead of py3kcompat.urlutils. This change will help us on our way to\nbeing more Python3 friendly.\n\nOur test_policy tests had to be updated because we are stubbing\nimplementation details in policy.\n\nChange-Id: I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243\nImplements: bp keystone-py3kcompat\n""}]",1,69795,1288f694d51c13d12e6d61a1349b758ac8eab893,16,5,3,7725,,,0,"Sync oslo's policy module

I made some changes to the policy module in oslo to use six.moves.urllib
instead of py3kcompat.urlutils. This change will help us on our way to
being more Python3 friendly.

Our test_policy tests had to be updated because we are stubbing
implementation details in policy.

Change-Id: I23377a4c71f0f0cb58518f0cd5ce341a8a9c4243
Implements: bp keystone-py3kcompat
",git fetch https://review.opendev.org/openstack/keystone refs/changes/95/69795/3 && git format-patch -1 --stdout FETCH_HEAD,['keystone/openstack/common/policy.py'],1,3ca08e626f39a3b413a378e79c91aa949699829e,(detached,"import six.moves.urllib.parse as urlparse import six.moves.urllib.request as urlrequestfrom keystone.openstack.common.gettextutils import _ post_data = urlparse.urlencode(data) f = urlrequest.urlopen(url, post_data)","import urllib import urllib2from keystone.openstack.common.gettextutils import _ # noqa post_data = urllib.urlencode(data) f = urllib2.urlopen(url, post_data)",6,5
openstack%2Fpython-novaclient~master~Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c,openstack/python-novaclient,master,Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c,Flavor ExtraSpecs containing '/' cannot be deleted,MERGED,2014-01-23 16:57:21.000000000,2014-02-01 20:12:07.000000000,2014-02-01 20:12:07.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 7629}, {'_account_id': 9214}, {'_account_id': 9275}, {'_account_id': 9313}]","[{'number': 1, 'created': '2014-01-23 16:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/03425fcbf6e5cc953dc4a1d84ef9dc77ed87c9b9', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 2, 'created': '2014-01-23 18:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e79dae20a17b22ac031b4193764bd2daa2a37a4f', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 3, 'created': '2014-01-27 13:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/5bd0eba4b7b7ec58b7fea1ad1f7e5085766969a1', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 4, 'created': '2014-01-27 13:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/bba942d3a573fb9e862095bd5c9416d932571372', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 5, 'created': '2014-01-27 13:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/bf18dde969b607518f149a62e05273291b124d8b', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 6, 'created': '2014-01-27 15:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/887912a51e899b6d7d01d74e097edb4f39b46967', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\nA new test flavor has been created which doesn't check the\nkeys in the post body. This flavor has been created in the\nthird place (instead of in the last) in order to keep\nworking existent test cases which depend on the last flavor\nreceived in the get method.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 7, 'created': '2014-01-30 19:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/463369a6951d625b9f76b015420979c9cdaa0e09', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 8, 'created': '2014-01-31 18:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/342f184c2f919c0fabf4b835847a6d2e3a506d16', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons and hyphens.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}, {'number': 9, 'created': '2014-01-31 20:39:41.000000000', 'files': ['novaclient/tests/v1_1/fakes.py', 'novaclient/tests/v3/test_flavors.py', 'novaclient/v1_1/flavors.py', 'novaclient/tests/v1_1/test_flavors.py', 'novaclient/utils.py', 'novaclient/v3/flavors.py', 'novaclient/tests/test_utils.py', 'novaclient/tests/v3/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fc8579dfa8f2d897ce4ea9f6acfeea3ca170d6f0', 'message': ""Flavor ExtraSpecs containing '/' cannot be deleted\n\nThis change applies a regular expression in order to filter\nflavor extraspects keys with invalid characters.\nThe characters allowed are: letters, numbers, underscores,\nperiods, colons, spaces and hyphens.\nA new test flavor has been created which doesn't check the\nkeys in the post body. This flavor has been created in the\nthird place (instead of in the last) in order to keep\nworking existent test cases which depend on the last flavor\nreceived in the get method.\n\nChange-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c\nPartial-Bug: #1256119\n""}]",33,68695,fc8579dfa8f2d897ce4ea9f6acfeea3ca170d6f0,43,8,9,9214,,,0,"Flavor ExtraSpecs containing '/' cannot be deleted

This change applies a regular expression in order to filter
flavor extraspects keys with invalid characters.
The characters allowed are: letters, numbers, underscores,
periods, colons, spaces and hyphens.
A new test flavor has been created which doesn't check the
keys in the post body. This flavor has been created in the
third place (instead of in the last) in order to keep
working existent test cases which depend on the last flavor
received in the get method.

Change-Id: Ifd86bed23a05a5946ae8b9ba6f6c9bf4b24b1d4c
Partial-Bug: #1256119
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/95/68695/8 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/v1_1/fakes.py', 'novaclient/tests/v3/test_flavors.py', 'novaclient/tests/v1_1/test_flavors.py', 'novaclient/v1_1/flavors.py', 'novaclient/v3/flavors.py', 'novaclient/tests/v3/fakes.py']",6,03425fcbf6e5cc953dc4a1d84ef9dc77ed87c9b9,bug/1256119," post_flavors_4_flavor_extra_specs = ( fakes_v1_1.FakeHTTPClient.post_flavors_4_os_extra_specs) {'id': 4, 'name': '1024 MB Server', 'ram': 1024, 'disk': 10, 'ephemeral': 10, 'flavor-access:is_public': True, 'links': {}},",,83,0
openstack%2Fopenstack-manuals~master~I9335d3e74b6885feba6bd2d9991efb5b6cbc63ac,openstack/openstack-manuals,master,I9335d3e74b6885feba6bd2d9991efb5b6cbc63ac,Add CLI reference to docs.o.o pages,MERGED,2014-01-31 18:39:15.000000000,2014-02-01 19:43:37.000000000,2014-02-01 19:43:36.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-01-31 18:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/47ac3a398f631bcec885452d777c2caef46aa564', 'message': 'Add CLI reference to docs.o.o pages\n\nNow that the CLI reference is published, we can link to it.\n\nChange-Id: I9335d3e74b6885feba6bd2d9991efb5b6cbc63ac\n'}, {'number': 2, 'created': '2014-01-31 19:44:30.000000000', 'files': ['www/havana/index.html', 'www/trunk/index.html', 'www/developer/language-bindings.html', 'www/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a5dd49e9fc6e8de8657de2927f24bc7e1deed1a', 'message': 'Add CLI reference to docs.o.o pages\n\nNow that the CLI reference is published, we can link to it.\n\nChange-Id: I9335d3e74b6885feba6bd2d9991efb5b6cbc63ac\n'}]",1,70392,1a5dd49e9fc6e8de8657de2927f24bc7e1deed1a,10,4,2,6547,,,0,"Add CLI reference to docs.o.o pages

Now that the CLI reference is published, we can link to it.

Change-Id: I9335d3e74b6885feba6bd2d9991efb5b6cbc63ac
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/70392/2 && git format-patch -1 --stdout FETCH_HEAD,"['www/havana/index.html', 'www/trunk/index.html', 'www/developer/language-bindings.html', 'www/index.html']",4,47ac3a398f631bcec885452d777c2caef46aa564,publish-cli-reference," <dd><a href=""http://docs.openstack.org/cli-reference/content/"" >Command Line Interface Reference</a></dd> ",,13,1
openstack%2Fopenstack-manuals~master~Ic4b466dbf83d9f94364e7339a0b96f0fe9f3db93,openstack/openstack-manuals,master,Ic4b466dbf83d9f94364e7339a0b96f0fe9f3db93,Added configuration in a single page,MERGED,2014-02-01 18:09:24.000000000,2014-02-01 19:43:29.000000000,2014-02-01 19:43:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 8944}]","[{'number': 1, 'created': '2014-02-01 18:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/02f77439f139730261118e4c869f67b98d10e993', 'message': 'Added configuration in a single page\n\nBug: #1266367\nChange-Id: Ic4b466dbf83d9f94364e7339a0b96f0fe9f3db93\n'}, {'number': 2, 'created': '2014-02-01 18:11:17.000000000', 'files': ['doc/install-guide/ch_basics.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ea9bb51dbd8c82f04cb67cdd2e392ddc52d6aa89', 'message': 'Added configuration in a single page\n\nCloses-Bug: #1266367\nChange-Id: Ic4b466dbf83d9f94364e7339a0b96f0fe9f3db93\n'}]",0,70538,ea9bb51dbd8c82f04cb67cdd2e392ddc52d6aa89,8,4,2,8944,,,0,"Added configuration in a single page

Closes-Bug: #1266367
Change-Id: Ic4b466dbf83d9f94364e7339a0b96f0fe9f3db93
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/70538/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/ch_basics.xml'],1,02f77439f139730261118e4c869f67b98d10e993,test, <?dbhtml-stop-chunking?>,,1,0
openstack%2Foperations-guide~master~I82a7dfa6a4c8f672d410a005dc0e8e127a6397fc,openstack/operations-guide,master,I82a7dfa6a4c8f672d410a005dc0e8e127a6397fc,Reformat glossary,MERGED,2014-01-30 19:44:05.000000000,2014-02-01 19:17:10.000000000,2014-02-01 19:17:10.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-01-30 19:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/39b20472d1c848689f33c2679b02f778e52c6310', 'message': 'Reformat glossary\n\nThis formats the glossary in the OPS guide the same way as the file\nin the openstack-manuals repository.\n\nIt changes whitespace and adds comment marks for each letter.\n\nThis allows easier syncing with the openstack-manuals version.\n\nChange-Id: I82a7dfa6a4c8f672d410a005dc0e8e127a6397fc\nNote: Best reviewed with ""git diff -w"".\n'}, {'number': 2, 'created': '2014-01-30 20:18:01.000000000', 'files': ['doc/openstack-ops/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/32bde9259ec19ded34c63ff959c784cadcf7bce0', 'message': 'Reformat glossary\n\nThis formats the glossary in the OPS guide the same way as the file\nin the openstack-manuals repository.\n\nIt changes whitespace and adds comment marks for each letter.\n\nThis allows easier syncing with the openstack-manuals version.\n\nChange-Id: I82a7dfa6a4c8f672d410a005dc0e8e127a6397fc\nNote: Best reviewed with ""git diff -w"".\n'}]",0,70203,32bde9259ec19ded34c63ff959c784cadcf7bce0,8,4,2,6547,,,0,"Reformat glossary

This formats the glossary in the OPS guide the same way as the file
in the openstack-manuals repository.

It changes whitespace and adds comment marks for each letter.

This allows easier syncing with the openstack-manuals version.

Change-Id: I82a7dfa6a4c8f672d410a005dc0e8e127a6397fc
Note: Best reviewed with ""git diff -w"".
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/03/70203/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/glossary-terms.xml'],1,39b20472d1c848689f33c2679b02f778e52c6310,reformat-glossary," <!-- .A. --> <title>A</title> <glossentry> <glossterm>account</glossterm> <glossdef> <para>The swift context of an account, or a user account from an identity service such as Active Directory, /etc/passwd, OpenLDAP, keystone, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>account auditor</glossterm> <glossdef> <para>Checks for missing replicas, incorrect, and corrupted objects in a specified swift account by running queries against the back-end SQLite database.</para> </glossdef> </glossentry> <glossentry> <glossterm>account database</glossterm> <glossdef> <para>An SQLite database that contains swift accounts and related metadata and is accessed by the accounts server. Alternately, the keystone back-end which contains accounts.</para> </glossdef> </glossentry> <glossentry> <glossterm>account reaper</glossterm> <glossdef> <para>A swift worker that scans for and deletes account databases that are marked for deletion on an account server.</para> </glossdef> </glossentry> <glossentry> <glossterm>account server</glossterm> <glossdef> <para>Lists containers in swift and stores container information in the account database.</para> </glossdef> </glossentry> <glossentry> <glossterm>account service</glossterm> <glossdef> <para>Component of swift that provides account services such as list, create, modify, and audit. Do not confuse with keystone, OpenLDAP, or similar user account services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Active Directory</glossterm> <glossdef> <para>Authentication and Identity Service by Microsoft, based on LDAP. Supported in OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>address pool</glossterm> <glossdef> <para>A group of fixed and/or floating IP addresses that are assigned to a nova project and can be used by or assigned to the VM instances in a project.</para> </glossdef> </glossentry> <glossentry> <glossterm>admin API</glossterm> <glossdef> <para>A subset of API calls that are accessible to authorized administrators and are generally not accessible to end users or the public internet, can exist as a separate service (keystone) or can be a subset of another API (nova).</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Kernel Image (AKI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Machine Image (AMI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Ramdisk Image (ARI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Apache</glossterm> <glossdef> <para>The most common web server software currently used on the Internet, known as HTTPd.</para> </glossdef> </glossentry> <glossentry> <glossterm>Apache License 2.0</glossterm> <glossdef> <para>All OpenStack core projects are provided under the terms of the Apache License 2.0 license.</para> </glossdef> </glossentry> <glossentry> <glossterm>API endpoint</glossterm> <glossdef> <para>The daemon, worker, or service that a client communicates with to access an API. In OpenStack, API endpoints can provide services such as authentication, adding images, booting virtual machines, and attaching volumes.</para> </glossdef> </glossentry> <glossentry> <glossterm>API extension</glossterm> <glossdef> <para>A feature of nova and neutron that allows custom modules to extend the core APIs.</para> </glossdef> </glossentry> <glossentry> <glossterm>API extension plug-in</glossterm> <glossdef> <para>Alternative term for a neutron plug-in or neutron API extension.</para> </glossdef> </glossentry> <glossentry> <glossterm>API server</glossterm> <glossdef> <para>Any node running a daemon or worker that provides an API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>API version</glossterm> <glossdef> <para>In OpenStack, a the API version for a project is part of the URL. For example, <code>example.com/nova/v1/foobar</code>.</para> </glossdef> </glossentry> <glossentry> <glossterm>Application Programming Interface (API)</glossterm> <glossdef> <para>A collection of specifications used to access a service, application, or program. Includes service calls, required parameters for each call, and the expected return values.</para> </glossdef> </glossentry> <glossentry> <glossterm>arptables</glossterm> <glossdef> <para>Used along with iptables, ebtables, and ip6tables in nova to provide firewall services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Asynchronous JavaScript and XML (AJAX)</glossterm> <glossdef> <para>A group of interrelated web development techniques used on the client-side to create asynchronous web applications. Used extensively in horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>attachment (network)</glossterm> <glossdef> <para>Association of an interface ID to a logical port. Plugs an interface into a port.</para> </glossdef> </glossentry> <glossentry> <glossterm>auditor</glossterm> <glossdef> <para>A worker process that verifies the integrity of swift objects, containers, and accounts. Auditors is the collective term for the swift account auditor, container auditor, and object auditor.</para> </glossdef> </glossentry> <glossentry> <glossterm>Austin</glossterm> <glossdef> <para>Project name for the initial release of </glossdef> </glossentry> <glossentry> <glossterm>authentication</glossterm> <glossdef> <para>The process that confirms that the user, process, or client is really who they say they are through private key, secret token, password, fingerprint, or similar method. Abbreviated as AuthN.</para> </glossdef> </glossentry> <glossentry> <glossterm>authentication token</glossterm> <glossdef> <para>A string of text provided to the client after authentication. Must be provided by the user or process in subsequent requests to the API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>authorization</glossterm> <glossdef> <para>The act of verifying that a user, process, or client is authorized to perform an action, such as delete a swift object, list a swift container, start a nova VM, reset a password, and so on. Abbreviate as AuthZ.</para> </glossdef> </glossentry> <glossentry> <glossterm>availability zone</glossterm> <glossdef> <para>A segregated area of a cloud deployment.</para> </glossdef> </glossentry> <!-- .B. --> <title>B</title> <glossentry> <glossterm>back-end catalog</glossterm> <glossdef> <para>The storage method used by the keystone catalog service to store and retrieve information about API endpoints that are available to the client. Examples include a SQL database, LDAP database, or KVS back-end.</para> </glossdef> </glossentry> <glossentry> <glossterm>back-end store</glossterm> <glossdef> <para>The persistent data store used that glance uses to retrieve and store VM images. Options include swift, local file system, S3, and HTTP.</para> </glossdef> </glossentry> <glossentry> <glossterm>bare</glossterm> <glossdef> <para>A glance container format that indicates that no container exists for the VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>Bexar</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in February of 2011. It included Compute (nova) and Object Storage (swift) only.</para> </glossdef> </glossentry> <glossentry> <glossterm>block device</glossterm> <glossdef> <para>A device that moves data in the form of blocks. These device nodes interface the devices, such as hard disks, CD-ROM drives, flash drives, and other addressable regions of memory.</para> </glossdef> </glossentry> <glossentry> <glossterm>block migration</glossterm> <glossdef> <para>A method of VM live migration used by KVM to evacuate instances from one host to another with very little downtime during a user-initiated switch-over. Does not require shared storage. Supported by nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>bootable disk image</glossterm> <glossdef> <para>A type of VM image that exists as a single, bootable file.</para> </glossdef> </glossentry> <glossentry> <glossterm>builder file</glossterm> <glossdef> <para>Contains configuration information for a swift ring, and is used to re-configure the ring or to recreate it from scratch after a serious failure.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .C. --> <title>C</title> <glossentry> <glossterm>cache pruner</glossterm> <glossdef> <para>An executable program that is used to keep a glance VM image cache at or below its configured maximum size.</para> </glossdef> </glossentry> <glossentry> <glossterm>Cactus</glossterm> <glossdef> <para>An OpenStack grouped release of projects that came out in the spring of 2011. It included Compute (nova), Object Storage (swift), and the Image service (glance).</para> </glossdef> </glossentry> <glossentry> <glossterm>capability</glossterm> <glossdef> <para>Defines resources for a cell, including CPU, storage, and networking. Can apply to the specific services within a cell or a whole cell.</para> </glossdef> </glossentry> <glossentry> <glossterm>capacity cache</glossterm> <glossdef> <para>A table within the nova back-end database that contains the current workload, amount of free RAM, number of VMs running on each host. Used to determine on which VM a host starts.</para> </glossdef> </glossentry> <glossentry> <glossterm>capacity updater</glossterm> <glossdef> <para>A notification driver that monitors VM instances and updates the capacity cache as needed.</para> </glossdef> </glossentry> <glossentry> <glossterm>catalog</glossterm> <glossdef> <para>Contains a list of available API endpoints to a user after they authenticate to keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>catalog service</glossterm> <glossdef> <para>A keystone service that provides a list of available API endpoints to a user after they authenticate to keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>ceilometer</glossterm> <glossdef> <para>An incubated project that provides metering and billing facilities for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell</glossterm> <glossdef> <para>Provides logical partitioning of nova resources in a child and parent relationship. Requests are passed from parent cells to child cells if the parent cannot provide the requested resource.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell forwarding</glossterm> <glossdef> <para>A nova option that allows parent cells to pass resource requests to child cells if the parent cannot provide the requested resource.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell manager</glossterm> <glossdef> <para>The nova component that contains a list of the current capabilities of each host within the cell and routes requests as appropriate.</para> </glossdef> </glossentry> <glossentry> <glossterm>Ceph</glossterm> <glossdef> <para>Massively scalable distributed storage system that consists of an object store, block store, and POSIX-compatible distributed file system. Compatible with OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>CephFS</glossterm> <glossdef> <para>The POSIX-compliant file system provided by Ceph.</para> </glossdef> </glossentry> <glossentry> <glossterm>certificate authority</glossterm> <glossdef> <para>A simple certificate authority provided by nova for cloudpipe VPNs and VM image decryption.</para> </glossdef> </glossentry> <glossentry> <glossterm>chance scheduler</glossterm> <glossdef> <para>A scheduling method used by nova that randomly chooses an available host from the pool.</para> </glossdef> </glossentry> <glossentry> <glossterm>changes-since</glossterm> <glossdef> <para>A nova API parameter that allows you to download changes to the requested item since your last request, instead of downloading a new, fresh set of data and comparing it against the old data.</para> </glossdef> </glossentry> <glossentry> <glossterm>Chef</glossterm> <glossdef> <para>A configuration management tool that supports OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>child cell</glossterm> <glossdef> <para>If a requested resource such as CPU time, disk storage, or memory is not available in the parent cell, the request is forwarded to its associated child cells. If the child cell can fulfill the request, it does. Otherwise, it attempts to pass the request to any of its children.</para> </glossdef> </glossentry> <glossentry> <glossterm>cinder</glossterm> <glossdef> <para>The OpenStack Block Storage service that maintains the block devices that can be attached to virtual machine instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud architect</glossterm> <glossdef> <para>A person who plans, designs, and oversees the creation of clouds.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud controller node</glossterm> <glossdef> <para>A node that runs network, volume, API, scheduler and image services. Each service may be broken out into separate nodes for scalability or availability.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud-init</glossterm> <glossdef> <para>A package commonly installed in VM images that performs initialization of an instance after boot using information that it retrieves from the metadata service such as the SSH public key and user data.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloudpipe</glossterm> <glossdef> <para>A service in nova used to create VPNs on a per-project basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloudpipe image</glossterm> <glossdef> <para>A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN running on Linux.</para> </glossdef> </glossentry> <glossentry> <glossterm>command filter</glossterm> <glossdef> <para>Lists allowed commands within the nova rootwrap facility.</para> </glossdef> </glossentry> <glossentry> <glossterm>community project</glossterm> <glossdef> <para>A project that is not officially endorsed by the OpenStack Foundation. If the project is successful enough, it might be elevated to an incubated project and then to a core project, or it might be merged with the main code trunk.</para> </glossdef> </glossentry> <glossentry> <glossterm>Compute API</glossterm> <glossdef> <para>The nova-api daemon that provides access to the nova services. Can also communicate with some outside APIs such as the Amazons EC2 API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Compute API extension</glossterm> <glossdef> <para>Alternative term for a nova API extension.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute controller</glossterm> <glossdef> <para>The nova component that chooses suitable hosts on which to start VM instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute node</glossterm> <glossdef> <para>A node that runs the nova-compute daemon and the virtual machine instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute service</glossterm> <glossdef> <para>Alternative term for the nova component that manages VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>concatenated object</glossterm> <glossdef> <para>A segmented large object within swift that is put back together again and then sent to the client.</para> </glossdef> </glossentry> <glossentry> <glossterm>consistency window</glossterm> <glossdef> <para>The amount of time it takes for a new swift object to become accessible to all clients.</para> </glossdef> </glossentry> <glossentry> <glossterm>console log</glossterm> <glossdef> <para>Contains the output from a Linux VM console in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>container</glossterm> <glossdef> <para>Used to organize and store objects within swift, similar to the concept as a Linux directory but cannot be nested. Alternative term for a glance container format.</para> </glossdef> </glossentry> <glossentry> <glossterm>container auditor</glossterm> <glossdef> <para>Checks for missing replicas or incorrect objects in the specified swift containers through queries to the SQLite back-end database.</para> </glossdef> </glossentry> <glossentry> <glossterm>container database</glossterm> <glossdef> <para>A SQLite database that contains swift containers and related metadata and is accessed by the container server</para> </glossdef> </glossentry> <glossentry> <glossterm>container format</glossterm> <glossdef> <para>The ""envelope"" used by glance to store a VM image and its associated metadata, such as machine state, OS disk size, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>container server</glossterm> <glossdef> <para>Component of swift that manages containers.</para> </glossdef> </glossentry> <glossentry> <glossterm>container service</glossterm> <glossdef> <para>The swift component that provides container services, such as create, delete, list, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>controller node</glossterm> <glossdef> <para>Alternative term for a cloud controller node.</para> </glossdef> </glossentry> <glossentry> <glossterm>core API</glossterm> <glossdef> <para>Depending on context, the core API is either the OpenStack API or the main API of a specific core project, such as nova, neutron, glance, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>core project</glossterm> <glossdef> <para>An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image Service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Volume (cinder).</para> </glossdef> </glossentry> <glossentry> <glossterm>credentials</glossterm> <glossdef> <para>Data that is only known to or accessible by a user that is used to verify the user is who they say they are and presented to the server during authentication. Examples include a password, secret key, digital certificate, fingerprint, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>Crowbar</glossterm> <glossdef> <para>An open source community project by Dell that aims to provide all necessary services to quickly deploy clouds.</para> </glossdef> </glossentry> <glossentry> <glossterm>current workload</glossterm> <glossdef> <para>An element of the nova capacity cache that is calculated based on the number of build, snapshot, migrate, and resize operations currently in progress on a given host.</para> </glossdef> </glossentry> <glossentry> <glossterm>customization module</glossterm> <glossdef> <para>A user-created Python module that is loaded by horizon to change the look and feel of the dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .D. --> <title>D</title> <glossentry> <glossterm>dashboard</glossterm> <glossdef> <para>The web-based management interface for OpenStack. An alternative name for horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>database replicator</glossterm> <glossdef> <para>The component of swift that copies changes in the account, container, and object databases to other nodes.</para> </glossdef> </glossentry> <glossentry> <glossterm>default panel</glossterm> <glossdef> <para>The panel that is displayed when a user accesses the horizon dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm>default tenant</glossterm> <glossdef> <para>New users are assigned to this keystone tenant if no tenant is specified when a user is created.</para> </glossdef> </glossentry> <glossentry> <glossterm>default token</glossterm> <glossdef> <para>A keystone token that is not associated with a specific tenant and is exchanged for a scoped token.</para> </glossdef> </glossentry> <glossentry> <glossterm>delayed delete</glossterm> <glossdef> <para>An option within glance so that rather than immediately delete an image, it is deleted after a pre-defined number of seconds.</para> </glossdef> </glossentry> <glossentry> <glossterm>delivery mode</glossterm> <glossdef> <para>Setting for the nova RabbitMQ message delivery mode, can be set to either transient or persistent.</para> </glossdef> </glossentry> <glossentry> <glossterm>device</glossterm> <glossdef> <para>In the context of swift this refers to the underlying storage device.</para> </glossdef> </glossentry> <glossentry> <glossterm>device ID</glossterm> <glossdef> <para>Maps swift partitions to physical storage devices.</para> </glossdef> </glossentry> <glossentry> <glossterm>device weight</glossterm> <glossdef> <para>Used to distribute the partitions among swift devices. The distribution is usually proportional to the storage capacity of the device.</para> </glossdef> </glossentry> <glossentry> <glossterm>DevStack</glossterm> <glossdef> <para>Community project that uses shell scripts to quickly deploy complete OpenStack development environments.</para> </glossdef> </glossentry> <glossentry> <glossterm>Diablo</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in the fall of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image service (glance).</para> </glossdef> </glossentry> <glossentry> <glossterm>disk format</glossterm> <glossdef> <para>The underlying format that a disk image for a VM is stored as within the glance back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>dispersion</glossterm> <glossdef> <para>In swift, tools to test and ensure dispersion of objects and containers to ensure fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Django</glossterm> <glossdef> <para>A web framework used extensively in horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>dnsmasq</glossterm> <glossdef> <para>Daemon that provides DNS, DHCP, BOOTP, and TFTP services, used by the nova VLAN manager and FlatDHCP manager.</para> </glossdef> </glossentry> <glossentry> <glossterm>DNS record</glossterm> <glossdef> <para>A record that specifies information about a particular domain and belongs to the domain.</para> </glossdef> </glossentry> <glossentry> <glossterm>Dynamic Host Configuration Protocol <glossdef> <para>A method to automatically configure networking for a host at boot time. Provided by both neutron and nova.</para> </glossdef> </glossentry> <!-- .E. --> <title>E</title> <glossentry> <glossterm>ebtables</glossterm> <glossdef> <para>Used in nova along with arptables, iptables, and ip6tables to create firewalls and to ensure isolation of network communications.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2</glossterm> <glossdef> <para>The Amazon Elastic Compute Cloud, a public cloud run by Amazon that provides similar functionality to nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 access key</glossterm> <glossdef> <para>Used along with an EC2 secret key to access the nova EC2 API.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 API</glossterm> <glossdef> <para>OpenStack supports accessing the Amazon EC2 API through nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 Compatibility API</glossterm> <glossdef> <para>A nova component that allows OpenStack to communicate with Amazon EC2</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 secret key</glossterm> <glossdef> <para>Used along with an EC2 access key when communicating with the nova EC2 API, is used to digitally sign each request.</para> </glossdef> </glossentry> <glossentry> <glossterm>Elastic Block Storage (EBS)</glossterm> <glossdef> <para>The Amazon commercial block storage product, similar to cinder.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint</glossterm> <glossdef> <para>See API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint registry</glossterm> <glossdef> <para>Alternative term for a keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint template</glossterm> <glossdef> <para>A list of URL and port number endpoints that indicate where a service, such as object storage, compute, identity, and so on, can be accessed.</para> </glossdef> </glossentry> <glossentry> <glossterm>entity</glossterm> <glossdef> <para>Any piece of hardware or software that wants to connect to the network services provided by neutron, the Network Connectivity service. An entity can make use of neutron by implementing a VIF.</para> </glossdef> </glossentry> <glossentry> <glossterm>ephemeral storage</glossterm> <glossdef> <para>A storage volume attached to a virtual machine instance that does not persist after the instance is terminated.</para> </glossdef> </glossentry> <glossentry> <glossterm>Essex</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in April 2012, the fifth release of OpenStack. It included Compute (nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and Dashboard (horizon).</para> </glossdef> </glossentry> <glossentry> <glossterm>ESX</glossterm> <glossdef> <para>An OpenStack-supported hypervisor, owned by VMware.</para> </glossdef> </glossentry> <glossentry> <glossterm>ESXi</glossterm> <glossdef> <para>An OpenStack-supported hypervisor, owned by VMware.</para> </glossdef> </glossentry> <glossentry> <glossterm>ETag</glossterm> <glossdef> <para>MD5 hash of an object within swift, used to ensure data integrity.</para> </glossdef> </glossentry> <glossentry> <glossterm>euca2ools</glossterm> <glossdef> <para>A collection of command line tools for administering VMs, most are compatible with OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>evacuate</glossterm> <glossdef> <para>The process of migrating one or all virtual machine (VM) instances from one host to another, compatible with both shared storage live migration and block migration.</para> </glossdef> </glossentry> <glossentry> <glossterm>extension</glossterm> <glossdef> <para>Alternative term for a nova API extension or plug-in. In the context of keystone this is a call that is specific to the implementation, such as adding support for OpenID.</para> </glossdef> </glossentry> <glossentry> <glossterm>extra specs</glossterm> <glossdef> <para>Additional requirements that a user can specify when requesting a new instance, examples include a minimum amount of network bandwidth or a GPU.</para> </glossdef> </glossentry> <!-- .F. --> <title>F</title> <glossentry> <glossterm>FakeLDAP</glossterm> <glossdef> <para>An easy method to create a local LDAP directory for testing keystone and nova. Requires Redis.</para> </glossdef> </glossentry> <glossentry> <glossterm>fill-first scheduler</glossterm> <glossdef> <para>The nova scheduling method that attempts to fill a host with VMs rather than starting new VMs on a variety of hosts.</para> </glossdef> </glossentry> <glossentry> <glossterm>filter</glossterm> <glossdef> <para>The step of the nova scheduling process where hosts that cannot run the VMs are eliminated and are not chosen.</para> </glossdef> </glossentry> <glossentry> <glossterm>firewall</glossterm> <glossdef> <para>Used to restrict communications between hosts and/or nodes, implemented in nova using iptables, arptables, ip6tables and etables.</para> </glossdef> </glossentry> <glossentry> <glossterm>Fixed IP address</glossterm> <glossdef> <para>An IP address that is associated with the same instance each time that instance boots, generally not accessible to end users or the public internet, used for management of the instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>FlatDHCP Manager</glossterm> <glossdef> <para>A nova networking manager that provides a single Layer 2 domain for all subnets in the OpenStack cloud. Provides a single DHCP server for each instance of nova-network to assign and manage IP addresses for all instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>Flat Manager</glossterm> <glossdef> <para>The nova component that gives IP addresses to authorized nodes and assumes DHCP, DNS, and routing configuration and services are provided by something else.</para> </glossdef> </glossentry> <glossentry> <glossterm>flat mode injection</glossterm> <glossdef> <para>A nova networking method where the OS network configuration information is injected into the VM (VM) image before the instance starts.</para> </glossdef> </glossentry> <glossentry> <glossterm>flat network</glossterm> <glossdef> <para>A nova network configuration where all of the instances have IP addresses on the same subnet. Flat networks do not use VLANs.</para> </glossdef> </glossentry> <glossentry> <glossterm>flavor</glossterm> <glossdef> <para>Describes the parameters of the various virtual machine images that are available to users, includes parameters such as CPU, storage, and memory. Also known as instance type.</para> </glossdef> </glossentry> <glossentry> <glossterm>flavor ID</glossterm> <glossdef> <para>UUID for each nova or glance VM flavor or instance type.</para> </glossdef> </glossentry> <glossentry> <glossterm>Floating IP address</glossterm> <glossdef> <para>An IP address that a nova project can associate with a VM so the instance has the same public IP address each time that it boots. You create a pool of floating IP addresses and assign them to instances as they are launched to maintain a consistent IP address for maintaining DNS assignment.</para> </glossdef> </glossentry> <glossentry> <glossterm>Folsom</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in the fall of 2012, the sixth release of OpenStack. It includes Compute (nova), Object Storage (swift), Identity (keystone), Networking (neutron), Image service (glance) and Volumes or Block Storage (cinder).</para> </glossdef> </glossentry> <glossentry> <glossterm>FormPost</glossterm> <glossdef> <para>swift middleware that allows users to upload (post) an image through a form on a web page.</para> </glossdef> </glossentry> <!-- .G. --> <title>G</title> <glossentry> <glossterm>glance</glossterm> <glossdef> <para>A core project that provides the OpenStack Image Service.</para> </glossdef> </glossentry> <glossentry> <glossterm>glance API server</glossterm> <glossdef> <para>Processes client requests for VMs, updates glance metadata on the registry server, and communicates with the store adapter to upload VM images from the back-end store.</para> </glossdef> </glossentry> <glossentry> <glossterm>global endpoint template</glossterm> <glossdef> <para>The keystone endpoint template that contains services available to all tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>GlusterFS</glossterm> <glossdef> <para>An open-source, distributed, shared file system,</para> </glossdef> </glossentry> <glossentry> <glossterm>Grizzly</glossterm> <glossdef> <para>Project name for the seventh release of OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>guest OS</glossterm> <glossdef> <para>An operating system instance running under the control of a hypervisor.</para> </glossdef> </glossentry> <!-- .H. --> <title>H</title> <glossentry> <glossterm>handover</glossterm> <glossdef> <para>An object state in swift where a new replica of the object is automatically created due to a drive failure.</para> </glossdef> </glossentry> <glossentry> <glossterm>hard reboot</glossterm> <glossdef> <para>A type of reboot where a physical or virtual power button is pressed as opposed to a graceful, proper shutdown of the operating system.</para> </glossdef> </glossentry> <glossentry> <glossterm>Havana</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm>Heat</glossterm> <glossdef> <para>An integrated project that aims to orchestrate multiple cloud applications for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>horizon</glossterm> <glossdef> <para>The project that provides the OpenStack Dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm>host</glossterm> <glossdef> <para>A physical computer, also known as a node. Contrast with: instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>host aggregate</glossterm> <glossdef> <para>A method to further subdivide availability zones into a collection of hosts.</para> </glossdef> </glossentry> <glossentry> <glossterm>Hyper-V</glossterm> <glossdef> <para>One of the hypervisors supported by OpenStack, developed by Microsoft.</para> </glossdef> </glossentry> <glossentry> <glossterm>hypervisor</glossterm> <glossdef> <para>Software that arbitrates and controls VM access to the actual underlying hardware.</para> </glossdef> </glossentry> <glossentry> <glossterm>hypervisor pool</glossterm> <glossdef> <para>A collection of hypervisors grouped together through host aggregates.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .I. --> <title>I</title> <glossentry> <glossterm>Icehouse</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm>ID number</glossterm> <glossdef> <para>Unique numeric ID associated with each user in keystone, conceptually similar to a Linux or LDAP UID.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity API</glossterm> <glossdef> <para>Alternative term for the Identity Service API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity back-end</glossterm> <glossdef> <para>The source used by keystone to retrieve user information an OpenLDAP server for example.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity Service</glossterm> <glossdef> <para>Provides authentication services, also known as keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity Service API</glossterm> <glossdef> <para>The API used to access the OpenStack Identity Service provided through keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>image</glossterm> <glossdef> <para>A collection of files for a specific operating system (OS) that you use to create or rebuild a server. You can also create custom images, or snapshots, from servers that you have launched.</para> </glossdef> </glossentry> <glossentry> <glossterm>Image API</glossterm> <glossdef> <para>The glance API endpoint for management of VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>image cache</glossterm> <glossdef> <para>Used by glance to allow images on the local host to be used rather than re-downloading them from the image server each time one is requested.</para> </glossdef> </glossentry> <glossentry> <glossterm>image ID</glossterm> <glossdef> <para>Combination of URI and UUID used to access glance VM images through the image API.</para> </glossdef> </glossentry> <glossentry> <glossterm>image membership</glossterm> <glossdef> <para>A list of tenants that can access a given VM image within glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>image owner</glossterm> <glossdef> <para>The keystone tenant who owns a glance virtual machine image.</para> </glossdef> </glossentry> <glossentry> <glossterm>image registry</glossterm> <glossdef> <para>A list of VM images that are available through glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Image Service API</glossterm> <glossdef> <para>Alternative name for the glance image API.</para> </glossdef> </glossentry> <glossentry> <glossterm>image status</glossterm> <glossdef> <para>The current status of a VM image in glance, not to be confused with the status of a running instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>image store</glossterm> <glossdef> <para>The back-end store used by glance to store VM images, options include swift, local file system, S3, or HTTP.</para> </glossdef> </glossentry> <glossentry> <glossterm>image UUID</glossterm> <glossdef> <para>The UUID used by glance to uniquely identify each VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>incubated project</glossterm> <glossdef> <para>A community project may be elevated to this status and is then promoted to a core project.</para> </glossdef> </glossentry> <glossentry> <glossterm>ingress filtering</glossterm> <glossdef> <para>The process of filtering incoming network traffic. Supported by nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>injection</glossterm> <glossdef> <para>The process of putting a file into a virtual machine image before the instance is started.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance</glossterm> <glossdef> <para>A running VM, or a VM in a known state such as suspended that can be used like a hardware server.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance ID</glossterm> <glossdef> <para>Unique ID that is specific to each running nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance state</glossterm> <glossdef> <para>The current state of a nova VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance type</glossterm> <glossdef> <para>Alternative term for flavor.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance type ID</glossterm> <glossdef> <para>Alternative term for a flavor ID.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance UUID</glossterm> <glossdef> <para>Unique ID assigned to each nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>interface ID</glossterm> <glossdef> <para>Unique ID for a neutron VIF or vNIC in the form of a UUID.</para> </glossdef> </glossentry> <glossentry> <glossterm>ip6tables</glossterm> <glossdef> <para>Used along with arptables, ebtables, and iptables to create firewalls in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>iptables</glossterm> <glossdef> <para>Used along with arptables, ebtables, and ip6tables to create firewalls in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .J. --> <title>J</title> <glossentry> <glossterm>JavaScript Object Notation <glossdef> <para>One of the supported response formats for the OpenStack API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Jenkins</glossterm> <glossdef> <para>Tool used for OpenStack development to run jobs automatically.</para> </glossdef> </glossentry> <glossentry> <glossterm>Juno</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .K. --> <title>K</title> <glossentry> <glossterm>kernel-based VM (KVM)</glossterm> <glossdef> <para>An OpenStack-supported hypervisor</para> </glossdef> </glossentry> <glossentry> <glossterm>keystone</glossterm> <glossdef> <para>The project that provides OpenStack Identity services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Kickstart</glossterm> <glossdef> <para>A tool to automate system configuration and installation on Red Hat, Fedora, and CentOS based Linux distributions.</para> </glossdef> </glossentry> <!-- .L. --> <title>L</title> <glossentry> <glossterm>large object</glossterm> <glossdef> <para>An object within swift that is larger than 5 GBs.</para> </glossdef> </glossentry> <glossentry> <glossterm>Launchpad</glossterm> <glossdef> <para>The collaboration site for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>Layer-2 network</glossterm> <glossdef> <para>Term used for OSI network architecture for the data link layer.</para> </glossdef> </glossentry> <glossentry> <glossterm>libvirt</glossterm> <glossdef> <para>Virtualization API library used by OpenStack to interact with many of its supported hypervisors, including KVM, QEMU and LXC.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux bridge</glossterm> <glossdef> <para>Software used to allow multiple VMs to share a single physical NIC within nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux bridge neutron plug-in</glossterm> <glossdef> <para>Plugin that allows a Linux bridge to understand a neutron port, interface attachment, and other abstractions.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux containers (LXC)</glossterm> <glossdef> <para>An OpenStack-supported hypervisor.</para> </glossdef> </glossentry> <glossentry> <glossterm>live migration</glossterm> <glossdef> <para>The ability within nova to move running virtual machine instances from one host to another with only a small service interruption during switch-over.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .M. --> <title>M</title> <glossentry> <glossterm>management API</glossterm> <glossdef> <para>Alternative term for an admin API.</para> </glossdef> </glossentry> <glossentry> <glossterm>management network</glossterm> <glossdef> <para>A network segment used for administration, not accessible to the public internet.</para> </glossdef> </glossentry> <glossentry> <glossterm>manifest</glossterm> <glossdef> <para>Used to track segments of a large object within swift.</para> </glossdef> </glossentry> <glossentry> <glossterm>manifest object</glossterm> <glossdef> <para>A special swift object that contains the manifest for a large object.</para> </glossdef> </glossentry> <glossentry> <glossterm>membership</glossterm> <glossdef> <para>The association between a glance VM image and a tenant, allows images to be shared with specified tenant(s).</para> </glossdef> </glossentry> <glossentry> <glossterm>membership list</glossterm> <glossdef> <para>Contains a list of tenants that can access a given VM image within glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>memory overcommit</glossterm> <glossdef> <para>The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as RAM overcommit.</para> </glossdef> </glossentry> <glossentry> <glossterm>message broker</glossterm> <glossdef> <para>The software package used to provide AMQP messaging capabilities within nova, default is RabbitMQ.</para> </glossdef> </glossentry> <glossentry> <glossterm>message bus</glossterm> <glossdef> <para>The main virtual communication line used by all AMQP messages for inter-cloud communications within nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>message queue</glossterm> <glossdef> <para>Passes requests from clients to the appropriate workers and returns the output to the client once the job is complete.</para> </glossdef> </glossentry> <glossentry> <glossterm>migration</glossterm> <glossdef> <para>The process of moving a VM instance from one host to another.</para> </glossdef> </glossentry> <glossentry> <glossterm>multinic</glossterm> <glossdef> <para>Facility in nova that allows each virtual machine instance to have more than one VIF connected to it.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .N. --> <title>N</title> <glossentry> <glossterm>network ID</glossterm> <glossdef> <para>Unique ID assigned to each network segment within neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>network manager</glossterm> <glossdef> <para>The nova component that manages various network components, such as firewall rules, IP address allocation, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>network node</glossterm> <glossdef> <para>Any nova node that runs the network worker daemon.</para> </glossdef> </glossentry> <glossentry> <glossterm>network segment</glossterm> <glossdef> <para>Represents a virtual, isolated OSI layer 2 subnet in neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>network UUID</glossterm> <glossdef> <para>Unique ID for a neutron network segment.</para> </glossdef> </glossentry> <glossentry> <glossterm>network worker</glossterm> <glossdef> <para>The nova-network worker daemon, provides services such as giving an IP address to a booting nova instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>non-persistent volume</glossterm> <glossdef> <para>Alternative term for an ephemeral volume.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova</glossterm> <glossdef> <para>The OpenStack project that provides compute services.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova API</glossterm> <glossdef> <para>Alternative term for the nova Compute API.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova-network</glossterm> <glossdef> <para>A nova component that manages IP address allocation, firewalls, and other network-related tasks.</para> </glossdef> </glossentry> <!-- .O. --> <title>O</title> <glossentry> <glossterm>object</glossterm> <glossdef> <para>A BLOB of data held by swift, can be in any format.</para> </glossdef> </glossentry> <glossentry> <glossterm>Object API</glossterm> <glossdef> <para>Alternative term for the swift object API.</para> </glossdef> </glossentry> <glossentry> <glossterm>object auditor</glossterm> <glossdef> <para>Opens all objects for an object server and verifies the MD5 hash, size, and metadata for each object.</para> </glossdef> </glossentry> <glossentry> <glossterm>object expiration</glossterm> <glossdef> <para>A configurable option within swift to automatically delete objects after a specified amount of time has passed or a certain date is reached.</para> </glossdef> </glossentry> <glossentry> <glossterm>object hash</glossterm> <glossdef> <para>Uniquely ID for a swift object.</para> </glossdef> </glossentry> <glossentry> <glossterm>object path hash</glossterm> <glossdef> <para>Used by swift to determine the location of an object in the ring. Maps objects to partitions.</para> </glossdef> </glossentry> <glossentry> <glossterm>object replicator</glossterm> <glossdef> <para>Component of swift that copies and object to remote partitions for fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>object server</glossterm> <glossdef> <para>Component of swift that is responsible for managing objects.</para> </glossdef> </glossentry> <glossentry> <glossterm>Object Service API</glossterm> <glossdef> <para>Alternative term for the swift object API.</para> </glossdef> </glossentry> <glossentry> <glossterm>object storage</glossterm> <glossdef> <para>Provides eventually consistent and redundant storage and retrieval of fixed digital content.</para> </glossdef> </glossentry> <glossentry> <glossterm>object versioning</glossterm> <glossdef> <para>Allows a user to set a flag on a swift container so all objects within the container are versioned.</para> </glossdef> </glossentry> <glossentry> <glossterm>operator</glossterm> <glossdef> <para>The person responsible for planning and maintaining an OpenStack installation.</para> </glossdef> </glossentry> <!-- .P. --> <title>P</title> <glossentry> <glossterm>parent cell</glossterm> <glossdef> <para>If a requested resource, such as CPU time, disk storage, or memory, is not available in the parent cell, the request is forwarded to associated child cells.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition</glossterm> <glossdef> <para>A unit of storage within swift used to store objects, exists on top of devices, replicated for fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition index</glossterm> <glossdef> <para>Contains the locations of all swift partitions within the ring.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition shift value</glossterm> <glossdef> <para>Used by swift to determine which partition data should reside on.</para> </glossdef> </glossentry> <glossentry> <glossterm>pause</glossterm> <glossdef> <para>A VM state where no changes occur (no changes in memory, network communications stop, etc), the VM is frozen but not shut down.</para> </glossdef> </glossentry> <glossentry> <glossterm>persistent volume</glossterm> <glossdef> <para>Disk volumes that persist beyond the lifetime of individual virtual machine instances. Contrast with: ephemeral storage</para> </glossdef> </glossentry> <glossentry> <glossterm>plugin</glossterm> <glossdef> <para>Software component providing the actual implementation for neutron APIs, or for Compute APIs, depending on the context.</para> </glossdef> </glossentry> <glossentry> <glossterm>policy service</glossterm> <glossdef> <para>Component of keystone that provides a rule management interface and a rule based authorization engine.</para> </glossdef> </glossentry> <glossentry> <glossterm>port</glossterm> <glossdef> <para>A virtual network port within neutron, VIFs / vNICs are connected to a port.</para> </glossdef> </glossentry> <glossentry> <glossterm>port UUID</glossterm> <glossdef> <para>Unique ID for a neutron port.</para> </glossdef> </glossentry> <glossentry> <glossterm>preseed</glossterm> <glossdef> <para>A tool to automate system configuration and installation on Debian based Linux distributions.</para> </glossdef> </glossentry> <glossentry> <glossterm>private image</glossterm> <glossdef> <para>A glance VM image that is only available to specified tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>project</glossterm> <glossdef> <para>A logical grouping of users within nova, used to define quotas and access to VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>project ID</glossterm> <glossdef> <para>User defined alpha-numeric string in nova, the name of a project.</para> </glossdef> </glossentry> <glossentry> <glossterm>project VPN</glossterm> <glossdef> <para>Alternative term for a cloudpipe.</para> </glossdef> </glossentry> <glossentry> <glossterm>proxy node</glossterm> <glossdef> <para>A node that provides the swift proxy service.</para> </glossdef> </glossentry> <glossentry> <glossterm>proxy server</glossterm> <glossdef> <para>Users of swift interact with the service through the proxy server which in-turn looks up the location of the requested data within the ring and returns the results to the user.</para> </glossdef> </glossentry> <glossentry> <glossterm>public API</glossterm> <glossdef> <para>An API endpoint used for both service to service communication and end user interactions.</para> </glossdef> </glossentry> <glossentry> <glossterm>public image</glossterm> <glossdef> <para>A glance VM image that is available to all tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>public IP address</glossterm> <glossdef> <para>An IP address that is accessible to end-users.</para> </glossdef> </glossentry> <glossentry> <glossterm>public network</glossterm> <glossdef> <para>The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. The public network interface is controlled by the public_interface option.</para> </glossdef> </glossentry> <glossentry> <glossterm>Puppet</glossterm> <glossdef> <para>A configuration management tool that supports OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>Python</glossterm> <glossdef> <para>Programming language used extensively in OpenStack.</para> </glossdef> </glossentry> <!-- .Q. --> <title>Q</title> <glossentry> <glossterm>neutron</glossterm> <glossdef> <para>A core OpenStack project that provides a network connectivity abstraction layer to OpenStack Compute.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron API</glossterm> <glossdef> <para>API used to access neutron, provides and extensible architecture to allow custom plugin creation.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron manager</glossterm> <glossdef> <para>Allows nova and neutron integration thus allowing neutron to perform network management for nova VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron plugin</glossterm> <glossdef> <para>Interface within neutron that allows organizations to create custom plugins for advanced features such as QoS, ACLs, or IDS.</para> </glossdef> </glossentry> <glossentry> <glossterm>quarantine</glossterm> <glossdef> <para>If swift finds objects, containers, or accounts that are corrupt they are placed in this state, are not replicated, cannot be read by clients, and a correct copy is re-replicated.</para> </glossdef> </glossentry> <glossentry> <glossterm>Quick EMUlator (QEMU)</glossterm> <glossdef> <para>One of the hypervisors supported by OpenStack, generally used for development purposes.</para> </glossdef> </glossentry> <glossentry> <glossterm>quota</glossterm> <glossdef> <para>In nova, the ability to set resource limits on a per-project basis.</para> </glossdef> </glossentry> <!-- .R. --> <title>R</title> <glossentry> <glossterm>RAM filter</glossterm> <glossdef> <para>The nova setting that allows or disallows RAM overcommitment.</para> </glossdef> </glossentry> <glossentry> <glossterm>RAM overcommit</glossterm> <glossdef> <para>The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as memory overcommit.</para> </glossdef> </glossentry> <glossentry> <glossterm>rate limit</glossterm> <glossdef> <para>Configurable option within swift to limit database writes on a per-account and/or per-container basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>rebalance</glossterm> <glossdef> <para>The process of distributing swift partitions across all drives in the ring, used during initial ring creation and after ring reconfiguration.</para> </glossdef> </glossentry> <glossentry> <glossterm>Recon</glossterm> <glossdef> <para>A component of swift used to collect metrics.</para> </glossdef> </glossentry> <glossentry> <glossterm>record ID</glossterm> <glossdef> <para>A number within a database that is incremented each time a change is made. Used by swift when replicating.</para> </glossdef> </glossentry> <glossentry> <glossterm>registry server</glossterm> <glossdef> <para>A glance service that provides VM image metadata information to clients.</para> </glossdef> </glossentry> <glossentry> <glossterm>replica</glossterm> <glossdef> <para>Provides data redundancy and fault tolerance by creating copies of swift objects, accounts, and containers so they are not lost when the underlying storage fails.</para> </glossdef> </glossentry> <glossentry> <glossterm>replica count</glossterm> <glossdef> <para>The number of replicas of the data in a swift ring.</para> </glossdef> </glossentry> <glossentry> <glossterm>replication</glossterm> <glossdef> <para>The process of copying data to a separate physical device for fault tolerance and performance.</para> </glossdef> </glossentry> <glossentry> <glossterm>replicator</glossterm> <glossdef> <para>The swift back-end process that creates and manages object replicas.</para> </glossdef> </glossentry> <glossentry> <glossterm>request ID</glossterm> <glossdef> <para>Unique ID assigned to each request sent to nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>ring</glossterm> <glossdef> <para>An entity that maps swift data to partitions. A separate ring exists for each service, such as account, object, and container.</para> </glossdef> </glossentry> <glossentry> <glossterm>ring builder</glossterm> <glossdef> <para>Builds and manages rings within swift, assigns partitions to devices, and pushes the configuration to other storage nodes.</para> </glossdef> </glossentry> <glossentry> <glossterm>role ID</glossterm> <glossdef> <para>Alpha-numeric ID assigned to each keystone role.</para> </glossdef> </glossentry> <glossentry> <glossterm>rootwrap</glossterm> <glossdef> <para>A feature of nova that allows the unprivileged ""nova"" user to run a specified list of commands as the Linux root user.</para> </glossdef> </glossentry> <glossentry> <glossterm>RPC driver</glossterm> <glossdef> <para>Modular system that allows the nova underlying message queue software to be changed. For example, from RabbitMQ to ZeroMQ or Qpid.</para> </glossdef> </glossentry> <!-- .S. --> <title>S</title> <glossentry> <glossterm>S3</glossterm> <glossdef> <para>Object storage service by Amazon, similar in function to swift, can act as a back-end store for glance VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>scheduler manager</glossterm> <glossdef> <para>A nova component that determines where VM instances should start. Uses modular design to support a variety of scheduler types.</para> </glossdef> </glossentry> <glossentry> <glossterm>scoped token</glossterm> <glossdef> <para>A keystone API access token that is associated with a specific tenant.</para> </glossdef> </glossentry> <glossentry> <glossterm>secret key</glossterm> <glossdef> <para>String of text only known by the user, used along with an access key to make requests to the nova API.</para> </glossdef> </glossentry> <glossentry> <glossterm>security group</glossterm> <glossdef> <para>A set of network traffic filtering rules that are applied to a nova instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>segmented object</glossterm> <glossdef> <para>A swift large object that has been broken up into pieces, the re-assembled object is called a concatenated object.</para> </glossdef> </glossentry> <glossentry> <glossterm>server image</glossterm> <glossdef> <para>Alternative term for a VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>server UUID</glossterm> <glossdef> <para>Unique ID assigned to each nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>service catalog</glossterm> <glossdef> <para>Alternative term for the keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service ID</glossterm> <glossdef> <para>Unique ID assigned to each service that is available in the keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service registration</glossterm> <glossdef> <para>A keystone feature that allows services such as nova to automatically register with the catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service tenant</glossterm> <glossdef> <para>Special keystone tenant that contains all services that are listed in the catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service token</glossterm> <glossdef> <para>An administrator defined token used by nova to communicate securely with keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>session back-end</glossterm> <glossdef> <para>The method of storage used by horizon to track client sessions such as local memory, cookies, a database, or memcached.</para> </glossdef> </glossentry> <glossentry> <glossterm>session persistence</glossterm> <glossdef> <para>A feature of the load balancing service. It attempts to force subsequent connections to a service to be redirected to the same node as long as it is online.</para> </glossdef> </glossentry> <glossentry> <glossterm>session storage</glossterm> <glossdef> <para>A horizon component that stores and tracks client session information. Implemented through the Django sessions framework.</para> </glossdef> </glossentry> <glossentry> <glossterm>shared storage</glossterm> <glossdef> <para>Block storage that is simultaneously accessible by multiple clients. For example, NFS.</para> </glossdef> </glossentry> <glossentry> <glossterm>SmokeStack</glossterm> <glossdef> <para>Runs automated tests against the core OpenStack API, written in Rails.</para> </glossdef> </glossentry> <glossentry> <glossterm>snapshot</glossterm> <glossdef> <para>A point-in-time copy of an OpenStack storage volume or image. Use storage volume snapshots to back up volumes. Use image snapshots to back up data, or as ""gold"" images for additional servers.</para> </glossdef> </glossentry> <glossentry> <glossterm>spread-first scheduler</glossterm> <glossdef> <para>The nova VM scheduling algorithm that attempts to start new VM on the host with the least amount of load.</para> </glossdef> </glossentry> <glossentry> <glossterm>SQLAlchemy</glossterm> <glossdef> <para>An open source SQL toolkit for Python, used in OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>SQLite</glossterm> <glossdef> <para>A lightweight SQL database, used as the default persistent storage method in many OpenStack services.</para> </glossdef> </glossentry> <glossentry> <glossterm>StackTach</glossterm> <glossdef> <para>Community project that captures nova AMQP communications, useful for debugging.</para> </glossdef> </glossentry> <glossentry> <glossterm>static IP address</glossterm> <glossdef> <para>Alternative term for a fixed IP address.</para> </glossdef> </glossentry> <glossentry> <glossterm>StaticWeb</glossterm> <glossdef> <para>WSGI middleware component of swift that serves container data as a static web page.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage back-end</glossterm> <glossdef> <para>The method that a service uses for persistent storage such as iSCSI, NFS, or local disk.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage node</glossterm> <glossdef> <para>A swift node that provides container services, account services, and object services, controls the account databases, container databases, and object storage.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage manager</glossterm> <glossdef> <para>Component of XenAPI that provides a pluggable interface to support a wide variety of persistent storage back-ends.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage manager back-end</glossterm> <glossdef> <para>A persistent storage method supported by XenAPI such as iSCSI or NFS.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage services</glossterm> <glossdef> <para>Collective name for the swift object services, container services, and account services.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift</glossterm> <glossdef> <para>An OpenStack core project that provides object storage services.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift All in One (SAIO)</glossterm> <glossdef> <para>Creates a full swift development environment within a single VM.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift middleware</glossterm> <glossdef> <para>Collective term for components within swift that allows for additional functionality.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift proxy server</glossterm> <glossdef> <para>Acts as the gatekeeper to swift and is responsible for authenticating the user.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift storage node</glossterm> <glossdef> <para>A node that runs swift account, container, and object services.</para> </glossdef> </glossentry> <glossentry> <glossterm>sync point</glossterm> <glossdef> <para>Point in time since the last container and accounts database sync among nodes within swift.</para> </glossdef> </glossentry> <!-- .T. --> <title>T</title> <glossentry> <glossterm>TempAuth</glossterm> <glossdef> <para>An authentication facility within swift that allows swift itself to perform authentication and authorization, frequently used in testing and development.</para> </glossdef> </glossentry> <glossentry> <glossterm>Tempest</glossterm> <glossdef> <para>Automated software test suite designed to run against the trunk of the OpenStack core project.</para> </glossdef> </glossentry> <glossentry> <glossterm>TempURL</glossterm> <glossdef> <para>A swift middleware component that allows a user to create URLs for temporary object access.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant</glossterm> <glossdef> <para>A group of users, used to isolate access to nova resources. An alternative term for a nova project.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant endpoint</glossterm> <glossdef> <para>A keystone API endpoint that is associated with one or more tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant ID</glossterm> <glossdef> <para>Unique ID assigned to each tenant within keystone, the nova project IDs map to the keystone tenant IDs.</para> </glossdef> </glossentry> <glossentry> <glossterm>token</glossterm> <glossdef> <para>An alpha-numeric string of text used to access OpenStack APIs and resources.</para> </glossdef> </glossentry> <glossentry> <glossterm>tombstone</glossterm> <glossdef> <para>Used to mark swift objects that have been deleted, ensures the object is not updated on another node after it has been deleted.</para> </glossdef> </glossentry> <glossentry> <glossterm>transaction ID</glossterm> <glossdef> <para>Unique ID assigned to each swift request, used for debugging and tracing.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <!-- .U. --> <title>U</title> <glossentry> <glossterm>unscoped token</glossterm> <glossdef> <para>Alternative term for a keystone default token.</para> </glossdef> </glossentry> <glossentry> <glossterm>updater</glossterm> <glossdef> <para>Collective term for a group of swift components that process queued and failed updates for containers and objects.</para> </glossdef> </glossentry> <glossentry> <glossterm>user</glossterm> <glossdef> <para>In keystone each user is associated with one or more tenants, and in nova they can be associated with roles, projects, or both.</para> </glossdef> </glossentry> <glossentry> <glossterm>user data</glossterm> <glossdef> <para>A blob of data that can be specified by the user when launching an instance. This data can be accessed by the instance through the metadata service or config drive. Commonly used for passing a shell script that is executed by the instance on boot.</para> </glossdef> </glossentry> <!-- .V. --> <title>V</title> <glossentry> <glossterm>VIF UUID</glossterm> <glossdef> <para>Unique ID assigned to each neutron VIF.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Central Processing Unit <glossdef> <para>Allows physical CPUs to be sub-divided and those divisions are then used by instances. Also known as virtual cores.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Machine (VM)</glossterm> <glossdef> <para>An operating system instance that runs on top of a hypervisor. Multiple VMs can run at the same time on the same physical host.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual network</glossterm> <glossdef> <para>An L2 network segment within neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Network InterFace (VIF)</glossterm> <glossdef> <para>An interface that is plugged into a port in a neutron network. Typically a virtual network interface belonging to a VM.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual port</glossterm> <glossdef> <para>Attachment point where a virtual interface connects to a virtual network.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual private network (VPN)</glossterm> <glossdef> <para>Provided by nova in the form of cloudpipes, specialized instances that are used to create VPNs on a per-project basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual server</glossterm> <glossdef> <para>Alternative term for a VM or guest.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual switch (vSwitch)</glossterm> <glossdef> <para>Software that runs on a host or node and provides the features and functions of a hardware based network switch.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual VLAN</glossterm> <glossdef> <para>Alternative term for a virtual network.</para> </glossdef> </glossentry> <glossentry> <glossterm>VLAN manager</glossterm> <glossdef> <para>A nova networking manager that divides subnet and tenants into different VLANs allowing for Layer 2 segregation. Provides a DHCP server for each VLAN to assign IP addresses for instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>VLAN network</glossterm> <glossdef> <para>The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. A VLAN network is a private network interface, which is controlled by the vlan_interface option with VLAN managers.</para> </glossdef> </glossentry> <glossentry> <glossterm>VM image</glossterm> <glossdef> <para>Alternative term for an image.</para> </glossdef> </glossentry> <glossentry> <glossterm>VNC proxy</glossterm> <glossdef> <para>A nova component that provides users access to the consoles of their VM instances through VNC or VMRC.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume</glossterm> <glossdef> <para>Disk-based data storage generally represented as an iSCSI target with a file system that supports extended attributes, can be persistent or ephemeral. Commonly used as a synonym for block device.</para> </glossdef> </glossentry> <glossentry> <glossterm>Volume API</glossterm> <glossdef> <para>An API on a separate endpoint for attaching, detaching, and creating block storage for compute VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume controller</glossterm> <glossdef> <para>A nova component that oversees and coordinates storage volume actions.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume driver</glossterm> <glossdef> <para>Alternative term for a volume plugin.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume ID</glossterm> <glossdef> <para>Unique ID applied to each storage volume under the nova control.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume manager</glossterm> <glossdef> <para>A nova component that creates, attaches, and detaches persistent storage volumes.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume node</glossterm> <glossdef> <para>A nova node that runs the cinder-volume daemon.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume plugin</glossterm> <glossdef> <para>A plugin for the nova volume manager. Provides support for a new and specialized types of back-end storage.</para> </glossdef> </glossentry> <glossentry> <glossterm>Volume Service API</glossterm> <glossdef> <para>Alternative term for the Block Storage API.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume worker</glossterm> <glossdef> <para>The nova component that interacts with back-end storage to manage the creation and deletion of volumes and the creation of compute volumes, provided by the nova-volume daemon.</para> </glossdef> </glossentry> <!-- .W. --> <title>W</title> <glossentry> <glossterm>weight</glossterm> <glossdef> <para>Used by swift storage devices to determine which storage devices are suitable for the job. Devices are weighted by size.</para> </glossdef> </glossentry> <glossentry> <glossterm>weighted cost</glossterm> <glossdef> <para>The sum of each cost used when deciding where to start a new VM instance in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>weighing</glossterm> <glossdef> <para>A nova process that determines the suitability of the VM instances for a job for a particular host. For example, not enough RAM on the host, too many CPUs on the host, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>worker</glossterm> <glossdef> <para>A daemon that carries out tasks. For example, the nova-volume worker attaches storage to an VM instance. Workers listen to a queue and take action when new messages arrive.</para> </glossdef> </glossentry> <!-- .Z. --> <title>Z</title> <glossentry> <glossterm>Zuul</glossterm> <glossdef> <para>Tool used in OpenStack development to ensure correctly ordered testing of changes in parallel.</para> </glossdef> </glossentry> <!-- ... --> </glossary>"," <title>A</title> <glossentry> <glossterm>account</glossterm> <glossdef> <para>The swift context of an account, or a user account from an identity service such as Active Directory, /etc/passwd, OpenLDAP, keystone, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>account auditor</glossterm> <glossdef> <para>Checks for missing replicas, incorrect, and corrupted objects in a specified swift account by running queries against the back-end SQLite database.</para> </glossdef> </glossentry> <glossentry> <glossterm>account database</glossterm> <glossdef> <para>An SQLite database that contains swift accounts and related metadata and is accessed by the accounts server. Alternately, the keystone back-end which contains accounts.</para> </glossdef> </glossentry> <glossentry> <glossterm>account reaper</glossterm> <glossdef> <para>A swift worker that scans for and deletes account databases that are marked for deletion on an account server.</para> </glossdef> </glossentry> <glossentry> <glossterm>account server</glossterm> <glossdef> <para>Lists containers in swift and stores container information in the account database.</para> </glossdef> </glossentry> <glossentry> <glossterm>account service</glossterm> <glossdef> <para>Component of swift that provides account services such as list, create, modify, and audit. Do not confuse with keystone, OpenLDAP, or similar user account services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Active Directory</glossterm> <glossdef> <para>Authentication and Identity Service by Microsoft, based on LDAP. Supported in </glossdef> </glossentry> <glossentry> <glossterm>address pool</glossterm> <glossdef> <para>A group of fixed and/or floating IP addresses that are assigned to a nova project and can be used by or assigned to the VM instances in a project.</para> </glossdef> </glossentry> <glossentry> <glossterm>admin API</glossterm> <glossdef> <para>A subset of API calls that are accessible to authorized administrators and are generally not accessible to end users or the public internet, can exist as a separate service (keystone) or can be a subset of another API (nova).</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Kernel Image (AKI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Machine Image (AMI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Amazon Ramdisk Image (ARI)</glossterm> <glossdef> <para>Both a VM container format and a VM disk format. Supported by glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Apache</glossterm> <glossdef> <para>The most common web server software currently used on the Internet, known as HTTPd.</para> </glossdef> </glossentry> <glossentry> <glossterm>Apache License 2.0</glossterm> <glossdef> <para>All OpenStack core projects are provided under the terms of the Apache License 2.0 license.</para> </glossdef> </glossentry> <glossentry> <glossterm>API endpoint</glossterm> <glossdef> <para>The daemon, worker, or service that a client communicates with to access an API. In OpenStack, API endpoints can provide services such as authentication, adding images, booting virtual machines, and attaching volumes.</para> </glossdef> </glossentry> <glossentry> <glossterm>API extension</glossterm> <glossdef> <para>A feature of nova and neutron that allows custom modules to extend the core APIs.</para> </glossdef> </glossentry> <glossentry> <glossterm>API extension plug-in</glossterm> <glossdef> <para>Alternative term for a neutron plug-in or neutron API extension.</para> </glossdef> </glossentry> <glossentry> <glossterm>API server</glossterm> <glossdef> <para>Any node running a daemon or worker that provides an API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>API version</glossterm> <glossdef> <para>In OpenStack, a the API version for a project is part of the URL. For example, <code>example.com/nova/v1/foobar</code>.</para> </glossdef> </glossentry> <glossentry> <glossterm>Application Programming Interface (API)</glossterm> <glossdef> <para>A collection of specifications used to access a service, application, or program. Includes service calls, required parameters for each call, and the expected return values.</para> </glossdef> </glossentry> <glossentry> <glossterm>arptables</glossterm> <glossdef> <para>Used along with iptables, ebtables, and ip6tables in nova to provide firewall services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Asynchronous JavaScript and XML (AJAX)</glossterm> <glossdef> <para>A group of interrelated web development techniques used on the client-side to create asynchronous web applications. Used extensively in horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>attachment (network)</glossterm> <glossdef> <para>Association of an interface ID to a logical port. Plugs an interface into a port.</para> </glossdef> </glossentry> <glossentry> <glossterm>auditor</glossterm> <glossdef> <para>A worker process that verifies the integrity of swift objects, containers, and accounts. Auditors is the collective term for the swift account auditor, container auditor, and object auditor.</para> </glossdef> </glossentry> <glossentry> <glossterm>Austin</glossterm> <glossdef> <para>Project name for the initial release of OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>authentication</glossterm> <glossdef> <para>The process that confirms that the user, process, or client is really who they say they are through private key, secret token, password, fingerprint, or similar method. Abbreviated as AuthN.</para> </glossdef> </glossentry> <glossentry> <glossterm>authentication token</glossterm> <glossdef> <para>A string of text provided to the client after authentication. Must be provided by the user or process in subsequent requests to the API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>authorization</glossterm> <glossdef> <para>The act of verifying that a user, process, or client is authorized to perform an action, such as delete a swift object, list a swift container, start a nova VM, reset a password, and so on. Abbreviate as AuthZ.</para> </glossdef> </glossentry> <glossentry> <glossterm>availability zone</glossterm> <glossdef> <para>A segregated area of a cloud deployment.</para> </glossdef> </glossentry> <title>B</title> <glossentry> <glossterm>back-end catalog</glossterm> <glossdef> <para>The storage method used by the keystone catalog service to store and retrieve information about API endpoints that are available to the client. Examples include a SQL database, LDAP database, or KVS back-end.</para> </glossdef> </glossentry> <glossentry> <glossterm>back-end store</glossterm> <glossdef> <para>The persistent data store used that glance uses to retrieve and store VM images. Options include swift, local file system, S3, and HTTP.</para> </glossdef> </glossentry> <glossentry> <glossterm>bare</glossterm> <glossdef> <para>A glance container format that indicates that no container exists for the VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>Bexar</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in February of 2011. It included Compute (nova) and Object Storage (swift) only.</para> </glossdef> </glossentry> <glossentry> <glossterm>block device</glossterm> <glossdef> <para>A device that moves data in the form of blocks. These device nodes interface the devices, such as hard disks, CD-ROM drives, flash drives, and other addressable regions of memory.</para> </glossdef> </glossentry> <glossentry> <glossterm>block migration</glossterm> <glossdef> <para>A method of VM live migration used by KVM to evacuate instances from one host to another with very little downtime during a user-initiated switch-over. Does not require shared storage. Supported by nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>bootable disk image</glossterm> <glossdef> <para>A type of VM image that exists as a single, bootable file.</para> </glossdef> </glossentry> <glossentry> <glossterm>builder file</glossterm> <glossdef> <para>Contains configuration information for a swift ring, and is used to re-configure the ring or to recreate it from scratch after a serious failure.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>C</title> <glossentry> <glossterm>cache pruner</glossterm> <glossdef> <para>An executable program that is used to keep a glance VM image cache at or below its configured maximum size.</para> </glossdef> </glossentry> <glossentry> <glossterm>Cactus</glossterm> <glossdef> <para>An OpenStack grouped release of projects that came out in the spring of 2011. It included Compute (nova), Object Storage (swift), and the Image service (glance).</para> </glossdef> </glossentry> <glossentry> <glossterm>capability</glossterm> <glossdef> <para>Defines resources for a cell, including CPU, storage, and networking. Can apply to the specific services within a cell or a whole cell.</para> </glossdef> </glossentry> <glossentry> <glossterm>capacity cache</glossterm> <glossdef> <para>A table within the nova back-end database that contains the current workload, amount of free RAM, number of VMs running on each host. Used to determine on which VM a host starts.</para> </glossdef> </glossentry> <glossentry> <glossterm>capacity updater</glossterm> <glossdef> <para>A notification driver that monitors VM instances and updates the capacity cache as needed.</para> </glossdef> </glossentry> <glossentry> <glossterm>catalog</glossterm> <glossdef> <para>Contains a list of available API endpoints to a user after they authenticate to keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>catalog service</glossterm> <glossdef> <para>A keystone service that provides a list of available API endpoints to a user after they authenticate to keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>ceilometer</glossterm> <glossdef> <para>An incubated project that provides metering and billing facilities for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell</glossterm> <glossdef> <para>Provides logical partitioning of nova resources in a child and parent relationship. Requests are passed from parent cells to child cells if the parent cannot provide the requested resource.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell forwarding</glossterm> <glossdef> <para>A nova option that allows parent cells to pass resource requests to child cells if the parent cannot provide the requested resource.</para> </glossdef> </glossentry> <glossentry> <glossterm>cell manager</glossterm> <glossdef> <para>The nova component that contains a list of the current capabilities of each host within the cell and routes requests as appropriate.</para> </glossdef> </glossentry> <glossentry> <glossterm>Ceph</glossterm> <glossdef> <para>Massively scalable distributed storage system that consists of an object store, block store, and POSIX-compatible distributed file system. Compatible with OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>CephFS</glossterm> <glossdef> <para>The POSIX-compliant file system provided by Ceph.</para> </glossdef> </glossentry> <glossentry> <glossterm>certificate authority</glossterm> <glossdef> <para>A simple certificate authority provided by nova for cloudpipe VPNs and VM image decryption.</para> </glossdef> </glossentry> <glossentry> <glossterm>chance scheduler</glossterm> <glossdef> <para>A scheduling method used by nova that randomly chooses an available host from the pool.</para> </glossdef> </glossentry> <glossentry> <glossterm>changes-since</glossterm> <glossdef> <para>A nova API parameter that allows you to download changes to the requested item since your last request, instead of downloading a new, fresh set of data and comparing it against the old data.</para> </glossdef> </glossentry> <glossentry> <glossterm>Chef</glossterm> <glossdef> <para>A configuration management tool that supports OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>child cell</glossterm> <glossdef> <para>If a requested resource such as CPU time, disk storage, or memory is not available in the parent cell, the request is forwarded to its associated child cells. If the child cell can fulfill the request, it does. Otherwise, it attempts to pass the request to any of its children.</para> </glossdef> </glossentry> <glossentry> <glossterm>cinder</glossterm> <glossdef> <para>The OpenStack Block Storage service that maintains the block devices that can be attached to virtual machine instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud architect</glossterm> <glossdef> <para>A person who plans, designs, and oversees the creation of clouds.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud controller node</glossterm> <glossdef> <para>A node that runs network, volume, API, scheduler and image services. Each service may be broken out into separate nodes for scalability or availability.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloud-init</glossterm> <glossdef> <para>A package commonly installed in VM images that performs initialization of an instance after boot using information that it retrieves from the metadata service such as the SSH public key and user data.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloudpipe</glossterm> <glossdef> <para>A service in nova used to create VPNs on a per-project basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>cloudpipe image</glossterm> <glossdef> <para>A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN running on Linux.</para> </glossdef> </glossentry> <glossentry> <glossterm>command filter</glossterm> <glossdef> <para>Lists allowed commands within the nova rootwrap facility.</para> </glossdef> </glossentry> <glossentry> <glossterm>community project</glossterm> <glossdef> <para>A project that is not officially endorsed by the OpenStack Foundation. If the project is successful enough, it might be elevated to an incubated project and then to a core project, or it might be merged with the main code trunk.</para> </glossdef> </glossentry> <glossentry> <glossterm>Compute API</glossterm> <glossdef> <para>The nova-api daemon that provides access to the nova services. Can also communicate with some outside APIs such as the Amazons EC2 API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Compute API extension</glossterm> <glossdef> <para>Alternative term for a nova API extension.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute controller</glossterm> <glossdef> <para>The nova component that chooses suitable hosts on which to start VM instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute node</glossterm> <glossdef> <para>A node that runs the nova-compute daemon and the virtual machine instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>compute service</glossterm> <glossdef> <para>Alternative term for the nova component that manages VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>concatenated object</glossterm> <glossdef> <para>A segmented large object within swift that is put back together again and then sent to the client.</para> </glossdef> </glossentry> <glossentry> <glossterm>consistency window</glossterm> <glossdef> <para>The amount of time it takes for a new swift object to become accessible to all clients.</para> </glossdef> </glossentry> <glossentry> <glossterm>console log</glossterm> <glossdef> <para>Contains the output from a Linux VM console in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>container</glossterm> <glossdef> <para>Used to organize and store objects within swift, similar to the concept as a Linux directory but cannot be nested. Alternative term for a glance container format.</para> </glossdef> </glossentry> <glossentry> <glossterm>container auditor</glossterm> <glossdef> <para>Checks for missing replicas or incorrect objects in the specified swift containers through queries to the SQLite back-end database.</para> </glossdef> </glossentry> <glossentry> <glossterm>container database</glossterm> <glossdef> <para>A SQLite database that contains swift containers and related metadata and is accessed by the container server</para> </glossdef> </glossentry> <glossentry> <glossterm>container format</glossterm> <glossdef> <para>The ""envelope"" used by glance to store a VM image and its associated metadata, such as machine state, OS disk size, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>container server</glossterm> <glossdef> <para>Component of swift that manages containers.</para> </glossdef> </glossentry> <glossentry> <glossterm>container service</glossterm> <glossdef> <para>The swift component that provides container services, such as create, delete, list, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>controller node</glossterm> <glossdef> <para>Alternative term for a cloud controller node.</para> </glossdef> </glossentry> <glossentry> <glossterm>core API</glossterm> <glossdef> <para>Depending on context, the core API is either the OpenStack API or the main API of a specific core project, such as nova, neutron, glance, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>core project</glossterm> <glossdef> <para>An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image Service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Volume (cinder).</para> </glossdef> </glossentry> <glossentry> <glossterm>credentials</glossterm> <glossdef> <para>Data that is only known to or accessible by a user that is used to verify the user is who they say they are and presented to the server during authentication. Examples include a password, secret key, digital certificate, fingerprint, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>Crowbar</glossterm> <glossdef> <para>An open source community project by Dell that aims to provide all necessary services to quickly deploy clouds.</para> </glossdef> </glossentry> <glossentry> <glossterm>current workload</glossterm> <glossdef> <para>An element of the nova capacity cache that is calculated based on the number of build, snapshot, migrate, and resize operations currently in progress on a given host.</para> </glossdef> </glossentry> <glossentry> <glossterm>customization module</glossterm> <glossdef> <para>A user-created Python module that is loaded by horizon to change the look and feel of the dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>D</title> <glossentry> <glossterm>dashboard</glossterm> <glossdef> <para>The web-based management interface for OpenStack. An alternative name for horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>database replicator</glossterm> <glossdef> <para>The component of swift that copies changes in the account, container, and object databases to other nodes.</para> </glossdef> </glossentry> <glossentry> <glossterm>default panel</glossterm> <glossdef> <para>The panel that is displayed when a user accesses the horizon dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm>default tenant</glossterm> <glossdef> <para>New users are assigned to this keystone tenant if no tenant is specified when a user is created.</para> </glossdef> </glossentry> <glossentry> <glossterm>default token</glossterm> <glossdef> <para>A keystone token that is not associated with a specific tenant and is exchanged for a scoped token.</para> </glossdef> </glossentry> <glossentry> <glossterm>delayed delete</glossterm> <glossdef> <para>An option within glance so that rather than immediately delete an image, it is deleted after a pre-defined number of seconds.</para> </glossdef> </glossentry> <glossentry> <glossterm>delivery mode</glossterm> <glossdef> <para>Setting for the nova RabbitMQ message delivery mode, can be set to either transient or persistent.</para> </glossdef> </glossentry> <glossentry> <glossterm>device</glossterm> <glossdef> <para>In the context of swift this refers to the underlying storage device.</para> </glossdef> </glossentry> <glossentry> <glossterm>device ID</glossterm> <glossdef> <para>Maps swift partitions to physical storage devices.</para> </glossdef> </glossentry> <glossentry> <glossterm>device weight</glossterm> <glossdef> <para>Used to distribute the partitions among swift devices. The distribution is usually proportional to the storage capacity of the device.</para> </glossdef> </glossentry> <glossentry> <glossterm>DevStack</glossterm> <glossdef> <para>Community project that uses shell scripts to quickly deploy complete OpenStack development environments.</para> </glossdef> </glossentry> <glossentry> <glossterm>Diablo</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in the fall of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image service (glance).</para> </glossdef> </glossentry> <glossentry> <glossterm>disk format</glossterm> <glossdef> <para>The underlying format that a disk image for a VM is stored as within the glance back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>dispersion</glossterm> <glossdef> <para>In swift, tools to test and ensure dispersion of objects and containers to ensure fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Django</glossterm> <glossdef> <para>A web framework used extensively in horizon.</para> </glossdef> </glossentry> <glossentry> <glossterm>dnsmasq</glossterm> <glossdef> <para>Daemon that provides DNS, DHCP, BOOTP, and TFTP services, used by the nova VLAN manager and FlatDHCP manager.</para> </glossdef> </glossentry> <glossentry> <glossterm>DNS record</glossterm> <glossdef> <para>A record that specifies information about a particular domain and belongs to the domain.</para> </glossdef> </glossentry> <glossentry> <glossterm>Dynamic Host Configuration Protocol <glossdef> <para>A method to automatically configure networking for a host at boot time. Provided by both neutron and nova.</para> </glossdef> </glossentry> <title>E</title> <glossentry> <glossterm>ebtables</glossterm> <glossdef> <para>Used in nova along with arptables, iptables, and ip6tables to create firewalls and to ensure isolation of network communications.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2</glossterm> <glossdef> <para>The Amazon Elastic Compute Cloud, a public cloud run by Amazon that provides similar functionality to nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 access key</glossterm> <glossdef> <para>Used along with an EC2 secret key to access the nova EC2 API.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 API</glossterm> <glossdef> <para>OpenStack supports accessing the Amazon EC2 API through nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 Compatibility API</glossterm> <glossdef> <para>A nova component that allows OpenStack to communicate with Amazon EC2</para> </glossdef> </glossentry> <glossentry> <glossterm>EC2 secret key</glossterm> <glossdef> <para>Used along with an EC2 access key when communicating with the nova EC2 API, is used to digitally sign each request.</para> </glossdef> </glossentry> <glossentry> <glossterm>Elastic Block Storage (EBS)</glossterm> <glossdef> <para>The Amazon commercial block storage product, similar to cinder.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint</glossterm> <glossdef> <para>See API endpoint.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint registry</glossterm> <glossdef> <para>Alternative term for a keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>endpoint template</glossterm> <glossdef> <para>A list of URL and port number endpoints that indicate where a service, such as object storage, compute, identity, and so on, can be accessed.</para> </glossdef> </glossentry> <glossentry> <glossterm>entity</glossterm> <glossdef> <para>Any piece of hardware or software that wants to connect to the network services provided by neutron, the Network Connectivity service. An entity can make use of neutron by implementing a VIF.</para> </glossdef> </glossentry> <glossentry> <glossterm>ephemeral storage</glossterm> <glossdef> <para>A storage volume attached to a virtual machine instance that does not persist after the instance is terminated.</para> </glossdef> </glossentry> <glossentry> <glossterm>Essex</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in April 2012, the fifth release of OpenStack. It included Compute (nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and Dashboard (horizon).</para> </glossdef> </glossentry> <glossentry> <glossterm>ESX</glossterm> <glossdef> <para>An OpenStack-supported hypervisor, owned by VMware.</para> </glossdef> </glossentry> <glossentry> <glossterm>ESXi</glossterm> <glossdef> <para>An OpenStack-supported hypervisor, owned by VMware.</para> </glossdef> </glossentry> <glossentry> <glossterm>ETag</glossterm> <glossdef> <para>MD5 hash of an object within swift, used to ensure data integrity.</para> </glossdef> </glossentry> <glossentry> <glossterm>euca2ools</glossterm> <glossdef> <para>A collection of command line tools for administering VMs, most are compatible with OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>evacuate</glossterm> <glossdef> <para>The process of migrating one or all virtual machine (VM) instances from one host to another, compatible with both shared storage live migration and block migration.</para> </glossdef> </glossentry> <glossentry> <glossterm>extension</glossterm> <glossdef> <para>Alternative term for a nova API extension or plug-in. In the context of keystone this is a call that is specific to the implementation, such as adding support for OpenID.</para> </glossdef> </glossentry> <glossentry> <glossterm>extra specs</glossterm> <glossdef> <para>Additional requirements that a user can specify when requesting a new instance, examples include a minimum amount of network bandwidth or a GPU.</para> </glossdef> </glossentry> <title>F</title> <glossentry> <glossterm>FakeLDAP</glossterm> <glossdef> <para>An easy method to create a local LDAP directory for testing keystone and nova. Requires Redis.</para> </glossdef> </glossentry> <glossentry> <glossterm>fill-first scheduler</glossterm> <glossdef> <para>The nova scheduling method that attempts to fill a host with VMs rather than starting new VMs on a variety of hosts.</para> </glossdef> </glossentry> <glossentry> <glossterm>filter</glossterm> <glossdef> <para>The step of the nova scheduling process where hosts that cannot run the VMs are eliminated and are not chosen.</para> </glossdef> </glossentry> <glossentry> <glossterm>firewall</glossterm> <glossdef> <para>Used to restrict communications between hosts and/or nodes, implemented in nova using iptables, arptables, ip6tables and etables.</para> </glossdef> </glossentry> <glossentry> <glossterm>Fixed IP address</glossterm> <glossdef> <para>An IP address that is associated with the same instance each time that instance boots, generally not accessible to end users or the public internet, used for management of the instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>FlatDHCP Manager</glossterm> <glossdef> <para>A nova networking manager that provides a single Layer 2 domain for all subnets in the OpenStack cloud. Provides a single DHCP server for each instance of nova-network to assign and manage IP addresses for all instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>Flat Manager</glossterm> <glossdef> <para>The nova component that gives IP addresses to authorized nodes and assumes DHCP, DNS, and routing configuration and services are provided by something else.</para> </glossdef> </glossentry> <glossentry> <glossterm>flat mode injection</glossterm> <glossdef> <para>A nova networking method where the OS network configuration information is injected into the VM (VM) image before the instance starts.</para> </glossdef> </glossentry> <glossentry> <glossterm>flat network</glossterm> <glossdef> <para>A nova network configuration where all of the instances have IP addresses on the same subnet. Flat networks do not use VLANs.</para> </glossdef> </glossentry> <glossentry> <glossterm>flavor</glossterm> <glossdef> <para>Describes the parameters of the various virtual machine images that are available to users, includes parameters such as CPU, storage, and memory. Also known as instance type.</para> </glossdef> </glossentry> <glossentry> <glossterm>flavor ID</glossterm> <glossdef> <para>UUID for each nova or glance VM flavor or instance type.</para> </glossdef> </glossentry> <glossentry> <glossterm>Floating IP address</glossterm> <glossdef> <para>An IP address that a nova project can associate with a VM so the instance has the same public IP address each time that it boots. You create a pool of floating IP addresses and assign them to instances as they are launched to maintain a consistent IP address for maintaining DNS assignment.</para> </glossdef> </glossentry> <glossentry> <glossterm>Folsom</glossterm> <glossdef> <para>A grouped release of projects related to OpenStack that came out in the fall of 2012, the sixth release of OpenStack. It includes Compute (nova), Object Storage (swift), Identity (keystone), Networking (neutron), Image service (glance) and Volumes or Block Storage (cinder).</para> </glossdef> </glossentry> <glossentry> <glossterm>FormPost</glossterm> <glossdef> <para>swift middleware that allows users to upload (post) an image through a form on a web page.</para> </glossdef> </glossentry> <title>G</title> <glossentry> <glossterm>glance</glossterm> <glossdef> <para>A core project that provides the OpenStack Image Service.</para> </glossdef> </glossentry> <glossentry> <glossterm>glance API server</glossterm> <glossdef> <para>Processes client requests for VMs, updates glance metadata on the registry server, and communicates with the store adapter to upload VM images from the back-end store.</para> </glossdef> </glossentry> <glossentry> <glossterm>global endpoint template</glossterm> <glossdef> <para>The keystone endpoint template that contains services available to all tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>GlusterFS</glossterm> <glossdef> <para>An open-source, distributed, shared file system,</para> </glossdef> </glossentry> <glossentry> <glossterm>Grizzly</glossterm> <glossdef> <para>Project name for the seventh release of OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>guest OS</glossterm> <glossdef> <para>An operating system instance running under the control of a hypervisor.</para> </glossdef> </glossentry> <title>H</title> <glossentry> <glossterm>handover</glossterm> <glossdef> <para>An object state in swift where a new replica of the object is automatically created due to a drive failure.</para> </glossdef> </glossentry> <glossentry> <glossterm>hard reboot</glossterm> <glossdef> <para>A type of reboot where a physical or virtual power button is pressed as opposed to a graceful, proper shutdown of the operating system.</para> </glossdef> </glossentry> <glossentry> <glossterm>Havana</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm>Heat</glossterm> <glossdef> <para>An integrated project that aims to orchestrate multiple cloud applications for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>horizon</glossterm> <glossdef> <para>The project that provides the OpenStack Dashboard.</para> </glossdef> </glossentry> <glossentry> <glossterm>host</glossterm> <glossdef> <para>A physical computer, also known as a node. Contrast with: instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>host aggregate</glossterm> <glossdef> <para>A method to further subdivide availability zones into a collection of hosts.</para> </glossdef> </glossentry> <glossentry> <glossterm>Hyper-V</glossterm> <glossdef> <para>One of the hypervisors supported by OpenStack, developed by Microsoft.</para> </glossdef> </glossentry> <glossentry> <glossterm>hypervisor</glossterm> <glossdef> <para>Software that arbitrates and controls VM access to the actual underlying hardware.</para> </glossdef> </glossentry> <glossentry> <glossterm>hypervisor pool</glossterm> <glossdef> <para>A collection of hypervisors grouped together through host aggregates.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>I</title> <glossentry> <glossterm>Icehouse</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm>ID number</glossterm> <glossdef> <para>Unique numeric ID associated with each user in keystone, conceptually similar to a Linux or LDAP UID.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity API</glossterm> <glossdef> <para>Alternative term for the Identity Service API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity back-end</glossterm> <glossdef> <para>The source used by keystone to retrieve user information an OpenLDAP server for example.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity Service</glossterm> <glossdef> <para>Provides authentication services, also known as keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>Identity Service API</glossterm> <glossdef> <para>The API used to access the OpenStack Identity Service provided through keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>image</glossterm> <glossdef> <para>A collection of files for a specific operating system (OS) that you use to create or rebuild a server. You can also create custom images, or snapshots, from servers that you have launched.</para> </glossdef> </glossentry> <glossentry> <glossterm>Image API</glossterm> <glossdef> <para>The glance API endpoint for management of VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>image cache</glossterm> <glossdef> <para>Used by glance to allow images on the local host to be used rather than re-downloading them from the image server each time one is requested.</para> </glossdef> </glossentry> <glossentry> <glossterm>image ID</glossterm> <glossdef> <para>Combination of URI and UUID used to access glance VM images through the image API.</para> </glossdef> </glossentry> <glossentry> <glossterm>image membership</glossterm> <glossdef> <para>A list of tenants that can access a given VM image within glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>image owner</glossterm> <glossdef> <para>The keystone tenant who owns a glance virtual machine image.</para> </glossdef> </glossentry> <glossentry> <glossterm>image registry</glossterm> <glossdef> <para>A list of VM images that are available through glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>Image Service API</glossterm> <glossdef> <para>Alternative name for the glance image API.</para> </glossdef> </glossentry> <glossentry> <glossterm>image status</glossterm> <glossdef> <para>The current status of a VM image in glance, not to be confused with the status of a running instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>image store</glossterm> <glossdef> <para>The back-end store used by glance to store VM images, options include swift, local file system, S3, or HTTP.</para> </glossdef> </glossentry> <glossentry> <glossterm>image UUID</glossterm> <glossdef> <para>The UUID used by glance to uniquely identify each VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>incubated project</glossterm> <glossdef> <para>A community project may be elevated to this status and is then promoted to a core project.</para> </glossdef> </glossentry> <glossentry> <glossterm>ingress filtering</glossterm> <glossdef> <para>The process of filtering incoming network traffic. Supported by nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>injection</glossterm> <glossdef> <para>The process of putting a file into a virtual machine image before the instance is started.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance</glossterm> <glossdef> <para>A running VM, or a VM in a known state such as suspended that can be used like a hardware server.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance ID</glossterm> <glossdef> <para>Unique ID that is specific to each running nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance state</glossterm> <glossdef> <para>The current state of a nova VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance type</glossterm> <glossdef> <para>Alternative term for flavor.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance type ID</glossterm> <glossdef> <para>Alternative term for a flavor ID.</para> </glossdef> </glossentry> <glossentry> <glossterm>instance UUID</glossterm> <glossdef> <para>Unique ID assigned to each nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>interface ID</glossterm> <glossdef> <para>Unique ID for a neutron VIF or vNIC in the form of a UUID.</para> </glossdef> </glossentry> <glossentry> <glossterm>ip6tables</glossterm> <glossdef> <para>Used along with arptables, ebtables, and iptables to create firewalls in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>iptables</glossterm> <glossdef> <para>Used along with arptables, ebtables, and ip6tables to create firewalls in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>J</title> <glossentry> <glossterm>JavaScript Object Notation <glossdef> <para>One of the supported response formats for the OpenStack API.</para> </glossdef> </glossentry> <glossentry> <glossterm>Jenkins</glossterm> <glossdef> <para>Tool used for OpenStack development to run jobs automatically.</para> </glossdef> </glossentry> <glossentry> <glossterm>Juno</glossterm> <glossdef> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>K</title> <glossentry> <glossterm>kernel-based VM (KVM)</glossterm> <glossdef> <para>An OpenStack-supported hypervisor</para> </glossdef> </glossentry> <glossentry> <glossterm>keystone</glossterm> <glossdef> <para>The project that provides OpenStack Identity services.</para> </glossdef> </glossentry> <glossentry> <glossterm>Kickstart</glossterm> <glossdef> <para>A tool to automate system configuration and installation on Red Hat, Fedora, and CentOS based Linux distributions.</para> </glossdef> </glossentry> <title>L</title> <glossentry> <glossterm>large object</glossterm> <glossdef> <para>An object within swift that is larger than 5 GBs.</para> </glossdef> </glossentry> <glossentry> <glossterm>Launchpad</glossterm> <glossdef> <para>The collaboration site for OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>Layer-2 network</glossterm> <glossdef> <para>Term used for OSI network architecture for the data link layer.</para> </glossdef> </glossentry> <glossentry> <glossterm>libvirt</glossterm> <glossdef> <para>Virtualization API library used by OpenStack to interact with many of its supported hypervisors, including KVM, QEMU and LXC.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux bridge</glossterm> <glossdef> <para>Software used to allow multiple VMs to share a single physical NIC within nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux bridge neutron plug-in</glossterm> <glossdef> <para>Plugin that allows a Linux bridge to understand a neutron port, interface attachment, and other abstractions.</para> </glossdef> </glossentry> <glossentry> <glossterm>Linux containers (LXC)</glossterm> <glossdef> <para>An OpenStack-supported hypervisor.</para> </glossdef> </glossentry> <glossentry> <glossterm>live migration</glossterm> <glossdef> <para>The ability within nova to move running virtual machine instances from one host to another with only a small service interruption during switch-over.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>M</title> <glossentry> <glossterm>management API</glossterm> <glossdef> <para>Alternative term for an admin API.</para> </glossdef> </glossentry> <glossentry> <glossterm>management network</glossterm> <glossdef> <para>A network segment used for administration, not accessible to the public internet.</para> </glossdef> </glossentry> <glossentry> <glossterm>manifest</glossterm> <glossdef> <para>Used to track segments of a large object within swift.</para> </glossdef> </glossentry> <glossentry> <glossterm>manifest object</glossterm> <glossdef> <para>A special swift object that contains the manifest for a large object.</para> </glossdef> </glossentry> <glossentry> <glossterm>membership</glossterm> <glossdef> <para>The association between a glance VM image and a tenant, allows images to be shared with specified tenant(s).</para> </glossdef> </glossentry> <glossentry> <glossterm>membership list</glossterm> <glossdef> <para>Contains a list of tenants that can access a given VM image within glance.</para> </glossdef> </glossentry> <glossentry> <glossterm>memory overcommit</glossterm> <glossdef> <para>The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as RAM overcommit.</para> </glossdef> </glossentry> <glossentry> <glossterm>message broker</glossterm> <glossdef> <para>The software package used to provide AMQP messaging capabilities within nova, default is RabbitMQ.</para> </glossdef> </glossentry> <glossentry> <glossterm>message bus</glossterm> <glossdef> <para>The main virtual communication line used by all AMQP messages for inter-cloud communications within nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>message queue</glossterm> <glossdef> <para>Passes requests from clients to the appropriate workers and returns the output to the client once the job is complete.</para> </glossdef> </glossentry> <glossentry> <glossterm>migration</glossterm> <glossdef> <para>The process of moving a VM instance from one host to another.</para> </glossdef> </glossentry> <glossentry> <glossterm>multinic</glossterm> <glossdef> <para>Facility in nova that allows each virtual machine instance to have more than one VIF connected to it.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>N</title> <glossentry> <glossterm>network ID</glossterm> <glossdef> <para>Unique ID assigned to each network segment within neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>network manager</glossterm> <glossdef> <para>The nova component that manages various network components, such as firewall rules, IP address allocation, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>network node</glossterm> <glossdef> <para>Any nova node that runs the network worker daemon.</para> </glossdef> </glossentry> <glossentry> <glossterm>network segment</glossterm> <glossdef> <para>Represents a virtual, isolated OSI layer 2 subnet in neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>network UUID</glossterm> <glossdef> <para>Unique ID for a neutron network segment.</para> </glossdef> </glossentry> <glossentry> <glossterm>network worker</glossterm> <glossdef> <para>The nova-network worker daemon, provides services such as giving an IP address to a booting nova instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>non-persistent volume</glossterm> <glossdef> <para>Alternative term for an ephemeral volume.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova</glossterm> <glossdef> <para>The OpenStack project that provides compute services.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova API</glossterm> <glossdef> <para>Alternative term for the nova Compute API.</para> </glossdef> </glossentry> <glossentry> <glossterm>nova-network</glossterm> <glossdef> <para>A nova component that manages IP address allocation, firewalls, and other network-related tasks.</para> </glossdef> </glossentry> <title>O</title> <glossentry> <glossterm>object</glossterm> <glossdef> <para>A BLOB of data held by swift, can be in any format.</para> </glossdef> </glossentry> <glossentry> <glossterm>Object API</glossterm> <glossdef> <para>Alternative term for the swift object API.</para> </glossdef> </glossentry> <glossentry> <glossterm>object auditor</glossterm> <glossdef> <para>Opens all objects for an object server and verifies the MD5 hash, size, and metadata for each object.</para> </glossdef> </glossentry> <glossentry> <glossterm>object expiration</glossterm> <glossdef> <para>A configurable option within swift to automatically delete objects after a specified amount of time has passed or a certain date is reached.</para> </glossdef> </glossentry> <glossentry> <glossterm>object hash</glossterm> <glossdef> <para>Uniquely ID for a swift object.</para> </glossdef> </glossentry> <glossentry> <glossterm>object path hash</glossterm> <glossdef> <para>Used by swift to determine the location of an object in the ring. Maps objects to partitions.</para> </glossdef> </glossentry> <glossentry> <glossterm>object replicator</glossterm> <glossdef> <para>Component of swift that copies and object to remote partitions for fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>object server</glossterm> <glossdef> <para>Component of swift that is responsible for managing objects.</para> </glossdef> </glossentry> <glossentry> <glossterm>Object Service API</glossterm> <glossdef> <para>Alternative term for the swift object API.</para> </glossdef> </glossentry> <glossentry> <glossterm>object storage</glossterm> <glossdef> <para>Provides eventually consistent and redundant storage and retrieval of fixed digital content.</para> </glossdef> </glossentry> <glossentry> <glossterm>object versioning</glossterm> <glossdef> <para>Allows a user to set a flag on a swift container so all objects within the container are versioned.</para> </glossdef> </glossentry> <glossentry> <glossterm>operator</glossterm> <glossdef> <para>The person responsible for planning and maintaining an OpenStack installation.</para> </glossdef> </glossentry> <title>P</title> <glossentry> <glossterm>parent cell</glossterm> <glossdef> <para>If a requested resource, such as CPU time, disk storage, or memory, is not available in the parent cell, the request is forwarded to associated child cells.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition</glossterm> <glossdef> <para>A unit of storage within swift used to store objects, exists on top of devices, replicated for fault tolerance.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition index</glossterm> <glossdef> <para>Contains the locations of all swift partitions within the ring.</para> </glossdef> </glossentry> <glossentry> <glossterm>partition shift value</glossterm> <glossdef> <para>Used by swift to determine which partition data should reside on.</para> </glossdef> </glossentry> <glossentry> <glossterm>pause</glossterm> <glossdef> <para>A VM state where no changes occur (no changes in memory, network communications stop, etc), the VM is frozen but not shut down.</para> </glossdef> </glossentry> <glossentry> <glossterm>persistent volume</glossterm> <glossdef> <para>Disk volumes that persist beyond the lifetime of individual virtual machine instances. Contrast with: ephemeral storage</para> </glossdef> </glossentry> <glossentry> <glossterm>plugin</glossterm> <glossdef> <para>Software component providing the actual implementation for neutron APIs, or for Compute APIs, depending on the context.</para> </glossdef> </glossentry> <glossentry> <glossterm>policy service</glossterm> <glossdef> <para>Component of keystone that provides a rule management interface and a rule based authorization engine.</para> </glossdef> </glossentry> <glossentry> <glossterm>port</glossterm> <glossdef> <para>A virtual network port within neutron, VIFs / vNICs are connected to a port.</para> </glossdef> </glossentry> <glossentry> <glossterm>port UUID</glossterm> <glossdef> <para>Unique ID for a neutron port.</para> </glossdef> </glossentry> <glossentry> <glossterm>preseed</glossterm> <glossdef> <para>A tool to automate system configuration and installation on Debian based Linux distributions.</para> </glossdef> </glossentry> <glossentry> <glossterm>private image</glossterm> <glossdef> <para>A glance VM image that is only available to specified tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>project</glossterm> <glossdef> <para>A logical grouping of users within nova, used to define quotas and access to VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>project ID</glossterm> <glossdef> <para>User defined alpha-numeric string in nova, the name of a project.</para> </glossdef> </glossentry> <glossentry> <glossterm>project VPN</glossterm> <glossdef> <para>Alternative term for a cloudpipe.</para> </glossdef> </glossentry> <glossentry> <glossterm>proxy node</glossterm> <glossdef> <para>A node that provides the swift proxy service.</para> </glossdef> </glossentry> <glossentry> <glossterm>proxy server</glossterm> <glossdef> <para>Users of swift interact with the service through the proxy server which in-turn looks up the location of the requested data within the ring and returns the results to the user.</para> </glossdef> </glossentry> <glossentry> <glossterm>public API</glossterm> <glossdef> <para>An API endpoint used for both service to service communication and end user interactions.</para> </glossdef> </glossentry> <glossentry> <glossterm>public image</glossterm> <glossdef> <para>A glance VM image that is available to all tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>public IP address</glossterm> <glossdef> <para>An IP address that is accessible to end-users.</para> </glossdef> </glossentry> <glossentry> <glossterm>public network</glossterm> <glossdef> <para>The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. The public network interface is controlled by the public_interface option.</para> </glossdef> </glossentry> <glossentry> <glossterm>Puppet</glossterm> <glossdef> <para>A configuration management tool that supports OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>Python</glossterm> <glossdef> <para>Programming language used extensively in OpenStack.</para> </glossdef> </glossentry> <title>Q</title> <glossentry> <glossterm>neutron</glossterm> <glossdef> <para>A core OpenStack project that provides a network connectivity abstraction layer to OpenStack Compute.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron API</glossterm> <glossdef> <para>API used to access neutron, provides and extensible architecture to allow custom plugin creation.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron manager</glossterm> <glossdef> <para>Allows nova and neutron integration thus allowing neutron to perform network management for nova VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>neutron plugin</glossterm> <glossdef> <para>Interface within neutron that allows organizations to create custom plugins for advanced features such as QoS, ACLs, or IDS.</para> </glossdef> </glossentry> <glossentry> <glossterm>quarantine</glossterm> <glossdef> <para>If swift finds objects, containers, or accounts that are corrupt they are placed in this state, are not replicated, cannot be read by clients, and a correct copy is re-replicated.</para> </glossdef> </glossentry> <glossentry> <glossterm>Quick EMUlator (QEMU)</glossterm> <glossdef> <para>One of the hypervisors supported by OpenStack, generally used for development purposes.</para> </glossdef> </glossentry> <glossentry> <glossterm>quota</glossterm> <glossdef> <para>In nova, the ability to set resource limits on a per-project basis.</para> </glossdef> </glossentry> <title>R</title> <glossentry> <glossterm>RAM filter</glossterm> <glossdef> <para>The nova setting that allows or disallows RAM overcommitment.</para> </glossdef> </glossentry> <glossentry> <glossterm>RAM overcommit</glossterm> <glossdef> <para>The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as memory overcommit.</para> </glossdef> </glossentry> <glossentry> <glossterm>rate limit</glossterm> <glossdef> <para>Configurable option within swift to limit database writes on a per-account and/or per-container basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>rebalance</glossterm> <glossdef> <para>The process of distributing swift partitions across all drives in the ring, used during initial ring creation and after ring reconfiguration.</para> </glossdef> </glossentry> <glossentry> <glossterm>Recon</glossterm> <glossdef> <para>A component of swift used to collect metrics.</para> </glossdef> </glossentry> <glossentry> <glossterm>record ID</glossterm> <glossdef> <para>A number within a database that is incremented each time a change is made. Used by swift when replicating.</para> </glossdef> </glossentry> <glossentry> <glossterm>registry server</glossterm> <glossdef> <para>A glance service that provides VM image metadata information to clients.</para> </glossdef> </glossentry> <glossentry> <glossterm>replica</glossterm> <glossdef> <para>Provides data redundancy and fault tolerance by creating copies of swift objects, accounts, and containers so they are not lost when the underlying storage fails.</para> </glossdef> </glossentry> <glossentry> <glossterm>replica count</glossterm> <glossdef> <para>The number of replicas of the data in a swift ring.</para> </glossdef> </glossentry> <glossentry> <glossterm>replication</glossterm> <glossdef> <para>The process of copying data to a separate physical device for fault tolerance and performance.</para> </glossdef> </glossentry> <glossentry> <glossterm>replicator</glossterm> <glossdef> <para>The swift back-end process that creates and manages object replicas.</para> </glossdef> </glossentry> <glossentry> <glossterm>request ID</glossterm> <glossdef> <para>Unique ID assigned to each request sent to nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>ring</glossterm> <glossdef> <para>An entity that maps swift data to partitions. A separate ring exists for each service, such as account, object, and container.</para> </glossdef> </glossentry> <glossentry> <glossterm>ring builder</glossterm> <glossdef> <para>Builds and manages rings within swift, assigns partitions to devices, and pushes the configuration to other storage nodes.</para> </glossdef> </glossentry> <glossentry> <glossterm>role ID</glossterm> <glossdef> <para>Alpha-numeric ID assigned to each keystone role.</para> </glossdef> </glossentry> <glossentry> <glossterm>rootwrap</glossterm> <glossdef> <para>A feature of nova that allows the unprivileged ""nova"" user to run a specified list of commands as the Linux root user.</para> </glossdef> </glossentry> <glossentry> <glossterm>RPC driver</glossterm> <glossdef> <para>Modular system that allows the nova underlying message queue software to be changed. For example, from RabbitMQ to ZeroMQ or Qpid.</para> </glossdef> </glossentry> <title>S</title> <glossentry> <glossterm>S3</glossterm> <glossdef> <para>Object storage service by Amazon, similar in function to swift, can act as a back-end store for glance VM images.</para> </glossdef> </glossentry> <glossentry> <glossterm>scheduler manager</glossterm> <glossdef> <para>A nova component that determines where VM instances should start. Uses modular design to support a variety of scheduler types.</para> </glossdef> </glossentry> <glossentry> <glossterm>scoped token</glossterm> <glossdef> <para>A keystone API access token that is associated with a specific tenant.</para> </glossdef> </glossentry> <glossentry> <glossterm>secret key</glossterm> <glossdef> <para>String of text only known by the user, used along with an access key to make requests to the nova API.</para> </glossdef> </glossentry> <glossentry> <glossterm>security group</glossterm> <glossdef> <para>A set of network traffic filtering rules that are applied to a nova instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>segmented object</glossterm> <glossdef> <para>A swift large object that has been broken up into pieces, the re-assembled object is called a concatenated object.</para> </glossdef> </glossentry> <glossentry> <glossterm>server image</glossterm> <glossdef> <para>Alternative term for a VM image.</para> </glossdef> </glossentry> <glossentry> <glossterm>server UUID</glossterm> <glossdef> <para>Unique ID assigned to each nova VM instance.</para> </glossdef> </glossentry> <glossentry> <glossterm>service catalog</glossterm> <glossdef> <para>Alternative term for the keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service ID</glossterm> <glossdef> <para>Unique ID assigned to each service that is available in the keystone catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service registration</glossterm> <glossdef> <para>A keystone feature that allows services such as nova to automatically register with the catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service tenant</glossterm> <glossdef> <para>Special keystone tenant that contains all services that are listed in the catalog.</para> </glossdef> </glossentry> <glossentry> <glossterm>service token</glossterm> <glossdef> <para>An administrator defined token used by nova to communicate securely with keystone.</para> </glossdef> </glossentry> <glossentry> <glossterm>session back-end</glossterm> <glossdef> <para>The method of storage used by horizon to track client sessions such as local memory, cookies, a database, or memcached.</para> </glossdef> </glossentry> <glossentry> <glossterm>session persistence</glossterm> <glossdef> <para>A feature of the load balancing service. It attempts to force subsequent connections to a service to be redirected to the same node as long as it is online.</para> </glossdef> </glossentry> <glossentry> <glossterm>session storage</glossterm> <glossdef> <para>A horizon component that stores and tracks client session information. Implemented through the Django sessions framework.</para> </glossdef> </glossentry> <glossentry> <glossterm>shared storage</glossterm> <glossdef> <para>Block storage that is simultaneously accessible by multiple clients. For example, NFS.</para> </glossdef> </glossentry> <glossentry> <glossterm>SmokeStack</glossterm> <glossdef> <para>Runs automated tests against the core OpenStack API, written in Rails.</para> </glossdef> </glossentry> <glossentry> <glossterm>snapshot</glossterm> <glossdef> <para>A point-in-time copy of an OpenStack storage volume or image. Use storage volume snapshots to back up volumes. Use image snapshots to back up data, or as ""gold"" images for additional servers.</para> </glossdef> </glossentry> <glossentry> <glossterm>spread-first scheduler</glossterm> <glossdef> <para>The nova VM scheduling algorithm that attempts to start new VM on the host with the least amount of load.</para> </glossdef> </glossentry> <glossentry> <glossterm>SQLAlchemy</glossterm> <glossdef> <para>An open source SQL toolkit for Python, used in OpenStack.</para> </glossdef> </glossentry> <glossentry> <glossterm>SQLite</glossterm> <glossdef> <para>A lightweight SQL database, used as the default persistent storage method in many OpenStack services.</para> </glossdef> </glossentry> <glossentry> <glossterm>StackTach</glossterm> <glossdef> <para>Community project that captures nova AMQP communications, useful for debugging.</para> </glossdef> </glossentry> <glossentry> <glossterm>static IP address</glossterm> <glossdef> <para>Alternative term for a fixed IP address.</para> </glossdef> </glossentry> <glossentry> <glossterm>StaticWeb</glossterm> <glossdef> <para>WSGI middleware component of swift that serves container data as a static web page.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage back-end</glossterm> <glossdef> <para>The method that a service uses for persistent storage such as iSCSI, NFS, or local disk.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage node</glossterm> <glossdef> <para>A swift node that provides container services, account services, and object services, controls the account databases, container databases, and object storage.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage manager</glossterm> <glossdef> <para>Component of XenAPI that provides a pluggable interface to support a wide variety of persistent storage back-ends.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage manager back-end</glossterm> <glossdef> <para>A persistent storage method supported by XenAPI such as iSCSI or NFS.</para> </glossdef> </glossentry> <glossentry> <glossterm>storage services</glossterm> <glossdef> <para>Collective name for the swift object services, container services, and account services.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift</glossterm> <glossdef> <para>An OpenStack core project that provides object storage services.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift All in One (SAIO)</glossterm> <glossdef> <para>Creates a full swift development environment within a single VM.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift middleware</glossterm> <glossdef> <para>Collective term for components within swift that allows for additional functionality.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift proxy server</glossterm> <glossdef> <para>Acts as the gatekeeper to swift and is responsible for authenticating the user.</para> </glossdef> </glossentry> <glossentry> <glossterm>swift storage node</glossterm> <glossdef> <para>A node that runs swift account, container, and object services.</para> </glossdef> </glossentry> <glossentry> <glossterm>sync point</glossterm> <glossdef> <para>Point in time since the last container and accounts database sync among nodes within swift.</para> </glossdef> </glossentry> <title>T</title> <glossentry> <glossterm>TempAuth</glossterm> <glossdef> <para>An authentication facility within swift that allows swift itself to perform authentication and authorization, frequently used in testing and development.</para> </glossdef> </glossentry> <glossentry> <glossterm>Tempest</glossterm> <glossdef> <para>Automated software test suite designed to run against the trunk of the OpenStack core project.</para> </glossdef> </glossentry> <glossentry> <glossterm>TempURL</glossterm> <glossdef> <para>A swift middleware component that allows a user to create URLs for temporary object access.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant</glossterm> <glossdef> <para>A group of users, used to isolate access to nova resources. An alternative term for a nova project.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant endpoint</glossterm> <glossdef> <para>A keystone API endpoint that is associated with one or more tenants.</para> </glossdef> </glossentry> <glossentry> <glossterm>tenant ID</glossterm> <glossdef> <para>Unique ID assigned to each tenant within keystone, the nova project IDs map to the keystone tenant IDs.</para> </glossdef> </glossentry> <glossentry> <glossterm>token</glossterm> <glossdef> <para>An alpha-numeric string of text used to access OpenStack APIs and resources.</para> </glossdef> </glossentry> <glossentry> <glossterm>tombstone</glossterm> <glossdef> <para>Used to mark swift objects that have been deleted, ensures the object is not updated on another node after it has been deleted.</para> </glossdef> </glossentry> <glossentry> <glossterm>transaction ID</glossterm> <glossdef> <para>Unique ID assigned to each swift request, used for debugging and tracing.</para> </glossdef> </glossentry> <glossentry> <glossterm/> <glossdef> <para> </para> </glossdef> </glossentry> <title>U</title> <glossentry> <glossterm>unscoped token</glossterm> <glossdef> <para>Alternative term for a keystone default token.</para> </glossdef> </glossentry> <glossentry> <glossterm>updater</glossterm> <glossdef> <para>Collective term for a group of swift components that process queued and failed updates for containers and objects.</para> </glossdef> </glossentry> <glossentry> <glossterm>user</glossterm> <glossdef> <para>In keystone each user is associated with one or more tenants, and in nova they can be associated with roles, projects, or both.</para> </glossdef> </glossentry> <glossentry> <glossterm>user data</glossterm> <glossdef> <para>A blob of data that can be specified by the user when launching an instance. This data can be accessed by the instance through the metadata service or config drive. Commonly used for passing a shell script that is executed by the instance on boot.</para> </glossdef> </glossentry> <title>V</title> <glossentry> <glossterm>VIF UUID</glossterm> <glossdef> <para>Unique ID assigned to each neutron VIF.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Central Processing Unit <glossdef> <para>Allows physical CPUs to be sub-divided and those divisions are then used by instances. Also known as virtual cores.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Machine (VM)</glossterm> <glossdef> <para>An operating system instance that runs on top of a hypervisor. Multiple VMs can run at the same time on the same physical host.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual network</glossterm> <glossdef> <para>An L2 network segment within neutron.</para> </glossdef> </glossentry> <glossentry> <glossterm>Virtual Network InterFace (VIF)</glossterm> <glossdef> <para>An interface that is plugged into a port in a neutron network. Typically a virtual network interface belonging to a VM.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual port</glossterm> <glossdef> <para>Attachment point where a virtual interface connects to a virtual network.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual private network (VPN)</glossterm> <glossdef> <para>Provided by nova in the form of cloudpipes, specialized instances that are used to create VPNs on a per-project basis.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual server</glossterm> <glossdef> <para>Alternative term for a VM or guest.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual switch (vSwitch)</glossterm> <glossdef> <para>Software that runs on a host or node and provides the features and functions of a hardware based network switch.</para> </glossdef> </glossentry> <glossentry> <glossterm>virtual VLAN</glossterm> <glossdef> <para>Alternative term for a virtual network.</para> </glossdef> </glossentry> <glossentry> <glossterm>VLAN manager</glossterm> <glossdef> <para>A nova networking manager that divides subnet and tenants into different VLANs allowing for Layer 2 segregation. Provides a DHCP server for each VLAN to assign IP addresses for instances.</para> </glossdef> </glossentry> <glossentry> <glossterm>VLAN network</glossterm> <glossdef> <para>The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. A VLAN network is a private network interface, which is controlled by the vlan_interface option with VLAN managers.</para> </glossdef> </glossentry> <glossentry> <glossterm>VM image</glossterm> <glossdef> <para>Alternative term for an image.</para> </glossdef> </glossentry> <glossentry> <glossterm>VNC proxy</glossterm> <glossdef> <para>A nova component that provides users access to the consoles of their VM instances through VNC or VMRC.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume</glossterm> <glossdef> <para>Disk-based data storage generally represented as an iSCSI target with a file system that supports extended attributes, can be persistent or ephemeral. Commonly used as a synonym for block device.</para> </glossdef> </glossentry> <glossentry> <glossterm>Volume API</glossterm> <glossdef> <para>An API on a separate endpoint for attaching, detaching, and creating block storage for compute VMs.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume controller</glossterm> <glossdef> <para>A nova component that oversees and coordinates storage volume actions.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume driver</glossterm> <glossdef> <para>Alternative term for a volume plugin.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume ID</glossterm> <glossdef> <para>Unique ID applied to each storage volume under the nova control.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume manager</glossterm> <glossdef> <para>A nova component that creates, attaches, and detaches persistent storage volumes.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume node</glossterm> <glossdef> <para>A nova node that runs the cinder-volume daemon.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume plugin</glossterm> <glossdef> <para>A plugin for the nova volume manager. Provides support for a new and specialized types of back-end storage.</para> </glossdef> </glossentry> <glossentry> <glossterm>Volume Service API</glossterm> <glossdef> <para>Alternative term for the Block Storage API.</para> </glossdef> </glossentry> <glossentry> <glossterm>volume worker</glossterm> <glossdef> <para>The nova component that interacts with back-end storage to manage the creation and deletion of volumes and the creation of compute volumes, provided by the nova-volume daemon.</para> </glossdef> </glossentry> <title>W</title> <glossentry> <glossterm>weight</glossterm> <glossdef> <para>Used by swift storage devices to determine which storage devices are suitable for the job. Devices are weighted by size.</para> </glossdef> </glossentry> <glossentry> <glossterm>weighted cost</glossterm> <glossdef> <para>The sum of each cost used when deciding where to start a new VM instance in nova.</para> </glossdef> </glossentry> <glossentry> <glossterm>weighing</glossterm> <glossdef> <para>A nova process that determines the suitability of the VM instances for a job for a particular host. For example, not enough RAM on the host, too many CPUs on the host, and so on.</para> </glossdef> </glossentry> <glossentry> <glossterm>worker</glossterm> <glossdef> <para>A daemon that carries out tasks. For example, the nova-volume worker attaches storage to an VM instance. Workers listen to a queue and take action when new messages arrive.</para> </glossdef> </glossentry> <title>Z</title> <glossentry> <glossterm>Zuul</glossterm> <glossdef> <para>Tool used in OpenStack development to ensure correctly ordered testing of changes in parallel.</para> </glossdef> </glossentry> </glossary>",2914,2889
openstack%2Fopenstack-manuals~master~I90d419b696f9231f674cd7dd4ab466295a58f210,openstack/openstack-manuals,master,I90d419b696f9231f674cd7dd4ab466295a58f210,updated operations training labs network image,MERGED,2014-02-01 19:01:46.000000000,2014-02-01 19:11:28.000000000,2014-02-01 19:11:27.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 19:01:46.000000000', 'files': ['doc/training-guides/lab002-network-node.xml', 'doc/training-guides/lab003-compute-node.xml', 'doc/training-guides/figures/lab000-virtual-box/image03.png', 'doc/training-guides/lab001-control-node.xml', 'doc/training-guides/lab000-virtualbox-basics.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/23d14f3d1d743999279dff8a5b9e14060775f647', 'message': 'updated operations training labs network image\n\nremoved reference to quantum. cleaned up image. made\nit slightly smaller. created the publicly editable source\nimage. added reference to image source in the docs.\n\nChange-Id: I90d419b696f9231f674cd7dd4ab466295a58f210\nCloses-Bug: #1275149\n'}]",0,70543,23d14f3d1d743999279dff8a5b9e14060775f647,5,2,1,6923,,,0,"updated operations training labs network image

removed reference to quantum. cleaned up image. made
it slightly smaller. created the publicly editable source
image. added reference to image source in the docs.

Change-Id: I90d419b696f9231f674cd7dd4ab466295a58f210
Closes-Bug: #1275149
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/70543/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/lab002-network-node.xml', 'doc/training-guides/lab003-compute-node.xml', 'doc/training-guides/figures/lab000-virtual-box/image03.png', 'doc/training-guides/lab001-control-node.xml', 'doc/training-guides/lab000-virtualbox-basics.xml']",5,23d14f3d1d743999279dff8a5b9e14060775f647,bug/1275149," <para>Publicly editable image source at <link xlink:href=""https://docs.google.com/drawings/d/1GX3FXmkz3c_tUDpZXUVMpyIxicWuHs5fNsHvYNjwNNk/edit?usp=sharing"" >https://docs.google.com/drawings/d/1GX3FXmkz3c_tUDpZXUVMpyIxicWuHs5fNsHvYNjwNNk/edit?usp=sharing</link></para> <para>Vboxnet0, Vboxnet1, Vboxnet2 - are virtual networks setup up"," <para>Vboxnet0, Vboxnet1, Vboxnet2 - are virtual networks setup up",13,1
openstack%2Frequirements~master~I2af4dc6ab460fd8a368b22e3ffbde9467c23f774,openstack/requirements,master,I2af4dc6ab460fd8a368b22e3ffbde9467c23f774,Have tox install via setup.py develop,MERGED,2014-01-14 12:19:12.000000000,2014-02-01 18:13:03.000000000,2014-02-01 18:13:03.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4395}, {'_account_id': 5263}, {'_account_id': 7575}, {'_account_id': 7680}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-01-14 12:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/251b4a3cd3721bb4898952756b411742a97b179c', 'message': 'Whitelist external netifaces requirement\n\nThis patch include two parts to fix the Jekins failure.\n\n* Have tox install via setup.py develop\n\ntox 1.6 was released, which means that we can now take advantage of\nthe feature we added to it - which is using setup.py develop to\ninstall the code into the virtualenv. The logic was taken from\nrun_tests.sh - so the performance issues around using tox vs. using\ninstall_venv should now be gone.\n\nAdditionally, override the tox pip install command to avoid using\nthe ""--pre"" option which is the default in tox. ""--pre"" means\n""Include pre-release and development versions."" By default, pip will\nonly install stable versions of software, and that is the behavior\nwe want.\n\n* tox.ini(testenv.install_command): Use the --allow-external and\n--allow-insecure options so that pip 1.5 and later will assent to\nretrieve the netifaces package even though it\'s not hosted on PyPI.\nThe --allow-insecure option is aliased to a clearer\n--allow-unverified wording in 1.5, but the old form is being used to\navoid breaking users of 1.4.x and will be valid at least through\n1.6.x according to comments in the pip source.\n\nCopied from https://review.openstack.org/#/c/65019/\n\nChange-Id: I2af4dc6ab460fd8a368b22e3ffbde9467c23f774\nPartial-Bug: #1266513\n'}, {'number': 2, 'created': '2014-01-17 01:09:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6538f1638c16cf73a0e1678c2d4d24cefad16e98', 'message': 'Have tox install via setup.py develop\n\ntox 1.6 was released, which means that we can now take advantage of\nthe feature we added to it - which is using setup.py develop to\ninstall the code into the virtualenv. The logic was taken from\nrun_tests.sh - so the performance issues around using tox vs. using\ninstall_venv should now be gone.\n\nAdditionally, override the tox pip install command to avoid using\nthe ""--pre"" option which is the default in tox. ""--pre"" means\n""Include pre-release and development versions."" By default, pip will\nonly install stable versions of software, and that is the behavior\nwe want.\n\nChange-Id: I2af4dc6ab460fd8a368b22e3ffbde9467c23f774\n'}]",0,66549,6538f1638c16cf73a0e1678c2d4d24cefad16e98,21,8,2,9796,,,0,"Have tox install via setup.py develop

tox 1.6 was released, which means that we can now take advantage of
the feature we added to it - which is using setup.py develop to
install the code into the virtualenv. The logic was taken from
run_tests.sh - so the performance issues around using tox vs. using
install_venv should now be gone.

Additionally, override the tox pip install command to avoid using
the ""--pre"" option which is the default in tox. ""--pre"" means
""Include pre-release and development versions."" By default, pip will
only install stable versions of software, and that is the behavior
we want.

Change-Id: I2af4dc6ab460fd8a368b22e3ffbde9467c23f774
",git fetch https://review.opendev.org/openstack/requirements refs/changes/49/66549/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,251b4a3cd3721bb4898952756b411742a97b179c,fix_failure,minversion = 1.6 skipsdist = Trueusedevelop = True install_command = pip install --allow-external netifaces --allow-insecure netifaces -U {opts} {packages}deps = -r{toxinidir}/test-requirements.txt,deps = -U -r{toxinidir}/test-requirements.txt,5,2
openstack%2Fkeystone~master~Ic480e88793935e9cdd0b163cebe055c9458896ad,openstack/keystone,master,Ic480e88793935e9cdd0b163cebe055c9458896ad,Make error strings translatable,MERGED,2014-01-30 19:19:44.000000000,2014-02-01 17:05:48.000000000,2014-02-01 17:05:48.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-01-30 19:19:44.000000000', 'files': ['keystone/identity/backends/pam.py', 'keystone/identity/backends/kvs.py', 'keystone/identity/backends/sql.py', 'keystone/common/wsgi.py', 'keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/66b1a22bd1612cdd6602d493537ab7b694b1b2d4', 'message': 'Make error strings translatable\n\nThe error string for failed authentication, and some others, were not\nbeing translated because they were plain strings. This patch makes them\nMessages so they can be translated.\n\nChange-Id: Ic480e88793935e9cdd0b163cebe055c9458896ad\nPartial-Bug: #1274638\n'}]",1,70196,66b1a22bd1612cdd6602d493537ab7b694b1b2d4,8,4,1,7996,,,0,"Make error strings translatable

The error string for failed authentication, and some others, were not
being translated because they were plain strings. This patch makes them
Messages so they can be translated.

Change-Id: Ic480e88793935e9cdd0b163cebe055c9458896ad
Partial-Bug: #1274638
",git fetch https://review.opendev.org/openstack/keystone refs/changes/96/70196/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/backends/pam.py', 'keystone/identity/backends/kvs.py', 'keystone/identity/backends/sql.py', 'keystone/common/wsgi.py', 'keystone/identity/backends/ldap.py']",5,66b1a22bd1612cdd6602d493537ab7b694b1b2d4,bug/1274638, raise AssertionError(_('Invalid user / password')) if not user_id or not password: raise AssertionError(_('Invalid user / password')) raise AssertionError(_('Invalid user / password')) except Exception: raise AssertionError(_('Invalid user / password')) raise exception.ValidationError(_('Cannot change user ID')) raise exception.Conflict(_('Cannot change user name')), raise AssertionError('Invalid user / password') if not user_id or not password: raise AssertionError('Invalid user / password') raise AssertionError('Invalid user / password') except Exception: raise AssertionError('Invalid user / password') raise exception.ValidationError('Cannot change user ID') raise exception.Conflict('Cannot change user name'),19,19
openstack%2Fglance~master~Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55,openstack/glance,master,Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55,Log a warning when a create fails due to quota,MERGED,2014-01-21 17:51:10.000000000,2014-02-01 17:05:40.000000000,2014-02-01 17:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 616}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-01-21 17:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6f99bd9bf04b39c86724e0647338f98c51d7e8e5', 'message': 'Log an error when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log an Error message.\n\nCloses-Bug #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 2, 'created': '2014-01-22 14:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3d5670aef80ceacee635a5f339933a901bebec5a', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 3, 'created': '2014-01-22 15:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/96cfa25385927bf95ef70fbae283a38d72a65a71', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 4, 'created': '2014-01-22 19:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/14eeebec9d16f067b7028b7bf7dd837f47880edf', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 5, 'created': '2014-01-23 02:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c99bce31a3a027b35560b479b2372d84308fea16', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 6, 'created': '2014-01-24 02:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/feacab6a4e03240839eb5394901909845e0ae9ad', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 7, 'created': '2014-01-24 21:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5299c26fcc2044a18bd6d10604e317e8ce39a6fe', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 8, 'created': '2014-01-26 02:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/59c54a78598b394bce08e81718c6c525731a92b9', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}, {'number': 9, 'created': '2014-01-31 23:37:32.000000000', 'files': ['glance/api/common.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1777e019e0df8e83d5ac25dd7265186e4bb01aae', 'message': 'Log a warning when a create fails due to quota\n\nWhen a create call fails due to user_storage_quota\nbeing exceeded, log a warning message.\n\nCloses-Bug: #1270832\n\nChange-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55\n'}]",15,68189,1777e019e0df8e83d5ac25dd7265186e4bb01aae,48,8,9,9500,,,0,"Log a warning when a create fails due to quota

When a create call fails due to user_storage_quota
being exceeded, log a warning message.

Closes-Bug: #1270832

Change-Id: Ic7ec266aace03cff0a1f72dc3ba6f17b89f5fd55
",git fetch https://review.opendev.org/openstack/glance refs/changes/89/68189/3 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/common.py'],1,6f99bd9bf04b39c86724e0647338f98c51d7e8e5,bugs/1270832," LOG.error(_(""User %s attempted to upload an image of size %d"" "" that will exceeed the quota. %s bytes remaining."") % (context.user, image_size, remaining)) LOG.error(_(""User %s attempted to upload an image of size %d"" "" that will exceeed the quota. %s bytes remaining."") % (context.user, image_size, remaining))",,6,0
openstack%2Fpython-novaclient~master~I499c0399eb961588d7e1491e1481412ffdda38b8,openstack/python-novaclient,master,I499c0399eb961588d7e1491e1481412ffdda38b8,Removed undefined method in install_env.py file,MERGED,2014-01-31 17:47:57.000000000,2014-02-01 16:40:46.000000000,2014-02-01 16:40:46.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-01-31 17:47:57.000000000', 'files': ['tools/install_venv.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0194492059920fd8d9d91849c341b2de0b561089', 'message': ""Removed undefined method in install_env.py file\n\nThere was a call from install_venv.py file to post_process method\nof InstallVenv class, but this method is not defined in this class\nas result it was raising an error. Even when this error doesn't\naffect dependencies installation, it is not allowing to display user\ninformation.\n\nChange-Id: I499c0399eb961588d7e1491e1481412ffdda38b8\nCloses-Bug: #1275025\n""}]",0,70385,0194492059920fd8d9d91849c341b2de0b561089,6,3,1,8726,,,0,"Removed undefined method in install_env.py file

There was a call from install_venv.py file to post_process method
of InstallVenv class, but this method is not defined in this class
as result it was raising an error. Even when this error doesn't
affect dependencies installation, it is not allowing to display user
information.

Change-Id: I499c0399eb961588d7e1491e1481412ffdda38b8
Closes-Bug: #1275025
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/85/70385/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_venv.py'],1,0194492059920fd8d9d91849c341b2de0b561089,bug/1275025,, install.post_process(),0,1
openstack%2Fnova~master~I973e4f4591945f225e374797aebd1bbe00c3c9bd,openstack/nova,master,I973e4f4591945f225e374797aebd1bbe00c3c9bd,Fixes errors on start/stop unittest,MERGED,2013-12-03 09:45:05.000000000,2014-02-01 16:35:32.000000000,2014-02-01 16:35:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5652}, {'_account_id': 6062}, {'_account_id': 8289}, {'_account_id': 8290}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-03 09:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c396221ced3e9531b5897323216cd6555f4df224', 'message': 'Fixes errors on start/stop unittest\n\nChange-Id: I973e4f4591945f225e374797aebd1bbe00c3c9bd\nCloses-Bug: #1257222\n'}, {'number': 2, 'created': '2013-12-12 01:29:38.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/api/openstack/compute/contrib/test_server_start_stop.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1cd59abef5e9947fa8a98932d71a6b3aeae88ae5', 'message': 'Fixes errors on start/stop unittest\n\nThe action name is incorrect on stop unittest, we should use ""stop""\ninstead of ""start"".\n\nChange-Id: I973e4f4591945f225e374797aebd1bbe00c3c9bd\nCloses-Bug: #1257222\n'}]",1,59659,1cd59abef5e9947fa8a98932d71a6b3aeae88ae5,21,8,2,8289,,,0,"Fixes errors on start/stop unittest

The action name is incorrect on stop unittest, we should use ""stop""
instead of ""start"".

Change-Id: I973e4f4591945f225e374797aebd1bbe00c3c9bd
Closes-Bug: #1257222
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/59659/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/api/openstack/compute/contrib/test_server_start_stop.py']",2,c396221ced3e9531b5897323216cd6555f4df224,bug/1257222," body = dict(stop="""") body = dict(stop="""") body = dict(stop="""")"," body = dict(start="""") body = dict(start="""") body = dict(start="""")",6,6
openstack%2Ftempest~master~Ibf741059c3a7a94543f1a2230fe7048692e1db0c,openstack/tempest,master,Ibf741059c3a7a94543f1a2230fe7048692e1db0c,Skip flavor_access_add/remove related tests,MERGED,2014-01-02 02:58:19.000000000,2014-02-01 14:20:04.000000000,2014-02-01 14:20:03.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 5754}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-01-02 02:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b38457bfcc5acb8a042b3099755e64b482289d53', 'message': 'Skip flavor_access_add/remove related tests\n\nThis patch add skip decorator for flavor_access_add/remove related tests.\nAfter use project instead of tenant in the flavor_access extensions, will\nfix those tests.\n\nChange-Id: Ibf741059c3a7a94543f1a2230fe7048692e1db0c\nRelated-Bug: #1265416\n'}, {'number': 2, 'created': '2014-01-02 03:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/345655a05e9b1e980d2feba113312df3a4f99bd6', 'message': 'Skip flavor_access_add/remove related tests\n\nThis patch add skip decorator for flavor_access_add/remove related tests.\nAfter use project instead of tenant in the flavor_access extensions, will\nfix those tests.\n\nRelated patch:\nhttps://review.openstack.org/#/c/58450/\n\nChange-Id: Ibf741059c3a7a94543f1a2230fe7048692e1db0c\nRelated-Bug: #1265416\n'}, {'number': 3, 'created': '2014-01-02 05:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e60aca650bb47ea44f2da2b4e7ffa921e52cffc3', 'message': 'Skip flavor_access_add/remove related tests\n\nThis patch add skip decorator for flavor_access_add/remove related tests.\nAfter use project instead of tenant in the flavor_access extensions, will\nfix those tests.\n\nRelated patch:\nhttps://review.openstack.org/#/c/58450/\n\nChange-Id: Ibf741059c3a7a94543f1a2230fe7048692e1db0c\nRelated-Bug: #1265416\n'}, {'number': 4, 'created': '2014-01-06 07:07:58.000000000', 'files': ['tempest/api/compute/v3/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/admin/test_flavors_access.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e8cb11198fd53504bff76ad961da27d249f4b86e', 'message': 'Skip flavor_access_add/remove related tests\n\nThis patch add skip decorator for flavor_access_add/remove related tests.\nAfter use project instead of tenant in the flavor_access extensions, will\nfix those tests.\n\nRelated patch:\nhttps://review.openstack.org/#/c/58450/\n\nChange-Id: Ibf741059c3a7a94543f1a2230fe7048692e1db0c\nRelated-Bug: #1265416\n'}]",6,64634,e8cb11198fd53504bff76ad961da27d249f4b86e,23,5,4,5754,,,0,"Skip flavor_access_add/remove related tests

This patch add skip decorator for flavor_access_add/remove related tests.
After use project instead of tenant in the flavor_access extensions, will
fix those tests.

Related patch:
https://review.openstack.org/#/c/58450/

Change-Id: Ibf741059c3a7a94543f1a2230fe7048692e1db0c
Related-Bug: #1265416
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/64634/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/admin/test_flavors_access.py']",2,b38457bfcc5acb8a042b3099755e64b482289d53,bug/1265416, @skip_because(bug='1265416') @skip_because(bug='1265416'),,6,0
openstack%2Ftempest~master~I6af9fa40bad8cae062125f486534d1724ad9baef,openstack/tempest,master,I6af9fa40bad8cae062125f486534d1724ad9baef,Fix stress test README.rst,MERGED,2014-01-31 23:53:59.000000000,2014-02-01 14:19:55.000000000,2014-02-01 14:19:55.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1297}, {'_account_id': 2750}, {'_account_id': 6172}, {'_account_id': 6707}, {'_account_id': 7125}, {'_account_id': 7706}, {'_account_id': 7872}, {'_account_id': 8408}, {'_account_id': 8493}, {'_account_id': 8911}, {'_account_id': 10222}]","[{'number': 1, 'created': '2014-01-31 23:53:59.000000000', 'files': ['tempest/stress/README.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/17ffbb999e27e1079d1fcdedf3930394b0ae952c', 'message': 'Fix stress test README.rst\n\nWe should be more precise and actually whole OpenStack (not only Nova)\nis a distributed, asynchronous system that is prone to race condition bugs.\n\nChange-Id: I6af9fa40bad8cae062125f486534d1724ad9baef\n'}]",0,70472,17ffbb999e27e1079d1fcdedf3930394b0ae952c,17,13,1,6172,,,0,"Fix stress test README.rst

We should be more precise and actually whole OpenStack (not only Nova)
is a distributed, asynchronous system that is prone to race condition bugs.

Change-Id: I6af9fa40bad8cae062125f486534d1724ad9baef
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/70472/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/stress/README.rst'],1,17ffbb999e27e1079d1fcdedf3930394b0ae952c,,"OpenStack is a distributed, asynchronous system that is prone to race condition","Nova is a distributed, asynchronous system that is prone to race condition",1,1
openstack%2Fdevstack~master~I413587130c64ca4f5f467b2ea1c0ab12867999ce,openstack/devstack,master,I413587130c64ca4f5f467b2ea1c0ab12867999ce,LDAP root DN creation fails,MERGED,2014-02-01 01:03:11.000000000,2014-02-01 14:04:21.000000000,2014-02-01 14:04:20.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2218}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-02-01 01:03:11.000000000', 'files': ['files/ldap/manager.ldif.in'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7bc783b95b2e115f40a4db8823823573afe7a768', 'message': ""LDAP root DN creation fails\n\nWhen keystone is configured to set up an LDAP server to use as\nit's identity backend, the creation of the root DN fails.  The\nproblem is that one of the mods in the modify operation that sets\nup the root DN is incorrect, which causes the entire modify\noperation to fail.  The incorrect mod is attempting to configure\nsome attribute indexes, but one of the attributes it specifies is\nundefined.  This patch removes the undefined attribute from the\ntemplate that is used to create the modify operation.\n\nChange-Id: I413587130c64ca4f5f467b2ea1c0ab12867999ce\nCloses-Bug: 1275158\n""}]",0,70488,7bc783b95b2e115f40a4db8823823573afe7a768,6,4,1,9098,,,0,"LDAP root DN creation fails

When keystone is configured to set up an LDAP server to use as
it's identity backend, the creation of the root DN fails.  The
problem is that one of the mods in the modify operation that sets
up the root DN is incorrect, which causes the entire modify
operation to fail.  The incorrect mod is attempting to configure
some attribute indexes, but one of the attributes it specifies is
undefined.  This patch removes the undefined attribute from the
template that is used to create the modify operation.

Change-Id: I413587130c64ca4f5f467b2ea1c0ab12867999ce
Closes-Bug: 1275158
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/70488/1 && git format-patch -1 --stdout FETCH_HEAD,['files/ldap/manager.ldif.in'],1,7bc783b95b2e115f40a4db8823823573afe7a768,bug/1275158,"olcDbIndex: cn,sn,givenName","olcDbIndex: cn,sn,givenName,co",1,1
openstack%2Ftempest~master~I350178ba9820dd2579cf8063f7dedb756c651ab5,openstack/tempest,master,I350178ba9820dd2579cf8063f7dedb756c651ab5,Add bool and integer support to XML parser,MERGED,2014-01-13 10:19:13.000000000,2014-02-01 13:58:37.000000000,2014-02-01 13:58:36.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 6072}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7872}, {'_account_id': 7930}]","[{'number': 1, 'created': '2014-01-13 10:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e35a1d841fd0bbdccbbfa3a8276bee586bbf2801', 'message': 'Add bool support to XML parser\n\nIf parameter has a boolean value XML parser converts it to string.\nThis change makes XML parser to convert it to boolean value.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 2, 'created': '2014-01-13 11:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6399a44d57c40082d02a9418c3a5860de6ae7451', 'message': 'Add bool support to XML parser\n\nIf parameter has a boolean value XML parser converts it to string.\nThis change makes XML parser to convert it to boolean value.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 3, 'created': '2014-01-13 13:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a14d97eb7e8d1b0e12abaf44b7eb08194e55a6f2', 'message': 'Add bool support to XML parser\n\nIf parameter has a boolean value XML parser converts it to string.\nThis change makes XML parser to convert it to boolean value.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 4, 'created': '2014-01-14 11:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3a10ac1c0e21faf0d55eb8c607b750b45e7aa2dd', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 5, 'created': '2014-01-15 10:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4277b10f74cce7b9f9707cac33bdb40e9098f245', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 6, 'created': '2014-01-17 07:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e9446738ac613596d477c7267052f8be4a67361a', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 7, 'created': '2014-01-20 07:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a53fecdf5a7bb1bd7519e840274782eaea880a91', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 8, 'created': '2014-01-21 06:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f392af65128139f1541cc83db8003e5eddaa2b2c', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 9, 'created': '2014-01-22 07:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/75b6eb5be6ac939098dd14d9a0d59081b1ef0eec', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 10, 'created': '2014-01-22 13:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8ff89c67b056279ab61a915e3e9e4d97559c30aa', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 11, 'created': '2014-01-23 12:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/60bd6b7fd458300e9e752f1201129bae345aa495', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nThis is needed for changes:\n  https://review.openstack.org/63999\n  https://review.openstack.org/65943\n  https://review.openstack.org/66541\n  https://review.openstack.org/66796\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 12, 'created': '2014-01-28 11:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45e84502d453445ecfc362edd67c2738eeb0cd47', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nThis is needed for changes:\n  https://review.openstack.org/63999\n  https://review.openstack.org/65943\n  https://review.openstack.org/66541\n  https://review.openstack.org/66796\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 13, 'created': '2014-01-29 10:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/81d183b26ddfc9b2bb8aab974cc8ce42062906e5', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nThis is needed for changes:\n  https://review.openstack.org/63999\n  https://review.openstack.org/65943\n  https://review.openstack.org/66541\n  https://review.openstack.org/66796\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 14, 'created': '2014-01-30 09:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/df808e22eab44751d9a168fef947446aaaa6ad20', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nThis is needed for changes:\n  https://review.openstack.org/63999\n  https://review.openstack.org/65943\n  https://review.openstack.org/66541\n  https://review.openstack.org/66796\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}, {'number': 15, 'created': '2014-01-30 10:15:46.000000000', 'files': ['tempest/tests/test_compute_xml_common.py', 'tempest/services/compute/xml/common.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f6bd57887e3632e3b38c7799f81c5e1786ec168a', 'message': 'Add bool and integer support to XML parser\n\nXML parser always returns value of all simple types as a string.\nThis change makes XML parser to convert it to boolean/integer/long\nvalue if necessary.\n\nChange-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5\n'}]",3,66297,f6bd57887e3632e3b38c7799f81c5e1786ec168a,66,8,15,7249,,,0,"Add bool and integer support to XML parser

XML parser always returns value of all simple types as a string.
This change makes XML parser to convert it to boolean/integer/long
value if necessary.

Change-Id: I350178ba9820dd2579cf8063f7dedb756c651ab5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/97/66297/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/compute/xml/common.py'],1,e35a1d841fd0bbdccbbfa3a8276bee586bbf2801,66297, bool_flag = False if json[attr] == 'bool': bool_flag = True if not node.getchildren(): if bool_flag: return node.text == 'True' else: return node.text or json, if not node.getchildren(): return node.text or json,7,1
openstack%2Ftempest~master~Icb018631dcda0753218af8cf1cc4ad461160072c,openstack/tempest,master,Icb018631dcda0753218af8cf1cc4ad461160072c,Enable tenant isolation for the boto tests,MERGED,2014-01-27 23:19:18.000000000,2014-02-01 13:57:34.000000000,2014-02-01 13:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-01-27 23:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d2c28064e7cf230b40be5d805b3248ab86c81128', 'message': 'Enable tenant isolation for the boto tests\n\nThis commit enables using tenant isolation on the boto tests. It also\nreplaces duplicate Manager() create calls by doing this in the base\nboto test class.\n\nChange-Id: Icb018631dcda0753218af8cf1cc4ad461160072c\n'}, {'number': 2, 'created': '2014-01-28 02:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf16bd6d58104157c717f37a1f840eff6cf37637', 'message': 'Enable tenant isolation for the boto tests\n\nThis commit enables using tenant isolation on the boto tests. It also\nreplaces duplicate Manager() create calls by doing this in the base\nboto test class.\n\nChange-Id: Icb018631dcda0753218af8cf1cc4ad461160072c\n'}, {'number': 3, 'created': '2014-01-30 20:19:38.000000000', 'files': ['tempest/thirdparty/boto/test_ec2_volumes.py', 'tempest/thirdparty/boto/test_s3_objects.py', 'tempest/thirdparty/boto/test_ec2_network.py', 'tempest/thirdparty/boto/test.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/thirdparty/boto/test_ec2_security_groups.py', 'tempest/thirdparty/boto/test_ec2_keys.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py', 'tempest/test.py', 'tempest/thirdparty/boto/test_s3_buckets.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8004e8c38f07655a2d91cb4ba1cd0e067951c870', 'message': 'Enable tenant isolation for the boto tests\n\nThis commit enables using tenant isolation on the boto tests. It also\nreplaces duplicate Manager() create calls by doing this in the base\nboto test class.\n\nChange-Id: Icb018631dcda0753218af8cf1cc4ad461160072c\n'}]",4,69500,8004e8c38f07655a2d91cb4ba1cd0e067951c870,14,4,3,5196,,,0,"Enable tenant isolation for the boto tests

This commit enables using tenant isolation on the boto tests. It also
replaces duplicate Manager() create calls by doing this in the base
boto test class.

Change-Id: Icb018631dcda0753218af8cf1cc4ad461160072c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/69500/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/thirdparty/boto/test_ec2_volumes.py', 'tempest/thirdparty/boto/test_s3_objects.py', 'tempest/thirdparty/boto/test.py', 'tempest/thirdparty/boto/test_ec2_network.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/thirdparty/boto/test_ec2_security_groups.py', 'tempest/thirdparty/boto/test_ec2_keys.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py', 'tempest/test.py', 'tempest/thirdparty/boto/test_s3_buckets.py']",10,d2c28064e7cf230b40be5d805b3248ab86c81128,boto-isolation,,from tempest import clients cls.os = clients.Manager(),17,21
openstack%2Fdevstack~master~Iddf8538ad0a1e36e2c6944dc70315984026c8245,openstack/devstack,master,Iddf8538ad0a1e36e2c6944dc70315984026c8245,Make MySQL query logging optional,MERGED,2014-01-25 01:38:11.000000000,2014-02-01 13:47:51.000000000,2014-02-01 13:47:50.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-01-25 01:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/aa064c72e45a1d6744ff6d7b3053bdc883959fba', 'message': 'Make MySQL query logging optional\n\n* lib/databases/mysql: Wrap query log configuration in a check for a\nENABLE_QUERY_LOGGING variable.\n\n* stackrc: Add the ENABLE_QUERY_LOGGING variable defaulted to True.\n\nChange-Id: Iddf8538ad0a1e36e2c6944dc70315984026c8245\n'}, {'number': 2, 'created': '2014-01-25 17:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/043102403cc9b531773746fbb38c570c7197cad3', 'message': 'Make MySQL query logging optional\n\n* lib/databases/mysql: Wrap query log configuration in a check for a\nENABLE_QUERY_LOGGING variable.\n\n* stackrc: Add the DATABASE_QUERY_LOGGING variable defaulted to True.\n\nChange-Id: Iddf8538ad0a1e36e2c6944dc70315984026c8245\n'}, {'number': 3, 'created': '2014-01-31 20:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/27854ec946bee9b7e55880e7eca04e4c1d7a585b', 'message': 'Make MySQL query logging optional\n\n* lib/databases/mysql: Wrap query log configuration in a check for a\nENABLE_QUERY_LOGGING variable.\n\n* stackrc: Add the DATABASE_QUERY_LOGGING variable defaulted to True.\n\nChange-Id: Iddf8538ad0a1e36e2c6944dc70315984026c8245\n'}, {'number': 4, 'created': '2014-01-31 20:39:49.000000000', 'files': ['lib/databases/mysql', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c4f47345a588b15d83ebc5584c8698843b568a40', 'message': 'Make MySQL query logging optional\n\n* lib/databases/mysql: Wrap query log configuration in a check for a\nENABLE_QUERY_LOGGING variable.\n\n* stackrc: Add the DATABASE_QUERY_LOGGING variable defaulted to True.\n\nChange-Id: Iddf8538ad0a1e36e2c6944dc70315984026c8245\n'}]",3,69075,c4f47345a588b15d83ebc5584c8698843b568a40,14,4,4,5263,,,0,"Make MySQL query logging optional

* lib/databases/mysql: Wrap query log configuration in a check for a
ENABLE_QUERY_LOGGING variable.

* stackrc: Add the DATABASE_QUERY_LOGGING variable defaulted to True.

Change-Id: Iddf8538ad0a1e36e2c6944dc70315984026c8245
",git fetch https://review.opendev.org/openstack/devstack refs/changes/75/69075/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/databases/mysql', 'stackrc']",2,aa064c72e45a1d6744ff6d7b3053bdc883959fba,mysql-slowlog,# This can be used to turn database query logging on and off # (currently only implemented for MySQL backend) ENABLE_QUERY_LOGGING=True,,17,9
openstack%2Fpuppet-neutron~master~I6c5fa5426162e2dd358a360324abb040c7462f16,openstack/puppet-neutron,master,I6c5fa5426162e2dd358a360324abb040c7462f16,Prefix database parameters with database,MERGED,2014-01-28 18:52:15.000000000,2014-02-01 13:13:23.000000000,2014-02-01 13:13:22.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-01-28 18:52:15.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a6232366a2d538447a6568ec61ddbe9fcbdecad6', 'message': 'Prefix database parameters with database\n\nBe consistent with other puppet modules for OpenStack by prefixing\ndatabase related parameters with database.\n\nProperly deprecate sql_* parameters and other database parameters.\n\nCloses-bug: #1273771\nChange-Id: I6c5fa5426162e2dd358a360324abb040c7462f16\n'}]",0,69697,a6232366a2d538447a6568ec61ddbe9fcbdecad6,7,4,1,7156,,,0,"Prefix database parameters with database

Be consistent with other puppet modules for OpenStack by prefixing
database related parameters with database.

Properly deprecate sql_* parameters and other database parameters.

Closes-bug: #1273771
Change-Id: I6c5fa5426162e2dd358a360324abb040c7462f16
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/97/69697/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",2,a6232366a2d538447a6568ec61ddbe9fcbdecad6,bug/1273771,"# [*database_connection*]# (Defaults to 'sqlite:////var/lib/neutron/ovs.sqlite') # # [*sql_connection*] # DEPRECATED: Use database_connection instead. # # [*connection*] # DEPRECATED: Use database_connection instead. # # [*database_max_retries*] # (optional) Maximum database connection retries during startup. # (Defaults to 10) # # [*sql_max_retries*] # DEPRECATED: Use database_max_retries instead.# DEPRECATED: Use database_max_retries instead. # # [*database_idle_timeout*] # (optional) Timeout before idle database connections are reaped. # Deprecates sql_idle_timeout # (Defaults to 3600) # # [*sql_idle_timeout*] # DEPRECATED: Use database_idle_timeout instead.# DEPRECATED: Use database_idle_timeout instead. # # [*database_retry_interval*] # (optional) Interval between retries of opening a database connection. # (Defaults to 10) # # [*sql_reconnect_interval*] # DEPRECATED: Use database_retry_interval instead.# DEPRECATED: Use database_retry_interval instead. $database_connection = 'sqlite:////var/lib/neutron/ovs.sqlite', $database_max_retries = 10, $database_idle_timeout = 3600, $database_retry_interval = 10, $router_scheduler_driver = 'neutron.scheduler.l3_agent_scheduler.ChanceScheduler', # DEPRECATED PARAMETERS $sql_connection = undef, $connection = undef, $sql_max_retries = undef, $max_retries = undef, $sql_idle_timeout = undef, $idle_timeout = undef, $sql_reconnect_interval = undef, $retry_interval = undef, warning('The sql_connection parameter is deprecated, use database_connection instead.') $database_connection_real = $sql_connection } elsif $connection { warning('The connection parameter is deprecated, use database_connection instead.') $database_connection_real = $connection } else { $database_connection_real = $database_connection warning('The sql_max_retries parameter is deprecated, use database_max_retries instead.') $database_max_retries_real = $sql_max_retries } elsif $connection { warning('The max_retries parameter is deprecated, use database_max_retries instead.') $database_max_retries_real = $max_retries } else { $database_max_retries_real = $database_max_retries warning('The sql_idle_timeout parameter is deprecated, use database_idle_timeout instead.') $database_idle_timeout_real = $sql_idle_timeout } elsif $idle_timeout { warning('The dle_timeout parameter is deprecated, use database_idle_timeout instead.') $database_idle_timeout_real = $idle_timeout } else { $database_idle_timeout_real = $database_idle_timeout } if $sql_reconnect_interval { warning('The sql_reconnect_interval parameter is deprecated, use database_retry_interval instead.') $database_retry_interval_real = $sql_reconnect_interval } elsif $retry_interval { warning('The retry_interval parameter is deprecated, use database_retry_interval instead.') $database_retry_interval_real = $retry_interval } else { $database_retry_interval_real = $database_retry_interval } validate_re($database_connection_real, '(sqlite|mysql|postgresql):\/\/(\S+:\S+@\S+\/\S+)?') case $database_connection_real { fail(""Invalid database_connection parameter: ${database_connection_real}"") 'database/connection': value => $database_connection_real; 'database/idle_timeout': value => $database_idle_timeout_real; 'database/retry_interval': value => $database_retry_interval_real; 'database/max_retries': value => $database_max_retries_real;","# [*connection*]# Deprecates sql_connection # Defaults to: sqlite:////var/lib/neutron/ovs.sqlite# (optional) Database reconnection retry times. # Deprecates sql_max_retries # Defaults to: 10# (optional) Timeout before idle db connections are reaped. # Deprecates sql_idle_timeout # Defaults to: 3600# (optional) Database reconnection interval in seconds. # Deprecates reconnect_interval # Defaults to: 10 $sql_connection = false, $connection = 'sqlite:////var/lib/neutron/ovs.sqlite', $max_retries = '10', $sql_max_retries = false, $sql_idle_timeout = false, $idle_timeout = '3600', $reconnect_interval = false, $retry_interval = '10', $router_scheduler_driver = 'neutron.scheduler.l3_agent_scheduler.ChanceScheduler' warning('sql_connection deprecated for connection') $connection_real = $sql_connection } else { $connection_real = $connection warning('sql_max_retries deprecated for max_retries') $max_retries_real = $sql_max_retries } else { $max_retries_real = $max_retries warning('sql_idle_timeout deprecated for idle_timeout') $idle_timeout_real = $sql_idle_timeout } else { $idle_timeout_real = $idle_timeout } if $reconnect_interval { warning('reconnect_interval deprecated for retry_interval') $retry_interval_real = $reconnect_interval } else { $retry_interval_real = $retry_interval } validate_re($connection_real, '(sqlite|mysql|postgresql):\/\/(\S+:\S+@\S+\/\S+)?') case $connection_real { fail(""Invalid sql connection: ${connection_real}"") 'database/connection': value => $connection_real; 'database/idle_timeout': value => $idle_timeout_real; 'database/retry_interval': value => $retry_interval_real; 'database/max_retries': value => $max_retries_real;",138,69
openstack%2Fpuppet-designate~master~Ie66b8f0685337d56828e2b3852fcc029aff621ad,openstack/puppet-designate,master,Ie66b8f0685337d56828e2b3852fcc029aff621ad,Fix wrong rspec tests filename,MERGED,2014-01-31 18:49:36.000000000,2014-02-01 13:04:07.000000000,2014-02-01 13:04:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9061}]","[{'number': 1, 'created': '2014-01-31 18:49:36.000000000', 'files': ['spec/classes/designate_db_mysql_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/1999d86d6bd085d9b3bf0709ed54fb1e2ff4e7f0', 'message': 'Fix wrong rspec tests filename\n\nLooks like the file was copied from puppet-ceilometer and forgot\nto be renamed accordingly.\n\nChange-Id: Ie66b8f0685337d56828e2b3852fcc029aff621ad\n'}]",0,70394,1999d86d6bd085d9b3bf0709ed54fb1e2ff4e7f0,6,3,1,7156,,,0,"Fix wrong rspec tests filename

Looks like the file was copied from puppet-ceilometer and forgot
to be renamed accordingly.

Change-Id: Ie66b8f0685337d56828e2b3852fcc029aff621ad
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/94/70394/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/designate_db_mysql_spec.rb'],1,1999d86d6bd085d9b3bf0709ed54fb1e2ff4e7f0,rename_spec_file,,,0,0
openstack%2Foslo.messaging~master~I9e157810caa7a45e9a61ec571cfe9024fabacf93,openstack/oslo.messaging,master,I9e157810caa7a45e9a61ec571cfe9024fabacf93,Fix UnboundLocalError error,MERGED,2014-01-24 11:15:21.000000000,2014-02-01 10:54:57.000000000,2014-02-01 10:54:57.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 7781}, {'_account_id': 9107}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-01-24 11:15:21.000000000', 'files': ['oslo/messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7295d8fdd2a708128c792eb63de38268fc55ad0d', 'message': 'Fix UnboundLocalError error\n\nThis change corrects the UnboundLocalError exception that\ncan occur if something bad happens on reconnect to RabbitMQ\n\nCloses-Bug: #1272271\n\nChange-Id: I9e157810caa7a45e9a61ec571cfe9024fabacf93\n'}]",3,68888,7295d8fdd2a708128c792eb63de38268fc55ad0d,10,7,1,7781,,,0,"Fix UnboundLocalError error

This change corrects the UnboundLocalError exception that
can occur if something bad happens on reconnect to RabbitMQ

Closes-Bug: #1272271

Change-Id: I9e157810caa7a45e9a61ec571cfe9024fabacf93
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/88/68888/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_rabbit.py'],1,7295d8fdd2a708128c792eb63de38268fc55ad0d,bug/1272271, except IOError as e: except self.connection_errors as e:, except IOError: except self.connection_errors:,2,2
openstack%2Fdevstack~master~I403dcd503aa8e74e2ba6312a0decf0d4fd0d8795,openstack/devstack,master,I403dcd503aa8e74e2ba6312a0decf0d4fd0d8795,Retry rabbitmq password change,MERGED,2014-01-30 16:22:02.000000000,2014-02-01 10:50:55.000000000,2014-02-01 10:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-01-30 16:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f612f73accdc2c155274aeb7d44b37c3dd6fed96', 'message': 'Retry rabbitmq password change\n\nDue to the bug referenced below, on Fedora it is possible for\nthe rabbitmq password change to fail the first time rabbitmq is\nstarted.  This change adds a retry loop to avoid the problem in\ndevstack.  One retry should be enough in most (all?) cases, but\nthis will retry up to ten times just to be safe.\n\nNote that just retrying the password change is not enough.  The\nrabbitmq-server service must be restarted as well.\n\nChange-Id: I403dcd503aa8e74e2ba6312a0decf0d4fd0d8795\nbz: https://bugzilla.redhat.com/show_bug.cgi?id=1059028\n'}, {'number': 2, 'created': '2014-01-30 18:54:40.000000000', 'files': ['lib/rpc_backend'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ec5918f2f6ee54c3384e85866e98b67ef01e1e1e', 'message': 'Retry rabbitmq password change\n\nDue to the bug referenced below, on Fedora it is possible for\nthe rabbitmq password change to fail the first time rabbitmq is\nstarted.  This change adds a retry loop to avoid the problem in\ndevstack.  One retry should be enough in most (all?) cases, but\nthis will retry up to ten times just to be safe.\n\nNote that just retrying the password change is not enough.  The\nrabbitmq-server service must be restarted as well.\n\nChange-Id: I403dcd503aa8e74e2ba6312a0decf0d4fd0d8795\nbz: https://bugzilla.redhat.com/show_bug.cgi?id=1059028\n'}]",8,70156,ec5918f2f6ee54c3384e85866e98b67ef01e1e1e,12,4,2,6928,,,0,"Retry rabbitmq password change

Due to the bug referenced below, on Fedora it is possible for
the rabbitmq password change to fail the first time rabbitmq is
started.  This change adds a retry loop to avoid the problem in
devstack.  One retry should be enough in most (all?) cases, but
this will retry up to ten times just to be safe.

Note that just retrying the password change is not enough.  The
rabbitmq-server service must be restarted as well.

Change-Id: I403dcd503aa8e74e2ba6312a0decf0d4fd0d8795
bz: https://bugzilla.redhat.com/show_bug.cgi?id=1059028
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/70156/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/rpc_backend'],1,f612f73accdc2c155274aeb7d44b37c3dd6fed96,retry-rabbit," # NOTE(bnemec): Retry initial rabbitmq configuration to deal with # the fact that sometimes it fails to start properly. # Reference: https://bugzilla.redhat.com/show_bug.cgi?id=1059028 for i in `seq 10`; do restart_service rabbitmq-server sudo rabbitmqctl change_password guest $RABBIT_PASSWORD && break sleep 10 done else # change the rabbit password since the default is ""guest"" sudo rabbitmqctl change_password guest $RABBIT_PASSWORD"," restart_service rabbitmq-server # change the rabbit password since the default is ""guest"" sudo rabbitmqctl change_password guest $RABBIT_PASSWORD",11,3
openstack%2Fgovernance~master~I31c18a0074224b973cb44373993d3e7e20a7d085,openstack/governance,master,I31c18a0074224b973cb44373993d3e7e20a7d085,Mention scope expansion in incubation requirements,MERGED,2013-12-17 11:51:40.000000000,2014-02-01 08:50:19.000000000,2014-02-01 08:50:19.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 67}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2243}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-12-17 11:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/47305dc71c33e4a80fdd870b8a0969e5c61dd4fe', 'message': ""Mention scope expansion in incubation requirements\n\nThe incubation requirements mention that a project should have a clearly\ndefined and non-overlapping scope, but we don't make any mention about\nour cautious approach to widening the scope of OpenStack.\n\nBrought up here:\n\n  http://lists.openstack.org/pipermail/openstack-dev/2013-December/022412.html\n\nChange-Id: I31c18a0074224b973cb44373993d3e7e20a7d085\n""}, {'number': 2, 'created': '2014-01-14 14:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/dfd89adaa5a6631ebc5b700aba610b0d8e3c31b6', 'message': ""Mention scope expansion in incubation requirements\n\nThe incubation requirements mention that a project should have a clearly\ndefined and non-overlapping scope, but we don't make any mention about\nour cautious approach to widening the scope of OpenStack.\n\nBrought up here:\n\n  http://lists.openstack.org/pipermail/openstack-dev/2013-December/022412.html\n\nChange-Id: I31c18a0074224b973cb44373993d3e7e20a7d085\n""}, {'number': 3, 'created': '2014-01-21 20:58:09.000000000', 'files': ['reference/incubation-integration-requirements'], 'web_link': 'https://opendev.org/openstack/governance/commit/5364f15fbdffa387c7f900ab4732026eef906dba', 'message': ""Mention scope expansion in incubation requirements\n\nThe incubation requirements mention that a project should have a clearly\ndefined and non-overlapping scope, but we don't make any mention about\nour cautious approach to widening the scope of OpenStack.\n\nBrought up here:\n\n  http://lists.openstack.org/pipermail/openstack-dev/2013-December/022412.html\n\nChange-Id: I31c18a0074224b973cb44373993d3e7e20a7d085\n""}]",5,62612,5364f15fbdffa387c7f900ab4732026eef906dba,39,12,3,1247,,,0,"Mention scope expansion in incubation requirements

The incubation requirements mention that a project should have a clearly
defined and non-overlapping scope, but we don't make any mention about
our cautious approach to widening the scope of OpenStack.

Brought up here:

  http://lists.openstack.org/pipermail/openstack-dev/2013-December/022412.html

Change-Id: I31c18a0074224b973cb44373993d3e7e20a7d085
",git fetch https://review.opendev.org/openstack/governance refs/changes/12/62612/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/incubation-integration-requirements'],1,47305dc71c33e4a80fdd870b8a0969e5c61dd4fe,,"** Project must have a clear and defined scope which, in turn, represents a measured and obvious progression for OpenStack as a whole.",** Project must have a clear and defined scope,2,1
openstack%2Ftempest~master~If56b28d0efb6364fe2105f7d62d6a2b05b906070,openstack/tempest,master,If56b28d0efb6364fe2105f7d62d6a2b05b906070,Removes vim headers 4th round,MERGED,2014-01-30 15:10:28.000000000,2014-02-01 08:34:40.000000000,2014-02-01 08:34:39.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 7872}]","[{'number': 1, 'created': '2014-01-30 15:10:28.000000000', 'files': ['tempest/api/compute/servers/test_server_metadata_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ddbe412516ce8d8fef9b5f9b29bc3099b9ab445', 'message': ""Removes vim headers 4th round\n\nThis is a follow up on:\n   Change-Id: Ie8097db6c60481749c88991864187ade64f39ecb\n\nThe vim headers in all the files are being removed. We've missed these\nfiles because of delays in the patches.\nI hope this is the last one for Tempest.\nCloses-Bug: #1229324\n\nChange-Id: If56b28d0efb6364fe2105f7d62d6a2b05b906070\n""}]",0,70133,9ddbe412516ce8d8fef9b5f9b29bc3099b9ab445,7,4,1,5689,,,0,"Removes vim headers 4th round

This is a follow up on:
   Change-Id: Ie8097db6c60481749c88991864187ade64f39ecb

The vim headers in all the files are being removed. We've missed these
files because of delays in the patches.
I hope this is the last one for Tempest.
Closes-Bug: #1229324

Change-Id: If56b28d0efb6364fe2105f7d62d6a2b05b906070
",git fetch https://review.opendev.org/openstack/tempest refs/changes/33/70133/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_metadata_negative.py'],1,9ddbe412516ce8d8fef9b5f9b29bc3099b9ab445,remove-vim-header-4th,,# vim: tabstop=4 shiftwidth=4 softtabstop=4 ,0,2
openstack%2Fopenstack-planet~master~I04305fe4c6bc63d3463f359a932c5335da9406c1,openstack/openstack-planet,master,I04305fe4c6bc63d3463f359a932c5335da9406c1,Added mfisch to Planet OpenStack,MERGED,2014-02-01 03:55:15.000000000,2014-02-01 08:17:07.000000000,2014-02-01 08:17:07.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-02-01 03:55:15.000000000', 'files': ['planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/3bcc625daa6ad25d18e3f4e943651757de0ed13f', 'message': 'Added mfisch to Planet OpenStack\n\nChange-Id: I04305fe4c6bc63d3463f359a932c5335da9406c1\n'}]",0,70510,3bcc625daa6ad25d18e3f4e943651757de0ed13f,5,2,1,9500,,,0,"Added mfisch to Planet OpenStack

Change-Id: I04305fe4c6bc63d3463f359a932c5335da9406c1
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/10/70510/1 && git format-patch -1 --stdout FETCH_HEAD,['planet.ini'],1,3bcc625daa6ad25d18e3f4e943651757de0ed13f,mfisch, [http://www.mattfischer.com/blog/?feed=rss2&cat=50] name = Matt Fischer nick = mfisch,,4,0
openstack%2Ftempest~master~Ide865012269d3f60250d24443e4f20af263ee021,openstack/tempest,master,Ide865012269d3f60250d24443e4f20af263ee021,Matches one flavor and one image by default,MERGED,2014-01-30 18:10:22.000000000,2014-02-01 07:57:20.000000000,2014-02-01 07:57:19.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 7872}]","[{'number': 1, 'created': '2014-01-30 18:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b612786582a3cdf1f9e921fb8045c99edacc47b5', 'message': 'Matches one flavor and one image by default\n\nChanges default in the input-scenario settings to match only\none image and one flavor, to avoid consuming gate time.\n\nFixes bug 1274628\n\nChange-Id: Ide865012269d3f60250d24443e4f20af263ee021\n'}, {'number': 2, 'created': '2014-01-30 19:44:11.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/99901c043edda0cc8cc3fd39986615b64f6a72f2', 'message': 'Matches one flavor and one image by default\n\nChanges default in the input-scenario settings to match only\none image and one flavor, to avoid consuming gate time.\n\nFixes bug 1274628\n\nChange-Id: Ide865012269d3f60250d24443e4f20af263ee021\n'}]",0,70179,99901c043edda0cc8cc3fd39986615b64f6a72f2,8,4,2,1921,,,0,"Matches one flavor and one image by default

Changes default in the input-scenario settings to match only
one image and one flavor, to avoid consuming gate time.

Fixes bug 1274628

Change-Id: Ide865012269d3f60250d24443e4f20af263ee021
",git fetch https://review.opendev.org/openstack/tempest refs/changes/79/70179/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,b612786582a3cdf1f9e921fb8045c99edacc47b5,bug/1274628," default='^m1.nano$',"," default='^m1.(micro|nano|tiny)$',",1,1
openstack%2Fswift~feature%2Fec~I4c3ac2fec3184b783e94c3a0605d336cc319bbb9,openstack/swift,feature/ec,I4c3ac2fec3184b783e94c3a0605d336cc319bbb9,Merge remote-tracking branch 'upstream/master' into feature/ec,MERGED,2014-01-31 21:17:42.000000000,2014-02-01 07:43:20.000000000,2014-02-01 07:43:19.000000000,"[{'_account_id': 3}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-01-31 21:17:42.000000000', 'files': ['test/unit/obj/test_diskfile.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3a871e286a648be74ef9a1a36994c3a940d67b5a', 'message': ""Merge remote-tracking branch 'upstream/master' into feature/ec\n\nConflicts:\n\tswift/proxy/controllers/obj.py\n\ttest/unit/obj/test_diskfile.py\n\nChange-Id: I4c3ac2fec3184b783e94c3a0605d336cc319bbb9\n""}]",0,70442,3a871e286a648be74ef9a1a36994c3a940d67b5a,12,2,1,2622,,,0,"Merge remote-tracking branch 'upstream/master' into feature/ec

Conflicts:
	swift/proxy/controllers/obj.py
	test/unit/obj/test_diskfile.py

Change-Id: I4c3ac2fec3184b783e94c3a0605d336cc319bbb9
",git fetch https://review.opendev.org/openstack/swift refs/changes/42/70442/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_diskfile.py', 'swift/proxy/controllers/obj.py']",2,3a871e286a648be74ef9a1a36994c3a940d67b5a,bug/1269473,"from swift.common.storage_policy import POLICY_INDEX response=None, max_lo_time=86400): self, lcontainer, listing, obj_ring, resp, self, lcontainer, listing, obj_ring, resp, partition, nodes = obj_ring.get_nodes(","<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) HTTPClientDisconnect, HTTPNotImplemented, HTTPException from swift.common.storage_policy import POLICY_INDEX =======>>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) response=None, is_slo=False, max_lo_time=86400): ======= def __init__(self, controller, container, listing, response=None, max_lo_time=86400): >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) def _slo_listing_obj_iter(self, incoming_req, obj_ring, account, container, obj, partition=None, initial_resp=None): """""" The initial_resp indicated that this is a SLO manifest file. This will create an iterable that will expand nested SLOs as it walks though the listing. :params incoming_req: The original GET request from client :params initial_resp: the first resp from the above request """""" if initial_resp and initial_resp.status_int == HTTP_OK and \ incoming_req.method == 'GET' and not incoming_req.range: valid_resp = initial_resp else: new_req = incoming_req.copy_get() new_req.method = 'GET' new_req.range = None new_req.path_info = '/'.join(['/v1', account, container, obj]) if partition is None: try: partition = obj_ring.get_part( account, container, obj) except ValueError: raise HTTPException( ""Invalid path to whole SLO manifest: %s"" % new_req.path) valid_resp = self.GETorHEAD_base( new_req, _('Object'), obj_ring, partition, new_req.swift_entity_path) if 'swift.authorize' in incoming_req.environ: incoming_req.acl = valid_resp.headers.get('x-container-read') auth_resp = incoming_req.environ['swift.authorize'](incoming_req) if auth_resp: raise ListingIterNotAuthorized(auth_resp) if valid_resp.status_int == HTTP_NOT_FOUND: raise ListingIterNotFound() elif not is_success(valid_resp.status_int): raise ListingIterError() try: listing = json.loads(valid_resp.body) except ValueError: listing = [] for seg_dict in listing: if config_true_value(seg_dict.get('sub_slo')): if incoming_req.method == 'HEAD': override_bytes_from_content_type(seg_dict, logger=self.app.logger) yield seg_dict continue sub_path = get_valid_utf8_str(seg_dict['name']) sub_cont, sub_obj = split_path(sub_path, 2, 2, True) self.slo_recursion_depth += 1 if self.slo_recursion_depth >= self.max_slo_recusion_depth: raise ListingIterError(""Max recursion depth exceeded"") for sub_seg_dict in self._slo_listing_obj_iter( incoming_req, obj_ring, account, sub_cont, sub_obj): yield sub_seg_dict self.slo_recursion_depth -= 1 else: yield seg_dict ======= >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) if config_true_value(resp.headers.get('x-static-large-object')) and \ req.params.get('multipart-manifest') == 'get' and \ 'X-Copy-From' not in req.headers and \ self.app.allow_static_large_object: resp.content_type = 'application/json' resp.charset = 'utf-8' if config_true_value(resp.headers.get('x-static-large-object')) and \ req.params.get('multipart-manifest') != 'get' and \ self.app.allow_static_large_object: large_object = 'SLO' lcontainer = None # container name is included in listing try: seg_iter = iter(self._slo_listing_obj_iter( req, obj_ring, self.account_name, self.container_name, self.object_name, partition=partition, initial_resp=resp)) listing_page1 = [] for seg in seg_iter: listing_page1.append(seg) if len(listing_page1) >= CONTAINER_LISTING_LIMIT: break listing = itertools.chain(listing_page1, self._remaining_items(seg_iter)) except ListingIterNotFound: return HTTPNotFound(request=req) except ListingIterNotAuthorized, err: return err.aresp except ListingIterError: return HTTPServerError(request=req) except StopIteration: listing_page1 = listing = () except HTTPException: return HTTPServiceUnavailable( ""Unable to load SLO manifest"", request=req) ======= >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) self, lcontainer, listing, obj_ring, resp, is_slo=(large_object == 'SLO'), ======= self, lcontainer, listing, resp, >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) self, lcontainer, listing, obj_ring, resp, is_slo=(large_object == 'SLO'), ======= self, lcontainer, listing, resp, >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")<<<<<<< HEAD (3ecb39 Merge ""Add Storage Policy Support to the Auditor"" into featu) req.headers['x-delete-at'] = '%d' % (time.time() + x_delete_after) partition, nodes = obj_ring.get_nodes( ======= partition, nodes = self.app.object_ring.get_nodes( >>>>>>> BRANCH (4b9667 Merge ""Container Sync: Simple HTTP Proxy load balancing"")",8,152
openstack%2Ftempest~master~Ib3ea97eddc0373f6f16bdd11715e265193a16626,openstack/tempest,master,Ib3ea97eddc0373f6f16bdd11715e265193a16626,Start instances using fixed network when possible,ABANDONED,2014-01-26 08:31:10.000000000,2014-02-01 07:14:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-26 08:31:10.000000000', 'files': ['tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/base.py', 'tempest/api/volume/test_volumes_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a326a843a31f815202a29f65bc47c66e214279dc', 'message': 'Start instances using fixed network when possible\n\nThis is the same as Ia78582cac3790653c2281a5b63d953cd46d5c290 but for\nvolume API tests.\n\nChange-Id: Ib3ea97eddc0373f6f16bdd11715e265193a16626\n'}]",0,69181,a326a843a31f815202a29f65bc47c66e214279dc,3,1,1,4460,,,0,"Start instances using fixed network when possible

This is the same as Ia78582cac3790653c2281a5b63d953cd46d5c290 but for
volume API tests.

Change-Id: Ib3ea97eddc0373f6f16bdd11715e265193a16626
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/69181/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/base.py', 'tempest/api/volume/test_volumes_actions.py']",3,a326a843a31f815202a29f65bc47c66e214279dc,fixed_network," networks = self.get_default_networks() cls.flavor_ref, networks=networks)", cls.flavor_ref),37,2
openstack%2Fheat~master~I6b4b862ff9f88c8fb356f0733cf490669f832c42,openstack/heat,master,I6b4b862ff9f88c8fb356f0733cf490669f832c42,Remove vim header,ABANDONED,2014-01-02 16:17:19.000000000,2014-02-01 06:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 8641}]","[{'number': 1, 'created': '2014-01-02 16:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b15cb6f497bf1c6980cdf85b77f925701db74e2', 'message': 'Remove vim header\n\nNo need to set tabstop tons of times, this can be set in your vimrc\nfile instead.\n\nMore disucssion:\nhttp://openstack.10931.n7.nabble.com/Remove-vim-modelines-td21780.html\n\nChange-Id: I6b4b862ff9f88c8fb356f0733cf490669f832c42\nPartial-Bug: #1229324\n'}, {'number': 2, 'created': '2014-01-02 16:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9c0bdcf4832cae9ef732fcc0824452f4e82ef96e', 'message': 'Remove vim header\n\nNo need to set tabstop tons of times, this can be set in your vimrc\nfile instead.\n\nMore disucssion:\nhttp://openstack.10931.n7.nabble.com/Remove-vim-modelines-td21780.html\n\nChange-Id: I6b4b862ff9f88c8fb356f0733cf490669f832c42\nPartial-Bug: #1229324\n'}, {'number': 3, 'created': '2014-01-09 16:09:01.000000000', 'files': ['heat/tests/test_urlfetch.py', 'heat/tests/test_dependencies.py', 'heat/tests/test_s3.py', 'heat/engine/properties.py', 'heat/db/sync.py', 'heat/api/openstack/v1/stacks.py', 'heat/api/openstack/v1/__init__.py', 'heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py', 'contrib/rackspace/heat/tests/test_clouddatabase.py', 'heat/engine/resources/swift.py', 'heat/engine/resources/loadbalancer.py', 'heat/tests/test_dbinstance.py', 'heat/common/crypt.py', 'heat/api/openstack/v1/build_info.py', 'heat/engine/resources/network_interface.py', 'heat/tests/test_api_openstack_v1_views_stacks_view_builder.py', 'heat/db/sqlalchemy/api.py', 'heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py', 'heat/engine/clients.py', 'heat/engine/dependencies.py', 'heat/engine/resources/s3.py', 'heat/tests/test_cloudwatch.py', 'heat/db/sqlalchemy/filters.py', 'heat/engine/resources/stack.py', 'heat/tests/test_server.py', 'heat/engine/resources/random_string.py', 'heat/tests/test_plugin_loader.py', 'heat/tests/test_api_openstack_v1_util.py', 'contrib/rackspace/heat/tests/test_auto_scale.py', 'heat/tests/test_loguserdata.py', 'contrib/rackspace/heat/tests/test_rackspace_clients.py', 'contrib/rackspace/heat/engine/plugins/cloud_loadbalancer.py', 'heat/engine/resources/resource_group.py', 'heat/engine/resources/eip.py', 'heat/tests/test_resource_group.py', 'heat/api/openstack/v1/events.py', 'heat/common/plugin_loader.py', 'heat/api/aws/exception.py', 'heat/engine/resources/neutron/security_group.py', 'heat/tests/fakes.py', 'heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py', 'heat/tests/test_clients.py', 'contrib/docker-plugin/tests/test_docker_container.py', 'heat/api/aws/ec2token.py', 'heat/tests/test_resource.py', 'heat/tests/test_rpc_client.py', 'heat/engine/attributes.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_random_string.py', 'heat/tests/test_server_tags.py', 'heat/engine/update.py', 'heat/common/short_id.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_api_aws.py', 'heat/engine/resources/template_resource.py', 'heat/tests/test_api_cloudwatch.py', 'heat/api/aws/utils.py', 'heat/common/auth_password.py', 'heat/engine/resources/cloud_watch.py', 'heat/engine/resources/security_group.py', 'heat/tests/test_validate.py', 'heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/server.py', 'heat/engine/resources/volume.py', 'heat/tests/test_common_context.py', 'heat/tests/test_constraints.py', 'heat/engine/resources/neutron/port.py', 'heat/api/cloudwatch/watch.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_wsgi.py', 'heat/api/openstack/v1/views/views_common.py', 'heat/tests/test_nova_utils.py', 'heat/api/openstack/v1/views/stacks_view.py', 'heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py', 'heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_attributes.py', 'heat/tests/test_neutron_firewall.py', 'heat/api/openstack/versions.py', 'heat/tests/common.py', 'heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py', 'heat/tests/test_instance_network.py', 'heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py', 'heat/engine/resources/route_table.py', 'heat/tests/test_nested_stack.py', 'contrib/rackspace/heat/engine/plugins/clouddatabase.py', 'heat/tests/test_volume.py', 'heat/tests/test_user.py', 'heat/tests/utils.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/resources/subnet.py', 'heat/common/context.py', 'heat/common/custom_backend_auth.py', 'heat/tests/test_heatclient.py', 'heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py', 'heat/tests/test_instance_group_update_policy.py', 'heat/tests/test_environment.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/tests/test_parameters.py', 'heat/tests/test_short_id.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/util.py', 'heat/tests/test_stack_resource.py', 'contrib/rackspace/heat/engine/plugins/auto_scale.py', 'heat/engine/hot.py', 'heat/tests/test_metadata_refresh.py', 'heat/engine/resources/nova_utils.py', 'heat/common/exception.py', 'heat/engine/stack_resource.py', 'heat/api/cfn/versions.py', 'heat/tests/generic_resource.py', 'heat/api/middleware/version_negotiation.py', 'heat/tests/test_neutron.py', 'bin/heat-api', 'heat/tests/test_os_database.py', 'heat/engine/environment.py', 'heat/tests/test_parser.py', 'heat/api/cloudwatch/versions.py', 'heat/tests/test_security_group.py', 'heat/engine/scheduler.py', 'heat/engine/watchrule.py', 'heat/engine/service.py', 'heat/tests/test_event.py', 'heat/db/sqlalchemy/migration.py', 'heat/engine/resources/autoscaling.py', 'heat/tests/test_waitcondition.py', 'heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py', 'heat/tests/test_provider_template.py', 'heat/api/cloudwatch/__init__.py', 'heat/cmd/manage.py', 'heat/common/timeutils.py', 'heat/engine/resources/os_database.py', 'heat/api/cfn/v1/__init__.py', 'heat/tests/test_template_format.py', 'heat/api/cfn/__init__.py', 'heat/engine/event.py', 'heat/tests/test_watch.py', 'heat/db/sqlalchemy/models.py', 'heat/common/config.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/common/template_format.py', 'heat/db/sqlalchemy/mutable.py', 'heat/db/utils.py', 'heat/tests/test_iso8601_utils.py', 'tools/cfn-json2yaml', 'heat/api/cfn/v1/signal.py', 'heat/tests/__init__.py', 'bin/heat-api-cfn', 'heat/engine/signal_responder.py', 'heat/tests/test_signal.py', 'heat/engine/resources/neutron/floatingip.py', 'bin/heat-manage', 'heat/api/cfn/v1/stacks.py', 'heat/tests/test_api_ec2token.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_instance_group.py', 'contrib/rackspace/heat/engine/plugins/clients.py', 'heat/tests/test_fault_middleware.py', 'heat/engine/resources/internet_gateway.py', 'heat/tests/test_autoscaling.py', 'heat/engine/resources/user.py', 'heat/engine/timestamp.py', 'heat/tests/test_neutron_vpnservice.py', 'bin/heat-engine', 'contrib/docker-plugin/plugin/docker_container.py', 'contrib/rackspace/heat/tests/test_cloud_loadbalancer.py', 'heat/common/policy.py', 'heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py', 'heat/api/openstack/__init__.py', 'heat/engine/parser.py', 'heat/version.py', 'heat/tests/test_scheduler.py', 'heat/tests/test_identifier.py', 'heat/engine/resources/neutron/firewall.py', 'heat/tests/test_environment_format.py', 'heat/tests/test_vpc.py', 'heat/tests/test_swift.py', 'heat/engine/resources/__init__.py', 'heat/engine/resources/wait_condition.py', 'heat/api/openstack/v1/actions.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/common/auth_token.py', 'heat/rpc/client.py', 'heat/engine/parameters.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/common/heat_keystoneclient.py', 'tools/install_venv.py', 'heat/engine/resources/vpc.py', 'heat/tests/test_engine_api_utils.py', 'heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py', 'bin/heat-api-cloudwatch', 'heat/tests/test_eip.py', 'heat/common/wsgi.py', 'heat/engine/resources/instance.py', 'heat/tests/test_api_openstack_v1_views_views_common.py', 'heat/engine/constraints.py', 'heat/tests/test_engine_service.py', 'heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py', 'heat/engine/api.py', 'heat/__init__.py', 'heat/common/identifier.py', 'heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py', 'heat/tests/test_nokey.py', 'heat/engine/resources/neutron/subnet.py', 'heat/common/urlfetch.py', 'heat/db/api.py', 'heat/engine/template.py', 'heat/rpc/api.py', 'heat/engine/resources/neutron/net.py', 'heat/tests/test_properties.py', 'heat/common/environment_format.py', 'heat/engine/resources/neutron/vpnservice.py', 'doc/source/ext/resources.py', 'heat/tests/test_hot.py', 'heat/api/openstack/v1/resources.py', 'heat/tests/test_auth_password.py', 'heat/tests/test_version_negotiation_middleware.py', 'contrib/docker-plugin/tests/fake_docker_client.py', 'heat/engine/resource.py', 'heat/tests/test_ceilometer_alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5e2067b92442372cd800de56a98d96198e0e2035', 'message': 'Remove vim header\n\nNo need to set tabstop tons of times, this can be set in your vimrc\nfile instead.\n\nMore disucssion:\nhttp://openstack.10931.n7.nabble.com/Remove-vim-modelines-td21780.html\n\nChange-Id: I6b4b862ff9f88c8fb356f0733cf490669f832c42\nPartial-Bug: #1229324\n'}]",3,64691,5e2067b92442372cd800de56a98d96198e0e2035,24,7,3,8641,,,0,"Remove vim header

No need to set tabstop tons of times, this can be set in your vimrc
file instead.

More disucssion:
http://openstack.10931.n7.nabble.com/Remove-vim-modelines-td21780.html

Change-Id: I6b4b862ff9f88c8fb356f0733cf490669f832c42
Partial-Bug: #1229324
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/64691/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_urlfetch.py', 'heat/tests/test_dependencies.py', 'heat/tests/test_s3.py', 'heat/engine/properties.py', 'heat/db/sync.py', 'heat/api/openstack/v1/stacks.py', 'heat/api/openstack/v1/__init__.py', 'heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py', 'contrib/rackspace/heat/tests/test_clouddatabase.py', 'heat/engine/resources/swift.py', 'heat/engine/resources/loadbalancer.py', 'heat/tests/test_dbinstance.py', 'heat/common/crypt.py', 'heat/api/openstack/v1/build_info.py', 'heat/engine/resources/network_interface.py', 'heat/tests/test_api_openstack_v1_views_stacks_view_builder.py', 'heat/db/sqlalchemy/api.py', 'heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py', 'heat/engine/clients.py', 'heat/engine/dependencies.py', 'heat/engine/resources/s3.py', 'heat/tests/test_cloudwatch.py', 'heat/db/sqlalchemy/filters.py', 'heat/engine/resources/stack.py', 'heat/tests/test_server.py', 'heat/engine/resources/random_string.py', 'heat/tests/test_plugin_loader.py', 'heat/tests/test_api_openstack_v1_util.py', 'contrib/rackspace/heat/tests/test_auto_scale.py', 'heat/tests/test_loguserdata.py', 'contrib/rackspace/heat/tests/test_rackspace_clients.py', 'contrib/rackspace/heat/engine/plugins/cloud_loadbalancer.py', 'heat/engine/resources/resource_group.py', 'heat/engine/resources/eip.py', 'heat/tests/test_resource_group.py', 'heat/api/openstack/v1/events.py', 'heat/common/plugin_loader.py', 'heat/api/aws/exception.py', 'heat/engine/resources/neutron/security_group.py', 'heat/tests/fakes.py', 'heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py', 'heat/tests/test_clients.py', 'contrib/docker-plugin/tests/test_docker_container.py', 'heat/api/aws/ec2token.py', 'heat/tests/test_resource.py', 'heat/tests/test_rpc_client.py', 'heat/engine/attributes.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_random_string.py', 'heat/tests/test_server_tags.py', 'heat/engine/update.py', 'heat/common/short_id.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_api_aws.py', 'heat/engine/resources/template_resource.py', 'heat/tests/test_api_cloudwatch.py', 'heat/api/aws/utils.py', 'heat/common/auth_password.py', 'heat/engine/resources/cloud_watch.py', 'heat/engine/resources/security_group.py', 'heat/tests/test_validate.py', 'heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/server.py', 'heat/engine/resources/volume.py', 'heat/tests/test_common_context.py', 'heat/tests/test_constraints.py', 'heat/engine/resources/neutron/port.py', 'heat/api/cloudwatch/watch.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_wsgi.py', 'heat/api/openstack/v1/views/views_common.py', 'heat/tests/test_nova_utils.py', 'heat/api/openstack/v1/views/stacks_view.py', 'heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py', 'heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_attributes.py', 'heat/tests/test_neutron_firewall.py', 'heat/api/openstack/versions.py', 'heat/tests/common.py', 'heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py', 'heat/tests/test_instance_network.py', 'heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py', 'heat/engine/resources/route_table.py', 'heat/tests/test_nested_stack.py', 'contrib/rackspace/heat/engine/plugins/clouddatabase.py', 'heat/tests/test_volume.py', 'heat/tests/test_user.py', 'heat/tests/utils.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/resources/subnet.py', 'heat/common/context.py', 'heat/common/custom_backend_auth.py', 'heat/tests/test_heatclient.py', 'heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py', 'heat/tests/test_instance_group_update_policy.py', 'heat/tests/test_environment.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/tests/test_parameters.py', 'heat/tests/test_short_id.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/util.py', 'heat/tests/test_stack_resource.py', 'contrib/rackspace/heat/engine/plugins/auto_scale.py', 'heat/engine/hot.py', 'heat/tests/test_metadata_refresh.py', 'heat/engine/resources/nova_utils.py', 'heat/common/exception.py', 'heat/engine/stack_resource.py', 'heat/api/cfn/versions.py', 'heat/tests/generic_resource.py', 'heat/api/middleware/version_negotiation.py', 'heat/tests/test_neutron.py', 'bin/heat-api', 'heat/tests/test_os_database.py', 'heat/engine/environment.py', 'heat/tests/test_parser.py', 'heat/api/cloudwatch/versions.py', 'heat/tests/test_security_group.py', 'heat/engine/scheduler.py', 'heat/engine/watchrule.py', 'heat/engine/service.py', 'heat/tests/test_event.py', 'heat/db/sqlalchemy/migration.py', 'heat/engine/resources/autoscaling.py', 'heat/tests/test_waitcondition.py', 'heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py', 'heat/tests/test_provider_template.py', 'heat/api/cloudwatch/__init__.py', 'heat/cmd/manage.py', 'heat/common/timeutils.py', 'heat/engine/resources/os_database.py', 'heat/api/cfn/v1/__init__.py', 'heat/tests/test_template_format.py', 'heat/api/cfn/__init__.py', 'heat/engine/event.py', 'heat/tests/test_watch.py', 'heat/db/sqlalchemy/models.py', 'heat/common/config.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/common/template_format.py', 'heat/db/sqlalchemy/mutable.py', 'heat/db/utils.py', 'heat/tests/test_iso8601_utils.py', 'tools/cfn-json2yaml', 'heat/api/cfn/v1/signal.py', 'heat/tests/__init__.py', 'bin/heat-api-cfn', 'heat/engine/signal_responder.py', 'heat/tests/test_signal.py', 'heat/engine/resources/neutron/floatingip.py', 'bin/heat-manage', 'heat/api/cfn/v1/stacks.py', 'heat/tests/test_api_ec2token.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_instance_group.py', 'contrib/rackspace/heat/engine/plugins/clients.py', 'heat/tests/test_fault_middleware.py', 'heat/engine/resources/internet_gateway.py', 'heat/tests/test_autoscaling.py', 'heat/engine/resources/user.py', 'heat/engine/timestamp.py', 'heat/tests/test_neutron_vpnservice.py', 'bin/heat-engine', 'contrib/docker-plugin/plugin/docker_container.py', 'contrib/rackspace/heat/tests/test_cloud_loadbalancer.py', 'heat/common/policy.py', 'heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py', 'heat/api/openstack/__init__.py', 'heat/engine/parser.py', 'heat/version.py', 'heat/tests/test_scheduler.py', 'heat/tests/test_identifier.py', 'heat/engine/resources/neutron/firewall.py', 'heat/tests/test_environment_format.py', 'heat/tests/test_vpc.py', 'heat/tests/test_swift.py', 'heat/engine/resources/__init__.py', 'heat/engine/resources/wait_condition.py', 'heat/api/openstack/v1/actions.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/common/auth_token.py', 'heat/rpc/client.py', 'heat/engine/parameters.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/common/heat_keystoneclient.py', 'tools/install_venv.py', 'heat/engine/resources/vpc.py', 'heat/tests/test_engine_api_utils.py', 'heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py', 'bin/heat-api-cloudwatch', 'heat/tests/test_eip.py', 'heat/common/wsgi.py', 'heat/engine/resources/instance.py', 'heat/tests/test_api_openstack_v1_views_views_common.py', 'heat/engine/constraints.py', 'heat/tests/test_engine_service.py', 'heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py', 'heat/engine/api.py', 'heat/__init__.py', 'heat/common/identifier.py', 'heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py', 'heat/tests/test_nokey.py', 'heat/engine/resources/neutron/subnet.py', 'heat/common/urlfetch.py', 'heat/db/api.py', 'heat/engine/template.py', 'heat/rpc/api.py', 'heat/engine/resources/neutron/net.py', 'heat/tests/test_properties.py', 'heat/common/environment_format.py', 'heat/engine/resources/neutron/vpnservice.py', 'doc/source/ext/resources.py', 'heat/tests/test_hot.py', 'heat/api/openstack/v1/resources.py', 'heat/tests/test_auth_password.py', 'heat/tests/test_version_negotiation_middleware.py', 'contrib/docker-plugin/tests/fake_docker_client.py', 'heat/engine/resource.py', 'heat/tests/test_ceilometer_alarm.py']",223,0b15cb6f497bf1c6980cdf85b77f925701db74e2,(detached,,# vim: tabstop=4 shiftwidth=4 softtabstop=4 ,1,432
openstack%2Fglance~master~I25f140d21ccc22af4bc1b55987bdfa6136c28d5e,openstack/glance,master,I25f140d21ccc22af4bc1b55987bdfa6136c28d5e,Update tox.ini to use new features,ABANDONED,2013-12-09 13:54:10.000000000,2014-02-01 06:03:12.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 177}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 7806}, {'_account_id': 7884}, {'_account_id': 8759}]","[{'number': 2, 'created': '2013-12-09 13:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ff0578f07f596198459c8a933dbfc6b4d556f729', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 3, 'created': '2013-12-09 13:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/300d218a336e9e3dca8c1cd15680cc262cc4ee50', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 1, 'created': '2013-12-09 13:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/95ba873f60eccc3f12b73b85437d134f0db19179', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 6, 'created': '2013-12-17 18:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e779cce5ec5b40d345ce6754faf2b4a9d4bf979f', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 7, 'created': '2013-12-17 18:14:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/6d3db136a3b61e30495f086e4a26232309d25c12', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 4, 'created': '2013-12-17 18:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/78fd09cf07a7a7973bdfa3975bed1042108cecdd', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}, {'number': 5, 'created': '2013-12-17 18:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5f2dc5b2e3e57ab0377f325cdcd49a1cb1f57354', 'message': ""Update tox.ini to use new features\n\nReasons:\n - tox update v1.6\n\nChanges:\n - tox 1.6 allows us to skip the sdist step, which is slow.\n - It also allows us to override the install line. In this case, it's\n   important as it allows us to stop getting pre-release software we\n   weren't asking for.\n\nOriginal patch by Monty Taylor, talked about here:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html\n\nChange-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e\n""}]",0,60821,6d3db136a3b61e30495f086e4a26232309d25c12,65,8,7,7806,,,0,"Update tox.ini to use new features

Reasons:
 - tox update v1.6

Changes:
 - tox 1.6 allows us to skip the sdist step, which is slow.
 - It also allows us to override the install line. In this case, it's
   important as it allows us to stop getting pre-release software we
   weren't asking for.

Original patch by Monty Taylor, talked about here:
http://lists.openstack.org/pipermail/openstack-dev/2013-September/015495.html

Change-Id: I25f140d21ccc22af4bc1b55987bdfa6136c28d5e
",git fetch https://review.opendev.org/openstack/glance refs/changes/21/60821/6 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ff0578f07f596198459c8a933dbfc6b4d556f729,,minversion = 1.6 skipsdist = Trueusedevelop = True install_command = pip install {opts} {packages},,4,0
openstack%2Ftempest~master~I8a9793d07d555f4394bbf94e007724ec62cdc4af,openstack/tempest,master,I8a9793d07d555f4394bbf94e007724ec62cdc4af,Add vcpu & disk testcases,ABANDONED,2013-11-26 09:37:57.000000000,2014-02-01 06:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 7189}]","[{'number': 1, 'created': '2013-11-26 09:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a513d12ae2889eab601934f098a17ea9c0ab1988', 'message': 'Add vcpu & disk testcases\nThis change adds some vcpu and disk testcases\nto check whether they are recorded in Ceilometer.\n\nChange-Id: I8a9793d07d555f4394bbf94e007724ec62cdc4af\n'}, {'number': 2, 'created': '2013-11-26 09:47:36.000000000', 'files': ['tempest/api/metering/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/de74fedc7cc051f5c8f3c5d115b5a9068a3b6cac', 'message': 'Add vcpu & disk testcases\n\nThis change adds some vcpu and disk testcases\nto check whether they are recorded in Ceilometer.\n\nChange-Id: I8a9793d07d555f4394bbf94e007724ec62cdc4af\n'}]",0,58470,de74fedc7cc051f5c8f3c5d115b5a9068a3b6cac,27,3,2,7189,,,0,"Add vcpu & disk testcases

This change adds some vcpu and disk testcases
to check whether they are recorded in Ceilometer.

Change-Id: I8a9793d07d555f4394bbf94e007724ec62cdc4af
",git fetch https://review.opendev.org/openstack/tempest refs/changes/70/58470/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/metering/compute/test_compute.py'],1,a513d12ae2889eab601934f098a17ea9c0ab1988,basedon6and14," @attr(type='gate') def test_server_vcpu(self): """"""Verify that the vcpu has been recorded."""""" resp, body = self.metering_client.get_meters( ""vcpus"", [{""field"": ""resource_id"", ""op"": ""eq"", ""value"": self.server[""id""]}] ) self.assertEquals(200, resp.status) self.assertEquals(body[0][""counter_name""], ""vcpus"") @attr(type='gate') def test_server_disk(self): """"""Verify that the disk has been recorded."""""" resp, body = self.metering_client.get_meters( ""disk.root.size"", [{""field"": ""resource_id"", ""op"": ""eq"", ""value"": self.server[""id""]}] ) self.assertEquals(200, resp.status) self.assertEquals(body[0][""counter_name""], ""disk.root.size"") resp_ephemeral, body_ephemeral = self.metering_client.get_meters( ""disk.ephemeral.size"", [{""field"": ""resource_id"", ""op"": ""eq"", ""value"": self.server[""id""]}] ) self.assertEquals(200, resp_ephemeral.status) self.assertEquals(body_ephemeral[0][""counter_name""], ""disk.ephemeral.size"")",,30,0
openstack%2Fsolum~master~Ie4d48f3fa435ed69b30ab2fc4482b1255a7b115b,openstack/solum,master,Ie4d48f3fa435ed69b30ab2fc4482b1255a7b115b,WIP: contrib script to set up local system packages for testing,ABANDONED,2014-01-17 23:59:43.000000000,2014-02-01 06:03:11.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8334}, {'_account_id': 9094}]","[{'number': 1, 'created': '2014-01-17 23:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2dea293df8aaaaf8d0350cc008aa92cf06f45b58', 'message': 'WIP: contrib script to set up local system packages for testing\n\nChange-Id: Ie4d48f3fa435ed69b30ab2fc4482b1255a7b115b\nImplements: blueprint test-system-package-scripts\n'}, {'number': 2, 'created': '2014-01-22 21:31:12.000000000', 'files': ['.gitignore', 'README.rst', 'contrib/toxbox/Vagrantfile', 'contrib/toxbox/ubuntu.sh'], 'web_link': 'https://opendev.org/openstack/solum/commit/4148714488afa26eb9f4dc5e321963c228063345', 'message': 'WIP: contrib script to set up local system packages for testing\n\nChange-Id: Ie4d48f3fa435ed69b30ab2fc4482b1255a7b115b\nImplements: blueprint test-system-package-scripts\n'}]",0,67602,4148714488afa26eb9f4dc5e321963c228063345,15,6,2,7858,,,0,"WIP: contrib script to set up local system packages for testing

Change-Id: Ie4d48f3fa435ed69b30ab2fc4482b1255a7b115b
Implements: blueprint test-system-package-scripts
",git fetch https://review.opendev.org/openstack/solum refs/changes/02/67602/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'contrib/toxbox/.vagrant/machines/ubuntu/virtualbox/action_set_name', 'contrib/toxbox/Vagrantfile', 'contrib/toxbox/.vagrant/machines/ubuntu/virtualbox/id', 'contrib/toxbox/.vagrant/machines/ubuntu/virtualbox/action_provision', 'contrib/toxbox/ubuntu.sh']",6,2dea293df8aaaaf8d0350cc008aa92cf06f45b58,bp/test-system-package-scripts,"#!/bin/sh # refresh apt cache sudo apt-get update # Some apt prereqs sudo apt-get -yqq install python-software-properties software-properties-common # Deadsnakes is a repo with various python builds. echo Add Deadsnakes Apt Repo echo ""\n"" | sudo add-apt-repository ppa:fkrull/deadsnakes sudo apt-get -yqq update # libraries echo Add supporting dev libraries sudo apt-get -yqq install libxml2-dev libxslt-dev build-essential python-dev # Python echo Add Python Versions sudo apt-get -yqq install python-gdbm python2.6 python2.7 python3.3 pypy-dev python-pip # Pip echo Install necessary PIPs pip install virtualenv pecan WSME tox pep8 echo Done. ",,89,7
openstack%2Foperations-guide~master~I60d2a87d7cd18ec7ac663cf55accee668fc81f08,openstack/operations-guide,master,I60d2a87d7cd18ec7ac663cf55accee668fc81f08,Added steps to deploy stable havana openstack release using devstack,ABANDONED,2013-12-20 13:19:12.000000000,2014-02-01 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1112}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 8944}]","[{'number': 1, 'created': '2013-12-20 13:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/551bf7674223777a321f38dc1a3134a4803c730d', 'message': 'Updated instruction for devstack\n\nChange-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08\nCloses-bug:#1257735\n'}, {'number': 2, 'created': '2013-12-20 16:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/61ee369e06dec95b796a4d2a81c1386e32adcee0', 'message': 'Updated instruction for devstack\n\nChange-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08\nCloses-bug:#1257735\n'}, {'number': 3, 'created': '2013-12-30 12:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/a87a4e0687116c6fcad8341cfb021951f147bf04', 'message': 'Added steps to deploy devstack for stable havana release.\n\nChange-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08\nCloses-bug:#1257735\n'}, {'number': 4, 'created': '2014-01-22 17:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6eb56b560a32ffeae55a22196615946ad874bf18', 'message': 'Added steps to deploy devstack for stable havana release.\n\nChange-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08\nCloses-bug:#1257735\n'}, {'number': 5, 'created': '2014-01-22 19:15:05.000000000', 'files': ['doc/openstack-ops/ch_ops_customize.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/3c5d7099516e99b6e594912c6a41ad58b3111c85', 'message': 'Added steps to deploy stable havana openstack release using devstack\n\nChange-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08\nCloses-bug:#1257735\n'}]",8,63405,3c5d7099516e99b6e594912c6a41ad58b3111c85,29,6,5,8944,,,0,"Added steps to deploy stable havana openstack release using devstack

Change-Id: I60d2a87d7cd18ec7ac663cf55accee668fc81f08
Closes-bug:#1257735
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/05/63405/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_customize.xml'],1,551bf7674223777a321f38dc1a3134a4803c730d,test, <title>To run DevStack for the stable Havana branch on an <code>git clone https://github.com/openstack-dev/devstack.git -b stable/havana devstack/</code># Identity Service (manages accounts/tokens) KEYSTONE_BRANCH=stable/havana # object storage Service SWIFT_BRANCH=stable/havana# Compute Service NOVA_BRANCH=stable/havana # Block Storage Service CINDER_BRANCH=stable/havana # Image Service GLANCE_BRANCH=stable/havana # Identity Service (manages accounts/tokens) KEYSTONE_BRANCH=stable/havana # django powered Dashboard for openstack HORIZON_BRANCH=stable/havana # Orchestration Service HEAT_BRANCH=stable/havana #Telemetry service CEILOMETER_BRANCH=stable/havana</programlisting>, <title>To run DevStack for the stable Folsom branch on an <code>git clone https://github.com/openstack-dev/devstack.git -b stable/folsom devstack/</code># unified auth system (manages accounts/tokens) KEYSTONE_BRANCH=stable/folsom # object storage SWIFT_BRANCH=stable/folsom# compute service NOVA_BRANCH=stable/folsom # volume service CINDER_BRANCH=stable/folsom # image catalog service GLANCE_BRANCH=stable/folsom # unified auth system (manages accounts/tokens) KEYSTONE_BRANCH=stable/folsom # django powered web control panel for openstack HORIZON_BRANCH=stable/folsom</programlisting>,22,16
openstack%2Fneutron~stable%2Fhavana~Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696,openstack/neutron,stable/havana,Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696,Update RPC code from oslo: consumer threads robustness,ABANDONED,2014-01-23 15:53:49.000000000,2014-02-01 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2035}, {'_account_id': 5948}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}]","[{'number': 1, 'created': '2014-01-23 15:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2a0ec65f2eba77618bf56589f9eeb6440421773', 'message': 'Update RPC code from oslo: consumer threads robustness\n\nThe common RPC code has been updated to include the following:\n\n  22ec8ff616a799085239e3e529daeeefea6366c4\n\nbug 1189711\n\nChange-Id: Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696\n'}, {'number': 2, 'created': '2014-01-24 07:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/49faac4c6158e7abb8d804d8f04c70a4cd101998', 'message': 'Update RPC code from oslo: consumer threads robustness\n\nThe common RPC code has been updated to include the following:\n\n  22ec8ff616a799085239e3e529daeeefea6366c4\n\nbug 1189711\n\nChange-Id: Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696\n'}, {'number': 3, 'created': '2014-01-24 15:01:43.000000000', 'files': ['neutron/openstack/common/rpc/impl_qpid.py', 'neutron/openstack/common/excutils.py', 'neutron/openstack/common/rpc/impl_kombu.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/687272a40f9f59ba21b8de2b7b34feb434985858', 'message': 'Update RPC code from oslo: consumer threads robustness\n\nThe common RPC code has been updated to include the following:\n\n  22ec8ff616a799085239e3e529daeeefea6366c4\n\nRelated-Bug: #1189711\n\nChange-Id: Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696\n'}]",2,68672,687272a40f9f59ba21b8de2b7b34feb434985858,21,11,3,8788,,,0,"Update RPC code from oslo: consumer threads robustness

The common RPC code has been updated to include the following:

  22ec8ff616a799085239e3e529daeeefea6366c4

Related-Bug: #1189711

Change-Id: Ib4afa82ad70c38e835b7655cfb2a1fe47b4d1696
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/68672/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/openstack/common/rpc/impl_qpid.py', 'neutron/openstack/common/excutils.py', 'neutron/openstack/common/rpc/impl_kombu.py']",3,e2a0ec65f2eba77618bf56589f9eeb6440421773,backport/oslo-rpc-fixes,from neutron.openstack.common import excutils @excutils.forever_retry_uncaught_exceptions,,34,0
openstack%2Fkeystone~master~If1645ec59f2cff9a0b4ec2a6cae8a23fcedcefec,openstack/keystone,master,If1645ec59f2cff9a0b4ec2a6cae8a23fcedcefec,fix TypeError on None value of username from passwordCredentials,ABANDONED,2014-01-24 14:24:10.000000000,2014-02-01 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-24 14:24:10.000000000', 'files': ['keystone/token/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/391e606fd03052970b3af61795b1af5873bd8937', 'message': 'fix TypeError on None value of username from passwordCredentials\n\nCloses-Bug: #1272350\n\nChange-Id: If1645ec59f2cff9a0b4ec2a6cae8a23fcedcefec\n'}]",0,68923,391e606fd03052970b3af61795b1af5873bd8937,6,4,1,2340,,,0,"fix TypeError on None value of username from passwordCredentials

Closes-Bug: #1272350

Change-Id: If1645ec59f2cff9a0b4ec2a6cae8a23fcedcefec
",git fetch https://review.opendev.org/openstack/keystone refs/changes/23/68923/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/token/controllers.py'],1,391e606fd03052970b3af61795b1af5873bd8937,nil-username," username = auth['passwordCredentials'].get('username') if username: if len(username) > CONF.max_param_size: raise exception.ValidationSizeError(attribute='username', size=CONF.max_param_size)"," username = auth['passwordCredentials'].get('username', '') if len(username) > CONF.max_param_size: raise exception.ValidationSizeError(attribute='username', size=CONF.max_param_size) if username:",4,5
openstack%2Fsolum~master~I1de3bcac0c4096fe5f3ce5ec1bd9ae0fcc7ef210,openstack/solum,master,I1de3bcac0c4096fe5f3ce5ec1bd9ae0fcc7ef210,Add run_tests.sh for Solum,ABANDONED,2014-01-23 10:08:56.000000000,2014-02-01 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-01-23 10:08:56.000000000', 'files': ['run_tests.sh', '.gitignore', 'tools/with_venv.sh', 'tools/run_tests_common.sh', 'tools/colorizer.py', 'tools/install_venv_common.py', 'tools/install_venv.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/e314b8732114ed0d6f7896e93d2c8d504be52f1c', 'message': 'Add run_tests.sh for Solum\n\nAdded run_tests.sh script and needed dependencies to run the script, so that\nits easier for starter and beginners on the project to just create a virtualenv\nand run tests easily.\n\nAlso added .venv to .gitignore\n\nfiles have been copied (and then modified for Solum) from\nhttps://github.com/stackforge/rally\n\nChange-Id: I1de3bcac0c4096fe5f3ce5ec1bd9ae0fcc7ef210\n'}]",0,68590,e314b8732114ed0d6f7896e93d2c8d504be52f1c,12,6,1,9537,,,0,"Add run_tests.sh for Solum

Added run_tests.sh script and needed dependencies to run the script, so that
its easier for starter and beginners on the project to just create a virtualenv
and run tests easily.

Also added .venv to .gitignore

files have been copied (and then modified for Solum) from
https://github.com/stackforge/rally

Change-Id: I1de3bcac0c4096fe5f3ce5ec1bd9ae0fcc7ef210
",git fetch https://review.opendev.org/openstack/solum refs/changes/90/68590/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.gitignore', 'tools/with_venv.sh', 'tools/run_tests_common.sh', 'tools/colorizer.py', 'tools/install_venv_common.py', 'tools/install_venv.py']",7,e314b8732114ed0d6f7896e93d2c8d504be52f1c,,"# Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Copyright 2010 OpenStack Foundation # Copyright 2013 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import sys import install_venv_common as install_venv # noqa def print_help(venv, root): help = """""" Solum development environment setup is complete. Solum development uses virtualenv to track and manage Python dependencies while in development and testing. To activate the Solum virtualenv for the extent of your current shell session you can run: $ source %s/bin/activate Or, if you prefer, you can run commands in the virtualenv on a case by case basis by running: $ %s/tools/with_venv.sh <your command> Also, make test will automatically use the virtualenv. """""" print(help % (venv, root)) def main(argv): root = os.path.dirname(os.path.dirname(os.path.realpath(__file__))) if os.environ.get('tools_path'): root = os.environ['tools_path'] venv = os.path.join(root, '.venv') if os.environ.get('venv'): venv = os.environ['venv'] pip_requires = os.path.join(root, 'requirements.txt') test_requires = os.path.join(root, 'test-requirements.txt') py_version = ""python%s.%s"" % (sys.version_info[0], sys.version_info[1]) project = 'Solum' install = install_venv.InstallVenv(root, venv, pip_requires, test_requires, py_version, project) options = install.parse_args(argv) install.check_python_version() install.check_dependencies() install.create_virtualenv(no_site_packages=options.no_site_packages) install.install_dependencies() install.post_process() print_help(venv, root) if __name__ == '__main__': main(sys.argv) ",,932,0
openstack%2Fcinder~master~I393460d3b14e9d35481ae38f0c6a9eb67719bb1a,openstack/cinder,master,I393460d3b14e9d35481ae38f0c6a9eb67719bb1a,Error using /dev/zero in copy_volume,ABANDONED,2014-01-18 06:29:00.000000000,2014-02-01 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8874}]","[{'number': 1, 'created': '2014-01-18 06:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/42a9ddb179aa153717e2b2d788ddc675f1d9ed5a', 'message': 'Error using /dev/zero in copy_volume\n\nWhen using /dev/zero with count=0 & iflag=direct to determine\nwhether snapshot/volume is accessible, it return an error with value 1.\nSo remove the ""iflag=direct"" while determining whether snapshot/volume\nis accessible.\n\nChange-Id: I393460d3b14e9d35481ae38f0c6a9eb67719bb1a\nCloses-Bug: #1270020\n'}, {'number': 2, 'created': '2014-01-24 07:28:34.000000000', 'files': ['cinder/volume/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b4da24ca36f2c0da58412b5ca3689a5335332686', 'message': 'Error using /dev/zero in copy_volume\n\nWhen using /dev/zero with count=0 & iflag=direct to determine\nwhether snapshot/volume is accessible, it returns an error with value 1.\nSo remove the ""iflag=direct"" while determining whether snapshot/volume\nis accessible.\n\nChange-Id: I393460d3b14e9d35481ae38f0c6a9eb67719bb1a\nCloses-Bug: #1270362\n'}]",7,67636,b4da24ca36f2c0da58412b5ca3689a5335332686,13,5,2,8874,,,0,"Error using /dev/zero in copy_volume

When using /dev/zero with count=0 & iflag=direct to determine
whether snapshot/volume is accessible, it returns an error with value 1.
So remove the ""iflag=direct"" while determining whether snapshot/volume
is accessible.

Change-Id: I393460d3b14e9d35481ae38f0c6a9eb67719bb1a
Closes-Bug: #1270362
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/67636/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/utils.py'],1,42a9ddb179aa153717e2b2d788ddc675f1d9ed5a,bug/1270362," extra_flags = ['oflag=direct'] extra_flags = ['iflag=direct', 'oflag=direct']"," extra_flags = ['iflag=direct', 'oflag=direct']",2,1
openstack%2Fsolum~master~Id44185b618eb0dc2c23381539814fae923816422,openstack/solum,master,Id44185b618eb0dc2c23381539814fae923816422,Add user authentication in functional tests.,ABANDONED,2013-12-26 16:52:24.000000000,2014-02-01 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 6427}, {'_account_id': 8334}, {'_account_id': 8443}]","[{'number': 1, 'created': '2013-12-26 16:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b39bc49d759943d824d31e402644ca8861dd7e1c', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 2, 'created': '2013-12-26 17:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d1ab52ed8acecbe43b988a601803221f3f04f76c', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nAdded fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 3, 'created': '2013-12-26 17:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7118c03321394ba09c2322f9479db2d3fe98fa52', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 4, 'created': '2013-12-26 17:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d8144aa18750473f20c118339633bf02e21ffd19', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 5, 'created': '2013-12-26 18:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/60be62becfd25c3f0273aed0b9db7146568a194b', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 6, 'created': '2013-12-26 18:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e26547facf7c0b209749544ec152f727f37b8f25', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 7, 'created': '2013-12-26 19:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/33ab86c352bc9f51e5200b46d05ea0c47293fe52', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 8, 'created': '2013-12-26 19:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7e6c341f4718ae06337a4d7c8e79ac47c1dc3a8e', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 9, 'created': '2013-12-26 19:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/58ab921a64cdd41be1e37767aeb1a3a6a7eb43a0', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 10, 'created': '2014-01-07 22:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0f0545ca432faf5e6f88e8d882e04290a8efba22', 'message': 'Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n'}, {'number': 11, 'created': '2014-01-10 02:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/cea30afdca0d6bdef3c217ffbda1dab56fe36c79', 'message': ""Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 12, 'created': '2014-01-10 05:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4cfeeaf90eafabd322d78316edcc00b0340d6c96', 'message': ""Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 13, 'created': '2014-01-10 05:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1d2a1b2c0d270aa901abf21949e5cb15d9ae376e', 'message': ""Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 14, 'created': '2014-01-10 06:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ff310c92f0eaf08982ea7a2c0d234d75b4e864b3', 'message': ""Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 15, 'created': '2014-01-10 17:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3a76402f21337969a20bc3d231c5bbdabb7dc269', 'message': ""Enable user authentication in functional tests via Tempest rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 16, 'created': '2014-01-10 18:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5c1eb15cfe196e3fd31bc1c43d0a6ad4748b00d5', 'message': ""Enable user authentication in functional tests via Tempest\n rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 17, 'created': '2014-01-10 21:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/9a0ac7d71b2fc2ed60d28f019463a10522e421ce', 'message': ""Enable user authentication in functional tests via Tempest\n rest client.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}, {'number': 18, 'created': '2014-01-10 23:21:05.000000000', 'files': ['contrib/devstack/lib/solum', 'contrib/devstack/extras.d/70-solum.sh', 'test-requirements.txt', 'functionaltests/clients/solum_client.py', 'functionaltests/base.py', 'functionaltests/common/utils.py', 'functionaltests/common/__init__.py', 'functionaltests/api/test_versions.py', 'functionaltests/clients/clients.py', 'functionaltests/common/http.py', 'requirements.txt', 'functionaltests/test.py', 'functionaltests/common/config.py', 'functionaltests/common/rest_client.py', 'functionaltests/clients/__init__.py', 'functionaltests/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/19b9f731a95ee73b343a4de186ba91a1d6449302', 'message': ""Add user authentication in functional tests.\n\nThis patch adds minimal Tempest like framework to functional tests.\nTempest does not allow to run tests outside tempest code, so\nfor Solum right now the only option is to copy tempest framework\nfunctions to functional test folder.\nThis minimal tempest framework code allows to write functional\ntest cases in tempest style. In the future, when we will merge\nwith tempest, we will not require to change functional test cases.\nIn order to put Solum tests we will need to put tests\nin proper folders and change module names from functional tests\nto tempest.\nThis patch adds all required class with tempest compatible\ninterfaces.\n\nThis functional test framework supports keystone and solum\nconfigurations options. Dependencies for other OpenSack\nwere removed.\n\nThis patch allows execution of Solum functional tests\nindependently from tempest.\n\nMoved fixtures to requirements.txt. This can be\nfixed after Nooril's commit merged to master.\n\nCloses-Bug: 1262404\nChange-Id: Id44185b618eb0dc2c23381539814fae923816422\n""}]",23,64165,19b9f731a95ee73b343a4de186ba91a1d6449302,46,7,18,8443,,,0,"Add user authentication in functional tests.

This patch adds minimal Tempest like framework to functional tests.
Tempest does not allow to run tests outside tempest code, so
for Solum right now the only option is to copy tempest framework
functions to functional test folder.
This minimal tempest framework code allows to write functional
test cases in tempest style. In the future, when we will merge
with tempest, we will not require to change functional test cases.
In order to put Solum tests we will need to put tests
in proper folders and change module names from functional tests
to tempest.
This patch adds all required class with tempest compatible
interfaces.

This functional test framework supports keystone and solum
configurations options. Dependencies for other OpenSack
were removed.

This patch allows execution of Solum functional tests
independently from tempest.

Moved fixtures to requirements.txt. This can be
fixed after Nooril's commit merged to master.

Closes-Bug: 1262404
Change-Id: Id44185b618eb0dc2c23381539814fae923816422
",git fetch https://review.opendev.org/openstack/solum refs/changes/65/64165/4 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/lib/solum', 'contrib/devstack/extras.d/70-solum.sh', 'functionaltests/clients/solum_client.py', 'functionaltests/base.py', 'functionaltests/common/utils.py', 'functionaltests/common/__init__.py', 'functionaltests/api/test_versions.py', 'functionaltests/clients/clients.py', 'functionaltests/common/http.py', 'functionaltests/test.py', 'functionaltests/common/config.py', 'functionaltests/common/rest_client.py', 'functionaltests/clients/__init__.py', 'functionaltests/common/exceptions.py']",14,b39bc49d759943d824d31e402644ca8861dd7e1c,bug/1262404,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools class TempestException(Exception): """"""Base Tempest Exception To correctly use this class, inherit from it and define a 'message' property. That message will get printf'd with the keyword arguments provided to the constructor. """""" message = ""An unknown exception occurred"" def __init__(self, *args, **kwargs): super(TempestException, self).__init__() try: self._error_string = self.message % kwargs except Exception: # at least get the core message out if something happened self._error_string = self.message if len(args) > 0: # If there is a non-kwarg parameter, assume it's the error # message or reason description and tack it on to the end # of the exception message # Convert all arguments into their string representations... args = [""%s"" % arg for arg in args] self._error_string = (self._error_string + ""\nDetails: %s"" % '\n'.join(args)) def __str__(self): return self._error_string class InvalidConfiguration(TempestException): message = ""Invalid Configuration"" class RestClientException(TempestException, testtools.TestCase.failureException): pass class InvalidHttpSuccessCode(RestClientException): message = ""The success code is different than the expected one"" class NotFound(RestClientException): message = ""Object not found"" class Unauthorized(RestClientException): message = 'Unauthorized' class InvalidServiceTag(RestClientException): message = ""Invalid service tag"" class TimeoutException(TempestException): message = ""Request timed out"" class BuildErrorException(TempestException): message = ""Server %(server_id)s failed to build and is in ERROR status"" class ImageKilledException(TempestException): message = ""Image %(image_id)s 'killed' while waiting for '%(status)s'"" class AddImageException(TempestException): message = ""Image %(image_id)s failed to become ACTIVE in the allotted time"" class EC2RegisterImageException(TempestException): message = (""Image %(image_id)s failed to become 'available' "" ""in the allotted time"") class VolumeBuildErrorException(TempestException): message = ""Volume %(volume_id)s failed to build and is in ERROR status"" class SnapshotBuildErrorException(TempestException): message = ""Snapshot %(snapshot_id)s failed to build and is in ERROR status"" class StackBuildErrorException(TempestException): message = (""Stack %(stack_identifier)s is in %(stack_status)s status "" ""due to '%(stack_status_reason)s'"") class BadRequest(RestClientException): message = ""Bad request"" class UnprocessableEntity(RestClientException): message = ""Unprocessable entity"" class AuthenticationFailure(RestClientException): message = (""Authentication with user %(user)s and password "" ""%(password)s failed auth using tenant %(tenant)s."") class EndpointNotFound(TempestException): message = ""Endpoint not found"" class RateLimitExceeded(TempestException): message = (""Rate limit exceeded.\nMessage: %(message)s\n"" ""Details: %(details)s"") class OverLimit(TempestException): message = ""Quota exceeded"" class ServerFault(TempestException): message = ""Got server fault"" class ImageFault(TempestException): message = ""Got image fault"" class IdentityError(TempestException): message = ""Got identity error"" class Conflict(RestClientException): message = ""An object with that identifier already exists"" class SSHTimeout(TempestException): message = (""Connection to the %(host)s via SSH timed out.\n"" ""User: %(user)s, Password: %(password)s"") class SSHExecCommandFailed(TempestException): """"""Raised when remotely executed command returns nonzero status."""""" message = (""Command '%(command)s', exit status: %(exit_status)d, "" ""Error:\n%(strerror)s"") class ServerUnreachable(TempestException): message = ""The server is not reachable via the configured network"" class SQLException(TempestException): message = ""SQL error: %(message)s"" class TearDownException(TempestException): message = ""%(num)d cleanUp operation failed"" class RFCViolation(RestClientException): message = ""RFC Violation"" class ResponseWithNonEmptyBody(RFCViolation): message = (""RFC Violation! Response with %(status)d HTTP Status Code "" ""MUST NOT have a body"") class ResponseWithEntity(RFCViolation): message = (""RFC Violation! Response with 205 HTTP Status Code "" ""MUST NOT have an entity"") class InvalidHTTPResponseBody(RestClientException): message = ""HTTP response body is invalid json or xml"" ",,1575,12
openstack%2Fheat~master~I2266cecd41831316c6ba3006bd6d277bcb5f6fcb,openstack/heat,master,I2266cecd41831316c6ba3006bd6d277bcb5f6fcb,Enforce event purge process to remove older events,ABANDONED,2014-01-24 21:34:36.000000000,2014-02-01 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-01-24 21:34:36.000000000', 'files': ['heat/tests/test_event.py', 'heat/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ccb6eca2170790aacd6844e346ee4afedf545e5a', 'message': 'Enforce event purge process to remove older events\n\nWhen max_events_per_stack is configured and the number of created events\nreach this number; event_purge_batch_size events are removed from the\ndatabase.\nBut when the events to delete are gathered from the database, is used a\nquery which performs an order by Event.id, which could cause that newly\ncreated events are removed (which happens because Event.id is an uuid)\nTo fix the bug the order by clause used in the query was modified to use\nEvent.created_at (ascending order) instead of Event.id\n\nChange-Id: I2266cecd41831316c6ba3006bd6d277bcb5f6fcb\nCloses-Bug: #1272528\n'}]",0,69021,ccb6eca2170790aacd6844e346ee4afedf545e5a,4,2,1,9331,,,0,"Enforce event purge process to remove older events

When max_events_per_stack is configured and the number of created events
reach this number; event_purge_batch_size events are removed from the
database.
But when the events to delete are gathered from the database, is used a
query which performs an order by Event.id, which could cause that newly
created events are removed (which happens because Event.id is an uuid)
To fix the bug the order by clause used in the query was modified to use
Event.created_at (ascending order) instead of Event.id

Change-Id: I2266cecd41831316c6ba3006bd6d277bcb5f6fcb
Closes-Bug: #1272528
",git fetch https://review.opendev.org/openstack/heat refs/changes/21/69021/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_event.py', 'heat/db/sqlalchemy/api.py']",2,ccb6eca2170790aacd6844e346ee4afedf545e5a,bug/1272528, sqlalchemy.sql.expression.asc( models.Event.created_at)).limit(limit).all()] models.Event.id).filter_by(stack_id=stack_id).order_by( sqlalchemy.sql.expression.asc( models.Event.created_at)).limit(limit).subquery(), models.Event.id).limit(limit).all()] models.Event.id).filter_by( stack_id=stack_id).order_by( models.Event.id).limit(limit).subquery(),40,4
openstack%2Fhorizon~master~I5fcad5c738aeecce598b414ae994078392df902d,openstack/horizon,master,I5fcad5c738aeecce598b414ae994078392df902d,horizon is removing the URL path from endpoint,ABANDONED,2013-12-17 14:55:26.000000000,2014-02-01 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6771}, {'_account_id': 6914}, {'_account_id': 8866}, {'_account_id': 9659}, {'_account_id': 10099}]","[{'number': 1, 'created': '2013-12-17 14:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9fbc2e77f385c0c61f243690dcfd2f83614f913c', 'message': 'horizon is removing the URL path from endpoint\n\nGlanceclient removes the API version from the endpoint in case it exists. Look the following code:\n\nhttps://github.com/openstack/python-glanceclient/blob/master/glanceclient/shell.py#L310\n\nThe rest of code includes the API version in use accordingly.\n\nAutor: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: I5fcad5c738aeecce598b414ae994078392df902d\nCloses-Bug: #1188182\n'}, {'number': 2, 'created': '2013-12-20 19:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8402c22121eee0dd90253efe5a0652f1172c14fb', 'message': 'horizon is removing the URL path from endpoint\n\nGlanceclient removes the API version from the endpoint in case it exists. Look the following code:\nhttps://github.com/openstack/python-glanceclient/blob/master/glanceclient/shell.py#L310\nThe rest of code includes the API version in use accordingly.\n\nAutor: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: I5fcad5c738aeecce598b414ae994078392df902d\nCloses-Bug: #1188182\n'}, {'number': 3, 'created': '2013-12-20 19:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ecf1ccb370dc854930141ce76670ca116d05c3c2', 'message': 'horizon is removing the URL path from endpoint\n\nGlanceclient removes the API version from the endpoint in case it exists. Look the following code:\nhttps://github.com/openstack/python-glanceclient/blob/master/glanceclient/shell.py#L310\nThe rest of code includes the API version in use accordingly.\n\nAutor: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: I5fcad5c738aeecce598b414ae994078392df902d\nCloses-Bug: #1188182\n'}, {'number': 4, 'created': '2014-01-24 16:35:48.000000000', 'files': ['openstack_dashboard/test/api_tests/glance_tests.py', 'horizon/test/urls.py', 'openstack_dashboard/api/glance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ceda14d7eb8cdd8e1601956bd8488948461e70d6', 'message': 'horizon is removing the URL path from endpoint\n\nGlanceclient removes the API version from the endpoint in case it exists. Look the following code:\nhttps://github.com/openstack/python-glanceclient/blob/master/glanceclient/shell.py#L310\nThe rest of code includes the API version in use accordingly.\n\nAutor: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: I5fcad5c738aeecce598b414ae994078392df902d\nCloses-Bug: #1188182\n'}]",6,62668,ceda14d7eb8cdd8e1601956bd8488948461e70d6,16,8,4,8866,,,0,"horizon is removing the URL path from endpoint

Glanceclient removes the API version from the endpoint in case it exists. Look the following code:
https://github.com/openstack/python-glanceclient/blob/master/glanceclient/shell.py#L310
The rest of code includes the API version in use accordingly.

Autor: Raildo Mascena <raildo@lsd.ufcg.edu.br>

Change-Id: I5fcad5c738aeecce598b414ae994078392df902d
Closes-Bug: #1188182
",git fetch https://review.opendev.org/openstack/horizon refs/changes/68/62668/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/test/urls.py', 'openstack_dashboard/api/glance.py']",2,9fbc2e77f385c0c61f243690dcfd2f83614f913c,bug/1188182,"import re url = base.url_for(request, 'image') # Get rid of trailing '/' if present if url.endswith('/'): url = url[:-1] url_bits = url.split('/') # regex to match 'v1' or 'v2.0' etc if re.match('v\d+\.?\d*', url_bits[-1]): url = '/'.join(url_bits[:-1])","import urlparse o = urlparse.urlparse(base.url_for(request, 'image')) url = ""://"".join((o.scheme, o.netloc))",36,7
openstack%2Fdevstack-gate~master~I2ca6095b3b6144ddb52d2d59c77a6917916fcd14,openstack/devstack-gate,master,I2ca6095b3b6144ddb52d2d59c77a6917916fcd14,Experiment: set concurrency to 6,ABANDONED,2014-01-24 18:11:34.000000000,2014-02-01 06:03:03.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-01-24 18:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/27764c7d1dc6d5e34a4d26d253c2689afe2e09e9', 'message': ""Experiment: set concurrency to 6\n\nThis will hose hpcloud nodes, but hopefully we'll get some test\nresults from rax performance nodes with have 8 vcpus.\n\nChange-Id: I2ca6095b3b6144ddb52d2d59c77a6917916fcd14\n""}, {'number': 2, 'created': '2014-01-24 18:23:08.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f5f7cd5df4e4920cc350c967c2eb6780b1b549ae', 'message': ""Experiment: set concurrency to 6\n\nThis will hose hpcloud nodes, but hopefully we'll get some test\nresults from rax performance nodes with have 8 vcpus.\n\nMore testing.\n\nChange-Id: I2ca6095b3b6144ddb52d2d59c77a6917916fcd14\n""}]",0,68982,f5f7cd5df4e4920cc350c967c2eb6780b1b549ae,6,3,2,1,,,0,"Experiment: set concurrency to 6

This will hose hpcloud nodes, but hopefully we'll get some test
results from rax performance nodes with have 8 vcpus.

More testing.

Change-Id: I2ca6095b3b6144ddb52d2d59c77a6917916fcd14
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/82/68982/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,27764c7d1dc6d5e34a4d26d253c2689afe2e09e9,test,export TEMPEST_CONCURRENCY=${TEMPEST_CONCURRENCY:-6},export TEMPEST_CONCURRENCY=${TEMPEST_CONCURRENCY:-2},1,1
openstack%2Fopenstack-manuals~master~I80f00056feae6d0aa1eef516e732d897ac1df68e,openstack/openstack-manuals,master,I80f00056feae6d0aa1eef516e732d897ac1df68e,Remove redundant package install,MERGED,2014-02-01 03:46:02.000000000,2014-02-01 05:58:28.000000000,2014-02-01 05:58:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-02-01 03:46:02.000000000', 'files': ['doc/install-guide/section_cinder-node.xml', 'doc/install-guide/section_cinder-controller.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f8d0e6bed5eaa700d934a417e52ac4389f564e8a', 'message': ""Remove redundant package install\n\nThe openstack-util and openstack-selinux packages have already been\ninstalled in the 'Basic operating system configuration' chapter, so\nit is redundant to install again in 'Add the Block Storage Service'\nchapter.\n\nChange-Id: I80f00056feae6d0aa1eef516e732d897ac1df68e\nCloses-Bug: #1275059\n""}]",0,70509,f8d0e6bed5eaa700d934a417e52ac4389f564e8a,6,3,1,6676,,,0,"Remove redundant package install

The openstack-util and openstack-selinux packages have already been
installed in the 'Basic operating system configuration' chapter, so
it is redundant to install again in 'Add the Block Storage Service'
chapter.

Change-Id: I80f00056feae6d0aa1eef516e732d897ac1df68e
Closes-Bug: #1275059
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/09/70509/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/section_cinder-node.xml', 'doc/install-guide/section_cinder-controller.xml']",2,f8d0e6bed5eaa700d934a417e52ac4389f564e8a,bug/1275059," <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>yum install openstack-cinder</userinput></screen>"," <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>yum install openstack-cinder openstack-utils openstack-selinux</userinput></screen>",2,2
openstack%2Fkeystone~stable%2Fhavana~Ifb3b262f47d629670b06c670353dbe798af4dc03,openstack/keystone,stable/havana,Ifb3b262f47d629670b06c670353dbe798af4dc03,Remove netifaces requirement,MERGED,2014-01-12 00:27:53.000000000,2014-02-01 05:39:51.000000000,2014-02-01 05:39:50.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 1955}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 9954}]","[{'number': 1, 'created': '2014-01-12 00:27:53.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/af2bdcbe66b95a82340091729cf13da26bc97b21', 'message': 'Remove netifaces requirement\n\nnetifaces is not required to run the tests, so remove it from\nthe requirements.\n\nRelated-Bug: #1266513\nChange-Id: Ifb3b262f47d629670b06c670353dbe798af4dc03\n'}]",0,66145,af2bdcbe66b95a82340091729cf13da26bc97b21,20,6,1,2903,,,0,"Remove netifaces requirement

netifaces is not required to run the tests, so remove it from
the requirements.

Related-Bug: #1266513
Change-Id: Ifb3b262f47d629670b06c670353dbe798af4dc03
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/66145/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,af2bdcbe66b95a82340091729cf13da26bc97b21,,,netifaces>=0.5 ,0,2
openstack%2Ftripleo-incubator~master~I9831d8a81c176db20b6c972033fb9f42d455f122,openstack/tripleo-incubator,master,I9831d8a81c176db20b6c972033fb9f42d455f122,Fix grep for notCompute in devtest_overcloud,MERGED,2014-01-31 19:32:58.000000000,2014-02-01 05:03:16.000000000,2014-02-01 05:03:16.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2014-01-31 19:32:58.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0655a33698f329dcf430bbc04dcb6f8552776d96', 'message': 'Fix grep for notCompute in devtest_overcloud\n\nThe resource changed names recently, so the hosts will also have changed\nnames.\n\nChange-Id: I9831d8a81c176db20b6c972033fb9f42d455f122\n'}]",0,70415,0655a33698f329dcf430bbc04dcb6f8552776d96,5,2,1,6488,,,0,"Fix grep for notCompute in devtest_overcloud

The resource changed names recently, so the hosts will also have changed
names.

Change-Id: I9831d8a81c176db20b6c972033fb9f42d455f122
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/15/70415/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,0655a33698f329dcf430bbc04dcb6f8552776d96,,"export OVERCLOUD_IP=$(nova list | grep notCompute0.*ctlplane | sed -e ""s/.*=\\([0-9.]*\\).*/\1/"")","export OVERCLOUD_IP=$(nova list | grep notcompute.*ctlplane | sed -e ""s/.*=\\([0-9.]*\\).*/\1/"")",1,1
openstack%2Fnova~stable%2Fhavana~Ie3be46024f06b9f59af92f5e3918a1958386d4f1,openstack/nova,stable/havana,Ie3be46024f06b9f59af92f5e3918a1958386d4f1,Setup destination disk from virt_disk_size,MERGED,2014-01-20 09:14:02.000000000,2014-02-01 04:51:57.000000000,2014-02-01 04:51:53.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 6593}]","[{'number': 1, 'created': '2014-01-20 09:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80a30f28b2f9ced9bdcec3f092a91e03e93f6184', 'message': 'Setup destination disk from virt_disk_size\n\nWhen running live-migration --block-migrate on a qcow2 backed\nVM without cow image, the destination qcow2 file should be created\nwith the virtual disk size. For raw images, the virt_disk_size\nis set to disk_size to ensure that virt_disk_size is always the\nsize of the disk that should be re-created.\n\nUpdate unit tests to be more strict and check for sizes to be correct.\n\nCloses-Bug: #1257355\n\nChange-Id: Ie3be46024f06b9f59af92f5e3918a1958386d4f1\n'}, {'number': 2, 'created': '2014-01-30 17:57:24.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f9dcd2e622207d76cd0008fb69463791cb94c0e9', 'message': 'Setup destination disk from virt_disk_size\n\nWhen running live-migration --block-migrate on a qcow2 backed\nVM without cow image, the destination qcow2 file should be created\nwith the virtual disk size. For raw images, the virt_disk_size\nis set to disk_size to ensure that virt_disk_size is always the\nsize of the disk that should be re-created.\n\nUpdate unit tests to be more strict and check for sizes to be correct.\n\nCloses-Bug: #1257355\n\nChange-Id: Ie3be46024f06b9f59af92f5e3918a1958386d4f1\n'}]",0,67795,f9dcd2e622207d76cd0008fb69463791cb94c0e9,19,6,2,6593,,,0,"Setup destination disk from virt_disk_size

When running live-migration --block-migrate on a qcow2 backed
VM without cow image, the destination qcow2 file should be created
with the virtual disk size. For raw images, the virt_disk_size
is set to disk_size to ensure that virt_disk_size is always the
size of the disk that should be re-created.

Update unit tests to be more strict and check for sizes to be correct.

Closes-Bug: #1257355

Change-Id: Ie3be46024f06b9f59af92f5e3918a1958386d4f1
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/67795/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,80a30f28b2f9ced9bdcec3f092a91e03e93f6184,virt_backport, info['virt_disk_size']) virt_size = dk_size, info['disk_size']) virt_size = 0,17,9
openstack%2Fglance~stable%2Fhavana~Id897085f93bcd143ec443f477f666d4cabd77567,openstack/glance,stable/havana,Id897085f93bcd143ec443f477f666d4cabd77567,Check first matching rule for protected properties,MERGED,2014-01-24 16:16:06.000000000,2014-02-01 04:51:44.000000000,2014-02-01 04:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 6484}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-01-24 16:16:06.000000000', 'files': ['glance/tests/unit/common/test_property_utils.py', 'glance/common/property_utils.py', 'glance/tests/etc/property-protections.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/1a9e0e94c36127d525c41f03c4223c3e0c2eda03', 'message': 'Check first matching rule for protected properties\n\nWhen using roles to define protected properties, the first matching rule\nin the config file should be used to grant/deny access. This change\nenforces that behaviour.\n\nReferences bug 1271426\n\nChange-Id: Id897085f93bcd143ec443f477f666d4cabd77567\n(Cherry-picked from b6dd538569ebf0f1580c8e1fadc5e0f8054c9b08)\nConflicts:\n    glance/common/property_utils.py\n    glance/tests/etc/property-protections.conf\n    glance/tests/unit/common/test_property_utils.py\n'}]",1,68952,1a9e0e94c36127d525c41f03c4223c3e0c2eda03,8,5,1,7817,,,0,"Check first matching rule for protected properties

When using roles to define protected properties, the first matching rule
in the config file should be used to grant/deny access. This change
enforces that behaviour.

References bug 1271426

Change-Id: Id897085f93bcd143ec443f477f666d4cabd77567
(Cherry-picked from b6dd538569ebf0f1580c8e1fadc5e0f8054c9b08)
Conflicts:
    glance/common/property_utils.py
    glance/tests/etc/property-protections.conf
    glance/tests/unit/common/test_property_utils.py
",git fetch https://review.opendev.org/openstack/glance refs/changes/52/68952/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/common/test_property_utils.py', 'glance/common/property_utils.py', 'glance/tests/etc/property-protections.conf']",3,1a9e0e94c36127d525c41f03c4223c3e0c2eda03,bug/1271426,[x_foo_matcher] create = admin read = admin update = admin delete = admin [x_foo_*] create = member read = member update = member delete = member ,,33,2
openstack%2Fdevstack~master~Ibdaecffd25bc0201551ed695e5693bd01e1ea7f3,openstack/devstack,master,Ibdaecffd25bc0201551ed695e5693bd01e1ea7f3,Initial Barbican entry into DevStack,ABANDONED,2014-01-29 20:26:43.000000000,2014-02-01 04:20:40.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-01-29 20:26:43.000000000', 'files': ['exercises/barbican.sh', 'functions', 'unstack.sh', 'lib/barbican', 'files/rpms/barbican', 'files/apts/barbican', 'lib/tempest', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d5aceeb0502c155513214481ecb50c5c5dc90378', 'message': 'Initial Barbican entry into DevStack\n\nChange-Id: Ibdaecffd25bc0201551ed695e5693bd01e1ea7f3\n'}]",9,69962,d5aceeb0502c155513214481ecb50c5c5dc90378,6,3,1,7136,,,0,"Initial Barbican entry into DevStack

Change-Id: Ibdaecffd25bc0201551ed695e5693bd01e1ea7f3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/69962/1 && git format-patch -1 --stdout FETCH_HEAD,"['exercises/barbican.sh', 'functions', 'unstack.sh', 'lib/barbican', 'files/rpms/barbican', 'files/apts/barbican', 'lib/tempest', 'stack.sh']",8,d5aceeb0502c155513214481ecb50c5c5dc90378,,"source $TOP_DIR/lib/barbicanif is_service_enabled barbican; then install_barbican install_barbicanclient fi # Barbican Service # ---------------- if is_service_enabled barbican; then echo_summary ""Configuring Barbican"" init_barbican configure_barbican echo_summary ""Starting Barbican"" start_barbican fi ",,279,4
openstack%2Fkeystone~stable%2Fhavana~Ib97bc01b60d7ea6c2e6bc3f0229deffbadbf18cc,openstack/keystone,stable/havana,Ib97bc01b60d7ea6c2e6bc3f0229deffbadbf18cc,Sync log_handler module from Oslo,MERGED,2014-01-28 21:12:04.000000000,2014-02-01 03:20:50.000000000,2014-02-01 03:20:49.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6722}]","[{'number': 1, 'created': '2014-01-28 21:12:04.000000000', 'files': ['openstack-common.conf', 'keystone/openstack/common/log_handler.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/70f045acc8a1628f770d3cf24e6348dc2e6b4887', 'message': 'Sync log_handler module from Oslo\n\nIbf28ba17f Remove the notifier and its dependencies from log.py\n\nMove the code related to the publish error handler out of the\nlog module so its easier for other projects to consume it\n\nCloses-bug: #1240349\n(cherry picked from commit 1a961bf7e64e7a1610b6be0a5d68bda242352ec4)\n\nConflicts:\n\topenstack-common.conf\n\nChange-Id: Ib97bc01b60d7ea6c2e6bc3f0229deffbadbf18cc\n'}]",0,69720,70f045acc8a1628f770d3cf24e6348dc2e6b4887,6,3,1,1420,,,0,"Sync log_handler module from Oslo

Ibf28ba17f Remove the notifier and its dependencies from log.py

Move the code related to the publish error handler out of the
log module so its easier for other projects to consume it

Closes-bug: #1240349
(cherry picked from commit 1a961bf7e64e7a1610b6be0a5d68bda242352ec4)

Conflicts:
	openstack-common.conf

Change-Id: Ib97bc01b60d7ea6c2e6bc3f0229deffbadbf18cc
",git fetch https://review.opendev.org/openstack/keystone refs/changes/20/69720/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'keystone/openstack/common/log_handler.py']",2,70f045acc8a1628f770d3cf24e6348dc2e6b4887,add_log_handler,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging from keystone.openstack.common import notifier from oslo.config import cfg class PublishErrorsHandler(logging.Handler): def emit(self, record): if ('keystone.openstack.common.notifier.log_notifier' in cfg.CONF.notification_driver): return notifier.api.notify(None, 'error.publisher', 'error_notification', notifier.api.ERROR, dict(error=record.msg)) ",,33,0
openstack%2Fheat~stable%2Fgrizzly~Ic7b286933a51d070e73eae452b93f8a011eb05c0,openstack/heat,stable/grizzly,Ic7b286933a51d070e73eae452b93f8a011eb05c0,Make AMQP based RPC consumer threads more robust,MERGED,2014-01-15 16:15:22.000000000,2014-02-01 03:12:56.000000000,2014-02-01 03:12:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}]","[{'number': 1, 'created': '2014-01-15 16:15:22.000000000', 'files': ['heat/openstack/common/rpc/impl_kombu.py', 'heat/openstack/common/excutils.py', 'heat/openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7da5956a9b6c3b37ae27667a03a61f228f0ce21f', 'message': 'Make AMQP based RPC consumer threads more robust\n\nThis is a backport from oslo-incubator,\ncommit 22ec8ff616a799085239e3e529daeeefea6366c4:\n\nbug 1189711 Should RPC consume_in_thread() be more fault tolerant?\n\nThere are unprotected holes in the thread kicked off by RPC\nconsume_in_thread such that an exception will kill the thread.\nThis exists for both the service (TopicConsumer) and the new\nreply proxy (DirectConsumer) consumers. This patch plugs\nthose holes as close to the base of the consumer thread as\npossible by catching all non-caught exceptions and retrying\nwith sleeps between retries and some pacing of the log\noutput to prevent log flooding.\n\nChange-Id: Ic7b286933a51d070e73eae452b93f8a011eb05c0\n'}]",0,66888,7da5956a9b6c3b37ae27667a03a61f228f0ce21f,20,5,1,3098,,,0,"Make AMQP based RPC consumer threads more robust

This is a backport from oslo-incubator,
commit 22ec8ff616a799085239e3e529daeeefea6366c4:

bug 1189711 Should RPC consume_in_thread() be more fault tolerant?

There are unprotected holes in the thread kicked off by RPC
consume_in_thread such that an exception will kill the thread.
This exists for both the service (TopicConsumer) and the new
reply proxy (DirectConsumer) consumers. This patch plugs
those holes as close to the base of the consumer thread as
possible by catching all non-caught exceptions and retrying
with sleeps between retries and some pacing of the log
output to prevent log flooding.

Change-Id: Ic7b286933a51d070e73eae452b93f8a011eb05c0
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/66888/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/rpc/impl_kombu.py', 'heat/openstack/common/excutils.py', 'heat/openstack/common/rpc/impl_qpid.py']",3,7da5956a9b6c3b37ae27667a03a61f228f0ce21f,bug/1189711,from heat.openstack.common import excutils @excutils.forever_retry_uncaught_exceptions,,35,0
openstack%2Fhorizon~stable%2Fhavana~I23159d2dee7fc05653a99fc89fbfd4d52e988df5,openstack/horizon,stable/havana,I23159d2dee7fc05653a99fc89fbfd4d52e988df5,Fix inappropriate logouts on load-balanced Horizon,MERGED,2014-01-29 23:32:18.000000000,2014-02-01 03:05:45.000000000,2014-02-01 03:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 5733}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-01-29 23:32:18.000000000', 'files': ['horizon/test/tests/middleware.py', 'horizon/middleware.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/970b165d5fef31c56f5914b921665bdf6882d2e2', 'message': 'Fix inappropriate logouts on load-balanced Horizon\n\nThe session timeout code in the horizon/middleware.py can cause\ninappropriate timeouts/logouts when running Horizon behind a load\nbalancer on two machines that are slightly out of sync time-wise.\n\nUse timestamps rather than datetime as the arithmetic is simpler.\n\nCloses-bug: #1243277\n(cherry-picked from commit 13355dacdbfa9ef14a4e1c16afeffaece5c13a39,\n minus the unrelated settings.py changes.)\n\nChange-Id: I23159d2dee7fc05653a99fc89fbfd4d52e988df5\n'}]",0,70016,970b165d5fef31c56f5914b921665bdf6882d2e2,14,7,1,5733,,,0,"Fix inappropriate logouts on load-balanced Horizon

The session timeout code in the horizon/middleware.py can cause
inappropriate timeouts/logouts when running Horizon behind a load
balancer on two machines that are slightly out of sync time-wise.

Use timestamps rather than datetime as the arithmetic is simpler.

Closes-bug: #1243277
(cherry-picked from commit 13355dacdbfa9ef14a4e1c16afeffaece5c13a39,
 minus the unrelated settings.py changes.)

Change-Id: I23159d2dee7fc05653a99fc89fbfd4d52e988df5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/16/70016/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/test/tests/middleware.py', 'horizon/middleware.py']",2,970b165d5fef31c56f5914b921665bdf6882d2e2,,"import time timestamp = int(time.time()) if (isinstance(last_activity, int) and (timestamp - last_activity) > timeout):",import datetime timestamp = datetime.datetime.now() if last_activity and (timestamp - last_activity).seconds > timeout:,6,6
openstack%2Fkeystone~stable%2Fhavana~I1b5b0c75f256382a685fceb2117db6d5b18d8c4f,openstack/keystone,stable/havana,I1b5b0c75f256382a685fceb2117db6d5b18d8c4f,Adds fixture package from oslo,MERGED,2014-01-30 12:40:32.000000000,2014-02-01 03:05:37.000000000,2014-02-01 03:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 67}, {'_account_id': 1955}, {'_account_id': 6593}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-30 12:40:32.000000000', 'files': ['test-requirements.txt', 'keystone/openstack/common/fixture/__init__.py', 'keystone/openstack/common/fixture/moxstubout.py', 'openstack-common.conf', 'keystone/openstack/common/fixture/lockutils.py', 'keystone/openstack/common/fixture/mockpatch.py', 'keystone/openstack/common/fixture/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9983fbeaf35a81b6bd3085238b42f3fc42f47d01', 'message': 'Adds fixture package from oslo\n\nThe mock library is added to test-requirements.txt since the\nmockpatch fixture requires it.\n\nChange-Id: I1b5b0c75f256382a685fceb2117db6d5b18d8c4f\n(cherry picked from commit 07aa0a91a120c1b07cbfe800ec0f78abb81a7271)\n'}]",0,70105,9983fbeaf35a81b6bd3085238b42f3fc42f47d01,11,6,1,6593,,,0,"Adds fixture package from oslo

The mock library is added to test-requirements.txt since the
mockpatch fixture requires it.

Change-Id: I1b5b0c75f256382a685fceb2117db6d5b18d8c4f
(cherry picked from commit 07aa0a91a120c1b07cbfe800ec0f78abb81a7271)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/70105/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/fixture/__init__.py', 'test-requirements.txt', 'keystone/openstack/common/fixture/moxstubout.py', 'openstack-common.conf', 'keystone/openstack/common/fixture/lockutils.py', 'keystone/openstack/common/fixture/mockpatch.py', 'keystone/openstack/common/fixture/config.py']",7,9983fbeaf35a81b6bd3085238b42f3fc42f47d01,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2013 Mirantis, Inc. # Copyright 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import fixtures from oslo.config import cfg import six class Config(fixtures.Fixture): """"""Override some configuration values. The keyword arguments are the names of configuration options to override and their values. If a group argument is supplied, the overrides are applied to the specified configuration option group. All overrides are automatically cleared at the end of the current test by the reset() method, which is registred by addCleanup(). """""" def __init__(self, conf=cfg.CONF): self.conf = conf def setUp(self): super(Config, self).setUp() self.addCleanup(self.conf.reset) def config(self, **kw): group = kw.pop('group', None) for k, v in six.iteritems(kw): self.conf.set_override(k, v, group) ",,187,0
openstack%2Ftempest~master~I54f89ffa49d3fdc8cc71528faef7b10f115370b2,openstack/tempest,master,I54f89ffa49d3fdc8cc71528faef7b10f115370b2,Updated from global requirements,MERGED,2014-01-21 20:29:58.000000000,2014-02-01 03:05:28.000000000,2014-02-01 03:05:27.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-01-21 20:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39ff873447feb4ec964cd26be1c5514a43d24454', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}, {'number': 2, 'created': '2014-01-24 01:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/40be831da289927c96838bf88f73457242db06fd', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}, {'number': 3, 'created': '2014-01-24 22:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f04dde5dc250514af300d783ba54392664cf6b2e', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}, {'number': 4, 'created': '2014-01-25 03:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e2874f4f64fa6dacd097ad6598c0100fc36747e0', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}, {'number': 5, 'created': '2014-01-25 05:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2838d5a8f35c1ad244509415b3c507985a9f71ea', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}, {'number': 6, 'created': '2014-01-31 19:00:22.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/435e38697983f633ff6a5e66a868685d654a8410', 'message': 'Updated from global requirements\n\nChange-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2\n'}]",0,68252,435e38697983f633ff6a5e66a868685d654a8410,25,3,6,3,,,0,"Updated from global requirements

Change-Id: I54f89ffa49d3fdc8cc71528faef7b10f115370b2
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/68252/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,39ff873447feb4ec964cd26be1c5514a43d24454,openstack/requirements,"keyring>=1.6.1,<2.0,>=2.1","keyring>=1.6.1,<2.0",1,1
openstack%2Fneutron~stable%2Fhavana~Iccc0daf4f6edd537fd7f9e4b2fc4be094543ca5d,openstack/neutron,stable/havana,Iccc0daf4f6edd537fd7f9e4b2fc4be094543ca5d,Fix MeteringLabel model to not clear router's tenant id on deletion,MERGED,2013-12-06 11:19:52.000000000,2014-02-01 02:56:51.000000000,2014-02-01 02:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 5948}, {'_account_id': 7141}, {'_account_id': 7781}]","[{'number': 1, 'created': '2013-12-06 11:19:52.000000000', 'files': ['neutron/tests/unit/services/metering/test_metering_plugin.py', 'neutron/db/metering/metering_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a95624b17434bb1b0cc2456d1ccc2f06403ef3f6', 'message': ""Fix MeteringLabel model to not clear router's tenant id on deletion\n\nforeign_keys parameter of orm.relationship should point to local columns.\nCurrently for MeteringLabel it points to Router.tenant_id column which causes\nrouters tenant_id clearing on label deletion.\n\nCloses-Bug: #1249188\n(cherry picked from commit d1220a3c22fccc1d86eaafeebe7ef9c074d4fcb9)\nChange-Id: Iccc0daf4f6edd537fd7f9e4b2fc4be094543ca5d\n""}]",0,60477,a95624b17434bb1b0cc2456d1ccc2f06403ef3f6,42,7,1,7141,,,0,"Fix MeteringLabel model to not clear router's tenant id on deletion

foreign_keys parameter of orm.relationship should point to local columns.
Currently for MeteringLabel it points to Router.tenant_id column which causes
routers tenant_id clearing on label deletion.

Closes-Bug: #1249188
(cherry picked from commit d1220a3c22fccc1d86eaafeebe7ef9c074d4fcb9)
Change-Id: Iccc0daf4f6edd537fd7f9e4b2fc4be094543ca5d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/60477/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/metering/test_metering_plugin.py', 'neutron/db/metering/metering_db.py']",2,a95624b17434bb1b0cc2456d1ccc2f06403ef3f6,bug/1249188," foreign_keys='MeteringLabel.tenant_id', uselist=True)", foreign_keys='Router.tenant_id'),14,1
openstack%2Fswift~master~I8805f7b0ef9f2b1f59be342e9c6d032330707688,openstack/swift,master,I8805f7b0ef9f2b1f59be342e9c6d032330707688,"Remove dependencies on pep8, pyflakes and flake8",MERGED,2014-01-16 12:39:26.000000000,2014-02-01 02:56:46.000000000,2014-02-01 02:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 4375}, {'_account_id': 6198}, {'_account_id': 6593}]","[{'number': 1, 'created': '2014-01-16 12:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b2c7a28903c609fa89cb38f10fff78023a76652', 'message': 'Remove dependencies on pep8, pyflakes and flake8\n\nThey should be determined by the hacking dependency\nimplicitely.\n\nChange-Id: I8805f7b0ef9f2b1f59be342e9c6d032330707688\n'}, {'number': 2, 'created': '2014-01-17 10:28:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/9f11819f1645dbcdf9272dde8532acd157085b5b', 'message': 'Remove dependencies on pep8, pyflakes and flake8\n\nThey should be determined by the hacking dependency\nimplicitely.\n\nChange-Id: I8805f7b0ef9f2b1f59be342e9c6d032330707688\n'}]",0,67145,9f11819f1645dbcdf9272dde8532acd157085b5b,9,5,2,6593,,,0,"Remove dependencies on pep8, pyflakes and flake8

They should be determined by the hacking dependency
implicitely.

Change-Id: I8805f7b0ef9f2b1f59be342e9c6d032330707688
",git fetch https://review.opendev.org/openstack/swift refs/changes/45/67145/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7b2c7a28903c609fa89cb38f10fff78023a76652,hacking,"# Hacking already pins down pep8, pyflakes and flake8 hacking>=0.5.6,<0.8","# Install bounded pep8/pyflakes first, then let flake8 install pep8==1.4.5 pyflakes==0.7.2 flake8==2.0 hacking>=0.5.6,<0.6",2,5
openstack%2Fkeystone~stable%2Fhavana~I5387021a53f3284add9e5e71e9e005c4dd31b76c,openstack/keystone,stable/havana,I5387021a53f3284add9e5e71e9e005c4dd31b76c,Remove roles from OS-TRUST list responses,MERGED,2014-01-28 00:23:34.000000000,2014-02-01 02:56:36.000000000,2014-02-01 02:56:35.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 994}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2218}, {'_account_id': 4328}, {'_account_id': 6738}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-01-28 00:23:34.000000000', 'files': ['keystone/trust/controllers.py', 'keystone/tests/test_v3_auth.py', 'keystone/tests/test_v3.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6a6bba0d447182e06120598c718b92b2e3d72a5', 'message': 'Remove roles from OS-TRUST list responses\n\nAccording to the docs, the list responses should not contain\nthe roles, only the detailed response when you get a trust\nexplicitly by ID.  So remove the roles and modify the tests\nappropriately.\n\nNote it was also observed that expires_at is present in all\nGET resonses, but not in the docs, but this has been agreed\nas a docs error so will be addressed via a docs patch.\n\nChange-Id: I5387021a53f3284add9e5e71e9e005c4dd31b76c\nCloses-Bug: #1245590\n(cherry picked from commit ab0e2c7667a9adc46fece742e1ee8160879b497b)\n'}]",5,69514,f6a6bba0d447182e06120598c718b92b2e3d72a5,15,9,1,7191,,,0,"Remove roles from OS-TRUST list responses

According to the docs, the list responses should not contain
the roles, only the detailed response when you get a trust
explicitly by ID.  So remove the roles and modify the tests
appropriately.

Note it was also observed that expires_at is present in all
GET resonses, but not in the docs, but this has been agreed
as a docs error so will be addressed via a docs patch.

Change-Id: I5387021a53f3284add9e5e71e9e005c4dd31b76c
Closes-Bug: #1245590
(cherry picked from commit ab0e2c7667a9adc46fece742e1ee8160879b497b)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/14/69514/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/trust/controllers.py', 'keystone/tests/test_v3_auth.py', 'keystone/tests/test_v3.py']",3,f6a6bba0d447182e06120598c718b92b2e3d72a5,listtrusts," self.assertValidTrustSummary, def assertValidTrustSummary(self, entity, ref=None): return self.assertValidTrust(entity, ref, summary=True) def assertValidTrust(self, entity, ref=None, summary=False): if summary: # Trust list contains no roles, but getting a specific # trust by ID provides the detailed reponse containing roles self.assertNotIn('roles', entity) self.assertIn('project_id', entity) else: for role in entity['roles']: self.assertIsNotNone(role) self.assertValidEntity(role) self.assertValidRole(role) self.assertValidListLinks(entity.get('roles_links')) # always disallow role xor project_id (neither or both is allowed) has_roles = bool(entity.get('roles')) has_project = bool(entity.get('project_id')) self.assertFalse(has_roles ^ has_project)"," self.assertValidTrust, def assertValidTrust(self, entity, ref=None): # always disallow project xor project_id (neither or both is allowed) has_roles = bool(entity.get('roles')) has_project = bool(entity.get('project_id')) self.assertFalse(has_roles ^ has_project) for role in entity['roles']: self.assertIsNotNone(role) self.assertValidEntity(role) self.assertValidRole(role) self.assertValidListLinks(entity.get('roles_links')) # these were used during dev and shouldn't land in final impl self.assertNotIn('role_ids', entity) self.assertNotIn('role_names', entity)",35,17
openstack%2Fcinder~master~Ia841e224bc253c68ed21520951016a1a90634faf,openstack/cinder,master,Ia841e224bc253c68ed21520951016a1a90634faf,Remove unused task from manager create_volume flow,MERGED,2014-01-31 16:08:08.000000000,2014-02-01 02:56:28.000000000,2014-02-01 02:56:27.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 7349}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-31 16:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d6292f08e6b345d20dfe2c53487f6256fac5fc17', 'message': 'Remove unused task from manager create_volume flow\n\nChange-Id: Ia841e224bc253c68ed21520951016a1a90634faf\n'}, {'number': 2, 'created': '2014-01-31 16:47:47.000000000', 'files': ['cinder/volume/flows/manager/create_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/db94cd232e8348f3a04536055ac199e3591ea854', 'message': ""Remove unused task from manager create_volume flow\n\nExtractSchedulerSpecTask hasn't been ever used in the\ncreate_volume flow, so it should be deleted.\n\nChange-Id: Ia841e224bc253c68ed21520951016a1a90634faf\n""}]",0,70367,db94cd232e8348f3a04536055ac199e3591ea854,10,8,2,7349,,,0,"Remove unused task from manager create_volume flow

ExtractSchedulerSpecTask hasn't been ever used in the
create_volume flow, so it should be deleted.

Change-Id: Ia841e224bc253c68ed21520951016a1a90634faf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/70367/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/flows/manager/create_volume.py'],1,d6292f08e6b345d20dfe2c53487f6256fac5fc17,taskflow,,"class ExtractSchedulerSpecTask(flow_utils.CinderTask): """"""Extracts a spec object from a partial and/or incomplete request spec. Reversion strategy: N/A """""" default_provides = set(['request_spec']) def __init__(self, db, **kwargs): super(ExtractSchedulerSpecTask, self).__init__(addons=[ACTION], **kwargs) self.db = db def _populate_request_spec(self, context, volume_id, snapshot_id, image_id): # Create the full request spec using the volume_id. # # NOTE(harlowja): this will fetch the volume from the database, if # the volume has been deleted before we got here then this should fail. # # In the future we might want to have a lock on the volume_id so that # the volume can not be deleted while its still being created? if not volume_id: msg = _(""No volume_id provided to populate a request_spec from"") raise exception.InvalidInput(reason=msg) volume_ref = self.db.volume_get(context, volume_id) volume_type_id = volume_ref.get('volume_type_id') vol_type = self.db.volume_type_get(context, volume_type_id) return { 'volume_id': volume_id, 'snapshot_id': snapshot_id, 'image_id': image_id, 'volume_properties': { 'size': utils.as_int(volume_ref.get('size'), quiet=False), 'availability_zone': volume_ref.get('availability_zone'), 'volume_type_id': volume_type_id, }, 'volume_type': list(dict(vol_type).iteritems()), } def execute(self, context, request_spec, volume_id, snapshot_id, image_id): # For RPC version < 1.2 backward compatibility if request_spec is None: request_spec = self._populate_request_spec(context, volume_id, snapshot_id, image_id) return { 'request_spec': request_spec, } ",0,51
openstack%2Fnova~stable%2Fhavana~Icb3796b0ddba25cf344953a649b2e762fab6d782,openstack/nova,stable/havana,Icb3796b0ddba25cf344953a649b2e762fab6d782,libvirt: Allow delete to complete when a volume disconnect fails,MERGED,2013-11-27 09:52:33.000000000,2014-02-01 02:55:30.000000000,2014-02-01 02:55:26.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 67}, {'_account_id': 1215}, {'_account_id': 1313}, {'_account_id': 1420}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1955}, {'_account_id': 4690}, {'_account_id': 5209}, {'_account_id': 6062}, {'_account_id': 7400}, {'_account_id': 8125}]","[{'number': 1, 'created': '2013-11-27 09:52:33.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f278f199b4103d5e3e910fdd98de9dc24cf1b8c7', 'message': 'libvirt: Allow delete to complete when a volume disconnect fails\n\nIf an instance which was booted from a volume fails to spawn, the\ninstance is left in an ERROR state.  If the failure is in the networking\nstage Nova will not have attached the volume via the Cinder driver,\nand so the volume remains in an available state.  In this state the\nvolume may be deleted or assigned to another instance.\nDuring the subsequent delete an exception may be thrown from\nthe cinder driver which prevents the instance from completing the\ndeletion process leaving the instance stuck in Error and unable to\nbe deleted.\n\nVolume exceptions should be logged and ignored when the instance\nis being deleted.\n\nCloses-Bug #1222979\n\n(cherry picked from commit 506a8f58cf4b8cecf90b647c7deba47da2a4dfec)\nConflicts:\n\tnova/tests/virt/libvirt/test_libvirt.py\n\nChange-Id: Icb3796b0ddba25cf344953a649b2e762fab6d782\n'}]",1,58707,f278f199b4103d5e3e910fdd98de9dc24cf1b8c7,18,15,1,1313,,,0,"libvirt: Allow delete to complete when a volume disconnect fails

If an instance which was booted from a volume fails to spawn, the
instance is left in an ERROR state.  If the failure is in the networking
stage Nova will not have attached the volume via the Cinder driver,
and so the volume remains in an available state.  In this state the
volume may be deleted or assigned to another instance.
During the subsequent delete an exception may be thrown from
the cinder driver which prevents the instance from completing the
deletion process leaving the instance stuck in Error and unable to
be deleted.

Volume exceptions should be logged and ignored when the instance
is being deleted.

Closes-Bug #1222979

(cherry picked from commit 506a8f58cf4b8cecf90b647c7deba47da2a4dfec)
Conflicts:
	nova/tests/virt/libvirt/test_libvirt.py

Change-Id: Icb3796b0ddba25cf344953a649b2e762fab6d782
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/58707/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,f278f199b4103d5e3e910fdd98de9dc24cf1b8c7,bug/1222979," try: self.volume_driver_method('disconnect_volume', connection_info, disk_dev) except Exception as exc: with excutils.save_and_reraise_exception() as ctxt: if destroy_disks: # Don't block on Volume errors if we're trying to # delete the instance as we may be patially created # or deleted ctxt.reraise = False LOG.warn(_(""Ignoring Volume Error on vol %(vol_id)s "" ""during delete %(exc)s""), {'vol_id': vol.get('volume_id'), 'exc': exc}, instance=instance)"," self.volume_driver_method('disconnect_volume', connection_info, disk_dev)",37,5
openstack%2Foslo.messaging~master~I717c0296bf8ae07b1dad8f0045bfe12c8620ad0a,openstack/oslo.messaging,master,I717c0296bf8ae07b1dad8f0045bfe12c8620ad0a,Use stevedore's make_test_instance,MERGED,2014-01-27 22:57:21.000000000,2014-02-01 02:55:22.000000000,2014-02-01 02:55:21.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-01-27 22:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/92c8abd14bfe26a77df9c602e539fb1b91d33079', 'message': ""Use stevedore's make_test_instance\n\nReplace the use of TestManager with make_test_instance\nto get an instance of the type of manager expected.\nThe old TestManager class is deprecated\n\nChange-Id: I717c0296bf8ae07b1dad8f0045bfe12c8620ad0a\nPartial-bug: #1273455\n""}, {'number': 2, 'created': '2014-01-28 00:23:23.000000000', 'files': ['tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dd8eb5196f8e00440ddd47decd8d7c1648b3642a', 'message': ""Use stevedore's make_test_instance\n\nReplace the use of TestManager with make_test_instance\nto get an instance of the type of manager expected.\nThe old TestManager class is deprecated\n\nChange-Id: I717c0296bf8ae07b1dad8f0045bfe12c8620ad0a\nPartial-bug: #1273455\n""}]",0,69492,dd8eb5196f8e00440ddd47decd8d7c1648b3642a,17,4,2,2472,,,0,"Use stevedore's make_test_instance

Replace the use of TestManager with make_test_instance
to get an instance of the type of manager expected.
The old TestManager class is deprecated

Change-Id: I717c0296bf8ae07b1dad8f0045bfe12c8620ad0a
Partial-bug: #1273455
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/92/69492/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_notifier.py'],1,92c8abd14bfe26a77df9c602e539fb1b91d33079,fix-stevedore-mocks-in-tests, return extension.ExtensionManager.make_test_instance( return extension.ExtensionManager.make_test_instance([]), return test_manager.TestExtensionManager( return test_manager.TestExtensionManager([]),2,2
openstack%2Fnova~master~I68958ddd1c1d0c02b54002c36b97270efaaaa892,openstack/nova,master,I68958ddd1c1d0c02b54002c36b97270efaaaa892,Sync latest config file generator from oslo-incubator,MERGED,2014-01-22 07:09:40.000000000,2014-02-01 02:54:21.000000000,2014-02-01 02:54:17.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1812}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-22 07:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8db5698adb541a95d1af0da324ee339fe4b5314e', 'message': ""Sync latest config file generator from oslo-incubator\n\nCommits included:\n\n  5dce17b Use entry points to discover options in libraries\n  dd9aa2b Remove unused variables\n  ad17a69 Fix filter() usage due to python 3 compability\n  343686b Add check_uptodate to tools/config\n\nThe library option discovery support is the main addition we're\ninterested in since it is required for oslo.messaging.\n\nChange-Id: I68958ddd1c1d0c02b54002c36b97270efaaaa892\n""}, {'number': 2, 'created': '2014-01-22 07:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c78578a205e469638e61c52b134b1aa6dc088a0e', 'message': ""Sync latest config file generator from oslo-incubator\n\nCommits included:\n\n  5dce17b Use entry points to discover options in libraries\n  dd9aa2b Remove unused variables\n  ad17a69 Fix filter() usage due to python 3 compability\n  343686b Add check_uptodate to tools/config\n\nThe library option discovery support is the main addition we're\ninterested in since it is required for oslo.messaging.\n\nChange-Id: I68958ddd1c1d0c02b54002c36b97270efaaaa892\n""}, {'number': 3, 'created': '2014-01-29 07:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1a90029fea331f7c2a682ca712bde70566ba94d', 'message': ""Sync latest config file generator from oslo-incubator\n\nCommits included:\n\n  e3dddd7 generator: use EXTRA_* env vars in the bash script\n  e8e636c generator: add an EXTRA_LIBRARIES env variable\n  6da13e8 generator: rename EXTRA_MODULES_FILE to RC_FILE\n  5dce17b Use entry points to discover options in libraries\n  dd9aa2b Remove unused variables\n  ad17a69 Fix filter() usage due to python 3 compability\n  343686b Add check_uptodate to tools/config\n\nThe library option discovery support is the main addition we're\ninterested in since it is required for oslo.messaging.\n\nChange-Id: I68958ddd1c1d0c02b54002c36b97270efaaaa892\n""}, {'number': 4, 'created': '2014-01-31 22:14:01.000000000', 'files': ['nova/openstack/common/config/generator.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh', 'tools/config/oslo.config.generator.rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/6fd09137f8c45ce4790833d7f6b840d885818771', 'message': ""Sync latest config file generator from oslo-incubator\n\nCommits included:\n\n  e3dddd7 generator: use EXTRA_* env vars in the bash script\n  e8e636c generator: add an EXTRA_LIBRARIES env variable\n  6da13e8 generator: rename EXTRA_MODULES_FILE to RC_FILE\n  5dce17b Use entry points to discover options in libraries\n  dd9aa2b Remove unused variables\n  ad17a69 Fix filter() usage due to python 3 compability\n  343686b Add check_uptodate to tools/config\n\nThe library option discovery support is the main addition we're\ninterested in since it is required for oslo.messaging.\n\nChange-Id: I68958ddd1c1d0c02b54002c36b97270efaaaa892\n""}]",0,68334,6fd09137f8c45ce4790833d7f6b840d885818771,33,7,4,1247,,,0,"Sync latest config file generator from oslo-incubator

Commits included:

  e3dddd7 generator: use EXTRA_* env vars in the bash script
  e8e636c generator: add an EXTRA_LIBRARIES env variable
  6da13e8 generator: rename EXTRA_MODULES_FILE to RC_FILE
  5dce17b Use entry points to discover options in libraries
  dd9aa2b Remove unused variables
  ad17a69 Fix filter() usage due to python 3 compability
  343686b Add check_uptodate to tools/config

The library option discovery support is the main addition we're
interested in since it is required for oslo.messaging.

Change-Id: I68958ddd1c1d0c02b54002c36b97270efaaaa892
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/68334/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/config/generator.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh']",3,8db5698adb541a95d1af0da324ee339fe4b5314e,bp/oslo.messaging,"PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:l:o: \ --long help,base-dir:,package-name:,output-dir:,library: -- ""$@"") echo ""-l, --library=LIB extra library that registers options for discovery"" -l|--library) shift LIBRARIES=""$LIBRARIES -l $1"" shift ;;python -m $MODULEPATH $LIBRARIES $FILES > $OUTPUTFILE","PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:o: \ --long help,base-dir:,package-name:,output-dir: -- ""$@"")python -m $MODULEPATH $FILES > $OUTPUTFILE",64,18
openstack%2Fopenstack-manuals~master~I9b4bec0245cdb2ad7ff81e5296f193b2139fc06b,openstack/openstack-manuals,master,I9b4bec0245cdb2ad7ff81e5296f193b2139fc06b,adds object storage lab to operator guide,MERGED,2014-02-01 02:38:43.000000000,2014-02-01 02:46:45.000000000,2014-02-01 02:46:44.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 02:38:43.000000000', 'files': ['doc/training-guides/bk002-ch014-operator-object-storage-node-lab.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8908863600044eea93cef2bafe632b8c8d312ff9', 'message': 'adds object storage lab to operator guide\n\nincludes install guides object storage installation\ninstructions and configuration.\n\nimplements blueprint training-manuals\n\nChange-Id: I9b4bec0245cdb2ad7ff81e5296f193b2139fc06b\n'}]",0,70503,8908863600044eea93cef2bafe632b8c8d312ff9,5,2,1,6923,,,0,"adds object storage lab to operator guide

includes install guides object storage installation
instructions and configuration.

implements blueprint training-manuals

Change-Id: I9b4bec0245cdb2ad7ff81e5296f193b2139fc06b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/03/70503/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/bk002-ch014-operator-object-storage-node-lab.xml'],1,8908863600044eea93cef2bafe632b8c8d312ff9,bp/training-manuals," <section xml:id=""operator-object-storage-node-lab-schedule""> <title>Day 9, 13:30 to 14:45, 15:00 to 17:00</title> <para></para> </section> <section xml:id=""operator-object-lab-getting-started""> <title>Installing Object Node</title> <xi:include href=""../install-guide/object-storage/section_object-storage-install.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'general-installation-steps-swift']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section> <section xml:id=""operator-object-lab-configuring-nodes""> <title>Configuring Object Node</title> <xi:include href=""../install-guide/object-storage/section_object-storage-install-config-storage-nodes.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'installing-and-configuring-storage-nodes']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section> <section xml:id=""operator-object-lab-configuring-proxy""> <title>Configuring Object Proxy</title> <xi:include href=""../install-guide/object-storage/section_object-storage-install-config-proxy-node.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'installing-and-configuring-the-proxy-node']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section> <section xml:id=""operator-object-lab-start-nodes""> <title>Start Object Node Services</title> <xi:include href=""../install-guide/object-storage/section_start-storage-node-services.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'start-storage-node-services']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section>"," <section xml:id=""operator-object-storage-node-lab-schedule""> <title>Day 9, 13:30 to 14:45, 15:00 to 17:00</title> <para></para> </section>",32,4
openstack%2Fopenstack-manuals~master~Iac9aa891081fc2914db055edd7ac054d5fc30ff7,openstack/openstack-manuals,master,Iac9aa891081fc2914db055edd7ac054d5fc30ff7,modifies set of books to remove duplicate references,MERGED,2014-02-01 01:57:31.000000000,2014-02-01 02:11:02.000000000,2014-02-01 02:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 01:57:31.000000000', 'files': ['doc/training-guides/module003-ch000-openstack-objstore.xml', 'doc/training-guides/lab000-openstack-training-labs.xml', 'doc/training-guides/st-training-guides.xml', 'doc/training-guides/module002-ch000-openstack-networking.xml', 'doc/training-guides/module001-intro-openstack.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/24c3664e2c989cd3d17128f31bf7d44faeecea4a', 'message': 'modifies set of books to remove duplicate references\n\nall of module and lab files are included in books 2-5. The\nfour index files used for books 2-5 are deleted as they are\nno longer used.\n\nChange-Id: Iac9aa891081fc2914db055edd7ac054d5fc30ff7\nCloses-Bug: #1275171\n'}]",0,70499,24c3664e2c989cd3d17128f31bf7d44faeecea4a,5,2,1,6923,,,0,"modifies set of books to remove duplicate references

all of module and lab files are included in books 2-5. The
four index files used for books 2-5 are deleted as they are
no longer used.

Change-Id: Iac9aa891081fc2914db055edd7ac054d5fc30ff7
Closes-Bug: #1275171
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/99/70499/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/module003-ch000-openstack-objstore.xml', 'doc/training-guides/lab000-openstack-training-labs.xml', 'doc/training-guides/st-training-guides.xml', 'doc/training-guides/module002-ch000-openstack-networking.xml', 'doc/training-guides/module001-intro-openstack.xml']",5,24c3664e2c989cd3d17128f31bf7d44faeecea4a,bug/1275171,,"<?xml version=""1.0"" encoding=""utf-8""?> <book xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""module001-intro-openstack""> <title>Introduction to OpenStack</title> <xi:include href=""module001-ch001-intro-text.xml""/> <xi:include href=""module001-ch002-brief-overview.xml""/> <xi:include href=""module001-ch003-core-projects.xml""/> <xi:include href=""module001-ch004-openstack-architecture.xml""/> <xi:include href=""module001-ch005-vm-provisioning-walk-through.xml""/> <xi:include href=""module001-ch006-overview-horizon-cli.xml""/> <xi:include href=""module001-ch007-keystone-arch.xml""/> <xi:include href=""module001-ch008-queues-messaging.xml""/> <xi:include href=""module001-ch009-vm-placement.xml""/> <xi:include href=""module001-ch010-vm-provisioning-indepth.xml""/> <xi:include href=""module001-ch011-block-storage.xml""/> </book>",0,67
openstack%2Fopenstack-manuals~master~Ic4471166c5c4de0b22551a94af8e7eebf1721a04,openstack/openstack-manuals,master,Ic4471166c5c4de0b22551a94af8e7eebf1721a04,adds more material to operator network node,MERGED,2014-02-01 01:40:58.000000000,2014-02-01 02:00:55.000000000,2014-02-01 02:00:54.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 01:40:58.000000000', 'files': ['doc/training-guides/bk002-ch010-operator-network-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/606a608aaa653fcf518f08ba2380c54d30ecbe2e', 'message': 'adds more material to operator network node\n\nincludes three new chapters to the operator network node\n\nimplements blueprint training-manuals\n\nChange-Id: Ic4471166c5c4de0b22551a94af8e7eebf1721a04\n'}]",0,70496,606a608aaa653fcf518f08ba2380c54d30ecbe2e,5,2,1,6923,,,0,"adds more material to operator network node

includes three new chapters to the operator network node

implements blueprint training-manuals

Change-Id: Ic4471166c5c4de0b22551a94af8e7eebf1721a04
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/70496/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/bk002-ch010-operator-network-node.xml'],1,606a608aaa653fcf518f08ba2380c54d30ecbe2e,bp/training-manuals," <para>TBD</para> </section> <section xml:id=""operator-openstack-networking-use-cases""> <title>Operator OpenStack Neutron Use Cases</title> <xi:include href=""./module002-ch003-neutron-use-cases.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'module002-ch003-neutron-use-cases']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section> <section xml:id=""operator-openstack-networking-security""> <title>Operator OpenStack Neutron Security</title> <xi:include href=""./module002-ch004-security-in-neutron.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'module002-ch004-security-in-neutron']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section> <section xml:id=""operator-openstack-networking-floating-ips""> <title>Operator OpenStack Neutron Floating IPs</title> <xi:include href=""./module002-ch005-floating-ips.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'module002-ch004-floating-ips']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include>", <para></para>,22,1
openstack%2Ffuel-docs~master~I17c68b26d90304b202c61387d82d8c56ccfdf550,openstack/fuel-docs,master,I17c68b26d90304b202c61387d82d8c56ccfdf550,Add instruction for Heat OSTF tests.,MERGED,2013-12-10 13:27:39.000000000,2014-02-01 01:59:33.000000000,2014-02-01 01:59:33.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9068}]","[{'number': 1, 'created': '2013-12-10 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9cabaa08f302878b8a9fdf698eebece7b87d6692', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}, {'number': 2, 'created': '2013-12-16 07:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f0906d86e9d1dad4fb04dab0bdf00669e0f9a0f0', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}, {'number': 3, 'created': '2013-12-20 08:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a3ebe0801512851577a14eff5e464cdd534174f1', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}, {'number': 4, 'created': '2014-01-14 09:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d721ce80716bf887c22b1d88fe458419a9f69ef2', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nDepends on https://review.openstack.org/#/c/61115/\nthat implements new Heat tests.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}, {'number': 5, 'created': '2014-01-14 09:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3b2bd2e679ac5462f5caf1397114d44eb42f716a', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nDepends on https://review.openstack.org/#/c/62323/\nthat implements new Heat tests.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}, {'number': 6, 'created': '2014-01-24 13:06:02.000000000', 'files': ['pages/user-guide/post-install-healthchecks.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/bf8e6d870d337a0cf782395047d1dcf89a7ef26b', 'message': 'Add instruction for Heat OSTF tests.\n\nAdded instruction for Heat autoscaling and\nnew test scenarios for Heat component\nto the post-install-healthchecks.rst.\n\nDepends on https://review.openstack.org/#/c/62323/\nthat implements new Heat tests.\n\nChange-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550\n'}]",5,61115,bf8e6d870d337a0cf782395047d1dcf89a7ef26b,47,5,6,9068,,,0,"Add instruction for Heat OSTF tests.

Added instruction for Heat autoscaling and
new test scenarios for Heat component
to the post-install-healthchecks.rst.

Depends on https://review.openstack.org/#/c/62323/
that implements new Heat tests.

Change-Id: I17c68b26d90304b202c61387d82d8c56ccfdf550
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/15/61115/6 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/post-install-healthchecks.rst'],1,9cabaa08f302878b8a9fdf698eebece7b87d6692,heat_tests_instruction,"Preparing Heat for Testing +++++++++++++++++++++++++++ The platform tests are run in the tenant you've specified in 'OpenStack Settings' tab during OpenStack installation. By default that is 'admin' tenant. Perform in that tenant the following actions to prepare Heat for testing of its autoscaling feature: 1. Download the following image of Linux Fedora with pre-installed cloud-init and heat-cfntools packages: http://fedorapeople.org/groups/heat/prebuilt-jeos-images/F17-x86_64-cfntools.qcow2 2. Then upload the image into OpenStack Image Service (Glance) into 'admin' tenant and name it 'F17-x86_64-cfntools'. Now Heat autoscaling is ready for testing. .. topic:: Typical stack actions: create, update, delete, show details, etc The test verifies that the Heat service can create, update and delete a stack and show details of the stack and its resources, events and template. 1. Create a stack. 2. Wait for the stack status to change to 'CREATE_COMPLETE'. 3. Get the details of the created stack by its name. 4. Get the resources list of the created stack. 5. Get the details of the stack resource. 6. Get the events list of the created stack. 7. Get the details of the stack event. 8. Update the stack. 9. Wait for the stack to update. 10. Get the stack template details. 11. Get the resources list of the updated stack. 12. Delete the stack. 13. Wait for the stack to be deleted. .. topic:: Check stack autoscaling The test verifies that the Heat service can scale the stack capacity up and down automatically according to the current conditions. Target component: Heat Scenario: 1. Image with cfntools package should be imported. 2. Create a flavor. 3. Create a keypair. 4. Save generated private key to file on Controller node. 5. Create a security group. 6. Create a stack. 7. Wait for the stack status to change to 'CREATE_COMPLETE'. 8. Create a floating ip. 9. Assign the floating ip to the instance of the stack. 10. Wait for cloud_init procedure to be completed on the instance. 11. Load the instance CPU to initiate the stack scaling up. 12. Wait for the 2nd instance to be launched. 13. Release the instance CPU to initiate the stack scaling down. 14. Wait for the 2nd instance to be terminated. 15. Delete the file with private key. 16. Delete the stack. 17. Wait for the stack to be deleted. .. topic:: Check stack rollback The test verifies that the Heat service can rollback the stack if its creation failed. Target component: Heat Scenario: 1. Start stack creation with rollback enabled. 2. Verify the stack appears with status 'CREATE_IN_PROGRESS'. 3. Wait for the stack to be deleted in result of rollback after expiration of timeout defined in WaitHandle resource of the stack. 4. Verify the instance of the stack has been deleted.",".. topic:: Create stack, check its details, then update and delete stack The test verifies that the Heat service can create, launch, and delete a stack. 1. Create stack. 2. Wait for stack status to become 'CREATE_COMPLETE'. 3. Get details of the created stack by its name. 4. Update stack. 5. Wait for stack to be updated. 6. Delete stack. 7. Wait for stack to be deleted.",76,9
openstack%2Ffuel-library~master~I45d039d5ae95d6a1a529b79db77bc2c7ce26c8d0,openstack/fuel-library,master,I45d039d5ae95d6a1a529b79db77bc2c7ce26c8d0,Reduce delay to 5 seconds when stopping supervisord,MERGED,2014-01-24 23:04:12.000000000,2014-02-01 01:54:48.000000000,2014-02-01 01:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-24 23:04:12.000000000', 'files': ['deployment/puppet/nailgun/files/supervisord'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/78c6e1ff868678ad6c0f9994dbf6de79f96ffa6f', 'message': 'Reduce delay to 5 seconds when stopping supervisord\n\nChange-Id: I45d039d5ae95d6a1a529b79db77bc2c7ce26c8d0\nCloses-bug: #1272550\n'}]",0,69059,78c6e1ff868678ad6c0f9994dbf6de79f96ffa6f,10,4,1,8829,,,0,"Reduce delay to 5 seconds when stopping supervisord

Change-Id: I45d039d5ae95d6a1a529b79db77bc2c7ce26c8d0
Closes-bug: #1272550
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/59/69059/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/files/supervisord'],1,78c6e1ff868678ad6c0f9994dbf6de79f96ffa6f,bug/1272550, killproc -d 5 supervisord, killproc -d 70 supervisord,1,1
openstack%2Foperations-guide~master~Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2,openstack/operations-guide,master,Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2,"Address O'Reilly edits for chapter 1, Provisioning and Deploying",MERGED,2013-12-19 01:17:46.000000000,2014-02-01 01:44:16.000000000,2014-01-30 07:21:43.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-12-19 01:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/083c46a17c75a96c3023f508a1957082ceb5f9d6', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 2, 'created': '2013-12-19 01:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/b38022045563d650275ea67df3bf9ffbed571417', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 3, 'created': '2013-12-19 14:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/5ee49bb5230da02af7516c3acca10ead355d4110', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 4, 'created': '2013-12-19 14:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/d40d29a383185506ad9825a35dd06496a64b00a8', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 5, 'created': '2013-12-19 15:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/aba4702a979f9d21eb01d6e71ff4e041d9a20f70', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 6, 'created': '2014-01-25 00:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/f85ea1d002b2cb7453e4bd7b80247616902c7097', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 7, 'created': '2014-01-26 12:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/c3e445cb4c1908d9884c22d0d02d2a6b3a957a4b', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}, {'number': 8, 'created': '2014-01-28 23:15:26.000000000', 'files': ['doc/openstack-ops/bk_ops_guide.xml', 'doc/openstack-ops/ch_arch_provision.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/0d9b3c3cc8644bcec1066b60ba29e59eabc5fe39', 'message': ""Address O'Reilly edits for chapter 1, Provisioning and Deploying\n\nChange-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2\n""}]",21,63038,0d9b3c3cc8644bcec1066b60ba29e59eabc5fe39,41,4,8,964,,,0,"Address O'Reilly edits for chapter 1, Provisioning and Deploying

Change-Id: Ifbcd41ae5f8a8c157c9ed8b26fd1370b423104b2
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/38/63038/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/bk_ops_guide.xml', 'doc/openstack-ops/ch_arch_provision.xml']",2,083c46a17c75a96c3023f508a1957082ceb5f9d6,provision-deploy-ch1-edits," <para>A critical part of a cloud's scalability is the amount of effort that it takes to run your cloud. To minimize the operational cost of running your cloud, set up and use an automated deployment and configuration infrastructure with repeatable managed configuration files like Puppet Modules or Chef Recipies.</para> <para>This infrastructure includes systems to automatically install the operating system's initial configuration and later coordinate the configuration of all services automatically and centrally, which reduces both manual effort and chance for error. Examples include Ansible, Chef, Puppet, Salt, and even using OpenStack to deploy OpenStack, fondly named Triple-O for OpenStack On OpenStack.</para> <para>An automated deployment system installs and configures operating systems on new servers, without intervention, after the absolute minimum amount of manual work, including physical racking, MAC to IP assignment, power configuration, and so on. Typically solutions rely on wrappers around PXE boot and TFTP servers for the basic operating system install, then hand off to an automated configuration management system.</para> <para>Ubuntu and Red Hat Linux both include mechanisms for configuring the operating system, including preseed and kickstart, that you can use after a network boot. Typically these are used to bootstrap an automated configuration system. Alternatively, you can use an image-based approach for deploying the operating system, such as systemimager. You can use both approaches with a virtualized infrastructure, such as when you run VMs to separate your control services and physical infrastructure.</para> <para>When you create a deployment plan, focus on a few vital areas because they are very hard to modify post-deployment.</para> <para>At the very base of any operating system are the hard drives on which the operating system (OS) is installed.</para> <para>You must complete the following configurations on the server's hard drives:</para> <para>Partitioning, which provides greater flexibility for layout of operating system and swap space, as described below. </para> <para>Adding to a RAID array (RAID stands for Redundant Array of Independent Disks), based on the number of disks you have available, so that you can add capacity as your cloud grows. Some options are described in more detail below.</para> <para>The simplest option to get started is to use one hard drive with two partitions:</para> <para>File system to store files, directories, where all the data lives including the root partition that starts and runs the system.</para> <para>Swap space to free up memory for processes, as an independent area of the physical disk used only for swapping and nothing else.</para> <para>RAID is not used in that simplistic one-drive setup because generally for production clouds you want to ensure that if one disk fails another can take its place.</para> <para>Installing to one hard drive is not recommended for production because if the hard drive fails, that entire server is down. Instead, we recommend that you use more than one disk. The number of disks determine what types of RAID arrays to build.</para> <para>We recommend that you choose one of the following multiple disk options:</para> <para><emphasis role=""bold"">Option 1:</emphasis> Partition all drives in the same way in a horizontal fashion, as shown in the following diagram: <informalfigure> <imagedata width=""5in"" fileref=""figures/os_disk_partition.png"" /> <para>With this option, you can assign different partitions to different RAID arrays. You can allocate partition 1 of disk one and two to the <code>/boot</code> partition mirror. You can make partition 2 of all disks the root partition mirror. You can use partition 3 of all disks for a <code>cinder-volumes</code> LVM partition running on a RAID 10 array.</para> <para>While you might end up with unused partitions, such as partition 1 in disk three and four of this example, it allows for maximum utilization off disk space. I/O performance might be an issue due to all disks being used for all tasks.</para> <para><emphasis role=""bold"">Option 2:</emphasis> Add all raw disks to one large RAID array, either hardware or software based. You can partition this large array with the boot, root, swap, and LVM areas. This option is simple to implement and uses all partitions. However, disk I/O might suffer.</para> <para><emphasis role=""bold"">Option 3:</emphasis> Dedicate entire disks to certain partitions. For example, you could allocate disk one and two entirely to the boot, root, and swap partitions under a RAID 1 mirror. Then, allocate disk 3 and 4 entirely to the LVM partition, also under a RAID 1 mirror. Disk I/O should be better because I/O is focused on dedicated tasks. However, the LVM partition is much smaller.</para> <para>You may find that you can automate the partitioning itself. For example, at MIT they use Fully Automatic Installation (FAI) (<link xlink:href=""http://fai-project.org/"" >fai-project.org/</link>) to do the initial PXE-based partition and install using some min/max and percentage-based partitioning.</para> <para>As with most architecture choices, the right answer depends on your environment. If you are using existing hardware, you know the disk density of your servers and can determine some decisions based on the options above. If you are going through a procurement process, your user's requirements also help you determine hardware purchases. Here are some examples from an internal private cloud providing web developers custom environments.</para> <itemizedlist> <listitem> <para>Hardware for controller nodes, used for all stateless OpenStack API services. About 32-64 GB memory, little attached disk, 1 processor, varied number of cores, such as 6-12.</para> </listitem> <listitem> <para>Hardware for compute nodes. Typically 256 or 144GB memory, 2 processors, 24 cores. 4-6TB direct attached storage, typically in a RAID 5 configuration.</para> </listitem> <listitem> <para>Hardware for storage nodes. Typically for these the disk space is optimized for the lowest cost per GB of storage while maintaining rack space efficiency.</para> </listitem> </itemizedlist> <para>Network configuration is a very large topic that spans multiple areas of this book. For now, make sure that your servers can PXE boot and successfully communicate with the deployment server.</para> <para>For example, you usually cannot configure NICs for VLANs when PXE booting. Additionally, you usually cannot PXE boot with bonded NICs. If you run into this scenario, consider using a simple 1 GB switch in a private network on which only your cloud <para>The purpose of automatic configuration management is to establish and maintain the consistency of a system with no human intervention. You want to maintain consistency in your deployments so you can have the same cloud every time, repeatably. Proper use of automatic configuration management tools ensures that components of the cloud systems are in particular states, in addition to simplifying deployment, and configuration change propagation.</para> <para>These tools also make it possible to test and roll back changes, as they are fully repeatable. Conveniently, a large body of work has been done by the OpenStack community in this space. Puppet  a configuration management tool  even provides official modules for OpenStack in an OpenStack infrastructure system know as Stackforge at https://github.com/stackforge/puppet-openstack. Chef configuration management is provided within https://github.com/rcbops/chef-cookbooks, soon to move to Stackforge also. Additional configuration management systems include Juju, Ansible, and Salt. Also, PackStack is a command line utility for RedHat Enterprise Linux and derivatives that uses Puppet modules to support rapid deployment of OpenStack on existing servers over an SSH connection.</para> <para>An integral part of a configuration management system is the items that it controls. You should carefully consider all of the items that you want, or do not want, to be automatically managed. For example, hard drives with user data should not be automatically formatted.</para> <para>In our experience, most operators don't sit right next to the servers running the cloud, and many don't necessarily enjoy visiting the data center. OpenStack should be entirely remotely configurable, but sometimes not everything goes according to plan.</para> <para>In this instance, having an out-of-band access into nodes running OpenStack components, is a boon. The IPMI protocol is the de-facto standard here, and acquiring hardware that supports it is highly recommended to achieve that lights-out data center aim.</para> <para>In addition, consider remote power control as well. While IPMI usually controls the server's power state, having remote access to the PDU that the server is plugged into can really be useful for situations when everything seems wedged.</para> </section> <section xml:id=""provision-deploy-summary""> <title>Parting Thoughts for Provisioning and Deploying OpenStack</title> <para>You can save time and resources by understanding the use cases for the cloud you want to create. You might have some high density storage hardware available and could plan to repurpose those for OpenStack Object Storage on it. Your users may have need for highly redundant servers to make sure their legacy applications continue to run. Perhaps a goal would be to rearchitect these legacy applications so they are running on multiple instances in a cloudy, fault-tolerant way, but not make it a goal to add to those clusters over time. Your users may indicate that they need scaling considerations due to heavy Windows server use. All of these considerations and the input from users help you build your use case and your deployment plan.</para> <para>For further research about OpenStack deployment, investigate the supported and documented pre-configured, pre-packaged installers for OpenStack from companies like <link xlink:href=""http://www.ubuntu.com/cloud/tools/openstack"">Canonical</link>, <link xlink:href=""http://www.cisco.com/web/solutions/openstack/"">Cisco</link>, Cloudscaling, <link xlink:href=""http://www-03.ibm.com/software/products/en/smartcloud-orchestrator/"">IBM</link>, Metacloud, Mirantis, Piston, Rackspace, <link xlink:href=""http://www.redhat.com/openstack/"">RedHat</link>, and SwiftStack.</para>"," <para>A critical part of a cloud's scalability is the amount of effort that it takes to run your cloud. To minimize the operational cost of running your cloud, set up and use an automated deployment and configuration infrastructure.</para> <para>This infrastructure includes systems to automatically install the operating system's initial configuration and later coordinate the configuration of all services automatically and centrally, which reduces both manual effort and chance for error.</para> <para>An automated deployment system installs and configures operating systems on new servers, without intervention, after the absolute minimum amount of manual work, including physical racking, MAC to IP assignment, power configuration, and so on. Typically solutions rely on wrappers around PXE boot and TFTP servers for the basic operating system install, then hand off to an automated configuration management system.</para> <para>Ubuntu and Red Hat Linux both include mechanisms for configuring the operating system, including preseed and kickstart, that you can use after a network boot. Typically these are used to bootstrap an automated configuration system. Alternatively, you can use an image-based approach for deploying the operating system, such as systemimager. You can use both approaches with a virtualized infrastructure, such as when you run VMs to separate your control services and physical infrastructure.</para> <para>When you create a deployment plan, focus on a few vital areas because they are very hard to modify post-deployment.</para> <para>At the very base of any operating system are the hard drives on which the OS is installed.</para> <para>You must complete the following configurations on the server's hard drives:</para> <para>Partitioning</para> <para>Adding to a RAID array</para> <para>The simplest option is to use one hard drive with two partitions:</para> <para>File system</para> <para>Swap space</para> <para>RAID is not used in this setup.</para> <para>This option is not recommended for production because if the hard drive fails, that entire server is down. Instead, we recommend that you use more than one disk. The number of disks determine what types of RAID arrays to build.</para> <para>We recommend that you choose one of the following multiple disk options:</para> <para><emphasis role=""bold"">Option 1:</emphasis> Partition all drives in the same way in a horizontal fashion, as shown in the following diagram: <informalfigure> <imagedata width=""5in"" fileref=""figures/os_disk_partition.png"" /> <para>With this option, you can assign different partitions to different RAID arrays. You can allocate partition 1 of disk one and two to the <code>/boot</code> partition mirror. You can make partition 2 of all disks the root partition mirror. You can use partition 3 of all disks for a <code>cinder-volumes</code> LVM partition running on a RAID 10 array.</para> <para>While you might end up with unused partitions, such as partition 1 in disk three and four of this example, it allows for maximum utilization off disk space. I/O performance might be an issue due to all disks being used for all tasks.</para> <para><emphasis role=""bold"">Option 2:</emphasis> Add all raw disks to one large RAID array, either hardware or software based. You can partition this large array with the boot, root, swap, and LVM areas. This option is simple to implement and uses all partitions. However, disk I/O might suffer.</para> <para><emphasis role=""bold"">Option 3:</emphasis> Dedicate entire disks to certain partitions. For example, you could allocate disk one and two entirely to the boot, root, and swap partitions under a RAID 1 mirror. Then, allocate disk 3 and 4 entirely to the LVM partition, also under a RAID 1 mirror. Disk I/O should be better because I/O is focused on dedicated tasks. However, the LVM partition is much smaller.</para> <para>As with most architecture choices, the right answer depends on your environment.</para> <para>Network configuration is a very large topic that spans multiple areas of this book. For now, make sure that your servers can PXE boot and successfully communicate with the deployment server.</para> <para>For example, you usually cannot configure NICs for VLANs when PXE booting. Additionally, you usually cannot PXE boot with bonded NICs. If you run into this scenario, consider using a simple 1 GB switch in a private network on which only your cloud <para>The purpose of automatic configuration management is to establish and maintain the consistency of a system with no human intervention. You want to maintain consistency in your deployments so you can have the same cloud every time, repeatably. Proper use of automatic configuration management tools ensures that components of the cloud systems are in particular states, in addition to simplifying deployment, and configuration change propagation.</para> <para>These tools also make it possible to test and roll back changes, as they are fully repeatable. Conveniently, a large body of work has been done by the OpenStack community in this space. Puppet  a configuration management tool  even provides official modules for OpenStack.</para> <para>An integral part of a configuration management system is the items that it controls. You should carefully consider all of the items that you want, or do not want, to be automatically managed.</para> <para>In our experience, most operators don't sit right next to the servers running the cloud, and many don't necessarily enjoy visiting the data center. OpenStack should be entirely remotely configurable, but sometimes not everything goes according to plan.</para> <para>In this instance, having an out-of-band access into nodes running OpenStack components, is a boon. The IPMI protocol is the de-facto standard here, and acquiring hardware that supports it is highly recommended to achieve that lights-out data center aim.</para> <para>In addition, consider remote power control as well. While IPMI usually controls the server's power state, having remote access to the PDU that the server is plugged into can really be useful for situations when everything seems wedged.</para>",198,133
openstack%2Ftempest~master~Id6be0f067673d600bf04dea700e69c2baffb9d9f,openstack/tempest,master,Id6be0f067673d600bf04dea700e69c2baffb9d9f,Fix logic for config file env variables,MERGED,2014-01-21 23:34:57.000000000,2014-02-01 01:40:38.000000000,2014-02-01 01:40:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-01-21 23:34:57.000000000', 'files': ['tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/56041dbf9d62aa2120910b2f7917927be3aa3466', 'message': ""Fix logic for config file env variables\n\nThis commit fixes the logic around the 2 env variables to set the\nlocation of the tempest config file. Previously the check to see\nwhether the config variables should be used instead of the default\npath would be too selective and the default path etc/tempest.conf\nwould be used. The only check needed is whether the specified file\nexists or not. The presence of the env variables shouldn't affect\nthat logic.\n\nChange-Id: Id6be0f067673d600bf04dea700e69c2baffb9d9f\n""}]",0,68287,56041dbf9d62aa2120910b2f7917927be3aa3466,6,3,1,5196,,,0,"Fix logic for config file env variables

This commit fixes the logic around the 2 env variables to set the
location of the tempest config file. Previously the check to see
whether the config variables should be used instead of the default
path would be too selective and the default path etc/tempest.conf
would be used. The only check needed is whether the specified file
exists or not. The presence of the env variables shouldn't affect
that logic.

Change-Id: Id6be0f067673d600bf04dea700e69c2baffb9d9f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/87/68287/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,56041dbf9d62aa2120910b2f7917927be3aa3466,fix-config, if not os.path.isfile(path):, if not (os.path.isfile(path) or 'TEMPEST_CONFIG_DIR' in os.environ or 'TEMPEST_CONFIG' in os.environ):,1,3
openstack%2Ftempest~master~I59f4d638f8ab6e95736c78a384607ca89f1dcb67,openstack/tempest,master,I59f4d638f8ab6e95736c78a384607ca89f1dcb67,Move common _delete_volume cleanup method in base compute test class,MERGED,2014-01-27 20:04:14.000000000,2014-02-01 01:40:30.000000000,2014-02-01 01:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-01-27 20:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45cad9bd11a7276bcae5e218dac3012bad48a819', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 2, 'created': '2014-01-27 20:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f10b629f8cd8c0628ed4e408af3b86382eb8b760', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 3, 'created': '2014-01-27 20:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/55b4ff7676bbf60e0e670d9185d0c3bbaec88d4a', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 4, 'created': '2014-01-27 23:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0856224f5d46a44292bf1ee730d9d61550e77a95', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 5, 'created': '2014-01-28 01:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d82517aee270b28700ea2394883ac883e1bc8850', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 6, 'created': '2014-01-28 19:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9c784ab3969b8ec3c7ccd20ff510674226a50052', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}, {'number': 7, 'created': '2014-01-28 21:50:23.000000000', 'files': ['tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/base.py', 'tempest/api/compute/volumes/test_volumes_get.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5dc594c1eb2d3f52008d0bc17d42986e94b44f90', 'message': 'Move common _delete_volume cleanup method in base compute test class\n\nThe test_volumes_get and test_volumes_list v2 compute tests were doing\nsimilar volume cleanup.  This patch moves that code into the base class\nso other tests that need to do volume cleanup, i.e. test_server_rescue,\ncan use it.\n\nRelated-Bug: #1254772\n\nChange-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67\n'}]",5,69454,5dc594c1eb2d3f52008d0bc17d42986e94b44f90,28,6,7,6873,,,0,"Move common _delete_volume cleanup method in base compute test class

The test_volumes_get and test_volumes_list v2 compute tests were doing
similar volume cleanup.  This patch moves that code into the base class
so other tests that need to do volume cleanup, i.e. test_server_rescue,
can use it.

Related-Bug: #1254772

Change-Id: I59f4d638f8ab6e95736c78a384607ca89f1dcb67
",git fetch https://review.opendev.org/openstack/tempest refs/changes/54/69454/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/base.py', 'tempest/api/compute/volumes/test_volumes_get.py']",3,45cad9bd11a7276bcae5e218dac3012bad48a819,bug/1254772," self.addCleanup(self._delete_volume, volume['id'])"," self.addCleanup(self._delete_volume, volume) def _delete_volume(self, volume): # Delete the Volume created in this method try: resp, _ = self.client.delete_volume(volume['id']) self.assertEqual(202, resp.status) # Checking if the deleted Volume still exists self.client.wait_for_resource_deletion(volume['id']) except KeyError: return ",12,14
openstack%2Ftempest~master~I02a05828e26be357728ff73adf75b469fce1b594,openstack/tempest,master,I02a05828e26be357728ff73adf75b469fce1b594,Move negative tests for v3 test_server_metadata,MERGED,2014-01-29 03:54:58.000000000,2014-02-01 01:40:22.000000000,2014-02-01 01:40:21.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 6348}]","[{'number': 1, 'created': '2014-01-29 03:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e4e29f52b92ba189862261920040fd4db570b37', 'message': 'Move negative tests for v3 test_server_metadata\n\nMove negative tests from test_server_metadata.py to its negative file\n\nPartially implements blueprint negative-test-files\n\nChange-Id: I02a05828e26be357728ff73adf75b469fce1b594\n'}, {'number': 2, 'created': '2014-01-29 04:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/950552ec71793b91e3fabf39f3bde6a31cbf5962', 'message': 'Move negative tests for v3 test_server_metadata\n\nMove negative tests from test_server_metadata.py to its negative file\n\nPartially implements blueprint negative-test-files\n\nChange-Id: I02a05828e26be357728ff73adf75b469fce1b594\n'}, {'number': 3, 'created': '2014-01-29 05:07:57.000000000', 'files': ['tempest/api/compute/v3/servers/test_server_metadata_negative.py', 'tempest/api/compute/v3/servers/test_server_metadata.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/54b5c45c19b65296c81cc5e27b0d33f1b6a49b64', 'message': 'Move negative tests for v3 test_server_metadata\n\nMove negative tests from test_server_metadata.py to its negative file\n\nPartially implements blueprint negative-test-files\n\nChange-Id: I02a05828e26be357728ff73adf75b469fce1b594\n'}]",2,69784,54b5c45c19b65296c81cc5e27b0d33f1b6a49b64,11,5,3,6167,,,0,"Move negative tests for v3 test_server_metadata

Move negative tests from test_server_metadata.py to its negative file

Partially implements blueprint negative-test-files

Change-Id: I02a05828e26be357728ff73adf75b469fce1b594
",git fetch https://review.opendev.org/openstack/tempest refs/changes/84/69784/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/servers/test_server_metadata_negative.py', 'tempest/api/compute/v3/servers/test_server_metadata.py']",2,5e4e29f52b92ba189862261920040fd4db570b37,bp/negative-test-files,," @attr(type=['negative', 'gate']) def test_server_metadata_negative(self): # Blank key should trigger an error. meta = {'': 'data1'} self.assertRaises(exceptions.BadRequest, self.create_test_server, meta=meta) # GET on a non-existent server should not succeed self.assertRaises(exceptions.NotFound, self.client.get_server_metadata_item, 999, 'test2') # List metadata on a non-existent server should not succeed self.assertRaises(exceptions.NotFound, self.client.list_server_metadata, 999) # Raise BadRequest if key in uri does not match # the key passed in body. meta = {'testkey': 'testvalue'} self.assertRaises(exceptions.BadRequest, self.client.set_server_metadata_item, self.server_id, 'key', meta) # Set metadata on a non-existent server should not succeed meta = {'meta1': 'data1'} self.assertRaises(exceptions.NotFound, self.client.set_server_metadata, 999, meta) # An update should not happen for a non-existent image meta = {'key1': 'value1', 'key2': 'value2'} self.assertRaises(exceptions.NotFound, self.client.update_server_metadata, 999, meta) # Blank key should trigger an error meta = {'': 'data1'} self.assertRaises(exceptions.BadRequest, self.client.update_server_metadata, self.server_id, meta=meta) # Should not be able to delete metadata item from a non-existent server self.assertRaises(exceptions.NotFound, self.client.delete_server_metadata_item, 999, 'd') # Raise a 413 OverLimit exception while exceeding metadata items limit # for tenant. _, quota_set = self.quotas.get_quota_set(self.tenant_id) quota_metadata = quota_set['metadata_items'] req_metadata = {} for num in range(1, quota_metadata + 2): req_metadata['key' + str(num)] = 'val' + str(num) self.assertRaises(exceptions.OverLimit, self.client.set_server_metadata, self.server_id, req_metadata) # Raise a 413 OverLimit exception while exceeding metadata items limit # for tenant (update). self.assertRaises(exceptions.OverLimit, self.client.update_server_metadata, self.server_id, req_metadata) # Raise a bad request error for blank key. # set_server_metadata will replace all metadata with new value meta = {'': 'data1'} self.assertRaises(exceptions.BadRequest, self.client.set_server_metadata, self.server_id, meta=meta) # Raise a bad request error for a missing metadata field # set_server_metadata will replace all metadata with new value meta = {'meta1': 'data1'} self.assertRaises(exceptions.BadRequest, self.client.set_server_metadata, self.server_id, meta=meta, no_metadata_field=True)",162,74
openstack%2Fopenstack-manuals~master~I56df2a9e86b19b52c9b47e6c70803089b10d52b7,openstack/openstack-manuals,master,I56df2a9e86b19b52c9b47e6c70803089b10d52b7,adds operator network lab,MERGED,2014-02-01 01:20:39.000000000,2014-02-01 01:37:38.000000000,2014-02-01 01:37:37.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 01:20:39.000000000', 'files': ['doc/training-guides/bk002-ch011-operator-network-node-lab.xml', 'doc/training-guides/lab002-network-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a95064160c36c47c1098dbdc9aea2c126a3f9582', 'message': 'adds operator network lab\n\nincludes network lab material in operator guide\n\nimplements blueprint training-manuals\n\nChange-Id: I56df2a9e86b19b52c9b47e6c70803089b10d52b7\n'}]",0,70489,a95064160c36c47c1098dbdc9aea2c126a3f9582,5,2,1,6923,,,0,"adds operator network lab

includes network lab material in operator guide

implements blueprint training-manuals

Change-Id: I56df2a9e86b19b52c9b47e6c70803089b10d52b7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/89/70489/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/bk002-ch011-operator-network-node-lab.xml', 'doc/training-guides/lab002-network-node.xml']",2,a95064160c36c47c1098dbdc9aea2c126a3f9582,bp/training-manuals," xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""lab002-network-node"">"," xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""lab002-network-node.xml"">",9,2
openstack%2Fswift~master~Ibd2ffd0e911463a432117b478585b9f8bc4a2495,openstack/swift,master,Ibd2ffd0e911463a432117b478585b9f8bc4a2495,Add a way to ratelimit all writes to an account,MERGED,2014-01-29 22:11:24.000000000,2014-02-01 01:34:23.000000000,2014-02-01 01:34:22.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-01-29 22:11:24.000000000', 'files': ['swift/common/middleware/ratelimit.py', 'test/unit/common/middleware/test_ratelimit.py', 'doc/source/ratelimit.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/b89ac55c05e723731d0df01c7a6e15c7d439f7f5', 'message': ""Add a way to ratelimit all writes to an account\n\nThis is in case a cluster gets a problem user who has distributed the\nwrites to a bunch of containers but is just taking too much of the\ncluster's resources.\n\nChange-Id: Ibd2ffd0e911463a432117b478585b9f8bc4a2495\n""}]",0,69995,b89ac55c05e723731d0df01c7a6e15c7d439f7f5,11,6,1,995,,,0,"Add a way to ratelimit all writes to an account

This is in case a cluster gets a problem user who has distributed the
writes to a bunch of containers but is just taking too much of the
cluster's resources.

Change-Id: Ibd2ffd0e911463a432117b478585b9f8bc4a2495
",git fetch https://review.opendev.org/openstack/swift refs/changes/95/69995/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/ratelimit.py', 'test/unit/common/middleware/test_ratelimit.py', 'doc/source/ratelimit.rst']",3,b89ac55c05e723731d0df01c7a6e15c7d439f7f5,acc_lvl_ratelimit,"----------------------------- Account Specific Ratelimiting ----------------------------- The above ratelimiting is to prevent the ""many writes to a single container"" bottleneck from causing a problem. There could also be a problem where a single account is just using too much of the cluster's resources. In this case, the container ratelimits may not help because the customer could be doing thousands of reqs/sec to distributed containers each getting a small fraction of the total so those limits would never trigger. If a system adminstrator notices this, he/she can set the X-Account-Sysmeta-Global-Write-Ratelimit on an account and that will limit the total number of write requests (PUT, POST, DELETE, COPY) that account can do for the whole account. This limit will be in addition to the applicable account/container limits from above. This header will be hidden from the user, because of the gatekeeper middleware, and can only be set using a direct client to the account nodes. It accepts a float value and will only limit requests if the value is > 0.",,151,71
openstack%2Fopenstack-manuals~master~I37ee1d6d6a09d6f38e177f92350ebfe9a8d83efd,openstack/openstack-manuals,master,I37ee1d6d6a09d6f38e177f92350ebfe9a8d83efd,updates operator compute node lab,MERGED,2014-02-01 00:46:25.000000000,2014-02-01 01:24:12.000000000,2014-02-01 01:24:11.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 00:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3b63dddf2c6817ef3c484fc33ca599b613509018', 'message': 'updates operator compute node lab\n\nincludes lab003 material\n\nimplements blueprint bp/training-manuals\n\nChange-Id: I37ee1d6d6a09d6f38e177f92350ebfe9a8d83efd\n'}, {'number': 2, 'created': '2014-02-01 01:04:57.000000000', 'files': ['doc/training-guides/lab003-compute-node.xml', 'doc/training-guides/bk002-ch008-operator-compute-node-lab.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/45d57d8515eb016e68386ca42988db45e5ce4254', 'message': 'updates operator compute node lab\n\nincludes lab003 material\n\nimplements blueprint training-manuals\n\nChange-Id: I37ee1d6d6a09d6f38e177f92350ebfe9a8d83efd\n'}]",0,70482,45d57d8515eb016e68386ca42988db45e5ce4254,9,2,2,6923,,,0,"updates operator compute node lab

includes lab003 material

implements blueprint training-manuals

Change-Id: I37ee1d6d6a09d6f38e177f92350ebfe9a8d83efd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/70482/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/lab003-compute-node.xml', 'doc/training-guides/bk002-ch008-operator-compute-node-lab.xml']",2,3b63dddf2c6817ef3c484fc33ca599b613509018,bp/bp," <section xml:id=""operator-lab003-compute-node-lab""> <title>Compute Node Lab</title> <xi:include href=""./lab003-compute-node.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'lab003-compute-node']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section>",,8,1
openstack%2Fopenstack-manuals~master~I0e08408e4ad9ae70ef51f0c594ab75d294c2c7ca,openstack/openstack-manuals,master,I0e08408e4ad9ae70ef51f0c594ab75d294c2c7ca,reorders operator chapters,MERGED,2014-02-01 00:58:11.000000000,2014-02-01 01:10:29.000000000,2014-02-01 01:10:28.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 00:58:11.000000000', 'files': ['doc/training-guides/bk002-operator-training-guide.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2214412987f90bf8b8b348be310820c6cae70b6f', 'message': 'reorders operator chapters\n\nnetwork now before compute chapter\n\nChange-Id: I0e08408e4ad9ae70ef51f0c594ab75d294c2c7ca\nCloses-Bug: #1275155\n'}]",0,70486,2214412987f90bf8b8b348be310820c6cae70b6f,5,2,1,6923,,,0,"reorders operator chapters

network now before compute chapter

Change-Id: I0e08408e4ad9ae70ef51f0c594ab75d294c2c7ca
Closes-Bug: #1275155
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/86/70486/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/bk002-operator-training-guide.xml'],1,2214412987f90bf8b8b348be310820c6cae70b6f,bug/1275155," <xi:include href=""./bk002-ch007-operator-compute-node.xml""/> <xi:include href=""./bk002-ch008-operator-compute-node-lab.xml""/> <xi:include href=""./bk002-ch009-operator-compute-node-quiz.xml""/>"," <xi:include href=""./bk002-ch007-operator-compute-node.xml""/> <xi:include href=""./bk002-ch008-operator-compute-node-lab.xml""/> <xi:include href=""./bk002-ch009-operator-compute-node-quiz.xml""/>",3,3
openstack%2Fkeystone~master~I1e2e477e39720ff6657c2e75c36bf59df1df8ded,openstack/keystone,master,I1e2e477e39720ff6657c2e75c36bf59df1df8ded,deprecate access log middleware,MERGED,2014-01-29 22:42:35.000000000,2014-02-01 00:29:16.000000000,2014-02-01 00:29:15.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-01-29 22:42:35.000000000', 'files': ['keystone/contrib/access/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/28c074451019d41b91d77665afd56b996a187c87', 'message': 'deprecate access log middleware\n\nChange-Id: I1e2e477e39720ff6657c2e75c36bf59df1df8ded\nImplements: bp deprecated-as-of-icehouse\n'}]",0,70003,28c074451019d41b91d77665afd56b996a187c87,6,3,1,4,,,0,"deprecate access log middleware

Change-Id: I1e2e477e39720ff6657c2e75c36bf59df1df8ded
Implements: bp deprecated-as-of-icehouse
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/70003/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/access/core.py'],1,28c074451019d41b91d77665afd56b996a187c87,bp/deprecated-as-of-icehouse,"from keystone.openstack.common import versionutils @versionutils.deprecated( what='keystone.contrib.access.core.AccessLogMiddleware', as_of=versionutils.deprecated.ICEHOUSE, in_favor_of='eventlet debug access log or httpd access log', remove_in=+2) def __init__(self, *args, **kwargs): super(AccessLogMiddleware, self).__init__(*args, **kwargs) ",,9,0
openstack%2Fopenstack-manuals~master~Id17ecd0bd500dad18740ab568140710aa46abac2,openstack/openstack-manuals,master,Id17ecd0bd500dad18740ab568140710aa46abac2,fixes duplicate section id,MERGED,2014-02-01 00:06:45.000000000,2014-02-01 00:16:27.000000000,2014-02-01 00:16:26.000000000,"[{'_account_id': 3}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-02-01 00:06:45.000000000', 'files': ['doc/training-guides/bk002-ch005-operator-controller-node-lab.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7981c95b86563294982baf245407dc0a0f081f62', 'message': 'fixes duplicate section id\n\nincorrect section id in operator controller lab\n\nChange-Id: Id17ecd0bd500dad18740ab568140710aa46abac2\nCloses-Bug: #1275142\n'}]",0,70476,7981c95b86563294982baf245407dc0a0f081f62,5,2,1,6923,,,0,"fixes duplicate section id

incorrect section id in operator controller lab

Change-Id: Id17ecd0bd500dad18740ab568140710aa46abac2
Closes-Bug: #1275142
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/76/70476/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/bk002-ch005-operator-controller-node-lab.xml'],1,7981c95b86563294982baf245407dc0a0f081f62,bug/1275142," <title>Days 2 to 4, 13:30 to 14:45, 15:00 to 16:30, 16:45 to 18:15</title> <section xml:id=""operator-lab001-control-node-lab""> <title>Control Node Lab</title> <xi:include href=""./lab001-control-node.xml"" xpointer=""xmlns(db=http://docbook.org/ns/docbook) xpath(//*[@xml:id = 'lab001-control-node.xml']/*[not(self::db:title)])""> <xi:fallback><para><mediaobject><imageobject><imagedata fileref=""figures/openstack-training-remote-content-not-available.png"" format=""PNG""/></imageobject></mediaobject>Remote content not available</para><para>image source</para><para><link xlink:href=""https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing"">https://docs.google.com/drawings/d/1J2LZSxmc06xKyxMgPjv5fC0blV7qK6956-AeTmFOZD4/edit?usp=sharing</link></para></xi:fallback> </xi:include> </section>"," <title>Days 2 to 4, 13:30 to 14:45, 15:00 to 17:00</title>",8,1
openstack%2Fswift~master~Ic3167019fc38ff6d0fc7e710912c59dc552484cc,openstack/swift,master,Ic3167019fc38ff6d0fc7e710912c59dc552484cc,Protect against NameError exceptions,ABANDONED,2013-10-22 22:12:51.000000000,2014-02-01 00:04:46.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-10-22 22:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/25b10097a06b5640f73d97111218b3242f5ae323', 'message': ""don't depend on the implementation of _quarantine for the correctness of _verify_data_file\n\nChange-Id: Ic3167019fc38ff6d0fc7e710912c59dc552484cc\n""}, {'number': 2, 'created': '2013-10-27 20:27:00.000000000', 'files': ['swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/76a6b5e0e4f60fde3c65ecb1ab52d199313c3d01', 'message': ""Protect against NameError exceptions\n\nIOW, don't depend on the implementation of _quarantine for the\ncorrectness of _verify_data_file\n\nChange-Id: Ic3167019fc38ff6d0fc7e710912c59dc552484cc\n""}]",0,53237,76a6b5e0e4f60fde3c65ecb1ab52d199313c3d01,14,6,2,330,,,0,"Protect against NameError exceptions

IOW, don't depend on the implementation of _quarantine for the
correctness of _verify_data_file

Change-Id: Ic3167019fc38ff6d0fc7e710912c59dc552484cc
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/53237/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/diskfile.py'],1,25b10097a06b5640f73d97111218b3242f5ae323,blah, metadata_size = obj_size = None,,1,0
openstack%2Fironic~master~Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10,openstack/ironic,master,Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10,Adds Neutron support to Ironic,MERGED,2014-01-10 22:22:05.000000000,2014-02-01 00:01:15.000000000,2014-02-01 00:01:15.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 4395}, {'_account_id': 5572}, {'_account_id': 5805}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-10 22:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/270f46b9523c044e1ba68dc29de4ae2ea9d56070', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly for DHCP BOOT requests to the\ncorrect conductor. In addition, Ironic will need to update that\nin Neutron when the mapping conductor becomes unavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 2, 'created': '2014-01-10 22:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a14c2925c75341e1445e4109cb7e629a4b854025', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly for DHCP BOOT requests to the\ncorrect conductor. In addition, Ironic will need to update that\nin Neutron when the mapping conductor becomes unavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 3, 'created': '2014-01-10 23:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a47dff8a8d805557bd0fd6afe09a18e65d571590', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 4, 'created': '2014-01-15 21:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e4ee39d038315480aa7a2013f2547432022e69c9', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 5, 'created': '2014-01-16 17:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/edeed0fc26cbedc71934117b3e3036f22836f4fe', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 6, 'created': '2014-01-20 15:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36e74945b0170c06c6db534d9dadf99003a535c0', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 7, 'created': '2014-01-20 17:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a736a127153fdc10a541905f8c3479e6a40f4ef', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 8, 'created': '2014-01-22 00:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f7b70f2a21e5c9d5309525212fa9bf46480c7742', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 9, 'created': '2014-01-23 02:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9fab3424c931152436a867ff56dd55f3e7bcbcc2', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 10, 'created': '2014-01-23 15:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a64899d7cd90ce965943bb2f94432eb5685c8a3f', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 11, 'created': '2014-01-24 21:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/25c58c1300845c5932327b82f86a80fd36ccbe64', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 12, 'created': '2014-01-27 21:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/15e3aa75988b37739ea5afb95a60b7fa8f2cca78', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 13, 'created': '2014-01-28 23:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fbcbeebb17429561018ee7e3b17474e5982def36', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to inform Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 14, 'created': '2014-01-28 23:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0e730951fa4255d60921bc5a390e307fe39e0d89', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 15, 'created': '2014-01-30 23:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8ff2ed383f4da6e32301c713b389d902f81d3b13', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 16, 'created': '2014-01-31 19:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e3967d1fabc590677c800cce7fbc3722914bf09f', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 17, 'created': '2014-01-31 20:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/223457de34fad96cbdefe843cd9e9588c7d123d3', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 18, 'created': '2014-01-31 20:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6582d1fae3a5cdb1ead7584604c04a60a4f459d5', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}, {'number': 19, 'created': '2014-01-31 22:30:39.000000000', 'files': ['ironic/common/exception.py', 'ironic/tests/test_neutron.py', 'etc/ironic/ironic.conf.sample', 'ironic/common/neutron.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a516b6a50bbe980be96cb39cbe060a4f0abc85f8', 'message': 'Adds Neutron support to Ironic\n\nIronic needs to notify Neutron of an instance:conductor change,\nso that Neutron can appropriatedly forward DHCP BOOT requests\nto the correct conductor. In addition, Ironic will need to update\nthis information in Neutron when the mapping conductor becomes\nunavailable.\n\nChange-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10\nImplements: blueprint add-neutron-support\n'}]",139,66071,a516b6a50bbe980be96cb39cbe060a4f0abc85f8,87,12,19,5572,,,0,"Adds Neutron support to Ironic

Ironic needs to notify Neutron of an instance:conductor change,
so that Neutron can appropriatedly forward DHCP BOOT requests
to the correct conductor. In addition, Ironic will need to update
this information in Neutron when the mapping conductor becomes
unavailable.

Change-Id: Iad8b110a7c690d2ee1c4af59103f5ecdd6a89e10
Implements: blueprint add-neutron-support
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/66071/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'etc/ironic/ironic.conf.sample', 'ironic/common/neutronv2/__init__.py', 'ironic/common/neutronv2/neutron.py', 'ironic/common/utils.py', 'ironic/tests/test_neutronv2.py']",6,270f46b9523c044e1ba68dc29de4ae2ea9d56070,bp/add-neutron-support,"# # Copyright 2014 OpenStack Foundation # All Rights Reserved # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import mock import uuid from neutronclient.common import exceptions from neutronclient.v2_0 import client from oslo.config import cfg from ironic.common import neutronv2 # from ironic.common.neutronv2 import neutron from ironic.common.neutronv2 import neutron from ironic.openstack.common import context from ironic.tests import base CONF = cfg.CONF #NOTE: Neutron client raises Exception which is discouraged by HACKING. # We set this variable here and use it for assertions below to avoid # the hacking checks until we can make neutron client throw a custom # exception class instead. NEUTRON_CLIENT_EXCEPTION = Exception class NeutronClientTestCase(base.TestCase): def setUp(self): super(NeutronClientTestCase, self).setUp() def test_withtoken(self): self.config(neutron_url='http://anyhost/', neutron_url_timeout=30) my_context = context.RequestContext(user='userid', tenant='my_tenant', auth_token='token') with mock.patch.object(client.Client, ""__init__"") as mock_client_init: mock_client_init(auth_strategy=None, endpoint_url=CONF.neutron_url, token=my_context.auth_token, timeout=CONF.neutron_url_timeout, insecure=False, ca_cert=None) mock_client_init.return_value = None neutronv2.get_client(my_context) def test_withouttoken(self): my_context = context.RequestContext(user='userid', tenant='my_tenant') self.assertRaises(exceptions.Unauthorized, neutronv2.get_client, my_context) def test_withtoken_context_is_admin(self): self.config(neutron_url='http://anyhost/', neutron_url_timeout=30) my_context = context.RequestContext(user='userid', tenant='my_tenant', is_admin=True) with mock.patch.object(client.Client, ""__init__"") as mock_client_init: mock_client_init(auth_strategy=None, endpoint_url=CONF.neutron_url, token=my_context.auth_token, timeout=CONF.neutron_url_timeout, insecure=False, ca_cert=None) mock_client_init.return_value = None # Note that although we have admin set in the context we # are not asking for an admin client, and so we auth with # our own token neutronv2.get_client(my_context) def test_withouttoken_keystone_connection_error(self): self.config(neutron_url='http://anyhost/', neutron_auth_strategy='keystone', neutron_url_timeout=30) my_context = context.RequestContext(user='userid', tenant='my_tenant') self.assertRaises(NEUTRON_CLIENT_EXCEPTION, neutronv2.get_client, my_context) class TestNeutronv2Base(base.TestCase): def setUp(self): super(TestNeutronv2Base, self).setUp() self.context = context.RequestContext(user='userid', tenant='my_tenantid') setattr(self.context, 'auth_token', 'bff4a5a6b9eb4ea2a6efec6eefb77936') self.instance = {'project_id': '9d049e4b60b64716978ab415e6fbd5c0', 'uuid': str(uuid.uuid4()), 'display_name': 'test_instance', 'availability_zone': 'nova', 'host': 'some_host', 'security_groups': []} self.instance2 = {'project_id': '9d049e4b60b64716978ab415e6fbd5c0', 'uuid': str(uuid.uuid4()), 'display_name': 'test_instance2', 'availability_zone': 'nova', 'security_groups': []} self.nets1 = [{'id': 'my_netid1', 'name': 'my_netname1', 'tenant_id': 'my_tenantid'}] self.nets2 = [] self.nets2.append(self.nets1[0]) self.nets2.append({'id': 'my_netid2', 'name': 'my_netname2', 'tenant_id': 'my_tenantid'}) self.nets3 = self.nets2 + [{'id': 'my_netid3', 'name': 'my_netname3', 'tenant_id': 'my_tenantid'}] self.nets4 = [{'id': 'his_netid4', 'name': 'his_netname4', 'tenant_id': 'his_tenantid'}] self.nets = [self.nets1, self.nets2, self.nets3, self.nets4] self.port_address = '10.0.1.2' self.port_data1 = [{'network_id': 'my_netid1', 'device_id': self.instance2['uuid'], 'device_owner': 'compute:nova', 'id': 'my_portid1', 'fixed_ips': [{'ip_address': self.port_address, 'subnet_id': 'my_subid1'}], 'mac_address': 'my_mac1', }] self.float_data1 = [{'port_id': 'my_portid1', 'fixed_ip_address': self.port_address, 'floating_ip_address': '172.0.1.2'}] self.dhcp_port_data1 = [{'fixed_ips': [{'ip_address': '10.0.1.9', 'subnet_id': 'my_subid1'}]}] self.port_address2 = '10.0.2.2' self.port_data2 = [] self.port_data2.append(self.port_data1[0]) self.port_data2.append({'network_id': 'my_netid2', 'device_id': self.instance['uuid'], 'device_owner': 'compute:nova', 'id': 'my_portid2', 'fixed_ips': [{'ip_address': self.port_address2, 'subnet_id': 'my_subid2'}], 'mac_address': 'my_mac2', }) self.float_data2 = [] self.float_data2.append(self.float_data1[0]) self.float_data2.append({'port_id': 'my_portid2', 'fixed_ip_address': '10.0.2.2', 'floating_ip_address': '172.0.2.2'}) self.port_data3 = [{'network_id': 'my_netid1', 'device_id': 'device_id3', 'device_owner': 'compute:nova', 'id': 'my_portid3', 'fixed_ips': [], # no fixed ip 'mac_address': 'my_mac3', }] self.subnet_data1 = [{'id': 'my_subid1', 'cidr': '10.0.1.0/24', 'network_id': 'my_netid1', 'gateway_ip': '10.0.1.1', 'dns_nameservers': ['8.8.1.1', '8.8.1.2']}] self.subnet_data2 = [] self.subnet_data_n = [{'id': 'my_subid1', 'cidr': '10.0.1.0/24', 'network_id': 'my_netid1', 'gateway_ip': '10.0.1.1', 'dns_nameservers': ['8.8.1.1', '8.8.1.2']}, {'id': 'my_subid2', 'cidr': '20.0.1.0/24', 'network_id': 'my_netid2', 'gateway_ip': '20.0.1.1', 'dns_nameservers': ['8.8.1.1', '8.8.1.2']}] self.subnet_data2.append({'id': 'my_subid2', 'cidr': '10.0.2.0/24', 'network_id': 'my_netid2', 'gateway_ip': '10.0.2.1', 'dns_nameservers': ['8.8.2.1', '8.8.2.2']}) self.fip_pool = {'id': '4fdbfd74-eaf8-4884-90d9-00bd6f10c2d3', 'name': 'ext_net', 'router:external': True, 'tenant_id': 'admin_tenantid'} self.fip_pool_nova = {'id': '435e20c3-d9f1-4f1b-bee5-4611a1dd07db', 'name': 'nova', 'router:external': True, 'tenant_id': 'admin_tenantid'} self.fip_unassociated = {'tenant_id': 'my_tenantid', 'id': 'fip_id1', 'floating_ip_address': '172.24.4.227', 'floating_network_id': self.fip_pool['id'], 'port_id': None, 'fixed_ip_address': None, 'router_id': None} fixed_ip_address = self.port_data2[1]['fixed_ips'][0]['ip_address'] self.fip_associated = {'tenant_id': 'my_tenantid', 'id': 'fip_id2', 'floating_ip_address': '172.24.4.228', 'floating_network_id': self.fip_pool['id'], 'port_id': self.port_data2[1]['id'], 'fixed_ip_address': fixed_ip_address, 'router_id': 'router_id1'} self._returned_nw_info = [] # self.mox.StubOutWithMock(neutronv2, 'get_client') # self.moxed_client = self.mox.CreateMock(client.Client) # self.addCleanup(CONF.reset) # self.addCleanup(self.mox.VerifyAll) # self.addCleanup(self.mox.UnsetStubs) # self.addCleanup(self.stubs.UnsetAll) class TestNeutronv2(TestNeutronv2Base): def setUp(self): super(TestNeutronv2, self).setUp() # neutronv2.get_client(mox.IgnoreArg()).MultipleTimes().AndReturn( # self.moxed_client) def test_neutron_port_update(self): opt_list = [{'opt_name': 'bootfile-name', 'opt_value': 'pxelinux.0'}, {'opt_name': 'tftp-server', 'opt_value': '123.123.123.123'}, {'opt_name': 'server-ip-address', 'opt_value': '123.123.123.456'}] upd_opts = [{'opt_name': 'bootfile-name', 'opt_value': 'changeme.0'}] expected_opts = copy.deepcopy(opt_list) for i in expected_opts: if i['opt_name'] == upd_opts[0]['opt_name']: i['opt_value'] = upd_opts[0]['opt_value'] break self.config(neutron_url='http://anyhost/', neutron_url_timeout=30) my_context = context.RequestContext(user='userid', tenant='my_tenant', auth_token='token') # TODO(dekehn): needs to add the rest of the update, but we will need # to create an entire network with ports in order to modify them. Some # of whats below is bogus. But it was necessary to pep8 happy! with mock.patch.object(client.Client, ""__init__"") as mock_client_init: mock_client_init(auth_strategy=None, endpoint_url=CONF.neutron_url, token=my_context.auth_token, timeout=CONF.neutron_url_timeout, insecure=False, ca_cert=None) mock_client_init.return_value = None neutronv2.get_client(my_context) port_id = str(uuid.uuid4()) port_id = str(port_id) test = neutron.neutronAPI.udpate_port print (""%r"" % (test)) #(my_context, port_id, #{'dhcp_options': opt_list}) ",,511,2
openstack%2Fdevstack~master~Ifa9d95bf759f1dad8685590a2df242d852dd2cb0,openstack/devstack,master,Ifa9d95bf759f1dad8685590a2df242d852dd2cb0,Install libguestfs for nova-compute on Ubuntu,MERGED,2014-01-30 22:50:04.000000000,2014-01-31 23:36:30.000000000,2014-01-31 23:36:30.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 970}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-01-30 22:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d61b3a262d01298cd9c593943756fe3d60e9cd29', 'message': 'Install libguestfs for nova-compute on Ubuntu\n\nWe were already installing this for n-cpu on rpm distros, but not\nUbuntu.  Install it so that nova-compute can use it for file injection,\nwhich is the preferred method over nbd.\n\nChange-Id: Ifa9d95bf759f1dad8685590a2df242d852dd2cb0\n'}, {'number': 2, 'created': '2014-01-30 23:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f849b4f40663a77aa76c8084fdb21f7f6f6cadf3', 'message': ""Install libguestfs for nova-compute on Ubuntu\n\nWe were already installing this for n-cpu on rpm distros, but not\nUbuntu.  Install it so that nova-compute can use it for file injection,\nwhich is the preferred method over nbd.\n\n(Pulled out of gate, this actually didn't pass check, and turns out\nguestfs is actually broken in icehouse.... yay.... tests?)\n\nChange-Id: Ifa9d95bf759f1dad8685590a2df242d852dd2cb0\n""}, {'number': 3, 'created': '2014-01-31 14:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2d2c7a1f77a80b2e29a81620f7b537a41408601a', 'message': ""Install libguestfs for nova-compute on Ubuntu\n\nWe were already installing this for n-cpu on rpm distros, but not\nUbuntu.  Install it so that nova-compute can use it for file injection,\nwhich is the preferred method over nbd.\n\nAdd a check for libguestfs and set CONF.libvirt.inject_partition to -1 if\nit is available.  This enables using libguestfs to determine the proper\npartition to inject into.\n\nIf libguestfs is available, don't bother trying to load the nbd kernel module,\nas it won't be used.\n\nChange-Id: Ifa9d95bf759f1dad8685590a2df242d852dd2cb0\n""}, {'number': 4, 'created': '2014-01-31 14:38:17.000000000', 'files': ['lib/nova', 'files/apts/n-cpu'], 'web_link': 'https://opendev.org/openstack/devstack/commit/43d950843769135d32ce316cfb0f72697a879623', 'message': ""Install libguestfs for nova-compute on Ubuntu\n\nWe were already installing this for n-cpu on rpm distros, but not\nUbuntu.  Install it so that nova-compute can use it for file injection,\nwhich is the preferred method over nbd.\n\nSet CONF.libvirt.inject_partition to -1.  This enables using libguestfs to\ndetermine the proper partition to inject into.\n\nDon't bother trying to load the nbd kernel module anymore.  It won't be used\nsince we know always expect libguestfs to be installed.\n\nChange-Id: Ifa9d95bf759f1dad8685590a2df242d852dd2cb0\n""}]",1,70237,43d950843769135d32ce316cfb0f72697a879623,30,9,4,1561,,,0,"Install libguestfs for nova-compute on Ubuntu

We were already installing this for n-cpu on rpm distros, but not
Ubuntu.  Install it so that nova-compute can use it for file injection,
which is the preferred method over nbd.

Set CONF.libvirt.inject_partition to -1.  This enables using libguestfs to
determine the proper partition to inject into.

Don't bother trying to load the nbd kernel module anymore.  It won't be used
since we know always expect libguestfs to be installed.

Change-Id: Ifa9d95bf759f1dad8685590a2df242d852dd2cb0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/70237/1 && git format-patch -1 --stdout FETCH_HEAD,['files/apts/n-cpu'],1,d61b3a262d01298cd9c593943756fe3d60e9cd29,guestfs-ubuntu,python-guestfs,,1,0
openstack%2Fkeystone~stable%2Fhavana~I45257c62168163d2d4ceda994c94ff2d16a27300,openstack/keystone,stable/havana,I45257c62168163d2d4ceda994c94ff2d16a27300,Sync rpc fix from oslo-incubator,MERGED,2013-12-06 14:11:38.000000000,2014-01-31 23:33:07.000000000,2014-01-31 23:33:06.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 5046}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-12-06 14:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f685f402b7c669bddf6a7e00cdc258de925d539', 'message': ""Sync rpc fix from oslo-incubator\n\nSync the following fixes from oslo-incubator:\n\ne355fa3 Create a shared queue for QPID topic consumers\ne227c0e Properly reconnect subscribing clients when QPID broker restarts\n76972e2 Support a new qpid topology\n7b0cb37 Don't eat callback exceptions\n\nIt also pulls unrelated fix for impl_kombu, to bring it in sync\nwith oslo-incubator stable/havana:\n69abf38 requeue instead of reject\n\nCloses-bug: #1251757\nCloses-bug: #1257293\nCloses-bug: #1178375\n\nChange-Id: I45257c62168163d2d4ceda994c94ff2d16a27300\n""}, {'number': 2, 'created': '2013-12-06 20:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb0bed739e49f0c08f8934c1fb579be03238d1c9', 'message': ""Sync rpc fix from oslo-incubator\n\nSync the following fixes from oslo-incubator:\n\ne355fa3 Create a shared queue for QPID topic consumers\n55678c7 Properly reconnect subscribing clients when QPID broker restarts\n76972e2 Support a new qpid topology\n7b0cb37 Don't eat callback exceptions\n\nIt also pulls unrelated fix for impl_kombu, to bring it in sync\nwith oslo-incubator stable/havana:\n69abf38 requeue instead of reject\n\nCloses-bug: #1251757\nCloses-bug: #1257293\nCloses-bug: #1178375\n\nChange-Id: I45257c62168163d2d4ceda994c94ff2d16a27300\n""}, {'number': 3, 'created': '2014-01-17 05:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f1a0202cd9fa85eead73ddbe2d06e1c2c58cbf59', 'message': ""Sync rpc fix from oslo-incubator\n\nSync the following fixes from oslo-incubator:\n\ne355fa3 Create a shared queue for QPID topic consumers\n55678c7 Properly reconnect subscribing clients when QPID broker restarts\n76972e2 Support a new qpid topology\n7b0cb37 Don't eat callback exceptions\n\nIt also pulls unrelated fix for impl_kombu, to bring it in sync\nwith oslo-incubator stable/havana:\n69abf38 requeue instead of reject\n\nCloses-bug: #1251757\nCloses-bug: #1257293\nCloses-bug: #1178375\nChange-Id: I45257c62168163d2d4ceda994c94ff2d16a27300\n""}, {'number': 4, 'created': '2014-01-31 09:12:27.000000000', 'files': ['keystone/openstack/common/rpc/impl_kombu.py', 'keystone/openstack/common/rpc/amqp.py', 'keystone/openstack/common/rpc/impl_qpid.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e8b7595c914ba7a40ce2ac4dcf11898db85708df', 'message': ""Sync rpc fix from oslo-incubator\n\nSync the following fixes from oslo-incubator:\n\ne355fa3 Create a shared queue for QPID topic consumers\n55678c7 Properly reconnect subscribing clients when QPID broker restarts\n76972e2 Support a new qpid topology\n7b0cb37 Don't eat callback exceptions\n\nIt also pulls unrelated fix for impl_kombu, to bring it in sync\nwith oslo-incubator stable/havana:\n69abf38 requeue instead of reject\n\nCloses-bug: #1251757\nCloses-bug: #1257293\nCloses-bug: #1178375\n\nChange-Id: I45257c62168163d2d4ceda994c94ff2d16a27300\n""}]",1,60514,e8b7595c914ba7a40ce2ac4dcf11898db85708df,44,6,4,1955,,,0,"Sync rpc fix from oslo-incubator

Sync the following fixes from oslo-incubator:

e355fa3 Create a shared queue for QPID topic consumers
55678c7 Properly reconnect subscribing clients when QPID broker restarts
76972e2 Support a new qpid topology
7b0cb37 Don't eat callback exceptions

It also pulls unrelated fix for impl_kombu, to bring it in sync
with oslo-incubator stable/havana:
69abf38 requeue instead of reject

Closes-bug: #1251757
Closes-bug: #1257293
Closes-bug: #1178375

Change-Id: I45257c62168163d2d4ceda994c94ff2d16a27300
",git fetch https://review.opendev.org/openstack/keystone refs/changes/14/60514/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/rpc/impl_kombu.py', 'keystone/openstack/common/rpc/amqp.py', 'keystone/openstack/common/rpc/impl_qpid.py', 'openstack-common.conf']",4,9f685f402b7c669bddf6a7e00cdc258de925d539,qpidv2-fixes-havana,module=rpc,,191,91
openstack%2Fglance~master~If70a924e01fa75a129ef97aed5a432eeb552c437,openstack/glance,master,If70a924e01fa75a129ef97aed5a432eeb552c437,Imported Translations from Transifex,MERGED,2013-11-24 06:04:06.000000000,2014-01-31 23:32:14.000000000,2014-01-31 23:32:14.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}]","[{'number': 1, 'created': '2013-11-24 06:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e9ec72a0ee8492506371ea001e5ac5e447340406', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 2, 'created': '2013-11-25 06:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3ec9a6f0c2cf0110f6bd84987b39d3d1ad09d37f', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 3, 'created': '2013-11-26 06:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ee42cada9f6daef7a0be5ed04b2c5f62bcf22de7', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 4, 'created': '2013-11-27 06:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ee731b1fef495e951813673f911bb33c89a94585', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 5, 'created': '2013-11-28 06:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a1eba3d017abef9330d8d4bbcaec2dea6417b719', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 6, 'created': '2013-11-29 06:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cb3ff9795853d048cc2eb1fd3e3077df46589ebe', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 7, 'created': '2013-11-30 06:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/64c7216b7c20d0080dbfc52060d02703706505b2', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 8, 'created': '2013-12-01 06:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/94492d59a74a9cf03c3aeb3203c4a2f0231f4a0e', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 9, 'created': '2013-12-02 06:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c4ff3233881e307617839d835e5062b3ab47a9c7', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 10, 'created': '2013-12-03 06:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/356f70fa70703b2c2ba6a6f7b0daea45109d95c6', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 11, 'created': '2013-12-04 06:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/62c6a3cbb2cdc46ddde7d56834ced25c287b4c53', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 12, 'created': '2013-12-05 06:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fd55a52b4b84a901b6392d0d34a0d7f11f8560a4', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 13, 'created': '2013-12-06 06:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0c458a36a160ffccb604de6012e7de1d7fd732ce', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 14, 'created': '2013-12-07 06:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/51493b7ac4b4f0918dbed57a39fcfd0b2de393a0', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 15, 'created': '2013-12-08 06:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e3e216c5982e5dc5b759d9d20d4e089990d023ed', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 16, 'created': '2013-12-09 06:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/877a81c339c3164ce4320ac328249ddbcea0cd99', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 17, 'created': '2013-12-10 06:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/896cd359b888c4936378657d48a1ecfa9d05de50', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 18, 'created': '2013-12-11 06:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8de33da2a93c3cca2cd88d9e48f97b02019bdf05', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 19, 'created': '2013-12-12 06:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a0f9b19ec1892a711d549951d83e88130bd66f43', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 20, 'created': '2013-12-13 06:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cacdb4dc79f0fc9ec0d1fd6fd9d065391d078747', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 21, 'created': '2013-12-14 06:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b9c75001208947e3b6f945c8249a6b5ff5af7bb1', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 22, 'created': '2013-12-15 06:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/527af416c40ca6572caeb23cfa62bd9f718aaf2e', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 23, 'created': '2013-12-16 06:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/579a9754ac2a0beec7caedbcd76ce401e8439132', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 24, 'created': '2013-12-17 06:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6c35c0f1e30c1f671d982237a19d511e19788fcb', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 25, 'created': '2013-12-18 06:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e4f14fda5d66354e026f622043b1b4b8b4e5896c', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 26, 'created': '2013-12-19 06:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6e329bafed1bb58787a18585142b127fd0604878', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 27, 'created': '2013-12-20 06:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/06fdbe70943145a0e9f05a7ac89be4123680c21c', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 28, 'created': '2013-12-21 06:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1d0a1b866038a9429ae17313d1e4f5529cc406a7', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 29, 'created': '2013-12-22 06:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/37a6752a9f802ed93ca2901c5ade56c081bef579', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 30, 'created': '2013-12-23 06:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/56bf60bd660fa0829c16ac5f6493962c6351ccf9', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 31, 'created': '2013-12-24 06:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c811626847f8592ecbd822a47fa7abef59d6d14f', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 32, 'created': '2013-12-25 06:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cad0a3bdb4b41e82d54b59828129236f166b3da0', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 33, 'created': '2013-12-26 06:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d51eedaa3c5544581514775d10f728f997ad1777', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 34, 'created': '2013-12-27 06:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4f4069233f3d6d4d3bdee47f4ad2bedd3eef0ba9', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 35, 'created': '2013-12-27 06:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5adedeb16e4ba632f0de5850db8ed327b2624f05', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 36, 'created': '2013-12-27 06:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/86147950e2daf054c29764a4a1d3635036b05a42', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 37, 'created': '2013-12-27 06:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b05b417507e6cdf88cc38d501c7e0c0df492eb3d', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 38, 'created': '2013-12-28 06:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7b0f62c1219308d97ad63b265cc45c05ec9a1b64', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 39, 'created': '2013-12-29 06:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/26e2e5e5aa6d555e5a608df567c90535a4409d90', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 40, 'created': '2013-12-30 06:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b3a6dc0f410e44cc90d5fd8cb09ebc6e9ba2334', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 41, 'created': '2013-12-31 06:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/34be204269ff3ce02ac5e63452eab877134d59ae', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 42, 'created': '2014-01-01 06:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0715282bea8de8f9734c460b16277ae8d2b0a592', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 43, 'created': '2014-01-02 06:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3ade017b6f11e1ce8a3bdf14626679affcf7bfd9', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 44, 'created': '2014-01-03 06:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ccac57e79578fc28c8908617fbcb81859e116eed', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 45, 'created': '2014-01-04 06:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7feebc650658cd53453bce2a86696828900efd54', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 46, 'created': '2014-01-05 06:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f443ab4efbc25bca1b258d59451f4fa36967f9a5', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 47, 'created': '2014-01-06 06:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e3ff2f4cf4c97598d980f6b73e1facbe6f1322c1', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 48, 'created': '2014-01-07 07:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b14d6c8637a8928fe432cb8bdb033bee1b9bece', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 49, 'created': '2014-01-08 06:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cf957481c03fc7ae3ce19e7ef9b6cd711f50d3bd', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 50, 'created': '2014-01-09 06:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4301a0641b6504064f7f528eb618f16c05bf18bf', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 51, 'created': '2014-01-10 06:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f6fbf30849cca5153723553788b6a2410c94c509', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 52, 'created': '2014-01-11 06:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4546ee9a55016058f19f49d168411c16cb696f4f', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 53, 'created': '2014-01-12 06:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5e7eab5c9f59d466575a00e277c574da096681d7', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 54, 'created': '2014-01-13 06:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/03a174a79e2b05b19e88def9f9271529bdca17e5', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 55, 'created': '2014-01-14 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/97ade7683b80c539d00a02a7b92e24d836c47cbd', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 56, 'created': '2014-01-15 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0864c702187ce3e2314aabf0f64bd9dd6ca72d4a', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 57, 'created': '2014-01-16 06:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a33d4b18fe7bfc167c8e657f75b83c1c174391cd', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 58, 'created': '2014-01-17 06:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cfbfc4b894b18a947673182cf5d61f9e4549eeee', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 59, 'created': '2014-01-18 06:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bb7dbe0679bc3995e7ce99dcb14b35bc58ee5558', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 60, 'created': '2014-01-19 06:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1a0d19a410733b1340432809d5263c82593f95b4', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 61, 'created': '2014-01-20 06:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/74d15118859c787b5e0994f145f68ee0f1fd7e73', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 62, 'created': '2014-01-21 06:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/af53b5990a9f73c2b52785fdc223738e58a895c6', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 63, 'created': '2014-01-22 07:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9eed97fe615a60cb785a1877e0b5a11e56190ef0', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 64, 'created': '2014-01-23 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/eb35eec8839d64d2024a55683a5ced60e99c5aa0', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 65, 'created': '2014-01-24 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d2469ac749b2baf8636753689f1c85d30c00dfaa', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 66, 'created': '2014-01-25 06:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3397ce1ae54113ce442ca93651cf5dced58e1c73', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 67, 'created': '2014-01-26 06:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6a6a7679a9ddcfad0e971dc587a006c80cd9ade8', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 68, 'created': '2014-01-27 06:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8e90f7068bddd10b2eb32396b74238650828b256', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 69, 'created': '2014-01-28 06:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d00350f976651b26218369325a9dd6c710f8b307', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 70, 'created': '2014-01-29 06:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8d11d21008fc50a9a48a7dbd0048f7fcac1358a4', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 71, 'created': '2014-01-30 06:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a213651f52bbb84199e4e6985f3f4e5aa544c775', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}, {'number': 72, 'created': '2014-01-31 06:02:10.000000000', 'files': ['glance/locale/km/LC_MESSAGES/glance.po', 'glance/locale/bn_IN/LC_MESSAGES/glance.po', 'glance/locale/fi_FI/LC_MESSAGES/glance.po', 'glance/locale/en_US/LC_MESSAGES/glance.po', 'glance/locale/pl_PL/LC_MESSAGES/glance.po', 'glance/locale/uk/LC_MESSAGES/glance.po', 'glance/locale/fr/LC_MESSAGES/glance.po', 'glance/locale/pt_BR/LC_MESSAGES/glance.po', 'glance/locale/ru/LC_MESSAGES/glance.po', 'glance/locale/eu_ES/LC_MESSAGES/glance.po', 'glance/locale/it_IT/LC_MESSAGES/glance.po', 'glance/locale/fa/LC_MESSAGES/glance.po', 'glance/locale/ur/LC_MESSAGES/glance.po', 'glance/locale/he_IL/LC_MESSAGES/glance.po', 'glance/locale/ja/LC_MESSAGES/glance.po', 'glance/locale/zh_TW/LC_MESSAGES/glance.po', 'glance/locale/de/LC_MESSAGES/glance.po', 'glance/locale/sv/LC_MESSAGES/glance.po', 'glance/locale/tl_PH/LC_MESSAGES/glance.po', 'glance/locale/he/LC_MESSAGES/glance.po', 'glance/locale/bs/LC_MESSAGES/glance.po', 'glance/locale/gl/LC_MESSAGES/glance.po', 'glance/locale/bg_BG/LC_MESSAGES/glance.po', 'glance/locale/ne/LC_MESSAGES/glance.po', 'glance/locale/hi/LC_MESSAGES/glance.po', 'glance/locale/ca/LC_MESSAGES/glance.po', 'glance/locale/ru_RU/LC_MESSAGES/glance.po', 'glance/locale/fil/LC_MESSAGES/glance.po', 'glance/locale/vi_VN/LC_MESSAGES/glance.po', 'glance/locale/cs/LC_MESSAGES/glance.po', 'glance/locale/nb/LC_MESSAGES/glance.po', 'glance/locale/sk/LC_MESSAGES/glance.po', 'glance/locale/tr/LC_MESSAGES/glance.po', 'glance/locale/glance.pot', 'glance/locale/pa_IN/LC_MESSAGES/glance.po', 'glance/locale/nl_NL/LC_MESSAGES/glance.po', 'glance/locale/sl_SI/LC_MESSAGES/glance.po', 'glance/locale/pt/LC_MESSAGES/glance.po', 'glance/locale/es_MX/LC_MESSAGES/glance.po', 'glance/locale/tr_TR/LC_MESSAGES/glance.po', 'glance/locale/tl/LC_MESSAGES/glance.po', 'glance/locale/da/LC_MESSAGES/glance.po', 'glance/locale/ml_IN/LC_MESSAGES/glance.po', 'glance/locale/hr/LC_MESSAGES/glance.po', 'glance/locale/id/LC_MESSAGES/glance.po', 'glance/locale/is_IS/LC_MESSAGES/glance.po', 'glance/locale/en_AU/LC_MESSAGES/glance.po', 'glance/locale/eu/LC_MESSAGES/glance.po', 'glance/locale/ro/LC_MESSAGES/glance.po', 'glance/locale/ko/LC_MESSAGES/glance.po', 'glance/locale/hu/LC_MESSAGES/glance.po', 'glance/locale/ka_GE/LC_MESSAGES/glance.po', 'glance/locale/ar/LC_MESSAGES/glance.po', 'glance/locale/en_GB/LC_MESSAGES/glance.po', 'glance/locale/kn/LC_MESSAGES/glance.po', 'glance/locale/zh_HK/LC_MESSAGES/glance.po', 'glance/locale/zh_CN/LC_MESSAGES/glance.po', 'glance/locale/it/LC_MESSAGES/glance.po', 'glance/locale/ms/LC_MESSAGES/glance.po', 'glance/locale/mr_IN/LC_MESSAGES/glance.po', 'glance/locale/es/LC_MESSAGES/glance.po', 'glance/locale/sw_KE/LC_MESSAGES/glance.po', 'glance/locale/ko_KR/LC_MESSAGES/glance.po'], 'web_link': 'https://opendev.org/openstack/glance/commit/899736b7c1cfcabfe15183572e10425444738ec4', 'message': 'Imported Translations from Transifex\n\nChange-Id: If70a924e01fa75a129ef97aed5a432eeb552c437\n'}]",0,58128,899736b7c1cfcabfe15183572e10425444738ec4,149,3,72,3,,,0,"Imported Translations from Transifex

Change-Id: If70a924e01fa75a129ef97aed5a432eeb552c437
",git fetch https://review.opendev.org/openstack/glance refs/changes/28/58128/5 && git format-patch -1 --stdout FETCH_HEAD,"['glance/locale/km/LC_MESSAGES/glance.po', 'glance/locale/bn_IN/LC_MESSAGES/glance.po', 'glance/locale/fi_FI/LC_MESSAGES/glance.po', 'glance/locale/en_US/LC_MESSAGES/glance.po', 'glance/locale/pl_PL/LC_MESSAGES/glance.po', 'glance/locale/uk/LC_MESSAGES/glance.po', 'glance/locale/fr/LC_MESSAGES/glance.po', 'glance/locale/pt_BR/LC_MESSAGES/glance.po', 'glance/locale/ru/LC_MESSAGES/glance.po', 'glance/locale/eu_ES/LC_MESSAGES/glance.po', 'glance/locale/it_IT/LC_MESSAGES/glance.po', 'glance/locale/fa/LC_MESSAGES/glance.po', 'glance/locale/ur/LC_MESSAGES/glance.po', 'glance/locale/ja/LC_MESSAGES/glance.po', 'glance/locale/zh_TW/LC_MESSAGES/glance.po', 'glance/locale/de/LC_MESSAGES/glance.po', 'glance/locale/sv/LC_MESSAGES/glance.po', 'glance/locale/tl_PH/LC_MESSAGES/glance.po', 'glance/locale/bs/LC_MESSAGES/glance.po', 'glance/locale/gl/LC_MESSAGES/glance.po', 'glance/locale/bg_BG/LC_MESSAGES/glance.po', 'glance/locale/ne/LC_MESSAGES/glance.po', 'glance/locale/hi/LC_MESSAGES/glance.po', 'glance/locale/ca/LC_MESSAGES/glance.po', 'glance/locale/ru_RU/LC_MESSAGES/glance.po', 'glance/locale/fil/LC_MESSAGES/glance.po', 'glance/locale/vi_VN/LC_MESSAGES/glance.po', 'glance/locale/cs/LC_MESSAGES/glance.po', 'glance/locale/nb/LC_MESSAGES/glance.po', 'glance/locale/sk/LC_MESSAGES/glance.po', 'glance/locale/tr/LC_MESSAGES/glance.po', 'glance/locale/glance.pot', 'glance/locale/nl_NL/LC_MESSAGES/glance.po', 'glance/locale/sl_SI/LC_MESSAGES/glance.po', 'glance/locale/pt/LC_MESSAGES/glance.po', 'glance/locale/es_MX/LC_MESSAGES/glance.po', 'glance/locale/tr_TR/LC_MESSAGES/glance.po', 'glance/locale/tl/LC_MESSAGES/glance.po', 'glance/locale/da/LC_MESSAGES/glance.po', 'glance/locale/ml_IN/LC_MESSAGES/glance.po', 'glance/locale/hr/LC_MESSAGES/glance.po', 'glance/locale/id/LC_MESSAGES/glance.po', 'glance/locale/en_AU/LC_MESSAGES/glance.po', 'glance/locale/eu/LC_MESSAGES/glance.po', 'glance/locale/ro/LC_MESSAGES/glance.po', 'glance/locale/ko/LC_MESSAGES/glance.po', 'glance/locale/hu/LC_MESSAGES/glance.po', 'glance/locale/ka_GE/LC_MESSAGES/glance.po', 'glance/locale/ar/LC_MESSAGES/glance.po', 'glance/locale/en_GB/LC_MESSAGES/glance.po', 'glance/locale/kn/LC_MESSAGES/glance.po', 'glance/locale/zh_HK/LC_MESSAGES/glance.po', 'glance/locale/zh_CN/LC_MESSAGES/glance.po', 'glance/locale/it/LC_MESSAGES/glance.po', 'glance/locale/ms/LC_MESSAGES/glance.po', 'glance/locale/mr_IN/LC_MESSAGES/glance.po', 'glance/locale/es/LC_MESSAGES/glance.po', 'glance/locale/sw_KE/LC_MESSAGES/glance.po', 'glance/locale/ko_KR/LC_MESSAGES/glance.po']",59,e9ec72a0ee8492506371ea001e5ac5e447340406,transifex/translations,"""POT-Creation-Date: 2013-11-24 06:03+0000\n""","""POT-Creation-Date: 2013-11-23 06:03+0000\n""#~ msgid """" #~ ""Whether to include the backend image "" #~ ""storage location in image properties. "" #~ ""Revealing storage location can be a "" #~ ""security risk, so use this setting "" #~ ""with caution!"" #~ msgstr """" ",60,469
openstack%2Fdesignate~master~Iab185314be2efc78753289b06efffefbe8e0d0f6,openstack/designate,master,Iab185314be2efc78753289b06efffefbe8e0d0f6,Keep the DevStack plugin in-tree,MERGED,2014-01-31 21:47:45.000000000,2014-01-31 23:10:11.000000000,2014-01-31 23:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-01-31 21:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b549be97c17e49c627c379890d9af45d79baeceb', 'message': 'Keep the DevStack plugin in-tree\n\nChange-Id: Iab185314be2efc78753289b06efffefbe8e0d0f6\n'}, {'number': 2, 'created': '2014-01-31 21:55:05.000000000', 'files': ['contrib/devstack/extras.d/70-designate.sh', 'contrib/devstack/install.sh', 'contrib/devstack/lib/designate', 'contrib/devstack/exercises/designate.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/7fc43e3805793b1cf274560a7bcf7856455a5aee', 'message': 'Keep the DevStack plugin in-tree\n\nChange-Id: Iab185314be2efc78753289b06efffefbe8e0d0f6\n'}]",0,70447,7fc43e3805793b1cf274560a7bcf7856455a5aee,9,3,2,741,,,0,"Keep the DevStack plugin in-tree

Change-Id: Iab185314be2efc78753289b06efffefbe8e0d0f6
",git fetch https://review.opendev.org/openstack/designate refs/changes/47/70447/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/extras.d/70-designate.sh', 'contrib/devstack/install.sh', 'contrib/devstack/lib/designate', 'contrib/devstack/exercises/designate.sh']",4,b549be97c17e49c627c379890d9af45d79baeceb,designate-dsvm,"#!/usr/bin/env bash # **designate.sh** # Simple Tests to verify designate is running echo ""*********************************************************************"" echo ""Begin DevStack Exercise: $0"" echo ""*********************************************************************"" # This script exits on an error so that errors don't compound and you see # only the first error that occurred. set -o errexit # Print the commands being run so that we can see the command that triggers # an error. It is also useful for following allowing as the install occurs. set -o xtrace # Settings # ======== # Keep track of the current directory EXERCISE_DIR=$(cd $(dirname ""$0"") && pwd) TOP_DIR=$(cd $EXERCISE_DIR/..; pwd) # Import common functions source $TOP_DIR/functions # Import configuration source $TOP_DIR/openrc # Import exercise configuration source $TOP_DIR/exerciserc # Skip if designate is not enabled is_service_enabled designate || exit 55 # Various functions # ----------------- function get_domain_id { local DOMAIN_NAME=$1 local DOMAIN_ID=$(designate domain-list | egrep "" $DOMAIN_NAME "" | get_field 1) die_if_not_set $LINENO DOMAIN_ID ""Failure retrieving DOMAIN_ID"" echo ""$DOMAIN_ID"" } function get_record_id { local DOMAIN_ID=$1 local RECORD_NAME=$2 local RECORD_ID=$(designate record-list $DOMAIN_ID | egrep "" $RECORD_NAME "" | get_field 1) die_if_not_set $LINENO RECORD_ID ""Failure retrieving RECORD_ID"" echo ""$RECORD_ID"" } # Testing Domains # =============== # List domains designate domain-list # Create random domain name DOMAIN_NAME=""exercise-$(openssl rand -hex 4).com."" # Create the domain designate domain-create --name $DOMAIN_NAME --email devstack@example.org DOMAIN_ID=$(get_domain_id $DOMAIN_NAME) # Fetch the domain designate domain-get $DOMAIN_ID # Testing Records # =============== # Create random record name RECORD_NAME=""$(openssl rand -hex 4).${DOMAIN_NAME}"" # Create the record designate record-create $DOMAIN_ID --name $RECORD_NAME --type A --data 127.0.0.1 RECORD_ID=$(get_record_id $DOMAIN_ID $RECORD_NAME) # Fetch the record designate record-get $DOMAIN_ID $RECORD_ID set +o xtrace echo ""*********************************************************************"" echo ""SUCCESS: End DevStack Exercise: $0"" echo ""*********************************************************************""",,357,0
openstack%2Fcookbook-openstack-common~master~I6de2942ea4c7713d0c7115e40d42066353d97e85,openstack/cookbook-openstack-common,master,I6de2942ea4c7713d0c7115e40d42066353d97e85,Attribute typo,ABANDONED,2014-01-31 22:58:33.000000000,2014-01-31 23:08:14.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-31 22:58:33.000000000', 'files': ['libraries/network.rb', 'metadata.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/834e967a037fbcbc0fed9fa9df0ba522260b4c0c', 'message': 'Attribute typo\n\nThe network library looks for ""node[\'network\']""\nhowever, this doesn\'t exist, it\'s ""node[\'networking\']""\n\nChange-Id: I6de2942ea4c7713d0c7115e40d42066353d97e85\n'}]",0,70464,834e967a037fbcbc0fed9fa9df0ba522260b4c0c,2,1,1,7220,,,0,"Attribute typo

The network library looks for ""node['network']""
however, this doesn't exist, it's ""node['networking']""

Change-Id: I6de2942ea4c7713d0c7115e40d42066353d97e85
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/64/70464/1 && git format-patch -1 --stdout FETCH_HEAD,"['libraries/network.rb', 'metadata.rb']",2,834e967a037fbcbc0fed9fa9df0ba522260b4c0c,networking-typo,version '8.0.2',version '8.0.1',2,2
openstack%2Fswift-bench~master~I8bbb74fc515dd3f8ac05ee258a58cd19d6d09c58,openstack/swift-bench,master,I8bbb74fc515dd3f8ac05ee258a58cd19d6d09c58,Add MANIFEST.in,MERGED,2014-01-14 16:20:32.000000000,2014-01-31 23:01:30.000000000,2014-01-31 23:01:30.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-01-14 16:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/cd9f9404dc6161954672c3f2aed5622576cffc14', 'message': 'Add MANIFEST.in\n\n- minVersion to 1.6 for tox as well to get a much faster run.\n\nCloses-Bug: #1269054\nChange-Id: I8bbb74fc515dd3f8ac05ee258a58cd19d6d09c58\n'}, {'number': 2, 'created': '2014-01-24 06:52:40.000000000', 'files': ['tox.ini', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/cfb50967ae4c0ede27c01fc3aed6b85c7aea8dba', 'message': 'Add MANIFEST.in\n\n- minVersion to 1.6 for tox as well to get a much faster run.\n\nCloses-Bug: #1269054\nChange-Id: I8bbb74fc515dd3f8ac05ee258a58cd19d6d09c58\n'}]",0,66620,cfb50967ae4c0ede27c01fc3aed6b85c7aea8dba,10,4,2,866,,,0,"Add MANIFEST.in

- minVersion to 1.6 for tox as well to get a much faster run.

Closes-Bug: #1269054
Change-Id: I8bbb74fc515dd3f8ac05ee258a58cd19d6d09c58
",git fetch https://review.opendev.org/openstack/swift-bench refs/changes/20/66620/2 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'MANIFEST.in']",2,cd9f9404dc6161954672c3f2aed5622576cffc14,66620,include AUTHORS LICENSE .unittests test/__init__.py CHANGELOG include tox.ini requirements.txt test-requirements.txt ,,4,0
openstack%2Fzaqar~master~I1a5c5be290437b6087cb57c63d9ea10826667f19,openstack/zaqar,master,I1a5c5be290437b6087cb57c63d9ea10826667f19,DRY applied to class names,MERGED,2014-01-22 11:09:03.000000000,2014-01-31 22:58:17.000000000,2014-01-31 22:58:17.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-01-22 11:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3ae03ccc6d6a097d7a5ed4441b0b912be2b05225', 'message': 'DRY applied to class names\n\nCloses-bug: #1237747\n\nWe had some classes that contained part of the namespace in its name.\nThis makes classes names unnecessarily verbose.\n\nChange-Id: I1a5c5be290437b6087cb57c63d9ea10826667f19\n'}, {'number': 2, 'created': '2014-01-24 10:34:27.000000000', 'files': ['marconi/queues/storage/mongodb/claims.py', 'marconi/queues/storage/__init__.py', 'marconi/tests/queues/storage/base.py', 'marconi/queues/transport/wsgi/v1.py', 'marconi/queues/storage/sqlite/queues.py', 'marconi/queues/storage/mongodb/queues.py', 'marconi/tests/faulty_storage.py', 'marconi/queues/transport/wsgi/public/driver.py', 'marconi/queues/storage/sqlite/messages.py', 'marconi/queues/storage/sqlite/claims.py', 'marconi/queues/storage/mongodb/messages.py', 'marconi/queues/storage/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/518c34e9c757f77933f44709de18f830055ac9eb', 'message': 'DRY applied to class names\n\nCloses-bug: #1237747\n\nWe had some classes that contained part of the namespace in its name.\nThis makes classes names unnecessarily verbose.\n\nChange-Id: I1a5c5be290437b6087cb57c63d9ea10826667f19\n'}]",0,68352,518c34e9c757f77933f44709de18f830055ac9eb,9,5,2,6159,,,0,"DRY applied to class names

Closes-bug: #1237747

We had some classes that contained part of the namespace in its name.
This makes classes names unnecessarily verbose.

Change-Id: I1a5c5be290437b6087cb57c63d9ea10826667f19
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/52/68352/2 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/storage/mongodb/claims.py', 'marconi/queues/storage/__init__.py', 'marconi/tests/queues/storage/base.py', 'marconi/queues/transport/wsgi/v1.py', 'marconi/queues/storage/sqlite/queues.py', 'marconi/queues/storage/mongodb/queues.py', 'marconi/tests/faulty_storage.py', 'marconi/queues/transport/wsgi/public/driver.py', 'marconi/queues/storage/sqlite/messages.py', 'marconi/queues/storage/sqlite/claims.py', 'marconi/queues/storage/mongodb/messages.py', 'marconi/queues/storage/base.py']",12,3ae03ccc6d6a097d7a5ed4441b0b912be2b05225,1237747,class Queue(ControllerBase):class Message(ControllerBase):class Claim(ControllerBase):,class QueueBase(ControllerBase):class MessageBase(ControllerBase):class ClaimBase(ControllerBase):,19,19
openstack%2Ffuel-main~master~I7b18129b75c52ee1ea0b80c2419f95e87667cfb7,openstack/fuel-main,master,I7b18129b75c52ee1ea0b80c2419f95e87667cfb7,Cold restart for HA environment,MERGED,2013-12-30 12:13:41.000000000,2014-01-31 22:50:18.000000000,2014-01-31 22:50:18.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8767}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10017}]","[{'number': 1, 'created': '2013-12-30 12:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6468123eed5753f11e8ede51a6449940ff7bb854', 'message': 'Cold restart for HA environment\n\nThere were warm restart tests so far.\nIt renames restart_nodes method to warm_restart_nodes\nand adds real cold restart to HA test\n\nChange-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7\n'}, {'number': 2, 'created': '2014-01-14 11:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9eeb4cb110de588f9d2b8c3784dd8a547bef2b2f', 'message': 'Cold restart for HA environment\n\n* There were warm restart tests so far.\nIt renames restart_nodes method to warm_restart_nodes\nand adds real cold restart to HA test\n* Move warm / cold restart tests to seperate file\n\nChange-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7\n'}, {'number': 3, 'created': '2014-01-14 14:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4343376a7cedbb63748982049ed0f177086cce75', 'message': 'Cold restart for HA environment\n\n* There were warm restart tests so far.\nIt renames restart_nodes method to warm_restart_nodes\nand adds real cold restart to HA test\n* Move warm / cold restart tests to seperate package.\nSo that all new non-functional tests (for HA mode\nin most cases) will be stored there.\n\nChange-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7\n'}, {'number': 4, 'created': '2014-01-14 14:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/147b76a63d9ed911781b6f6dbcbfbf177b137158', 'message': 'Cold restart for HA environment\n\n* There were warm restart tests so far.\nIt renames restart_nodes method to warm_restart_nodes\nand adds real cold restart to HA test\n* Move warm / cold restart tests to seperate package.\nSo that all new non-functional tests (for HA mode\nin most cases) will be stored there.\n\nChange-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7\n'}, {'number': 5, 'created': '2014-01-31 22:48:54.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_ceph.py', 'fuelweb_test/tests_strength/__init__.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests_strength/test_restart.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cb36a45a6148f742665f4b0b426d69350a5f2243', 'message': 'Cold restart for HA environment\n\n* There were warm restart tests so far.\nIt renames restart_nodes method to warm_restart_nodes\nand adds real cold restart to HA test\n* Move warm / cold restart tests to seperate package.\nSo that all new non-functional tests (for HA mode\nin most cases) will be stored there.\n\nChange-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7\n'}]",0,64431,cb36a45a6148f742665f4b0b426d69350a5f2243,27,8,5,8767,,,0,"Cold restart for HA environment

* There were warm restart tests so far.
It renames restart_nodes method to warm_restart_nodes
and adds real cold restart to HA test
* Move warm / cold restart tests to seperate package.
So that all new non-functional tests (for HA mode
in most cases) will be stored there.

Change-Id: I7b18129b75c52ee1ea0b80c2419f95e87667cfb7
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/31/64431/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_ceph.py', 'fuelweb_test/tests/test_simple.py']",3,6468123eed5753f11e8ede51a6449940ff7bb854,sys-tests-warm-cold-restart-patch1, def simple_flat_warm_restart(self): 9. Warm restart 10. Run OSTF # Warm restart self.fuel_web.warm_restart_nodes(self.env.nodes().slaves[:2]), def simple_flat_cold_restart(self): self.fuel_web.restart_nodes(self.env.nodes().slaves[:2]),26,6
openstack%2Fzaqar~master~I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5,openstack/zaqar,master,I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5,WIP: fix(wsgi): Cleanup limit config options,ABANDONED,2014-01-17 22:57:24.000000000,2014-01-31 22:38:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}]","[{'number': 1, 'created': '2014-01-17 22:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c257317b828605c767122392e97cf9849b22fd10', 'message': 'fix(wsgi): Removed duplicate, YAGNI config options for max doc sizes\n\nThis patch removes a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\nAlso, the check on the size of a create claim request was removed\nsince it is not part of the API spec, and sanity-checks like that\nare best done by the web server, before it even touches the app.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 2, 'created': '2014-01-20 20:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/543531519a84b54cb06bf7a7c3374e6588479fda', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 3, 'created': '2014-01-22 17:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c079a3a5823a98ae1af893c8caa46da4eddac903', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 4, 'created': '2014-01-23 21:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0bdc96a57b4c3bc4a7007fce1e8ea98a29f66109', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 5, 'created': '2014-01-28 22:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/40af2839788d4ad0573f6b6d9da4abdfad8d54f5', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 6, 'created': '2014-01-30 17:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6f9ba50a841eb69a39d33d4a5cf94ff5fc1d3f2e', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 7, 'created': '2014-01-30 22:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1fe881098fbf06db17bbcfcef66615ec47c6c3d5', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 8, 'created': '2014-01-30 22:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fb0e78b2fd111d54059b4fa81654d83b5e5bfb59', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 9, 'created': '2014-01-30 22:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/701ca6194cae3b249b36991d311e1012c2b885c3', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 10, 'created': '2014-01-30 22:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/db44f4026ed720c74c91c34b7d5d61f5cdb439e7', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 11, 'created': '2014-01-30 22:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a32091c9b23d4ef81326aef59d39502ffc326301', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 12, 'created': '2014-01-30 23:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c21960d66170508c6c433a16e28d2c6e10b1be99', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 13, 'created': '2014-01-30 23:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5407e27a68517d2eb874f492dd491e9bda5774e3', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 14, 'created': '2014-01-30 23:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/38cff2045d49d3a95e9b62199e6cd76da5160ff2', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 15, 'created': '2014-01-31 00:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ed159932582fb473263ef59b83d83eb14c426611', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 16, 'created': '2014-01-31 00:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0d0200031b7c4f319b8f6595679aabd739b7b428', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 17, 'created': '2014-01-31 00:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/21ff2e3134019a07f3feec2119cc7e0a5cf86e70', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 18, 'created': '2014-01-31 00:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ef3bb80bfdb8723ea8c877ae976eb5a5738474ae', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 19, 'created': '2014-01-31 00:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/857a684b73f1b6aafc9543f0a6ccafe72559b172', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 20, 'created': '2014-01-31 01:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e6cc40e3166e92643a84a2972b444211b793e977', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 21, 'created': '2014-01-31 01:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d23a7284bea7159aeae96097f4e519d6359fa627', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 22, 'created': '2014-01-31 15:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c3cdbc25b6c8ad8f3f2fda394f18f1a1b2450364', 'message': 'fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 23, 'created': '2014-01-31 15:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d236bcaad140a4ebe0ac78e37c39ccd9df909c6e', 'message': 'WIP: fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 24, 'created': '2014-01-31 22:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bef9d6ba21443bba9b3ca9cc2e7a6890ac503a1c', 'message': 'WIP: fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}, {'number': 25, 'created': '2014-01-31 22:35:35.000000000', 'files': ['tests/unit/queues/transport/wsgi/test_claims.py', 'marconi/queues/storage/sharding.py', 'marconi/queues/api/v1/response.py', 'marconi/queues/transport/wsgi/claims.py', 'marconi/queues/transport/wsgi/driver.py', 'tests/etc/functional-marconi.conf', 'marconi/queues/storage/sqlite/queues.py', 'marconi/queues/storage/mongodb/queues.py', 'tests/unit/queues/transport/wsgi/base.py', 'tests/functional/wsgi/v1/test_messages.py', 'marconi/queues/storage/base.py', 'marconi/tests/functional/base.py', 'tests/unit/queues/transport/wsgi/test_messages.py', 'tests/functional/wsgi/v1/test_claims.py', 'marconi/queues/storage/mongodb/claims.py', 'etc/marconi.conf-sample', 'marconi/queues/storage/__init__.py', 'tests/unit/queues/transport/wsgi/wsgi/test_default_limits.py', 'tests/functional/wsgi/v1/test_queues.py', 'marconi/queues/transport/validation.py', 'tests/unit/queues/transport/wsgi/test_queue_lifecycle.py', 'tests/unit/queues/transport/wsgi/test_validation.py', 'tests/etc/wsgi_sqlite_default_limits.conf', 'marconi/queues/storage/sqlite/messages.py', 'marconi/queues/storage/sqlite/claims.py', 'marconi/queues/storage/mongodb/messages.py', 'tests/etc/wsgi_sqlite_validation.conf'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cd7b739030efbd623a1d91c10dde4fbc3931c60b', 'message': 'WIP: fix(wsgi): Cleanup limit config options\n\nThis patch contains several misc. changes to queue, message, and\nclaim limits to reduce confusion and bring the implementation in\nline with the v1 spec.\n\n1. Removed a couple of WSGI driver config options that are\nno longer needed now that we have redefined (and simplified) how\nwe constrain message and metadata size.\n\n    metadata_max_length = 65536\n    content_max_length = 262144\n\n2. Renamed options to be more readable and consistent\n3. Moved options to [transport] section\n4. Made max messages that can be claimed its own setting, to reduce confusion\n5. Removed enforcing an upper limit on the number of messages that can be\nposted; this was never in the spec, and appears to be gold-plating. Now, the\nonly upper limit is max_message_size.\n6. Removed the check on the size of a create claim request since (1) it is\nnot part of the API spec, and (2) sanity-checks like that are best done by\nthe web server, before a request even touches the app.\n7. Migrated limits for storage driver interface params to static values,\nsince those defaults define the static contract between transport and\nstorage drivers.\n8. Wrapped validation error messages in gettextutils._, and converted them\nto use .format instead of %.\n\nChange-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5\nCloses-Bug: #1270260\n'}]",1,67597,cd7b739030efbd623a1d91c10dde4fbc3931c60b,54,3,25,6427,,,0,"WIP: fix(wsgi): Cleanup limit config options

This patch contains several misc. changes to queue, message, and
claim limits to reduce confusion and bring the implementation in
line with the v1 spec.

1. Removed a couple of WSGI driver config options that are
no longer needed now that we have redefined (and simplified) how
we constrain message and metadata size.

    metadata_max_length = 65536
    content_max_length = 262144

2. Renamed options to be more readable and consistent
3. Moved options to [transport] section
4. Made max messages that can be claimed its own setting, to reduce confusion
5. Removed enforcing an upper limit on the number of messages that can be
posted; this was never in the spec, and appears to be gold-plating. Now, the
only upper limit is max_message_size.
6. Removed the check on the size of a create claim request since (1) it is
not part of the API spec, and (2) sanity-checks like that are best done by
the web server, before a request even touches the app.
7. Migrated limits for storage driver interface params to static values,
since those defaults define the static contract between transport and
storage drivers.
8. Wrapped validation error messages in gettextutils._, and converted them
to use .format instead of %.

Change-Id: I5f8e7ad649ddd29b91b459bd6fe5280de47d8ad5
Closes-Bug: #1270260
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/97/67597/24 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/queues/transport/wsgi/test_claims.py', 'tests/unit/queues/transport/wsgi/test_messages.py', 'tests/unit/queues/transport/wsgi/test_queue_lifecycle.py', 'tests/unit/queues/transport/wsgi/base.py', 'etc/marconi.conf-sample', 'marconi/queues/transport/wsgi/claims.py', 'marconi/queues/transport/wsgi/driver.py', 'tests/etc/functional-marconi.conf']",8,c257317b828605c767122392e97cf9849b22fd10,bug/1270260,# Maximum size in bytes allowed for queue metadata and bulk/single # message post bodies (including whitespace and envelope fields).,# Maximum Content-Length allowed for metadata updating and # message posting. ;metadata_max_length = 65536 ;content_max_length = 262144 # Maximum compact-JSON (without whitespace) size in bytes allowed # for each metadata body and each message body,27,50
openstack%2Fsahara~master~Iec7a5f4d70c650af8908e5be27fcbe7e6e5b76cf,openstack/sahara,master,Iec7a5f4d70c650af8908e5be27fcbe7e6e5b76cf,Added more strict check for heat stack statuses,MERGED,2014-01-27 13:04:08.000000000,2014-01-31 22:32:11.000000000,2014-01-31 22:32:11.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7555}, {'_account_id': 7700}, {'_account_id': 7710}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-27 13:04:08.000000000', 'files': ['savanna/exceptions.py', 'savanna/tests/unit/utils/test_heat.py', 'savanna/utils/openstack/heat.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4069d491bd8bc4d320976bcb3b5e59a9e75df81a', 'message': 'Added more strict check for heat stack statuses\n\n* Disabled automatic heat stack rollback. This was triggred before if some\n  unexpected issue occurred during stack create/update. So now stack\n  never goes to ROLLBACK state.\n* Checked only CREATE_IN_PROGRESS, UPDATE_IN_PROGRESS, CREATE_COMPLETE\n  and UPDATE_COMPLETE stack statuses which considered as valid states.\n  Others states considered as unexpected and special HeatStackException\n  raises.\n* Also replaced wrong time.sleep to context.sleep\n\nCloses-Bug: #1261725\nChange-Id: Iec7a5f4d70c650af8908e5be27fcbe7e6e5b76cf\n'}]",2,69360,4069d491bd8bc4d320976bcb3b5e59a9e75df81a,14,11,1,7125,,,0,"Added more strict check for heat stack statuses

* Disabled automatic heat stack rollback. This was triggred before if some
  unexpected issue occurred during stack create/update. So now stack
  never goes to ROLLBACK state.
* Checked only CREATE_IN_PROGRESS, UPDATE_IN_PROGRESS, CREATE_COMPLETE
  and UPDATE_COMPLETE stack statuses which considered as valid states.
  Others states considered as unexpected and special HeatStackException
  raises.
* Also replaced wrong time.sleep to context.sleep

Closes-Bug: #1261725
Change-Id: Iec7a5f4d70c650af8908e5be27fcbe7e6e5b76cf
",git fetch https://review.opendev.org/openstack/sahara refs/changes/60/69360/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/exceptions.py', 'savanna/tests/unit/utils/test_heat.py', 'savanna/utils/openstack/heat.py']",3,4069d491bd8bc4d320976bcb3b5e59a9e75df81a,bug/1261725,"from savanna import exceptions as ex 'disable_rollback': True, while self.heat_stack.stack_status in ('CREATE_IN_PROGRESS', 'UPDATE_IN_PROGRESS'): context.sleep(1) if self.heat_stack.stack_status not in ('CREATE_COMPLETE', 'UPDATE_COMPLETE'): raise ex.HeatStackException(self.heat_stack.stack_status) ","import time 'disable_rollback': False, while self.heat_stack.stack_status not in \ ('CREATE_COMPLETE', 'UPDATE_COMPLETE'): time.sleep(1)",45,5
openstack%2Foperations-guide~master~I0806e36574eb753b1b705db4f3a080e4bbeac9e5,openstack/operations-guide,master,I0806e36574eb753b1b705db4f3a080e4bbeac9e5,Address editors comments on Chapter Scaling,MERGED,2014-01-24 16:36:59.000000000,2014-01-31 22:30:31.000000000,2014-01-31 22:30:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-01-24 16:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/e76fd5ee5090f27dbe46b826850dee5590184613', 'message': 'Address editors comments on Chapter Scaling\n\nWIP\n\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}, {'number': 2, 'created': '2014-01-24 16:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/c36c7e386c9e5bc91fe8991ffbf5691c75b1c8e5', 'message': 'Address editors comments on Chapter Scaling\n\n* rework intro to mention types of scaling\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}, {'number': 3, 'created': '2014-01-24 18:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/83566d6fbe8cc79f727aedde589cdd8e265c57a2', 'message': 'Address editors comments on Chapter Scaling\n\n* rework intro to mention types of scaling\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}, {'number': 4, 'created': '2014-01-27 08:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/9242e2eb45c7a661e99ed45516eccb734634230e', 'message': 'Address editors comments on Chapter Scaling\n\n* rework intro to mention types of scaling\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}, {'number': 5, 'created': '2014-01-28 23:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/99690ccfee56aa94672819b97d33d007c34286d1', 'message': 'Address editors comments on Chapter Scaling\n\n* rework intro to mention types of scaling\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}, {'number': 6, 'created': '2014-01-31 22:25:13.000000000', 'files': ['doc/openstack-ops/ch_arch_scaling.xml', 'doc/openstack-ops/ch_ops_maintenance.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/a2bb17d758bd3b0faf5f40f0ad2c72bf5c11af0c', 'message': 'Address editors comments on Chapter Scaling\n\n* rework intro to mention types of scaling\n* bullet out ratios\n\nChange-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5\n'}]",2,68960,a2bb17d758bd3b0faf5f40f0ad2c72bf5c11af0c,20,5,6,612,,,0,"Address editors comments on Chapter Scaling

* rework intro to mention types of scaling
* bullet out ratios

Change-Id: I0806e36574eb753b1b705db4f3a080e4bbeac9e5
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/60/68960/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_arch_scaling.xml'],1,e76fd5ee5090f27dbe46b826850dee5590184613,banderson-scaling," about: <itemizedlist> <listitem><para> the number of virtual machines (VMs) you expect to run <code>((overcommit fraction  cores) / virtual cores per instance)</code>,</para></listitem> <listitem><para> how much storage is required <code>(flavor disk size  number of instances)</code>.</para></listitem> </itemizedlist>"," about the number of virtual machines (VMs) you expect to run <code>((overcommit fraction  cores) / virtual cores per instance)</code>, how much storage is required <code>(flavor disk size  number of instances)</code>.",6,4
openstack%2Fironic~master~I12157f9e420d401215ca23f95773238d7c8151df,openstack/ironic,master,I12157f9e420d401215ca23f95773238d7c8151df,Remove net_config_template options,MERGED,2014-01-30 15:29:58.000000000,2014-01-31 22:28:06.000000000,2014-01-31 22:28:06.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-01-30 15:29:58.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc6ea485ae34e65b155c0c7769ceadf07b3b3f36', 'message': 'Remove net_config_template options\n\nThis is no longer used, and the template is no longer\navailable in the code.\n\nChange-Id: I12157f9e420d401215ca23f95773238d7c8151df\n'}]",0,70141,bc6ea485ae34e65b155c0c7769ceadf07b3b3f36,7,4,1,1726,,,0,"Remove net_config_template options

This is no longer used, and the template is no longer
available in the code.

Change-Id: I12157f9e420d401215ca23f95773238d7c8151df
",git fetch https://review.opendev.org/openstack/ironic refs/changes/41/70141/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/pxe.py']",2,bc6ea485ae34e65b155c0c7769ceadf07b3b3f36,no_dhcp_template,," cfg.StrOpt('net_config_template', default=paths.basedir_def('ironic/net-dhcp.ubuntu.template'), help='Template file for injected network config'),",0,6
openstack%2Ffuel-library~master~I4a83b4dc81da5991d449f69e4c76ee0309e89205,openstack/fuel-library,master,I4a83b4dc81da5991d449f69e4c76ee0309e89205,Add puppet-pull helper script,MERGED,2013-12-24 16:41:56.000000000,2014-01-31 22:25:42.000000000,2014-01-31 22:25:42.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2013-12-24 16:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1273268e4ef4d5c9c585559ad4705c366af531d7', 'message': 'Add puppet-pull helper script\n\nIt allows users to sync manifests and run puppet directly\nfrom managed node without touching anything else.\n\nIt could be very usefull for debugging.\n\nChange-Id: I4a83b4dc81da5991d449f69e4c76ee0309e89205\n'}, {'number': 2, 'created': '2014-01-16 09:09:19.000000000', 'files': ['deployment/puppet/puppet/templates/puppet-pull.sh.erb', 'deployment/puppet/osnailyfacter/examples/site.pp', 'deployment/puppet/puppet/manifests/pull.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bff85fce0a628ef0757bb5a914f3d2b9964fd792', 'message': 'Add puppet-pull helper script\n\nIt allows users to sync manifests and run puppet directly\nfrom managed node without touching anything else.\nJust run puppet-pull on any managed node and it will\ndownload latest manifests from the master node and\nrun puppet to apply them.\n\nIt could be very usefull for debugging.\n\nChange-Id: I4a83b4dc81da5991d449f69e4c76ee0309e89205\n'}]",4,63950,bff85fce0a628ef0757bb5a914f3d2b9964fd792,26,6,2,9037,,,0,"Add puppet-pull helper script

It allows users to sync manifests and run puppet directly
from managed node without touching anything else.
Just run puppet-pull on any managed node and it will
download latest manifests from the master node and
run puppet to apply them.

It could be very usefull for debugging.

Change-Id: I4a83b4dc81da5991d449f69e4c76ee0309e89205
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/50/63950/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/puppet/templates/puppet-pull.sh.erb', 'deployment/puppet/osnailyfacter/examples/site.pp', 'deployment/puppet/puppet/manifests/pull.pp']",3,1273268e4ef4d5c9c585559ad4705c366af531d7,puppet_pull,"class puppet::pull ( $master_ip = '10.20.0.2', $script = '/usr/local/bin/puppet-pull', $template = 'puppet/puppet-pull.sh.erb', ) { file { $script : ensure => present, mode => '0755', owner => 'root', group => 'root', content => template($template), } } ",,30,0
openstack%2Fironic~master~Ib9feefc3bc1cbf300a48a3824586509947eacfd6,openstack/ironic,master,Ib9feefc3bc1cbf300a48a3824586509947eacfd6,Fix ssh_port type in _parse_driver_info() from ssh.py,MERGED,2014-01-31 12:34:35.000000000,2014-01-31 22:24:24.000000000,2014-01-31 22:24:24.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8003}, {'_account_id': 8412}]","[{'number': 1, 'created': '2014-01-31 12:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e091687de47844171bb8b8b020c3830e20468de', 'message': 'Fix ssh_port type in _parse_driver_info() from ssh.py\n\nssh_port should be integer, so performing type conversion to integer\n\nChange-Id: Ib9feefc3bc1cbf300a48a3824586509947eacfd6\n'}, {'number': 2, 'created': '2014-01-31 13:04:04.000000000', 'files': ['ironic/tests/drivers/test_ssh.py', 'ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a50ec2be6d48a4dfa3311b2bfc456f431b72545c', 'message': 'Fix ssh_port type in _parse_driver_info() from ssh.py\n\nssh_port should be integer, so performing type conversion to integer\n\nChange-Id: Ib9feefc3bc1cbf300a48a3824586509947eacfd6\n'}]",3,70336,a50ec2be6d48a4dfa3311b2bfc456f431b72545c,15,7,2,8003,,,0,"Fix ssh_port type in _parse_driver_info() from ssh.py

ssh_port should be integer, so performing type conversion to integer

Change-Id: Ib9feefc3bc1cbf300a48a3824586509947eacfd6
",git fetch https://review.opendev.org/openstack/ironic refs/changes/36/70336/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/test_ssh.py', 'ironic/drivers/modules/ssh.py']",2,1e091687de47844171bb8b8b020c3830e20468de,," try: port = int(info.get('ssh_port', 22)) except ValueError: raise exception.InvalidParameterValue(_( ""SSHPowerDriver requires ssh_port to be integer value""))"," port = info.get('ssh_port', 22)",18,1
openstack%2Foperations-guide~master~I887dc10c0efda14cd322777b44c141880522623c,openstack/operations-guide,master,I887dc10c0efda14cd322777b44c141880522623c,Add a new story by Felix Lee,MERGED,2014-01-23 18:50:07.000000000,2014-01-31 22:23:24.000000000,2014-01-31 22:23:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 6859}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-01-23 18:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/bbdb4d45f091fac94b7296427523b3ae029b0972', 'message': ""Add a new story by Felix Lee\n\nNote: I do not yet have Felix's permission to add this, please don't\napprove until we get his OK.\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n""}, {'number': 2, 'created': '2014-01-23 19:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/48de0f78a7380ae93f195d83cc91bd779af5b182', 'message': ""Add a new story by Felix Lee\n\nNote: I do not yet have Felix's permission to add this, please don't\napprove until we get his OK.\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n""}, {'number': 3, 'created': '2014-01-23 21:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/b26cfb97bd402d01baf38d35cab0dd82f0d833ef', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 4, 'created': '2014-01-24 14:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ffb3255a664f39b8f24a61fae482914a37abdfcb', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 5, 'created': '2014-01-28 22:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/066b9ebb9f8d0284fe8df69c788bff8f6e0b3512', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 6, 'created': '2014-01-29 19:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6407df4c7a8653e79e5dff6d27752fb6707f0454', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 7, 'created': '2014-01-29 20:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6fc470b38b1618d403f62342662e5de85222bc31', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 8, 'created': '2014-01-29 20:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/aefbca511e24fab6160c3527c8e3581dd1f54267', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 9, 'created': '2014-01-31 00:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/a6d7a5bd3bbba8bfff8af8bf19ae2eb23bab00e4', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}, {'number': 10, 'created': '2014-01-31 15:26:29.000000000', 'files': ['doc/openstack-ops/app_crypt.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/bca2f54ecfd6076d89e89e409179937d9e662404', 'message': 'Add a new story by Felix Lee\n\nThis adds a new story to tales from the crypt, about an experience\nupgrading from Grizzly to Havana on a decent sized cloud.\n\nChange-Id: I887dc10c0efda14cd322777b44c141880522623c\n'}]",46,68721,bca2f54ecfd6076d89e89e409179937d9e662404,44,7,10,612,,,0,"Add a new story by Felix Lee

This adds a new story to tales from the crypt, about an experience
upgrading from Grizzly to Havana on a decent sized cloud.

Change-Id: I887dc10c0efda14cd322777b44c141880522623c
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/21/68721/9 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/app_crypt.xml'],1,bbdb4d45f091fac94b7296427523b3ae029b0972,app-crypt," <section xml:id=""millllions""> <title>Milllllions of upgrade pain</title> <para>This story is contributed by Felix Lee, of Academica Sinica Grid Computing Centre in Taiwan</para> <para>I had just upgraded Openstack from Grizzy to Havana (2013.2-2, from RDO repository), and everything was running pretty well. Except the EC2 API. I noticed that the EC2 API would suffer from heavy load and respond slowly to particular ec2 requests, such as <literal>RunInstances</literal>, for instance: <programlisting> 2014-01-10 09:11:45.072 129745 INFO nova.ec2.wsgi.server [req-84d16d16-3808-426b-b7af-3b90a11b83b0 0c6e7dba03c24c6a9bce299747499e8a 7052bd6714e7460caeb16242e68124f9] 117.103.103.29 ""GET /services/Cloud?AWSAccessKeyId=<something>&amp;Action=RunInstances&amp;ClientToken=<something>&amp;ImageId=ami-00000001&amp;InstanceInitiatedShutdownBehavior=terminate&InstanceType=m8.pilot&MaxCount=1&MinCount=1&SecurityGroup.2=gridWN&SignatureMethod=HmacSHA256&SignatureVersion=2&Timestamp=2014-01-10T09%3A09%3A26Z&UserData=<something>&Version=2014-10-01&amp;Signature=Nxs8cRDvcyHikmyOKwbut0U6DTSfBxZpAGbwLjymQBs%3D HTTP/1.1"" status: 200 len: 1109 time: 138.5970151 </programlisting> </para> <para>It took over 2 minutes to process this request, but in another co-existing Grizzy instance using the same hardware and system configuration), there was no such problem. <programlisting> 2014-01-08 11:15:15.704 INFO nova.ec2.wsgi.server [req-ccac9790-3357-4aa8-84bd-cdaab1aa394e ebbd729575cb404081a45c9ada0849b7 8175953c209044358ab5e0ec19d52c37] 117.103.103.29 ""GET /services/Cloud?AWSAccessKeyId=<something>&amp;Action=RunInstances&amp;ClientToken=<something>&amp;ImageId=ami-00000007&amp;InstanceInitiatedShutdownBehavior=terminate&InstanceType=m1.large&MaxCount=1&MinCount=1&SecurityGroup.2=amsWN&SignatureMethod=HmacSHA256&SignatureVersion=2&Timestamp=2014-01-08T11%3A15%3A11Z&UserData=<something>%3D%3D&Version=2012-10-01&amp;Signature=uQ%2Bipw9buWTflC83tI76%2B9%2F66Bj8I%2FF8ChUUfEmK2v4%3D HTTP/1.1"" status: 200 len: 931 time: 3.9426181 </programlisting> </para> <para> Besides, the seemed to me that the EC2 API didn't not release memory (or didn't manage it in a good way ...) properly while processing such requests, so, if it receives many requests, the memory usage grows pretty fast until all of the system memory is consumed and goes to swap. Then, the entire system will be running like hell until I restart nova-api (I have 48GB memory, and it can eat all of it in minutes). So, I found myself wondering what changes were made for EC2 API in Havana and is there anyway to improve this if that is not a bug? </para> <para> Well, after posting on the mailing list, I kind of solve this problem myself. After I looked into the code, I noticed there are two matters which will impact on my system: <programlisting language=""python""> instances = self.compute_api.get_all(context, search_opts=search_opts, sort_dir='asc') sys_metas = self.compute_api.get_all_system_metadata( context, search_filts=[{'key': ['EC2_client_token']}, {'value': [client_token]}]) </programlisting> </para> <para>Since my database had a lot of records (over 1 million metadata, and over 300,000 deleted, errored instances.., yes, we have a lot of short term VMs...) each search takes ages. After I archive those old records and delete them, now, it's better. </para> </section>",,56,0
openstack%2Foperations-guide~master~I89b049d84c0f8b91a0f8a9a3f00b836820c6607a,openstack/operations-guide,master,I89b049d84c0f8b91a0f8a9a3f00b836820c6607a,cleanup of Openstack Operations app-roadmaps,MERGED,2014-01-31 20:01:20.000000000,2014-01-31 22:22:40.000000000,2014-01-31 22:22:40.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 20:01:20.000000000', 'files': ['doc/openstack-ops/app_roadmaps.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/f6ddfbc3b03d75e90491343215cc4911b75eacb5', 'message': 'cleanup of Openstack Operations app-roadmaps\n\ndesired to desire - not past tense\ndeafult changed to default - spell correction\nanalyses to analyzes - typo\n\nChange-Id: I89b049d84c0f8b91a0f8a9a3f00b836820c6607a\n'}]",0,70423,f6ddfbc3b03d75e90491343215cc4911b75eacb5,6,3,1,9382,,,0,"cleanup of Openstack Operations app-roadmaps

desired to desire - not past tense
deafult changed to default - spell correction
analyses to analyzes - typo

Change-Id: I89b049d84c0f8b91a0f8a9a3f00b836820c6607a
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/23/70423/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/app_roadmaps.xml'],1,f6ddfbc3b03d75e90491343215cc4911b75eacb5,apps_roadmap," you desire.</para> details of your deployments and needs, anonymously by default. Each cycle, the user committee analyzes the results and produces a"," you desired.</para> details of your deployments and needs, anonymously by deafult. Each cycle, the user committee analyses the results and produces a",3,3
openstack%2Ffuel-library~master~Ic31edfd957b58c82c13f57c8d06122f52e01c2ab,openstack/fuel-library,master,Ic31edfd957b58c82c13f57c8d06122f52e01c2ab,Install QLogic and Brocade firmware on CentOS,MERGED,2014-01-16 15:38:42.000000000,2014-01-31 22:21:29.000000000,2014-01-31 22:21:28.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8787}, {'_account_id': 8865}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-16 15:38:42.000000000', 'files': ['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6c8b19a86d943c60d807fc4b1f8546836c78ff12', 'message': 'Install QLogic and Brocade firmware on CentOS\n\nChange-Id: Ic31edfd957b58c82c13f57c8d06122f52e01c2ab\nRelated-bug: #1260492\n'}]",0,67192,6c8b19a86d943c60d807fc4b1f8546836c78ff12,10,5,1,8786,,,0,"Install QLogic and Brocade firmware on CentOS

Change-Id: Ic31edfd957b58c82c13f57c8d06122f52e01c2ab
Related-bug: #1260492
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/92/67192/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'],1,6c8b19a86d943c60d807fc4b1f8546836c78ff12,,bfa-firmware ql2100-firmware ql2200-firmware ql23xx-firmware ql2400-firmware ql2500-firmware,,6,0
openstack%2Foperations-guide~master~If228328d32784866e3e2e8483f71373078fb8a5c,openstack/operations-guide,master,If228328d32784866e3e2e8483f71373078fb8a5c,Cleanup of app_usecases.xml file,MERGED,2014-01-31 20:12:04.000000000,2014-01-31 22:20:33.000000000,2014-01-31 22:20:33.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 20:12:04.000000000', 'files': ['doc/openstack-ops/app_usecases.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/0d424f4170e2009b68a67969b3f83fa94317b4d0', 'message': 'Cleanup of app_usecases.xml file\n\nto to written duplicate - changed to do\nIP Address changed to plural\ncenters to centers\nadded hyphen to backending\n\nChange-Id: If228328d32784866e3e2e8483f71373078fb8a5c\n'}]",0,70427,0d424f4170e2009b68a67969b3f83fa94317b4d0,6,3,1,9382,,,0,"Cleanup of app_usecases.xml file

to to written duplicate - changed to do
IP Address changed to plural
centers to centers
added hyphen to backending

Change-Id: If228328d32784866e3e2e8483f71373078fb8a5c
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/27/70427/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/app_usecases.xml'],1,0d424f4170e2009b68a67969b3f83fa94317b4d0,app_usecases, shared file system and some use on compute node iSCSI storage back-ending the image storage and traffic bottleneck. We are able to do this because we have IP addresses. We provide a single generic public network to <para>DAIR is hosted at two different data centers across, shared file system and some use on compute node iSCSI storage backending the image storage and traffic bottleneck. We are able to to this because we have IP address. We provide a single generic public network to <para>DAIR is hosted at two different data centres across,5,5
openstack%2Ftrove-integration~master~Iccc0ccbdd8b832af1876fc8f3a32cbfb74130839,openstack/trove-integration,master,Iccc0ccbdd8b832af1876fc8f3a32cbfb74130839,Fixed retrieve_token function to use KEYSTONE_AUTH_HOST,MERGED,2014-01-31 21:55:56.000000000,2014-01-31 22:14:37.000000000,2014-01-31 22:14:37.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 7092}]","[{'number': 1, 'created': '2014-01-31 21:55:56.000000000', 'files': ['scripts/functions'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/8ddaa004ec9cc74722567b87a76b52c48a482a62', 'message': 'Fixed retrieve_token function to use KEYSTONE_AUTH_HOST\n\nThe function was using localhost, and the keystone-admin service\nmight only be bound to the KEYSTONE_AUTH_HOST IP.\n\nChange-Id: Iccc0ccbdd8b832af1876fc8f3a32cbfb74130839\n'}]",0,70451,8ddaa004ec9cc74722567b87a76b52c48a482a62,6,3,1,5293,,,0,"Fixed retrieve_token function to use KEYSTONE_AUTH_HOST

The function was using localhost, and the keystone-admin service
might only be bound to the KEYSTONE_AUTH_HOST IP.

Change-Id: Iccc0ccbdd8b832af1876fc8f3a32cbfb74130839
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/51/70451/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/functions'],1,8ddaa004ec9cc74722567b87a76b52c48a482a62,bug/fix_keystone_auth_host," -H ""Content-type: application/json"" http://$KEYSTONE_AUTH_HOST:35357/v2.0/tokens | python -c 'import json, sys; print json.loads(""\n"".join(sys.stdin))[""access""][""token""][""tenant""][""id""]'"," -H ""Content-type: application/json"" http://localhost:35357/v2.0/tokens | python -c 'import json, sys; print json.loads(""\n"".join(sys.stdin))[""access""][""token""][""tenant""][""id""]'",1,1
openstack%2Foslo-incubator~master~I41c5579f922dec6c7ca560a7898483841f9af6ef,openstack/oslo-incubator,master,I41c5579f922dec6c7ca560a7898483841f9af6ef,Update oslo log messages with translation domains,ABANDONED,2014-01-08 19:41:11.000000000,2014-01-31 22:08:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 3108}, {'_account_id': 6722}, {'_account_id': 7996}]","[{'number': 1, 'created': '2014-01-08 19:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7ae1c4b444ced0b6093a1f27926807348248b7ce', 'message': 'Update oslo log messages with translation domains\n\nUpdate the incubator code to use different domains for log\nmessages at different levels.\n\nbp log-messages-translation-domain\n\nChange-Id: I41c5579f922dec6c7ca560a7898483841f9af6ef\n'}, {'number': 2, 'created': '2014-01-13 17:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/eaa2faa2bbc97938f6e454a10283e93a6f192b9f', 'message': 'Update oslo log messages with translation domains\n\nUpdate the incubator code to use different domains for log\nmessages at different levels.\n\nUpdate the import exceptions setting for hacking to allow\nmultiple functions to be imported from gettextutils on one\nline.\n\nbp log-messages-translation-domain\n\nChange-Id: I41c5579f922dec6c7ca560a7898483841f9af6ef\n'}, {'number': 3, 'created': '2014-01-13 17:51:22.000000000', 'files': ['openstack/common/fileutils.py', 'openstack/common/rpc/matchmaker_ring.py', 'openstack/common/rpc/impl_kombu.py', 'openstack/common/service.py', 'openstack/common/rpc/amqp.py', 'openstack/common/notifier/api.py', 'openstack/common/processutils.py', 'openstack/common/db/sqlalchemy/session.py', 'openstack/common/quota.py', 'openstack/common/rpc/matchmaker.py', 'openstack/common/rpc/impl_qpid.py', 'openstack/common/excutils.py', 'openstack/common/lockutils.py', 'openstack/common/notifier/rpc_notifier2.py', 'openstack/common/db/sqlalchemy/utils.py', 'openstack/common/loopingcall.py', 'openstack/common/rpc/service.py', 'openstack/common/scheduler/filters/ignore_attempted_hosts_filter.py', 'openstack/common/eventlet_backdoor.py', 'openstack/common/notifier/rpc_notifier.py', 'openstack/common/policy.py', 'openstack/common/middleware/notifier.py', 'openstack/common/scheduler/filters/capabilities_filter.py', 'openstack/common/rpc/common.py', 'openstack/common/rpc/impl_zmq.py', 'openstack/common/periodic_task.py', 'tox.ini', 'openstack/common/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cf4250c094d51d706d8c7c4109a28247b1ff072a', 'message': 'Update oslo log messages with translation domains\n\nUpdate the incubator code to use different domains for log\nmessages at different levels.\n\nUpdate the import exceptions setting for hacking to allow\nmultiple functions to be imported from gettextutils on one\nline.\n\nbp log-messages-translation-domain\n\nChange-Id: I41c5579f922dec6c7ca560a7898483841f9af6ef\n'}]",0,65519,cf4250c094d51d706d8c7c4109a28247b1ff072a,11,5,3,2472,,,0,"Update oslo log messages with translation domains

Update the incubator code to use different domains for log
messages at different levels.

Update the import exceptions setting for hacking to allow
multiple functions to be imported from gettextutils on one
line.

bp log-messages-translation-domain

Change-Id: I41c5579f922dec6c7ca560a7898483841f9af6ef
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/19/65519/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/fileutils.py', 'openstack/common/rpc/matchmaker_ring.py', 'openstack/common/rpc/impl_kombu.py', 'openstack/common/service.py', 'openstack/common/rpc/amqp.py', 'openstack/common/notifier/api.py', 'openstack/common/processutils.py', 'openstack/common/db/sqlalchemy/session.py', 'openstack/common/quota.py', 'openstack/common/rpc/matchmaker.py', 'openstack/common/rpc/impl_qpid.py', 'openstack/common/excutils.py', 'openstack/common/lockutils.py', 'openstack/common/notifier/rpc_notifier2.py', 'openstack/common/db/sqlalchemy/utils.py', 'openstack/common/loopingcall.py', 'openstack/common/rpc/service.py', 'openstack/common/scheduler/filters/ignore_attempted_hosts_filter.py', 'openstack/common/eventlet_backdoor.py', 'openstack/common/notifier/rpc_notifier.py', 'openstack/common/policy.py', 'openstack/common/middleware/notifier.py', 'openstack/common/scheduler/filters/capabilities_filter.py', 'openstack/common/rpc/common.py', 'openstack/common/rpc/impl_zmq.py', 'openstack/common/periodic_task.py', 'openstack/common/db/sqlalchemy/test_migrations.py']",27,7ae1c4b444ced0b6093a1f27926807348248b7ce,bp/log-messages-translation-domain,"from openstack.common.gettextutils import _LD # noqa LOG.debug(_LD('Got lock ""%s""') % f.__name__) LOG.debug(_LD('Lock released ""%s""') % f.__name__)","from openstack.common.gettextutils import _ LOG.debug(_('Got lock ""%s""') % f.__name__) LOG.debug(_('Lock released ""%s""') % f.__name__)",200,194
openstack%2Fkeystone~stable%2Fhavana~Ida5e440d1bdb9f8e9031277ea53a02d2ef171438,openstack/keystone,stable/havana,Ida5e440d1bdb9f8e9031277ea53a02d2ef171438,Have tox use pip upgrade when installing,MERGED,2013-12-15 01:01:05.000000000,2014-01-31 22:08:09.000000000,2014-01-31 22:08:08.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1955}, {'_account_id': 5263}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-12-15 01:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a77b74a80ce6dd4aa50a9c997e73a1f3c26c6445', 'message': 'Have tox install via setup.py develop\n\ntox 1.6 was released, which means that we can now take advantage of\nthe feature we added to it - which is using setup.py develop to\ninstall the code into the virtualenv. The logic was taken from\nrun_tests.sh - so the performance issues around using tox vs. using\ninstall_venv should now be gone.\n\nAdditionally, override the tox pip install command to avoid using\nthe ""--pre"" option which is the default in tox. ""--pre"" means\n""Include pre-release and development versions."" By default, pip will\nonly install stable versions of software, and that is the behavior\nwe want.\n\nChange-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\n'}, {'number': 2, 'created': '2013-12-15 17:09:29.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a102d0f33142562f54dbe0de869d615ef0e8dd1f', 'message': 'Have tox use pip upgrade when installing\n\nTo synchronize behavior with other integrated projects for\nconsistency, tox uses pip install -U making sure any packages\nalready installed in a virtualenv are upgraded to what is specified\nin the requirements lists.\n\nChange-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\n'}]",2,62205,a102d0f33142562f54dbe0de869d615ef0e8dd1f,40,5,2,5263,,,0,"Have tox use pip upgrade when installing

To synchronize behavior with other integrated projects for
consistency, tox uses pip install -U making sure any packages
already installed in a virtualenv are upgraded to what is specified
in the requirements lists.

Change-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438
Co-Authored-By: Monty Taylor <mordred@inaugust.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/62205/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a77b74a80ce6dd4aa50a9c997e73a1f3c26c6445,tox-sync,install_command = pip install -U {opts} {packages},install_command = pip install {opts} {packages},1,1
openstack%2Fnova~master~I303c0905c40d6d07b9c935367d33df73b51fcd56,openstack/nova,master,I303c0905c40d6d07b9c935367d33df73b51fcd56,PCI address should be uniform,MERGED,2014-01-17 05:59:12.000000000,2014-01-31 22:07:12.000000000,2014-01-31 22:07:08.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 4573}, {'_account_id': 7543}, {'_account_id': 7641}, {'_account_id': 9407}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-17 05:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0450d15d9f4b21e03c31496271a6f6666192bfe8', 'message': 'PCI address should be uniform\n\nPCI address should be  ""domain:bus:slot.function"",format is\n""%04x:%02x:%02x.%1x"". so change the PF address to the standard\nformat.\n\nChange-Id: I303c0905c40d6d07b9c935367d33df73b51fcd56\nsigned-off-by: Yongli he <yongli.he@intel.com>\n'}, {'number': 2, 'created': '2014-01-20 02:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a589da82e716adb979fb65901f1b0a0a94d8a33', 'message': 'PCI address should be uniform\n\nPCI address should be  ""domain:bus:slot.function"",PF address should\nalso use this format.\n\nChange-Id: I303c0905c40d6d07b9c935367d33df73b51fcd56\nsigned-off-by: Yongli he <yongli.he@intel.com>\n'}, {'number': 3, 'created': '2014-01-26 08:07:20.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/65726540a19442c2882756b26959fdd1088d442e', 'message': 'PCI address should be uniform\n\nPCI address should be  ""domain:bus:slot.function"",PF address should\nalso use this format.\n\nCloses-Bug: #1240383\nChange-Id: I303c0905c40d6d07b9c935367d33df73b51fcd56\nsigned-off-by: Yongli he <yongli.he@intel.com>\n'}]",6,67375,65726540a19442c2882756b26959fdd1088d442e,24,10,3,7543,,,0,"PCI address should be uniform

PCI address should be  ""domain:bus:slot.function"",PF address should
also use this format.

Closes-Bug: #1240383
Change-Id: I303c0905c40d6d07b9c935367d33df73b51fcd56
signed-off-by: Yongli he <yongli.he@intel.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/67375/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py']",4,0450d15d9f4b21e03c31496271a6f6666192bfe8,uniform-pci-address," self.device_addrs = [] self.device_addrs.append(""%s:%s:%s.%s"" % ( c.get('domain').replace(""0x"", ''), c.get('bus').replace(""0x"", ''), c.get('slot').replace(""0x"", ''), c.get('function').replace(""0x"", '')))"," self.device_addrs = list() # list of tuple (domain,bus,slot,function) self.device_addrs.append((c.get('domain'), c.get('bus'), c.get('slot'), c.get('function')))",20,21
openstack%2Ftempest~master~If7cdb331b3305c39a8f58746129ec2f125e651be,openstack/tempest,master,If7cdb331b3305c39a8f58746129ec2f125e651be,Add key -n for sudo utility,MERGED,2014-01-30 11:19:45.000000000,2014-01-31 22:06:59.000000000,2014-01-31 22:06:58.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6509}, {'_account_id': 8478}]","[{'number': 1, 'created': '2014-01-30 11:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cab54ad7638933a9147f9bae00e18742de24a4c5', 'message': ""Add key -n for sudo utility\n\nIf user didn't configure sudo to work without password,\nit'll prompt for password during the test if debug is\nenabled in tempest confgiuration.\nIf a password is required for the command to run,\nsudo with option -n will display  an error messages and exit.\n\nChange-Id: If7cdb331b3305c39a8f58746129ec2f125e651be\n""}, {'number': 2, 'created': '2014-01-31 10:15:58.000000000', 'files': ['tempest/common/commands.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c930bd8adaaefba7a4f9d66bdf66ecfd33b3ae2', 'message': ""Add key -n for sudo utility\n\nIf user didn't configure sudo to work without password,\nit'll prompt for password during the test if debug is\nenabled in tempest confgiuration.\nIf a password is required for the command to run,\nsudo with option -n will display  an error messages and exit.\n\nChange-Id: If7cdb331b3305c39a8f58746129ec2f125e651be\n""}]",0,70088,4c930bd8adaaefba7a4f9d66bdf66ecfd33b3ae2,9,5,2,8478,,,0,"Add key -n for sudo utility

If user didn't configure sudo to work without password,
it'll prompt for password during the test if debug is
enabled in tempest confgiuration.
If a password is required for the command to run,
sudo with option -n will display  an error messages and exit.

Change-Id: If7cdb331b3305c39a8f58746129ec2f125e651be
",git fetch https://review.opendev.org/openstack/tempest refs/changes/88/70088/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/commands.py'],1,cab54ad7638933a9147f9bae00e18742de24a4c5,sudo_key," proc = subprocess.Popen(['/usr/bin/sudo', '-n'] + args, **subprocess_args)"," proc = subprocess.Popen(['/usr/bin/sudo'] + args, **subprocess_args)",1,1
openstack%2Fdevstack-gate~master~I4f88485fa2f9307ce80e0dd845f865e60c22f9f6,openstack/devstack-gate,master,I4f88485fa2f9307ce80e0dd845f865e60c22f9f6,Add ZUUL_PROJECT to periodic test,MERGED,2013-12-26 16:33:09.000000000,2014-01-31 22:06:57.000000000,2014-01-31 22:06:57.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}]","[{'number': 1, 'created': '2013-12-26 16:33:09.000000000', 'files': ['test-functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ea089da7f53c6c61c5397fc506f656500d7b239d', 'message': 'Add ZUUL_PROJECT to periodic test\n\nTo demonstrate that it is now safe to not unset it (because the\nZUUL_REF checkout check has been removed).\n\nChange-Id: I4f88485fa2f9307ce80e0dd845f865e60c22f9f6\n'}]",0,64163,ea089da7f53c6c61c5397fc506f656500d7b239d,11,4,1,1,,,0,"Add ZUUL_PROJECT to periodic test

To demonstrate that it is now safe to not unset it (because the
ZUUL_REF checkout check has been removed).

Change-Id: I4f88485fa2f9307ce80e0dd845f865e60c22f9f6
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/63/64163/1 && git format-patch -1 --stdout FETCH_HEAD,['test-functions.sh'],1,ea089da7f53c6c61c5397fc506f656500d7b239d,diff, ZUUL_PROJECT='openstack/glance',,1,0
openstack%2Fkeystone~master~Ie909e2b7b7eaf06c555b45daef7de4474aceba2e,openstack/keystone,master,Ie909e2b7b7eaf06c555b45daef7de4474aceba2e,Federation IdentityProvider filter fields on update response,MERGED,2014-01-27 00:25:48.000000000,2014-01-31 22:06:49.000000000,2014-01-31 22:06:48.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-27 00:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5189338244bca9bc3e7638a2eaf48190e21267c6', 'message': 'Federation IdentityProvider filter fields on update response\n\nThe Federation IdentityProvider was failing to filter the fields\nwhen an update was done. This could lead to extra fields being\nreturned to the client that should not be returned.\n\nbp identity-providers\n\nChange-Id: Ie909e2b7b7eaf06c555b45daef7de4474aceba2e\n'}, {'number': 2, 'created': '2014-01-30 22:22:25.000000000', 'files': ['keystone/contrib/federation/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3f586304e6df5b2fc6661d302f57609444959386', 'message': 'Federation IdentityProvider filter fields on update response\n\nThe Federation IdentityProvider was failing to filter the fields\nwhen an update was done. This could lead to extra fields being\nreturned to the client that should not be returned.\n\nbp identity-providers\n\nChange-Id: Ie909e2b7b7eaf06c555b45daef7de4474aceba2e\n'}]",1,69244,3f586304e6df5b2fc6661d302f57609444959386,9,5,2,6486,,,0,"Federation IdentityProvider filter fields on update response

The Federation IdentityProvider was failing to filter the fields
when an update was done. This could lead to extra fields being
returned to the client that should not be returned.

bp identity-providers

Change-Id: Ie909e2b7b7eaf06c555b45daef7de4474aceba2e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/44/69244/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/controllers.py'],1,5189338244bca9bc3e7638a2eaf48190e21267c6,bp/identity-providers, ref = cls.filter_params(ref), idp_ref = self.filter_params(idp_ref) ref = self.filter_params(ref),1,2
openstack%2Fkeystone~master~Ifc066b519cd3564384a617f7ee4009b9fc97f37c,openstack/keystone,master,Ifc066b519cd3564384a617f7ee4009b9fc97f37c,Remove unnecessary test methods,MERGED,2014-01-26 19:40:39.000000000,2014-01-31 22:06:40.000000000,2014-01-31 22:06:39.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-26 19:40:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/30dc1a8e9625330b74d8d2e049389b0ea50d84de', 'message': ""Remove unnecessary test methods\n\nThese functions aren't needed because the default behavior is to\ndo the same thing.\n\nbp identity-providers\n\nChange-Id: Ifc066b519cd3564384a617f7ee4009b9fc97f37c\n""}, {'number': 2, 'created': '2014-01-27 00:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e7212426d3080169cfc6015bedc6619cc6cecc9', 'message': ""Remove unnecessary test methods\n\nThese functions aren't needed because the default behavior is to\ndo the same thing.\n\nbp identity-providers\n\nChange-Id: Ifc066b519cd3564384a617f7ee4009b9fc97f37c\n""}, {'number': 3, 'created': '2014-01-30 22:22:24.000000000', 'files': ['keystone/tests/test_v3_federation.py', 'keystone/tests/test_backend_federation_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/155205795d8cc5a4b59d17eab71d2a6d97b11115', 'message': ""Remove unnecessary test methods\n\nThese functions aren't needed because the default behavior is to\ndo the same thing.\n\nbp identity-providers\n\nChange-Id: Ifc066b519cd3564384a617f7ee4009b9fc97f37c\n""}]",0,69230,155205795d8cc5a4b59d17eab71d2a6d97b11115,12,4,3,6486,,,0,"Remove unnecessary test methods

These functions aren't needed because the default behavior is to
do the same thing.

bp identity-providers

Change-Id: Ifc066b519cd3564384a617f7ee4009b9fc97f37c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/69230/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_v3_federation.py', 'keystone/tests/test_backend_federation_sql.py']",2,30dc1a8e9625330b74d8d2e049389b0ea50d84de,bp/identity-providers,," def setUp(self): super(SqlFederation, self).setUp() ",0,6
openstack%2Fkeystone~master~Id9d8b3f7f5990cad66518c9dc5067670cdb58030,openstack/keystone,master,Id9d8b3f7f5990cad66518c9dc5067670cdb58030,Refactor federation controller class hierarchy,MERGED,2014-01-26 19:40:38.000000000,2014-01-31 22:06:31.000000000,2014-01-31 22:06:30.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-26 19:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/86b4b173597a4c16ec7b7ef9dece0a58b4c94f11', 'message': 'Refactor federation controller class hierarchy\n\nThe FederationProtocol class should not be a subclass of IdentityProvider,\nsince that means that FederationProtocol will provide methods like\ncreate_identity_provider, which is confusing.\n\nbp identity-providers\n\nChange-Id: Id9d8b3f7f5990cad66518c9dc5067670cdb58030\n'}, {'number': 2, 'created': '2014-01-27 00:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/15b7d464f42d01dc917a13991fe126ba6fb77b80', 'message': 'Refactor federation controller class hierarchy\n\nThe FederationProtocol class should not be a subclass of\nIdentityProvider, since that means that FederationProtocol will\nprovide methods like create_identity_provider, which is confusing.\n\nAlso, MappingController can use the new base class to share the\nbase_url calculation.\n\nbp identity-providers\n\nChange-Id: Id9d8b3f7f5990cad66518c9dc5067670cdb58030\n'}, {'number': 3, 'created': '2014-01-30 22:22:25.000000000', 'files': ['keystone/contrib/federation/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/11225d5b252ae0e7e91832fadfa1e800e5282404', 'message': 'Refactor federation controller class hierarchy\n\nThe FederationProtocol class should not be a subclass of\nIdentityProvider, since that means that FederationProtocol will\nprovide methods like create_identity_provider, which is confusing.\n\nAlso, MappingController can use the new base class to share the\nbase_url calculation.\n\nbp identity-providers\n\nChange-Id: Id9d8b3f7f5990cad66518c9dc5067670cdb58030\n'}]",3,69229,11225d5b252ae0e7e91832fadfa1e800e5282404,13,4,3,6486,,,0,"Refactor federation controller class hierarchy

The FederationProtocol class should not be a subclass of
IdentityProvider, since that means that FederationProtocol will
provide methods like create_identity_provider, which is confusing.

Also, MappingController can use the new base class to share the
base_url calculation.

bp identity-providers

Change-Id: Id9d8b3f7f5990cad66518c9dc5067670cdb58030
",git fetch https://review.opendev.org/openstack/keystone refs/changes/29/69229/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/controllers.py'],1,86b4b173597a4c16ec7b7ef9dece0a58b4c94f11,bp/identity-providers,"class _ControllerBase(controller.V3Controller): """"""Base behaviors for federation controllers. @dependency.requires('federation_api') class IdentityProvider(_ControllerBase): """"""Identity Provider representation."""""" collection_name = 'identity_providers' member_name = 'identity_provider' _public_parameters = frozenset(['id', 'enabled', 'description', 'links']) class FederationProtocol(_ControllerBase):","@dependency.requires('federation_api') class IdentityProvider(controller.V3Controller): """"""Identity Provider representation. collection_name = 'identity_providers' member_name = 'identity_provider' _public_parameters = frozenset(['id', 'enabled', 'description', 'links'])class FederationProtocol(IdentityProvider):",12,9
openstack%2Ffuel-library~master~Icb85381fb0462865a2ab961a0357b6e2a0548a56,openstack/fuel-library,master,Icb85381fb0462865a2ab961a0357b6e2a0548a56,Use TCP for Openstack logging,MERGED,2014-01-24 12:48:25.000000000,2014-01-31 22:05:55.000000000,2014-01-31 22:05:54.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-24 12:48:25.000000000', 'files': ['deployment/puppet/osnailyfacter/examples/site.pp', 'deployment/puppet/nailgun/manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a79d32e486a20f0cb7beb39c50acb9e1602b2404', 'message': 'Use TCP for Openstack logging\n\nCloses bug: #1271176\n\nChange-Id: Icb85381fb0462865a2ab961a0357b6e2a0548a56\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,68900,a79d32e486a20f0cb7beb39c50acb9e1602b2404,11,5,1,6926,,,0,"Use TCP for Openstack logging

Closes bug: #1271176

Change-Id: Icb85381fb0462865a2ab961a0357b6e2a0548a56
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/00/68900/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/manifests/init.pp', 'deployment/puppet/osnailyfacter/examples/site.pp']",2,a79d32e486a20f0cb7beb39c50acb9e1602b2404,fix1271176_rsyslog_tcp," proto => 'tcp',",,3,2
openstack%2Fnova~master~I196297af104a775d8cad30f7c1f9547df03d8d2d,openstack/nova,master,I196297af104a775d8cad30f7c1f9547df03d8d2d,Update config from oslo-incubator,ABANDONED,2014-01-31 20:19:36.000000000,2014-01-31 22:04:11.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 20:19:36.000000000', 'files': ['nova/openstack/common/config/generator.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/nova/commit/ff775298ee4a8c14ef4af1372897f0b242fb9186', 'message': 'Update config from oslo-incubator\n\nThis includes the following commits:\n\n  e3dddd7 generator: use EXTRA_* env vars in the bash script\n  e8e636c generator: add an EXTRA_LIBRARIES env variable\n  5dce17b Use entry points to discover options in libraries\n\nChange-Id: I196297af104a775d8cad30f7c1f9547df03d8d2d\n'}]",0,70433,ff775298ee4a8c14ef4af1372897f0b242fb9186,5,3,1,1561,,,0,"Update config from oslo-incubator

This includes the following commits:

  e3dddd7 generator: use EXTRA_* env vars in the bash script
  e8e636c generator: add an EXTRA_LIBRARIES env variable
  5dce17b Use entry points to discover options in libraries

Change-Id: I196297af104a775d8cad30f7c1f9547df03d8d2d
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/70433/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/config/generator.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh']",3,ff775298ee4a8c14ef4af1372897f0b242fb9186,oslo-updates,"PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:m:l:o: \ --long help,base-dir:,package-name:,output-dir:,module:,library: -- ""$@"") echo ""-m, --module=MOD extra python module to interrogate for options"" echo ""-l, --library=LIB extra library that registers options for discovery"" -m|--module) shift MODULES=""$MODULES -m $1"" shift ;; -l|--library) shift LIBRARIES=""$LIBRARIES -l $1"" shift ;;RC_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$RC_FILE"" source ""$RC_FILE""for mod in ${NOVA_CONFIG_GENERATOR_EXTRA_MODULES}; do MODULES=""$MODULES -m $mod"" done for lib in ${NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES}; do LIBRARIES=""$LIBRARIES -l $lib"" done python -m $MODULEPATH $MODULES $LIBRARIES $FILES > $OUTPUTFILE","PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:o: \ --long help,base-dir:,package-name:,output-dir: -- ""$@"")EXTRA_MODULES_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$EXTRA_MODULES_FILE"" source ""$EXTRA_MODULES_FILE""python -m $MODULEPATH $FILES > $OUTPUTFILE",84,25
openstack%2Fnova~master~I1abc808c35d3061f7b65f4985f34ff2cef30ea82,openstack/nova,master,I1abc808c35d3061f7b65f4985f34ff2cef30ea82,Update config from oslo-incubator,ABANDONED,2014-01-31 20:13:37.000000000,2014-01-31 22:03:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 5371}, {'_account_id': 6601}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 20:13:37.000000000', 'files': ['nova/openstack/common/config/generator.py', 'nova/openstack/common/gettextutils.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/nova/commit/4c39df779689f87c31e26c1a0f8ac0ab974a825e', 'message': 'Update config from oslo-incubator\n\nThis includes the following commits:\n\n  e3dddd7 generator: use EXTRA_* env vars in the bash script\n  e8e636c generator: add an EXTRA_LIBRARIES env variable\n  5dce17b Use entry points to discover options in libraries\n\nChange-Id: I1abc808c35d3061f7b65f4985f34ff2cef30ea82\n'}]",0,70430,4c39df779689f87c31e26c1a0f8ac0ab974a825e,6,6,1,1561,,,0,"Update config from oslo-incubator

This includes the following commits:

  e3dddd7 generator: use EXTRA_* env vars in the bash script
  e8e636c generator: add an EXTRA_LIBRARIES env variable
  5dce17b Use entry points to discover options in libraries

Change-Id: I1abc808c35d3061f7b65f4985f34ff2cef30ea82
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/70430/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/config/generator.py', 'nova/openstack/common/gettextutils.py', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh']",4,4c39df779689f87c31e26c1a0f8ac0ab974a825e,oslo-updates,"PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:m:l:o: \ --long help,base-dir:,package-name:,output-dir:,module:,library: -- ""$@"") echo ""-m, --module=MOD extra python module to interrogate for options"" echo ""-l, --library=LIB extra library that registers options for discovery"" -m|--module) shift MODULES=""$MODULES -m $1"" shift ;; -l|--library) shift LIBRARIES=""$LIBRARIES -l $1"" shift ;;RC_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$RC_FILE"" source ""$RC_FILE""for mod in ${NOVA_CONFIG_GENERATOR_EXTRA_MODULES}; do MODULES=""$MODULES -m $mod"" done for lib in ${NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES}; do LIBRARIES=""$LIBRARIES -l $lib"" done python -m $MODULEPATH $MODULES $LIBRARIES $FILES > $OUTPUTFILE","PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:o: \ --long help,base-dir:,package-name:,output-dir: -- ""$@"")EXTRA_MODULES_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$EXTRA_MODULES_FILE"" source ""$EXTRA_MODULES_FILE""python -m $MODULEPATH $FILES > $OUTPUTFILE",341,213
openstack%2Fnova~master~I1f0514d032a452d8531cf50684aad861311f493e,openstack/nova,master,I1f0514d032a452d8531cf50684aad861311f493e,Testing - do not merge,ABANDONED,2014-01-04 00:20:42.000000000,2014-01-31 22:00:48.000000000,,"[{'_account_id': 3}, {'_account_id': 8302}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-04 00:20:42.000000000', 'files': ['nova/virt/vmwareapi/kittens.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d1b7950e4aff4e056d0583550155aa995119338', 'message': 'Testing - do not merge\n\nChange-Id: I1f0514d032a452d8531cf50684aad861311f493e\n'}]",0,64925,1d1b7950e4aff4e056d0583550155aa995119338,55,3,1,8302,,,0,"Testing - do not merge

Change-Id: I1f0514d032a452d8531cf50684aad861311f493e
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/64925/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/kittens.py'],1,1d1b7950e4aff4e056d0583550155aa995119338,,,,0,0
openstack%2Fkeystone~master~I333fb23420282be350330dcb265f54da0fceac21,openstack/keystone,master,I333fb23420282be350330dcb265f54da0fceac21,Refactor mutable parameter handling,MERGED,2014-01-26 19:40:38.000000000,2014-01-31 21:31:51.000000000,2014-01-31 21:31:50.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-26 19:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd64484a1f437908efa34dfbccbe99ad90d714c4', 'message': 'Refactor mutable parameter handling\n\nThe use of _mutable_parameters in the federation controllers was confusing.\nThe mutable parameters were different each time check_immutable_params was\ncalled, so there was no reason to have it a class variable in\nIdentityProvider.\n\nIn FederationProvider it was copied for no reason.\n\nbp identity-providers\n\nChange-Id: I333fb23420282be350330dcb265f54da0fceac21\n'}, {'number': 2, 'created': '2014-01-27 00:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cc923bf571d5a00f9d54f7fbe93773973f6e799', 'message': ""Refactor mutable parameter handling\n\nThe use of _mutable_parameters in the federation controllers was confusing.\nThe mutable parameters were the same each time check_immutable_params was\ncalled, so there was no reason to allow passing in the mutable parameters.\n\nIn FederationProvider the mutable parameters was copied for no reason.\n\nSimilarly, filter_params is always used with the default keys so there's\nno need to allow passing in the keys, and safer to not allow it.\n\nbp identity-providers\n\nChange-Id: I333fb23420282be350330dcb265f54da0fceac21\n""}, {'number': 3, 'created': '2014-01-30 22:22:25.000000000', 'files': ['keystone/contrib/federation/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/135d07a8838a3ba1a5ee0452fe3b8cba33df2c8a', 'message': ""Refactor mutable parameter handling\n\nThe use of _mutable_parameters in the federation controllers was confusing.\nThe mutable parameters were the same each time check_immutable_params was\ncalled, so there was no reason to allow passing in the mutable parameters.\n\nIn FederationProvider the mutable parameters was copied for no reason.\n\nSimilarly, filter_params is always used with the default keys so there's\nno need to allow passing in the keys, and safer to not allow it.\n\nbp identity-providers\n\nChange-Id: I333fb23420282be350330dcb265f54da0fceac21\n""}]",5,69228,135d07a8838a3ba1a5ee0452fe3b8cba33df2c8a,17,4,3,6486,,,0,"Refactor mutable parameter handling

The use of _mutable_parameters in the federation controllers was confusing.
The mutable parameters were the same each time check_immutable_params was
called, so there was no reason to allow passing in the mutable parameters.

In FederationProvider the mutable parameters was copied for no reason.

Similarly, filter_params is always used with the default keys so there's
no need to allow passing in the keys, and safer to not allow it.

bp identity-providers

Change-Id: I333fb23420282be350330dcb265f54da0fceac21
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/69228/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/controllers.py'],1,dd64484a1f437908efa34dfbccbe99ad90d714c4,bp/identity-providers," New class parameter: def check_immutable_params(cls, ref, keys): :param keys: a set with mutable parameters. mutable_params = frozenset(['description', 'enabled']) self.check_immutable_params(identity_provider, mutable_params) idp_ref = self.filter_params(idp_ref) mutable_params = frozenset(['description', 'enabled']) self.check_immutable_params(identity_provider, mutable_params) _mutable_parameters = frozenset(['mapping_id']) self.check_immutable_params(ref, self._mutable_parameters) self.check_immutable_params(ref, self._mutable_parameters)"," Two new class parameters: - _mutable_parameters - set of parameters that can be changed by users. Usually used by cls.check_immutable_params() _mutable_parameters = frozenset(['description', 'enabled']) def check_immutable_params(cls, ref, keys=None): :param keys: a set with mutable parameters. If None, use default class attribute - _mutable_parameters if keys is None: keys = cls._mutable_parameters mutable_params = set(['description', 'enabled']) public_params = set(['id', 'description', 'enabled']) self.check_immutable_params(identity_provider, keys=mutable_params) idp_ref = self.filter_params(idp_ref, keys=public_params) self.check_immutable_params(identity_provider) _mutable_parameters = set(['mapping_id']) keys = self._mutable_parameters.copy() self.check_immutable_params(ref, keys=keys) self.check_immutable_params(ref)",11,19
openstack%2Ftripleo-image-elements~master~I4086ff08ecd84072a109319ea8f872c75ab7ce45,openstack/tripleo-image-elements,master,I4086ff08ecd84072a109319ea8f872c75ab7ce45,Fix mysql installation on openSUSE,MERGED,2014-01-21 22:35:46.000000000,2014-01-31 21:30:04.000000000,2014-01-31 21:30:03.000000000,"[{'_account_id': 3}, {'_account_id': 2062}, {'_account_id': 6449}, {'_account_id': 6593}, {'_account_id': 7144}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-21 22:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/73de2453f1b1e2c7082b4f24a252d8e80b4a2899', 'message': 'Fix mysql installation on openSUSE\n\nChange-Id: I4086ff08ecd84072a109319ea8f872c75ab7ce45\n'}, {'number': 2, 'created': '2014-01-28 08:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b84414bd7161e73c28293f392d83e50e6acb3a5f', 'message': 'Fix mysql installation on openSUSE\n\nUse os-svc-enable for enabling the mysql service to have ""map-services"" handle\nthe different service name on openSUSE.\nCreate /var/lib/mysql on openSUSE. Otherwise register-state-path will not\nprepare /var/lib/use-ephemeral/ correctly for it.\nCreate a /var/run/mysql/mysql.sock compatibility link to have mysql clients\nfind the database sockets. This needs to happen in the running system as\n/var/run is a tmpfs on openSUSE.\n\nChange-Id: I4086ff08ecd84072a109319ea8f872c75ab7ce45\n'}, {'number': 3, 'created': '2014-01-30 10:23:19.000000000', 'files': ['elements/mysql/os-refresh-config/post-configure.d/40-mysql', 'elements/mysql/install.d/10-mysql'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4777f32ab9589da0332c65bcb7e1a8b29fbed3d7', 'message': 'Fix mysql installation on openSUSE\n\nUse os-svc-enable and -restart the mysql service to have ""map-services""\nhandle the different service names on different Distros.\nCreate /var/lib/mysql on openSUSE. Otherwise register-state-path will\nnot prepare /var/lib/use-ephemeral/ correctly for it.\nCreate a /var/run/mysql/mysql.sock compatibility link to have mysql\nclients find the database sockets. This needs to happen in the running\nsystem as /var/run is a tmpfs on openSUSE.\n\nChange-Id: I4086ff08ecd84072a109319ea8f872c75ab7ce45\n'}]",4,68278,4777f32ab9589da0332c65bcb7e1a8b29fbed3d7,18,6,3,2062,,,0,"Fix mysql installation on openSUSE

Use os-svc-enable and -restart the mysql service to have ""map-services""
handle the different service names on different Distros.
Create /var/lib/mysql on openSUSE. Otherwise register-state-path will
not prepare /var/lib/use-ephemeral/ correctly for it.
Create a /var/run/mysql/mysql.sock compatibility link to have mysql
clients find the database sockets. This needs to happen in the running
system as /var/run is a tmpfs on openSUSE.

Change-Id: I4086ff08ecd84072a109319ea8f872c75ab7ce45
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/78/68278/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql/os-refresh-config/post-configure.d/40-mysql', 'elements/mysql/install.d/10-mysql']",2,73de2453f1b1e2c7082b4f24a252d8e80b4a2899,fix/mysql-opensuse,# On openSUSE /var/lib/mysql is not part of the mariadb packages. [ -d /var/lib/mysql ] || install -d -o mysql -g root -m 0700 /var/lib/mysql os-svc-enable -n mysqld || os-svc-enable -n mariadb, systemctl enable mysqld.service || systemctl enable mariadb.service,8,1
openstack%2Ftripleo-ci~master~I29d2560200c492c7e5d6fd07265782583abf6951,openstack/tripleo-ci,master,I29d2560200c492c7e5d6fd07265782583abf6951,Run undercloud tests as well.,MERGED,2014-01-31 00:37:29.000000000,2014-01-31 21:23:51.000000000,2014-01-31 21:23:51.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-01-31 00:37:29.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/03ba11a7b952222b0248925a87b53c539a5fe624', 'message': ""Run undercloud tests as well.\n\nInfra/config now has a job definition for undercloud tests. We'll work\non optimising these to skip building the seed eventually, but as a\nfirst approximation, lets just run them as an end-to-end story.\n\nChange-Id: I29d2560200c492c7e5d6fd07265782583abf6951\n""}]",0,70269,03ba11a7b952222b0248925a87b53c539a5fe624,8,4,1,4190,,,0,"Run undercloud tests as well.

Infra/config now has a job definition for undercloud tests. We'll work
on optimising these to skip building the seed eventually, but as a
first approximation, lets just run them as an end-to-end story.

Change-Id: I29d2560200c492c7e5d6fd07265782583abf6951
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/69/70269/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,03ba11a7b952222b0248925a87b53c539a5fe624,,"echo ""Running $TRIPLEO_TEST test run""export no_proxy=${no_proxy:-},192.0.2.1 source $TRIPLEO_ROOT/tripleo-incubator/seedrc if [ ""seed"" != ""$TRIPLEO_TEST"" ]; then devtest_undercloud.sh $TE_DATAFILE fi",,6,0
openstack%2Fopenstack-manuals~master~Ic9427fd17ad08955d7a5a9e4c2f1227260999701,openstack/openstack-manuals,master,Ic9427fd17ad08955d7a5a9e4c2f1227260999701,Adds NOZEROCONF option to CentOS Image Guide,MERGED,2014-01-31 05:27:47.000000000,2014-01-31 21:19:10.000000000,2014-01-31 21:19:09.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9191}]","[{'number': 1, 'created': '2014-01-31 05:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6af4bbe5c2f7ecd7c573cf44b0acf2406779fbcb', 'message': 'Adds NOZEROCONF option to CentOS Image Guide\n\nThe ""NOZEROCONF=yes"" option is a requirement for successful\naccess to the metadata service. By default in RHEL (or derivatives)\nthis option is not present.\n\nChange-Id: Ic9427fd17ad08955d7a5a9e4c2f1227260999701\nCloses-Bug: #1273916\nbackport: havana\n'}, {'number': 2, 'created': '2014-01-31 19:50:12.000000000', 'files': ['doc/image-guide/section_centos-example.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/48167af205d2c5fef4ded3f23902e4e60927d5ae', 'message': 'Adds NOZEROCONF option to CentOS Image Guide\n\nThe ""NOZEROCONF=yes"" option is a requirement for successful\naccess to the metadata service. By default in RHEL (or derivatives)\nthis option is not present.\n\nChange-Id: Ic9427fd17ad08955d7a5a9e4c2f1227260999701\nCloses-Bug: #1273916\nbackport: havana\n'}]",1,70299,48167af205d2c5fef4ded3f23902e4e60927d5ae,9,4,2,9191,,,0,"Adds NOZEROCONF option to CentOS Image Guide

The ""NOZEROCONF=yes"" option is a requirement for successful
access to the metadata service. By default in RHEL (or derivatives)
this option is not present.

Change-Id: Ic9427fd17ad08955d7a5a9e4c2f1227260999701
Closes-Bug: #1273916
backport: havana
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/99/70299/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_centos-example.xml'],1,6af4bbe5c2f7ecd7c573cf44b0acf2406779fbcb,bug/1273916," <title>Disable the zeroconf route</title> <para>In order for the instance to access the metadata service, disable the default zeroconf route:</para> <screen><prompt>#</prompt> <userinput>echo ""NOZEROCONF=yes"" >> /etc/sysconfig/network</userinput></screen> </simplesect> <simplesect>",,6,0
openstack%2Fpython-troveclient~master~I76fb0d99512b1ee70441c924835a900ba0b7acd1,openstack/python-troveclient,master,I76fb0d99512b1ee70441c924835a900ba0b7acd1,Add Neutron support,MERGED,2013-12-11 16:45:09.000000000,2014-01-31 21:11:41.000000000,2014-01-31 21:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 4240}, {'_account_id': 5170}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8259}, {'_account_id': 8415}]","[{'number': 1, 'created': '2013-12-11 16:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/e3b6889ebb90e397b83f4ff5be32de662ade5ac4', 'message': 'Add support of neutron NICs\n\nFixes bug: #1257838\n\nChange-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1\n'}, {'number': 2, 'created': '2013-12-18 21:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d1be5e421ecd9a3d48ec758b4cbefbdab614e5ea', 'message': 'Add support of neutron NICs\n\nFixes bug: #1257838\n\nChange-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1\n'}, {'number': 3, 'created': '2013-12-23 15:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/1d15fb27c5b3261b79d88fe345497c325fdb12d2', 'message': ""Add Neutron support\n\nCurrently create instance doesnt work in OS installation with Neutron.\nTo get it work, additional parameter 'nics' should be specified in Nova 'create' call.\nThis change allows user to pass 'nics' parameter when create instance.\n\nSyntax to specify '--nic' parameter is same as in novaclient.\n--nic <net-id=net-uuid,v4-fixed-ip=ip-addr,port-id=port-uuid>\nThis parameter can be specified multiple times, to attach multiple network interfaces to instance.\n\nFixes bug: #1257838\n\nChange-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1\n""}, {'number': 4, 'created': '2014-01-23 11:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5c5a5c2c5daab853878c5fb589f2fd0e7f864ccb', 'message': ""Add Neutron support\n\nCurrently create instance doesnt work in OS installation with Neutron.\nTo get it work, additional parameter 'nics' should be specified\nin Nova 'create' call.\nThis change allows user to pass 'nics' parameter when create instance.\n\nSyntax to specify '--nic' parameter is same as in novaclient.\n--nic <net-id=net-uuid,v4-fixed-ip=ip-addr,port-id=port-uuid>\nThis parameter can be specified multiple times, to attach multiple\nnetwork interfaces to instance.\n\nCloses-Bug: #1257838\n\nChange-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1\n""}, {'number': 5, 'created': '2014-01-29 17:42:43.000000000', 'files': ['troveclient/v1/shell.py', 'troveclient/v1/instances.py', 'troveclient/tests/test_instances.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/b62c7da0a9681c51bdf8dd01402f8b1e2abd2b0f', 'message': ""Add Neutron support\n\nCurrently create instance doesnt work in OS installation with Neutron.\nTo get it work, additional parameter 'nics' should be specified\nin Nova 'create' call.\nThis change allows user to pass 'nics' parameter when create instance.\n\nSyntax to specify '--nic' parameter is same as in novaclient.\n--nic <net-id=net-uuid,v4-fixed-ip=ip-addr,port-id=port-uuid>\nThis parameter can be specified multiple times, to attach multiple\nnetwork interfaces to instance.\n\nCloses-Bug: #1257838\n\nChange-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1\n""}]",14,61481,b62c7da0a9681c51bdf8dd01402f8b1e2abd2b0f,43,10,5,8259,,,0,"Add Neutron support

Currently create instance doesnt work in OS installation with Neutron.
To get it work, additional parameter 'nics' should be specified
in Nova 'create' call.
This change allows user to pass 'nics' parameter when create instance.

Syntax to specify '--nic' parameter is same as in novaclient.
--nic <net-id=net-uuid,v4-fixed-ip=ip-addr,port-id=port-uuid>
This parameter can be specified multiple times, to attach multiple
network interfaces to instance.

Closes-Bug: #1257838

Change-Id: I76fb0d99512b1ee70441c924835a900ba0b7acd1
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/81/61481/3 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/v1/shell.py', 'troveclient/v1/instances.py', 'troveclient/tests/test_instances.py']",3,e3b6889ebb90e397b83f4ff5be32de662ade5ac4,bug/multiple_networks," nics = [{'net-id': '000'}] datastore_version=""datastore-version"", nics=nics) self.assertEqual(nics, b[""instance""][""nics""])"," datastore_version=""datastore-version"")",44,3
openstack%2Fdevstack~master~I2b92a3c8e7db603eb13378e46893fc81f507405b,openstack/devstack,master,I2b92a3c8e7db603eb13378e46893fc81f507405b,Use service postgresql initdb with el6,MERGED,2014-01-27 08:46:38.000000000,2014-01-31 20:20:35.000000000,2014-01-31 20:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 5803}, {'_account_id': 6890}]","[{'number': 1, 'created': '2014-01-27 08:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7030dfdbe608d0b2bc830c59f8587b4353b35b40', 'message': 'Use service postgresql initdb with el6\n\npostgresql-setup does not exists on el6,\nthe service postgresql initdb is the documented db init command.\n\nChange-Id: I2b92a3c8e7db603eb13378e46893fc81f507405b\n'}, {'number': 2, 'created': '2014-01-27 10:10:46.000000000', 'files': ['lib/databases/postgresql'], 'web_link': 'https://opendev.org/openstack/devstack/commit/315f7b0747effbd490ff3b25d85bc6399ed290a1', 'message': 'Use service postgresql initdb with el6\n\npostgresql-setup does not exists on el6,\nthe service postgresql initdb is the documented db init command.\n\nChange-Id: I2b92a3c8e7db603eb13378e46893fc81f507405b\n'}]",0,69297,315f7b0747effbd490ff3b25d85bc6399ed290a1,8,5,2,5803,,,0,"Use service postgresql initdb with el6

postgresql-setup does not exists on el6,
the service postgresql initdb is the documented db init command.

Change-Id: I2b92a3c8e7db603eb13378e46893fc81f507405b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/97/69297/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/databases/postgresql'],1,7030dfdbe608d0b2bc830c59f8587b4353b35b40,pg-el6, if ! sudo [ -e $PG_HBA ]; then if ! [[ $DISTRO =~ (rhel6) ]]; then sudo postgresql-setup initdb else sudo service postgresql initdb fi, sudo [ -e $PG_HBA ] || sudo postgresql-setup initdb,6,1
openstack%2Fkeystone~master~Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de,openstack/keystone,master,Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de,Refactor Auth plugin configuration options,MERGED,2014-01-23 03:59:54.000000000,2014-01-31 20:15:56.000000000,2014-01-31 20:15:55.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7052}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-23 03:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0a7705361b24cfca95150c28384a7025b35eb338', 'message': ""Cleanup auth plugin configuration options\n\nThe auth plugin configuration options relied on magical-self-defining\nconfig options. This was due to the need to use the [auth] methods\noption to define the expected auth method for the plugin.\n\nThe new method is to simply specify each plugin\n(e.g. keystone.auth.plugins.external.DefaultDomain ) as a comma\nseparated list in the [auth] plugins option. Auth plugins are no longer\nlazy loaded on demand, but loaded on the first instatiation of the\nkeystone.auth.controllers.Auth object.\n\nEach auth plugin should now define a 'method' attribute that specifies\nthe auth method it is registering for.\n\nThe [auth] methods (and associated plugin options) are slated to be\nremoved in the K release.\n\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\nbp: keystone-parallel-testing\n""}, {'number': 2, 'created': '2014-01-23 19:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0dc17751e3e9a631e5713a4aca91465f5acaf11b', 'message': ""Cleanup auth plugin configuration options\n\nThe auth plugin configuration options relied on magical-self-defining\nconfig options. This was due to the need to use the [auth] methods\noption to define the expected auth method for the plugin.\n\nThe new method is to simply specify each plugin\n(e.g. keystone.auth.plugins.external.DefaultDomain ) as a comma\nseparated list in the [auth] plugins option. Auth plugins are no longer\nlazy loaded on demand, but loaded on the first instatiation of the\nkeystone.auth.controllers.Auth object.\n\nEach auth plugin should now define a 'method' attribute that specifies\nthe auth method it is registering for.\n\nThe [auth] methods (and associated plugin options) are slated to be\nremoved in the K release.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n""}, {'number': 3, 'created': '2014-01-23 20:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9bf2171fb2ba04ee2ed9d844394fcc2f7d70b06', 'message': ""Cleanup auth plugin configuration options\n\nThe auth plugin configuration options relied on magical-self-defining\nconfig options. This was due to the need to use the [auth] methods\noption to define the expected auth method for the plugin.\n\nThe new method is to simply specify each plugin\n(e.g. keystone.auth.plugins.external.DefaultDomain ) as a comma\nseparated list in the [auth] plugins option. Auth plugins are no longer\nlazy loaded on demand, but loaded on the first instatiation of the\nkeystone.auth.controllers.Auth object.\n\nEach auth plugin should now define a 'method' attribute that specifies\nthe auth method it is registering for.\n\nThe [auth] methods (and associated plugin options) are slated to be\nremoved in the K release.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n""}, {'number': 4, 'created': '2014-01-23 20:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0ae131365d1432552d93a586b8db597c26b68575', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration options relied on magical-self-defining\nconfig options. This was due to the need to use the [auth] methods\noption to define the expected auth method for the plugin.\n\nThe new method is to simply specify each plugin\n(e.g. keystone.auth.plugins.external.DefaultDomain ) as a comma\nseparated list in the [auth] plugins option. Auth plugins are no longer\nlazy loaded on demand, but loaded on the first instatiation of the\nkeystone.auth.controllers.Auth object.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nThe [auth] methods (and associated plugin options) are slated to be\nremoved in the K release.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 5, 'created': '2014-01-24 17:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/525c7a6224e623994841127bb0ac53caa6d3d479', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration options relied on magical-self-defining\nconfig options. This was due to the need to use the [auth] methods\noption to define the expected auth method for the plugin.\n\nThe new method is to simply specify each plugin\n(e.g. keystone.auth.plugins.external.DefaultDomain ) as a comma\nseparated list in the [auth] plugins option. Auth plugins are no longer\nlazy loaded on demand, but loaded on the first instatiation of the\nkeystone.auth.controllers.Auth object.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nThe [auth] methods (and associated plugin options) are slated to be\nremoved in the K release.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 6, 'created': '2014-01-25 02:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/250f3e083e4fd6d08efcbd34f6388831911d3802', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 7, 'created': '2014-01-25 02:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/37059ce9d0e50348943278c4d91f90de999b985d', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 9, 'created': '2014-01-25 02:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00d8e9a0e9df5d7f27997f8fedcb38982effd43c', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 8, 'created': '2014-01-25 02:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5129acc4d74ffaa9e1ab99b7ac5e9505d19bbd96', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 10, 'created': '2014-01-25 02:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/233056198581662c27c8c6f1bcdf70d42c58c2df', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 11, 'created': '2014-01-30 20:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f742c5d756ea03511b5aa13785ae6e7daa07b8a', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}, {'number': 12, 'created': '2014-01-30 22:39:48.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/auth/plugins/oauth1.py', 'keystone/tests/core.py', 'keystone/auth/plugins/external.py', 'keystone/tests/test_auth_plugin.py', 'keystone/service.py', 'keystone/auth/plugins/token.py', 'keystone/tests/test_auth_plugin.conf', 'keystone/auth/plugins/password.py', 'keystone/tests/test_auth_plugin_by_class_name.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d379a2971ac06506b231e6fdade9b7077d8186ed', 'message': 'Refactor Auth plugin configuration options\n\nThe auth plugin configuration can now either be specified by the\n[auth] methods and [auth] <method name> options or as a class-name\nas part of the [auth] methods option (e.g.\nkeystone.auth.plugins.password.Password). Both styles of auth\nmethod specification can be used at the same time.  No two auth\nplugins may register for the same auth method.\n\nEach auth plugin must now define a \'method\' attribute that specifies\nthe auth method it is registering for.\n\nTests have been modified to use a unified ""method"" name, this ensures\nwe are testing the appropriate code paths for auth methods rather than\nrelying on strings matching in all cases going forward.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\nbp: keystone-parallel-testing\nChange-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de\n'}]",52,68551,d379a2971ac06506b231e6fdade9b7077d8186ed,36,11,12,2903,,,0,"Refactor Auth plugin configuration options

The auth plugin configuration can now either be specified by the
[auth] methods and [auth] <method name> options or as a class-name
as part of the [auth] methods option (e.g.
keystone.auth.plugins.password.Password). Both styles of auth
method specification can be used at the same time.  No two auth
plugins may register for the same auth method.

Each auth plugin must now define a 'method' attribute that specifies
the auth method it is registering for.

Tests have been modified to use a unified ""method"" name, this ensures
we are testing the appropriate code paths for auth methods rather than
relying on strings matching in all cases going forward.

Co-Authored-By: Brant Knudson <bknudson@us.ibm.com>
bp: keystone-parallel-testing
Change-Id: Icbb1d63d36726b8dbf7dfd8c6353fa30bbe490de
",git fetch https://review.opendev.org/openstack/keystone refs/changes/51/68551/12 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/auth/plugins/oauth1.py', 'keystone/common/config.py', 'keystone/auth/plugins/external.py', 'keystone/auth/plugins/token.py', 'keystone/tests/legacy_test_auth_plugin.conf', 'keystone/tests/auth_plugin_external_domain.conf', 'keystone/tests/test_v3.py', 'keystone/auth/plugins/password.py', 'etc/keystone.conf.sample', 'keystone/tests/auth_plugin_external_disabled.conf', 'keystone/tests/test_auth_plugin.py', 'keystone/tests/auth_plugin_external_default_legacy.conf', 'keystone/tests/test_auth_plugin.conf']",14,0a7705361b24cfca95150c28384a7025b35eb338,bp/keystone-parallel-testing,"plugins = keystone.auth.plugins.external.DefaultDomain,keystone.auth.plugins.password.Password,keystone.auth.plugins.token.Token,keystone.tests.test_auth_plugin.SimpleChallengeResponse","methods = external,password,token,simple-challenge-response simple-challenge-response = challenge_response_method.SimpleChallengeResponse",98,40
openstack%2Ftempest~master~I81bfd831025af1ad42e26ef8a25985c06120aaf7,openstack/tempest,master,I81bfd831025af1ad42e26ef8a25985c06120aaf7,Add list server filter with extra limits,MERGED,2014-01-07 07:30:11.000000000,2014-01-31 20:13:07.000000000,2014-01-31 20:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5586}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 8607}]","[{'number': 1, 'created': '2014-01-07 07:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0240b9b53b30a00b661ee527d8b0d99a1509916a', 'message': 'Add list server filter with extra limits\n\nAdd list servers filter with zero and exceeding limits\n\nChange-Id: I81bfd831025af1ad42e26ef8a25985c06120aaf7\n'}, {'number': 2, 'created': '2014-01-07 09:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee58c9a512e50659ec5d6af6e30762cfa8490c7b', 'message': 'Add list server filter with extra limits\n\nAdd list servers filter with zero and exceeding limits\n\nChange-Id: I81bfd831025af1ad42e26ef8a25985c06120aaf7\n'}, {'number': 3, 'created': '2014-01-08 12:38:53.000000000', 'files': ['tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/v3/servers/test_list_server_filters.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ef73330638224e8941c3a95c6a84c3469d1eb9d', 'message': 'Add list server filter with extra limits\n\nAdd list servers filter with zero and exceeding limits\n\nChange-Id: I81bfd831025af1ad42e26ef8a25985c06120aaf7\n'}]",4,65227,9ef73330638224e8941c3a95c6a84c3469d1eb9d,19,6,3,8607,,,0,"Add list server filter with extra limits

Add list servers filter with zero and exceeding limits

Change-Id: I81bfd831025af1ad42e26ef8a25985c06120aaf7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/27/65227/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_list_server_filters.py'],1,0240b9b53b30a00b661ee527d8b0d99a1509916a,test_extra_list_server_limit," @attr(type='gate') def test_list_servers_filter_by_zero_limit(self): # Verify only the expected number of servers are returned params = {'limit': 0} resp, servers = self.client.list_servers(params) # when _interface='xml', zero element for servers_links in servers self.assertEqual(0, len([x for x in servers['servers'] if 'id' in x])) @attr(type='gate') def test_list_servers_filter_by_exceed_limit(self): # Verify only the expected number of servers are returned params = {'limit': 100000} resp, servers = self.client.list_servers(params) resp, all_servers = self.client.list_servers() self.assertEqual(len([x for x in all_servers['servers'] if 'id' in x]), len([x for x in servers['servers'] if 'id' in x])) ",,17,0
openstack%2Foslo-incubator~master~I79ce84e17c768daf13a7c8a3366e658ad10999b7,openstack/oslo-incubator,master,I79ce84e17c768daf13a7c8a3366e658ad10999b7,generator: use EXTRA_* env vars in the bash script,MERGED,2014-01-29 07:24:32.000000000,2014-01-31 20:05:13.000000000,2014-01-31 20:05:13.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-01-29 07:24:32.000000000', 'files': ['tools/config/generate_sample.sh', 'openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e3dddd7260ae04e5a82a69f9cd7098216cd1713c', 'message': ""generator: use EXTRA_* env vars in the bash script\n\nIt's a bit odd to source a file (intended to contain env vars) from\nthe bash script and then for the python module be the one to actually\nuse the env vars, especially since the python module has command line\narguments.\n\nInstead, lets read the values from the env vars in the bash script and\npass them to the python via command line arguments.\n\nThis is a slightly incompatible change - the env var was expected to\nbe comma separated before, but now its $IFS separated. However, none\nof the users of this rc file actually have multiple values listed\nin EXTRA_MODULES.\n\nChange-Id: I79ce84e17c768daf13a7c8a3366e658ad10999b7\n""}]",0,69801,e3dddd7260ae04e5a82a69f9cd7098216cd1713c,6,3,1,1247,,,0,"generator: use EXTRA_* env vars in the bash script

It's a bit odd to source a file (intended to contain env vars) from
the bash script and then for the python module be the one to actually
use the env vars, especially since the python module has command line
arguments.

Instead, lets read the values from the env vars in the bash script and
pass them to the python via command line arguments.

This is a slightly incompatible change - the env var was expected to
be comma separated before, but now its $IFS separated. However, none
of the users of this rc file actually have multiple values listed
in EXTRA_MODULES.

Change-Id: I79ce84e17c768daf13a7c8a3366e658ad10999b7
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/01/69801/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/config/generate_sample.sh', 'openstack/common/config/generator.py']",2,e3dddd7260ae04e5a82a69f9cd7098216cd1713c,," parser.add_argument('-m', dest='modules', action='append') if parsed_args.modules: for module_name in parsed_args.modules: if parsed_args.libraries: names=list(set(parsed_args.libraries)),"," extra_modules = os.getenv(""OSLO_CONFIG_GENERATOR_EXTRA_MODULES"", """") if extra_modules: for module_name in extra_modules.split(','): module_name = module_name.strip() libraries = parsed_args.libraries or [] extra_libraries = os.getenv(""OSLO_CONFIG_GENERATOR_EXTRA_LIBRARIES"", """") if extra_libraries: libraries.extend(l.strip() for l in extra_libraries.split(',')) if libraries: names=list(set(libraries)),",22,13
openstack%2Foslo-incubator~master~I977eb7009d677430a20987e31dcaeea3ace0fc6a,openstack/oslo-incubator,master,I977eb7009d677430a20987e31dcaeea3ace0fc6a,generator: add an EXTRA_LIBRARIES env variable,MERGED,2014-01-27 12:53:55.000000000,2014-01-31 20:04:23.000000000,2014-01-31 20:04:23.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-01-27 12:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b87a5b20df26cd7ae267f9920cc76e264ea5ce6a', 'message': 'generator: add an EXTRA_LIBRARIES env variable\n\nIf Nova uses oslo.messaging, we want to somehow configure the generator\nto automatically add options from oslo.messaging. Perhaps the easiest\nand most obvious way of doing that would be to add:\n\n  export NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=oslo.messaging\n\nto oslo.config.generator.rc.\n\nChange-Id: I977eb7009d677430a20987e31dcaeea3ace0fc6a\n'}, {'number': 2, 'created': '2014-01-27 14:00:41.000000000', 'files': ['openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e8e636cc6aa5347a480ad631566aa08bd29a54f1', 'message': 'generator: add an EXTRA_LIBRARIES env variable\n\nIf Nova uses oslo.messaging, we want to somehow configure the generator\nto automatically add options from oslo.messaging. Perhaps the easiest\nand most obvious way of doing that would be to add:\n\n  export NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=oslo.messaging\n\nto oslo.config.generator.rc.\n\nChange-Id: I977eb7009d677430a20987e31dcaeea3ace0fc6a\n'}]",3,69355,e8e636cc6aa5347a480ad631566aa08bd29a54f1,12,4,2,1247,,,0,"generator: add an EXTRA_LIBRARIES env variable

If Nova uses oslo.messaging, we want to somehow configure the generator
to automatically add options from oslo.messaging. Perhaps the easiest
and most obvious way of doing that would be to add:

  export NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=oslo.messaging

to oslo.config.generator.rc.

Change-Id: I977eb7009d677430a20987e31dcaeea3ace0fc6a
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/55/69355/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/config/generator.py'],1,b87a5b20df26cd7ae267f9920cc76e264ea5ce6a,," libraries = parsed_args.libraries extra_libraries = os.getenv(""OSLO_CONFIG_GENERATOR_EXTRA_LIBRARIES"", """") if extra_libraries: libraries.extend(l.strip() for l in extra_modules.split(',')) if libraries: names=list(set(libraries)),"," if parsed_args.libraries: names=list(set(parsed_args.libraries)),",6,2
openstack%2Fcinder~master~I8a7ee1201d5d273c3b6f4c5066ac2d0258d2c8ba,openstack/cinder,master,I8a7ee1201d5d273c3b6f4c5066ac2d0258d2c8ba,Brick: Fix nfs/glusterfs_mount_base_required messages,ABANDONED,2014-01-31 19:07:27.000000000,2014-01-31 19:56:10.000000000,,[{'_account_id': 5997}],"[{'number': 1, 'created': '2014-01-31 19:07:27.000000000', 'files': ['cinder/brick/remotefs/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d2086357731e41289edd5055ba6f922ff4cae591', 'message': ""Brick: Fix nfs/glusterfs_mount_base_required messages\n\nThese messages don't currently display correctly in the log\nbecause the wrong parameter name is used for the exception\nmessage.\n\nRelated-Bug: 1238085\n\nChange-Id: I8a7ee1201d5d273c3b6f4c5066ac2d0258d2c8ba\n""}]",0,70404,d2086357731e41289edd5055ba6f922ff4cae591,2,1,1,4523,,,0,"Brick: Fix nfs/glusterfs_mount_base_required messages

These messages don't currently display correctly in the log
because the wrong parameter name is used for the exception
message.

Related-Bug: 1238085

Change-Id: I8a7ee1201d5d273c3b6f4c5066ac2d0258d2c8ba
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/70404/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/remotefs/remotefs.py'],1,d2086357731e41289edd5055ba6f922ff4cae591,bug/1238085, message=_('nfs_mount_point_base required')) message=_('glusterfs_mount_point_base required')), err=_('nfs_mount_point_base required')) err=_('glusterfs_mount_point_base required')),2,2
openstack%2Fopenstack-manuals~master~Id3fee3024fca9fc09009969ffc58c74934a56a7f,openstack/openstack-manuals,master,Id3fee3024fca9fc09009969ffc58c74934a56a7f,Update generated cli commands,MERGED,2014-01-31 11:07:23.000000000,2014-01-31 19:55:47.000000000,2014-01-31 19:55:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-01-31 11:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/75898cbc4ff0bdd735d90a09c22d2adf64ba7ed6', 'message': 'Update keystone cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 2, 'created': '2014-01-31 12:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c77e8ea8df06959e5a273c631e4b40cbfe793673', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 3, 'created': '2014-01-31 14:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/deca422fa4468b25c9ddf146b0c348d63cb2f3aa', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 4, 'created': '2014-01-31 15:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df03c493454a8e8458c6d2c4aed83e0846c4283b', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 5, 'created': '2014-01-31 15:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c3b36a1aeeaef3ba204fe4c0959d340ea6cd7df', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 6, 'created': '2014-01-31 16:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f79cf1a9951cfe40b1bb6864213a1263aae18777', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}, {'number': 7, 'created': '2014-01-31 17:58:05.000000000', 'files': ['doc/common/section_cli_nova_commands.xml', 'doc/common/section_cli_swift_commands.xml', 'doc/common/section_cli_glance_commands.xml', 'doc/common/section_cli_ceilometer_commands.xml', 'doc/common/section_cli_neutron_commands.xml', 'doc/common/section_cli_cinder_commands.xml', 'doc/common/section_cli_keystone_commands.xml', 'doc/common/section_cli_heat_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5c6e2c94d20a435e60bbb6ed59d8f2207cc311a3', 'message': 'Update generated cli commands\n\nUpdate with new openstack-auto-commands tool.\n\nPartial-Bug: #1274699\nChange-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f\n'}]",1,70326,5c6e2c94d20a435e60bbb6ed59d8f2207cc311a3,24,5,7,6547,,,0,"Update generated cli commands

Update with new openstack-auto-commands tool.

Partial-Bug: #1274699
Change-Id: Id3fee3024fca9fc09009969ffc58c74934a56a7f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/26/70326/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_cli_keystone_commands.xml'],1,75898cbc4ff0bdd735d90a09c22d2adf64ba7ed6,cli-update," <screen><computeroutput> [--os-username &lt;auth-user-name&gt;] [--os-password &lt;auth-password&gt;] [--os-tenant-name &lt;auth-tenant-name&gt;] [--os-tenant-id &lt;tenant-id&gt;] [--os-auth-url &lt;auth-url&gt;] [--os-region-name &lt;region-name&gt;] [--os-identity-api-version &lt;identity-api-version&gt;] [--os-token &lt;service-token&gt;] [--os-endpoint &lt;service-endpoint&gt;] [--os-cacert &lt;ca-certificate&gt;] [--insecure] [--os-cert &lt;certificate&gt;] [--os-key &lt;key&gt;] [--os-cache] [--force-new-token] [--stale-duration &lt;seconds&gt;] &lt;subcommand&gt; ... <variablelist wordsize=""10""> <title>Subcommands</title> <varlistentry> <term><command>catalog</command></term> <listitem> <para> List service catalog, possibly filtered by service. </para> </listitem> </varlistentry> <varlistentry> <term><command>ec2-credentials-create</command></term> <listitem> <para> Create EC2-compatible credentials for user per tenant. </para> </listitem> </varlistentry> <varlistentry> <term><command>ec2-credentials-delete</command></term> <listitem> <para> Delete EC2-compatible credentials. </para> </listitem> </varlistentry> <varlistentry> <term><command>ec2-credentials-get</command></term> <listitem> <para> Display EC2-compatible credentials. </para> </listitem> </varlistentry> <varlistentry> <term><command>ec2-credentials-list</command></term> <listitem> <para> List EC2-compatible credentials for a user </para> </listitem> </varlistentry> <varlistentry> <term><command>endpoint-create</command></term> <listitem> <para> Create a new endpoint associated with a service. </para> </listitem> </varlistentry> <varlistentry> <term><command>endpoint-delete</command></term> <listitem> <para> Delete a service endpoint. </para> </listitem> </varlistentry> <varlistentry> <term><command>endpoint-get</command></term> <listitem> <para> Find endpoint filtered by a specific attribute or service type. </para> </listitem> </varlistentry> <varlistentry> <term><command>endpoint-list</command></term> <listitem> <para> List configured service endpoints. </para> </listitem> </varlistentry> <varlistentry> <term><command>password-update</command></term> <listitem> <para> Update own password. </para> </listitem> </varlistentry> <varlistentry> <term><command>role-create</command></term> <listitem> <para> Create new role. </para> </listitem> </varlistentry> <varlistentry> <term><command>role-delete</command></term> <listitem> <para> Delete role. </para> </listitem> </varlistentry> <varlistentry> <term><command>role-get</command></term> <listitem> <para> Display role details. </para> </listitem> </varlistentry> <varlistentry> <term><command>role-list</command></term> <listitem> <para> List all roles. </para> </listitem> </varlistentry> <varlistentry> <term><command>service-create</command></term> <listitem> <para> Add service to Service Catalog. </para> </listitem> </varlistentry> <varlistentry> <term><command>service-delete</command></term> <listitem> <para> Delete service from Service Catalog. </para> </listitem> </varlistentry> <varlistentry> <term><command>service-get</command></term> <listitem> <para> Display service from Service Catalog. </para> </listitem> </varlistentry> <varlistentry> <term><command>service-list</command></term> <listitem> <para> List all services in Service Catalog. </para> </listitem> </varlistentry> <varlistentry> <term><command>tenant-create</command></term> <listitem> <para> Create new tenant. </para> </listitem> </varlistentry> <varlistentry> <term><command>tenant-delete</command></term> <listitem> <para> Delete tenant. </para> </listitem> </varlistentry> <varlistentry> <term><command>tenant-get</command></term> <listitem> <para> Display tenant details. </para> </listitem> </varlistentry> <varlistentry> <term><command>tenant-list</command></term> <listitem> <para> List all tenants. </para> </listitem> </varlistentry> <varlistentry> <term><command>tenant-update</command></term> <listitem> <para> Update tenant name, description, enabled status. </para> </listitem> </varlistentry> <varlistentry> <term><command>token-get</command></term> <listitem> <para> Display the current user token. </para> </listitem> </varlistentry> <varlistentry> <term><command>user-create</command></term> <listitem> <para> Create new user </para> </listitem> </varlistentry> <varlistentry> <term><command>user-delete</command></term> <listitem> <para> Delete user </para> </listitem> </varlistentry> <varlistentry> <term><command>user-get</command></term> <listitem> <para> Display user details. </para> </listitem> </varlistentry> <varlistentry> <term><command>user-list</command></term> <listitem> <para> List users. </para> </listitem> </varlistentry> <varlistentry> <term><command>user-password-update</command></term> <listitem> <para> Update user password. </para> </listitem> </varlistentry> <varlistentry> <term><command>user-role-add</command></term> <listitem> <para> Add role to user </para> </listitem> </varlistentry> <varlistentry> <term><command>user-role-list</command></term> <listitem> <para> List roles granted to a user </para> </listitem> </varlistentry> <varlistentry> <term><command>user-role-remove</command></term> <listitem> <para> Remove role from user </para> </listitem> </varlistentry> <varlistentry> <term><command>user-update</command></term> <listitem> <para> Update user's name, email, and enabled status. </para> </listitem> </varlistentry> <varlistentry> <term><command>discover</command></term> <listitem> <para> Discover Keystone servers, supported API versions and extensions. </para> </listitem> </varlistentry> <varlistentry> <term><command>bootstrap</command></term> <listitem> <para> Grants a new role to a new user on a new tenant, after creating each. </para> </listitem> </varlistentry> <varlistentry> <term><command>bash-completion</command></term> <listitem> <para> Prints all of the commands and options to stdout. </para> </listitem> </varlistentry> <varlistentry> <term><command>help</command></term> <listitem> <para> Display help about this program or one of its subcommands. </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <varlistentry> <term><command>--version</command></term> <listitem> <para> Shows the client version and exits </para> </listitem> </varlistentry> <varlistentry> <term><command>--timeout &lt;seconds&gt;</command></term> <listitem> <para> Set request timeout (in seconds) </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-username &lt;auth-user-name&gt;</command></term> <listitem> <para> Name used for authentication with the OpenStack Identity service. Defaults to env[OS_USERNAME] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-password &lt;auth-password&gt;</command></term> <listitem> <para> Password used for authentication with the OpenStack Identity service. Defaults to env[OS_PASSWORD] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-tenant-name &lt;auth-tenant-name&gt;</command></term> <listitem> <para> Tenant to request authorization on. Defaults to env[OS_TENANT_NAME] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-tenant-id &lt;tenant-id&gt;</command></term> <listitem> <para> Tenant to request authorization on. Defaults to env[OS_TENANT_ID] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-auth-url &lt;auth-url&gt;</command></term> <listitem> <para> Specify the Identity endpoint to use for authentication. Defaults to env[OS_AUTH_URL] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-region-name &lt;region-name&gt;</command></term> <listitem> <para> Defaults to env[OS_REGION_NAME] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-identity-api-version &lt;identity-api-version&gt;</command></term> <listitem> <para> Defaults to env[OS_IDENTITY_API_VERSION] or 2.0 </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-token &lt;service-token&gt;</command></term> <listitem> <para> Specify an existing token to use instead of retrieving one via authentication (e.g. with username &amp; password). Defaults to env[OS_SERVICE_TOKEN] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-endpoint &lt;service-endpoint&gt;</command></term> <listitem> <para> Specify an endpoint to use instead of retrieving one from the service catalog (via authentication). Defaults to env[OS_SERVICE_ENDPOINT] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-cacert &lt;ca-certificate&gt;</command></term> <listitem> <para> Specify a CA bundle file to use in verifying a TLS (https) server certificate. Defaults to env[OS_CACERT] </para> </listitem> </varlistentry> <varlistentry> <term><command>--insecure</command></term> <listitem> <para> Explicitly allow keystoneclient to perform ""insecure"" TLS (https) requests. The server's certificate will not be verified against any certificate authorities. This option should be used with caution. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-cert &lt;certificate&gt;</command></term> <listitem> <para> Defaults to env[OS_CERT] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-key &lt;key&gt;</command></term> <listitem> <para> Defaults to env[OS_KEY] </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-cache</command></term> <listitem> <para> Use the auth token cache. Defaults to env[OS_CACHE] </para> </listitem> </varlistentry> <varlistentry> <term><command>--force-new-token</command></term> <listitem> <para> If the keyring is available and in use, token will always be stored and fetched from the keyring until the token has expired. Use this option to request a new token and replace the existing one in the keyring. </para> </listitem> </varlistentry> <varlistentry> <term><command>--stale-duration &lt;seconds&gt;</command></term> <listitem> <para> Stale duration (in seconds) used to determine whether a token has expired when retrieving it from keyring. This is useful in mitigating process or network delays. Default is 30 seconds. </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone bootstrap [--user-name &lt;user-name&gt;] --pass &lt;password&gt; [--role-name &lt;role-name&gt;] [--tenant-name &lt;tenant-name&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user-name &lt;user-name&gt;</command></term> <listitem> <para> The name of the user to be created (default=""admin""). </para> </listitem> </varlistentry> <varlistentry> <term><command>--pass &lt;password&gt;</command></term> <listitem> <para> The password for the new user. </para> </listitem> </varlistentry> <varlistentry> <term><command>--role-name &lt;role-name&gt;</command></term> <listitem> <para> The name of the role to be created and granted to the user (default=""admin""). </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant-name &lt;tenant-name&gt;</command></term> <listitem> <para> The name of the tenant to be created (default=""admin""). </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone catalog [--service &lt;service-type&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--service &lt;service-type&gt;</command></term> <listitem> <para> Service type to return </para> </listitem> </varlistentry> </variablelist> </computeroutput></screen> <para> </para> </section> <screen><computeroutput>usage: keystone ec2-credentials-create [--user-id &lt;user-id&gt;] [--tenant-id &lt;tenant-id&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user-id &lt;user-id&gt;</command></term> <listitem> <para> User ID </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant-id &lt;tenant-id&gt;</command></term> <listitem> <para> Tenant ID </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone ec2-credentials-delete [--user-id &lt;user-id&gt;] --access &lt;access-key&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user-id &lt;user-id&gt;</command></term> <listitem> <para> User ID </para> </listitem> </varlistentry> <varlistentry> <term><command>--access &lt;access-key&gt;</command></term> <listitem> <para> Access Key </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone ec2-credentials-get [--user-id &lt;user-id&gt;] --access &lt;access-key&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user-id &lt;user-id&gt;</command></term> <listitem> <para> User ID </para> </listitem> </varlistentry> <varlistentry> <term><command>--access &lt;access-key&gt;</command></term> <listitem> <para> Access Key </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone ec2-credentials-list [--user-id &lt;user-id&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user-id &lt;user-id&gt;</command></term> <listitem> <para> User ID </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone endpoint-create [--region &lt;endpoint-region&gt;] --service &lt;service&gt; --publicurl &lt;public-url&gt; [--adminurl &lt;admin-url&gt;] [--internalurl &lt;internal-url&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--region &lt;endpoint-region&gt;</command></term> <listitem> <para> Endpoint region </para> </listitem> </varlistentry> <varlistentry> <term><command>--service &lt;service&gt;, --service-id &lt;service&gt;, --service_id &lt;service&gt;</command></term> <listitem> <para> Name or ID of service associated with Endpoint </para> </listitem> </varlistentry> <varlistentry> <term><command>--publicurl &lt;public-url&gt;</command></term> <listitem> <para> Public URL endpoint </para> </listitem> </varlistentry> <varlistentry> <term><command>--adminurl &lt;admin-url&gt;</command></term> <listitem> <para> Admin URL endpoint </para> </listitem> </varlistentry> <varlistentry> <term><command>--internalurl &lt;internal-url&gt;</command></term> <listitem> <para> Internal URL endpoint </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone endpoint-delete &lt;endpoint-id&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;endpoint-id&gt;</command></term> <listitem> <para> ID of endpoint to delete </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone endpoint-get --service &lt;service-type&gt; [--endpoint-type &lt;endpoint-type&gt;] [--attr &lt;service-attribute&gt;] [--value &lt;value&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--service &lt;service-type&gt;</command></term> <listitem> <para> Service type to select </para> </listitem> </varlistentry> <varlistentry> <term><command>--endpoint-type &lt;endpoint-type&gt;</command></term> <listitem> <para> Endpoint type to select </para> </listitem> </varlistentry> <varlistentry> <term><command>--attr &lt;service-attribute&gt;</command></term> <listitem> <para> Service attribute to match for selection </para> </listitem> </varlistentry> <varlistentry> <term><command>--value &lt;value&gt;</command></term> <listitem> <para> Value of attribute to match </para> </listitem> </varlistentry> </variablelist> </computeroutput></screen> <para> </para> </section> <screen><computeroutput>usage: keystone password-update [--current-password &lt;current-password&gt;] [--new-password &lt;new-password&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--current-password &lt;current-password&gt;</command></term> <listitem> <para> Current password, Defaults to the password as set by --os-password or OS_PASSWORD </para> </listitem> </varlistentry> <varlistentry> <term><command>--new-password &lt;new-password&gt;</command></term> <listitem> <para> Desired new password </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone role-create --name &lt;role-name&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;role-name&gt;</command></term> <listitem> <para> Name of new role </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone role-delete &lt;role&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;role&gt;</command></term> <listitem> <para> Name or ID of role to delete </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone role-get &lt;role&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;role&gt;</command></term> <listitem> <para> Name or ID of role to display </para> </listitem> </varlistentry> </variablelist> </computeroutput></screen> <para> </para> </section> <screen><computeroutput>usage: keystone service-create --name &lt;name&gt; --type &lt;type&gt; [--description &lt;service-description&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;name&gt;</command></term> <listitem> <para> Name of new service (must be unique) </para> </listitem> </varlistentry> <varlistentry> <term><command>--type &lt;type&gt;</command></term> <listitem> <para> Service type (one of: identity, compute, network, image, object-store, or other service identifier string) </para> </listitem> </varlistentry> <varlistentry> <term><command>--description &lt;service-description&gt;</command></term> <listitem> <para> Description of service </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone service-delete &lt;service&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;service&gt;</command></term> <listitem> <para> Name or ID of service to delete </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone service-get &lt;service&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;service&gt;</command></term> <listitem> <para> Name or ID of service to display </para> </listitem> </varlistentry> </variablelist> </computeroutput></screen> <para> </para> </section> <screen><computeroutput>usage: keystone tenant-create --name &lt;tenant-name&gt; [--description &lt;tenant-description&gt;] [--enabled &lt;true|false&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;tenant-name&gt;</command></term> <listitem> <para> New tenant name (must be unique) </para> </listitem> </varlistentry> <varlistentry> <term><command>--description &lt;tenant-description&gt;</command></term> <listitem> <para> Description of new tenant (default is none) </para> </listitem> </varlistentry> <varlistentry> <term><command>--enabled &lt;true|false&gt;</command></term> <listitem> <para> Initial tenant enabled status (default true) </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone tenant-delete &lt;tenant&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;tenant&gt;</command></term> <listitem> <para> Name or ID of tenant to delete </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone tenant-get &lt;tenant&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;tenant&gt;</command></term> <listitem> <para> Name or ID of tenant to display </para> </listitem> </varlistentry> </variablelist> </computeroutput></screen> <para> </para> </section> <screen><computeroutput>usage: keystone tenant-update [--name &lt;tenant_name&gt;] [--description &lt;tenant-description&gt;] [--enabled &lt;true|false&gt;] &lt;tenant&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;tenant_name&gt;</command></term> <listitem> <para> Desired new name of tenant </para> </listitem> </varlistentry> <varlistentry> <term><command>--description &lt;tenant-description&gt;</command></term> <listitem> <para> Desired new description of tenant </para> </listitem> </varlistentry> <varlistentry> <term><command>--enabled &lt;true|false&gt;</command></term> <listitem> <para> Enable or disable tenant </para> </listitem> </varlistentry> <varlistentry> <term><command>&lt;tenant&gt;</command></term> <listitem> <para> Name or ID of tenant to update </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone token-get [--wrap &lt;integer&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--wrap &lt;integer&gt;</command></term> <listitem> <para> wrap PKI tokens to a specified length, or 0 to disable </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-create --name &lt;user-name&gt; [--tenant &lt;tenant&gt;] [--pass &lt;pass&gt;] [--email &lt;email&gt;] [--enabled &lt;true|false&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;user-name&gt;</command></term> <listitem> <para> New user name (must be unique) </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant &lt;tenant&gt;, --tenant-id &lt;tenant&gt;</command></term> <listitem> <para> New user default tenant </para> </listitem> </varlistentry> <varlistentry> <term><command>--pass &lt;pass&gt;</command></term> <listitem> <para> New user password </para> </listitem> </varlistentry> <varlistentry> <term><command>--email &lt;email&gt;</command></term> <listitem> <para> New user email address </para> </listitem> </varlistentry> <varlistentry> <term><command>--enabled &lt;true|false&gt;</command></term> <listitem> <para> Initial user enabled status (default true) </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-delete &lt;user&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;user&gt;</command></term> <listitem> <para> Name or ID of user to delete </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-get &lt;user&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>&lt;user&gt;</command></term> <listitem> <para> Name or ID of user to display </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-list [--tenant &lt;tenant&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--tenant &lt;tenant&gt;, --tenant-id &lt;tenant&gt;</command></term> <listitem> <para> Tenant; lists all users if not specified </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-password-update [--pass &lt;password&gt;] &lt;user&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--pass &lt;password&gt;</command></term> <listitem> <para> Desired new password </para> </listitem> </varlistentry> <varlistentry> <term><command>&lt;user&gt;</command></term> <listitem> <para> Name or ID of user to update password </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-role-add --user &lt;user&gt; --role &lt;role&gt; [--tenant &lt;tenant&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user &lt;user&gt;, --user-id &lt;user&gt;, --user_id &lt;user&gt;</command></term> <listitem> <para> Name or ID of user </para> </listitem> </varlistentry> <varlistentry> <term><command>--role &lt;role&gt;, --role-id &lt;role&gt;, --role_id &lt;role&gt;</command></term> <listitem> <para> Name or ID of role </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant &lt;tenant&gt;, --tenant-id &lt;tenant&gt;</command></term> <listitem> <para> Name or ID of tenant </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-role-list [--user &lt;user&gt;] [--tenant &lt;tenant&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user &lt;user&gt;, --user-id &lt;user&gt;</command></term> <listitem> <para> List roles granted to a user </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant &lt;tenant&gt;, --tenant-id &lt;tenant&gt;</command></term> <listitem> <para> List roles granted on a tenant </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-role-remove --user &lt;user&gt; --role &lt;role&gt; [--tenant &lt;tenant&gt;] </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--user &lt;user&gt;, --user-id &lt;user&gt;, --user_id &lt;user&gt;</command></term> <listitem> <para> Name or ID of user </para> </listitem> </varlistentry> <varlistentry> <term><command>--role &lt;role&gt;, --role-id &lt;role&gt;, --role_id &lt;role&gt;</command></term> <listitem> <para> Name or ID of role </para> </listitem> </varlistentry> <varlistentry> <term><command>--tenant &lt;tenant&gt;, --tenant-id &lt;tenant&gt;</command></term> <listitem> <para> Name or ID of tenant </para> </listitem> </varlistentry> </variablelist> <screen><computeroutput>usage: keystone user-update [--name &lt;user-name&gt;] [--email &lt;email&gt;] [--enabled &lt;true|false&gt;] &lt;user&gt; </computeroutput></screen> <para> </para> <variablelist wordsize=""10""> <title>Arguments</title> <varlistentry> <term><command>--name &lt;user-name&gt;</command></term> <listitem> <para> Desired new user name </para> </listitem> </varlistentry> <varlistentry> <term><command>--email &lt;email&gt;</command></term> <listitem> <para> Desired new email address </para> </listitem> </varlistentry> <varlistentry> <term><command>--enabled &lt;true|false&gt;</command></term> <listitem> <para> Enable or disable user </para> </listitem> </varlistentry> <varlistentry> <term><command>&lt;user&gt;</command></term> <listitem> <para> Name or ID of user to update </para> </listitem> </varlistentry> </variablelist>"," <screen><computeroutput> [--os-username &lt;auth-user-name>] [--os-password &lt;auth-password>] [--os-tenant-name &lt;auth-tenant-name>] [--os-tenant-id &lt;tenant-id>] [--os-auth-url &lt;auth-url>] [--os-region-name &lt;region-name>] [--os-identity-api-version &lt;identity-api-version>] [--os-token &lt;service-token>] [--os-endpoint &lt;service-endpoint>] [--os-cacert &lt;ca-certificate>] [--insecure] [--os-cert &lt;certificate>] [--os-key &lt;key>] [--os-cache] [--force-new-token] [--stale-duration &lt;seconds>] &lt;subcommand> ...</computeroutput></screen> </section> <section xml:id=""keystoneclient_command_pos""> <title>keystone positional arguments</title> <screen><computeroutput> &lt;subcommand> catalog List service catalog, possibly filtered by service. ec2-credentials-create Create EC2-compatible credentials for user per tenant. ec2-credentials-delete Delete EC2-compatible credentials. ec2-credentials-get Display EC2-compatible credentials. ec2-credentials-list List EC2-compatible credentials for a user endpoint-create Create a new endpoint associated with a service. endpoint-delete Delete a service endpoint. endpoint-get Find endpoint filtered by a specific attribute or service type. endpoint-list List configured service endpoints. password-update Update own password. role-create Create new role. role-delete Delete role. role-get Display role details. role-list List all roles. service-create Add service to Service Catalog. service-delete Delete service from Service Catalog. service-get Display service from Service Catalog. service-list List all services in Service Catalog. tenant-create Create new tenant. tenant-delete Delete tenant. tenant-get Display tenant details. tenant-list List all tenants. tenant-update Update tenant name, description, enabled status. token-get Display the current user token. user-create Create new user user-delete Delete user user-get Display user details. user-list List users. user-password-update Update user password. user-role-add Add role to user user-role-list List roles granted to a user user-role-remove Remove role from user user-update Update user's name, email, and enabled status. discover Discover Keystone servers, supported API versions and extensions. bootstrap Grants a new role to a new user on a new tenant, after creating each. bash-completion Prints all of the commands and options to stdout. help Display help about this program or one of its subcommands. <screen><computeroutput> --version Shows the client version and exits --timeout &lt;seconds> Set request timeout (in seconds) --os-username &lt;auth-user-name> Name used for authentication with the OpenStack Identity service. Defaults to env[OS_USERNAME] --os-password &lt;auth-password> Password used for authentication with the OpenStack Identity service. Defaults to env[OS_PASSWORD] --os-tenant-name &lt;auth-tenant-name> Tenant to request authorization on. Defaults to env[OS_TENANT_NAME] --os-tenant-id &lt;tenant-id> Tenant to request authorization on. Defaults to env[OS_TENANT_ID] --os-auth-url &lt;auth-url> Specify the Identity endpoint to use for authentication. Defaults to env[OS_AUTH_URL] --os-region-name &lt;region-name> Defaults to env[OS_REGION_NAME] --os-identity-api-version &lt;identity-api-version> Defaults to env[OS_IDENTITY_API_VERSION] or 2.0 --os-token &lt;service-token> Specify an existing token to use instead of retrieving one via authentication (e.g. with username &amp; password). Defaults to env[OS_SERVICE_TOKEN] --os-endpoint &lt;service-endpoint> Specify an endpoint to use instead of retrieving one from the service catalog (via authentication). Defaults to env[OS_SERVICE_ENDPOINT] --os-cacert &lt;ca-certificate> Specify a CA bundle file to use in verifying a TLS (https) server certificate. Defaults to env[OS_CACERT] --insecure Explicitly allow keystoneclient to perform ""insecure"" TLS (https) requests. The server's certificate will not be verified against any certificate authorities. This option should be used with caution. --os-cert &lt;certificate> Defaults to env[OS_CERT] --os-key &lt;key> Defaults to env[OS_KEY] --os-cache Use the auth token cache. Defaults to env[OS_CACHE] --force-new-token If the keyring is available and in use, token will always be stored and fetched from the keyring until the token has expired. Use this option to request a new token and replace the existing one in the keyring. --stale-duration &lt;seconds> Stale duration (in seconds) used to determine whether a token has expired when retrieving it from keyring. This is useful in mitigating process or network delays. Default is 30 seconds. </computeroutput></screen> <screen><computeroutput>usage: keystone bootstrap [--user-name &lt;user-name>] --pass &lt;password> [--role-name &lt;role-name>] [--tenant-name &lt;tenant-name>] Arguments: --user-name &lt;user-name> The name of the user to be created (default=""admin""). --pass &lt;password> The password for the new user. --role-name &lt;role-name> The name of the role to be created and granted to the user (default=""admin""). --tenant-name &lt;tenant-name> The name of the tenant to be created (default=""admin""). </computeroutput></screen> <screen><computeroutput>usage: keystone catalog [--service &lt;service-type>] Arguments: --service &lt;service-type> Service type to return </computeroutput></screen> </computeroutput></screen> </section> <screen><computeroutput>usage: keystone ec2-credentials-create [--user-id &lt;user-id>] [--tenant-id &lt;tenant-id>] Arguments: --user-id &lt;user-id> User ID --tenant-id &lt;tenant-id> Tenant ID </computeroutput></screen> <screen><computeroutput>usage: keystone ec2-credentials-delete [--user-id &lt;user-id>] --access &lt;access-key> Arguments: --user-id &lt;user-id> User ID --access &lt;access-key> Access Key </computeroutput></screen> <screen><computeroutput>usage: keystone ec2-credentials-get [--user-id &lt;user-id>] --access &lt;access-key> Arguments: --user-id &lt;user-id> User ID --access &lt;access-key> Access Key </computeroutput></screen> <screen><computeroutput>usage: keystone ec2-credentials-list [--user-id &lt;user-id>] Arguments: --user-id &lt;user-id> User ID </computeroutput></screen> <screen><computeroutput>usage: keystone endpoint-create [--region &lt;endpoint-region>] --service &lt;service> --publicurl &lt;public-url> [--adminurl &lt;admin-url>] [--internalurl &lt;internal-url>] Arguments: --region &lt;endpoint-region> Endpoint region --service &lt;service>, --service-id &lt;service>, --service_id &lt;service> Name or ID of service associated with Endpoint --publicurl &lt;public-url> Public URL endpoint --adminurl &lt;admin-url> Admin URL endpoint --internalurl &lt;internal-url> Internal URL endpoint </computeroutput></screen> <screen><computeroutput>usage: keystone endpoint-delete &lt;endpoint-id> Arguments: &lt;endpoint-id> ID of endpoint to delete </computeroutput></screen> <screen><computeroutput>usage: keystone endpoint-get --service &lt;service-type> [--endpoint-type &lt;endpoint-type>] [--attr &lt;service-attribute>] [--value &lt;value>] Arguments: --service &lt;service-type> Service type to select --endpoint-type &lt;endpoint-type> Endpoint type to select --attr &lt;service-attribute> Service attribute to match for selection --value &lt;value> Value of attribute to match </computeroutput></screen> </computeroutput></screen> </section> <screen><computeroutput>usage: keystone password-update [--current-password &lt;current-password>] [--new-password &lt;new-password>] Arguments: --current-password &lt;current-password> Current password, Defaults to the password as set by --os-password or OS_PASSWORD --new-password &lt;new-password> Desired new password </computeroutput></screen> <screen><computeroutput>usage: keystone role-create --name &lt;role-name> Arguments: --name &lt;role-name> Name of new role </computeroutput></screen> <screen><computeroutput>usage: keystone role-delete &lt;role> Arguments: &lt;role> Name or ID of role to delete </computeroutput></screen> <screen><computeroutput>usage: keystone role-get &lt;role> Arguments: &lt;role> Name or ID of role to display </computeroutput></screen> </computeroutput></screen> </section> <screen><computeroutput>usage: keystone service-create --name &lt;name> --type &lt;type> [--description &lt;service-description>] Arguments: --name &lt;name> Name of new service (must be unique) --type &lt;type> Service type (one of: identity, compute, network, image, object-store, or other service identifier string) --description &lt;service-description> Description of service </computeroutput></screen> <screen><computeroutput>usage: keystone service-delete &lt;service> Arguments: &lt;service> Name or ID of service to delete </computeroutput></screen> <screen><computeroutput>usage: keystone service-get &lt;service> Arguments: &lt;service> Name or ID of service to display </computeroutput></screen> </computeroutput></screen> </section> <screen><computeroutput>usage: keystone tenant-create --name &lt;tenant-name> [--description &lt;tenant-description>] [--enabled &lt;true|false>] Arguments: --name &lt;tenant-name> New tenant name (must be unique) --description &lt;tenant-description> Description of new tenant (default is none) --enabled &lt;true|false> Initial tenant enabled status (default true) </computeroutput></screen> <screen><computeroutput>usage: keystone tenant-delete &lt;tenant> Arguments: &lt;tenant> Name or ID of tenant to delete </computeroutput></screen> <screen><computeroutput>usage: keystone tenant-get &lt;tenant> Arguments: &lt;tenant> Name or ID of tenant to display </computeroutput></screen> </computeroutput></screen> </section> <screen><computeroutput>usage: keystone tenant-update [--name &lt;tenant_name>] [--description &lt;tenant-description>] [--enabled &lt;true|false>] &lt;tenant> Arguments: --name &lt;tenant_name> Desired new name of tenant --description &lt;tenant-description> Desired new description of tenant --enabled &lt;true|false> Enable or disable tenant &lt;tenant> Name or ID of tenant to update </computeroutput></screen> <screen><computeroutput>usage: keystone token-get [--wrap &lt;integer>] Arguments: --wrap &lt;integer> wrap PKI tokens to a specified length, or 0 to disable </computeroutput></screen> <screen><computeroutput>usage: keystone user-create --name &lt;user-name> [--tenant &lt;tenant>] [--pass &lt;pass>] [--email &lt;email>] [--enabled &lt;true|false>] Arguments: --name &lt;user-name> New user name (must be unique) --tenant &lt;tenant>, --tenant-id &lt;tenant> New user default tenant --pass &lt;pass> New user password --email &lt;email> New user email address --enabled &lt;true|false> Initial user enabled status (default true) </computeroutput></screen> <screen><computeroutput>usage: keystone user-delete &lt;user> Arguments: &lt;user> Name or ID of user to delete </computeroutput></screen> <screen><computeroutput>usage: keystone user-get &lt;user> Arguments: &lt;user> Name or ID of user to display </computeroutput></screen> <screen><computeroutput>usage: keystone user-list [--tenant &lt;tenant>] Arguments: --tenant &lt;tenant>, --tenant-id &lt;tenant> Tenant; lists all users if not specified </computeroutput></screen> <screen><computeroutput>usage: keystone user-password-update [--pass &lt;password>] &lt;user> Arguments: --pass &lt;password> Desired new password &lt;user> Name or ID of user to update password </computeroutput></screen> <screen><computeroutput>usage: keystone user-role-add --user &lt;user> --role &lt;role> [--tenant &lt;tenant>] Arguments: --user &lt;user>, --user-id &lt;user>, --user_id &lt;user> Name or ID of user --role &lt;role>, --role-id &lt;role>, --role_id &lt;role> Name or ID of role --tenant &lt;tenant>, --tenant-id &lt;tenant> Name or ID of tenant </computeroutput></screen> <screen><computeroutput>usage: keystone user-role-list [--user &lt;user>] [--tenant &lt;tenant>] Arguments: --user &lt;user>, --user-id &lt;user> List roles granted to a user --tenant &lt;tenant>, --tenant-id &lt;tenant> List roles granted on a tenant </computeroutput></screen> <screen><computeroutput>usage: keystone user-role-remove --user &lt;user> --role &lt;role> [--tenant &lt;tenant>] Arguments: --user &lt;user>, --user-id &lt;user>, --user_id &lt;user> Name or ID of user --role &lt;role>, --role-id &lt;role>, --role_id &lt;role> Name or ID of role --tenant &lt;tenant>, --tenant-id &lt;tenant> Name or ID of tenant </computeroutput></screen> <screen><computeroutput>usage: keystone user-update [--name &lt;user-name>] [--email &lt;email>] [--enabled &lt;true|false>] &lt;user> Arguments: --name &lt;user-name> Desired new user name --email &lt;email> Desired new email address --enabled &lt;true|false> Enable or disable user &lt;user> Name or ID of user to update </computeroutput></screen>",1214,437
openstack%2Fopenstack-manuals~master~Id875d132dc25c076f320e118c41d9b935ffdedf4,openstack/openstack-manuals,master,Id875d132dc25c076f320e118c41d9b935ffdedf4,Add cli-reference to local-files.html,MERGED,2014-01-31 15:34:52.000000000,2014-01-31 19:55:40.000000000,2014-01-31 19:55:39.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-01-31 15:34:52.000000000', 'files': ['doc/local-files.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5c0a2ffb31a820d31821e383c838c5a2a97a83e2', 'message': 'Add cli-reference to local-files.html\n\nAdd entry for cli-reference for easier viewing.\n\nChange-Id: Id875d132dc25c076f320e118c41d9b935ffdedf4\n'}]",0,70365,5c0a2ffb31a820d31821e383c838c5a2a97a83e2,5,2,1,6547,,,0,"Add cli-reference to local-files.html

Add entry for cli-reference for easier viewing.

Change-Id: Id875d132dc25c076f320e118c41d9b935ffdedf4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/70365/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/local-files.html'],1,5c0a2ffb31a820d31821e383c838c5a2a97a83e2,cli-local-files," <dd><a href=""cli-reference/target/docbkx/webhelp/cli-reference/content/index.html"" >Command Line Interface Reference</a></dd>",,3,0
openstack%2Fopenstack-doc-tools~master~Id43470e0930a3a447f1e7ab63e956541984bce0e,openstack/openstack-doc-tools,master,Id43470e0930a3a447f1e7ab63e956541984bce0e,Verify that resources have xml:id,MERGED,2014-01-31 19:03:20.000000000,2014-01-31 19:50:49.000000000,2014-01-31 19:50:49.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 19:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/6854539fb2ccc30f20037873054bd6d9b49c1adf', 'message': 'Verify that resources have xml:id\n\nAdd validation check for WADL files to ensure they contain an xml:id at\nthe parent resources. This is a new requirement that has to do with the\ngeneration of PDFs from WADL files  without this, the paths are not\nunique across WADL files.\n\nChange-Id: Id43470e0930a3a447f1e7ab63e956541984bce0e\nCloses-Bug: #1275007\n'}, {'number': 2, 'created': '2014-01-31 19:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/6b4999a5310816dff7a6043f177525b6aff56fc0', 'message': 'Verify that resources have xml:id\n\nAdd validation check for WADL files to ensure they contain an xml:id at\nthe parent resources. This is a new requirement that has to do with the\ngeneration of PDFs from WADL files  without this, the paths are not\nunique across WADL files.\n\nChange-Id: Id43470e0930a3a447f1e7ab63e956541984bce0e\nCloses-Bug: #1275007\n'}, {'number': 3, 'created': '2014-01-31 19:46:59.000000000', 'files': ['os_doc_tools/doctest.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/2e87f673241c6fc2670b5a97adfb8cdc22080b85', 'message': 'Verify that resources have xml:id\n\nAdd validation check for WADL files to ensure they contain an xml:id at\nthe parent resources. This is a new requirement that has to do with the\ngeneration of PDFs from WADL files  without this, the paths are not\nunique across WADL files.\n\nChange-Id: Id43470e0930a3a447f1e7ab63e956541984bce0e\nCloses-Bug: #1275007\n'}]",0,70401,2e87f673241c6fc2670b5a97adfb8cdc22080b85,9,3,3,6547,,,0,"Verify that resources have xml:id

Add validation check for WADL files to ensure they contain an xml:id at
the parent resources. This is a new requirement that has to do with the
generation of PDFs from WADL files  without this, the paths are not
unique across WADL files.

Change-Id: Id43470e0930a3a447f1e7ab63e956541984bce0e
Closes-Bug: #1275007
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/01/70401/2 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,6854539fb2ccc30f20037873054bd6d9b49c1adf,wadl-resources,"def verify_resources_tags_have_xmid(doc): """"""Check that all resources tags have an xml:id attribute Will throw an exception if there's at least one missing. """""" ns = {""wadl"": ""http://wadl.dev.java.net/2009/02""} for node in doc.xpath('//wadl:resources', namespaces=ns): if ""{http://www.w3.org/XML/1998/namespace}id"" not in node.attrib: raise ValueError(""resources missing xml:id attribute, line %d"" % node.sourceline) if is_wadl(path): verify_resources_tags_have_xmid(doc)",,12,0
openstack%2Fopenstack-manuals~master~Ifcc9cccf8a5e74f115761164b1e970aaa62bb89d,openstack/openstack-manuals,master,Ifcc9cccf8a5e74f115761164b1e970aaa62bb89d,minor edit to ceph-rbd-volume-driver.xml,MERGED,2014-01-30 18:11:53.000000000,2014-01-31 19:44:52.000000000,2014-01-31 19:44:51.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6838}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-01-30 18:11:53.000000000', 'files': ['doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/41879c06f0fab5efc576bb57f506d0137c84fcdb', 'message': 'minor edit to ceph-rbd-volume-driver.xml\n\nremoved plural disks to disk - referring to single\n\nChange-Id: Ifcc9cccf8a5e74f115761164b1e970aaa62bb89d\n'}]",0,70180,41879c06f0fab5efc576bb57f506d0137c84fcdb,8,5,1,9382,,,0,"minor edit to ceph-rbd-volume-driver.xml

removed plural disks to disk - referring to single

Change-Id: Ifcc9cccf8a5e74f115761164b1e970aaa62bb89d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/70180/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml'],1,41879c06f0fab5efc576bb57f506d0137c84fcdb,Cleanup_ceph-rbd-volume-driver," disk. For performance purposes, pool your hard"," disks. For performance purposes, pool your hard",1,1
openstack%2Fnova~master~I56481f488e55f6f0a75f15925126ca573de1693b,openstack/nova,master,I56481f488e55f6f0a75f15925126ca573de1693b,WIP Rough outline of instance tasks,ABANDONED,2014-01-24 19:41:31.000000000,2014-01-31 19:43:57.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-24 19:41:31.000000000', 'files': ['nova/objects/instance_task.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/api/openstack/compute/plugins/v3/instance_tasks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e93d218c6df98d407e278016fda67bcdaff260ed', 'message': ""WIP Rough outline of instance tasks\n\nThis adds an instance task for reboot to provide a rough outline of how\nit may look.  The db is missing, the task link isn't returned from the\nreboot api call, and cells support is missing.\n\nThe task has been pulled out of the instance and is passed separately to\nmove towards tasks driving changes on instances, not the other way\naround.\n\nChange-Id: I56481f488e55f6f0a75f15925126ca573de1693b\n""}]",0,68994,e93d218c6df98d407e278016fda67bcdaff260ed,6,3,1,5441,,,0,"WIP Rough outline of instance tasks

This adds an instance task for reboot to provide a rough outline of how
it may look.  The db is missing, the task link isn't returned from the
reboot api call, and cells support is missing.

The task has been pulled out of the instance and is passed separately to
move towards tasks driving changes on instances, not the other way
around.

Change-Id: I56481f488e55f6f0a75f15925126ca573de1693b
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/68994/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance_task.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/api/openstack/compute/plugins/v3/instance_tasks.py']",5,e93d218c6df98d407e278016fda67bcdaff260ed,instance_tasks,"# Copyright 2014 Rackspace Hosting # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from webob import exc from nova.api.openstack import extensions from nova.api.openstack import wsgi from nova import compute from nova import exception from nova.openstack.common.gettextutils import _ ALIAS = ""os-instance-tasks"" authorize = extensions.extension_authorizer('compute', 'v3:' + ALIAS) class InstanceTasksController(wsgi.Controller): def __init__(self): super(InstanceTasksController, self).__init__() self.compute_api = compute.API() self.task_api = compute.InstanceTaskAPI() @extensions.expected_errors(404) def index(self, req, server_id): """"""Returns the list of tasks recorded for a given instance."""""" context = req.environ[""nova.context""] try: instance = self.compute_api.get(context, server_id) except exception.InstanceNotFound as err: raise exc.HTTPNotFound(explanation=err.format_message()) authorize(context, target=instance) tasks = self.tasks_api.get(context, instance) return {'instance_tasks': tasks} @extensions.expected_errors(404) def show(self, req, server_id, id): """"""Return data about the given instance task."""""" context = req.environ['nova.context'] try: instance = self.compute_api.get(context, server_id) except exception.InstanceNotFound as err: raise exc.HTTPNotFound(explanation=err.format_message()) authorize(context, target=instance) task = self.tasks_api.get_by_uuid(context, instance, id) if task is None: msg = _(""Task %s not found"") % id raise exc.HTTPNotFound(msg) return {'instance_task': task} class InstanceTasks(extensions.V3APIExtensionBase): """"""View a log of tasks performed on an instance."""""" name = ""InstanceTasks"" alias = ALIAS namespace = (""http://docs.openstack.org/compute/ext/"" ""instance-tasks/api/v3"") version = 1 def get_resources(self): ext = extensions.ResourceExtension('os-instance-tasks', InstanceTasksController(), parent=dict( member_name='server', collection_name='servers')) return [ext] def get_controller_extensions(self): """"""It's an abstract function V3APIExtensionBase and the extension will not be loaded without it. """""" return [] ",,176,6
openstack%2Fopenstack-doc-tools~master~Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048,openstack/openstack-doc-tools,master,Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048,Improve docbook format for cli commands,MERGED,2014-01-31 11:14:57.000000000,2014-01-31 19:35:09.000000000,2014-01-31 19:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 11:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/73c7b30e3e4747ebb6b8326bc6e94d088e652267', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}, {'number': 2, 'created': '2014-01-31 12:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/4c2c0f9a3b8ef54aee785cef0691e7ce421bac85', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nCloses-Bug: #1274699\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}, {'number': 3, 'created': '2014-01-31 15:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/14d95d38ecf075360dc1c8ddbc4a7bc9dd0c1174', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nCloses-Bug: #1274699\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}, {'number': 4, 'created': '2014-01-31 16:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/fa38fd9de7ba651f469f3634ba8e6fdc074e8e5d', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nCloses-Bug: #1274699\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}, {'number': 5, 'created': '2014-01-31 17:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/25f1ab646696fc54472f3704c8e40c626c506dd7', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nCloses-Bug: #1274699\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}, {'number': 6, 'created': '2014-01-31 18:48:25.000000000', 'files': ['README.rst', 'autogenerate_config_docs/common.py', 'os_doc_tools/commands.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/0863f76f20856e459715c6084691ceb21a640e9c', 'message': 'Improve docbook format for cli commands\n\nThanks to Diane for a great proposal!\n\nAlso fixes autogenerate_config_docs/common.py to pass pep8 check.\n\nCloses-Bug: #1274699\nChange-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048\n'}]",0,70328,0863f76f20856e459715c6084691ceb21a640e9c,16,2,6,6547,,,0,"Improve docbook format for cli commands

Thanks to Diane for a great proposal!

Also fixes autogenerate_config_docs/common.py to pass pep8 check.

Closes-Bug: #1274699
Change-Id: Ic7b9cacc99a8bdf39c7a0f7e429d9f538370f048
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/28/70328/3 && git format-patch -1 --stdout FETCH_HEAD,"['autogenerate_config_docs/common.py', 'os_doc_tools/commands.py']",2,73c7b30e3e4747ebb6b8326bc6e94d088e652267,improve-cli," return line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')def extract_options(line): """"""Extract command or option from line."""""" # We have a command or parameter to handle # Differentiate: # 1. --version # 2. --timeout <seconds> # 3. --service <service>, --service-id <service> split_line = line.split(None, 2) if len(split_line) > 1 and '<' in split_line[1]: split_line[0] = split_line[0] + ' ' + split_line[1] if len(split_line) == 3: split_line[1] = split_line[2] del split_line[2] else: del split_line[1] # Check for "" --service-id"" if (len(split_line) > 1 and split_line[1].lstrip(' ').startswith('--')): print(""found %s"" % split_line[1]) nsplit_line = extract_options(split_line[1]) split_line[0] = split_line[0] + ' ' + nsplit_line[0] if len(nsplit_line) > 1: split_line[1] = nsplit_line[1] else: del split_line[1] else: split_line = line.split(None, 1) return split_line def format_table(title, lines, os_file): """"""Nicely print section of lines."""""" close_entry = False os_file.write("" <variablelist wordsize=\""10\"">\n"") if len(title) > 0: os_file.write("" <title>%s</title>\n"" % title) for line in lines: if len(line) == 0 or line[0] != ' ': break # We have to handle these cases: # 1. command Explanation # 2. command # Explanation on next line # 3. command Explanation continued # on next line # If there are more than 8 spaces, let's treat it as # explanation. if line.startswith(' '): # Explanation os_file.write("" %s\n"" % quote_xml(line.lstrip(' '))) continue # Now we have a command or parameter to handle split_line = extract_options(line) if not close_entry: close_entry = True else: os_file.write("" </para>\n"") os_file.write("" </listitem>\n"") os_file.write("" </varlistentry>\n"") os_file.write("" <varlistentry>\n"") os_file.write("" <term><command>%s</command></term>\n"" % quote_xml(split_line[0])) os_file.write("" <listitem>\n"") os_file.write("" <para>\n"") if len(split_line) > 1: os_file.write("" %s\n"" % quote_xml(split_line[1])) os_file.write("" </para>\n"") os_file.write("" </listitem>\n"") os_file.write("" </varlistentry>\n"") os_file.write("" </variablelist>\n"") return line_index = -1 for line in help_lines: line_index += 1 # XXX: Might have whitespace before!! if '<subcommands>' in line: ignore_next_lines = True os_file.write(""</computeroutput></screen>\n"") format_table('Subcommands', help_lines[line_index + 2:], os_file) format_table('', help_lines[line_index + 1:], os_file) ignore_next_lines = True #os_file.write(""</computeroutput></screen>\n"") line_index = -1 # Content is: # usage... # # Description # # Arguments in_para = False for line in help_lines: line_index += 1 if line.startswith(('Arguments:', 'Positional arguments:')): in_para = False os_file.write("" </para>"") format_table('Arguments', help_lines[line_index + 1:], os_file) break if len(line) == 0: if not in_para: os_file.write("" </computeroutput></screen>\n"") os_file.write("" <para>\n"") in_para = True continue if in_para: os_file.write("" </para>"")"," return line.replace('&', '&amp;').replace('<', '&lt;') for line in help_lines: if '<subcommand>' in line: ignore_next_lines = False os_file.write(""</computeroutput></screen>\n"") ignore_next_lines = False os_file.write(""</computeroutput></screen>\n"") if '<subcommand> ...' in line: os_file.write(""%s</computeroutput></screen>\n"" % xline) os_file.write("" </section>\n"") os_file.write("" <section xml:id=\""%sclient_command_pos\"">\n"" % os_command) os_file.write("" <title>%s positional arguments</title>\n"" % os_command) ignore_next_lines = True continue os_file.write(""</computeroutput></screen>\n"") for line in help_lines: os_file.write(""</computeroutput></screen>\n"")",122,22
openstack%2Fnova~master~I83deae464518fef5abe8fc00bfd0a186de01527b,openstack/nova,master,I83deae464518fef5abe8fc00bfd0a186de01527b,Allow deleting instances while uuid lock is held,MERGED,2014-01-30 18:45:31.000000000,2014-01-31 19:07:11.000000000,2014-01-31 19:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 1561}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-30 18:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c32262e7a027c393ba2640cadf263951dc961d9', 'message': ""Allow deleting instances while uuid lock is held\n\nAvoid issues where locked up operations on the instance prevent it\nfrom being deleted by the user. Reasons for the lock up are a separate\nissue and will be handled elsewhere, but terminating the instance\nshould not affect any tasks anyway. Any modification should already\ngracefully handle the instance going away.\n\nFor more discussion about the issue see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-October/017454.html\n\nThis patch was merged once before and had to be reverted in\n6b7304d8d38c0f04643bdcd031d682c688c91b28.  It was causing an extremely\nlarge number of errors in gate jobs.  I believe that the case being hit\nshould be expected with this patch in place, and that it's actually OK.\nWe expect that the rest of the code will handle this case gracefully.\nSimply remove this error message from the code.\n\nChange-Id: I83deae464518fef5abe8fc00bfd0a186de01527b\nPartial-Bug: #1248563\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\n""}, {'number': 2, 'created': '2014-01-31 00:27:14.000000000', 'files': ['nova/network/manager.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/08beabc5e0fc3fffc074a634040f5821d4d1d5f2', 'message': ""Allow deleting instances while uuid lock is held\n\nAvoid issues where locked up operations on the instance prevent it\nfrom being deleted by the user. Reasons for the lock up are a separate\nissue and will be handled elsewhere, but terminating the instance\nshould not affect any tasks anyway. Any modification should already\ngracefully handle the instance going away.\n\nFor more discussion about the issue see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-October/017454.html\n\nThis patch was merged once before and had to be reverted in\n6b7304d8d38c0f04643bdcd031d682c688c91b28.  It was causing an extremely\nlarge number of errors in gate jobs.  I believe that the case being hit\nshould be expected with this patch in place, and that it's actually OK.\nWe expect that the rest of the code will handle this case gracefully.\nSimply remove this error message from the code.\n\nChange-Id: I83deae464518fef5abe8fc00bfd0a186de01527b\nPartial-Bug: #1248563\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\n""}]",1,70187,08beabc5e0fc3fffc074a634040f5821d4d1d5f2,22,6,2,1561,,,0,"Allow deleting instances while uuid lock is held

Avoid issues where locked up operations on the instance prevent it
from being deleted by the user. Reasons for the lock up are a separate
issue and will be handled elsewhere, but terminating the instance
should not affect any tasks anyway. Any modification should already
gracefully handle the instance going away.

For more discussion about the issue see:
http://lists.openstack.org/pipermail/openstack-dev/2013-October/017454.html

This patch was merged once before and had to be reverted in
6b7304d8d38c0f04643bdcd031d682c688c91b28.  It was causing an extremely
large number of errors in gate jobs.  I believe that the case being hit
should be expected with this patch in place, and that it's actually OK.
We expect that the rest of the code will handle this case gracefully.
Simply remove this error message from the code.

Change-Id: I83deae464518fef5abe8fc00bfd0a186de01527b
Partial-Bug: #1248563
Co-authored-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/70187/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/compute/manager.py']",2,4c32262e7a027c393ba2640cadf263951dc961d9,async-delete," @utils.synchronized(instance['uuid'] + "".delete"")", @utils.synchronized(instance['uuid']),6,7
openstack%2Fceilometer~stable%2Fgrizzly~I11fe95c6295583b8cbf44eec5bf1d94b87e5dc98,openstack/ceilometer,stable/grizzly,I11fe95c6295583b8cbf44eec5bf1d94b87e5dc98,Don't allow qpid receiving thread to die,MERGED,2014-01-20 14:16:40.000000000,2014-01-31 19:06:57.000000000,2014-01-31 19:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-01-20 14:16:40.000000000', 'files': ['ceilometer/openstack/common/excutils.py', 'ceilometer/openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6b3d2410b1c9325db177fd8aa249228883477e0b', 'message': ""Don't allow qpid receiving thread to die\n\nOriginal-bug: #1189711\n\nThis patch is a partial backport of\n22ec8ff616a799085239e3e529daeeefea6366c4 in oslo-incubator.\n\nThis patch ensures that the thread created by consume_in_thread() can\nnot be killed off by an unexpected exception.\n\nChange-Id: I11fe95c6295583b8cbf44eec5bf1d94b87e5dc98\n""}]",0,67838,6b3d2410b1c9325db177fd8aa249228883477e0b,11,7,1,2284,,,0,"Don't allow qpid receiving thread to die

Original-bug: #1189711

This patch is a partial backport of
22ec8ff616a799085239e3e529daeeefea6366c4 in oslo-incubator.

This patch ensures that the thread created by consume_in_thread() can
not be killed off by an unexpected exception.

Change-Id: I11fe95c6295583b8cbf44eec5bf1d94b87e5dc98
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/38/67838/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/excutils.py', 'ceilometer/openstack/common/rpc/impl_qpid.py']",2,6b3d2410b1c9325db177fd8aa249228883477e0b,,from ceilometer.openstack.common import excutils @excutils.forever_retry_uncaught_exceptions,,34,0
openstack%2Fheat~master~If00c4de41dc24f462af0b32b29cd6d70f314f3bf,openstack/heat,master,If00c4de41dc24f462af0b32b29cd6d70f314f3bf,Map the NotFound exception to HTTPNotFound,MERGED,2014-01-31 03:49:35.000000000,2014-01-31 19:06:48.000000000,2014-01-31 19:06:47.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-01-31 03:49:35.000000000', 'files': ['heat/api/middleware/fault.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/759b46259c29de812e9db9cc45238fe646b1d42b', 'message': 'Map the NotFound exception to HTTPNotFound\n\nNow if the DB API raises a NotFound which propagates\nto the REST response, the user will receive a 404.\n\nThis seems to be a better default behaviour than a 500,\nand other behaviours can be handled by catching NotFound\nin service.py\n\nThis change is needed for the SoftwareDeployment resource\nto do our usual ignore-404-on-handle_delete behaviour.\n\nChange-Id: If00c4de41dc24f462af0b32b29cd6d70f314f3bf\n'}]",0,70288,759b46259c29de812e9db9cc45238fe646b1d42b,8,5,1,4571,,,0,"Map the NotFound exception to HTTPNotFound

Now if the DB API raises a NotFound which propagates
to the REST response, the user will receive a 404.

This seems to be a better default behaviour than a 500,
and other behaviours can be handled by catching NotFound
in service.py

This change is needed for the SoftwareDeployment resource
to do our usual ignore-404-on-handle_delete behaviour.

Change-Id: If00c4de41dc24f462af0b32b29cd6d70f314f3bf
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/70288/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/api/middleware/fault.py'],1,759b46259c29de812e9db9cc45238fe646b1d42b,not-found," 'NotFound': webob.exc.HTTPNotFound,",,1,0
openstack%2Fnova~master~Ib617aa82651923ebb2824edf5ff5008f61898bfb,openstack/nova,master,Ib617aa82651923ebb2824edf5ff5008f61898bfb,vmwareapi:remove unused variables in volumeops,MERGED,2014-01-08 11:46:30.000000000,2014-01-31 19:05:50.000000000,2014-01-31 19:05:46.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 7575}, {'_account_id': 7629}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-01-08 11:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5715bd8d2dd3e4d2ae13c3ed94bd264328b32d9', 'message': 'vmwareapi:remove unused variables in volumeops\n\nVariables instance_name were not used in two methods,\nLet remove them.\n\nChange-Id: Ib617aa82651923ebb2824edf5ff5008f61898bfb\n'}, {'number': 2, 'created': '2014-01-08 11:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7aac21cca04960204e7b29a780bedb4c781b11d1', 'message': 'vmwareapi:remove unused variables in volumeops\n\nVariables instance_name were not used in two methods,\nLet us remove them.\n\nChange-Id: Ib617aa82651923ebb2824edf5ff5008f61898bfb\n'}, {'number': 3, 'created': '2014-01-08 11:52:10.000000000', 'files': ['nova/virt/vmwareapi/volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c217249e719642f9a797ba2ea770d4a3c4a38d81', 'message': 'vmwareapi:remove unused variables in volumeops\n\nVariables instance_name were not used in two methods,\nLet us remove them.\n\nChange-Id: Ib617aa82651923ebb2824edf5ff5008f61898bfb\n'}]",0,65456,c217249e719642f9a797ba2ea770d4a3c4a38d81,31,10,3,9796,,,0,"vmwareapi:remove unused variables in volumeops

Variables instance_name were not used in two methods,
Let us remove them.

Change-Id: Ib617aa82651923ebb2824edf5ff5008f61898bfb
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/65456/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/volumeops.py'],1,f5715bd8d2dd3e4d2ae13c3ed94bd264328b32d9,remove_variable,, instance_name = instance['name'] instance_name = instance['name'],0,2
openstack%2Fkeystone~master~I1da036d998138964139c7fde3dde7ccb47f6a595,openstack/keystone,master,I1da036d998138964139c7fde3dde7ccb47f6a595,remove access log middleware from the default paste pipeline,MERGED,2014-01-27 16:37:57.000000000,2014-01-31 19:05:36.000000000,2014-01-31 19:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6738}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-27 16:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ea9683c0c07225aaa314408fc6058917fb605c5d', 'message': 'deprecate access log middleware\n\nImplements: bp deprecated-as-of-icehouse\nChange-Id: I1da036d998138964139c7fde3dde7ccb47f6a595\n'}, {'number': 2, 'created': '2014-01-29 22:42:36.000000000', 'files': ['etc/keystone-paste.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/86c4e610bf68a8a3c1bdb91710a93860a8a58cd1', 'message': 'remove access log middleware from the default paste pipeline\n\nImplements: bp deprecated-as-of-icehouse\nChange-Id: I1da036d998138964139c7fde3dde7ccb47f6a595\n'}]",0,69404,86c4e610bf68a8a3c1bdb91710a93860a8a58cd1,14,7,2,4,,,0,"remove access log middleware from the default paste pipeline

Implements: bp deprecated-as-of-icehouse
Change-Id: I1da036d998138964139c7fde3dde7ccb47f6a595
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/69404/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/access/core.py', 'etc/keystone-paste.ini']",2,ea9683c0c07225aaa314408fc6058917fb605c5d,bp/deprecated-as-of-icehouse,pipeline = sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension user_crud_extension public_servicepipeline = sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension s3_extension crud_extension admin_servicepipeline = sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension s3_extension simple_cert_extension service_v3pipeline = sizelimit url_normalize xml_body public_version_servicepipeline = sizelimit url_normalize xml_body admin_version_service,pipeline = access_log sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension user_crud_extension public_servicepipeline = access_log sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension s3_extension crud_extension admin_servicepipeline = access_log sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body json_body ec2_extension s3_extension simple_cert_extension service_v3pipeline = access_log sizelimit url_normalize xml_body public_version_servicepipeline = access_log sizelimit url_normalize xml_body admin_version_service,14,5
openstack%2Fdevstack~master~I28dfa90c877b27f5d4919f2748fae092bb2f87fa,openstack/devstack,master,I28dfa90c877b27f5d4919f2748fae092bb2f87fa,Fix up tempest conf settings,MERGED,2014-01-23 01:17:34.000000000,2014-01-31 19:05:28.000000000,2014-01-31 19:05:27.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2243}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-01-23 01:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/22edd666079d4cf40c9da6b5f6e1aead0f0b3fcc', 'message': 'Fix up tempest conf settings\n\nCurrently devstack doesn\'t use the same variable names for\nconfiguration variables as tempest expects.  In addition there\'s\nno way to pass in variables like cinder backend ""vendor_name"" and\n""storage_protocol"".\n\nThis patch aligns the config variable names in devstack with those\nthat exist in tempest.  It also adds the options to specify a\ndifferent volume driver for tempest and the vendor_name and\nstorage_protocol so that the volume_type tests can be ran.\n\nAn example localrc for a custom config is shown below.  The example\nsets the tempest config file to /etc/tempest/tempest.conf, and\nconfigures tempest to use the SolidFire driver as the cinder backend.\n\nTEMPEST_VOLUME_VENDOR ==> tempest.conf.volume_vendor\nTEMPEST_STORAGE_PROTOCOL ==> tempest.conf.storage_protocol\n\nrelevant example localrc entries:\n  TEMPEST_CONFIG=/etc/tempest/tempest.conf\n  TEMPEST_CONFIG_DIR=/etc/tempest\n  TEMPEST_VOLUME_DRIVER=solidfire\n  TEMPEST_VOLUME_VENDOR=""SolidFire Inc""\n\n***NOTE***\nstorage_protocol and vendor_name MUST match what the backend device reports from\nget capabilities.\n\nChange-Id: I28dfa90c877b27f5d4919f2748fae092bb2f87fa\nCloses-Bug: 1271781\n'}, {'number': 2, 'created': '2014-01-23 04:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1a8b7e731af4f846a76f38e3b6b5ab8ce5ab3f31', 'message': 'Fix up tempest conf settings\n\nCurrently devstack doesn\'t use the same variable names for\nconfiguration variables as tempest expects.  In addition there\'s\nno way to pass in variables like cinder backend ""vendor_name"" and\n""storage_protocol"".\n\nThis patch aligns the config variable names in devstack with those\nthat exist in tempest.  It also adds the options to specify a\ndifferent volume driver for tempest and the vendor_name and\nstorage_protocol so that the volume_type tests can be ran.\n\nAn example localrc for a custom config is shown below.  The example\nsets the tempest config file to /etc/tempest/tempest.conf, and\nconfigures tempest to use the SolidFire driver as the cinder backend.\n\nTEMPEST_VOLUME_VENDOR ==> tempest.conf.volume_vendor\nTEMPEST_STORAGE_PROTOCOL ==> tempest.conf.storage_protocol\n\nrelevant example localrc entries:\n  TEMPEST_CONFIG=/etc/tempest/tempest.conf\n  TEMPEST_CONFIG_DIR=/etc/tempest\n  TEMPEST_VOLUME_DRIVER=solidfire\n  TEMPEST_VOLUME_VENDOR=""SolidFire Inc""\n\n***NOTE***\nstorage_protocol and vendor_name MUST match what the backend device reports from\nget capabilities.\n\nChange-Id: I28dfa90c877b27f5d4919f2748fae092bb2f87fa\nCloses-Bug: 1271781\n'}, {'number': 3, 'created': '2014-01-25 16:56:07.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dc4dc7f03335e26ea3d86b6184f0475cc5f3d51b', 'message': 'Fix up tempest conf settings\n\nThe tempest api.volume.test_volume_types test won\'t\nwork with non-default drivers configured for cinder\'s backend\nany more.  The reason is that we create a type using capability\nscheduler keywords in the extra-specs for the test;\n(vendor_name and storage_protocol).  The result is the extra-spec\nuses the filters: ""vendor_name=Open Source"" and\n""storage_protocol=iSCSI"", but for example if you have another backend\nsay SolidFire, EMC, NetApp, IBM etc the capabilities filter will fail\nthe create with a ""No valid host available"".\n\nThis is intended to work by simply setting these values in your\ntempest.conf file.  That\'s fine, however upon setting this up\nin my localrc I found that the tempest config variables being\nset via devtsack were never picked up\n\nCurrently devstack doesn\'t use the same variable names for\nconfiguration variables as tempest expects. Devstack is using\nthe variable ""TEMPEST_CONF"" however the Tempest project is\nexpecting the variable ""TEMPEST_CONFIG"", so currently the\ndevstack lib/tempest rc variables are never picked up by\ntempest properly.\n\nThis change modifes devstack\'s naming of TEMPEST_CONF, my though\nbeing that since this doesn\'t work in devstack currently\nthat changing it here would be better than changing it in Tempest\nwhere it\'s possible people had their own custoizations already\noutside of devstack.\n\nIn addition this change creates rc variables in devstack to actually\nset these via devstack.  The idea here is that Cinder 3\'rd party testing\nneeds to be a simple devstack config and run stack.sh.  By fixing up\nthe configuration file variable naming and adding the variables for\nthe vendor and protocol settings that\'s now possible.\n\nAn example localrc for a custom config is shown below.  The example\nsets the tempest config file to /etc/tempest/tempest.conf, and\nconfigures tempest to use the SolidFire driver as the cinder backend.\n\nTEMPEST_VOLUME_VENDOR ==> tempest.conf.volume_vendor\nTEMPEST_STORAGE_PROTOCOL ==> tempest.conf.storage_protocol\n\nrelevant example localrc entries:\n  TEMPEST_CONFIG=/etc/tempest/tempest.conf\n  TEMPEST_CONFIG_DIR=/etc/tempest\n  TEMPEST_VOLUME_DRIVER=solidfire\n  TEMPEST_VOLUME_VENDOR=""SolidFire Inc""\n\n***NOTE***\nstorage_protocol and vendor_name MUST match what the backend device reports from\nget capabilities.\n\nChange-Id: I28dfa90c877b27f5d4919f2748fae092bb2f87fa\nCloses-Bug: 1271781\n'}]",0,68532,dc4dc7f03335e26ea3d86b6184f0475cc5f3d51b,20,4,3,2243,,,0,"Fix up tempest conf settings

The tempest api.volume.test_volume_types test won't
work with non-default drivers configured for cinder's backend
any more.  The reason is that we create a type using capability
scheduler keywords in the extra-specs for the test;
(vendor_name and storage_protocol).  The result is the extra-spec
uses the filters: ""vendor_name=Open Source"" and
""storage_protocol=iSCSI"", but for example if you have another backend
say SolidFire, EMC, NetApp, IBM etc the capabilities filter will fail
the create with a ""No valid host available"".

This is intended to work by simply setting these values in your
tempest.conf file.  That's fine, however upon setting this up
in my localrc I found that the tempest config variables being
set via devtsack were never picked up

Currently devstack doesn't use the same variable names for
configuration variables as tempest expects. Devstack is using
the variable ""TEMPEST_CONF"" however the Tempest project is
expecting the variable ""TEMPEST_CONFIG"", so currently the
devstack lib/tempest rc variables are never picked up by
tempest properly.

This change modifes devstack's naming of TEMPEST_CONF, my though
being that since this doesn't work in devstack currently
that changing it here would be better than changing it in Tempest
where it's possible people had their own custoizations already
outside of devstack.

In addition this change creates rc variables in devstack to actually
set these via devstack.  The idea here is that Cinder 3'rd party testing
needs to be a simple devstack config and run stack.sh.  By fixing up
the configuration file variable naming and adding the variables for
the vendor and protocol settings that's now possible.

An example localrc for a custom config is shown below.  The example
sets the tempest config file to /etc/tempest/tempest.conf, and
configures tempest to use the SolidFire driver as the cinder backend.

TEMPEST_VOLUME_VENDOR ==> tempest.conf.volume_vendor
TEMPEST_STORAGE_PROTOCOL ==> tempest.conf.storage_protocol

relevant example localrc entries:
  TEMPEST_CONFIG=/etc/tempest/tempest.conf
  TEMPEST_CONFIG_DIR=/etc/tempest
  TEMPEST_VOLUME_DRIVER=solidfire
  TEMPEST_VOLUME_VENDOR=""SolidFire Inc""

***NOTE***
storage_protocol and vendor_name MUST match what the backend device reports from
get capabilities.

Change-Id: I28dfa90c877b27f5d4919f2748fae092bb2f87fa
Closes-Bug: 1271781
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/68532/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,22edd666079d4cf40c9da6b5f6e1aead0f0b3fcc,bug/1271781,"TEMPEST_CONFIG_DIR=${TEMPEST_CONFIG_DIR:-$TEMPEST_DIR/etc} TEMPEST_CONFIG=$TEMPEST_CONFIG_DIR/tempest.conf# Cinder/Volume variables TEMPEST_VOLUME_DRIVER=${TEMPEST_VOLUME_DRIVER:-default} TEMPEST_VOLUME_VENDOR=${TEMPEST_VOLUME_VENDOR:-""Open Source""} TEMPEST_STORAGE_PROTOCOL=${TEMPEST_STORAGE_PROTOCOL:-iSCSI} if [[ ! -d $TEMPEST_CONFIG_DIR ]]; then sudo mkdir -p $TEMPEST_CONFIG_DIR fi sudo chown $STACK_USER $TEMPEST_CONFIG_DIR sudo cp $TEMPEST_DIR/etc/tempest.conf.sample $TEMPEST_CONFIG sudo chmod 644 $TEMPEST_CONFIG iniset $TEMPEST_CONFIG DEFAULT lock_path $TEMPEST_STATE_PATH iniset $TEMPEST_CONFIG DEFAULT use_stderr False iniset $TEMPEST_CONFIG DEFAULT log_file tempest.log iniset $TEMPEST_CONFIG DEFAULT debug True iniset $TEMPEST_CONFIG compute build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONFIG volume build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONFIG boto build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONFIG compute build_interval $BUILD_INTERVAL iniset $TEMPEST_CONFIG volume build_interval $BUILD_INTERVAL iniset $TEMPEST_CONFIG boto build_interval $BUILD_INTERVAL iniset $TEMPEST_CONFIG boto http_socket_timeout 5 iniset $TEMPEST_CONFIG identity uri ""$KEYSTONE_SERVICE_PROTOCOL://$KEYSTONE_SERVICE_HOST:5000/v2.0/"" iniset $TEMPEST_CONFIG identity password ""$password"" iniset $TEMPEST_CONFIG identity alt_username $ALT_USERNAME iniset $TEMPEST_CONFIG identity alt_password ""$password"" iniset $TEMPEST_CONFIG identity alt_tenant_name $ALT_TENANT_NAME iniset $TEMPEST_CONFIG identity admin_password ""$password"" iniset $TEMPEST_CONFIG image http_image $TEMPEST_HTTP_IMAGE iniset $TEMPEST_CONFIG compute change_password_available False iniset $TEMPEST_CONFIG compute allow_tenant_isolation ${TEMPEST_ALLOW_TENANT_ISOLATION:-True} iniset $TEMPEST_CONFIG compute ssh_user ${DEFAULT_INSTANCE_USER:-cirros} # DEPRECATED iniset $TEMPEST_CONFIG compute network_for_ssh $PRIVATE_NETWORK_NAME iniset $TEMPEST_CONFIG compute ip_version_for_ssh 4 iniset $TEMPEST_CONFIG compute ssh_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONFIG compute image_ref $image_uuid iniset $TEMPEST_CONFIG compute image_ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONFIG compute image_ref_alt $image_uuid_alt iniset $TEMPEST_CONFIG compute image_alt_ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONFIG compute flavor_ref $flavor_ref iniset $TEMPEST_CONFIG compute flavor_ref_alt $flavor_ref_alt iniset $TEMPEST_CONFIG compute live_migration_available ${LIVE_MIGRATION_AVAILABLE:-False} iniset $TEMPEST_CONFIG compute use_block_migration_for_live_migration ${USE_BLOCK_MIGRATION_FOR_LIVE_MIGRATION:-False} iniset $TEMPEST_CONFIG compute ssh_connect_method $ssh_connect_method iniset $TEMPEST_CONFIG ""compute-admin"" password ""$password"" # DEPRECATED iniset $TEMPEST_CONFIG network api_version 2.0 iniset $TEMPEST_CONFIG network tenant_networks_reachable ""$tenant_networks_reachable"" iniset $TEMPEST_CONFIG network public_network_id ""$public_network_id"" iniset $TEMPEST_CONFIG network public_router_id ""$public_router_id"" iniset $TEMPEST_CONFIG network default_network ""$FIXED_RANGE"" iniset $TEMPEST_CONFIG boto ec2_url ""http://$SERVICE_HOST:8773/services/Cloud"" iniset $TEMPEST_CONFIG boto s3_url ""http://$SERVICE_HOST:${S3_SERVICE_PORT:-3333}"" iniset $TEMPEST_CONFIG boto s3_materials_path ""$BOTO_MATERIALS_PATH"" iniset $TEMPEST_CONFIG boto instance_type ""$boto_instance_type"" iniset $TEMPEST_CONFIG boto http_socket_timeout 30 iniset $TEMPEST_CONFIG boto ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONFIG orchestration image_ref ""$HEAT_FETCHED_TEST_IMAGE"" iniset $TEMPEST_CONFIG orchestration image_ref ""fedora-vm-heat-cfntools-tempest"" iniset $TEMPEST_CONFIG scenario img_dir ""$FILES/images/cirros-0.3.1-x86_64-uec"" iniset $TEMPEST_CONFIG scenario large_ops_number ${TEMPEST_LARGE_OPS_NUMBER:-0} iniset $TEMPEST_CONFIG volume volume_backup_enabled ""True"" iniset $TEMPEST_CONFIG volume multi_backend_enabled ""True"" iniset $TEMPEST_CONFIG volume backend1_name ""LVM_iSCSI"" iniset $TEMPEST_CONFIG volume backend2_name ""LVM_iSCSI_2"" if [ $TEMPEST_VOLUME_DRIVER != ""default"" ]; then iniset $TEMPEST_CONFIG volume vendor_name $TEMPEST_VOLUME_VENDOR iniset $TEMPEST_CONFIG volume storage_protocol $TEMPEST_STORAGE_PROTOCOL fi iniset $TEMPEST_CONFIG dashboard dashboard_url ""http://$SERVICE_HOST/"" iniset $TEMPEST_CONFIG dashboard login_url ""http://$SERVICE_HOST/auth/login/"" iniset $TEMPEST_CONFIG cli cli_dir $NOVA_BIN_DIR iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ""${NETWORK_API_EXTENSIONS:-all}"" iniset $TEMPEST_CONFIG service_available $service ""True"" iniset $TEMPEST_CONFIG service_available $service ""False"" cat $TEMPEST_CONFIG","TEMPEST_CONF_DIR=$TEMPEST_DIR/etc TEMPEST_CONF=$TEMPEST_CONF_DIR/tempest.conf cp $TEMPEST_CONF.sample $TEMPEST_CONF iniset $TEMPEST_CONF DEFAULT lock_path $TEMPEST_STATE_PATH iniset $TEMPEST_CONF DEFAULT use_stderr False iniset $TEMPEST_CONF DEFAULT log_file tempest.log iniset $TEMPEST_CONF DEFAULT debug True iniset $TEMPEST_CONF compute build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONF volume build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONF boto build_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONF compute build_interval $BUILD_INTERVAL iniset $TEMPEST_CONF volume build_interval $BUILD_INTERVAL iniset $TEMPEST_CONF boto build_interval $BUILD_INTERVAL iniset $TEMPEST_CONF boto http_socket_timeout 5 iniset $TEMPEST_CONF identity uri ""$KEYSTONE_SERVICE_PROTOCOL://$KEYSTONE_SERVICE_HOST:5000/v2.0/"" iniset $TEMPEST_CONF identity password ""$password"" iniset $TEMPEST_CONF identity alt_username $ALT_USERNAME iniset $TEMPEST_CONF identity alt_password ""$password"" iniset $TEMPEST_CONF identity alt_tenant_name $ALT_TENANT_NAME iniset $TEMPEST_CONF identity admin_password ""$password"" iniset $TEMPEST_CONF image http_image $TEMPEST_HTTP_IMAGE iniset $TEMPEST_CONF compute change_password_available False iniset $TEMPEST_CONF compute allow_tenant_isolation ${TEMPEST_ALLOW_TENANT_ISOLATION:-True} iniset $TEMPEST_CONF compute ssh_user ${DEFAULT_INSTANCE_USER:-cirros} # DEPRECATED iniset $TEMPEST_CONF compute network_for_ssh $PRIVATE_NETWORK_NAME iniset $TEMPEST_CONF compute ip_version_for_ssh 4 iniset $TEMPEST_CONF compute ssh_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONF compute image_ref $image_uuid iniset $TEMPEST_CONF compute image_ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONF compute image_ref_alt $image_uuid_alt iniset $TEMPEST_CONF compute image_alt_ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONF compute flavor_ref $flavor_ref iniset $TEMPEST_CONF compute flavor_ref_alt $flavor_ref_alt iniset $TEMPEST_CONF compute live_migration_available ${LIVE_MIGRATION_AVAILABLE:-False} iniset $TEMPEST_CONF compute use_block_migration_for_live_migration ${USE_BLOCK_MIGRATION_FOR_LIVE_MIGRATION:-False} iniset $TEMPEST_CONF compute ssh_connect_method $ssh_connect_method iniset $TEMPEST_CONF ""compute-admin"" password ""$password"" # DEPRECATED iniset $TEMPEST_CONF network api_version 2.0 iniset $TEMPEST_CONF network tenant_networks_reachable ""$tenant_networks_reachable"" iniset $TEMPEST_CONF network public_network_id ""$public_network_id"" iniset $TEMPEST_CONF network public_router_id ""$public_router_id"" iniset $TEMPEST_CONF network default_network ""$FIXED_RANGE"" iniset $TEMPEST_CONF boto ec2_url ""http://$SERVICE_HOST:8773/services/Cloud"" iniset $TEMPEST_CONF boto s3_url ""http://$SERVICE_HOST:${S3_SERVICE_PORT:-3333}"" iniset $TEMPEST_CONF boto s3_materials_path ""$BOTO_MATERIALS_PATH"" iniset $TEMPEST_CONF boto instance_type ""$boto_instance_type"" iniset $TEMPEST_CONF boto http_socket_timeout 30 iniset $TEMPEST_CONF boto ssh_user ${DEFAULT_INSTANCE_USER:-cirros} iniset $TEMPEST_CONF orchestration image_ref ""$HEAT_FETCHED_TEST_IMAGE"" iniset $TEMPEST_CONF orchestration image_ref ""fedora-vm-heat-cfntools-tempest"" iniset $TEMPEST_CONF scenario img_dir ""$FILES/images/cirros-0.3.1-x86_64-uec"" iniset $TEMPEST_CONF scenario large_ops_number ${TEMPEST_LARGE_OPS_NUMBER:-0} iniset $TEMPEST_CONF volume volume_backup_enabled ""True"" iniset $TEMPEST_CONF volume multi_backend_enabled ""True"" iniset $TEMPEST_CONF volume backend1_name ""LVM_iSCSI"" iniset $TEMPEST_CONF volume backend2_name ""LVM_iSCSI_2"" iniset $TEMPEST_CONF dashboard dashboard_url ""http://$SERVICE_HOST/"" iniset $TEMPEST_CONF dashboard login_url ""http://$SERVICE_HOST/auth/login/"" iniset $TEMPEST_CONF cli cli_dir $NOVA_BIN_DIR iniset $TEMPEST_CONF network-feature-enabled api_extensions ""${NETWORK_API_EXTENSIONS:-all}"" iniset $TEMPEST_CONF service_available $service ""True"" iniset $TEMPEST_CONF service_available $service ""False"" cat $TEMPEST_CONF",80,63
openstack%2Fdevstack~master~Ia2b6001f5ccf2469ee9fdee67564c9a915a13862,openstack/devstack,master,Ia2b6001f5ccf2469ee9fdee67564c9a915a13862,Add support for Gantt,MERGED,2014-01-18 16:47:03.000000000,2014-01-31 19:05:26.000000000,2014-01-31 19:05:25.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 1981}, {'_account_id': 2750}, {'_account_id': 7494}, {'_account_id': 7629}]","[{'number': 1, 'created': '2014-01-18 16:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40785300fb79e2bac631d698def1b22e7d8ba24a', 'message': 'Add support for Gantt\n\nGantt is the new breakout of the scheduler code from the Nova\nsource tree.  These changes allow devstack to install/configure/startup\ngantt as the scheduler service for openstack.\n\nChange-Id: Ia2b6001f5ccf2469ee9fdee67564c9a915a13862\nSigned-off-by: Don Dugger <donald.d.dugger@intel.com>\n'}, {'number': 2, 'created': '2014-01-18 20:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40e729c93ba09f36ae8d9e5838a9f84f4a8b8416', 'message': 'Add support for Gantt\n\nGantt is the new breakout of the scheduler code from the Nova\nsource tree.  These changes allow devstack to install/configure/startup\ngantt as the scheduler service for openstack.\n\nChange-Id: Ia2b6001f5ccf2469ee9fdee67564c9a915a13862\nSigned-off-by: Don Dugger <donald.d.dugger@intel.com>\n'}, {'number': 3, 'created': '2014-01-30 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4e3ac5840b1c137443ecc84035d3a03259cf9516', 'message': 'Add support for Gantt\n\nGantt is the new breakout of the scheduler code from the Nova\nsource tree.  These changes allow devstack to install/configure/startup\ngantt as the scheduler service for openstack.\n\nChange-Id: Ia2b6001f5ccf2469ee9fdee67564c9a915a13862\n'}, {'number': 4, 'created': '2014-01-30 21:52:44.000000000', 'files': ['lib/gantt', 'extras.d/70-gantt.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f84eb5ba43ec0d548e59d982ec149a8feaa4d4d0', 'message': 'Add support for Gantt\n\nGantt is the new breakout of the scheduler code from the Nova\nsource tree.  These changes allow devstack to install/configure/startup\ngantt as the scheduler service for openstack.\n\nChange-Id: Ia2b6001f5ccf2469ee9fdee67564c9a915a13862\n'}]",3,67666,f84eb5ba43ec0d548e59d982ec149a8feaa4d4d0,22,8,4,1981,,,0,"Add support for Gantt

Gantt is the new breakout of the scheduler code from the Nova
source tree.  These changes allow devstack to install/configure/startup
gantt as the scheduler service for openstack.

Change-Id: Ia2b6001f5ccf2469ee9fdee67564c9a915a13862
",git fetch https://review.opendev.org/openstack/devstack refs/changes/66/67666/4 && git format-patch -1 --stdout FETCH_HEAD,"['clean.sh', 'lib/gantt', 'unstack.sh', 'stackrc', 'stack.sh']",5,40785300fb79e2bac631d698def1b22e7d8ba24a,gantt,"# **Glance**, **Heat**, **Horizon**, **Keystone**, **Nova**, **Gantt**, # **Neutron**, **Swift**, and **Trove**source $TOP_DIR/lib/ganttif is_service_enabled gantt; then install_gantt configure_gantt fi # Gantt scheduler service # ----------------------- if is_service_enabled gantt; then echo_summary ""Configuring gantt"" init_gantt fi if is_service_enabled gantt; then echo_summary ""Starting Gantt"" start_gantt fi","# **Glance**, **Heat**, **Horizon**, **Keystone**, **Nova**, **Neutron**, # **Swift**, and **Trove**",125,2
openstack%2Fnova~master~Ic47c1cb997ece3710f8c4465733148fcfa94068d,openstack/nova,master,Ic47c1cb997ece3710f8c4465733148fcfa94068d,Deal with old versions of libguestfs,MERGED,2014-01-31 14:31:14.000000000,2014-01-31 18:56:01.000000000,2014-01-31 18:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 14:31:14.000000000', 'files': ['nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd621ef05a024b8319f2c67f7e5c084b9ab77755', 'message': ""Deal with old versions of libguestfs\n\nCommit 02abbef960b12deaa7a911788dbc56f3a0bd555a added the use of the\nclose_on_exit parameter.  This is supported by libguestfs 1.20 and up.\nCatch the exeption raised when this parameter isn't supported and retry\nwithout it.\n\nChange-Id: Ic47c1cb997ece3710f8c4465733148fcfa94068d\nCloses-Bug: #1271562\nRelated-Bug: #1261475\n""}]",0,70354,fd621ef05a024b8319f2c67f7e5c084b9ab77755,10,5,1,1561,,,0,"Deal with old versions of libguestfs

Commit 02abbef960b12deaa7a911788dbc56f3a0bd555a added the use of the
close_on_exit parameter.  This is supported by libguestfs 1.20 and up.
Catch the exeption raised when this parameter isn't supported and retry
without it.

Change-Id: Ic47c1cb997ece3710f8c4465733148fcfa94068d
Closes-Bug: #1271562
Related-Bug: #1261475
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/70354/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/vfs/guestfs.py'],1,fd621ef05a024b8319f2c67f7e5c084b9ab77755,," try: self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)) except TypeError as e: if 'close_on_exit' in str(e): # NOTE(russellb) In case we're not using a version of # libguestfs new enough to support the close_on_exit paramater, # which was added in libguestfs 1.20. self.handle = tpool.Proxy(guestfs.GuestFS()) else: raise", self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)),10,1
openstack%2Ffuel-main~master~I179ee6a787f037bd2cd97807700d736eab21a318,openstack/fuel-main,master,I179ee6a787f037bd2cd97807700d736eab21a318,Added auth mechanism for Nailgan API client.,MERGED,2014-01-30 15:14:34.000000000,2014-01-31 18:49:34.000000000,2014-01-31 18:49:34.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 7261}, {'_account_id': 8084}, {'_account_id': 8767}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-30 15:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/671cf6925bcdaaad8d82ea45385de80bf76d14a4', 'message': 'Added auth mechanism for Nailgan API client.\n\nChange-Id: I179ee6a787f037bd2cd97807700d736eab21a318\n'}, {'number': 2, 'created': '2014-01-31 02:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6d7d539a2a744a2cd513ca5ab641ddb7b478bfdf', 'message': 'Added auth mechanism for Nailgan API client.\n\nChange-Id: I179ee6a787f037bd2cd97807700d736eab21a318\n'}, {'number': 3, 'created': '2014-01-31 06:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/26b67bfe1ce28d8df9828ae50b31d7f3ea81ea19', 'message': 'Added auth mechanism for Nailgan API client.\n\nChange-Id: I179ee6a787f037bd2cd97807700d736eab21a318\n'}, {'number': 4, 'created': '2014-01-31 09:54:51.000000000', 'files': ['fuelweb_test/models/nailgun_client.py', 'fuelweb_test/helpers/http.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d21a9f76bc43938c0bfd6b682526f682ae1c267f', 'message': 'Added auth mechanism for Nailgan API client.\n\nChange-Id: I179ee6a787f037bd2cd97807700d736eab21a318\n'}]",2,70134,d21a9f76bc43938c0bfd6b682526f682ae1c267f,27,9,4,7227,,,0,"Added auth mechanism for Nailgan API client.

Change-Id: I179ee6a787f037bd2cd97807700d736eab21a318
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/34/70134/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/http.py'],1,671cf6925bcdaaad8d82ea45385de80bf76d14a4,(detached,"import base64 base64string = None def __init__(self, url, user=None, password=None): if user and password: creds = base64.encodestring('%s:%s' % (user, password)) self.base64string = creds.replace('\n', '') if self.base64string: req.add_header(""Authorization"", ""Basic %s"" % self.base64string)"," def __init__(self, url):",13,1
openstack%2Frequirements~master~Ibc7ed47a7eae94196c4e7961217ace2f9e8cadee,openstack/requirements,master,Ibc7ed47a7eae94196c4e7961217ace2f9e8cadee,Use new hplefthandclient,ABANDONED,2014-01-31 00:32:01.000000000,2014-01-31 18:45:34.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-31 00:32:01.000000000', 'files': ['tests/files/gr-base.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5a9a2b8c201f870c2fc7e91ff14b0f4c8a3ce7fa', 'message': 'Use new hplefthandclient\n\nThe hplefthandclient is required for HP LeftHand (LH) StoreVirtual\nCinder iSCSI Driver unit tests.\n\nThe hplefthandclient has already been added to\nglobal-requirements.txt.\n\nChange-Id: Ibc7ed47a7eae94196c4e7961217ace2f9e8cadee\n'}]",0,70268,5a9a2b8c201f870c2fc7e91ff14b0f4c8a3ce7fa,2,1,1,7389,,,0,"Use new hplefthandclient

The hplefthandclient is required for HP LeftHand (LH) StoreVirtual
Cinder iSCSI Driver unit tests.

The hplefthandclient has already been added to
global-requirements.txt.

Change-Id: Ibc7ed47a7eae94196c4e7961217ace2f9e8cadee
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/70268/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/files/gr-base.txt'],1,5a9a2b8c201f870c2fc7e91ff14b0f4c8a3ce7fa,,"hplefthandclient>=1.0.0,<2.0.0",,1,0
openstack%2Fopenstacksdk~master~Ic6b68a66108beb52da8060865516b17d61bdb9c6,openstack/openstacksdk,master,Ic6b68a66108beb52da8060865516b17d61bdb9c6,Finished the pystack strawman overview.,MERGED,2014-01-31 16:30:03.000000000,2014-01-31 18:40:00.000000000,2014-01-31 18:40:00.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 9473}]","[{'number': 1, 'created': '2014-01-31 16:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e16f4bf050e6ef0143f162e2d2be8d7a94ac3f28', 'message': 'Finished the pystack strawman overview.\n\nChange-Id: Ic6b68a66108beb52da8060865516b17d61bdb9c6\n'}, {'number': 2, 'created': '2014-01-31 16:33:54.000000000', 'files': ['api_strawman/pystack/overview.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9b80da813efd654ea037cd027ccad7388e4ffcd8', 'message': 'Finished the pystack strawman overview.\n\nChange-Id: Ic6b68a66108beb52da8060865516b17d61bdb9c6\n'}]",0,70371,9b80da813efd654ea037cd027ccad7388e4ffcd8,7,3,2,1063,,,0,"Finished the pystack strawman overview.

Change-Id: Ic6b68a66108beb52da8060865516b17d61bdb9c6
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/71/70371/2 && git format-patch -1 --stdout FETCH_HEAD,['api_strawman/pystack/overview.rst'],1,e16f4bf050e6ef0143f162e2d2be8d7a94ac3f28,," # Get the object storage client clt_swift = context.RegionOne.object_store.client # List the containers containers = clt_swift.list() # Get the container named 'Photos' photo_cont = clt_swift.get(""Photos"") # Get the objects in that container photos = photo_cont.list() # Show the first photo print(photos[0]) <StorageObject bytes=2445839, content_type=image/jpeg, hash=b61cbc2d01fcb897d37614d1db23d9fb, last_modified=2012-12-10T16:06:12.416920, name=family/IMG_0086.jpg> * **service_catalog**: Holds the service catalog returned by the provider. After authenticating, the primary use for a Context Object is to get the appropriate Client object for the service and region you wish to work with. Once you have the client objects you need, you will rarely need to interact with the Context Object again. The only exceptions would be the admin identity functions for managing users.object for that service. The client is specific to the authenticated user, service, and the chosen region. You use standard dot notation to access the desired client. >> print(context.East) >> print(context.compute)Some services expose private (internal) endpoints, i.e., for accessing the service using an internal private network, which would improve efficiency and reduce bandwidth usage. If such an endpoint exists, you can get the client for it by using the ``client_private`` attribute. For example:: clt_priv = context.East.object_store.client_private If there is no private endpoint defined for that service, a ``NoEndpointForService`` exception will be raised. Clients also have a reference to the Context Object that created it, so that if any request returns a 401 due to an expired token, the client will ask the Context Object to re-authenticate to obtain a fresh token. If this succeeds, the client will then re-issue the request. This all happens transparently to the application built on pystack, allowing the developer to create long-running applications without having to worry about token expiration. * ``create(*args, **kwargs)``: Creates a new resource. The particular arguments required depend on the servicei and the resource being created.Additonally, clients have methods to handle all of the interaction you will need with the API. ---------------------- Working with Resources ---------------------- Resource objects represent cloud resources: servers, images, stored objects, networks, etc. The attributes of a Resource represent the state of that resource in the cloud, and depend on the type of resource. For example, when listing the stored objects in a Swift container, the API returns a JSON dict like this:: {""hash"": ""194577a7e20bdcc7afbb718f502c134c"", ""last_modified"": ""2012-12-10T16:06:12.115680"", ""bytes"": 6148, ""name"": ""some/object/name.txt"", ""content_type"": ""text/plain""} The Resource object returned by pystack for this object would have the attributes ""hash"", ""last_modified"", ""bytes"", ""name"", and ""content_type"", with values corresponding to the values returned by the API. Resource objects also have methods for operations that affect them. For example, while you can always call the client to delete an object:: clt.delete(obj) ... you can also call ``delete()`` directly on the resource itself:: obj.delete() ","* **service_catalog**: Holds the service catalog returned by the provider. object for that service. The client is specific to the authenticated user and the chosen region. You use standard dot notation to access the desired client. >> print context.East >> print context.compute* ``create(*args, **kwargs)``: Creates a new resource. The particular arguments required depend on the service.",74,6
openstack%2Fbarbican~master~I86ef3597321d2af54fd317021274a95173e3f3ac,openstack/barbican,master,I86ef3597321d2af54fd317021274a95173e3f3ac,Removed dead code and updated tests to cover 100% for crypto,MERGED,2014-01-27 17:43:05.000000000,2014-01-31 18:35:47.000000000,2014-01-31 18:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 8004}]","[{'number': 1, 'created': '2014-01-27 17:43:05.000000000', 'files': ['barbican/tests/crypto/test_extension_manager.py', 'barbican/tests/crypto/test_mime_types.py', 'barbican/crypto/p11_crypto.py', 'barbican/crypto/plugin.py', 'barbican/crypto/extension_manager.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/1c03cff079e2711d18311347eb2de1ec74bc750f', 'message': 'Removed dead code and updated tests to cover 100% for crypto\n\nChange-Id: I86ef3597321d2af54fd317021274a95173e3f3ac\n'}]",0,69422,1c03cff079e2711d18311347eb2de1ec74bc750f,8,3,1,9234,,,0,"Removed dead code and updated tests to cover 100% for crypto

Change-Id: I86ef3597321d2af54fd317021274a95173e3f3ac
",git fetch https://review.opendev.org/openstack/barbican refs/changes/22/69422/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/crypto/test_extension_manager.py', 'barbican/tests/crypto/test_mime_types.py', 'barbican/crypto/p11_crypto.py', 'barbican/crypto/plugin.py', 'barbican/crypto/extension_manager.py']",5,1c03cff079e2711d18311347eb2de1ec74bc750f,topic/deadcode, else:, elif normalized_mime in mime_types.BINARY: else: raise CryptoContentTypeNotSupportedException(content_type) ,33,5
openstack%2Ffuel-docs~master~I90d84204d7f9ff8f8e97706bb94dbab23ad14b1c,openstack/fuel-docs,master,I90d84204d7f9ff8f8e97706bb94dbab23ad14b1c,Inkscape could be installed with apt,MERGED,2014-01-31 14:00:53.000000000,2014-01-31 18:32:03.000000000,2014-01-31 18:32:03.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-31 14:00:53.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0b61aff730e793b904522cea084160921332d616', 'message': 'Inkscape could be installed with apt\n\nSo why not suggest to do it?\n\nChange-Id: I90d84204d7f9ff8f8e97706bb94dbab23ad14b1c\n'}]",0,70346,0b61aff730e793b904522cea084160921332d616,7,5,1,7109,,,0,"Inkscape could be installed with apt

So why not suggest to do it?

Change-Id: I90d84204d7f9ff8f8e97706bb94dbab23ad14b1c
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/46/70346/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,0b61aff730e793b904522cea084160921332d616,fix-readme," sudo apt-get install git python-pip python-dev make imagemagick libjpeg-dev inkscape Among other things that installs [ImageMagick](http://www.imagemagick.org/ ""ImageMagick"") and [Inkscape](http://inkscape.org/ ""Inkscape"").[PlantUML](http://plantuml.sourceforge.net/ ""PlantUML"") To install PlantUML run this wget process:"," sudo apt-get install git python-pip python-dev make imagemagick libjpeg-dev[PlantUML](http://plantuml.sourceforge.net/ ""PlantUML""), [ImageMagick](http://www.imagemagick.org/ ""ImageMagick""), and [Inkscape](http://inkscape.org/ ""Inkscape""). To install PlantUML you run this wget process:",7,5
openstack%2Ffuel-docs~master~I0e9fcdfb753ff8771a4e44f143fe5cd44e794239,openstack/fuel-docs,master,I0e9fcdfb753ff8771a4e44f143fe5cd44e794239,Correct ports used by Hadoop for Savanna,MERGED,2014-01-16 12:35:24.000000000,2014-01-31 18:31:51.000000000,2014-01-31 18:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 8084}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-16 12:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/41ff284698b00b2ba59dbba6d69487e7d862de29', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\nCloses-Bug: #1268612\n'}, {'number': 2, 'created': '2014-01-17 11:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3ec20b2688d90c2f1e76fc6fe59214afc665cf9c', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}, {'number': 3, 'created': '2014-01-17 11:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c7d789f807bee75ecdade15527b67314a89ad86a', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}, {'number': 4, 'created': '2014-01-17 11:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/48e468e0a18d96fed74b59064ba5ed63743feb54', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}, {'number': 5, 'created': '2014-01-17 12:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ae7627288028902011f5be3d0d3f98772ace9020', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}, {'number': 6, 'created': '2014-01-20 09:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/caf187fbffd3d7168a546853bf85344ecd7dfcb0', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded three more ports: 50060, 50075 and 50090. Also sorted them: now ports\nare listed in ascending order, except those required by HDP. The later ports\nare grouped in the end of the list.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}, {'number': 7, 'created': '2014-01-31 12:22:27.000000000', 'files': ['pages/reference-architecture/0090-savanna.rst', 'pages/user-guide/post-install-healthchecks.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d8352ee00be013544a8d7df4f41c451072d788e0', 'message': 'Correct ports used by Hadoop for Savanna\n\nAdded more ports to the Reference Architecture page with their description.\nAlso explicitly marked ports which are required for Savanna to work\nproperly and the ports required for post-deployment check to pass.\n\nCloses-Bug: #1268612\nChange-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239\n'}]",11,67142,d8352ee00be013544a8d7df4f41c451072d788e0,41,8,7,7109,,,0,"Correct ports used by Hadoop for Savanna

Added more ports to the Reference Architecture page with their description.
Also explicitly marked ports which are required for Savanna to work
properly and the ports required for post-deployment check to pass.

Closes-Bug: #1268612
Change-Id: I0e9fcdfb753ff8771a4e44f143fe5cd44e794239
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/42/67142/6 && git format-patch -1 --stdout FETCH_HEAD,['pages/reference-architecture/0090-savanna.rst'],1,41ff284698b00b2ba59dbba6d69487e7d862de29,, * Port 50030 (TCP) JobTracker HTTP server address and port * Port 50060 (TCP) TaskTracker HTTP server address and port NameNode HTTP server address and port * Port 50075 (TCP) DataNode HTTP server address and port * Port 50090 (TCP) Secondary NameNode HTTP server address and port * Port 8080 (TCP) Ambari REST API [HDP plugin only] , * Port 8080 (TCP) Ambari REST API [HDP plugin only] NameNode web interface * Port 50030 (TCP) JobTracker web interface,17,5
openstack%2Fopenstack-manuals~master~Ied66ecde223537e5e1e7b0f33dd4e86dcde07379,openstack/openstack-manuals,master,Ied66ecde223537e5e1e7b0f33dd4e86dcde07379,Minor edit of wording regarding Networking clusters,MERGED,2014-01-31 04:45:17.000000000,2014-01-31 18:29:38.000000000,2014-01-31 18:29:37.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-31 04:45:17.000000000', 'files': ['doc/admin-guide-cloud/section_networking_high_avail.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bdeaeade1cd7bfef2bb075b81d831cb9f48929b9', 'message': 'Minor edit of wording regarding Networking clusters\n\nText originally stated that Networking services can be run into a\ncluster. Revised to clarify that these services can be run in a\ncluster configuration.\n\nChange-Id: Ied66ecde223537e5e1e7b0f33dd4e86dcde07379\nPartial-Bug: #1217503\n'}]",0,70293,bdeaeade1cd7bfef2bb075b81d831cb9f48929b9,6,2,1,10203,,,0,"Minor edit of wording regarding Networking clusters

Text originally stated that Networking services can be run into a
cluster. Revised to clarify that these services can be run in a
cluster configuration.

Change-Id: Ied66ecde223537e5e1e7b0f33dd4e86dcde07379
Partial-Bug: #1217503
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/70293/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/section_networking_high_avail.xml'],1,bdeaeade1cd7bfef2bb075b81d831cb9f48929b9,Conventions-1217503, <para>You can run some Networking services in a cluster configuration (Active / Passive or Active / Active for Networking Server only) with Pacemaker.</para>, <para>You can run some Networking services into a cluster (Active / Passive or Active / Active for Networking Server only) with Pacemaker.</para>,3,3
openstack%2Ffuel-main~master~I088acdce5243d65cc8b3f4132fad52b7647b9663,openstack/fuel-main,master,I088acdce5243d65cc8b3f4132fad52b7647b9663,Disable invocation of heat tests in savanna deploy,MERGED,2014-01-30 16:13:44.000000000,2014-01-31 18:21:45.000000000,2014-01-31 18:21:45.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8839}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-30 16:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1317ef7decba837ae328a3669450b0c42b203381', 'message': 'Disbale invocation of heat tests in savanna deploy\n\nChange execution of all platform tests\nfor invocation savanna specific tests only\n\nChange-Id: I088acdce5243d65cc8b3f4132fad52b7647b9663\nCloses-bug: #1273674\n'}, {'number': 2, 'created': '2014-01-30 16:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cccaec95144c7cc6584d522a0131d2eb667f8d6c', 'message': 'Disable invocation of heat tests in savanna deploy\n\nChange execution of all platform tests\nfor invocation savanna specific tests only\n\nChange-Id: I088acdce5243d65cc8b3f4132fad52b7647b9663\nCloses-bug: #1273674\n'}, {'number': 3, 'created': '2014-01-31 17:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8bcff0150686e6328d13d39ad42048c032747585', 'message': 'Disable invocation of heat tests in savanna deploy\n\nChange execution of all platform tests\nfor invocation savanna specific tests only\n\nChange-Id: I088acdce5243d65cc8b3f4132fad52b7647b9663\nCloses-bug: #1273674\n'}, {'number': 4, 'created': '2014-01-31 18:18:40.000000000', 'files': ['fuelweb_test/tests/test_services.py', 'fuelweb_test/tests/test_simple.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e04a13f79f0206e5cbdcd024267bc7e2289f9c06', 'message': 'Disable invocation of heat tests in savanna deploy\n\nChange execution of all platform tests\nfor invocation savanna specific tests only\n\nChange-Id: I088acdce5243d65cc8b3f4132fad52b7647b9663\nCloses-bug: #1273674\n'}]",0,70155,e04a13f79f0206e5cbdcd024267bc7e2289f9c06,20,5,4,6719,,,0,"Disable invocation of heat tests in savanna deploy

Change execution of all platform tests
for invocation savanna specific tests only

Change-Id: I088acdce5243d65cc8b3f4132fad52b7647b9663
Closes-bug: #1273674
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/55/70155/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_services.py'],1,1317ef7decba837ae328a3669450b0c42b203381,bug/1273674," 8. Run OSTF platform savanna tests only LOGGER.debug('Run OSTF savanna platform tests') self.fuel_web.run_single_ostf_test( cluster_id=cluster_id, test_sets=['platform_tests'], test_name=('fuel_health.tests.platform_tests.' 'test_platform_savanna.test_platform_savanna')) "," 8. Run OSTF platform tests LOGGER.debug('Run OSTF platform tests') test_classes = ['fuel_health.tests.platform_tests' '.test_platform_savanna.' 'PlatformSavannaTests.test_platform_savanna'] self.fuel_web.run_ostf( cluster_id=self.fuel_web.get_last_created_cluster(), tests_must_be_passed=test_classes, test_sets=['platform_tests'])",9,9
openstack%2Fheat-templates~master~I60ca2404436e20461e5b38166e440cd41b8f947b,openstack/heat-templates,master,I60ca2404436e20461e5b38166e440cd41b8f947b,Fix incorrect HOT Parameter types,MERGED,2014-01-29 22:49:49.000000000,2014-01-31 17:39:54.000000000,2014-01-31 17:39:54.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-01-29 22:49:49.000000000', 'files': ['hot/F18/NovaInstanceWithCinderVolume_Native.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/dfad1beddf4201e4eb03fb831cd91efec536501f', 'message': 'Fix incorrect HOT Parameter types\n\nOnly types with lowercase names are valid in HOT.\n\nChange-Id: I60ca2404436e20461e5b38166e440cd41b8f947b\n'}]",0,70005,dfad1beddf4201e4eb03fb831cd91efec536501f,8,5,1,4257,,,0,"Fix incorrect HOT Parameter types

Only types with lowercase names are valid in HOT.

Change-Id: I60ca2404436e20461e5b38166e440cd41b8f947b
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/05/70005/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/F18/NovaInstanceWithCinderVolume_Native.yaml'],1,dfad1beddf4201e4eb03fb831cd91efec536501f,, type: string type: number, type: String type: Number,2,2
openstack%2Fnova~master~Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8,openstack/nova,master,Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8,Use objects internally in DriverBlockDevice class,MERGED,2013-12-09 13:59:08.000000000,2014-01-31 17:34:18.000000000,2014-01-31 17:34:14.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-09 13:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f170ae5b3b69e1512465b4596ae22d036eeca8ad', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 2, 'created': '2013-12-12 17:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51b361967bec2d65e30f10aa6f1d64631e32e378', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 3, 'created': '2013-12-13 10:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/279d8291f6ffa9a2e62735640637e4a7e3c68061', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 4, 'created': '2013-12-13 13:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/471a1db8d75f23765fe59d8c664452b134d30d70', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 5, 'created': '2013-12-13 17:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cfd2b7546a0f376d1883e250426bea981a3293a', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 6, 'created': '2013-12-17 12:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7788958960b7f00d04b4537c0f4c3658e12899fe', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 7, 'created': '2013-12-18 14:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78b181eea714ea87b37f8d8145b6373626255415', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 8, 'created': '2013-12-19 15:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d04a05dfebef30edcc441024c799cff027e4dd2', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 9, 'created': '2013-12-23 20:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d5bd15dacfd7fc1fbd3ad6c61496ea873a9176f', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 10, 'created': '2014-01-02 09:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3394fe16a4f42772518ebe71cbfa87a92b1f116e', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 11, 'created': '2014-01-03 15:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f744ee4e905f4e815c40b13c1c0c7755668afea', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 12, 'created': '2014-01-06 13:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2924e5e2147dc215fcca70debf3c91c8f7a344df', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 13, 'created': '2014-01-06 17:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cedeb9c2dcdc2a5d0c3ae3fbd659be315638669', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 14, 'created': '2014-01-06 19:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8835416972169381516c1015efd434e10ce41b36', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 15, 'created': '2014-01-13 14:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab34a42e729296b299d2b132474d50908e9c1510', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 16, 'created': '2014-01-14 23:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b8eabf0fe0e2891ec7d485bf6dfce5a11439961', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 17, 'created': '2014-01-15 10:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56b6ecb0e39f1f1d5f99e82df4d9379aa03903dc', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 18, 'created': '2014-01-17 16:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54e4774dd03711c2aea8ad14192adb280e9a8d73', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 19, 'created': '2014-01-22 17:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9ee85fef1d0d92be8cf40c75928162203983fa4', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 20, 'created': '2014-01-27 12:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b4b1797d35b9e86fd59aa0a0a084286bfe29011', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}, {'number': 21, 'created': '2014-01-30 14:33:01.000000000', 'files': ['nova/virt/fake.py', 'nova/tests/virt/test_block_device.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/virt/virtapi.py', 'nova/tests/compute/test_compute.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/compute/manager.py', 'nova/tests/compute/test_virtapi.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b3e05bdb51e2f238db655e75ff1384bd8a111fe0', 'message': 'Use objects internally in DriverBlockDevice class\n\nThis patch makes DriverBlockDevice use objects to do the database\nupdates. The object will be kept as a private object attribute and the\nonly change in the external API of the DriverBlockDevice objects is an\naddition of the save() method.\n\nThis patch also removes the block_device_mapping_update method from the\nVirtAPI class as that functionality can now be handled by\nDriverBlockDeviceDict class (using BlockDeviceMapping objects\ninternally).\n\nAlso cleans up tests and simplifies some code in the libvirt driver that was\nrelying on virtapi to do the db updates.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8\n'}]",4,60824,b3e05bdb51e2f238db655e75ff1384bd8a111fe0,81,7,21,5511,,,0,"Use objects internally in DriverBlockDevice class

This patch makes DriverBlockDevice use objects to do the database
updates. The object will be kept as a private object attribute and the
only change in the external API of the DriverBlockDevice objects is an
addition of the save() method.

This patch also removes the block_device_mapping_update method from the
VirtAPI class as that functionality can now be handled by
DriverBlockDeviceDict class (using BlockDeviceMapping objects
internally).

Also cleans up tests and simplifies some code in the libvirt driver that was
relying on virtapi to do the db updates.

Related to blueprint: icehouse-objects
Related to blueprint: clean-up-legacy-block-device-mapping

Change-Id: Ibafd1a05fb1050349ad12c0cafac77f64a8e96d8
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/60824/15 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/test_block_device.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py', 'nova/virt/block_device.py']",9,f170ae5b3b69e1512465b4596ae22d036eeca8ad,bp/icehouse-objects,"from nova.objects import block_device as block_device_objdef update_db(method): @functools.wraps(method) def wrapped(obj, context, *args, **kwargs): ret_val = method(obj, context, *args, **kwargs) obj.save(context) return ret_val return wrapped class DriverBlockDevice(dict): """""" A dict subclass that represents block devices used by the virt layer. Uses block device objects internally to do the database access. _fields and _legacy_fields class attributes present a set of fields that are expected on a certain DriverBlockDevice type. We may have more legacy versions in the future. If an attribute access is attempted for a name that is found in the _proxy_as_attr set, it will be proxied to the underlying object. This allows us to access stuff that is not part of the data model that all drivers understand. The save() method allows us to update the database using the underlying object. _update_on_save class attribute dictionary keeps the following mapping: {'object field name': 'driver dict field name (or None if same)'} These fields will be updated on the internal object, from the values in the dict, before the actual database update is done. """""" _proxy_as_attr = set() _update_on_save = {'disk_bus': None, 'device_name': None, 'device_type': None} def __init__(self, bdm): # TODO (ndipanov): Remove this check when we have all the rpc methods # use objects for block devices. if isinstance(bdm, block_device_obj.BlockDeviceMapping): self.__dict__['_bdm_obj'] = bdm else: self.__dict__['_bdm_obj'] = block_device_obj.BlockDeviceMapping() self._bdm_obj.update(block_device.BlockDeviceDict(bdm)) self._bdm_obj.obj_reset_changes() if self._bdm_obj.no_device: self._transform() def __getattr__(self, name): if name in self._proxy_as_attr: return getattr(self._bdm_obj, name) else: raise AttributeError(""Cannot access %s on DriverBlockDevice "" ""class"" % name) def __setattr__(self, name, value): if name in self._proxy_as_attr: return setattr(self._bdm_obj, name, value) else: raise AttributeError(""Cannot access %s on DriverBlockDevice "" ""class"" % name) def _transform(self): def save(self, context): for attr_name, key_name in self._update_on_save.iteritems(): setattr(self._bdm_obj, attr_name, self[key_name or attr_name]) self._bdm_obj.save(context) def _transform(self): if not block_device.new_format_is_swap(self._bdm_obj): 'device_name': self._bdm_obj.device_name, 'swap_size': self._bdm_obj.volume_size or 0, 'disk_bus': self._bdm_obj.disk_bus def _transform(self): if not block_device.new_format_is_ephemeral(self._bdm_obj): 'device_name': self._bdm_obj.device_name, 'size': self._bdm_obj.volume_size or 0, 'disk_bus': self._bdm_obj.disk_bus, 'device_type': self._bdm_obj.device_type, 'guest_format': self._bdm_obj.guest_format _proxy_as_attr = set(['volume_size', 'volume_id']) _update_on_save = {'disk_bus': None, 'device_name': 'mount_device', 'device_type': None} def _transform(self): if not self._bdm_obj.source_type == self._valid_source\ or not self._bdm_obj.destination_type == \ dict((k, v) for k, v in self._bdm_obj.iteritems() self['mount_device'] = self._bdm_obj.device_name self._bdm_obj.connection_info) @update_db def attach(self, context, instance, volume_api, virt_driver): self._bdm_obj.connection_info = jsonutils.dumps(connection_info) @update_db def refresh_connection_info(self, context, instance, volume_api, virt_driver): self._bdm_obj.connection_info = jsonutils.dumps(connection_info) _proxy_as_attr = set(['volume_size', 'volume_id', 'snapshot_id']) def attach(self, context, instance, volume_api, virt_driver, wait_func=None): volume_api, virt_driver) _proxy_as_attr = set(['volume_size', 'volume_id', 'image_id']) def attach(self, context, instance, volume_api, virt_driver, wait_func=None): volume_api, virt_driver)","class DriverBlockDevice(dict): def __init__(self, bdm): if bdm.get('no_device'): # NOTE (ndipanov): Always save the id of the bdm # so we can use it for db updates. self.id = bdm.get('id') self._transform(bdm) def _transform(self, bdm): def _transform(self, bdm): if not block_device.new_format_is_swap(bdm): 'device_name': bdm.get('device_name'), 'swap_size': bdm.get('volume_size') or 0, 'disk_bus': bdm.get('disk_bus') def _transform(self, bdm): if not block_device.new_format_is_ephemeral(bdm): 'device_name': bdm.get('device_name'), 'size': bdm.get('volume_size') or 0, 'disk_bus': bdm.get('disk_bus'), 'device_type': bdm.get('device_type'), 'guest_format': bdm.get('guest_format') # Override in subclasses if volume should be created from # another source. _source_id_field = None def _transform(self, bdm): if not bdm.get('source_type') == self._valid_source\ or not bdm.get('destination_type') == \ # NOTE (ndipanov): Save it as an attribute as we will # need it for attach() self.volume_size = bdm.get('volume_size') self.volume_id = bdm.get('volume_id') if self._source_id_field: setattr(self, self._source_id_field, bdm.get(self._source_id_field, None)) dict((k, v) for k, v in bdm.iteritems() self['mount_device'] = bdm.get('device_name') bdm.get('connection_info')) def attach(self, context, instance, volume_api, virt_driver, db_api=None): if db_api: db_api.block_device_mapping_update( context, self.id, {'connection_info': jsonutils.dumps(connection_info)}) def refresh_connection_info(self, context, instance, volume_api, virt_driver, db_api=None): if db_api: db_api.block_device_mapping_update(context, self.id, {'connection_info': jsonutils.dumps(connection_info)}) _source_id_field = 'snapshot_id' def attach(self, context, instance, volume_api, virt_driver, db_api=None, wait_func=None): if db_api: db_api.block_device_mapping_update(context, self.id, {'volume_id': vol['id']}) volume_api, virt_driver, db_api) _source_id_field = 'image_id' def attach(self, context, instance, volume_api, virt_driver, db_api=None, wait_func=None): if db_api: db_api.block_device_mapping_update(context, self.id, {'volume_id': vol['id']}) volume_api, virt_driver, db_api)",239,206
openstack%2Ftempest~master~Idc649993b7cd5a45282fde827b2b08f6fb19ab4d,openstack/tempest,master,Idc649993b7cd5a45282fde827b2b08f6fb19ab4d,Remove last uses of config without global CONF object,MERGED,2014-01-30 20:00:12.000000000,2014-01-31 17:34:04.000000000,2014-01-31 17:34:03.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-30 20:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2dd6d8faae5700c7e1006d66699ea73d497c0cf5', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 2, 'created': '2014-01-30 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8733928e68e70305f52876016cfca4be26127f4c', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 3, 'created': '2014-01-30 21:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8815fcacf0c6ffd6a4f24afd74b878ad96814b77', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 4, 'created': '2014-01-30 22:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dbfe14a3a4e03b9a9d0d9be12cc9f17ce75bf3e7', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 5, 'created': '2014-01-30 23:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0605e72f20390d36ccd8d2950cb4804c356192a3', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 6, 'created': '2014-01-31 00:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6cf3ef9e238d58eb105cf3d23212424daaa03e9b', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 7, 'created': '2014-01-31 00:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/50010271d25c3c7114e8e69d3b16e229c3d2ab72', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 8, 'created': '2014-01-31 02:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/46dcb0850dc8a51f078ace09511a68aed800d39b', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}, {'number': 9, 'created': '2014-01-31 15:00:47.000000000', 'files': ['tempest/api/compute/volumes/test_volumes_get.py', 'tempest/api/image/v1/test_images.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/manager.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/bc0e03ef6aa596d4630f7d8e7e87b704069d4e5d', 'message': 'Remove last uses of config without global CONF object\n\nThis commit removes that last uses of config without using the global\nCONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d\n'}]",2,70208,bc0e03ef6aa596d4630f7d8e7e87b704069d4e5d,34,5,9,5196,,,0,"Remove last uses of config without global CONF object

This commit removes that last uses of config without using the global
CONF object.

Partially implements bp config-cleanup

Change-Id: Idc649993b7cd5a45282fde827b2b08f6fb19ab4d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/08/70208/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/manager.py', 'tempest/test.py']",2,2dd6d8faae5700c7e1006d66699ea73d497c0cf5,bp/config-cleanup," config_dict = { 'compute': CONF.compute_feature_enabled.api_extensions, 'compute_v3': CONF.compute_feature_enabled.api_v3_extensions, 'volume': CONF.volume_feature_enabled.api_extensions, 'network': CONF.network_feature_enabled.api_extensions, 'object': CONF.object_storage_feature_enabled.discoverable_apis, if (CONF.compute.allow_tenant_isolation or CONF.identity.admin_username, CONF.identity.admin_password, CONF.identity.uri"," configs = CONF config_dict = { 'compute': configs.compute_feature_enabled.api_extensions, 'compute_v3': configs.compute_feature_enabled.api_v3_extensions, 'volume': configs.volume_feature_enabled.api_extensions, 'network': configs.network_feature_enabled.api_extensions, 'object': configs.object_storage_feature_enabled.discoverable_apis, config = CONF if (cls.config.compute.allow_tenant_isolation or cls.config, cls.config.identity.admin_username, cls.config.identity.admin_password, cls.config.identity.uri",9,15
openstack%2Fnova~master~Ic6656457afced20bff2f23c03493e72a96a00fb9,openstack/nova,master,Ic6656457afced20bff2f23c03493e72a96a00fb9,Add 'icehouse-compat' to [upgrade_levels] compute=,MERGED,2013-12-11 22:49:14.000000000,2014-01-31 17:33:14.000000000,2014-01-31 17:33:10.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-11 22:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab7998d10c4d01ff5a9e1057b957be95cbcdcac4', 'message': ""Add 'icehouse-compat' to [upgrade_levels] compute=\n\nAdd support for the 'icehouse-compat' value for the compute\nconfiguration option in the [upgrade_levels] configuration option group.\nThis option is set during a live upgrade from havana to icehouse to\nensure that compute messages are sent that both havana and icehouse\nunderstand.\n\nThis is added to stable/havana in this change id:\nIf09bd38c9d8c3beb5b95107c497699dec47aa3ef\n\nDocImpact\n\nChange-Id: Ic6656457afced20bff2f23c03493e72a96a00fb9\n""}, {'number': 2, 'created': '2014-01-20 18:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26be8eb82015b6ad943ca78dae4338f79bf78c75', 'message': ""Add 'icehouse-compat' to [upgrade_levels] compute=\n\nAdd support for the 'icehouse-compat' value for the compute\nconfiguration option in the [upgrade_levels] configuration option group.\nThis option is set during a live upgrade from havana to icehouse to\nensure that compute messages are sent that both havana and icehouse\nunderstand.\n\nThis is added to stable/havana in this change id:\nIf09bd38c9d8c3beb5b95107c497699dec47aa3ef\n\nDocImpact\n\nChange-Id: Ic6656457afced20bff2f23c03493e72a96a00fb9\n""}, {'number': 3, 'created': '2014-01-30 17:56:13.000000000', 'files': ['etc/nova/nova.conf.sample', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13cb4e7d3fb7b119f7ee01d8aa3f265d4be20090', 'message': ""Add 'icehouse-compat' to [upgrade_levels] compute=\n\nAdd support for the 'icehouse-compat' value for the compute\nconfiguration option in the [upgrade_levels] configuration option group.\nThis option is set during a live upgrade from havana to icehouse to\nensure that compute messages are sent that both havana and icehouse\nunderstand.\n\nThis is added to stable/havana in this change id:\nIf09bd38c9d8c3beb5b95107c497699dec47aa3ef\n\nDocImpact\n\nChange-Id: Ic6656457afced20bff2f23c03493e72a96a00fb9\n""}]",6,61592,13cb4e7d3fb7b119f7ee01d8aa3f265d4be20090,39,9,3,1561,,,0,"Add 'icehouse-compat' to [upgrade_levels] compute=

Add support for the 'icehouse-compat' value for the compute
configuration option in the [upgrade_levels] configuration option group.
This option is set during a live upgrade from havana to icehouse to
ensure that compute messages are sent that both havana and icehouse
understand.

This is added to stable/havana in this change id:
If09bd38c9d8c3beb5b95107c497699dec47aa3ef

DocImpact

Change-Id: Ic6656457afced20bff2f23c03493e72a96a00fb9
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/61592/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/nova.conf.sample', 'nova/compute/rpcapi.py']",2,ab7998d10c4d01ff5a9e1057b957be95cbcdcac4,icehouse-compat-rpc," help='Set a version cap for messages sent to compute services. If you ' 'plan to do a live upgrade from havana to icehouse, you should ' 'set this option to ""icehouse-compat"" before beginning the live ' 'upgrade procedure.') 'icehouse-compat': '3.0',", help='Set a version cap for messages sent to compute services'),9,3
openstack%2Ftempest~master~I17ebb23f31bc10d669208b64a66e89fa415f96ac,openstack/tempest,master,I17ebb23f31bc10d669208b64a66e89fa415f96ac,test_rescued_vm_add_remove_security_group missing addCleanup,MERGED,2014-01-29 14:35:27.000000000,2014-01-31 17:33:00.000000000,2014-01-31 17:33:00.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2014-01-29 14:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/559e8115abe5b91483b74e3ef9bce0efb021d7d3', 'message': 'test_rescued_vm_add_remove_security_group missing addCleanup\n\ntest_rescued_vm_add_remove_security_group on failure caused\nother test cases fail.\n\nChange-Id: I17ebb23f31bc10d669208b64a66e89fa415f96ac\n'}, {'number': 2, 'created': '2014-01-29 15:18:40.000000000', 'files': ['tempest/api/compute/servers/test_server_rescue.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/87a409ac922812414b3cd1429b5f1e940b586888', 'message': 'test_rescued_vm_add_remove_security_group missing addCleanup\n\ntest_rescued_vm_add_remove_security_group on failure caused\nother test cases fail.\n\nChange-Id: I17ebb23f31bc10d669208b64a66e89fa415f96ac\n'}]",1,69873,87a409ac922812414b3cd1429b5f1e940b586888,11,5,2,5803,,,0,"test_rescued_vm_add_remove_security_group missing addCleanup

test_rescued_vm_add_remove_security_group on failure caused
other test cases fail.

Change-Id: I17ebb23f31bc10d669208b64a66e89fa415f96ac
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/69873/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_rescue.py'],1,559e8115abe5b91483b74e3ef9bce0efb021d7d3,rescue_missing_add_cleanup," self.addCleanup(self._unrescue, self.server_id)",,1,0
openstack%2Fdevstack~master~I537e0bf2127efaf337c4792bc23d938145c8990d,openstack/devstack,master,I537e0bf2127efaf337c4792bc23d938145c8990d,fix sar reporting in the gate,MERGED,2014-01-31 13:22:40.000000000,2014-01-31 17:32:53.000000000,2014-01-31 17:32:52.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}]","[{'number': 1, 'created': '2014-01-31 13:22:40.000000000', 'files': ['tools/sar_filter.py'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6114a518de8d2db560db193ed4bc26d6e1659ce7', 'message': ""fix sar reporting in the gate\n\nthe sar filter made an assumption of time display including an\nAM/PM... which isn't true in all environments. Hence the blank\nsysstat screen in the gate runs of late.\n\nThis fixes that, and displays the first line which includes header\nversion to make sure we are functioning.\n\nChange-Id: I537e0bf2127efaf337c4792bc23d938145c8990d\n""}]",1,70341,6114a518de8d2db560db193ed4bc26d6e1659ce7,6,3,1,2750,,,0,"fix sar reporting in the gate

the sar filter made an assumption of time display including an
AM/PM... which isn't true in all environments. Hence the blank
sysstat screen in the gate runs of late.

This fixes that, and displays the first line which includes header
version to make sure we are functioning.

Change-Id: I537e0bf2127efaf337c4792bc23d938145c8990d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/41/70341/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/sar_filter.py'],1,6114a518de8d2db560db193ed4bc26d6e1659ce7,sar_fix," m = re.search('(\d\d:\d\d:\d\d( \w\w)?)(\s+((\S+)\s*)+)', line) data = m.group(3).rstrip() # print out the first sysstat line regardless print process.stdout.readline() "," m = re.search('(\d\d:\d\d:\d\d \w\w)(\s+((\S+)\s*)+)', line) data = m.group(2).rstrip()",6,2
openstack%2Fpython-swiftclient~master~I590932f00476eacd434cdae012fd62010845581d,openstack/python-swiftclient,master,I590932f00476eacd434cdae012fd62010845581d,Install manpage in share/man/man1 instead of man/man1,MERGED,2014-01-20 11:24:45.000000000,2014-01-31 17:32:51.000000000,2014-01-31 17:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 6476}]","[{'number': 1, 'created': '2014-01-20 11:24:45.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/65d7a136f69a2f0a692eeaed7ca68e2a5f91b07d', 'message': 'Install manpage in share/man/man1 instead of man/man1\n\nAccording to FHS 2.3 the correct place to install the manpage for a\nbinary in /usr/local/bin/ would be /usr/local/man/.\n\nHowever, on Debian/Ubuntu-based systems /usr/local/man/ is a link to\n/usr/local/share/man/ and on other systems /usr/local/man/ might not\nexist at all.\n\nEven worse, if the client is installed in /usr/bin/ the manpage\nshould should be installed in /usr/share/man, but will be installed\nin /usr/man/ which is completely wrong.\n\nThis patch fixes this and uses share/man/man1 as common prefix. Doing\nthis will install the manpage either in /usr/local/share/man/man1 or\n/usr/share/man/man1.\n\nPartial-Bug: 1269715\nChange-Id: I590932f00476eacd434cdae012fd62010845581d\n'}]",0,67813,65d7a136f69a2f0a692eeaed7ca68e2a5f91b07d,8,4,1,6968,,,0,"Install manpage in share/man/man1 instead of man/man1

According to FHS 2.3 the correct place to install the manpage for a
binary in /usr/local/bin/ would be /usr/local/man/.

However, on Debian/Ubuntu-based systems /usr/local/man/ is a link to
/usr/local/share/man/ and on other systems /usr/local/man/ might not
exist at all.

Even worse, if the client is installed in /usr/bin/ the manpage
should should be installed in /usr/share/man, but will be installed
in /usr/man/ which is completely wrong.

This patch fixes this and uses share/man/man1 as common prefix. Doing
this will install the manpage either in /usr/local/share/man/man1 or
/usr/share/man/man1.

Partial-Bug: 1269715
Change-Id: I590932f00476eacd434cdae012fd62010845581d
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/13/67813/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,65d7a136f69a2f0a692eeaed7ca68e2a5f91b07d,bug/1269715, share/man/man1 = doc/manpages/swift.1, man/man1 = doc/manpages/swift.1,1,1
openstack%2Fkeystone~master~Iccd72003b61f775b71ea7402dc70eba1723d2336,openstack/keystone,master,Iccd72003b61f775b71ea7402dc70eba1723d2336,Use self.opt_in_group overrides,MERGED,2014-01-25 02:54:23.000000000,2014-01-31 17:32:43.000000000,2014-01-31 17:32:42.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-25 02:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4669fea4942a6c8116f127768ee92c75c0692295', 'message': 'Fix test configuration for test_cert_setup\n\n``test_cert_setup.CertSetupTestCase`` was directly setting the options\non the configuration object. This is not as sticky as configuration\nobjects should be.  ``opt_in_group`` sets hard-overrides that are\nnot overridden by configuration files.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}, {'number': 2, 'created': '2014-01-25 02:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fb27b99b4f4ae8594d05c9848dbe1d698215ab4d', 'message': 'Fix test configuration for test_cert_setup\n\n``test_cert_setup.CertSetupTestCase`` was directly setting the options\non the configuration object. This is not as sticky as configuration\nobjects should be.  ``opt_in_group`` sets hard-overrides that are\nnot overridden by configuration files.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}, {'number': 3, 'created': '2014-01-25 02:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/523db469adbac5f3f22d57b9bebdd1e2174a43bd', 'message': 'Fix test configuration for test_cert_setup\n\n``test_cert_setup.CertSetupTestCase`` was directly setting the options\non the configuration object. This is not as sticky as configuration\nobjects should be.  ``opt_in_group`` sets hard-overrides that are\nnot overridden by configuration files.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}, {'number': 4, 'created': '2014-01-25 03:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25d9220727dcd6e59b71054de2e4a765a295ed3c', 'message': 'Fix test configuration for test_cert_setup\n\n``test_cert_setup.CertSetupTestCase`` was directly setting the options\non the configuration object. This is not as sticky as configuration\nobjects should be.  ``opt_in_group`` sets hard-overrides that are\nnot overridden by configuration files.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}, {'number': 5, 'created': '2014-01-30 20:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f78e94bcb2cefc1865b5c6ba41697a52c30a833', 'message': 'Use self.opt_in_group overrides\n\nUse of self.opt_in_group makes option setting ""sticky"" even when\nsubsequent configuration files are loaded in. In some cases\n(e.g. ``test_cert_setup.CertSetupTestCase``) the directly set\noverride (not using ``opt_in_group``) could be lost as test further\ntest cleanup patchsets were proposed. All identified direct\nCONF object option setting has been replaced with use of\n``opt_in_group``.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}, {'number': 6, 'created': '2014-01-30 22:39:48.000000000', 'files': ['keystone/tests/test_cert_setup.py', 'keystone/tests/test_auth.py', 'keystone/tests/test_token_bind.py', 'keystone/tests/test_cache.py', 'keystone/tests/test_backend_kvs.py', 'keystone/tests/_ldap_tls_livetest.py', 'keystone/tests/_ldap_livetest.py', 'keystone/tests/test_backend_ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e92324f44f4cc5a0dbf68fe6908f22f2b42cf631', 'message': 'Use self.opt_in_group overrides\n\nUse of self.opt_in_group makes option setting ""sticky"" even when\nsubsequent configuration files are loaded in. In some cases\n(e.g. ``test_cert_setup.CertSetupTestCase``) the directly set\noverride (not using ``opt_in_group``) could be lost as test further\ntest cleanup patchsets were proposed. All identified direct\nCONF object option setting has been replaced with use of\n``opt_in_group``.\n\nChange-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336\nbp: keystone-parallel-testing\n'}]",2,69080,e92324f44f4cc5a0dbf68fe6908f22f2b42cf631,17,10,6,2903,,,0,"Use self.opt_in_group overrides

Use of self.opt_in_group makes option setting ""sticky"" even when
subsequent configuration files are loaded in. In some cases
(e.g. ``test_cert_setup.CertSetupTestCase``) the directly set
override (not using ``opt_in_group``) could be lost as test further
test cleanup patchsets were proposed. All identified direct
CONF object option setting has been replaced with use of
``opt_in_group``.

Change-Id: Iccd72003b61f775b71ea7402dc70eba1723d2336
bp: keystone-parallel-testing
",git fetch https://review.opendev.org/openstack/keystone refs/changes/80/69080/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_cert_setup.py'],1,4669fea4942a6c8116f127768ee92c75c0692295,bp/keystone-parallel-testing," ca_certs = os.path.join(CERTDIR, 'ca.pem') ca_key = os.path.join(CERTDIR, 'cakey.pem') self.opt_in_group( 'signing', certfile=os.path.join(CERTDIR, 'signing_cert.pem'), ca_certs=ca_certs, ca_key=ca_key, keyfile=os.path.join(KEYDIR, 'signing_key.pem')) self.opt_in_group( 'ssl', ca_certs=ca_certs, ca_key=ca_key, certfile=os.path.join(CERTDIR, 'keystone.pem'), keyfile=os.path.join(KEYDIR, 'keystonekey.pem'))"," CONF.signing.certfile = os.path.join(CERTDIR, 'signing_cert.pem') CONF.signing.ca_certs = os.path.join(CERTDIR, ""ca.pem"") CONF.signing.ca_key = os.path.join(CERTDIR, ""cakey.pem"") CONF.signing.keyfile = os.path.join(KEYDIR, ""signing_key.pem"") CONF.ssl.ca_certs = CONF.signing.ca_certs CONF.ssl.ca_key = CONF.signing.ca_key CONF.ssl.certfile = os.path.join(CERTDIR, 'keystone.pem') CONF.ssl.keyfile = os.path.join(KEYDIR, 'keystonekey.pem')",14,9
openstack%2Fdevstack-gate~master~Iee001c8fd01aba9c9c98c2b15361ffb8d0346813,openstack/devstack-gate,master,Iee001c8fd01aba9c9c98c2b15361ffb8d0346813,Enable pidstat by default,MERGED,2014-01-27 01:53:30.000000000,2014-01-31 17:32:41.000000000,2014-01-31 17:32:41.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-01-27 01:53:30.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/797a8a0321c780e75b3f8337d3cf7fb54f583a55', 'message': 'Enable pidstat by default\n\npidstat comes from the sysstat package and will allow us to get some\nper-process CPU/memory information for devstack runs.  pidstat was added\nto devstack in the following change:\n\n    https://review.openstack.org/#/c/68702\n\nChange-Id: Iee001c8fd01aba9c9c98c2b15361ffb8d0346813\n'}]",0,69253,797a8a0321c780e75b3f8337d3cf7fb54f583a55,8,5,1,1561,,,0,"Enable pidstat by default

pidstat comes from the sysstat package and will allow us to get some
per-process CPU/memory information for devstack runs.  pidstat was added
to devstack in the following change:

    https://review.openstack.org/#/c/68702

Change-Id: Iee001c8fd01aba9c9c98c2b15361ffb8d0346813
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/53/69253/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,797a8a0321c780e75b3f8337d3cf7fb54f583a55,pidstat," DEFAULT_ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,horizon,mysql,rabbit,sysstat,pidstat"," DEFAULT_ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,horizon,mysql,rabbit,sysstat",1,1
openstack%2Fdevstack-gate~master~Ib0dd8a92ef2b7143cfbe4aef50823f2254c77cff,openstack/devstack-gate,master,Ib0dd8a92ef2b7143cfbe4aef50823f2254c77cff,Pretty up the post-run df call,MERGED,2014-01-26 02:22:40.000000000,2014-01-31 17:32:07.000000000,2014-01-31 17:32:07.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-01-26 02:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/42d95fce0283c757155b150c5a331fbcde2e6345', 'message': 'Pretty up the post-run df call\n\nJust easier to read.\n\nChange-Id: Ib0dd8a92ef2b7143cfbe4aef50823f2254c77cff\n'}, {'number': 2, 'created': '2014-01-27 03:51:50.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c580cf16340170249e737bdfd3394cf2dfdd4014', 'message': 'Pretty up the post-run df call\n\nJust easier to read.\n\nChange-Id: Ib0dd8a92ef2b7143cfbe4aef50823f2254c77cff\n'}]",0,69157,c580cf16340170249e737bdfd3394cf2dfdd4014,10,5,2,4190,,,0,"Pretty up the post-run df call

Just easier to read.

Change-Id: Ib0dd8a92ef2b7143cfbe4aef50823f2254c77cff
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/57/69157/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,42d95fce0283c757155b150c5a331fbcde2e6345,, df -h > $WORKSPACE/logs/df.txt, df -h> $WORKSPACE/logs/df.txt,1,1
openstack%2Fdevstack-gate~master~Ia6d0723fd8dc5dde60fba76783678053069a0a86,openstack/devstack-gate,master,Ia6d0723fd8dc5dde60fba76783678053069a0a86,Tiny  improvement in paths,MERGED,2013-12-24 10:42:31.000000000,2014-01-31 17:32:06.000000000,2014-01-31 17:32:06.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 3009}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-12-24 10:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fbd7719e28378fbc93490bb72ff4ab7ca2c44393', 'message': 'Tiny improvement in paths\n\nThis patch allows to run devstack-vm-gate-wrap.sh outside\n$WORKSPACE directory. Without this patch script fails with\nerror that logs/* paths are not found.\n\nChange-Id: Ia6d0723fd8dc5dde60fba76783678053069a0a86\n'}, {'number': 2, 'created': '2013-12-24 13:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/85c29ba58073af67891a1dc3ab1e1ac4f7809409', 'message': 'Tiny  improvement in paths\n\nThis patch allows to run devstack-vm-gate-wrap.sh outside\n$WORKSPACE directory. Without this patch script fails with\nerror that logs/* paths are not found.\n\nChange-Id: Ia6d0723fd8dc5dde60fba76783678053069a0a86\n'}, {'number': 3, 'created': '2014-01-15 12:46:19.000000000', 'files': ['devstack-vm-gate-wrap.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6301d0051989f85d2645da10029ce5fe30e81dc0', 'message': 'Tiny  improvement in paths\n\nThis patch allows to run devstack-vm-gate-wrap.sh outside\n$WORKSPACE directory. Without this patch script fails with\nerror that logs/* paths are not found.\n\nChange-Id: Ia6d0723fd8dc5dde60fba76783678053069a0a86\n'}]",0,63902,6301d0051989f85d2645da10029ce5fe30e81dc0,26,7,3,3009,,,0,"Tiny  improvement in paths

This patch allows to run devstack-vm-gate-wrap.sh outside
$WORKSPACE directory. Without this patch script fails with
error that logs/* paths are not found.

Change-Id: Ia6d0723fd8dc5dde60fba76783678053069a0a86
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/02/63902/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,fbd7719e28378fbc93490bb72ff4ab7ca2c44393,master, sudo mkdir -p $BASErm -rf $WORKSPACE/logs mkdir -p $WORKSPACE/logs, sudo mkdir $BASErm -rf logs mkdir -p logs,3,3
openstack%2Ftaskflow~master~I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f,openstack/taskflow,master,I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f,Engine tests refactoring,MERGED,2014-01-23 16:10:55.000000000,2014-01-31 17:29:18.000000000,2014-01-31 17:29:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-01-23 16:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b55c7e9721f01c9c2bf3a400e3c7a32e6723ebbb', 'message': '(WIP) bring some order to engine tests\n\ntests for netsted linear-in-parallel flow are a bit messy\n\nChange-Id: I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f\n'}, {'number': 2, 'created': '2014-01-30 17:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c6e137fe47c8cc16aa7d132c07e07b1c94359d7a', 'message': 'Engine tests refactoring\n\nThis change makes tests from test_action_engine.py more focused and\ndeterministic:\n- replace assertIsSubset with assertIsSuperAndSubsequence, which checks\n  order, too;\n- remove all sleeping from test tasks, it does not help anything anyway;\n- refactor tests that verify behaviour in case of task failing in nested\n  subflow.\n\nChange-Id: I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f\n'}, {'number': 3, 'created': '2014-01-30 17:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f8146111741680f84bfba3bf1b56b9367af4c967', 'message': 'Engine tests refactoring\n\nThis change makes tests from test_action_engine.py more focused and\ndeterministic:\n- replace assertIsSubset with assertIsSuperAndSubsequence, which checks\n  order, too;\n- remove all sleeping from test tasks, it does not help anything anyway;\n- refactor tests that verify behaviour in case of task failing in nested\n  subflow.\n\nChange-Id: I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f\n'}, {'number': 4, 'created': '2014-01-30 19:27:17.000000000', 'files': ['taskflow/test.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/test_action_engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7ff1cde77e97fae6fde61ca515cbbce98b0d3b92', 'message': 'Engine tests refactoring\n\nThis change makes tests from test_action_engine.py more focused and\ndeterministic:\n- replace assertIsSubset with assertIsSuperAndSubsequence, which checks\n  order, too;\n- remove all sleeping from test tasks, it does not help anything anyway;\n- refactor tests that verify behaviour in case of task failing in nested\n  subflow.\n\nChange-Id: I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f\n'}]",3,68677,7ff1cde77e97fae6fde61ca515cbbce98b0d3b92,15,5,4,7366,,,0,"Engine tests refactoring

This change makes tests from test_action_engine.py more focused and
deterministic:
- replace assertIsSubset with assertIsSuperAndSubsequence, which checks
  order, too;
- remove all sleeping from test tasks, it does not help anything anyway;
- refactor tests that verify behaviour in case of task failing in nested
  subflow.

Change-Id: I87ce1e5eed4a3a93c3c6593b618e82cfdd68204f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/77/68677/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/test.py', 'taskflow/tests/utils.py', 'taskflow/tests/unit/test_action_engine.py']",3,b55c7e9721f01c9c2bf3a400e3c7a32e6723ebbb,," def test_nasty_failing_task_exception_reraised(self): flow = utils.NastyFailingTask() engine = self._make_engine(flow) self.assertRaisesRegexp(RuntimeError, '^Gotcha', engine.run) utils.SaveOrderTask(name='task1') utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2') def test_parallel_revert(self): utils.FailingTask(name='fail'), self.assertIn('fail reverted(Failure: RuntimeError: Woot!)', self.values) utils.FailingTask() utils.SaveOrderTask(name='task3'), utils.FailingTask(name='fail') utils.SaveOrderTask(name='task3'),class EngineLinearAndUnorderedExceptionsTest(utils.EngineTestBase): def test_revert_for_unordered_in_linear(self): flow = lf.Flow('p-root').add( utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2'), uf.Flow('p-inner').add( utils.SaveOrderTask(name='task3'), utils.NastyFailingTask() ) ) engine = self._make_engine(flow) self.assertRaisesRegexp(RuntimeError, '^Gotcha', engine.run) # NOTE(imelnikov): maybe task3 was not run? possible_values = [ 'task1', 'task2', 'task3', 'task3 reverted(5)', 'task2 reverted(5)', 'task1 reverted(5)' ] self.assertIsSuperAndSubsequence(possible_values, self.values) possible_values_no_task3 = [ 'task1', 'task2', 'task2 reverted(5)', 'task1 reverted(5)' ] self.assertIsSuperAndSubsequence(self.values, possible_values_no_task3) def test_revert_for_linear_in_unordered(self): flow = uf.Flow('p-root').add( utils.SaveOrderTask(name='task1'), lf.Flow('p-inner').add( utils.SaveOrderTask(name='task2'), utils.NastyFailingTask() ) ) engine = self._make_engine(flow) self.assertRaisesRegexp(RuntimeError, '^Gotcha', engine.run) # NOTE(imelnikov): maybe task1 was not run possible_values = [ 'task1', 'task2', 'task2 reverted(5)', 'task1 reverted(5)' ] self.assertIsSubset(possible_values, self.values) possible_values_no_task1 = ['task2', 'task2 reverted(5)'] self.assertIsSuperAndSubsequence(self.values, possible_values_no_task1) EngineLinearAndUnorderedExceptionsTest,"," utils.SaveOrderTask(name='task1', sleep=0.01) utils.SaveOrderTask(name='task1', sleep=0.01), utils.SaveOrderTask(name='task2', sleep=0.01) def test_parallel_revert_common(self): utils.FailingTask(sleep=0.01), utils.FailingTask(sleep=0.1) def test_parallel_revert_specific(self): flow = uf.Flow('p-r-r').add( utils.SaveOrderTask(name='task1', sleep=0.01), utils.FailingTask(name='fail', sleep=0.01), utils.SaveOrderTask(name='task2', sleep=0.01) ) engine = self._make_engine(flow) self.assertRaisesRegexp(RuntimeError, '^Woot', engine.run) result = set(self.values) # NOTE(harlowja): task 1/2 may or may not have executed, even with the # sleeps due to the fact that the above is an unordered flow. possible_result = set(['task1', 'task2', 'fail reverted(Failure: RuntimeError: Woot!)', 'task2 reverted(5)', 'task1 reverted(5)']) self.assertIsSubset(possible_result, result) utils.SaveOrderTask(name='task3', sleep=0.1), utils.FailingTask(name='fail', sleep=0.01) utils.SaveOrderTask(name='task3', sleep=0.1),",93,35
openstack%2Fpython-openstackclient~master~I2255021c9d1f10f757686583b1ebe40b5f3a9ecb,openstack/python-openstackclient,master,I2255021c9d1f10f757686583b1ebe40b5f3a9ecb,Add token create subcommand for identity v3 api,MERGED,2014-01-29 07:59:47.000000000,2014-01-31 17:28:02.000000000,2014-01-31 17:28:02.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2468}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-01-29 07:59:47.000000000', 'files': ['openstackclient/tests/identity/v3/test_token.py', 'openstackclient/identity/v3/token.py', 'openstackclient/tests/identity/v3/fakes.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a8d828f330119502fc18107c264f2944548a7fb9', 'message': 'Add token create subcommand for identity v3 api\n\nImplements token create subcommand which is an equivalent of keystone\ntoken-get command. Original ""wrap"" parameter for keystone token-get is\nnot implemented yet due to cliff Bug #1269299\n\nThis is a part of: blueprint add-identity-token-support\n\nChange-Id: I2255021c9d1f10f757686583b1ebe40b5f3a9ecb\n'}]",7,69805,a8d828f330119502fc18107c264f2944548a7fb9,10,4,1,2468,,,0,"Add token create subcommand for identity v3 api

Implements token create subcommand which is an equivalent of keystone
token-get command. Original ""wrap"" parameter for keystone token-get is
not implemented yet due to cliff Bug #1269299

This is a part of: blueprint add-identity-token-support

Change-Id: I2255021c9d1f10f757686583b1ebe40b5f3a9ecb
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/05/69805/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/identity/v3/test_token.py', 'openstackclient/identity/v3/token.py', 'openstackclient/tests/identity/v3/fakes.py', 'setup.cfg']",4,a8d828f330119502fc18107c264f2944548a7fb9,bug/1269299, token_create = openstackclient.identity.v3.token:CreateToken ,,117,0
openstack%2Fcinder~master~Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d,openstack/cinder,master,Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d,Brick LVM: Handle space info as numeric types,MERGED,2014-01-03 19:43:03.000000000,2014-01-31 17:15:45.000000000,2014-01-31 17:15:44.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 8574}]","[{'number': 1, 'created': '2014-01-03 19:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71a46bfbd372e22ddd917fe956d014fc6106c280', 'message': 'Brick LVM: Handle space info as numeric types\n\nRather than relying on callers to cast values from the VG object\nto float, always create them as floats up front.\n\nThis removes the nosuffix option used with the LVM commands in\nBrick, as it does not appear to be used.\n\nAlso removes unneeded self.vg_pool_name variable.\n\nChange-Id: Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d\n'}, {'number': 2, 'created': '2014-01-04 16:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/317600042b07018a25b030c15930236333111885', 'message': 'Brick LVM: Handle space info as numeric types\n\nRather than relying on callers to cast values from the VG object\nto float, always create them as floats up front.\n\nThis removes the nosuffix option used with the LVM commands in\nBrick, as it does not appear to be used.\n\nAlso removes unneeded self.vg_pool_name variable.\n\nChange-Id: Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d\n'}, {'number': 3, 'created': '2014-01-25 14:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2d87d3f6e2971f253ed3155cf16a9f17f9c36504', 'message': 'Brick LVM: Handle space info as numeric types\n\nRather than relying on callers to cast values from the VG object\nto float, always create them as floats up front.\n\nThis removes the nosuffix option used with the LVM commands in\nBrick, as it does not appear to be used.\n\nAlso removes unneeded self.vg_pool_name variable.\n\nChange-Id: Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d\n'}, {'number': 4, 'created': '2014-01-30 15:26:59.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'cinder/volume/utils.py', 'cinder/tests/brick/fake_lvm.py', 'cinder/tests/brick/test_brick_lvm.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf9915e363924c49a9039543c85c8fdb5322527b', 'message': 'Brick LVM: Handle space info as numeric types\n\nRather than relying on callers to cast values from the VG object\nto float, always create them as floats up front.\n\nThis removes the nosuffix option used with the LVM commands in\nBrick, as it does not appear to be used.\n\nAlso removes unneeded self.vg_pool_name variable.\n\nChange-Id: Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d\n'}]",0,64889,cf9915e363924c49a9039543c85c8fdb5322527b,37,9,4,4523,,,0,"Brick LVM: Handle space info as numeric types

Rather than relying on callers to cast values from the VG object
to float, always create them as floats up front.

This removes the nosuffix option used with the LVM commands in
Brick, as it does not appear to be used.

Also removes unneeded self.vg_pool_name variable.

Change-Id: Ic19ce206bc8069071e3c2d9e58ba5393119e9b4d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/89/64889/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/volume/utils.py', 'cinder/volume/drivers/lvm.py']",3,71a46bfbd372e22ddd917fe956d014fc6106c280,brick_lvm, data['total_capacity_gb'] = self.vg.vg_size data['free_capacity_gb'] = self.vg.vg_free_space if self.configuration.lvm_type == 'thin': data['total_capacity_gb'] = self.vg.vg_thin_pool_size data['free_capacity_gb'] = self.vg.vg_thin_pool_free_space, data['total_capacity_gb'] = float(self.vg.vg_size) data['free_capacity_gb'] = float(self.vg.vg_free_space) if self.configuration.lvm_type == 'thin': data['total_capacity_gb'] = float(self.vg.vg_thin_pool_size) data['free_capacity_gb'] = float(self.vg.vg_thin_pool_free_space),35,43
openstack%2Fceilometer~master~Ic9e3f5ced560ebd9e1e1a7aa8ea4492238754138,openstack/ceilometer,master,Ic9e3f5ced560ebd9e1e1a7aa8ea4492238754138,Force import path to be right in test_bin.py,ABANDONED,2014-01-29 20:28:03.000000000,2014-01-31 17:14:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-01-29 20:28:03.000000000', 'files': ['ceilometer/tests/test_bin.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a77ed23a76c8d4203d1fe9c9fa486417e5e50717', 'message': ""Force import path to be right in test_bin.py\n\nThe test that tries to run ceilometer-send-counter out of our\nbin directory fails for me reliably on my local system. I suspect\na change in the behavior of one of the tools in the test library\nstack, but can't say for sure. The script was failing because\nit could not import the ceilometer package, so the fix is to\nmake sure the import path is set in such a way that the package\ncan be found. Since test_bin.py can import ceilometer, but the\nchild process can't, all we have to do is export the right value\nfor PYTHONPATH when we create the child process.\n\nChange-Id: Ic9e3f5ced560ebd9e1e1a7aa8ea4492238754138\n""}]",0,69963,a77ed23a76c8d4203d1fe9c9fa486417e5e50717,7,3,1,2472,,,0,"Force import path to be right in test_bin.py

The test that tries to run ceilometer-send-counter out of our
bin directory fails for me reliably on my local system. I suspect
a change in the behavior of one of the tools in the test library
stack, but can't say for sure. The script was failing because
it could not import the ceilometer package, so the fix is to
make sure the import path is set in such a way that the package
can be found. Since test_bin.py can import ceilometer, but the
child process can't, all we have to do is export the right value
for PYTHONPATH when we create the child process.

Change-Id: Ic9e3f5ced560ebd9e1e1a7aa8ea4492238754138
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/63/69963/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/test_bin.py'],1,a77ed23a76c8d4203d1fe9c9fa486417e5e50717,bug/bin-test-fails,"import sysimport ceilometer ""--counter-name=mycounter""], # Something about one of the tools in # the test stack breaks the script's # ability to find ceilometer's # libraries sometimes, so we # brute-force it by passing the parent # directory as the PYTHONPATH. env={'PYTHONPATH': os.path.dirname(ceilometer.__path__[0])}, )"," ""--counter-name=mycounter""])",11,1
openstack%2Fdevstack~master~If939da305dcb9403c418219032ac6b50b0099bd3,openstack/devstack,master,If939da305dcb9403c418219032ac6b50b0099bd3,Copy container-sync-realms.conf in /etc/swift,MERGED,2014-01-29 21:40:29.000000000,2014-01-31 17:06:38.000000000,2014-01-31 17:06:38.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-01-29 21:40:29.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f2c1a712e82ac1d347b0fb6526c79471a9ef8d55', 'message': 'Copy container-sync-realms.conf in /etc/swift\n\nWe need the new container-sync realms configuration or we will get a\nnasty harmless error opening file at swift proxy startup.\n\nChange-Id: If939da305dcb9403c418219032ac6b50b0099bd3\nCloses-Bug: 1274295\n'}]",0,69986,f2c1a712e82ac1d347b0fb6526c79471a9ef8d55,6,3,1,866,,,0,"Copy container-sync-realms.conf in /etc/swift

We need the new container-sync realms configuration or we will get a
nasty harmless error opening file at swift proxy startup.

Change-Id: If939da305dcb9403c418219032ac6b50b0099bd3
Closes-Bug: 1274295
",git fetch https://review.opendev.org/openstack/devstack refs/changes/86/69986/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,f2c1a712e82ac1d347b0fb6526c79471a9ef8d55,bug/1274295, cp ${SWIFT_DIR}/etc/container-sync-realms.conf-sample ${SWIFT_CONF_DIR}/container-sync-realms.conf ,,2,0
openstack%2Fdevstack~stable%2Fhavana~Ib4439b0d32f103253b461841fa903c65763ff280,openstack/devstack,stable/havana,Ib4439b0d32f103253b461841fa903c65763ff280,Stop all neutron-ns-metadata-proxy with stop_neutron,MERGED,2014-01-30 14:41:30.000000000,2014-01-31 17:06:36.000000000,2014-01-31 17:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-01-30 14:41:30.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6c223b3204605f5df9dcf7c11891120126dc2ab0', 'message': ""Stop all neutron-ns-metadata-proxy with stop_neutron\n\nProcess name is actually python therefore neutron-ns-metadata-proxy\npattern didn't match wanted process.\n\nCloses-bug: #1269982\nChange-Id: Ib4439b0d32f103253b461841fa903c65763ff280\n(cherry picked from commit 1f76328027bb5cee0b0ea7077f4c59c919f1c4ae)\n""}]",0,70124,6c223b3204605f5df9dcf7c11891120126dc2ab0,6,4,1,8655,,,0,"Stop all neutron-ns-metadata-proxy with stop_neutron

Process name is actually python therefore neutron-ns-metadata-proxy
pattern didn't match wanted process.

Closes-bug: #1269982
Change-Id: Ib4439b0d32f103253b461841fa903c65763ff280
(cherry picked from commit 1f76328027bb5cee0b0ea7077f4c59c919f1c4ae)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/24/70124/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,6c223b3204605f5df9dcf7c11891120126dc2ab0,bug/1269982, sudo pkill -9 -f neutron-ns-metadata-proxy || :, sudo pkill -9 neutron-ns-metadata-proxy || :,1,1
openstack%2Fnova~master~I8337d672cb119efe700aa6be420fdac9864c1577,openstack/nova,master,I8337d672cb119efe700aa6be420fdac9864c1577,Workers verification for WSGI service,MERGED,2014-01-17 02:03:55.000000000,2014-01-31 17:05:39.000000000,2014-01-31 17:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4428}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-17 02:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/977c0096988ce08f00b1e5f29e9597870eeea8a3', 'message': 'Workers verification for WSGI service\n\nWhen we start the nova-api service, the *_workers (metadata_workers,\nec2_workers, osapi_compute_workers) value are not verified if the value\nis negative. If the user passes a negative value accidentally, and\nInvalidInput exception will be threw.\n\nChange-Id: I8337d672cb119efe700aa6be420fdac9864c1577\nCloses-bug: #1269997\n'}, {'number': 2, 'created': '2014-01-30 02:10:41.000000000', 'files': ['nova/tests/test_service.py', 'nova/service.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/eba96f363e370ebdbd08c3bdfbe8f57df6cb7a80', 'message': 'Workers verification for WSGI service\n\nWhen we start the nova-api service, the *_workers (metadata_workers,\nec2_workers, osapi_compute_workers) value are not verified if the value\nis negative. If the user passes a negative value accidentally, and\nInvalidInput exception will be threw.\n\nChange-Id: I8337d672cb119efe700aa6be420fdac9864c1577\nCloses-bug: #1269997\n'}]",2,67355,eba96f363e370ebdbd08c3bdfbe8f57df6cb7a80,16,12,2,4428,,,0,"Workers verification for WSGI service

When we start the nova-api service, the *_workers (metadata_workers,
ec2_workers, osapi_compute_workers) value are not verified if the value
is negative. If the user passes a negative value accidentally, and
InvalidInput exception will be threw.

Change-Id: I8337d672cb119efe700aa6be420fdac9864c1577
Closes-bug: #1269997
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/67355/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/service.py', 'nova/tests/test_service.py']",2,977c0096988ce08f00b1e5f29e9597870eeea8a3,workers-verification," def test_service_start_with_illegal_workers(self): CONF.set_override(""osapi_compute_workers"", -1) self.assertRaises(exception.InvalidInput, service.WSGIService, ""osapi_compute"") ",,13,0
openstack%2Fnova~master~If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9,openstack/nova,master,If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9,Remove XML support from migrations pci multiple_create v3 API plugins,MERGED,2014-01-29 03:22:43.000000000,2014-01-31 17:04:44.000000000,2014-01-31 17:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 7641}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/537658703b3f5cfe86936fd01948f54fcc498f26', 'message': 'Remove XML support from migrations pci multiple_create v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - migrations\n - multiple_create\n - pci\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9\n'}, {'number': 2, 'created': '2014-01-30 14:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da2b1cad65e00b4fef485a04222dc90acd075a19', 'message': 'Remove XML support from migrations pci multiple_create v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - migrations\n - multiple_create\n - pci\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9\n'}, {'number': 3, 'created': '2014-01-30 16:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10584e5b1510a4d7f03acf4ef5017be6dfc3acc5', 'message': 'Remove XML support from migrations pci multiple_create v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - migrations\n - multiple_create\n - pci\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9\n'}, {'number': 4, 'created': '2014-01-31 04:32:49.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/pci.py', 'nova/api/openstack/compute/plugins/v3/multiple_create.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/12ecf0bdd80ea8d9643f1f798bc0e263453b9103', 'message': 'Remove XML support from migrations pci multiple_create v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - migrations\n - multiple_create\n - pci\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9\n'}]",5,69778,12ecf0bdd80ea8d9643f1f798bc0e263453b9103,27,7,4,7641,,,0,"Remove XML support from migrations pci multiple_create v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - migrations
 - multiple_create
 - pci

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: If7dfda52eea63a39fae0e546cfeaf4b1d814b7b9
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/69778/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/pci.py', 'nova/api/openstack/compute/plugins/v3/multiple_create.py']",3,537658703b3f5cfe86936fd01948f54fcc498f26,bp/remove-v3-xml-api,,"from nova.openstack.common import strutils def server_xml_extract_server_deserialize(self, server_node, server_dict): res_id = server_node.getAttribute(RRID_ATTRIBUTE_NAME) if res_id: server_dict[RRID_ATTRIBUTE_NAME] = strutils.bool_from_string( res_id) min_count = server_node.getAttribute(MIN_ATTRIBUTE_NAME) if min_count: server_dict[MIN_ATTRIBUTE_NAME] = min_count max_count = server_node.getAttribute(MAX_ATTRIBUTE_NAME) if max_count: server_dict[MAX_ATTRIBUTE_NAME] = max_count",0,98
openstack%2Fnova~master~I92b94dbcd0405d8f2bb818ad1c44c4f4934c8bec,openstack/nova,master,I92b94dbcd0405d8f2bb818ad1c44c4f4934c8bec,Recommend the right call instead of datetime.now(),MERGED,2013-12-05 14:22:30.000000000,2014-01-31 16:55:19.000000000,2014-01-31 16:55:16.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5652}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-05 14:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33719f3ed73ade822062f08216471c2e5cf4e6d6', 'message': 'Recommend the right function instead of dt.now()\n\nCloses bug: #1258166\n\nChange-Id: I92b94dbcd0405d8f2bb818ad1c44c4f4934c8bec\n'}, {'number': 2, 'created': '2013-12-05 14:26:50.000000000', 'files': ['nova/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7dd4d98c2873e1868296ef973f0be42cadcb6d6d', 'message': 'Recommend the right call instead of datetime.now()\n\nCloses-Bug: #1258166\nChange-Id: I92b94dbcd0405d8f2bb818ad1c44c4f4934c8bec\n'}]",0,60247,7dd4d98c2873e1868296ef973f0be42cadcb6d6d,12,6,2,1528,,,0,"Recommend the right call instead of datetime.now()

Closes-Bug: #1258166
Change-Id: I92b94dbcd0405d8f2bb818ad1c44c4f4934c8bec
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/60247/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/hacking/checks.py'],1,33719f3ed73ade822062f08216471c2e5cf4e6d6,," msg = ""N310: timeutils.utcnow() must be used instead of datetime.%s()"" yield (pos, msg % f)"," msg = ""N310: timeutils.%s() must be used instead of datetime.%s()"" yield (pos, msg % (f, f))",2,2
openstack%2Fsahara~master~Ic35e275fd404e83e02b503fa8ee8c1c372885e8b,openstack/sahara,master,Ic35e275fd404e83e02b503fa8ee8c1c372885e8b,Fix nova client initialization arguments,MERGED,2014-01-26 17:14:37.000000000,2014-01-31 16:45:41.000000000,2014-01-31 16:45:41.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-26 17:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b49ecba4c014b0204a49dafe5caa5f65507f9d4e', 'message': 'Fix nova client initialization arguments\n\nWe already have token and endpoints in context, so, just pass them to\nthe nova client.\n\nChange-Id: Ic35e275fd404e83e02b503fa8ee8c1c372885e8b\n'}, {'number': 2, 'created': '2014-01-26 17:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6f79a17d106b70867bcdcdc77575e3eebd209ff2', 'message': 'Fix nova client initialization arguments\n\nWe already have token and endpoints in context, so, just pass them to\nthe nova client.\n\nChange-Id: Ic35e275fd404e83e02b503fa8ee8c1c372885e8b\n'}, {'number': 3, 'created': '2014-01-28 15:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9c51a84edb0015057faeba491f9b7b2d6b18a302', 'message': 'Fix nova client initialization arguments\n\nWe already have token and endpoints in context, so, just pass them to\nthe nova client.\n\nChange-Id: Ic35e275fd404e83e02b503fa8ee8c1c372885e8b\n'}, {'number': 4, 'created': '2014-01-28 15:28:08.000000000', 'files': ['savanna/utils/openstack/nova.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/96fa4cb8263f8c3fb6deb455ed5c84317aa48330', 'message': 'Fix nova client initialization arguments\n\nWe already have token and endpoints in context, so, just pass them to\nthe nova client.\n\nChange-Id: Ic35e275fd404e83e02b503fa8ee8c1c372885e8b\n'}]",6,69210,96fa4cb8263f8c3fb6deb455ed5c84317aa48330,27,9,4,6786,,,0,"Fix nova client initialization arguments

We already have token and endpoints in context, so, just pass them to
the nova client.

Change-Id: Ic35e275fd404e83e02b503fa8ee8c1c372885e8b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/10/69210/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/utils/openstack/nova.py'],1,b49ecba4c014b0204a49dafe5caa5f65507f9d4e,," nova = nova_client.Client(username=ctx.username, api_key=None, project_id=ctx.tenant_id)"," nova = nova_client.Client(ctx.username, ctx.token, ctx.tenant_id, auth_url=compute_url)",3,3
openstack%2Fsahara~master~Ia45eb58381460a8668ed16031ec3fe47905cea31,openstack/sahara,master,Ia45eb58381460a8668ed16031ec3fe47905cea31,Remove kombu from requirements,MERGED,2014-01-30 14:51:22.000000000,2014-01-31 16:45:40.000000000,2014-01-31 16:45:39.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 8090}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-30 14:51:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/35222cfe6ec49664a96021f856817fea91c85136', 'message': 'Remove kombu from requirements\n\nIt was added with oslo.rpc half a year ago. We neither need it\nnow nor in foreseeable future.\n\nChange-Id: Ia45eb58381460a8668ed16031ec3fe47905cea31\n'}]",0,70125,35222cfe6ec49664a96021f856817fea91c85136,10,7,1,7109,,,0,"Remove kombu from requirements

It was added with oslo.rpc half a year ago. We neither need it
now nor in foreseeable future.

Change-Id: Ia45eb58381460a8668ed16031ec3fe47905cea31
",git fetch https://review.opendev.org/openstack/sahara refs/changes/25/70125/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,35222cfe6ec49664a96021f856817fea91c85136,(detached,,kombu>=2.4.8,0,1
openstack%2Fopenstack-manuals~master~I5122bf81004984e9d32e530bb0d2852b3df13b4a,openstack/openstack-manuals,master,I5122bf81004984e9d32e530bb0d2852b3df13b4a,Modified punctuation and clarified a service information sentence.,MERGED,2014-01-30 23:04:03.000000000,2014-01-31 16:15:18.000000000,2014-01-31 16:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-30 23:04:03.000000000', 'files': ['doc/config-reference/block-storage/section_block-storage-overview.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d39a399d1f0f0f989caba731d23d0bf2c16be8dd', 'message': 'Modified punctuation and clarified a service information sentence.\n\nAdded uniform punctuation and clarified the\n""Volumes, Snapshots, and Backups"" description.\n\nChange-Id: I5122bf81004984e9d32e530bb0d2852b3df13b4a\n'}]",0,70251,d39a399d1f0f0f989caba731d23d0bf2c16be8dd,6,3,1,6838,,,0,"Modified punctuation and clarified a service information sentence.

Added uniform punctuation and clarified the
""Volumes, Snapshots, and Backups"" description.

Change-Id: I5122bf81004984e9d32e530bb0d2852b3df13b4a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/70251/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/section_block-storage-overview.xml'],1,d39a399d1f0f0f989caba731d23d0bf2c16be8dd,some_cinder_punctuation," <para><systemitem class=""service"">cinder-backup</systemitem>. created.</para> created.</para> (shared between snapshots and volumes).</para> snapshots which are derived from volumes and volume backups:</para>"," <para><systemitem class=""service"">cinder-backup</systemitem> created</para> created</para> (shared between snapshots and volumes)</para> snapshots, which are derived from volumes, and backups:</para>",6,6
openstack%2Fopenstack-manuals~master~I0bd35b3f18731c5c5b7c7a35abae999cf937acf9,openstack/openstack-manuals,master,I0bd35b3f18731c5c5b7c7a35abae999cf937acf9,Edited terminology for hypervisor support in Compute,MERGED,2014-01-30 06:22:26.000000000,2014-01-31 16:11:47.000000000,2014-01-31 16:11:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-01-30 06:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d156e0473f0ce1f07c4267a09200cb5582924dff', 'message': 'Edited terminology for hypervisor support in Compute\n\nThe word ""type"" has a specific application when used in reference to\nhypervisor technology. The bulleted list that follows could be\nconsidered a variety of bare metal hypervisors rather than\nvirtualization standards.\n\nChange-Id: I0bd35b3f18731c5c5b7c7a35abae999cf937acf9\nPartial-Bug: #1217503\n'}, {'number': 2, 'created': '2014-01-31 02:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a701c127f77d3502098398171edaa78acafd1010', 'message': 'Edited terminology for hypervisor support in Compute\n\nThe word ""type"" has a specific application when used in reference to\nhypervisor technology. The bulleted list that follows could be\nconsidered a variety of bare metal hypervisors rather than\nvirtualization standards.\n\nChange-Id: I0bd35b3f18731c5c5b7c7a35abae999cf937acf9\nPartial-Bug: #1217503\n'}, {'number': 3, 'created': '2014-01-31 06:53:52.000000000', 'files': ['doc/admin-guide-cloud/ch_compute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1fff455519112615f5b3f7ef9586a3b33041425b', 'message': 'Edited terminology for hypervisor support in Compute\n\nThe word ""type"" has a specific application when used in reference to\nhypervisor technology. The bulleted list that follows could be\nconsidered a variety of bare metal hypervisors rather than\nvirtualization standards.\n\nChange-Id: I0bd35b3f18731c5c5b7c7a35abae999cf937acf9\nPartial-Bug: #1217503\n'}]",2,70063,1fff455519112615f5b3f7ef9586a3b33041425b,13,3,3,9930,,,0,"Edited terminology for hypervisor support in Compute

The word ""type"" has a specific application when used in reference to
hypervisor technology. The bulleted list that follows could be
considered a variety of bare metal hypervisors rather than
virtualization standards.

Change-Id: I0bd35b3f18731c5c5b7c7a35abae999cf937acf9
Partial-Bug: #1217503
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/70063/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/ch_compute.xml'],1,d156e0473f0ce1f07c4267a09200cb5582924dff,Conventions-1217503, hypervisors in different availability zones. Compute includes support for the following hypervisors:</para>, hypervisors in different availability zones. The types of virtualization standards that can be used with Compute include:</para>,2,3
openstack%2Fheat-templates~master~I667e7d5a7ace744949e8b7acf0060381c21a0775,openstack/heat-templates,master,I667e7d5a7ace744949e8b7acf0060381c21a0775,Run dos2unix over template files,MERGED,2014-01-29 22:49:49.000000000,2014-01-31 16:05:52.000000000,2014-01-31 16:05:52.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-01-29 22:49:49.000000000', 'files': ['hot/servers_in_existing_neutron_net.yaml', 'hot/servers_in_new_neutron_net.yaml', 'hot/F18/NovaInstanceWithCinderVolume_Native.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/69783277892145eb7e18b6da3e0d09e26c704ead', 'message': 'Run dos2unix over template files\n\nRemove DOS line-endings (CRLF) from templates.\n\nChange-Id: I667e7d5a7ace744949e8b7acf0060381c21a0775\n'}]",0,70004,69783277892145eb7e18b6da3e0d09e26c704ead,9,6,1,4257,,,0,"Run dos2unix over template files

Remove DOS line-endings (CRLF) from templates.

Change-Id: I667e7d5a7ace744949e8b7acf0060381c21a0775
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/04/70004/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/servers_in_existing_neutron_net.yaml', 'hot/servers_in_new_neutron_net.yaml', 'hot/F18/NovaInstanceWithCinderVolume_Native.yaml']",3,69783277892145eb7e18b6da3e0d09e26c704ead,,"heat_template_version: 2013-05-23 description: > A template showing how to create a Nova instance, a Cinder volume and attach the volume to the instance. The template uses only Heat OpenStack native resource types. parameters: key_name: type: string description: Name of an existing key pair to enable SSH access to the instance. instance_type: type: string description: Type of the instance to be created. default: m1.small constraints: - allowed_values: [m1.small, m1.medium, m1.large] description: Value must be one of 'm1.small', 'm1.medium' or 'm1.large'. image_id: type: string description: ID of the image to use for the instance to be created. default: F18-x86_64-cfntools constraints: - allowed_values: [ F18-i386-cfntools, F18-x86_64-cfntools ] description: Image ID must be either F18-i386-cfntools or F18-x86_64-cfntools. availability_zone: type: String description: The Availability Zone to launch the instance. default: nova volume_size: type: Number description: Size of the volume to be created. default: 1 constraints: - range: { min: 1, max: 1024 } description: must be between 1 and 1024 Gb. resources: nova_instance: type: OS::Nova::Server properties: availability_zone: { get_param: availability_zone } image: { get_param: image_id } flavor: { get_param: instance_type } key_name: { get_param: key_name } cinder_volume: type: OS::Cinder::Volume properties: size: { get_param: volume_size } availability_zone: { get_param: availability_zone } volume_attachment: type: OS::Cinder::VolumeAttachment properties: volume_id: { get_resource: cinder_volume } instance_uuid: { get_resource: nova_instance } mountpoint: /dev/vdc outputs: instance_ip: description: Public IP address of the newly created Nova instance. value: { get_attr: [nova_instance, first_address] }","heat_template_version: 2013-05-23 description: > A template showing how to create a Nova instance, a Cinder volume and attach the volume to the instance. The template uses only Heat OpenStack native resource types. parameters: key_name: type: string description: Name of an existing key pair to enable SSH access to the instance. instance_type: type: string description: Type of the instance to be created. default: m1.small constraints: - allowed_values: [m1.small, m1.medium, m1.large] description: Value must be one of 'm1.small', 'm1.medium' or 'm1.large'. image_id: type: string description: ID of the image to use for the instance to be created. default: F18-x86_64-cfntools constraints: - allowed_values: [ F18-i386-cfntools, F18-x86_64-cfntools ] description: Image ID must be either F18-i386-cfntools or F18-x86_64-cfntools. availability_zone: type: String description: The Availability Zone to launch the instance. default: nova volume_size: type: Number description: Size of the volume to be created. default: 1 constraints: - range: { min: 1, max: 1024 } description: must be between 1 and 1024 Gb. resources: nova_instance: type: OS::Nova::Server properties: availability_zone: { get_param: availability_zone } image: { get_param: image_id } flavor: { get_param: instance_type } key_name: { get_param: key_name } cinder_volume: type: OS::Cinder::Volume properties: size: { get_param: volume_size } availability_zone: { get_param: availability_zone } volume_attachment: type: OS::Cinder::VolumeAttachment properties: volume_id: { get_resource: cinder_volume } instance_uuid: { get_resource: nova_instance } mountpoint: /dev/vdc outputs: instance_ip: description: Public IP address of the newly created Nova instance. value: { get_attr: [nova_instance, first_address] } ",278,278
openstack%2Ftripleo-incubator~master~I89e63bb9a12988c0a4fa9fc781719070c98a0dfa,openstack/tripleo-incubator,master,I89e63bb9a12988c0a4fa9fc781719070c98a0dfa,Documents workarounds for tmpfs space errors,MERGED,2014-01-30 10:18:51.000000000,2014-01-31 15:58:32.000000000,2014-01-31 15:58:32.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9976}]","[{'number': 1, 'created': '2014-01-30 10:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0d273b9a8ab60c980bc5083c5a3454a0036a6975', 'message': 'Documents workarounds for tmpfs space errors\n\ntmpfs space errors result from creating a new seed image on\na system with less than 9GB of RAM. This patch documents\nhow to prevent the tmpfs space errors by avoiding the use of\ntmpfs or specifying a minimum tmpfs size required.\nCloses-Bug: 1215298\n\nChange-Id: I89e63bb9a12988c0a4fa9fc781719070c98a0dfa\n'}, {'number': 2, 'created': '2014-01-31 14:14:55.000000000', 'files': ['doc/source/deploying.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/4884df9c60ecfa6a9d61224eb0532c588ed499f7', 'message': 'Documents workarounds for tmpfs space errors\n\ntmpfs space errors result from creating a new seed image on\na system with less than 9GB of RAM. This patch documents\nhow to prevent the tmpfs space errors by avoiding the use of\ntmpfs or specifying a minimum tmpfs size required.\nCloses-Bug: 1215298\n\nChange-Id: I89e63bb9a12988c0a4fa9fc781719070c98a0dfa\n'}]",1,70080,4884df9c60ecfa6a9d61224eb0532c588ed499f7,10,4,2,9976,,,0,"Documents workarounds for tmpfs space errors

tmpfs space errors result from creating a new seed image on
a system with less than 9GB of RAM. This patch documents
how to prevent the tmpfs space errors by avoiding the use of
tmpfs or specifying a minimum tmpfs size required.
Closes-Bug: 1215298

Change-Id: I89e63bb9a12988c0a4fa9fc781719070c98a0dfa
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/80/70080/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploying.rst'],1,0d273b9a8ab60c980bc5083c5a3454a0036a6975,bug/1215298,"New seed image creation returns tmpfs space errors (systems with < 9GB of RAM) ------------------------------------------------------------------------------ Creating a new seed image takes up to 4.5GB of space inside a /tmp/imageXXXXX directory. tmpfs can take up to 50% of RAM and systems with less than 9GB of RAM will fail in this step. When using 'diskimage-builder' directly, you can prevent the space errors by: - avoiding tmpfs with --no-tmpfs or - specifying a minimum tmpfs size required with --min-tmpf If you are using 'boot-seed-vm', set the environment variable DIB_NO_TMPFS=1. ",,13,0
openstack%2Fnova~master~I52993874dad7d89edcdaba36e1227c26cc3e8f43,openstack/nova,master,I52993874dad7d89edcdaba36e1227c26cc3e8f43,Remove extra space in log message,MERGED,2014-01-31 02:40:49.000000000,2014-01-31 15:53:32.000000000,2014-01-31 15:53:29.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 8125}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 02:40:49.000000000', 'files': ['nova/scheduler/filters/compute_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/317da07269332336d2a574f88dbdcbe8526a42d7', 'message': 'Remove extra space in log message\n\nChange-Id: I52993874dad7d89edcdaba36e1227c26cc3e8f43\n'}]",0,70282,317da07269332336d2a574f88dbdcbe8526a42d7,10,6,1,1849,,,0,"Remove extra space in log message

Change-Id: I52993874dad7d89edcdaba36e1227c26cc3e8f43
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/70282/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/compute_filter.py'],1,317da07269332336d2a574f88dbdcbe8526a42d7,2space," ""while""), {'host_state': host_state})"," "" while""), {'host_state': host_state})",1,1
openstack%2Fapi-site~master~I75e4282748a63a19b30593444fd9a6ea8c2c7af7,openstack/api-site,master,I75e4282748a63a19b30593444fd9a6ea8c2c7af7,Replace username with name,MERGED,2014-01-30 09:46:11.000000000,2014-01-31 14:59:37.000000000,2014-01-31 14:59:37.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-01-30 09:46:11.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSADM.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/2894dea2a570bb788aff84ae8faadf22644bc498', 'message': 'Replace username with name\n\nKeystone V2 API for user resource has field name instead of username.\nThis patch fixes this problem in samples, also fixes incorrect param\ntype.\n\nChange-Id: I75e4282748a63a19b30593444fd9a6ea8c2c7af7\nCloses-Bug: #1273860\n'}]",0,70078,2894dea2a570bb788aff84ae8faadf22644bc498,5,2,1,6676,,,0,"Replace username with name

Keystone V2 API for user resource has field name instead of username.
This patch fixes this problem in samples, also fixes incorrect param
type.

Change-Id: I75e4282748a63a19b30593444fd9a6ea8c2c7af7
Closes-Bug: #1273860
",git fetch https://review.opendev.org/openstack/api-site refs/changes/78/70078/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSADM.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.xml']",14,2894dea2a570bb788aff84ae8faadf22644bc498,bug/1273860," name=""jqsmith"" id=""u1000""/>"," username=""jqsmith"" id=""u1000""/>",20,34
openstack%2Fnova~master~Iaa29c5f667c03b292d4f3383ac38bf544a5ef577,openstack/nova,master,Iaa29c5f667c03b292d4f3383ac38bf544a5ef577,Remove more v3 xml unit test code,ABANDONED,2014-01-30 15:19:13.000000000,2014-01-31 14:51:30.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 7641}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-30 15:19:13.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_hypervisors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2578c5289dd006a92c6b4b7bbef4d36864287b51', 'message': 'Remove more v3 xml unit test code\n\nRemove a couple more remnants of unit testing XML support in the v3\ncompute API.\n\nPart of blueprint remove-v3-xml-api\n\nChange-Id: Iaa29c5f667c03b292d4f3383ac38bf544a5ef577\n'}]",0,70138,2578c5289dd006a92c6b4b7bbef4d36864287b51,7,5,1,1561,,,0,"Remove more v3 xml unit test code

Remove a couple more remnants of unit testing XML support in the v3
compute API.

Part of blueprint remove-v3-xml-api

Change-Id: Iaa29c5f667c03b292d4f3383ac38bf544a5ef577
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/70138/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_hypervisors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py']",2,2578c5289dd006a92c6b4b7bbef4d36864287b51,bp/remove-v3-xml-api,,"class SimpleTenantUsageSerializerTest(test.TestCase): def _verify_server_usage(self, raw_usage, tree): self.assertEqual('server_usage', tree.tag) # Figure out what fields we expect not_seen = set(raw_usage.keys()) for child in tree: self.assertIn(child.tag, not_seen) not_seen.remove(child.tag) self.assertEqual(str(raw_usage[child.tag]), child.text) self.assertEqual(len(not_seen), 0) def _verify_tenant_usage(self, raw_usage, tree): self.assertEqual('tenant_usage', tree.tag) # Figure out what fields we expect not_seen = set(raw_usage.keys()) for child in tree: self.assertIn(child.tag, not_seen) not_seen.remove(child.tag) if child.tag == 'server_usages': for idx, gr_child in enumerate(child): self._verify_server_usage(raw_usage['server_usages'][idx], gr_child) else: self.assertEqual(str(raw_usage[child.tag]), child.text) self.assertEqual(len(not_seen), 0) ",0,66
openstack%2Fnova~master~I4a929227c0e53c497798eee02f5dcecdf5f7bc60,openstack/nova,master,I4a929227c0e53c497798eee02f5dcecdf5f7bc60,"Revert ""Disable libguestfs' default atexit handlers.""",ABANDONED,2014-01-31 11:46:06.000000000,2014-01-31 14:51:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 5292}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-01-31 11:46:06.000000000', 'files': ['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6847058d96117591109e4ead289f93bc653f07cb', 'message': 'Revert ""Disable libguestfs\' default atexit handlers.""\n\nThis reverts commit 02abbef960b12deaa7a911788dbc56f3a0bd555a\n\nBecause guestfs support was not tested in the gate, this went in\nwithout any testing. Neither the RHEL6 nor Ubuntu 12.04 versions of\nguestfs have this option, so it makes guestsfs break in both\nenvironments.\n\nWhen we attempted to turn on guestfs to stop breaking neutron with\nnbd, this blew up on us in the gate.\n\nChange-Id: I4a929227c0e53c497798eee02f5dcecdf5f7bc60\nCloses-Bug: #1271562\nRelated-Bug: #1261475\n'}]",0,70333,6847058d96117591109e4ead289f93bc653f07cb,11,6,1,2750,,,0,"Revert ""Disable libguestfs' default atexit handlers.""

This reverts commit 02abbef960b12deaa7a911788dbc56f3a0bd555a

Because guestfs support was not tested in the gate, this went in
without any testing. Neither the RHEL6 nor Ubuntu 12.04 versions of
guestfs have this option, so it makes guestsfs break in both
environments.

When we attempted to turn on guestfs to stop breaking neutron with
nbd, this blew up on us in the gate.

Change-Id: I4a929227c0e53c497798eee02f5dcecdf5f7bc60
Closes-Bug: #1271562
Related-Bug: #1261475
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/70333/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py']",2,6847058d96117591109e4ead289f93bc653f07cb,70331, self.handle = tpool.Proxy(guestfs.GuestFS()), self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)),2,2
openstack%2Fmurano-dashboard~release-0.4~I980c97157f27adba2b98d2c6126a0f1bd6e91654,openstack/murano-dashboard,release-0.4,I980c97157f27adba2b98d2c6126a0f1bd6e91654,Show floating IP checkbox only for 'routed',MERGED,2014-01-31 11:42:35.000000000,2014-01-31 14:47:14.000000000,2014-01-31 14:47:14.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-01-31 11:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4cdfca91561f58b7556b07f035cb28eca3ba6542', 'message': ""Show floating IP checkbox only for 'routed'\n\nSet floatingIp to the unit level\nblueprint auto-assign-floating-ip\n\nChange-Id: I980c97157f27adba2b98d2c6126a0f1bd6e91654\n""}, {'number': 2, 'created': '2014-01-31 14:20:17.000000000', 'files': ['muranodashboard/dynamic_ui/forms.py', 'muranodashboard/dynamic_ui/fields.py', 'muranodashboard/environments/tabs.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d23497d18be09a0d305a724abb87ff95d2fa8fb7', 'message': ""Show floating IP checkbox only for 'routed'\n\nSet floatingIp to the unit level\nblueprint auto-assign-floating-ip\n\nChange-Id: I980c97157f27adba2b98d2c6126a0f1bd6e91654\n""}]",2,70330,d23497d18be09a0d305a724abb87ff95d2fa8fb7,13,6,2,7549,,,0,"Show floating IP checkbox only for 'routed'

Set floatingIp to the unit level
blueprint auto-assign-floating-ip

Change-Id: I980c97157f27adba2b98d2c6126a0f1bd6e91654
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/30/70330/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/dynamic_ui/forms.py', 'muranodashboard/dynamic_ui/fields.py', 'muranodashboard/environments/tabs.py']",3,4cdfca91561f58b7556b07f035cb28eca3ba6542,bp/auto-assign-floating-ip, detail_info['Floating IP'] = unit.get('floatingip'),,12,2
openstack%2Fswift~master~I33d58e635b5cd4a7169d01c4b0410e7cb78ec877,openstack/swift,master,I33d58e635b5cd4a7169d01c4b0410e7cb78ec877,Add some tests for bin/swift-recon,ABANDONED,2014-01-31 14:26:40.000000000,2014-01-31 14:27:23.000000000,,[],"[{'number': 1, 'created': '2014-01-31 14:26:40.000000000', 'files': ['test/unit/cli/__init__.py', 'test/unit/cli/test_recon_client.py', 'swift/cli/swift_recon.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/swift/commit/44ffc28fcb03b149acb07f83afcbb25eaaaa917c', 'message': 'Add some tests for bin/swift-recon\n\nFix also minor bug in zone filtering when zone set to 0.\n\nMoved bin/swift-recon to swift/cli/swift_recon.py, which makes\nit possible to import swift_recon without using some scary hacks.\nbin/swift-recon is now created by setup.py install.\n\nChange-Id: I33d58e635b5cd4a7169d01c4b0410e7cb78ec877\nCloses-Bug: #1261692 Change-Id: Id0729991c8ece73604467480dbf93fec7d8eb196\n'}]",0,70352,44ffc28fcb03b149acb07f83afcbb25eaaaa917c,1,0,1,6968,,,0,"Add some tests for bin/swift-recon

Fix also minor bug in zone filtering when zone set to 0.

Moved bin/swift-recon to swift/cli/swift_recon.py, which makes
it possible to import swift_recon without using some scary hacks.
bin/swift-recon is now created by setup.py install.

Change-Id: I33d58e635b5cd4a7169d01c4b0410e7cb78ec877
Closes-Bug: #1261692 Change-Id: Id0729991c8ece73604467480dbf93fec7d8eb196
",git fetch https://review.opendev.org/openstack/swift refs/changes/52/70352/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/cli/__init__.py', 'test/unit/cli/test_recon_client.py', 'swift/cli/swift_recon.py', 'setup.cfg']",4,44ffc28fcb03b149acb07f83afcbb25eaaaa917c,test-swift-recon-cli,console_scripts = swift-recon = swift.cli.swift_recon:main , bin/swift-recon,160,4
openstack%2Fsahara~master~I9564b656ca5d9f442bb54ede7bf52f324407c059,openstack/sahara,master,I9564b656ca5d9f442bb54ede7bf52f324407c059,Fix mocking of utcnow() for model datetime cols,ABANDONED,2014-01-31 14:21:04.000000000,2014-01-31 14:22:34.000000000,,"[{'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7555}, {'_account_id': 8304}]","[{'number': 1, 'created': '2014-01-31 14:21:04.000000000', 'files': ['savanna/openstack/common/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8c36510152ec7db195b485f52da105cb5c1cf671', 'message': 'Fix mocking of utcnow() for model datetime cols\n\nYou can find details in oslo/db: I7adce90eacb4a3f334d77da7b4a176c31ff818ed\nOslo/db ync from oslo: I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c\n\nChange-Id: I9564b656ca5d9f442bb54ede7bf52f324407c059\n'}]",0,70350,8c36510152ec7db195b485f52da105cb5c1cf671,1,4,1,6786,,,0,"Fix mocking of utcnow() for model datetime cols

You can find details in oslo/db: I7adce90eacb4a3f334d77da7b4a176c31ff818ed
Oslo/db ync from oslo: I8782cbb7a2f1a03df6d5c5e8ff6406836a6c645c

Change-Id: I9564b656ca5d9f442bb54ede7bf52f324407c059
",git fetch https://review.opendev.org/openstack/sahara refs/changes/50/70350/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/openstack/common/db/sqlalchemy/models.py'],1,8c36510152ec7db195b485f52da105cb5c1cf671,," created_at = Column(DateTime, default=lambda: timeutils.utcnow()) updated_at = Column(DateTime, onupdate=lambda: timeutils.utcnow())"," created_at = Column(DateTime, default=timeutils.utcnow) updated_at = Column(DateTime, onupdate=timeutils.utcnow)",2,2
openstack%2Fpython-saharaclient~master~I61e96c65454ff9cdc26f3d2ceea93a4284004b9c,openstack/python-saharaclient,master,I61e96c65454ff9cdc26f3d2ceea93a4284004b9c,Update oslo-incubator cliutils module,MERGED,2014-01-29 17:27:12.000000000,2014-01-31 14:07:08.000000000,2014-01-31 14:07:08.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-01-29 17:27:12.000000000', 'files': ['savannaclient/openstack/common/apiclient/auth.py', 'savannaclient/openstack/common/py3kcompat/urlutils.py', 'savannaclient/openstack/common/uuidutils.py', 'savannaclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/bac70425515da900a261008e3d8e32db984794b0', 'message': 'Update oslo-incubator cliutils module\n\nChanges -\n * Add method quote_plus in module py3kcompat.urlutils\n * Add common methods to cliutils\n * Cleanup unused log related code\n\nChange-Id: I61e96c65454ff9cdc26f3d2ceea93a4284004b9c\n'}]",0,69917,bac70425515da900a261008e3d8e32db984794b0,10,7,1,7555,,,0,"Update oslo-incubator cliutils module

Changes -
 * Add method quote_plus in module py3kcompat.urlutils
 * Add common methods to cliutils
 * Cleanup unused log related code

Change-Id: I61e96c65454ff9cdc26f3d2ceea93a4284004b9c
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/17/69917/1 && git format-patch -1 --stdout FETCH_HEAD,"['savannaclient/openstack/common/apiclient/auth.py', 'savannaclient/openstack/common/py3kcompat/urlutils.py', 'savannaclient/openstack/common/uuidutils.py', 'savannaclient/openstack/common/cliutils.py']",4,bac70425515da900a261008e3d8e32db984794b0,,"from __future__ import print_function from savannaclient.openstack.common.gettextutils import _ from savannaclient.openstack.common import importutilsfrom savannaclient.openstack.common import uuidutils for __ in moves.range(max_password_prompts): def find_resource(manager, name_or_id, **find_args): """"""Look for resource in a given manager. Used as a helper for the _find_* methods. Example: def _find_hypervisor(cs, hypervisor): #Get a hypervisor by name or ID. return cliutils.find_resource(cs.hypervisors, hypervisor) """""" # first try to get entity as integer id try: return manager.get(int(name_or_id)) except (TypeError, ValueError, exceptions.NotFound): pass # now try to get entity as uuid try: tmp_id = strutils.safe_encode(name_or_id) if uuidutils.is_uuid_like(tmp_id): return manager.get(tmp_id) except (TypeError, ValueError, exceptions.NotFound): pass # for str id which is not uuid if getattr(manager, 'is_alphanum_id_allowed', False): try: return manager.get(name_or_id) except exceptions.NotFound: pass try: try: return manager.find(human_id=name_or_id, **find_args) except exceptions.NotFound: pass # finally try to find entity by name try: resource = getattr(manager, 'resource_class', None) name_attr = resource.NAME_ATTR if resource else 'name' kwargs = {name_attr: name_or_id} kwargs.update(find_args) return manager.find(**kwargs) except exceptions.NotFound: msg = _(""No %(name)s with a name or "" ""ID of '%(name_or_id)s' exists."") % \ { ""name"": manager.resource_class.__name__.lower(), ""name_or_id"": name_or_id } raise exceptions.CommandError(msg) except exceptions.NoUniqueMatch: msg = _(""Multiple %(name)s matches found for "" ""'%(name_or_id)s', use an ID to be more specific."") % \ { ""name"": manager.resource_class.__name__.lower(), ""name_or_id"": name_or_id } raise exceptions.CommandError(msg) def service_type(stype): """"""Adds 'service_type' attribute to decorated function. Usage: @service_type('volume') def mymethod(f): ... """""" def inner(f): f.service_type = stype return f return inner def get_service_type(f): """"""Retrieves service type from function."""""" return getattr(f, 'service_type', None) def pretty_choice_list(l): return ', '.join(""'%s'"" % i for i in l) def import_class(import_str): """"""Returns a class from a string including module and class."""""" mod_str, _sep, class_str = import_str.rpartition('.') __import__(mod_str) return getattr(sys.modules[mod_str], class_str) def import_versioned_module(version, submodule=None): module = 'savannaclient.v%s' % version if submodule: module = '.'.join((module, submodule)) return importutils.import_module(module) def exit(msg=''): if msg: print (msg, file=sys.stderr) sys.exit(1)", for _ in moves.range(max_password_prompts):,151,5
openstack%2Fpython-saharaclient~master~I78ed75e35ed10c3c5e1fae415f11fb5343b59123,openstack/python-saharaclient,master,I78ed75e35ed10c3c5e1fae415f11fb5343b59123,Update oslo-incubator strutils module,MERGED,2014-01-29 17:27:12.000000000,2014-01-31 14:06:38.000000000,2014-01-31 14:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-01-29 17:27:12.000000000', 'files': ['savannaclient/openstack/common/gettextutils.py', 'savannaclient/openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/794bc3748d869277ba8eac5dd89ccf8ca58d23f2', 'message': 'Update oslo-incubator strutils module\n\nChanges -\n * Fix E501 in individual openstack projects\n * Make Message keep string interpolation args\n * Add support for locales missing from babel\n * strutils bool_from_string, allow specified default\n\nChange-Id: I78ed75e35ed10c3c5e1fae415f11fb5343b59123\n'}]",0,69916,794bc3748d869277ba8eac5dd89ccf8ca58d23f2,10,7,1,7555,,,0,"Update oslo-incubator strutils module

Changes -
 * Fix E501 in individual openstack projects
 * Make Message keep string interpolation args
 * Add support for locales missing from babel
 * strutils bool_from_string, allow specified default

Change-Id: I78ed75e35ed10c3c5e1fae415f11fb5343b59123
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/16/69916/1 && git format-patch -1 --stdout FETCH_HEAD,"['savannaclient/openstack/common/gettextutils.py', 'savannaclient/openstack/common/strutils.py']",2,794bc3748d869277ba8eac5dd89ccf8ca58d23f2,,"def bool_from_string(subject, strict=False, default=False): `strict=False`, anything else returns the value specified by 'default'. return default","def bool_from_string(subject, strict=False): `strict=False`, anything else is considered False. return False",36,7
openstack-attic%2Fidentity-api~master~I6a97ce0702dbe29fa2492f876d453273b8c52ae0,openstack-attic/identity-api,master,I6a97ce0702dbe29fa2492f876d453273b8c52ae0,Add example for domain-scoped authentication,MERGED,2014-01-27 23:48:27.000000000,2014-01-31 13:58:16.000000000,2014-01-31 13:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 6482}, {'_account_id': 6547}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-01-27 23:48:27.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/0fd7eaa248b035ae67480a4eb761a7c36c21cfb4', 'message': 'Add example for domain-scoped authentication\n\nChange-Id: I6a97ce0702dbe29fa2492f876d453273b8c52ae0\nCloses-Bug: 1269160\n'}]",5,69505,0fd7eaa248b035ae67480a4eb761a7c36c21cfb4,11,7,1,4,,,0,"Add example for domain-scoped authentication

Change-Id: I6a97ce0702dbe29fa2492f876d453273b8c52ae0
Closes-Bug: 1269160
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/05/69505/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3.md'],1,0fd7eaa248b035ae67480a4eb761a7c36c21cfb4,bug/1269160,"An authorization scope, including either a `project` or `domain`, can be optionally specified as part of the request. If both a `domain` and a `project` are specified, an HTTP 400 Bad Request will be returned, as a token cannot be simultaneously scoped to both a `project` and `domain`.A `domain` scope may be specified by either the domain's `id` or `name` with equivalent results. Example request specifying a domain by `id`: { ""auth"": { ""identity"": { ""methods"": [ ""password"" ], ""password"": { ""user"": { ""id"": ""0ca8f6"", ""password"": ""secrete"" } } }, ""scope"": { ""domain"": { ""id"": ""1789d1"" } } } } Example request specifying a domain by `name`: { ""auth"": { ""identity"": { ""methods"": [ ""password"" ], ""password"": { ""user"": { ""id"": ""0ca8f6"", ""password"": ""secrete"" } } }, ""scope"": { ""domain"": { ""name"": ""example.com"" } } } } ","An authorization scope, including either a project or domain, can be optionally specified as part of the request. If both a domain and a project are specified, an HTTP 400 Bad Request will be returned, as a token cannot be simultaneously scoped to both a project and domain.",51,4
openstack%2Ftempest~master~I09525af4f1b308b91d45b7bbea05e0f734ea485c,openstack/tempest,master,I09525af4f1b308b91d45b7bbea05e0f734ea485c,Convert all service clients to global CONF object,MERGED,2014-01-29 20:51:41.000000000,2014-01-31 13:27:49.000000000,2014-01-31 13:27:48.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 20:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f43f3834a1dfbfd5b4b87a8475b5eafbb09c913', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 2, 'created': '2014-01-29 20:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/12951a87e54b4db2652aabaad44ff1591213a840', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 3, 'created': '2014-01-30 20:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/70b6dca8ecb3ac85b710c234dfb69614e2833c1a', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 4, 'created': '2014-01-30 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c3003527a97befd0f419044fa538f79f5445dc7b', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 5, 'created': '2014-01-30 21:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e722d56e3970b4da162e15e8d5087c9ff046b717', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 6, 'created': '2014-01-30 22:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f7e3854ead9c8c03436d961c65682488fa839f5e', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}, {'number': 7, 'created': '2014-01-30 23:45:34.000000000', 'files': ['tempest/services/volume/xml/snapshots_client.py', 'tempest/services/compute/json/servers_client.py', 'tempest/services/compute/xml/extensions_client.py', 'tempest/services/compute/json/images_client.py', 'tempest/services/identity/v3/xml/endpoints_client.py', 'tempest/services/identity/v3/json/policy_client.py', 'tempest/services/compute/json/hypervisor_client.py', 'tempest/services/compute/v3/json/hypervisor_client.py', 'tempest/services/network/xml/network_client.py', 'tempest/services/compute/xml/availability_zone_client.py', 'tempest/services/compute/xml/security_groups_client.py', 'tempest/services/compute/v3/json/certificates_client.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/services/compute/xml/tenant_usages_client.py', 'tempest/services/compute/json/aggregates_client.py', 'tempest/services/compute/xml/volumes_extensions_client.py', 'tempest/services/compute/json/volumes_extensions_client.py', 'tempest/services/compute/xml/interfaces_client.py', 'tempest/services/object_storage/account_client.py', 'tempest/services/network/json/network_client.py', 'tempest/services/compute/xml/services_client.py', 'tempest/services/compute/json/extensions_client.py', 'tempest/services/compute/v3/json/version_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/compute/xml/hosts_client.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/services/compute/json/instance_usage_audit_log_client.py', 'tempest/services/compute/xml/fixed_ips_client.py', 'tempest/services/compute/xml/images_client.py', 'tempest/services/compute/v3/json/extensions_client.py', 'tempest/services/baremetal/v1/base_v1.py', 'tempest/services/identity/v3/xml/credentials_client.py', 'tempest/services/compute/json/availability_zone_client.py', 'tempest/services/compute/json/keypairs_client.py', 'tempest/services/compute/xml/aggregates_client.py', 'tempest/services/compute/xml/flavors_client.py', 'tempest/services/compute/v3/json/aggregates_client.py', 'tempest/services/compute/xml/keypairs_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/clients.py', 'tempest/services/baremetal/base.py', 'tempest/services/image/v1/json/image_client.py', 'tempest/services/identity/v3/xml/policy_client.py', 'tempest/services/compute/v3/json/quotas_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/volume/json/admin/volume_hosts_client.py', 'tempest/services/compute/xml/quotas_client.py', 'tempest/services/compute/json/tenant_usages_client.py', 'tempest/services/compute/json/limits_client.py', 'tempest/services/volume/xml/admin/volume_types_client.py', 'tempest/services/data_processing/v1_1/client.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/services/baremetal/v1/client_json.py', 'tempest/services/compute/v3/json/availability_zone_client.py', 'tempest/services/orchestration/json/orchestration_client.py', 'tempest/services/compute/json/certificates_client.py', 'tempest/common/rest_client.py', 'tempest/services/compute/json/hosts_client.py', 'tempest/services/volume/json/volumes_client.py', 'tempest/tests/test_rest_client.py', 'tempest/services/compute/json/services_client.py', 'tempest/services/telemetry/json/telemetry_client.py', 'tempest/services/identity/v3/xml/service_client.py', 'tempest/services/volume/xml/admin/volume_hosts_client.py', 'tempest/services/compute/json/quotas_client.py', 'tempest/services/volume/xml/extensions_client.py', 'tempest/services/compute/v3/json/interfaces_client.py', 'tempest/services/compute/v3/json/services_client.py', 'tempest/services/volume/json/snapshots_client.py', 'tempest/services/compute/v3/json/keypairs_client.py', 'tempest/services/telemetry/telemetry_client_base.py', 'tempest/services/compute/v3/json/hosts_client.py', 'tempest/services/compute/v3/json/tenant_usages_client.py', 'tempest/services/identity/xml/identity_client.py', 'tempest/services/compute/v3/json/flavors_client.py', 'tempest/services/compute/xml/limits_client.py', 'tempest/services/compute/xml/servers_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/volume/json/admin/volume_types_client.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/services/telemetry/xml/telemetry_client.py', 'tempest/services/compute/json/interfaces_client.py', 'tempest/services/object_storage/object_client.py', 'tempest/services/volume/json/extensions_client.py', 'tempest/services/object_storage/container_client.py', 'tempest/services/network/network_client_base.py', 'tempest/services/compute/xml/floating_ips_client.py', 'tempest/services/volume/xml/volumes_client.py', 'tempest/services/compute/xml/hypervisor_client.py', 'tempest/services/botoclients.py', 'tempest/services/compute/json/security_groups_client.py', 'tempest/services/identity/v3/xml/identity_client.py', 'tempest/services/compute/v3/json/instance_usage_audit_log_client.py', 'tempest/services/compute/xml/certificates_client.py', 'tempest/services/compute/xml/instance_usage_audit_log_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/684d8997bbdfb14dca680e32e579d92c5cc279d0', 'message': 'Convert all service clients to global CONF object\n\nThis commit takes the rest client and all subclass(all the service\nclients) and converts all uses of config to the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c\n'}]",0,69974,684d8997bbdfb14dca680e32e579d92c5cc279d0,17,4,7,5196,,,0,"Convert all service clients to global CONF object

This commit takes the rest client and all subclass(all the service
clients) and converts all uses of config to the global CONF object.

Partially implements bp config-cleanup

Change-Id: I09525af4f1b308b91d45b7bbea05e0f734ea485c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/74/69974/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v3/xml/policy_client.py', 'tempest/services/compute/v3/json/quotas_client.py', 'tempest/services/volume/xml/snapshots_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/volume/json/admin/volume_hosts_client.py', 'tempest/services/compute/xml/quotas_client.py', 'tempest/services/compute/json/servers_client.py', 'tempest/services/compute/xml/extensions_client.py', 'tempest/services/compute/json/tenant_usages_client.py', 'tempest/services/compute/json/limits_client.py', 'tempest/services/compute/json/images_client.py', 'tempest/services/identity/v3/xml/endpoints_client.py', 'tempest/services/identity/v3/json/policy_client.py', 'tempest/services/data_processing/v1_1/client.py', 'tempest/services/compute/json/hypervisor_client.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/services/compute/v3/json/hypervisor_client.py', 'tempest/services/network/xml/network_client.py', 'tempest/services/compute/xml/availability_zone_client.py', 'tempest/services/baremetal/v1/client_json.py', 'tempest/services/compute/xml/security_groups_client.py', 'tempest/services/compute/v3/json/availability_zone_client.py', 'tempest/services/orchestration/json/orchestration_client.py', 'tempest/services/compute/json/certificates_client.py', 'tempest/common/rest_client.py', 'tempest/services/compute/json/hosts_client.py', 'tempest/services/volume/json/volumes_client.py', 'tempest/services/compute/v3/json/certificates_client.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/services/compute/xml/tenant_usages_client.py', 'tempest/services/compute/json/services_client.py', 'tempest/services/telemetry/json/telemetry_client.py', 'tempest/services/identity/v3/xml/service_client.py', 'tempest/services/compute/json/aggregates_client.py', 'tempest/services/compute/xml/volumes_extensions_client.py', 'tempest/services/compute/json/volumes_extensions_client.py', 'tempest/services/compute/xml/interfaces_client.py', 'tempest/services/volume/xml/admin/volume_hosts_client.py', 'tempest/services/compute/json/quotas_client.py', 'tempest/services/volume/xml/extensions_client.py', 'tempest/services/compute/v3/json/interfaces_client.py', 'tempest/services/object_storage/account_client.py', 'tempest/services/compute/v3/json/services_client.py', 'tempest/services/network/json/network_client.py', 'tempest/services/volume/json/snapshots_client.py', 'tempest/services/compute/xml/services_client.py', 'tempest/services/compute/v3/json/keypairs_client.py', 'tempest/services/telemetry/telemetry_client_base.py', 'tempest/services/compute/v3/json/hosts_client.py', 'tempest/services/compute/v3/json/tenant_usages_client.py', 'tempest/services/identity/xml/identity_client.py', 'tempest/services/compute/json/extensions_client.py', 'tempest/services/compute/v3/json/flavors_client.py', 'tempest/services/compute/v3/json/version_client.py', 'tempest/services/compute/xml/limits_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/compute/xml/hosts_client.py', 'tempest/services/compute/xml/servers_client.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/services/compute/json/instance_usage_audit_log_client.py', 'tempest/services/compute/xml/fixed_ips_client.py', 'tempest/services/compute/xml/images_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/compute/v3/json/extensions_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/baremetal/v1/base_v1.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/services/identity/v3/xml/credentials_client.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/services/compute/json/keypairs_client.py', 'tempest/services/compute/xml/aggregates_client.py', 'tempest/services/telemetry/xml/telemetry_client.py', 'tempest/services/compute/json/interfaces_client.py', 'tempest/services/object_storage/object_client.py', 'tempest/services/volume/json/extensions_client.py', 'tempest/services/object_storage/container_client.py', 'tempest/services/compute/xml/flavors_client.py', 'tempest/services/baremetal/v1/client_xml.py', 'tempest/services/compute/v3/json/aggregates_client.py', 'tempest/services/compute/xml/keypairs_client.py', 'tempest/services/network/network_client_base.py', 'tempest/services/compute/xml/floating_ips_client.py', 'tempest/services/volume/xml/volumes_client.py', 'tempest/services/compute/xml/hypervisor_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/botoclients.py', 'tempest/services/compute/json/security_groups_client.py', 'tempest/clients.py', 'tempest/services/identity/v3/xml/identity_client.py', 'tempest/services/baremetal/base.py', 'tempest/services/compute/v3/json/instance_usage_audit_log_client.py', 'tempest/services/compute/xml/certificates_client.py', 'tempest/services/compute/xml/instance_usage_audit_log_client.py', 'tempest/services/image/v1/json/image_client.py']",94,4f43f3834a1dfbfd5b4b87a8475b5eafbb09c913,bp/config-cleanup,"from tempest import configCONF = config.CONF def __init__(self, username, password, auth_url, tenant_name=None): super(ImageClientJSON, self).__init__(username, password, self.service = CONF.images.catalog_type if CONF.service_available.glance: dscv = CONF.identity.disable_ssl_certificate_validation"," def __init__(self, config, username, password, auth_url, tenant_name=None): super(ImageClientJSON, self).__init__(config, username, password, self.service = self.config.images.catalog_type if config.service_available.glance: dscv = self.config.identity.disable_ssl_certificate_validation",606,356
openstack%2Ftempest~master~I7a39839d7a4ebbf8372489507486ad2cac7f3adc,openstack/tempest,master,I7a39839d7a4ebbf8372489507486ad2cac7f3adc,Convert cli tests to use global CONF object,MERGED,2014-01-29 19:28:42.000000000,2014-01-31 13:27:41.000000000,2014-01-31 13:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 8625}]","[{'number': 1, 'created': '2014-01-29 19:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf392bc7568cd8f7ec02f1719bc3e8b91cf473da', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}, {'number': 2, 'created': '2014-01-29 20:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/69343c300ba97f1d9190fdd3de6891dfd6068108', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}, {'number': 3, 'created': '2014-01-29 20:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2f10583a52f3b11a303b61e0b7fb1c5b58c7f20a', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}, {'number': 4, 'created': '2014-01-30 00:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/316d514f06981bf8d3d216cb3298df920167d592', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}, {'number': 5, 'created': '2014-01-30 20:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1bde5099b59f51d17cea87cd20563d5f92558cb', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}, {'number': 6, 'created': '2014-01-30 23:45:35.000000000', 'files': ['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/test_nova.py', 'tempest/cli/simple_read_only/test_heat.py', 'tempest/cli/simple_read_only/test_cinder.py', 'tempest/cli/simple_read_only/test_keystone.py', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/cli/simple_read_only/test_glance.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e2b56b5713273013d28b768f20106b015b83360d', 'message': 'Convert cli tests to use global CONF object\n\nThis commit takes all the uses of config in the cli tests and coverts\nthem to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc\n'}]",0,69955,e2b56b5713273013d28b768f20106b015b83360d,19,6,6,5196,,,0,"Convert cli tests to use global CONF object

This commit takes all the uses of config in the cli tests and coverts
them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: I7a39839d7a4ebbf8372489507486ad2cac7f3adc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/69955/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/test_nova.py', 'tempest/cli/simple_read_only/test_heat.py', 'tempest/cli/simple_read_only/test_cinder.py', 'tempest/cli/simple_read_only/test_keystone.py', 'tempest/config.py', 'tempest/cli/simple_read_only/test_glance.py']",7,cf392bc7568cd8f7ec02f1719bc3e8b91cf473da,bp/config-cleanup,from tempest import configCONF = config.CONF,from oslo.config import cfg CONF = cfg.CONF ,35,38
openstack%2Ftempest~master~I1bac686587f1705901b653b07300077623ba9f21,openstack/tempest,master,I1bac686587f1705901b653b07300077623ba9f21,Convert scenario tests to use global CONF object,MERGED,2014-01-29 19:28:42.000000000,2014-01-31 13:27:32.000000000,2014-01-31 13:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-29 19:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c58c729b521421e52636ab64d546018bc7fe499a', 'message': 'Convert scenario tests to use global CONF object\n\nThis commit takes all the uses of config in the scenario tests and\nconverts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I1bac686587f1705901b653b07300077623ba9f21\n'}, {'number': 2, 'created': '2014-01-29 20:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36912cbea47c01c25c6a0b59ce89c4c6790c9e7b', 'message': 'Convert scenario tests to use global CONF object\n\nThis commit takes all the uses of config in the scenario tests and\nconverts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I1bac686587f1705901b653b07300077623ba9f21\n'}, {'number': 3, 'created': '2014-01-30 20:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec4b109069b9e4439c034f0320199327e95e6b22', 'message': 'Convert scenario tests to use global CONF object\n\nThis commit takes all the uses of config in the scenario tests and\nconverts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I1bac686587f1705901b653b07300077623ba9f21\n'}, {'number': 4, 'created': '2014-01-30 23:45:34.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_snapshot_pattern.py', 'tempest/scenario/orchestration/test_autoscaling.py', 'tempest/scenario/test_dashboard_basic_ops.py', 'tempest/scenario/test_cross_tenant_connectivity.py', 'tempest/scenario/test_minimum_basic.py', 'tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/scenario/test_server_advanced_ops.py', 'tempest/scenario/test_large_ops.py', 'tempest/scenario/test_stamp_pattern.py', 'tempest/scenario/test_swift_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c07229e1302681abee01ed0726d876bfa596c45', 'message': 'Convert scenario tests to use global CONF object\n\nThis commit takes all the uses of config in the scenario tests and\nconverts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I1bac686587f1705901b653b07300077623ba9f21\n'}]",0,69954,6c07229e1302681abee01ed0726d876bfa596c45,20,6,4,5196,,,0,"Convert scenario tests to use global CONF object

This commit takes all the uses of config in the scenario tests and
converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: I1bac686587f1705901b653b07300077623ba9f21
",git fetch https://review.opendev.org/openstack/tempest refs/changes/54/69954/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_snapshot_pattern.py', 'tempest/scenario/orchestration/test_autoscaling.py', 'tempest/scenario/test_dashboard_basic_ops.py', 'tempest/scenario/test_cross_tenant_connectivity.py', 'tempest/scenario/test_minimum_basic.py', 'tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/scenario/test_server_advanced_ops.py', 'tempest/scenario/test_large_ops.py', 'tempest/scenario/test_stamp_pattern.py', 'tempest/scenario/test_swift_basic_ops.py']",13,c58c729b521421e52636ab64d546018bc7fe499a,bp/config-cleanup,from tempest import configCONF = config.CONF if not CONF.service_available.swift:, if not cls.config.service_available.swift:,132,107
openstack%2Ftempest~master~I683577f133643f6159dbfe7295911d155b613f92,openstack/tempest,master,I683577f133643f6159dbfe7295911d155b613f92,Convert thirdparty and stress tests to use global CONF object,MERGED,2014-01-29 19:28:41.000000000,2014-01-31 13:27:24.000000000,2014-01-31 13:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 19:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8660ab589ccb44600ca423a3ae8f2e6b9d05aa19', 'message': 'Convert thirdparty and stress tests to use global CONF object\n\nThis commit takes all the uses of config in the thirdparty and stress\ntests and converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I683577f133643f6159dbfe7295911d155b613f92\n'}, {'number': 2, 'created': '2014-01-29 20:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/23b32701cf6d458ef9bbde17f97a05c49b9f32b3', 'message': 'Convert thirdparty and stress tests to use global CONF object\n\nThis commit takes all the uses of config in the thirdparty and stress\ntests and converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I683577f133643f6159dbfe7295911d155b613f92\n'}, {'number': 3, 'created': '2014-01-30 20:00:14.000000000', 'files': ['tempest/stress/actions/volume_attach_delete.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/stress/actions/server_create_destroy.py', 'tempest/stress/driver.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/88f49ef627b20af3d7408d87b359c83681e8ea19', 'message': 'Convert thirdparty and stress tests to use global CONF object\n\nThis commit takes all the uses of config in the thirdparty and stress\ntests and converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I683577f133643f6159dbfe7295911d155b613f92\n'}]",0,69953,88f49ef627b20af3d7408d87b359c83681e8ea19,17,4,3,5196,,,0,"Convert thirdparty and stress tests to use global CONF object

This commit takes all the uses of config in the thirdparty and stress
tests and converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: I683577f133643f6159dbfe7295911d155b613f92
",git fetch https://review.opendev.org/openstack/tempest refs/changes/53/69953/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/actions/volume_attach_delete.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/stress/actions/server_create_destroy.py', 'tempest/stress/driver.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py']",6,8660ab589ccb44600ca423a3ae8f2e6b9d05aa19,bp/config-cleanup,from tempest import configCONF = config.CONF cls.materials_path = CONF.boto.s3_materials_path cls.ami_manifest = CONF.boto.ami_manifest cls.aki_manifest = CONF.boto.aki_manifest cls.ari_manifest = CONF.boto.ari_manifest, config = cls.config cls.materials_path = config.boto.s3_materials_path cls.ami_manifest = config.boto.ami_manifest cls.aki_manifest = config.boto.aki_manifest cls.ari_manifest = config.boto.ari_manifest,40,25
openstack%2Ftempest~master~I258f0b4df1850ab4d2d670c297b9c43b6916d036,openstack/tempest,master,I258f0b4df1850ab4d2d670c297b9c43b6916d036,Convert volume api tests to use global CONF object,MERGED,2014-01-29 19:28:41.000000000,2014-01-31 13:25:49.000000000,2014-01-31 13:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 19:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/00098cee7c3a72db6b173065bbc60ea5497a0f55', 'message': 'Convert volume api tests to use global CONF object\n\nThis commit takes all the uses of config in the volume api tests\nand converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I258f0b4df1850ab4d2d670c297b9c43b6916d036\n'}, {'number': 2, 'created': '2014-01-29 20:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3fb6b17bb6840a62db73c0d05844d33324a07f4b', 'message': 'Convert volume api tests to use global CONF object\n\nThis commit takes all the uses of config in the volume api tests\nand converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I258f0b4df1850ab4d2d670c297b9c43b6916d036\n'}, {'number': 3, 'created': '2014-01-30 20:00:14.000000000', 'files': ['tempest/api/volume/admin/test_volume_types.py', 'tempest/api/volume/test_extensions.py', 'tempest/api/volume/base.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_get.py', 'tempest/api/volume/test_volume_transfers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4d352bcaa93898b5e8e9437f1e412e085bc194b2', 'message': 'Convert volume api tests to use global CONF object\n\nThis commit takes all the uses of config in the volume api tests\nand converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I258f0b4df1850ab4d2d670c297b9c43b6916d036\n'}]",0,69952,4d352bcaa93898b5e8e9437f1e412e085bc194b2,13,4,3,5196,,,0,"Convert volume api tests to use global CONF object

This commit takes all the uses of config in the volume api tests
and converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: I258f0b4df1850ab4d2d670c297b9c43b6916d036
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/69952/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/admin/test_volume_types.py', 'tempest/api/volume/test_extensions.py', 'tempest/api/volume/base.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_get.py', 'tempest/api/volume/test_volume_transfers.py']",7,00098cee7c3a72db6b173065bbc60ea5497a0f55,bp/config-cleanup,from tempest import configCONF = config.CONF if CONF.compute.allow_tenant_isolation:, if cls.config.compute.allow_tenant_isolation:,54,33
openstack%2Fironic~master~Ie1cfa1cae074cc3f519fad09b16c6347a59bfe00,openstack/ironic,master,Ie1cfa1cae074cc3f519fad09b16c6347a59bfe00,Update docstrings in ssh.py,MERGED,2014-01-30 01:17:39.000000000,2014-01-31 13:22:07.000000000,2014-01-31 13:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-01-30 01:17:39.000000000', 'files': ['ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/947ade50e7d8d0b30d1d07f915652fe75bcb4135', 'message': 'Update docstrings in ssh.py\n\nAdded and updated method docstrings in ssh.py.\n\nChange-Id: Ie1cfa1cae074cc3f519fad09b16c6347a59bfe00\n'}]",0,70033,947ade50e7d8d0b30d1d07f915652fe75bcb4135,7,4,1,6618,,,0,"Update docstrings in ssh.py

Added and updated method docstrings in ssh.py.

Change-Id: Ie1cfa1cae074cc3f519fad09b16c6347a59bfe00
",git fetch https://review.opendev.org/openstack/ironic refs/changes/33/70033/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/ssh.py'],1,947ade50e7d8d0b30d1d07f915652fe75bcb4135,ssh-docstrings," """"""Gets the information needed for accessing the node. :param node: the Node of interest. :returns: dictionary of information. :raises: InvalidParameterValue if any required parameters are missing or incorrect. """""" """"""Returns a node's current power state. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_OFF, POWER_ON. :raises: NodeNotFound """""" """"""Returns an SSH client connected to a node. :param node: the Node. :returns: paramiko.SSHClient, an active ssh connection. """""" """"""Get the name the host uses to reference the node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: the name or None if not found. """""" """"""Power ON this node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_ON or ERROR. """""" """"""Power OFF this node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_OFF or ERROR. """""" """"""Get all mac addresses for a node. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :param node: the Node of interest. :returns: a list of all the MAC addresses for the node. """""" """"""Check that the node's 'driver_info' is valid. Check that the node's 'driver_info' contains the requisite fields and that an SSH connection to the node can be established. :raises: InvalidParameterValue if any connection parameters are incorrect or if ssh failed to connect to the node. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect. :raises: NodeNotFound. :raises: SSHCommandFailed on an error from ssh. :raises: SSHConnectFailed if ssh failed to connect to the node. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect, or if the desired power state is invalid. :raises: NodeNotFound. :raises: PowerStateFailure if it failed to set power state to pstate. :raises: SSHCommandFailed on an error from ssh. :raises: SSHConnectFailed if ssh failed to connect to the node. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect. :raises: NodeNotFound. :raises: PowerStateFailure if it failed to set power state to POWER_ON. :raises: SSHCommandFailed on an error from ssh. :raises: SSHConnectFailed if ssh failed to connect to the node."," """"""Returns a node's current power state."""""" """"""Get the name the host uses to reference the node."""""" """"""Power ON this node."""""" """"""Power OFF this node."""""" """"""Get all mac addresses for a node."""""" """"""Check that node 'driver_info' is valid. Check that node 'driver_info' contains the requisite fields and SSH connection can be established. :raises: InvalidParameterValue :param task: A instance of `ironic.manager.task_manager.TaskManager`. :param task: A instance of `ironic.manager.task_manager.TaskManager`. :returns NOTHING: :raises: exception.IronicException or exception.PowerStateFailure. :param task: A instance of `ironic.manager.task_manager.TaskManager`. :returns NOTHING: :raises: exception.PowerStateFailure.",71,16
openstack%2Ftempest~master~Ib8d7ad36047a1e752511bc4c5541d04ea61d6afc,openstack/tempest,master,Ib8d7ad36047a1e752511bc4c5541d04ea61d6afc,"Convert ironic, swift, and heat api tests to use global CONF object",MERGED,2014-01-29 19:28:40.000000000,2014-01-31 13:06:42.000000000,2014-01-31 13:06:41.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 19:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3f79c1158729ec02d9fa0f0b7cef1a502875ade0', 'message': 'Convert ironic, swift, and heat api tests to use global CONF object\n\nThis commit takes all the uses of config in the object_storage and\norchestration api tests and converts them to use the global CONF\nobject.\n\nPartially implements bp config-cleanup\n\nChange-Id: Ib8d7ad36047a1e752511bc4c5541d04ea61d6afc\n'}, {'number': 2, 'created': '2014-01-30 20:00:15.000000000', 'files': ['tempest/api/object_storage/base.py', 'tempest/api/orchestration/stacks/test_limits.py', 'tempest/api/orchestration/stacks/test_server_cfn_init.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/api/baremetal/base.py', 'tempest/api/orchestration/base.py', 'tempest/api/object_storage/test_container_sync.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cb09bbb9dacfef2341a4d8fdba0b4934bfa5d28d', 'message': ""Convert ironic, swift, and heat api tests to use global CONF object\n\nThis commit takes all the uses of config in the object_storage and\norchestration api tests and converts them to use the global CONF\nobject.\n\nThe _get_client_args() method from the base orchestration test class\nis removed because it only uses the object attr config and isn't\nactually used anywhere. So instead of converting it to use the global\nobject it is removed.\n\nPartially implements bp config-cleanup\n\nChange-Id: Ib8d7ad36047a1e752511bc4c5541d04ea61d6afc\n""}]",2,69951,cb09bbb9dacfef2341a4d8fdba0b4934bfa5d28d,17,4,2,5196,,,0,"Convert ironic, swift, and heat api tests to use global CONF object

This commit takes all the uses of config in the object_storage and
orchestration api tests and converts them to use the global CONF
object.

The _get_client_args() method from the base orchestration test class
is removed because it only uses the object attr config and isn't
actually used anywhere. So instead of converting it to use the global
object it is removed.

Partially implements bp config-cleanup

Change-Id: Ib8d7ad36047a1e752511bc4c5541d04ea61d6afc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/69951/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/object_storage/base.py', 'tempest/api/orchestration/stacks/test_limits.py', 'tempest/api/orchestration/stacks/test_server_cfn_init.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/api/baremetal/base.py', 'tempest/api/orchestration/base.py', 'tempest/api/object_storage/test_container_sync.py']",7,3f79c1158729ec02d9fa0f0b7cef1a502875ade0,bp/config-cleanup,from tempest import configCONF = config.CONF int(CONF.object_storage.container_sync_timeout) int(CONF.object_storage.container_sync_interval), int(cls.config.object_storage.container_sync_timeout) int(cls.config.object_storage.container_sync_interval),41,28
openstack%2Fnova~master~I31d74f4267eaa33e798de926069d1a0f63006a59,openstack/nova,master,I31d74f4267eaa33e798de926069d1a0f63006a59,Retry reservation commit and rollback on deadlock,MERGED,2014-01-30 00:45:34.000000000,2014-01-31 13:05:45.000000000,2014-01-31 13:05:41.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1030}, {'_account_id': 2750}, {'_account_id': 4428}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-01-30 00:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/784c92e0616db01d51a165f74c23dc6eb982606b', 'message': 'Retry reservation commit and rollback on deadlock\n\nReservations can deadlock when concurrent commits are run from\nmultiple hosts on the same project. This fixes the issue by using\nour convienient retry on deadlock feature.\n\nChange-Id: I31d74f4267eaa33e798de926069d1a0f63006a59\nCloses-bug: #1274341\n'}, {'number': 2, 'created': '2014-01-30 00:54:13.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9c556d1557a7056d6056b25d3b91ff4abcb97971', 'message': 'Retry reservation commit and rollback on deadlock\n\nReservations can deadlock when concurrent commits are run from\nmultiple hosts on the same project. This fixes the issue by using\nour convienient retry on deadlock feature.\n\nChange-Id: I31d74f4267eaa33e798de926069d1a0f63006a59\nCloses-bug: #1274341\n'}]",0,70027,9c556d1557a7056d6056b25d3b91ff4abcb97971,15,7,2,67,,,0,"Retry reservation commit and rollback on deadlock

Reservations can deadlock when concurrent commits are run from
multiple hosts on the same project. This fixes the issue by using
our convienient retry on deadlock feature.

Change-Id: I31d74f4267eaa33e798de926069d1a0f63006a59
Closes-bug: #1274341
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/70027/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,784c92e0616db01d51a165f74c23dc6eb982606b,fix-1274341,@_retry_on_deadlock@_retry_on_deadlock,,2,0
openstack%2Fkeystone~stable%2Fhavana~Iecb1170387c51064918780dc6de07db7ca8aeeee,openstack/keystone,stable/havana,Iecb1170387c51064918780dc6de07db7ca8aeeee,Try decoding string to UTF-8 on error message fail,MERGED,2013-12-15 23:54:37.000000000,2014-01-31 12:11:02.000000000,2014-01-31 12:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1955}, {'_account_id': 5046}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-12-15 23:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/337f8d3d82f206151653bc9d0797780d02205fa8', 'message': ""Try decoding string to UTF-8 on error message fail\n\nDatabase Errors from SQLAlchemy tend to get mangled into ASCII. If an\nerror is process that contains UTF-8 data in ASCII form if fails to\nbuild the message and will lead to a 5xx error. Catch the error and try\nto decode it to create the message again, if that doesn't work at least\nfail gracefully.\n\nChange-Id: Iecb1170387c51064918780dc6de07db7ca8aeeee\nCloses-Bug: 1253905\n(cherry picked from commit dcefe5874de3073551226c0bdd1e70f00d6a91a1)\n""}, {'number': 2, 'created': '2014-01-17 04:58:22.000000000', 'files': ['keystone/tests/test_exception.py', 'keystone/exception.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e7d6a7f94faae205459ab41b50fcd457b6ca7345', 'message': ""Try decoding string to UTF-8 on error message fail\n\nDatabase Errors from SQLAlchemy tend to get mangled into ASCII. If an\nerror is process that contains UTF-8 data in ASCII form if fails to\nbuild the message and will lead to a 5xx error. Catch the error and try\nto decode it to create the message again, if that doesn't work at least\nfail gracefully.\n\nCloses-Bug: 1253905\nChange-Id: Iecb1170387c51064918780dc6de07db7ca8aeeee\n(cherry picked from commit dcefe5874de3073551226c0bdd1e70f00d6a91a1)\n""}]",0,62264,e7d6a7f94faae205459ab41b50fcd457b6ca7345,26,5,2,7191,,,0,"Try decoding string to UTF-8 on error message fail

Database Errors from SQLAlchemy tend to get mangled into ASCII. If an
error is process that contains UTF-8 data in ASCII form if fails to
build the message and will lead to a 5xx error. Catch the error and try
to decode it to create the message again, if that doesn't work at least
fail gracefully.

Closes-Bug: 1253905
Change-Id: Iecb1170387c51064918780dc6de07db7ca8aeeee
(cherry picked from commit dcefe5874de3073551226c0bdd1e70f00d6a91a1)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/64/62264/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_exception.py', 'keystone/exception.py']",2,337f8d3d82f206151653bc9d0797780d02205fa8,bug/1253905,"import six from keystone.openstack.common import strutils try: message = self.message_format % kwargs except UnicodeDecodeError: try: kwargs = dict([(k, strutils.safe_decode(v)) for k, v in six.iteritems(kwargs)]) except UnicodeDecodeError: # NOTE(jamielennox): This is the complete failure case # at least by showing the template we have some idea # of where the error is coming from message = self.message_format else: message = self.message_format % kwargs ", message = self.message_format % kwargs,31,1
openstack%2Fheat~master~Ief4e602845e7283c982a772bf53dbb0d8bffce43,openstack/heat,master,Ief4e602845e7283c982a772bf53dbb0d8bffce43,Imported Translations from Transifex,MERGED,2013-12-31 06:06:07.000000000,2014-01-31 12:10:01.000000000,2014-01-31 12:10:01.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-12-31 06:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a13a34b5f8a47cab0b34bc5deeceb231583b9ad2', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 2, 'created': '2014-01-01 06:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89dba5349d2fe94cd5043355cc34ac8eca92bcd7', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 3, 'created': '2014-01-02 06:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a29a650137e4100e1d1de98bf9c51dcf3e5611fb', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 4, 'created': '2014-01-03 06:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e54b7052f8b9487cc5d77357da4ec0e902abd72', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 5, 'created': '2014-01-04 06:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eeb708d225a0e90ea9a7fc4bffa5471fe3f4d0f3', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 6, 'created': '2014-01-05 06:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a86f34d28d8ed0200f6406bd03811a965c2da9ac', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 7, 'created': '2014-01-06 06:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84ffab139bac20512a9e8dba147fe20d0379c1ef', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 8, 'created': '2014-01-07 07:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/72a9ecd54065a3eb5447c75f75dc11387104ff26', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 9, 'created': '2014-01-08 06:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d905f1039f7205b91a7b3648ea5e0b7b8acc1708', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 10, 'created': '2014-01-09 06:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a71ac03decea5bfd0fe1d1a3391b0d3f1912420', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 11, 'created': '2014-01-10 06:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/59a97a3f96732bea481819ce98ab1a9b049a0d54', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 12, 'created': '2014-01-11 06:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eac3e13317c2d6bdb70ae2442860e351af415647', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 13, 'created': '2014-01-12 06:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a5b754a61a841c5c1b4c9ff6db962cd9c5978c4', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 14, 'created': '2014-01-13 06:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3648867e92a636d1c38b2de9abe451f8b1a1cf94', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 15, 'created': '2014-01-14 06:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/994aef9678d4b146e9b586ed11c9d69d1a7b0dda', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 16, 'created': '2014-01-15 06:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/885f763706f09c81d97ad9e95183193c7313b293', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 17, 'created': '2014-01-16 06:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b03158643b74ed2c3d3a447e99d2a5865493a7e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 18, 'created': '2014-01-17 07:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d369ec74b18940c1daf86df5ba6e26f5bafa8d66', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 19, 'created': '2014-01-18 06:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e1f8c22e9a0d782bcfcaf509848024de7a03f5b9', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 20, 'created': '2014-01-19 06:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/32036158d91cb773a7be4133455b6eb08e33d096', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 21, 'created': '2014-01-20 06:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/824d900dcc419f47816b92d9986b54256302dfbe', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 22, 'created': '2014-01-21 06:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dc7810868a81b67496dc6311660de62b06927240', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 23, 'created': '2014-01-22 07:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca6b0a0c47bf389109d603d55896567d1dac3cd4', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 24, 'created': '2014-01-23 06:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a299bcda47a278e1976cdd011f5d91f035ebb5b', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 25, 'created': '2014-01-24 06:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/32568e8743abbcd5891f6dc9ec80995aa7e00715', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 26, 'created': '2014-01-25 06:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a54da069f5bd1c793c1db61a0d342c2038d334a0', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 27, 'created': '2014-01-26 06:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8aa1440ae34e872dbb05770f7f493fdda593c96f', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 28, 'created': '2014-01-27 06:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/de0a3d390c144f46dd2fa632a207a73229cbdd19', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 29, 'created': '2014-01-28 06:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b0dbf0056d7bdc55a39761090c7f294dec2a147a', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 30, 'created': '2014-01-29 06:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/060ab260d4053c27e2631a11268ba61b478f1350', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 31, 'created': '2014-01-30 06:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1214e4317751df4a8444d63d5653aab0ced78606', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}, {'number': 32, 'created': '2014-01-31 06:08:04.000000000', 'files': ['heat/locale/tl_PH/LC_MESSAGES/heat.po', 'heat/locale/pa_IN/LC_MESSAGES/heat.po', 'heat/locale/sw_KE/LC_MESSAGES/heat.po', 'heat/locale/es_MX/LC_MESSAGES/heat.po', 'heat/locale/nb/LC_MESSAGES/heat.po', 'heat/locale/ko/LC_MESSAGES/heat.po', 'heat/locale/en_US/LC_MESSAGES/heat.po', 'heat/locale/pt/LC_MESSAGES/heat.po', 'heat/locale/nl_NL/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po', 'heat/locale/is_IS/LC_MESSAGES/heat.po', 'heat/locale/pl_PL/LC_MESSAGES/heat.po', 'heat/locale/tr/LC_MESSAGES/heat.po', 'heat/locale/eu/LC_MESSAGES/heat.po', 'heat/locale/cs/LC_MESSAGES/heat.po', 'heat/locale/it_IT/LC_MESSAGES/heat.po', 'heat/locale/ru_RU/LC_MESSAGES/heat.po', 'heat/locale/da/LC_MESSAGES/heat.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/gl/LC_MESSAGES/heat.po', 'heat/locale/he_IL/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/id/LC_MESSAGES/heat.po', 'heat/locale/en_GB/LC_MESSAGES/heat.po', 'heat/locale/eu_ES/LC_MESSAGES/heat.po', 'heat/locale/bg_BG/LC_MESSAGES/heat.po', 'heat/locale/ms/LC_MESSAGES/heat.po', 'heat/locale/hu/LC_MESSAGES/heat.po', 'heat/locale/mr_IN/LC_MESSAGES/heat.po', 'heat/locale/en_AU/LC_MESSAGES/heat.po', 'heat/locale/ka_GE/LC_MESSAGES/heat.po', 'heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ar/LC_MESSAGES/heat.po', 'heat/locale/heat.pot', 'heat/locale/ja/LC_MESSAGES/heat.po', 'heat/locale/ro/LC_MESSAGES/heat.po', 'heat/locale/hi/LC_MESSAGES/heat.po', 'heat/locale/bs/LC_MESSAGES/heat.po', 'heat/locale/ur/LC_MESSAGES/heat.po', 'heat/locale/tl/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/sk/LC_MESSAGES/heat.po', 'heat/locale/bn_IN/LC_MESSAGES/heat.po', 'heat/locale/fil/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/he/LC_MESSAGES/heat.po', 'heat/locale/km/LC_MESSAGES/heat.po', 'heat/locale/kn/LC_MESSAGES/heat.po', 'heat/locale/uk/LC_MESSAGES/heat.po', 'heat/locale/zh_HK/LC_MESSAGES/heat.po', 'heat/locale/fa/LC_MESSAGES/heat.po', 'heat/locale/tr_TR/LC_MESSAGES/heat.po', 'heat/locale/fi_FI/LC_MESSAGES/heat.po', 'heat/locale/sl_SI/LC_MESSAGES/heat.po', 'heat/locale/sv/LC_MESSAGES/heat.po', 'heat/locale/vi_VN/LC_MESSAGES/heat.po', 'heat/locale/hr/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'heat/locale/ml_IN/LC_MESSAGES/heat.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/ca/LC_MESSAGES/heat.po', 'heat/locale/ne/LC_MESSAGES/heat.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/3f143ced41ef1dafa10a7fba6b9a6a6f9a1a1f24', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43\n'}]",0,64504,3f143ced41ef1dafa10a7fba6b9a6a6f9a1a1f24,82,5,32,3,,,0,"Imported Translations from Transifex

Change-Id: Ief4e602845e7283c982a772bf53dbb0d8bffce43
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/64504/23 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/tl_PH/LC_MESSAGES/heat.po', 'heat/locale/pa_IN/LC_MESSAGES/heat.po', 'heat/locale/sw_KE/LC_MESSAGES/heat.po', 'heat/locale/es_MX/LC_MESSAGES/heat.po', 'heat/locale/nb/LC_MESSAGES/heat.po', 'heat/locale/ko/LC_MESSAGES/heat.po', 'heat/locale/en_US/LC_MESSAGES/heat.po', 'heat/locale/pt/LC_MESSAGES/heat.po', 'heat/locale/nl_NL/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po', 'heat/locale/is_IS/LC_MESSAGES/heat.po', 'heat/locale/pl_PL/LC_MESSAGES/heat.po', 'heat/locale/tr/LC_MESSAGES/heat.po', 'heat/locale/eu/LC_MESSAGES/heat.po', 'heat/locale/cs/LC_MESSAGES/heat.po', 'heat/locale/it_IT/LC_MESSAGES/heat.po', 'heat/locale/ru_RU/LC_MESSAGES/heat.po', 'heat/locale/da/LC_MESSAGES/heat.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/gl/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/id/LC_MESSAGES/heat.po', 'heat/locale/en_GB/LC_MESSAGES/heat.po', 'heat/locale/eu_ES/LC_MESSAGES/heat.po', 'heat/locale/bg_BG/LC_MESSAGES/heat.po', 'heat/locale/ms/LC_MESSAGES/heat.po', 'heat/locale/hu/LC_MESSAGES/heat.po', 'heat/locale/mr_IN/LC_MESSAGES/heat.po', 'heat/locale/en_AU/LC_MESSAGES/heat.po', 'heat/locale/ka_GE/LC_MESSAGES/heat.po', 'heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ar/LC_MESSAGES/heat.po', 'heat/locale/heat.pot', 'heat/locale/ja/LC_MESSAGES/heat.po', 'heat/locale/ro/LC_MESSAGES/heat.po', 'heat/locale/hi/LC_MESSAGES/heat.po', 'heat/locale/bs/LC_MESSAGES/heat.po', 'heat/locale/ur/LC_MESSAGES/heat.po', 'heat/locale/tl/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/sk/LC_MESSAGES/heat.po', 'heat/locale/bn_IN/LC_MESSAGES/heat.po', 'heat/locale/fil/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/km/LC_MESSAGES/heat.po', 'heat/locale/kn/LC_MESSAGES/heat.po', 'heat/locale/uk/LC_MESSAGES/heat.po', 'heat/locale/zh_HK/LC_MESSAGES/heat.po', 'heat/locale/fa/LC_MESSAGES/heat.po', 'heat/locale/tr_TR/LC_MESSAGES/heat.po', 'heat/locale/fi_FI/LC_MESSAGES/heat.po', 'heat/locale/sl_SI/LC_MESSAGES/heat.po', 'heat/locale/sv/LC_MESSAGES/heat.po', 'heat/locale/vi_VN/LC_MESSAGES/heat.po', 'heat/locale/hr/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'heat/locale/ml_IN/LC_MESSAGES/heat.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/ca/LC_MESSAGES/heat.po', 'heat/locale/ne/LC_MESSAGES/heat.po']",61,a13a34b5f8a47cab0b34bc5deeceb231583b9ad2,transifex/translations,"""POT-Creation-Date: 2013-12-31 06:05+0000\n""","""POT-Creation-Date: 2013-12-30 06:05+0000\n""",62,62
openstack%2Fhorizon~stable%2Fhavana~I1a580f11d85ba5ce52898f42ee1229df224e940f,openstack/horizon,stable/havana,I1a580f11d85ba5ce52898f42ee1229df224e940f,Update Transifex resource name for havana,MERGED,2014-01-29 09:15:44.000000000,2014-01-31 12:04:58.000000000,2014-01-31 12:04:58.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-01-29 09:15:44.000000000', 'files': ['.tx/config'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a716f7e727454baa175e1635ef0aa5f5ac1dd9c1', 'message': 'Update Transifex resource name for havana\n\nI18N team decided to maintain Horizon translations for Havana\nstable branch and Transifex resource names is renamed to *-havana.\n.tx/config in Horizon stable/havana repo needs to be updated.\n\nCloses-Bug: #1274005\n\nChange-Id: I1a580f11d85ba5ce52898f42ee1229df224e940f\n'}]",0,69818,a716f7e727454baa175e1635ef0aa5f5ac1dd9c1,12,5,1,841,,,0,"Update Transifex resource name for havana

I18N team decided to maintain Horizon translations for Havana
stable branch and Transifex resource names is renamed to *-havana.
.tx/config in Horizon stable/havana repo needs to be updated.

Closes-Bug: #1274005

Change-Id: I1a580f11d85ba5ce52898f42ee1229df224e940f
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/69818/1 && git format-patch -1 --stdout FETCH_HEAD,['.tx/config'],1,a716f7e727454baa175e1635ef0aa5f5ac1dd9c1,bug/1274005,[horizon.horizon-translations-havana][horizon.openstack-dashboard-translations-havana][horizon.horizon-js-translations-havana],[horizon.horizon-translations][horizon.openstack-dashboard-translations][horizon.horizon-js-translations],3,3
openstack%2Fhorizon~stable%2Fhavana~Id609da27c51f8d4725683d7fd1534ead0c3bb984,openstack/horizon,stable/havana,Id609da27c51f8d4725683d7fd1534ead0c3bb984,Bad workflow-steps check: has_required_fields,MERGED,2014-01-16 09:16:10.000000000,2014-01-31 12:04:51.000000000,2014-01-31 12:04:50.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6593}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 7699}, {'_account_id': 9659}]","[{'number': 1, 'created': '2014-01-16 09:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a6efd12a676a42c769b8b2a158179e365867bc7', 'message': 'Bad workflow-steps check: has_required_fields\n\nMany of the tabs on the Instance Creation screen don\'t show a ""*""\ndespite having require fields.  This is due to faulty logic in determining\nwhether the workflow-step has require fields.  (Previously, only keys from\nthe contributes list were checked.)\n\nCloses-Bug: 1252005\n\nChange-Id: Id609da27c51f8d4725683d7fd1534ead0c3bb984\n'}, {'number': 2, 'created': '2014-01-22 09:16:25.000000000', 'files': ['horizon/workflows/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce8611c3dc053c331170a9e6cc9813f9d6e4c756', 'message': 'Bad workflow-steps check: has_required_fields\n\nMany of the tabs on the Instance Creation screen don\'t show a ""*""\ndespite having require fields.  This is due to faulty logic in determining\nwhether the workflow-step has require fields.  (Previously, only keys from\nthe contributes list were checked.)\n\nCloses-Bug: 1252005\n\nChange-Id: Id609da27c51f8d4725683d7fd1534ead0c3bb984\n(cherry picked from commit 788ec08c4f3e53b1f3dbaa40c19a0a71c21cdf42)\n'}]",0,67076,ce8611c3dc053c331170a9e6cc9813f9d6e4c756,16,10,2,6593,,,0,"Bad workflow-steps check: has_required_fields

Many of the tabs on the Instance Creation screen don't show a ""*""
despite having require fields.  This is due to faulty logic in determining
whether the workflow-step has require fields.  (Previously, only keys from
the contributes list were checked.)

Closes-Bug: 1252005

Change-Id: Id609da27c51f8d4725683d7fd1534ead0c3bb984
(cherry picked from commit 788ec08c4f3e53b1f3dbaa40c19a0a71c21cdf42)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/67076/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/workflows/base.py'],1,5a6efd12a676a42c769b8b2a158179e365867bc7,bug/1252005," """"""Returns True if action contains any required fields."""""" return any(field.required for field in self.action.fields.values())"," """""" Returns True if action contains any required fields """""" for key in self.contributes: field = self.action.fields.get(key, None) if (field and field.required): return True return False",2,8
openstack%2Fnova~master~I19c3689eaebd0cf4eaa867bec438f4d13f28982a,openstack/nova,master,I19c3689eaebd0cf4eaa867bec438f4d13f28982a,"Revert ""Disable libguestfs' default atexit handlers.""",ABANDONED,2014-01-31 11:45:00.000000000,2014-01-31 11:56:44.000000000,,[],"[{'number': 1, 'created': '2014-01-31 11:45:00.000000000', 'files': ['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/19c3689eaebd0cf4eaa867bec438f4d13f28982a', 'message': 'Revert ""Disable libguestfs\' default atexit handlers.""\n\nThis reverts commit 02abbef960b12deaa7a911788dbc56f3a0bd555a\n\nBecause guestfs support was not tested in the gate, this went in without any testing. Neither the RHEL6 nor Ubuntu 12.04 versions of guestfs have this option, so it makes guestsfs break in both environments.\n\nWhen we attempted to turn on guestfs to stop breaking neutron with nbd, this blew up on us in the gate.\n\nCloses-Bug: #1271562\nRelated-Bug: #1261475'}]",0,70331,19c3689eaebd0cf4eaa867bec438f4d13f28982a,2,0,1,2750,,,0,"Revert ""Disable libguestfs' default atexit handlers.""

This reverts commit 02abbef960b12deaa7a911788dbc56f3a0bd555a

Because guestfs support was not tested in the gate, this went in without any testing. Neither the RHEL6 nor Ubuntu 12.04 versions of guestfs have this option, so it makes guestsfs break in both environments.

When we attempted to turn on guestfs to stop breaking neutron with nbd, this blew up on us in the gate.

Closes-Bug: #1271562
Related-Bug: #1261475",git fetch https://review.opendev.org/openstack/nova refs/changes/31/70331/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py']",2,19c3689eaebd0cf4eaa867bec438f4d13f28982a,, self.handle = tpool.Proxy(guestfs.GuestFS()), self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)),2,2
openstack%2Fheat~master~I0d5680d42d608bdc1cb70ccdf19a4c867b372351,openstack/heat,master,I0d5680d42d608bdc1cb70ccdf19a4c867b372351,Add migration method to test sqldump files,MERGED,2013-12-20 00:24:58.000000000,2014-01-31 11:55:59.000000000,2014-01-31 11:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7253}, {'_account_id': 8641}, {'_account_id': 9189}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-12-20 00:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38f2950de59a0f067ffa598d1617e1c1e0b14d52', 'message': ""Add migration method to test sqldump files\n\nThis is very useful for testing real migration issues from a mysqldump.\nYou use it like this:\n\n    def _pre_upgrade_031(self, engine):\n       _load_mysql_dump_file(engine, 'dump.sql')\n\nChange-Id: I0d5680d42d608bdc1cb70ccdf19a4c867b372351\n""}, {'number': 2, 'created': '2013-12-20 01:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/16565dc697c630a1aba80a87ed6dcf7c406cad70', 'message': ""Add migration method to test sqldump files\n\nThis is very useful for testing real migration issues from a mysqldump.\nYou use it like this:\n\n    def _pre_upgrade_031(self, engine):\n       _load_mysql_dump_file(engine, 'dump.sql')\n\nChange-Id: I0d5680d42d608bdc1cb70ccdf19a4c867b372351\n""}, {'number': 3, 'created': '2013-12-31 00:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5dce3c8b605d1928ff347e22812e06584e739482', 'message': ""Add migration method to test sqldump files\n\nThis is very useful for testing real migration issues from a mysqldump.\nYou use it like this:\n\n    def _pre_upgrade_031(self, engine):\n       _load_mysql_dump_file(engine, 'dump.sql')\n\nChange-Id: I0d5680d42d608bdc1cb70ccdf19a4c867b372351\n""}, {'number': 4, 'created': '2014-01-03 09:29:44.000000000', 'files': ['heat/tests/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/92560e2d13620689fe0b7f9606707724602290bd', 'message': ""Add migration method to test sqldump files\n\nThis is very useful for testing real migration issues from a mysqldump.\nYou use it like this:\n\n    def _pre_upgrade_031(self, engine):\n       _load_mysql_dump_file(engine, 'dump.sql')\n\nChange-Id: I0d5680d42d608bdc1cb70ccdf19a4c867b372351\n""}]",6,63251,92560e2d13620689fe0b7f9606707724602290bd,23,8,4,4715,,,0,"Add migration method to test sqldump files

This is very useful for testing real migration issues from a mysqldump.
You use it like this:

    def _pre_upgrade_031(self, engine):
       _load_mysql_dump_file(engine, 'dump.sql')

Change-Id: I0d5680d42d608bdc1cb70ccdf19a4c867b372351
",git fetch https://review.opendev.org/openstack/heat refs/changes/51/63251/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/db/test_migrations.py'],1,38f2950de59a0f067ffa598d1617e1c1e0b14d52,test_migration," def _load_mysql_dump_file(self, engine, file_name): for key, eng in self.engines.items(): if eng is engine: conn_string = self.test_databases[key] conn_pieces = urlutils.urlparse(conn_string) if conn_string.startswith('mysql'): break else: return (user, password, database, host) = \ test_migrations.get_db_connection_info(conn_pieces) cmd = ('mysql -u \""%(user)s\"" -p\""%(password)s\"" -h %(host)s %(db)s ' ) % {'user': user, 'password': password, 'host': host, 'db': database} file_path = os.path.join(os.path.dirname(__file__), file_name) with open(file_path) as sql_file: process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stdin=sql_file, stderr=subprocess.STDOUT) output = process.communicate()[0] self.assertEqual(0, process.returncode, ""Failed to run: %s\n%s"" % (cmd, output))",,26,0
openstack%2Fhorizon~stable%2Fhavana~Ib573487938e0833668b002d05574e587734ef829,openstack/horizon,stable/havana,Ib573487938e0833668b002d05574e587734ef829,"disable volume creation, when cinder is disabled",MERGED,2014-01-27 12:24:25.000000000,2014-01-31 11:51:11.000000000,2014-01-31 11:51:10.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1955}, {'_account_id': 4978}, {'_account_id': 9275}]","[{'number': 1, 'created': '2014-01-27 12:24:25.000000000', 'files': ['openstack_dashboard/dashboards/project/images_and_snapshots/volume_snapshots/tables.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/tables.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/361b76698bf368d4b7f8d31241a2f526fd5e96d9', 'message': ""disable volume creation, when cinder is disabled\n\nbefore this patch, it's possible to try to create a volume\nfrom an image, create a volume during instance creation etc.\n\nThe same applies to create a volume from snapshot.\n\nCloses-bug: 1267438\n(cherry picked from commit 33076684a9db19b5e25ba517ce3ac90bb5c25fc0)\n\nConflicts:\n\topenstack_dashboard/dashboards/project/images_and_snapshots/images/tables.py\n\topenstack_dashboard/dashboards/project/instances/workflows/create_instance.py\n\nChange-Id: Ib573487938e0833668b002d05574e587734ef829\n""}]",0,69343,361b76698bf368d4b7f8d31241a2f526fd5e96d9,8,5,1,4264,,,0,"disable volume creation, when cinder is disabled

before this patch, it's possible to try to create a volume
from an image, create a volume during instance creation etc.

The same applies to create a volume from snapshot.

Closes-bug: 1267438
(cherry picked from commit 33076684a9db19b5e25ba517ce3ac90bb5c25fc0)

Conflicts:
	openstack_dashboard/dashboards/project/images_and_snapshots/images/tables.py
	openstack_dashboard/dashboards/project/instances/workflows/create_instance.py

Change-Id: Ib573487938e0833668b002d05574e587734ef829
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/69343/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/images_and_snapshots/volume_snapshots/tables.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/tables.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py']",3,361b76698bf368d4b7f8d31241a2f526fd5e96d9,bug/1267438,"from openstack_dashboard.api import base (""image_id"", _(""Boot from image"")), (""instance_snapshot_id"", _(""Boot from snapshot"")), if base.is_service_enabled(request, 'volume'): source_type_choices.append((""volume_id"", _(""Boot from volume""))) try: if api.nova.extension_supported(""BlockDeviceMappingV2Boot"", request): source_type_choices.append((""volume_image_id"", _(""Boot from image (creates a new volume).""))) except Exception: exceptions.handle(request, _('Unable to retrieve extensions ' 'information.')) source_type_choices.append((""volume_snapshot_id"", _(""Boot from volume snapshot (creates a new volume)."")))"," (""image_id"", _(""Boot from image."")), (""instance_snapshot_id"", _(""Boot from snapshot."")), (""volume_id"", _(""Boot from volume."")), try: if api.nova.extension_supported(""BlockDeviceMappingV2Boot"", request): source_type_choices.append((""volume_image_id"", _(""Boot from image (creates a new volume).""))) except Exception: exceptions.handle(request, _('Unable to retrieve extensions ' 'information.')) source_type_choices.append((""volume_snapshot_id"", _(""Boot from volume snapshot (creates a new volume)."")))",21,15
openstack%2Fheat~master~I92f6b058067ace3b3370a3670856ab3dc073b52f,openstack/heat,master,I92f6b058067ace3b3370a3670856ab3dc073b52f,Enabled source code coverage for contrib directory,MERGED,2014-01-24 16:24:20.000000000,2014-01-31 11:51:03.000000000,2014-01-31 11:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7135}, {'_account_id': 7253}, {'_account_id': 7761}]","[{'number': 1, 'created': '2014-01-24 16:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3163ecdab898f237726916790c82163be7af5bda', 'message': ""Enabled source code coverage for contrib directory\n\nSo we can check the source code coverage status of contrib\ndirectory. It's obvious to adjust omit and source properties in\n.coveragerc. The tricky code in .testr.conf is caused by the behavior\nof setuptools.\n\nWhen running coverage, setuptools set environment variable PYTHON to\n'coverage run --source package --parallel-mode' and call testr to run\nthe tests. The value specified via command line option --source will\noverwrite the source value in .coveragerc. So contrib directory is\nexcluded from coverage run.\n\nThe change in .testr.conf removed the '--source heat' specified by\nsetuptools. So the source value specified in .coveragerc will be used\nby coverage.\n\nChange-Id: I92f6b058067ace3b3370a3670856ab3dc073b52f\n""}, {'number': 2, 'created': '2014-01-25 06:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/91796583da93fb2305059bb4d8eec4b20c745e8d', 'message': ""Enabled source code coverage for contrib directory\n\nSo we can check the source code coverage status of contrib\ndirectory. It's obvious to adjust omit and source properties in\n.coveragerc. The tricky code in .testr.conf is caused by the behavior\nof setuptools.\n\nWhen running coverage, setuptools set environment variable PYTHON to\n'coverage run --source package --parallel-mode' and call testr to run\nthe tests. The value specified via command line option --source will\noverwrite the source value in .coveragerc. So contrib directory is\nexcluded from coverage run.\n\nThe change in .testr.conf removed the '--source heat' specified by\nsetuptools. So the source value specified in .coveragerc will be used\nby coverage.\n\nChange-Id: I92f6b058067ace3b3370a3670856ab3dc073b52f\n""}, {'number': 3, 'created': '2014-01-28 13:50:06.000000000', 'files': ['.testr.conf', '.coveragerc'], 'web_link': 'https://opendev.org/openstack/heat/commit/58581ce92c403e0744766d1a8232aa248e33dda0', 'message': ""Enabled source code coverage for contrib directory\n\nSo we can check the source code coverage status of contrib\ndirectory. It's obvious to adjust omit and source properties in\n.coveragerc. The tricky code in .testr.conf is caused by the behavior\nof setuptools.\n\nWhen running coverage, setuptools set environment variable PYTHON to\n'coverage run --source package --parallel-mode' and call testr to run\nthe tests. The value specified via command line option --source will\noverwrite the source value in .coveragerc. So contrib directory is\nexcluded from coverage run.\n\nThe change in .testr.conf removed the '--source heat' specified by\nsetuptools. So the source value specified in .coveragerc will be used\nby coverage.\n\nChange-Id: I92f6b058067ace3b3370a3670856ab3dc073b52f\n""}]",2,68953,58581ce92c403e0744766d1a8232aa248e33dda0,14,9,3,7761,,,0,"Enabled source code coverage for contrib directory

So we can check the source code coverage status of contrib
directory. It's obvious to adjust omit and source properties in
.coveragerc. The tricky code in .testr.conf is caused by the behavior
of setuptools.

When running coverage, setuptools set environment variable PYTHON to
'coverage run --source package --parallel-mode' and call testr to run
the tests. The value specified via command line option --source will
overwrite the source value in .coveragerc. So contrib directory is
excluded from coverage run.

The change in .testr.conf removed the '--source heat' specified by
setuptools. So the source value specified in .coveragerc will be used
by coverage.

Change-Id: I92f6b058067ace3b3370a3670856ab3dc073b52f
",git fetch https://review.opendev.org/openstack/heat refs/changes/53/68953/1 && git format-patch -1 --stdout FETCH_HEAD,"['.testr.conf', '.coveragerc']",2,3163ecdab898f237726916790c82163be7af5bda,fixes/cover_contrib,"source = heat,contrib omit = */tests/*,heat/openstack/*","source = heat omit = heat/tests/*,heat/openstack/*",4,4
openstack%2Fnova~master~Iee5eb4b64587cb63eb5082303f5623424bc338ea,openstack/nova,master,Iee5eb4b64587cb63eb5082303f5623424bc338ea,remove unsupported guestfs option,ABANDONED,2014-01-31 00:57:43.000000000,2014-01-31 11:46:24.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-31 00:57:43.000000000', 'files': ['nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/36890552e80ffa1c71a06ce5e688f1c106b91729', 'message': ""remove unsupported guestfs option\n\nwhen we tried to enable guestfs in the gate, we failed because\nthe GuestFS object didn't support this option. Disable to see\nif we can get through the gate turning on guestfs after it.\n\nChange-Id: Iee5eb4b64587cb63eb5082303f5623424bc338ea\n""}]",0,70275,36890552e80ffa1c71a06ce5e688f1c106b91729,6,4,1,2750,,,0,"remove unsupported guestfs option

when we tried to enable guestfs in the gate, we failed because
the GuestFS object didn't support this option. Disable to see
if we can get through the gate turning on guestfs after it.

Change-Id: Iee5eb4b64587cb63eb5082303f5623424bc338ea
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/70275/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/vfs/guestfs.py'],1,36890552e80ffa1c71a06ce5e688f1c106b91729,, self.handle = tpool.Proxy(guestfs.GuestFS()), self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)),1,1
openstack%2Fnova~master~I4cc5eaded2e21f1b2cd55615242a27b9773f0b42,openstack/nova,master,I4cc5eaded2e21f1b2cd55615242a27b9773f0b42,Disable libguestfs' default atexit handlers.,MERGED,2013-12-30 00:31:55.000000000,2014-01-31 11:45:01.000000000,2013-12-31 22:43:03.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1812}, {'_account_id': 2271}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-30 00:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42b07e406b5722b7f5adfb7452d62469c8bf46ca', 'message': ""Disable libguestfs' default atexit handlers.\n\nThese aren't safe for multi-threaded applications, per the bug\nreport from Daniel Berrange.\n\nFixes bug: 1261475\n\nChange-Id: I4cc5eaded2e21f1b2cd55615242a27b9773f0b42\n""}, {'number': 2, 'created': '2013-12-30 00:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f90c83dec685aa7804b578e689dfc057fddd075', 'message': ""Disable libguestfs' default atexit handlers.\n\nThese aren't safe for multi-threaded applications, per the bug\nreport from Daniel Berrange.\n\nCloses bug: 1261475\n\nChange-Id: I4cc5eaded2e21f1b2cd55615242a27b9773f0b42\n""}, {'number': 3, 'created': '2013-12-30 00:40:06.000000000', 'files': ['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/02abbef960b12deaa7a911788dbc56f3a0bd555a', 'message': ""Disable libguestfs' default atexit handlers.\n\nThese aren't safe for multi-threaded applications, per the bug\nreport from Daniel Berrange.\n\nCloses-bug: #1261475\n\nChange-Id: I4cc5eaded2e21f1b2cd55615242a27b9773f0b42\n""}]",0,64384,02abbef960b12deaa7a911788dbc56f3a0bd555a,16,6,3,2271,,,0,"Disable libguestfs' default atexit handlers.

These aren't safe for multi-threaded applications, per the bug
report from Daniel Berrange.

Closes-bug: #1261475

Change-Id: I4cc5eaded2e21f1b2cd55615242a27b9773f0b42
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/64384/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fakeguestfs.py', 'nova/virt/disk/vfs/guestfs.py']",2,42b07e406b5722b7f5adfb7452d62469c8bf46ca,bug/1261475, self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)), self.handle = tpool.Proxy(guestfs.GuestFS()),2,2
openstack%2Fheat~master~I31217e3de69a016fb4daa7e353161d58c71df98b,openstack/heat,master,I31217e3de69a016fb4daa7e353161d58c71df98b,Add heat.sqlite in git ignore list,MERGED,2014-01-25 05:58:47.000000000,2014-01-31 11:37:10.000000000,2014-01-31 11:37:09.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-01-25 05:58:47.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/heat/commit/d1e778d2115f5276dc648296968e26d08a52f3eb', 'message': 'Add heat.sqlite in git ignore list\n\nSQLite file ""heat.sqlite"" will be generated during test cases\nrunning. So it should be in git ignore list.\n\nChange-Id: I31217e3de69a016fb4daa7e353161d58c71df98b\n'}]",0,69099,d1e778d2115f5276dc648296968e26d08a52f3eb,7,4,1,7761,,,0,"Add heat.sqlite in git ignore list

SQLite file ""heat.sqlite"" will be generated during test cases
running. So it should be in git ignore list.

Change-Id: I31217e3de69a016fb4daa7e353161d58c71df98b
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/69099/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,d1e778d2115f5276dc648296968e26d08a52f3eb,fixes/ignore_heat.sqlite,heat.sqlite,,1,0
openstack%2Fheat~master~Iae7d5ec34413aedf8a38a3e22d22cacf4e031c24,openstack/heat,master,Iae7d5ec34413aedf8a38a3e22d22cacf4e031c24,Refactor software config db model to use LongText,MERGED,2014-01-24 16:57:46.000000000,2014-01-31 11:37:02.000000000,2014-01-31 11:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7135}, {'_account_id': 7761}]","[{'number': 1, 'created': '2014-01-24 16:57:46.000000000', 'files': ['heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py', 'heat/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3d2e0807213c81c2745e13e7064e5247b1088445', 'message': 'Refactor software config db model to use LongText\n\nReuse the types defined in heat.db.sqlalchemy.types in software config\ndb model and versions migration to make code clean and consistent.\n\nChange-Id: Iae7d5ec34413aedf8a38a3e22d22cacf4e031c24\n'}]",0,68967,3d2e0807213c81c2745e13e7064e5247b1088445,8,5,1,7761,,,0,"Refactor software config db model to use LongText

Reuse the types defined in heat.db.sqlalchemy.types in software config
db model and versions migration to make code clean and consistent.

Change-Id: Iae7d5ec34413aedf8a38a3e22d22cacf4e031c24
",git fetch https://review.opendev.org/openstack/heat refs/changes/67/68967/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py', 'heat/db/sqlalchemy/models.py']",2,3d2e0807213c81c2745e13e7064e5247b1088445,fixes/longtext,"from heat.db.sqlalchemy.types import LongText config = sqlalchemy.Column('config', LongText)"," config = sqlalchemy.Column('config', sqlalchemy.Text)",9,11
openstack%2Ffuel-main~master~I12b11fb3b64ce386f72069b8aca50c599e8f39bb,openstack/fuel-main,master,I12b11fb3b64ce386f72069b8aca50c599e8f39bb,Change import for puppet testing,MERGED,2014-01-31 10:30:34.000000000,2014-01-31 11:18:44.000000000,2014-01-31 11:18:44.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-31 10:30:34.000000000', 'files': ['fuelweb_test/puppet_tests/puppet_module.py', 'fuelweb_test/make_pptests.py', 'fuelweb_test/puppet_tests/pp_testgenerator.py', 'fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0648e4bc1dbdeda7347309f279f87a72f9eccc35', 'message': 'Change import for puppet testing\n\nChange-Id: I12b11fb3b64ce386f72069b8aca50c599e8f39bb\n'}]",0,70320,0648e4bc1dbdeda7347309f279f87a72f9eccc35,9,5,1,8882,,,0,"Change import for puppet testing

Change-Id: I12b11fb3b64ce386f72069b8aca50c599e8f39bb
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/20/70320/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/puppet_tests/puppet_module.py', 'fuelweb_test/make_pptests.py', 'fuelweb_test/puppet_tests/pp_testgenerator.py', 'fuelweb_test/requirements.txt']",4,0648e4bc1dbdeda7347309f279f87a72f9eccc35,master,Jinja2,,2,10
openstack%2Fceilometer~master~Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d,openstack/ceilometer,master,Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d,Correct a misuse of RestController in the Event API,MERGED,2014-01-29 15:47:16.000000000,2014-01-31 11:08:57.000000000,2014-01-31 11:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5678}]","[{'number': 1, 'created': '2014-01-29 15:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d7d4663ed147cdc68bd51ca96a6ee26a8a629c14', 'message': 'Correct a misuse of RestController in the Event API.\n\nChange-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d\n'}, {'number': 2, 'created': '2014-01-29 15:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2b0cdc9d6e85c29347f2944326c1a768f4c6d6f9', 'message': 'Correct a misuse of RestController in the Event API.\n\nChange-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d\n'}, {'number': 3, 'created': '2014-01-29 18:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d226617bc1e1d34abe3ab25b4c417bfd6f367aac', 'message': 'Correct a misuse of RestController in the Event API.\n\nWhen nested RestControllers exist, in order to determine which\narguments are associated with the parent resource, pecan looks at the\nget_one() method signature in the parent controller (this method).\n\nTraitsController needs the EventTypesController.get_one method to exist in\norder to properly pass the `event_type` identifier.\n\nChange-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d\n'}, {'number': 4, 'created': '2014-01-29 18:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e821d71b72f845024cf7378f3d25a3d3919c1e92', 'message': 'Correct a misuse of RestController in the Event API.\n\nWhen nested RestControllers exist, in order to determine which\narguments are associated with the parent resource, pecan looks at the\nget_one() method signature in the parent controller.\n\nTraitsController needs the EventTypesController.get_one method to exist in\norder to properly pass the `event_type` identifier.\n\nChange-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d\n'}, {'number': 5, 'created': '2014-01-29 20:46:53.000000000', 'files': ['ceilometer/api/controllers/v2.py', 'ceilometer/tests/api/v2/test_event_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4be513f2677571d860cad7d3b61a3ab23e12d164', 'message': 'Correct a misuse of RestController in the Event API\n\nWhen nested RestControllers exist, in order to determine which\narguments are associated with the parent resource, pecan looks at the\nget_one() method signature in the parent controller.\n\nTraitsController needs the EventTypesController.get_one method to exist in\norder to properly pass the `event_type` identifier.\n\nChange-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d\n'}]",1,69885,4be513f2677571d860cad7d3b61a3ab23e12d164,18,7,5,8005,,,0,"Correct a misuse of RestController in the Event API

When nested RestControllers exist, in order to determine which
arguments are associated with the parent resource, pecan looks at the
get_one() method signature in the parent controller.

TraitsController needs the EventTypesController.get_one method to exist in
order to properly pass the `event_type` identifier.

Change-Id: Ic1704c8f9c810ada4e22e8de75ef2511006e8d9d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/69885/4 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/controllers/v2.py'],1,d7d4663ed147cdc68bd51ca96a6ee26a8a629c14,(detached," @pecan.expose() def get_one(self, event_type): # This controller isn't actually to be reachable. # # When nested RestControllers exist, in order to determine which # arguments are associated with the parent resource, pecan looks at the # get_one() method signature in the parent controller (this method). # # TraitsController needs this method signature to exist in order # to properly pass the `event_type` identifier. pecan.abort(404) def get_all(self):"," # FIXME(herndon): due to a bug in pecan, making this method # get_all instead of get will hide the traits subcontroller. # https://bugs.launchpad.net/pecan/+bug/1262277 def get(self):",13,4
openstack%2Fmurano-deployment~release-0.4~I0bf3dc00c441a5ae4756bae12b7f2e030de72405,openstack/murano-deployment,release-0.4,I0bf3dc00c441a5ae4756bae12b7f2e030de72405,Rename murano services in murano-git-install,MERGED,2014-01-31 09:05:17.000000000,2014-01-31 11:04:11.000000000,2014-01-31 11:04:11.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 8040}]","[{'number': 1, 'created': '2014-01-31 09:05:17.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/67202ba7c93a237281b4fa9b16f22dcd63f9116a', 'message': 'Rename murano services in murano-git-install\n\nChange-Id: I0bf3dc00c441a5ae4756bae12b7f2e030de72405\nCloses-Bug: 1274853\n'}]",0,70312,67202ba7c93a237281b4fa9b16f22dcd63f9116a,6,4,1,7562,,,0,"Rename murano services in murano-git-install

Change-Id: I0bf3dc00c441a5ae4756bae12b7f2e030de72405
Closes-Bug: 1274853
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/12/70312/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,67202ba7c93a237281b4fa9b16f22dcd63f9116a,bug/1274853,"murano_services='openstack-murano-api openstack-murano-conductor openstack-murano-repository' service ""$service_name"" restart","murano_services='murano-api murano-conductor murano-repository' stop ""$service_name"" start ""$service_name""",2,3
openstack%2Ffuel-main~master~I9e1d1fb2f3c6f642c23a509ac41580e5c53bf952,openstack/fuel-main,master,I9e1d1fb2f3c6f642c23a509ac41580e5c53bf952,Add test that OS is operation after master fail,MERGED,2014-01-27 18:27:06.000000000,2014-01-31 11:02:48.000000000,2014-01-31 11:02:48.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8767}, {'_account_id': 8839}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-27 18:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/89604833809d50537e73611b8ace00c8faf42e94', 'message': 'Add test that OS is operation after master fail\n\nTest verifies that openstack is operational\nafter master node is failed. Scenario:\n* Deploy simple nova flat\n* verify that deployment is successful\n* run ostf\n* destroy admin node\n* verify openstack\n\nCloses-bug: #1259460\nChange-Id: I9e1d1fb2f3c6f642c23a509ac41580e5c53bf952\n'}, {'number': 2, 'created': '2014-01-30 14:25:23.000000000', 'files': ['fuelweb_test/tests/tests_strength/__init__.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/helpers/common.py', 'fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/46bd199eb77b02c9e5552cc18446e53c7db62583', 'message': 'Add test that OS is operation after master fail\n\nTest verifies that openstack is operational\nafter master node is failed. Scenario:\n* Deploy simple nova flat\n* verify that deployment is successful\n* run ostf\n* destroy admin node\n* verify openstack\n\nCloses-bug: #1259460\nChange-Id: I9e1d1fb2f3c6f642c23a509ac41580e5c53bf952\n'}]",1,69435,46bd199eb77b02c9e5552cc18446e53c7db62583,16,6,2,6719,,,0,"Add test that OS is operation after master fail

Test verifies that openstack is operational
after master node is failed. Scenario:
* Deploy simple nova flat
* verify that deployment is successful
* run ostf
* destroy admin node
* verify openstack

Closes-bug: #1259460
Change-Id: I9e1d1fb2f3c6f642c23a509ac41580e5c53bf952
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/35/69435/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/__init__.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/helpers/common.py', 'fuelweb_test/helpers/checkers.py']",5,89604833809d50537e73611b8ace00c8faf42e94,bug/1259460," logger.debug( ""Services still not read. Sleeping for 60 seconds and retrying"")"," logger.debug(""Services still not read. Sleeping for 60 seconds and retrying"")",145,6
openstack%2Fceilometer~stable%2Fhavana~I4d4d7bdff09b6748e14ebac8293050513fb18ed2,openstack/ceilometer,stable/havana,I4d4d7bdff09b6748e14ebac8293050513fb18ed2,Fix to tackle instances without an image assigned,MERGED,2014-01-15 15:45:03.000000000,2014-01-31 10:39:13.000000000,2014-01-31 10:39:13.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 2860}, {'_account_id': 6924}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-01-15 15:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2a269b7ceb3e82ffb5a69923c1c7e86379ba554f', 'message': 'Fix to tackle instances without an image assigned\n\nfixes bug #1233103\n\nChange-Id: I4d4d7bdff09b6748e14ebac8293050513fb18ed2\n'}, {'number': 2, 'created': '2014-01-21 18:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04453b3034196d26383ff12695788f72c47b9e33', 'message': 'Fix to tackle instances without an image assigned\n\nfixes bug #1233103\n\nChange-Id: I4d4d7bdff09b6748e14ebac8293050513fb18ed2\n'}, {'number': 3, 'created': '2014-01-27 22:58:53.000000000', 'files': ['tests/test_novaclient.py', 'ceilometer/nova_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/df7ff3b4edfd61c0ada80006a6283fcf12d601cb', 'message': 'Fix to tackle instances without an image assigned\n\nfixes bug #1233103\n\nChange-Id: I4d4d7bdff09b6748e14ebac8293050513fb18ed2\n(cherry picked from commit e36f9f32fea2e128e1f03bf2b94ad0584337b2c4)\n'}]",3,66875,df7ff3b4edfd61c0ada80006a6283fcf12d601cb,20,8,3,6924,,,0,"Fix to tackle instances without an image assigned

fixes bug #1233103

Change-Id: I4d4d7bdff09b6748e14ebac8293050513fb18ed2
(cherry picked from commit e36f9f32fea2e128e1f03bf2b94ad0584337b2c4)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/75/66875/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_novaclient.py', 'ceilometer/nova_client.py']",2,2a269b7ceb3e82ffb5a69923c1c7e86379ba554f,bug/1233103, try: iid = instance.image['id'] except TypeError: instance.image = None instance.kernel_id = None instance.ramdisk_id = None return , iid = instance.image['id'],24,1
openstack%2Fheat~stable%2Fhavana~Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32,openstack/heat,stable/havana,Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32,Do not attempt a stack update when it is suspended,MERGED,2013-11-17 20:18:45.000000000,2014-01-31 10:39:05.000000000,2014-01-31 10:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-11-17 20:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/91081f217a2c36a1c31929c7e9dbb9fd7a4aae73', 'message': 'Do not attempt a stack update when it is suspended\n\nAnd in any state (inprogress, complete, failed).\n\nCloses-bug: #1234242\nChange-Id: Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32\n'}, {'number': 2, 'created': '2013-11-18 01:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/65824152e2d7fe83fccaec247fd188c37a100991', 'message': 'Do not attempt a stack update when it is suspended\n\nAnd in any state (inprogress, complete, failed).\n\nCloses-bug: #1234242\nChange-Id: Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32\n'}, {'number': 3, 'created': '2014-01-27 03:35:05.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ec4ed57627e8127978125bcbed1cf9fc03a991e0', 'message': 'Do not attempt a stack update when it is suspended\n\nAnd in any state (inprogress, complete, failed).\n\nCloses-bug: #1234242\nChange-Id: Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32\n'}]",0,56833,ec4ed57627e8127978125bcbed1cf9fc03a991e0,40,11,3,4571,,,0,"Do not attempt a stack update when it is suspended

And in any state (inprogress, complete, failed).

Closes-bug: #1234242
Change-Id: Ic0bccfa3d3d98cb41d0f5228d8cdc164c5c1fd32
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/56833/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,91081f217a2c36a1c31929c7e9dbb9fd7a4aae73,56835, if current_stack.action == current_stack.SUSPEND: msg = _('Updating a stack when it is suspended') raise exception.NotSupported(feature=msg) ,,51,0
openstack%2Fceilometer~master~Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7,openstack/ceilometer,master,Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7,Update oslo,MERGED,2014-01-29 16:43:19.000000000,2014-01-31 10:38:57.000000000,2014-01-31 10:38:56.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-01-29 16:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d08dcdb985b126e2120d14591f55b84e161d1ed9', 'message': 'Update oslo\n\nThis updates to:\n\ncommit dc68e458d1a70be3a73bc5ee92ab0c35dd2a5e40\nMerge: e16071e 6da13e8\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Wed Jan 29 12:31:16 2014 +0000\n\n    Merge ""generator: rename EXTRA_MODULES_FILE to RC_FILE""\n\nChange-Id: Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7\n'}, {'number': 2, 'created': '2014-01-31 09:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/de3d39bb28919266217839707e4f7b3501670c6a', 'message': 'Update oslo\n\nThis updates to:\n\ncommit dc68e458d1a70be3a73bc5ee92ab0c35dd2a5e40\nMerge: e16071e 6da13e8\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Wed Jan 29 12:31:16 2014 +0000\n\n    Merge ""generator: rename EXTRA_MODULES_FILE to RC_FILE""\n\nChange-Id: Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7\n'}, {'number': 3, 'created': '2014-01-31 09:18:37.000000000', 'files': ['ceilometer/openstack/common/rpc/impl_zmq.py', 'ceilometer/openstack/common/db/sqlalchemy/models.py', 'ceilometer/openstack/common/middleware/notifier.py', 'ceilometer/openstack/common/processutils.py', 'tools/config/generate_sample.sh', 'ceilometer/openstack/common/timeutils.py', 'ceilometer/openstack/common/middleware/debug.py', 'ceilometer/openstack/common/policy.py', 'ceilometer/openstack/common/rpc/matchmaker.py', 'ceilometer/openstack/common/middleware/audit.py', 'ceilometer/openstack/common/deprecated/__init__.py', 'ceilometer/openstack/common/rpc/impl_kombu.py', 'ceilometer/openstack/common/db/sqlalchemy/utils.py', 'ceilometer/openstack/common/log.py', 'ceilometer/openstack/common/rpc/impl_fake.py', 'ceilometer/openstack/common/threadgroup.py', 'ceilometer/openstack/common/fileutils.py', 'ceilometer/openstack/common/fixture/config.py', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/middleware/sizelimit.py', 'ceilometer/openstack/common/db/sqlalchemy/test_base.py', 'ceilometer/openstack/common/lockutils.py', 'ceilometer/openstack/common/test.py', 'ceilometer/openstack/common/middleware/base.py', 'ceilometer/openstack/common/db/sqlalchemy/test_migrations.py', 'ceilometer/openstack/common/deprecated/wsgi.py', 'ceilometer/openstack/common/log_handler.py', 'ceilometer/openstack/common/db/sqlalchemy/migration.py', 'etc/ceilometer/ceilometer.conf.sample', 'ceilometer/openstack/common/xmlutils.py', 'ceilometer/openstack/common/middleware/context.py', 'ceilometer/openstack/common/fixture/mockpatch.py', 'ceilometer/openstack/common/rpc/__init__.py', 'ceilometer/openstack/common/rpc/matchmaker_ring.py', 'ceilometer/openstack/common/config/generator.py', 'ceilometer/openstack/common/notifier/test_notifier.py', 'ceilometer/openstack/common/rpc/matchmaker_redis.py', 'ceilometer/openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aebf5ec9d0159c85f07d656dd81b5ad5e0e9386e', 'message': 'Update oslo\n\nThis updates to:\n\ncommit b3e5166e3f47148856d898c4653b0c089c2315f5\nMerge: 0002ffa 39e1c5c\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Thu Jan 30 10:18:54 2014 +0000\n\n    Merge ""Move db tests base.py to common code""\n\nChange-Id: Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7\n'}]",0,69903,aebf5ec9d0159c85f07d656dd81b5ad5e0e9386e,11,4,3,1669,,,0,"Update oslo

This updates to:

commit b3e5166e3f47148856d898c4653b0c089c2315f5
Merge: 0002ffa 39e1c5c
Author: Jenkins <jenkins@review.openstack.org>
Date:   Thu Jan 30 10:18:54 2014 +0000

    Merge ""Move db tests base.py to common code""

Change-Id: Iaa76b1165e195f0c3874bc5c8bcbc9ecbb6ca5d7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/03/69903/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/rpc/impl_zmq.py', 'ceilometer/openstack/common/db/sqlalchemy/models.py', 'ceilometer/openstack/common/middleware/notifier.py', 'ceilometer/openstack/common/processutils.py', 'tools/config/generate_sample.sh', 'ceilometer/openstack/common/timeutils.py', 'ceilometer/openstack/common/middleware/debug.py', 'ceilometer/openstack/common/policy.py', 'ceilometer/openstack/common/rpc/matchmaker.py', 'ceilometer/openstack/common/middleware/audit.py', 'ceilometer/openstack/common/deprecated/__init__.py', 'ceilometer/openstack/common/rpc/impl_kombu.py', 'ceilometer/openstack/common/db/sqlalchemy/utils.py', 'ceilometer/openstack/common/log.py', 'ceilometer/openstack/common/rpc/impl_fake.py', 'ceilometer/openstack/common/threadgroup.py', 'ceilometer/openstack/common/fileutils.py', 'ceilometer/openstack/common/fixture/config.py', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/middleware/sizelimit.py', 'ceilometer/openstack/common/lockutils.py', 'ceilometer/openstack/common/test.py', 'ceilometer/openstack/common/middleware/base.py', 'ceilometer/openstack/common/db/sqlalchemy/test_migrations.py', 'ceilometer/openstack/common/deprecated/wsgi.py', 'ceilometer/openstack/common/log_handler.py', 'ceilometer/openstack/common/db/sqlalchemy/migration.py', 'etc/ceilometer/ceilometer.conf.sample', 'ceilometer/openstack/common/xmlutils.py', 'ceilometer/openstack/common/middleware/context.py', 'ceilometer/openstack/common/fixture/mockpatch.py', 'ceilometer/openstack/common/rpc/__init__.py', 'ceilometer/openstack/common/rpc/matchmaker_ring.py', 'ceilometer/openstack/common/config/generator.py', 'ceilometer/openstack/common/notifier/test_notifier.py', 'ceilometer/openstack/common/rpc/matchmaker_redis.py', 'ceilometer/openstack/common/db/sqlalchemy/session.py']",37,d08dcdb985b126e2120d14591f55b84e161d1ed9,jd/update-oslo," help='The file name to use with SQLite'), help='If True, SQLite uses synchronous mode'), help='Timeout before idle sql connections are reaped'), help='Maximum db connection retries during startup. ' help='Interval between retries of opening a sql connection'),"," help='the filename to use with sqlite'), help='If true, use synchronous mode for sqlite'), help='timeout before idle sql connections are reaped'), help='maximum db connection retries during startup. ' help='interval between retries of opening a sql connection'),",327,1389
openstack%2Fheat~stable%2Fhavana~I5e245556c21a1ea800eb9e0346f3b2414ad56183,openstack/heat,stable/havana,I5e245556c21a1ea800eb9e0346f3b2414ad56183,Validate template parameter attributes,MERGED,2013-11-17 20:18:44.000000000,2014-01-31 10:38:04.000000000,2014-01-31 10:38:03.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6456}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7244}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7761}, {'_account_id': 7896}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-11-17 20:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a3a1c5df4463fdf9494bc046d328453f74d3390f', 'message': 'Validate template parameter attributes\n\nValidate that template parameter is provided with at least one attribute.\n\nCloses-Bug: #1227061\n\nChange-Id: I5e245556c21a1ea800eb9e0346f3b2414ad56183\n'}, {'number': 2, 'created': '2013-11-18 01:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d7216056698497d96210397c538fd2991c6c1636', 'message': 'Validate template parameter attributes\n\nValidate that template parameter is provided with at least one attribute.\n\nCloses-Bug: #1227061\n\nChange-Id: I5e245556c21a1ea800eb9e0346f3b2414ad56183\n'}, {'number': 3, 'created': '2014-01-27 03:35:05.000000000', 'files': ['heat/api/middleware/fault.py', 'heat/api/aws/exception.py', 'heat/tests/test_parameters.py', 'heat/common/exception.py', 'heat/engine/parameters.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/35cfa39fb1f05ea94a2d244d231b2381783795d7', 'message': 'Validate template parameter attributes\n\nValidate that template parameter is provided with at least one attribute.\n\nCloses-Bug: #1227061\n\nChange-Id: I5e245556c21a1ea800eb9e0346f3b2414ad56183\n'}]",7,56832,35cfa39fb1f05ea94a2d244d231b2381783795d7,47,15,3,4571,,,0,"Validate template parameter attributes

Validate that template parameter is provided with at least one attribute.

Closes-Bug: #1227061

Change-Id: I5e245556c21a1ea800eb9e0346f3b2414ad56183
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/56832/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/api/aws/exception.py', 'heat/tests/test_parameters.py', 'heat/common/exception.py', 'heat/engine/parameters.py']",5,a3a1c5df4463fdf9494bc046d328453f74d3390f,56835," self._validate_tmpl_parameters() def _validate_tmpl_parameters(self): param = None for key in self.tmpl.t.keys(): if key == 'Parameters' or key == 'parameters': param = key break if param is not None: template_params = self.tmpl.t[key] for name, attrs in template_params.iteritems(): if not isinstance(attrs, dict): raise exception.InvalidTemplateParameter(key=name)",,28,0
openstack%2Fheat~stable%2Fhavana~Ibed9e164c89543b679393ee18ccdb4a15bdea6d7,openstack/heat,stable/havana,Ibed9e164c89543b679393ee18ccdb4a15bdea6d7,"Use ""python -m coverage"" instead of coverage cli",MERGED,2013-11-17 20:18:44.000000000,2014-01-31 10:30:58.000000000,2014-01-31 10:30:57.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7230}, {'_account_id': 7244}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7761}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-11-17 20:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/34bb8b4110db978592ed3888961877ec5c881ea2', 'message': 'Use ""python -m coverage"" instead of coverage cli\n\nAs requested by the Debian package maintainer, this makes the\ncoverage report work more easily on Debian/Ubuntu\n\nChange-Id: Ibed9e164c89543b679393ee18ccdb4a15bdea6d7\nCloses-Bug: #1241330\n'}, {'number': 2, 'created': '2013-11-18 01:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c2ed4294337b61ceca98055857017dd442c96b55', 'message': 'Use ""python -m coverage"" instead of coverage cli\n\nAs requested by the Debian package maintainer, this makes the\ncoverage report work more easily on Debian/Ubuntu\n\nChange-Id: Ibed9e164c89543b679393ee18ccdb4a15bdea6d7\nCloses-Bug: #1241330\n'}, {'number': 3, 'created': '2014-01-27 03:35:06.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/50dc14af4f78f0d4050f82545aae6910a92aa8cf', 'message': 'Use ""python -m coverage"" instead of coverage cli\n\nAs requested by the Debian package maintainer, this makes the\ncoverage report work more easily on Debian/Ubuntu\n\nChange-Id: Ibed9e164c89543b679393ee18ccdb4a15bdea6d7\nCloses-Bug: #1241330\n'}]",0,56831,50dc14af4f78f0d4050f82545aae6910a92aa8cf,41,13,3,4571,,,0,"Use ""python -m coverage"" instead of coverage cli

As requested by the Debian package maintainer, this makes the
coverage report work more easily on Debian/Ubuntu

Change-Id: Ibed9e164c89543b679393ee18ccdb4a15bdea6d7
Closes-Bug: #1241330
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/56831/3 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,34bb8b4110db978592ed3888961877ec5c881ea2,56835, python -m coverage report --show-missing, coverage report -m,1,1
openstack%2Fpuppet-horizon~master~I5aeb577ce827e923ed01a73cca1bd79789f81eff,openstack/puppet-horizon,master,I5aeb577ce827e923ed01a73cca1bd79789f81eff,Add ability to disable configuration of apache,MERGED,2014-01-29 22:01:58.000000000,2014-01-31 10:27:32.000000000,2014-01-31 10:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 8318}]","[{'number': 1, 'created': '2014-01-29 22:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/1364ab51ed5f5155eff57ff9141b8fceaae42dd3', 'message': 'Add ability to disable configuration of apache\n\nAdd configure_apache parameter to add the ability to disable\nconfiguration of Apache vhost for Horizon.\n\n- Move Apache configuration to horizon::wsgi::apache class.\n- Move management of logdir resource to horizon::wsgi::apache class.\n\nChange-Id: I5aeb577ce827e923ed01a73cca1bd79789f81eff\nCloses-bug: #1190282\n'}, {'number': 2, 'created': '2014-01-29 22:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/9d60e6582f88cd1b079ddaa59d8a1c695a3d34aa', 'message': 'Add ability to disable configuration of apache\n\nAdd configure_apache parameter to add the ability to disable\nconfiguration of Apache vhost for Horizon.\n\n- Move Apache configuration to horizon::wsgi::apache class.\n- Move management of logdir resource to horizon::wsgi::apache class.\n\nChange-Id: I5aeb577ce827e923ed01a73cca1bd79789f81eff\nCloses-bug: #1190282\n'}, {'number': 3, 'created': '2014-01-30 18:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/905d00ad2e61bd88a18c57bd230357f42f7f7ef2', 'message': 'Add ability to disable configuration of apache\n\nAdd configure_apache parameter to add the ability to disable\nconfiguration of Apache vhost for Horizon.\n\n- Move Apache configuration to horizon::wsgi::apache class.\n- Move management of logdir resource to horizon::wsgi::apache class.\n\nChange-Id: I5aeb577ce827e923ed01a73cca1bd79789f81eff\nCloses-bug: #1190282\n'}, {'number': 4, 'created': '2014-01-30 21:35:55.000000000', 'files': ['manifests/wsgi/apache.pp', 'spec/spec_helper.rb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb', 'spec/classes/horizon_wsgi_apache_spec.rb', 'spec/shared_examples.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/4b864789c0dbf46897324e69ad6750912f758143', 'message': 'Add ability to disable configuration of apache\n\nAdd configure_apache parameter to add the ability to disable\nconfiguration of Apache vhost for Horizon.\n\n- Move Apache configuration to horizon::wsgi::apache class.\n- Move management of logdir resource to horizon::wsgi::apache class.\n\nChange-Id: I5aeb577ce827e923ed01a73cca1bd79789f81eff\nCloses-bug: #1190282\n'}]",6,69990,4b864789c0dbf46897324e69ad6750912f758143,15,5,4,7156,,,0,"Add ability to disable configuration of apache

Add configure_apache parameter to add the ability to disable
configuration of Apache vhost for Horizon.

- Move Apache configuration to horizon::wsgi::apache class.
- Move management of logdir resource to horizon::wsgi::apache class.

Change-Id: I5aeb577ce827e923ed01a73cca1bd79789f81eff
Closes-bug: #1190282
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/90/69990/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/wsgi/apache.pp', 'spec/spec_helper.rb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb', 'spec/classes/horizon_wsgi_apache_spec.rb', 'spec/shared_examples.rb']",6,1364ab51ed5f5155eff57ff9141b8fceaae42dd3,bug/1190282,"shared_examples_for ""a Puppet::Error"" do |description| it ""with message matching #{description.inspect}"" do expect { subject }.to raise_error(Puppet::Error, description) end end ",,286,114
openstack%2Fheat~stable%2Fhavana~I8187d8a0395cc96d9727aa812d57f281e69c516d,openstack/heat,stable/havana,I8187d8a0395cc96d9727aa812d57f281e69c516d,Allow DependsOn to accept a list,MERGED,2013-11-17 20:18:44.000000000,2014-01-31 10:20:31.000000000,2014-01-31 10:20:31.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7193}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7761}, {'_account_id': 8414}, {'_account_id': 9542}]","[{'number': 1, 'created': '2013-11-17 20:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/82eda613dbe4faf138ee86412fc6062a2294a19b', 'message': 'Allow DependsOn to accept a list\n\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html\n\nChange-Id: I8187d8a0395cc96d9727aa812d57f281e69c516d\nCloses-bug: #1235496\n'}, {'number': 2, 'created': '2013-11-18 01:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9120bfe2e59c1b517aaeace18f5131dd094ef0a6', 'message': 'Allow DependsOn to accept a list\n\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html\n\nChange-Id: I8187d8a0395cc96d9727aa812d57f281e69c516d\nCloses-bug: #1235496\n'}, {'number': 3, 'created': '2014-01-27 03:35:07.000000000', 'files': ['heat/tests/test_parser.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6fa3c8fa50b3570dff8da425250c4d3166fdc138', 'message': 'Allow DependsOn to accept a list\n\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html\n\nChange-Id: I8187d8a0395cc96d9727aa812d57f281e69c516d\nCloses-bug: #1235496\n'}]",2,56830,6fa3c8fa50b3570dff8da425250c4d3166fdc138,50,16,3,4571,,,0,"Allow DependsOn to accept a list

http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html

Change-Id: I8187d8a0395cc96d9727aa812d57f281e69c516d
Closes-bug: #1235496
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/56830/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parser.py', 'heat/engine/resource.py']",2,82eda613dbe4faf138ee86412fc6062a2294a19b,56835," res_name, att = value res_list = [res_name] elif key == 'DependsOn' and isinstance(value, list): res_list = value else: res_list = [value] for res in res_list: try: target = self.stack[res] except KeyError: raise exception.InvalidTemplateReference( resource=res, key=path) if key == 'DependsOn' or target.strict_dependency: deps += (self, target)"," value, att = value try: target = self.stack.resources[value] except KeyError: raise exception.InvalidTemplateReference( resource=value, key=path) if key == 'DependsOn' or target.strict_dependency: deps += (self, target)",36,9
openstack%2Fpuppet-horizon~master~I685b2430c06893dd3e80c4900e832024f0436ea8,openstack/puppet-horizon,master,I685b2430c06893dd3e80c4900e832024f0436ea8,"Deprecation of keystone_scheme,host,port params",MERGED,2014-01-28 16:35:20.000000000,2014-01-31 10:06:33.000000000,2014-01-31 10:06:33.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 8318}]","[{'number': 1, 'created': '2014-01-28 16:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/9e96308a974e1321baff9232e5ff4e8697877c9c', 'message': 'Deprecation of keystone_scheme,host,port params\n\nUse deprecated parameters if any value is passed to preserve\nproper backward compatibility.\n\nChange-Id: I685b2430c06893dd3e80c4900e832024f0436ea8\nCloses-bug: #1273442\n'}, {'number': 2, 'created': '2014-01-28 16:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/41111f8da6b2c0b26b5e23d1c5af36031b2764ac', 'message': 'Deprecation of keystone_scheme,host,port params\n\nUse deprecated parameters if any value is passed to preserve\nproper backward compatibility.\n\nChange-Id: I685b2430c06893dd3e80c4900e832024f0436ea8\nCloses-bug: #1273442\n'}, {'number': 3, 'created': '2014-01-29 20:58:09.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/ce4a82b4f88b982c69c90244844da01757b7e9f9', 'message': 'Deprecation of keystone_scheme,host,port params\n\nUse deprecated parameters if any value is passed to preserve\nproper backward compatibility.\n\nChange-Id: I685b2430c06893dd3e80c4900e832024f0436ea8\nCloses-bug: #1273442\n'}]",0,69646,ce4a82b4f88b982c69c90244844da01757b7e9f9,11,5,3,7156,,,0,"Deprecation of keystone_scheme,host,port params

Use deprecated parameters if any value is passed to preserve
proper backward compatibility.

Change-Id: I685b2430c06893dd3e80c4900e832024f0436ea8
Closes-bug: #1273442
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/46/69646/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,9e96308a974e1321baff9232e5ff4e8697877c9c,bug/1273442," context 'with deprecated parameters' do before do params.merge!( :keystone_host => 'keystone.example.com', :keystone_port => 4682, :keystone_scheme => 'https', ) end it 'generates local_settings.py' do verify_contents(subject, platforms_params[:config_file], [ 'OPENSTACK_KEYSTONE_URL = ""https://keystone.example.com:4682/v2.0""' ]) end end ",,68,27
openstack%2Fpython-blazarclient~master~I2121d14710cbc1620cbe6745766f708f57bdecf7,openstack/python-blazarclient,master,I2121d14710cbc1620cbe6745766f708f57bdecf7,Updated from global requirements,MERGED,2014-01-24 22:42:32.000000000,2014-01-31 10:05:50.000000000,2014-01-31 10:05:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2928}, {'_account_id': 3012}, {'_account_id': 6582}, {'_account_id': 7075}, {'_account_id': 7166}, {'_account_id': 7535}]","[{'number': 1, 'created': '2014-01-24 22:42:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/3ea9c3d805d594d52ee8fce22fafec2cbb616963', 'message': 'Updated from global requirements\n\nChange-Id: I2121d14710cbc1620cbe6745766f708f57bdecf7\n'}]",0,69050,3ea9c3d805d594d52ee8fce22fafec2cbb616963,5,8,1,3,,,0,"Updated from global requirements

Change-Id: I2121d14710cbc1620cbe6745766f708f57bdecf7
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/50/69050/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3ea9c3d805d594d52ee8fce22fafec2cbb616963,openstack/requirements,python-keystoneclient>=0.4.2,python-keystoneclient>=0.4.1,1,1
openstack%2Fpuppet-horizon~master~I4721cacff86a88ff360b7a3ede45464ff44e684d,openstack/puppet-horizon,master,I4721cacff86a88ff360b7a3ede45464ff44e684d,Refactor rspec tests,MERGED,2014-01-28 16:35:20.000000000,2014-01-31 10:04:49.000000000,2014-01-31 10:04:49.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 7156}, {'_account_id': 8318}]","[{'number': 1, 'created': '2014-01-28 16:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/39f8f033ea2e9057b0dd1d868916ccebcd8fc5eb', 'message': 'Refactor rspec tests\n\nChange-Id: I4721cacff86a88ff360b7a3ede45464ff44e684d\n'}, {'number': 2, 'created': '2014-01-28 16:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b457eca2a391ba84459b13e4ab737e0a93c4d857', 'message': 'Refactor rspec tests\n\nChange-Id: I4721cacff86a88ff360b7a3ede45464ff44e684d\n'}, {'number': 3, 'created': '2014-01-29 20:52:10.000000000', 'files': ['spec/classes/horizon_init_spec.rb', 'spec/fixtures/override_local_settings.py.erb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/700c637c9f61bdf384acc0f739bd63f9f5e9835c', 'message': 'Refactor rspec tests\n\nChange-Id: I4721cacff86a88ff360b7a3ede45464ff44e684d\n'}]",0,69645,700c637c9f61bdf384acc0f739bd63f9f5e9835c,12,6,3,7156,,,0,"Refactor rspec tests

Change-Id: I4721cacff86a88ff360b7a3ede45464ff44e684d
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/45/69645/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/horizon_init_spec.rb', 'spec/fixtures/override_local_settings.py.erb']",2,39f8f033ea2e9057b0dd1d868916ccebcd8fc5eb,cleanup_rspec,"DEBUG = <%= @django_debug %> 'help_url': ""<%= @help_url %>"",","DEBUG = <%= django_debug %> 'help_url': ""<%= help_url %>"",",83,135
openstack%2Ftripleo-image-elements~master~I1914383a9e0c834220f95d63b1896fb6b63e11ef,openstack/tripleo-image-elements,master,I1914383a9e0c834220f95d63b1896fb6b63e11ef,Delete stale file injection option.,MERGED,2014-01-30 21:58:29.000000000,2014-01-31 09:55:11.000000000,2014-01-31 09:55:11.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 7144}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-30 21:58:29.000000000', 'files': ['elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/seed-stack-config/config.json'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ea06d1660edff3e95e7580be7e14ee47f25f3cae', 'message': ""Delete stale file injection option.\n\nWe don't use nova-bm file injection anymore, and won't.\n\nChange-Id: I1914383a9e0c834220f95d63b1896fb6b63e11ef\n""}]",0,70226,ea06d1660edff3e95e7580be7e14ee47f25f3cae,7,4,1,4190,,,0,"Delete stale file injection option.

We don't use nova-bm file injection anymore, and won't.

Change-Id: I1914383a9e0c834220f95d63b1896fb6b63e11ef
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/26/70226/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/seed-stack-config/config.json']",2,ea06d1660edff3e95e7580be7e14ee47f25f3cae,,," ""use_file_injection"": ""False"",",1,3
openstack%2Fglance~master~Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8,openstack/glance,master,Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8,Add multifilesystem store to support NFS servers as backend,MERGED,2013-11-28 12:02:11.000000000,2014-01-31 09:53:11.000000000,2014-01-31 09:53:10.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 6536}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 9303}]","[{'number': 1, 'created': '2013-11-28 12:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/859cf7ca877aca723943fc686433e543bc288a0e', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image. Each directory can be coupled with its priority.\n\nCurrent Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir=</path/to/store>\nfilesystem_store_datadir = /var/glance/store1\n\nChanged Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir=</path/to/store>:<priority>,.....\nfilesystem_store_datadir = /var/glance/store1:100,/var/glance/store\n\nNote:\n-----\n1. Store with priority 200 has precedence over store with priority 100\n2. If no priority is specified, default priority '0' is associated with it.\n3. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n\nblueprint: glance-multifilesystem-store\nDocImpact: Miltifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 2, 'created': '2013-12-02 10:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/53ca991fcff0ae67ed7d3a25406e789aa7d7d4d3', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image. Each directory can be coupled with its priority.\n\nCurrent Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir=</path/to/store>\nfilesystem_store_datadir = /var/glance/store1\n\nChanged Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir=</path/to/store>:<priority>,.....\nfilesystem_store_datadir = /var/glance/store1:100,/var/glance/store\n\nNote:\n-----\n1. Store with priority 200 has precedence over store with priority 100\n2. If no priority is specified, default priority '0' is associated with it.\n3. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Miltifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 3, 'created': '2014-01-06 07:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/30e3817b582d5aca86c71c940a1bbf144cd1af48', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image. Each directory can be coupled with its priority.\n\nCurrent Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>\nfilesystem_store_datadir = /var/glance/store1\n\nChanged Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>:<priority>,.....\nfilesystem_store_datadir = /var/glance/store1:100,/var/glance/store\n\nNote:\n-----\n1. Store with priority 200 has precedence over store with priority 100\n2. If no priority is specified, default priority '0' is associated with it.\n3. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n4. If same store is specified multiple times with same/different priority\nthen priority of first occurence of store in configuration is used.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 4, 'created': '2014-01-13 08:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a1e7ad84951da3c1120832470065cdb42e51f971', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image. Each directory can be coupled with its priority.\n\nCurrent Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>\nfilesystem_store_datadir = /var/glance/store1\n\nChanged Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>:<priority>;.....\nfilesystem_store_datadir = /var/glance/store1:100;/var/glance/store\n\nNote:\n-----\n1. Store with priority 200 has precedence over store with priority 100\n2. If no priority is specified, default priority '0' is associated with it.\n3. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n4. If same store is specified multiple times with same/different priority\nthen priority of first occurence of store in configuration is used.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 5, 'created': '2014-01-13 10:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d26812aec3d14de0c4216160adbc4e45cb4e40f4', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image. Each directory can be coupled with its priority.\n\nCurrent Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>\nfilesystem_store_datadir = /var/glance/store1\n\nChanged Format for filesystem_store_datadir in glance-api.conf:\n---------------------------------------------------------------\nfilesystem_store_datadir = </path/to/store>:<priority>;.....\nfilesystem_store_datadir = /var/glance/store1:100;/var/glance/store\n\nNote:\n-----\n1. Store with priority 200 has precedence over store with priority 100\n2. If no priority is specified, default priority '0' is associated with it.\n3. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n4. If same store is specified multiple times with same/different priority\nthen priority of first occurence of store in configuration is used.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 6, 'created': '2014-01-14 11:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/65e1992a2f0b71aca4c505efb5ae580a956a589f', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times with same/different priority\nthen priority of first occurence of store in configuration is used.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadir param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 7, 'created': '2014-01-15 07:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/19091f08ac9d9954aa06ae1f772d4a9dfe68b1f5', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times with same/different priority\nthen priority of first occurence of store in configuration is used.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 8, 'created': '2014-01-17 11:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7acc717e5d397c36f9a2c138899cdda0ebe4b2a3', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times then BadStoreConfiguration\nexception will be raised.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 9, 'created': '2014-01-20 09:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ef6888bc19eca707cd51dcef898f74bac197616e', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times then BadStoreConfiguration\nexception will be raised.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 10, 'created': '2014-01-21 09:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/33050f319688b20002336b0386fa3730d3237979', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times then BadStoreConfiguration\nexception will be raised.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 11, 'created': '2014-01-22 17:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/54030b03f5cbd91f1c13fd1ed1a739d0550d77e3', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times then BadStoreConfiguration\nexception will be raised.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}, {'number': 12, 'created': '2014-01-22 23:03:46.000000000', 'files': ['glance/tests/unit/test_filesystem_store.py', 'etc/glance-api.conf', 'doc/source/configuring.rst', 'glance/store/filesystem.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/7e2c16104dfd7142213debc7dd59daa750d9e84c', 'message': ""Add multifilesystem store to support NFS servers as backend\n\nCurrently to configure multiple nfs server as a backend\nusing filesystem store, you cannot mount all disks to a single directory.\nFilesystem store allows administrator to configure only single directory with\nfilesystem_store_datadir parameter in the glance-api.conf.\n\nWith multifilesystem store, administrators can configure multiple directories\nto store the glance image with help of filesystem_store_datadirs option.\nEach directory can be coupled with its priority.\n\nFormat for filesystem_store_datadirs in glance-api.conf:\n--------------------------------------------------------\nfilesystem_store_datadirs = </path/to/store>:<priority>\n...\nfilesystem_store_datadirs = </path/to/store>:<priority>\n\nExample:\nfilesystem_store_datadirs = /var/glance/store\nfilesystem_store_datadirs = /var/glance/store1:100\nfilesystem_store_datadirs = /var/glance/store2:200\n\nNote:\n-----\n1. Either filesystem_store_datadir or filesystem_store_datadirs option\nmust be specified in glance-api.conf\n2. Store with priority 200 has precedence over store with priority 100\n3. If no priority is specified, default priority '0' is associated with it.\n4. If two filesystem stores have same priority store with maximum free space\nwill be chosen to store the image.\n5. If same store is specified multiple times then BadStoreConfiguration\nexception will be raised.\n\nblueprint: glance-multifilesystem-store\n\nDocImpact: Multifilesystem support can be used by specifying multiple\ndirectory paths to filesystem_store_datadirs param in glance-api.conf as\ndiscussed above.\n\nChange-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8\n""}]",67,58997,7e2c16104dfd7142213debc7dd59daa750d9e84c,99,9,12,6536,,,0,"Add multifilesystem store to support NFS servers as backend

Currently to configure multiple nfs server as a backend
using filesystem store, you cannot mount all disks to a single directory.
Filesystem store allows administrator to configure only single directory with
filesystem_store_datadir parameter in the glance-api.conf.

With multifilesystem store, administrators can configure multiple directories
to store the glance image with help of filesystem_store_datadirs option.
Each directory can be coupled with its priority.

Format for filesystem_store_datadirs in glance-api.conf:
--------------------------------------------------------
filesystem_store_datadirs = </path/to/store>:<priority>
...
filesystem_store_datadirs = </path/to/store>:<priority>

Example:
filesystem_store_datadirs = /var/glance/store
filesystem_store_datadirs = /var/glance/store1:100
filesystem_store_datadirs = /var/glance/store2:200

Note:
-----
1. Either filesystem_store_datadir or filesystem_store_datadirs option
must be specified in glance-api.conf
2. Store with priority 200 has precedence over store with priority 100
3. If no priority is specified, default priority '0' is associated with it.
4. If two filesystem stores have same priority store with maximum free space
will be chosen to store the image.
5. If same store is specified multiple times then BadStoreConfiguration
exception will be raised.

blueprint: glance-multifilesystem-store

DocImpact: Multifilesystem support can be used by specifying multiple
directory paths to filesystem_store_datadirs param in glance-api.conf as
discussed above.

Change-Id: Ibb04ac14c472cd863c5e285b6dc6a08c69014fe8
",git fetch https://review.opendev.org/openstack/glance refs/changes/97/58997/12 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_filesystem_store.py', 'glance/tests/unit/base.py', 'glance/store/filesystem.py']",3,859cf7ca877aca723943fc686433e543bc288a0e,bp/glance-multifilesystem-store,"from glance.openstack.common import processutils cfg.ListOpt('filesystem_store_datadir', default=[], help=_('List of directories to which the Filesystem backend ' 'store writes images.')), def _create_image_directories(self, directory_paths): """""" Create directories to write image files if it does not exist. :directory_paths is a list of directories belonging to glance store. :raise BadStoreConfiguration exception if creating a directory fails. """""" for datadir in directory_paths: if not os.path.exists(datadir): msg = _(""Directory to write image files does not exist "" ""(%s). Creating."") % datadir LOG.info(msg) try: os.makedirs(datadir) except (IOError, OSError): if os.path.exists(datadir): # NOTE(markwash): If the path now exists, some other # process must have beat us in the race condition. # But it doesn't hurt, so we can safely ignore # the error. continue reason = _(""Unable to create datadir: %s"") % datadir LOG.error(reason) raise exception.BadStoreConfiguration( store_name=""filesystem"", reason=reason) if not CONF.filesystem_store_datadir: directory_paths = set() if len(CONF.filesystem_store_datadir) == 1: self.multiple_datadirs = False self.datadir = CONF.filesystem_store_datadir[0] directory_paths.add(self.datadir) else: self.multiple_datadirs = True self.priority_data_map = {} for datadir in CONF.filesystem_store_datadir: priority = 0 parts = map(lambda x: x.strip(), datadir.split("":"")) datadir_path = parts[0] if len(parts) == 2 and parts[1]: priority = parts[1] if not priority.isdigit(): msg = (_(""Invalid priority value %s in %s "" ""configuration"") % (priority, ""filesystem"")) LOG.warn(msg) raise exception.BadStoreConfiguration( store_name=""filesystem"", reason=msg) if datadir_path: directory_paths.add(datadir_path) self.priority_data_map.setdefault(int(priority), []).append(datadir_path) self.priority_list = sorted(self.priority_data_map, reverse=True) self._create_image_directories(directory_paths) def _get_capacity_info(self, mount_point): """"""Calculate free space on store."""""" #Calculate total space df = processutils.execute(""stat"", ""-f"", ""-c"", ""'%S %b'"", mount_point)[0].strip(""'\n'"") block_size, blocks_total = map(int, df.split()) total_size = block_size * blocks_total #Calculate total allocated space du = processutils.execute(""du"", ""-sb"", ""--apparent-size"", mount_point)[0].strip(""'\n'"") total_allocated = int(du.split('\t')[0]) return max(0, total_size - total_allocated) def _find_best_datadir(self, image_size): """"""Finds best datadir based on free space available. Traverses all glance datadirs based in order of their priority and return datadir that has maximum free space to accomodate an image. Stores with no priority are checked last. :image_size size of image being uploaded. :returns best_datadir as directory path of the best priority datadir. :raises exception.StorageFull if there is no datadir in self.priority_data_map that can accomodate the image. """""" if not self.multiple_datadirs: return self.datadir best_datadir = None max_free_space = 0 for priority in self.priority_list: for datadir in self.priority_data_map.get(priority): free_space = self._get_capacity_info(datadir) if free_space >= image_size and free_space > max_free_space: max_free_space = free_space best_datadir = datadir # If datadir is found which can accomodate image and has maximum # free space for the given priority then break the loop, # else continue to lookup further. if best_datadir: break else: msg = (_(""There is no enough disk space left on the image "" ""storage media. requested=%s"") % image_size) LOG.warn(msg) raise exception.StorageFull(message=msg) return best_datadir datadir = self._find_best_datadir(image_size) filepath = os.path.join(datadir, str(image_id))"," cfg.StrOpt('filesystem_store_datadir', help=_('Directory to which the Filesystem backend ' 'store writes images.')), self.datadir = CONF.filesystem_store_datadir if self.datadir is None: if not os.path.exists(self.datadir): msg = _(""Directory to write image files does not exist "" ""(%s). Creating."") % self.datadir LOG.info(msg) try: os.makedirs(self.datadir) except (IOError, OSError): if os.path.exists(self.datadir): # NOTE(markwash): If the path now exists, some other # process must have beat us in the race condition. But it # doesn't hurt, so we can safely ignore the error. return reason = _(""Unable to create datadir: %s"") % self.datadir LOG.error(reason) raise exception.BadStoreConfiguration(store_name=""filesystem"", reason=reason) filepath = os.path.join(self.datadir, str(image_id))",216,24
openstack%2Fceilometer~master~I98024ccae41d1d17fcaa4eb80f54dac3485a3948,openstack/ceilometer,master,I98024ccae41d1d17fcaa4eb80f54dac3485a3948,Update oslo config generator,ABANDONED,2014-01-30 23:12:05.000000000,2014-01-31 09:40:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-01-30 23:12:05.000000000', 'files': ['ceilometer/openstack/common/config/generator.py', 'tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/88242dd4848bf1f8aea61db0d5b11b05eb0bfa13', 'message': 'Update oslo config generator\n\nThis patch update oslo config generator to latest commit\n\n b3e5166e3f47148856d898c4653b0c089c2315f5\n\nNeeded by blueprint switch-to-oslo.messaging\n\nChange-Id: I98024ccae41d1d17fcaa4eb80f54dac3485a3948\n'}]",0,70253,88242dd4848bf1f8aea61db0d5b11b05eb0bfa13,3,2,1,2813,,,0,"Update oslo config generator

This patch update oslo config generator to latest commit

 b3e5166e3f47148856d898c4653b0c089c2315f5

Needed by blueprint switch-to-oslo.messaging

Change-Id: I98024ccae41d1d17fcaa4eb80f54dac3485a3948
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/53/70253/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/config/generator.py', 'tools/config/generate_sample.sh']",2,88242dd4848bf1f8aea61db0d5b11b05eb0bfa13,bp/switch-to-oslo.messaging,"PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:l:o: \ --long help,base-dir:,package-name:,output-dir:,library: -- ""$@"") echo ""-l, --library=LIB extra library that registers options for discovery"" -l|--library) shift LIBRARIES=""$LIBRARIES -l $1"" shift ;;RC_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$RC_FILE"" source ""$RC_FILE""python -m $MODULEPATH $LIBRARIES $FILES > $OUTPUTFILE","PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:o: \ --long help,base-dir:,package-name:,output-dir: -- ""$@"")EXTRA_MODULES_FILE=""`dirname $0`/oslo.config.generator.rc"" if test -r ""$EXTRA_MODULES_FILE"" source ""$EXTRA_MODULES_FILE""python -m $MODULEPATH $FILES > $OUTPUTFILE",40,8
openstack%2Fpython-swiftclient~master~I226d9046d25d681beea60d38b029b71f9e6bf86c,openstack/python-swiftclient,master,I226d9046d25d681beea60d38b029b71f9e6bf86c,"assertEquals is deprecated, use assertEqual",MERGED,2014-01-17 10:31:09.000000000,2014-01-31 09:13:47.000000000,2014-01-31 09:13:46.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-17 10:31:09.000000000', 'files': ['tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/eac3c7292461caed7bae7d77fa00632ee3e90528', 'message': 'assertEquals is deprecated, use assertEqual\n\nChange-Id: I226d9046d25d681beea60d38b029b71f9e6bf86c\n'}]",0,67419,eac3c7292461caed7bae7d77fa00632ee3e90528,7,4,1,6593,,,0,"assertEquals is deprecated, use assertEqual

Change-Id: I226d9046d25d681beea60d38b029b71f9e6bf86c
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/19/67419/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_utils.py'],1,eac3c7292461caed7bae7d77fa00632ee3e90528,hacking," self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEqual('42Y', u.prt_bytes(bytes_, True).lstrip()) self.assertEqual('1024Y', u.prt_bytes(bytes_, True).lstrip()) self.assertEqual(proxy_dict['http'], 'http://proxy.tests.com:8080') self.assertEqual(proxy_dict.get('https'), None) self.assertEqual(len(proxy_dict), 1) self.assertEqual(proxy_dict['http'], 'http://proxy.tests.com:8080') self.assertEqual(proxy_dict.get('https'), None) self.assertEqual(len(proxy_dict), 1) self.assertEqual(proxy_dict['https'], 'http://proxy.tests.com:8080') self.assertEqual(proxy_dict.get('http'), None) self.assertEqual(len(proxy_dict), 1) self.assertEqual(proxy_dict['https'], 'http://proxy.tests.com:8080') self.assertEqual(proxy_dict.get('http'), None) self.assertEqual(len(proxy_dict), 1) self.assertEqual(proxy_dict['http'], 'http://proxy1.tests.com:8081') self.assertEqual(proxy_dict['https'], 'http://proxy2.tests.com:8082') self.assertEqual(len(proxy_dict), 2) self.assertEqual(proxy_dict['http'], 'http://proxy1.tests.com:8081') self.assertEqual(proxy_dict['https'], 'http://proxy2.tests.com:8082') self.assertEqual(len(proxy_dict), 2) self.assertEqual(len(proxy_dict), 0) self.assertEqual(len(proxy_dict), 0)"," self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(raw, u.prt_bytes(bytes_, False).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(human, u.prt_bytes(bytes_, True).lstrip()) self.assertEquals('42Y', u.prt_bytes(bytes_, True).lstrip()) self.assertEquals('1024Y', u.prt_bytes(bytes_, True).lstrip()) self.assertEquals(proxy_dict['http'], 'http://proxy.tests.com:8080') self.assertEquals(proxy_dict.get('https'), None) self.assertEquals(len(proxy_dict), 1) self.assertEquals(proxy_dict['http'], 'http://proxy.tests.com:8080') self.assertEquals(proxy_dict.get('https'), None) self.assertEquals(len(proxy_dict), 1) self.assertEquals(proxy_dict['https'], 'http://proxy.tests.com:8080') self.assertEquals(proxy_dict.get('http'), None) self.assertEquals(len(proxy_dict), 1) self.assertEquals(proxy_dict['https'], 'http://proxy.tests.com:8080') self.assertEquals(proxy_dict.get('http'), None) self.assertEquals(len(proxy_dict), 1) self.assertEquals(proxy_dict['http'], 'http://proxy1.tests.com:8081') self.assertEquals(proxy_dict['https'], 'http://proxy2.tests.com:8082') self.assertEquals(len(proxy_dict), 2) self.assertEquals(proxy_dict['http'], 'http://proxy1.tests.com:8081') self.assertEquals(proxy_dict['https'], 'http://proxy2.tests.com:8082') self.assertEquals(len(proxy_dict), 2) self.assertEquals(len(proxy_dict), 0) self.assertEquals(len(proxy_dict), 0)",41,41
openstack%2Fpython-swiftclient~master~Icebd5bed50a50930bde0305191e32628d93348c0,openstack/python-swiftclient,master,Icebd5bed50a50930bde0305191e32628d93348c0,Updated from global requirements,MERGED,2013-12-23 11:03:19.000000000,2014-01-31 09:10:24.000000000,2014-01-31 09:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}]","[{'number': 1, 'created': '2013-12-23 11:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/dffdfce5806e80d73791d01a23da8a9a2478a57f', 'message': 'Updated from global requirements\n\nChange-Id: Icebd5bed50a50930bde0305191e32628d93348c0\n'}, {'number': 2, 'created': '2014-01-24 22:41:08.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b9b8b8b42395561b7ea8c44888da48ff3fda8f5c', 'message': 'Updated from global requirements\n\nChange-Id: Icebd5bed50a50930bde0305191e32628d93348c0\n'}]",0,63714,b9b8b8b42395561b7ea8c44888da48ff3fda8f5c,7,3,2,3,,,0,"Updated from global requirements

Change-Id: Icebd5bed50a50930bde0305191e32628d93348c0
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/14/63714/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,dffdfce5806e80d73791d01a23da8a9a2478a57f,openstack/requirements,"hacking>=0.8.0,<0.9python-keystoneclient>=0.4.1","hacking>=0.5.6,<0.8python-keystoneclient>=0.3.2",2,2
openstack%2Fpython-swiftclient~master~Ie34b454511d5527e402e66e1fdb72120f427f2fd,openstack/python-swiftclient,master,Ie34b454511d5527e402e66e1fdb72120f427f2fd,Add capabilities option,MERGED,2014-01-13 21:43:06.000000000,2014-01-31 08:55:27.000000000,2014-01-31 08:55:27.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 2622}, {'_account_id': 6889}, {'_account_id': 6968}, {'_account_id': 7020}, {'_account_id': 7244}]","[{'number': 1, 'created': '2014-01-13 21:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/017239e3358e5121bd95cf21f15494337b2f02b0', 'message': 'Add capabilities option\n\nThis patch is an attempt to add an capabilities option\non swiftclient. This option uses the new /info endpoint to\nrequest the remote capabilities and display it.\n\nChange-Id: Ie34b454511d5527e402e66e1fdb72120f427f2fd\n'}, {'number': 2, 'created': '2014-01-15 13:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b1285bd6265042cbfb4b96bdbd8fbac53b70bf6b', 'message': 'Add capabilities option\n\nThis patch adds a capabilities option on swiftclient.\nThis option uses the new /info endpoint to request the\nremote capabilities and nicely display it.\n\nChange-Id: Ie34b454511d5527e402e66e1fdb72120f427f2fd\n'}, {'number': 3, 'created': '2014-01-16 15:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/4d48ac526f05af47d47de5a1a00425f243e5109c', 'message': 'Add capabilities option\n\nThis patch adds a capabilities option on swiftclient.\nThis option uses the new /info endpoint to request the\nremote capabilities and nicely display it.\n\nChange-Id: Ie34b454511d5527e402e66e1fdb72120f427f2fd\n'}, {'number': 4, 'created': '2014-01-17 09:26:51.000000000', 'files': ['bin/swift', 'tests/test_swiftclient.py', 'swiftclient/client.py', 'doc/manpages/swift.1'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/533c9c5ba14581ac06b31f82531f9c749d489868', 'message': 'Add capabilities option\n\nThis patch adds a capabilities option on swiftclient.\nThis option uses the new /info endpoint to request the\nremote capabilities and nicely display it.\n\nChange-Id: Ie34b454511d5527e402e66e1fdb72120f427f2fd\n'}]",9,66442,533c9c5ba14581ac06b31f82531f9c749d489868,18,8,4,6889,,,0,"Add capabilities option

This patch adds a capabilities option on swiftclient.
This option uses the new /info endpoint to request the
remote capabilities and nicely display it.

Change-Id: Ie34b454511d5527e402e66e1fdb72120f427f2fd
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/42/66442/4 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift', 'swiftclient/client.py']",2,017239e3358e5121bd95cf21f15494337b2f02b0,get_info,"def get_capabilities(http_conn): """""" Get cluster infos. :param http_conn: HTTP connection :returns: a dict containing the cluster capabilities :raises ClientException: HTTP Capabilities GET failed """""" parsed, conn = http_conn conn.request('GET', parsed.path, '') resp = conn.getresponse() body = resp.read() http_log((parsed.geturl(), 'GET',), {'headers': {}}, resp, body) if resp.status < 200 or resp.status >= 300: raise ClientException('Capabilities GET failed', http_scheme=parsed.scheme, http_host=conn.host, http_port=conn.port, http_path=parsed.path, http_status=resp.status, http_reason=resp.reason, http_response_content=body) return json_loads(body) def get_capabilities(self, url=None): if not url: url, _ = self.get_auth() scheme = urlparse(url).scheme netloc = urlparse(url).netloc url = scheme + '://' + netloc + '/info' http_conn = http_connection(url, ssl_compression=self.ssl_compression) return get_capabilities(http_conn)",,73,1
openstack%2Fheat~master~I1a943876d805dce731771b18a39d0c78f617264a,openstack/heat,master,I1a943876d805dce731771b18a39d0c78f617264a,serialize non-string nova metadata,MERGED,2014-01-30 03:11:38.000000000,2014-01-31 08:52:11.000000000,2014-01-31 08:52:10.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7253}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-01-30 03:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c1d26009d8604689acc41ac879f66a81168f9a5d', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 2, 'created': '2014-01-30 04:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf2695106f4a23ad71b560f623177e4c1c9ded9d', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 3, 'created': '2014-01-30 16:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a946cbc53a6427ba174984b9defeef17ae0c6429', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 4, 'created': '2014-01-30 16:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/032e1dca92a316febbe24f7c9ef6566a7665acc7', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 5, 'created': '2014-01-30 18:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/91f5cecb8ab142fac598685587461c2820ce3e4e', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 6, 'created': '2014-01-30 20:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b39898a47acaee787d856a22aac295939c2249f7', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}, {'number': 7, 'created': '2014-01-30 21:03:49.000000000', 'files': ['heat/engine/resources/nova_utils.py', 'heat/engine/resources/server.py', 'heat/tests/test_server.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3e3fc3e1ff0ce4edce9f432fe31d2d8e45082681', 'message': 'serialize non-string nova metadata\n\nThis patches ensures that non-string metadata values passed to Nova\nare JSON-encoded. This permits setting metadata to complex values,\nsuch as:\n\n    instance0:\n      type: OS::Nova::Server\n      properties:\n        metadata:\n          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}\n\nChange-Id: I1a943876d805dce731771b18a39d0c78f617264a\nCloses-Bug: 1274155\n'}]",3,70045,3e3fc3e1ff0ce4edce9f432fe31d2d8e45082681,35,6,7,8745,,,0,"serialize non-string nova metadata

This patches ensures that non-string metadata values passed to Nova
are JSON-encoded. This permits setting metadata to complex values,
such as:

    instance0:
      type: OS::Nova::Server
      properties:
        metadata:
          internal_ip: {get_attr: [instance0_eth1, fixed_ips]}

Change-Id: I1a943876d805dce731771b18a39d0c78f617264a
Closes-Bug: 1274155
",git fetch https://review.opendev.org/openstack/heat refs/changes/45/70045/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/nova_utils.py', 'heat/engine/resources/server.py', 'heat/tests/test_server.py']",3,c1d26009d8604689acc41ac879f66a81168f9a5d,bug/1274155,"from heat.engine.resources import nova_utils new_meta = {'test1': 123, 'test2': {'testkey': 'testvalue'}} nova_utils.meta_serialize(new_meta)).AndReturn(None) nova_utils.meta_serialize(new_meta)).AndReturn(None)", new_meta = {'test': 123} new_meta).AndReturn(None) new_meta).AndReturn(None),18,6
openstack%2Fmurano-dashboard~release-0.4~Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2,openstack/murano-dashboard,release-0.4,Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2,Show floating ip in details,MERGED,2014-01-27 12:43:22.000000000,2014-01-31 08:42:56.000000000,2014-01-31 08:42:56.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-01-27 12:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d21b552d8116701dae9e1c6c075383fa2c0758b7', 'message': 'Show floating ip in details\n\nblueprint auto-assign-floating-ip\n\nChange-Id: Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2\n'}, {'number': 2, 'created': '2014-01-30 12:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b3bc336d762f6962bf1d005e7f56ad4c8bc77a34', 'message': 'Show floating ip in details\n\nblueprint auto-assign-floating-ip\n\nChange-Id: Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2\n'}, {'number': 3, 'created': '2014-01-30 12:41:43.000000000', 'files': ['muranodashboard/environments/tabs.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a161d05c53893f2f9246ed292a276285703238a4', 'message': 'Show floating ip in details\n\nblueprint auto-assign-floating-ip\n\nChange-Id: Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2\n'}]",0,69349,a161d05c53893f2f9246ed292a276285703238a4,11,6,3,7549,,,0,"Show floating ip in details

blueprint auto-assign-floating-ip

Change-Id: Ic4b13259777d36933e4297fdd3f57a1e8ea06bc2
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/49/69349/3 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/environments/tabs.py'],1,d21b552d8116701dae9e1c6c075383fa2c0758b7,bp/auto-assign-floating-ip," if hasattr(service_data, 'floating-ip'): detail_info['floating-ip'] = service_data.floating-ip ",,3,0
openstack%2Fpuppet-nova~master~I8bc20a7d0d1ed002203852c48ab380dc0679ced4,openstack/puppet-nova,master,I8bc20a7d0d1ed002203852c48ab380dc0679ced4,Cleanup rspec tests of nova,MERGED,2014-01-30 22:58:19.000000000,2014-01-31 08:35:10.000000000,2014-01-31 08:35:10.000000000,"[{'_account_id': 3}, {'_account_id': 2265}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-01-30 22:58:19.000000000', 'files': ['spec/classes/nova_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f93e33c0ea062d5419f1edf863f923f2bc507cf0', 'message': 'Cleanup rspec tests of nova\n\nChange-Id: I8bc20a7d0d1ed002203852c48ab380dc0679ced4\n'}]",0,70241,f93e33c0ea062d5419f1edf863f923f2bc507cf0,7,3,1,7156,,,0,"Cleanup rspec tests of nova

Change-Id: I8bc20a7d0d1ed002203852c48ab380dc0679ced4
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/41/70241/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/nova_init_spec.rb'],1,f93e33c0ea062d5419f1edf863f923f2bc507cf0,cleanup_rspec," shared_examples 'nova' do context 'with default parameters' do it 'installs packages' do should contain_package('python').with_ensure('present') should contain_package('python-greenlet').with( :ensure => 'present', :require => 'Package[python]' ) should contain_package('python-nova').with( :ensure => 'present', :require => 'Package[python-greenlet]' ) should contain_package('nova-common').with( :name => platform_params[:nova_common_package], :ensure => 'present' ) end it 'creates user and group' do should contain_group('nova').with( :ensure => 'present', :system => true, :require => 'Package[nova-common]' ) should contain_user('nova').with( :ensure => 'present', :gid => 'nova', :system => true, :require => 'Package[nova-common]' ) end it 'creates various files and folders' do should contain_file('/var/log/nova').with( :ensure => 'directory', :mode => '0750', :owner => 'nova', :group => 'nova', :require => 'Package[nova-common]' ) should contain_file('/etc/nova/nova.conf').with( :mode => '0640', :owner => 'nova', :group => 'nova', :require => 'Package[nova-common]' ) end it 'configures rootwrap' do should contain_nova_config('DEFAULT/rootwrap_config').with_value('/etc/nova/rootwrap.conf') end it { should contain_exec('networking-refresh').with( :command => '/sbin/ifdown -a ; /sbin/ifup -a', :refreshonly => true )} it 'configures database' do should_not contain_nova_config('database/connection') should_not contain_nova_config('database/idle_timeout').with_value('3600') end it 'configures image service' do should contain_nova_config('DEFAULT/image_service').with_value('nova.image.glance.GlanceImageService') should contain_nova_config('DEFAULT/glance_api_servers').with_value('localhost:9292') end it 'configures auth_strategy' do should contain_nova_config('DEFAULT/auth_strategy').with_value('keystone') should_not contain_nova_config('DEFAULT/use_deprecated_auth').with_value(false) end it 'configures rabbit' do should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_kombu') should contain_nova_config('DEFAULT/rabbit_host').with_value('localhost') should contain_nova_config('DEFAULT/rabbit_password').with_value('guest').with_secret(true) should contain_nova_config('DEFAULT/rabbit_port').with_value('5672') should contain_nova_config('DEFAULT/rabbit_userid').with_value('guest') should contain_nova_config('DEFAULT/rabbit_virtual_host').with_value('/') end it 'configures various things' do should contain_nova_config('DEFAULT/verbose').with_value(false) should contain_nova_config('DEFAULT/debug').with_value(false) should contain_nova_config('DEFAULT/logdir').with_value('/var/log/nova') should contain_nova_config('DEFAULT/state_path').with_value('/var/lib/nova') should contain_nova_config('DEFAULT/lock_path').with_value(platform_params[:lock_path]) should contain_nova_config('DEFAULT/service_down_time').with_value('60') should contain_nova_config('DEFAULT/rootwrap_config').with_value('/etc/nova/rootwrap.conf') should_not contain_nova_config('DEFAULT/notification_driver') end it 'disables syslog' do should contain_nova_config('DEFAULT/use_syslog').with_value(false) end end context 'with overridden parameters' do let :params do { :database_connection => 'mysql://user:pass@db/db', :database_idle_timeout => '30', :verbose => true, :debug => true, :logdir => '/var/log/nova2', :image_service => 'nova.image.local.LocalImageService', :rabbit_host => 'rabbit', :rabbit_userid => 'rabbit_user', :rabbit_port => '5673', :rabbit_password => 'password', :lock_path => '/var/locky/path', :state_path => '/var/lib/nova2', :service_down_time => '120', :auth_strategy => 'foo', :ensure_package => '2012.1.1-15.el6', :monitoring_notifications => true, :memcached_servers => ['memcached01:11211', 'memcached02:11211'] } end it 'installs packages' do should contain_package('nova-common').with('ensure' => '2012.1.1-15.el6') should contain_package('python-nova').with('ensure' => '2012.1.1-15.el6') end it 'configures database' do should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db').with_secret(true) should contain_nova_config('database/idle_timeout').with_value('30') end it 'configures image service' do should contain_nova_config('DEFAULT/image_service').with_value('nova.image.local.LocalImageService') should_not contain_nova_config('DEFAULT/glance_api_servers') end it 'configures auth_strategy' do should contain_nova_config('DEFAULT/auth_strategy').with_value('foo') should_not contain_nova_config('DEFAULT/use_deprecated_auth').with_value(true) end it 'configures rabbit' do should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_kombu') should contain_nova_config('DEFAULT/rabbit_host').with_value('rabbit') should contain_nova_config('DEFAULT/rabbit_password').with_value('password').with_secret(true) should contain_nova_config('DEFAULT/rabbit_port').with_value('5673') should contain_nova_config('DEFAULT/rabbit_userid').with_value('rabbit_user') should contain_nova_config('DEFAULT/rabbit_virtual_host').with_value('/') end it 'configures memcached_servers' do should contain_nova_config('DEFAULT/memcached_servers').with_value('memcached01:11211,memcached02:11211') end it 'configures various things' do should contain_nova_config('DEFAULT/verbose').with_value(true) should contain_nova_config('DEFAULT/debug').with_value(true) should contain_nova_config('DEFAULT/logdir').with_value('/var/log/nova2') should contain_nova_config('DEFAULT/state_path').with_value('/var/lib/nova2') should contain_nova_config('DEFAULT/lock_path').with_value('/var/locky/path') should contain_nova_config('DEFAULT/service_down_time').with_value('120') should contain_nova_config('DEFAULT/notification_driver').with_value('nova.openstack.common.notifier.rpc_notifier') end end context 'with deprecated sql parameters' do let :params do { :sql_connection => 'mysql://user:pass@db/db', :sql_idle_timeout => '30' } end it 'configures database' do should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db').with_secret(true) should contain_nova_config('database/idle_timeout').with_value('30') end end context 'with syslog enabled' do let :params do { :use_syslog => 'true' } end it 'configures syslog' do should contain_nova_config('DEFAULT/use_syslog').with_value(true) should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') end end context 'with syslog enabled and log_facility parameter' do let :params do { :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' } end it 'configures syslog' do should contain_nova_config('DEFAULT/use_syslog').with_value(true) should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') end end context 'with rabbit_hosts parameter' do let :params do { :rabbit_hosts => ['rabbit:5673', 'rabbit2:5674'] } end it 'configures rabbit' do should_not contain_nova_config('DEFAULT/rabbit_host') should_not contain_nova_config('DEFAULT/rabbit_port') should contain_nova_config('DEFAULT/rabbit_hosts').with_value('rabbit:5673,rabbit2:5674') should contain_nova_config('DEFAULT/rabbit_ha_queues').with_value(true) end end context 'with rabbit_hosts parameter (one server)' do let :params do { :rabbit_hosts => ['rabbit:5673'] } end it 'configures rabbit' do should_not contain_nova_config('DEFAULT/rabbit_host') should_not contain_nova_config('DEFAULT/rabbit_port') should contain_nova_config('DEFAULT/rabbit_hosts').with_value('rabbit:5673') should contain_nova_config('DEFAULT/rabbit_ha_queues').with_value(true) end end context 'with qpid rpc_backend' do let :params do { :rpc_backend => 'nova.openstack.common.rpc.impl_qpid' } end context 'with default parameters' do it 'configures qpid' do should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_qpid') should contain_nova_config('DEFAULT/qpid_hostname').with_value('localhost') should contain_nova_config('DEFAULT/qpid_port').with_value('5672') should contain_nova_config('DEFAULT/qpid_username').with_value('guest') should contain_nova_config('DEFAULT/qpid_password').with_value('guest').with_secret(true) should contain_nova_config('DEFAULT/qpid_heartbeat').with_value('60') should contain_nova_config('DEFAULT/qpid_protocol').with_value('tcp') should contain_nova_config('DEFAULT/qpid_tcp_nodelay').with_value(true) end end context 'with qpid_password parameter (without qpid_sasl_mechanisms)' do before do params.merge!({ :qpid_password => 'guest' }) end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_ensure('absent') } end context 'with qpid_password parameter (with qpid_sasl_mechanisms)' do before do params.merge!({ :qpid_password => 'guest', :qpid_sasl_mechanisms => 'A' }) end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_value('A') } end context 'with qpid_password parameter (with array of qpid_sasl_mechanisms)' do before do params.merge!({ :qpid_password => 'guest', :qpid_sasl_mechanisms => [ 'DIGEST-MD5', 'GSSAPI', 'PLAIN' ] }) end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_value('DIGEST-MD5 GSSAPI PLAIN') } end end context 'on Debian platforms' do let :facts do { :osfamily => 'Debian' } let :platform_params do { :nova_common_package => 'nova-common', :lock_path => '/var/lock/nova' } it_behaves_like 'nova' end context 'on RedHat platforms' do let :facts do { :osfamily => 'RedHat' } let :platform_params do { :nova_common_package => 'openstack-nova-common', :lock_path => '/var/lib/nova/tmp' } it_behaves_like 'nova'"," let :facts do { :osfamily => 'Debian' } describe 'with default parameters' do it { should contain_package('python').with_ensure('present') } it { should contain_package('python-greenlet').with( 'ensure' => 'present', 'require' => 'Package[python]' )} it { should contain_package('python-nova').with( 'ensure' => 'present', 'require' => 'Package[python-greenlet]' )} it { should contain_package('nova-common').with( 'name' => 'nova-common', 'ensure' => 'present' )} it { should contain_group('nova').with( 'ensure' => 'present', 'system' => true, 'require' => 'Package[nova-common]' )} it { should contain_user('nova').with( 'ensure' => 'present', 'gid' => 'nova', 'system' => true, 'require' => 'Package[nova-common]' ) } it { should contain_file('/var/log/nova').with( 'ensure' => 'directory', 'mode' => '0750', 'owner' => 'nova', 'group' => 'nova', 'require' => 'Package[nova-common]' )} it { should contain_file('/etc/nova/nova.conf').with( 'mode' => '0640', 'owner' => 'nova', 'group' => 'nova', 'require' => 'Package[nova-common]' )} it { should contain_exec('networking-refresh').with( 'command' => '/sbin/ifdown -a ; /sbin/ifup -a', 'refreshonly' => true )} it { should_not contain_nova_config('database/connection') } it { should_not contain_nova_config('database/idle_timeout').with_value('3600') } it { should contain_nova_config('DEFAULT/image_service').with_value('nova.image.glance.GlanceImageService') } it { should contain_nova_config('DEFAULT/glance_api_servers').with_value('localhost:9292') } it { should contain_nova_config('DEFAULT/auth_strategy').with_value('keystone') } it { should_not contain_nova_config('DEFAULT/use_deprecated_auth').with_value(false) } it { should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_kombu') } it { should contain_nova_config('DEFAULT/rabbit_host').with_value('localhost') } it { should contain_nova_config('DEFAULT/rabbit_password').with_value('guest').with_secret(true) } it { should contain_nova_config('DEFAULT/rabbit_port').with_value('5672') } it { should contain_nova_config('DEFAULT/rabbit_userid').with_value('guest') } it { should contain_nova_config('DEFAULT/rabbit_virtual_host').with_value('/') } it { should contain_nova_config('DEFAULT/verbose').with_value(false) } it { should contain_nova_config('DEFAULT/debug').with_value(false) } it { should contain_nova_config('DEFAULT/logdir').with_value('/var/log/nova') } it { should contain_nova_config('DEFAULT/state_path').with_value('/var/lib/nova') } it { should contain_nova_config('DEFAULT/lock_path').with_value('/var/lock/nova') } it { should contain_nova_config('DEFAULT/service_down_time').with_value('60') } it { should contain_nova_config('DEFAULT/rootwrap_config').with_value('/etc/nova/rootwrap.conf') } it { should_not contain_nova_config('DEFAULT/notification_driver') } describe 'with parameters supplied' do let :params do { 'database_connection' => 'mysql://user:pass@db/db', 'database_idle_timeout' => '30', 'verbose' => true, 'debug' => true, 'logdir' => '/var/log/nova2', 'image_service' => 'nova.image.local.LocalImageService', 'rabbit_host' => 'rabbit', 'rabbit_userid' => 'rabbit_user', 'rabbit_port' => '5673', 'rabbit_password' => 'password', 'lock_path' => '/var/locky/path', 'state_path' => '/var/lib/nova2', 'service_down_time' => '120', 'auth_strategy' => 'foo', 'ensure_package' => '2012.1.1-15.el6', 'monitoring_notifications' => true } end it { should contain_package('nova-common').with('ensure' => '2012.1.1-15.el6') } it { should contain_package('python-nova').with('ensure' => '2012.1.1-15.el6') } it { should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db').with_secret(true) } it { should contain_nova_config('database/idle_timeout').with_value('30') } it { should contain_nova_config('DEFAULT/image_service').with_value('nova.image.local.LocalImageService') } it { should_not contain_nova_config('DEFAULT/glance_api_servers') } it { should contain_nova_config('DEFAULT/auth_strategy').with_value('foo') } it { should_not contain_nova_config('DEFAULT/use_deprecated_auth').with_value(true) } it { should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_kombu') } it { should contain_nova_config('DEFAULT/rabbit_host').with_value('rabbit') } it { should contain_nova_config('DEFAULT/rabbit_password').with_value('password').with_secret(true) } it { should contain_nova_config('DEFAULT/rabbit_port').with_value('5673') } it { should contain_nova_config('DEFAULT/rabbit_userid').with_value('rabbit_user') } it { should contain_nova_config('DEFAULT/rabbit_virtual_host').with_value('/') } it { should contain_nova_config('DEFAULT/verbose').with_value(true) } it { should contain_nova_config('DEFAULT/debug').with_value(true) } it { should contain_nova_config('DEFAULT/logdir').with_value('/var/log/nova2') } it { should contain_nova_config('DEFAULT/state_path').with_value('/var/lib/nova2') } it { should contain_nova_config('DEFAULT/lock_path').with_value('/var/locky/path') } it { should contain_nova_config('DEFAULT/service_down_time').with_value('120') } it { should contain_nova_config('DEFAULT/notification_driver').with_value('nova.openstack.common.notifier.rpc_notifier') } describe 'with deprecated sql parameters' do let :params do { 'sql_connection' => 'mysql://user:pass@db/db', 'sql_idle_timeout' => '30' } end it { should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db').with_secret(true) } it { should contain_nova_config('database/idle_timeout').with_value('30') } describe 'with some others parameters supplied' do let :params do { 'rabbit_hosts' => ['rabbit:5673', 'rabbit2:5674'], } end it { should_not contain_nova_config('DEFAULT/rabbit_host') } it { should_not contain_nova_config('DEFAULT/rabbit_port') } it { should contain_nova_config('DEFAULT/rabbit_hosts').with_value('rabbit:5673,rabbit2:5674') } it { should contain_nova_config('DEFAULT/rabbit_ha_queues').with_value(true) } describe 'with one rabbit_hosts supplied' do let :params do { 'rabbit_hosts' => ['rabbit:5673'], } end it { should_not contain_nova_config('DEFAULT/rabbit_host') } it { should_not contain_nova_config('DEFAULT/rabbit_port') } it { should contain_nova_config('DEFAULT/rabbit_hosts').with_value('rabbit:5673') } it { should contain_nova_config('DEFAULT/rabbit_ha_queues').with_value(true) } describe 'with memcached parameter supplied' do let :params do { 'memcached_servers' => ['memcached01:11211', 'memcached02:11211'], } end it { should contain_nova_config('DEFAULT/memcached_servers').with_value('memcached01:11211,memcached02:11211') } end describe 'with qpid rpc supplied' do let :params do { 'database_connection' => 'mysql://user:pass@db/db', 'database_idle_timeout' => '30', 'verbose' => true, 'debug' => true, 'logdir' => '/var/log/nova2', 'image_service' => 'nova.image.local.LocalImageService', 'rpc_backend' => 'nova.openstack.common.rpc.impl_qpid', 'lock_path' => '/var/locky/path', 'state_path' => '/var/lib/nova2', 'service_down_time' => '120', 'auth_strategy' => 'foo', 'ensure_package' => '2012.1.1-15.el6' } end it { should contain_package('nova-common').with('ensure' => '2012.1.1-15.el6') } it { should contain_package('python-nova').with('ensure' => '2012.1.1-15.el6') } it { should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db') } it { should contain_nova_config('database/idle_timeout').with_value('30') } it { should contain_nova_config('DEFAULT/image_service').with_value('nova.image.local.LocalImageService') } it { should_not contain_nova_config('DEFAULT/glance_api_servers') } it { should contain_nova_config('DEFAULT/auth_strategy').with_value('foo') } it { should_not contain_nova_config('DEFAULT/use_deprecated_auth').with_value(true) } it { should contain_nova_config('DEFAULT/rpc_backend').with_value('nova.openstack.common.rpc.impl_qpid') } it { should contain_nova_config('DEFAULT/qpid_hostname').with_value('localhost') } it { should contain_nova_config('DEFAULT/qpid_port').with_value('5672') } it { should contain_nova_config('DEFAULT/qpid_username').with_value('guest') } it { should contain_nova_config('DEFAULT/qpid_password').with_value('guest').with_secret(true) } it { should contain_nova_config('DEFAULT/qpid_heartbeat').with_value('60') } it { should contain_nova_config('DEFAULT/qpid_protocol').with_value('tcp') } it { should contain_nova_config('DEFAULT/qpid_tcp_nodelay').with_value(true) } it { should contain_nova_config('DEFAULT/verbose').with_value(true) } it { should contain_nova_config('DEFAULT/debug').with_value(true) } it { should contain_nova_config('DEFAULT/logdir').with_value('/var/log/nova2') } it { should contain_nova_config('DEFAULT/state_path').with_value('/var/lib/nova2') } it { should contain_nova_config('DEFAULT/lock_path').with_value('/var/locky/path') } it { should contain_nova_config('DEFAULT/service_down_time').with_value('120') } end describe 'with qpid rpc and no qpid_sasl_mechanisms' do let :params do { :sql_connection => 'mysql://user:password@host/database', :qpid_password => 'guest', :rpc_backend => 'nova.openstack.common.rpc.impl_qpid' } end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_ensure('absent') } end describe 'with qpid rpc and qpid_sasl_mechanisms string' do let :params do { :sql_connection => 'mysql://user:password@host/database', :qpid_password => 'guest', :qpid_sasl_mechanisms => 'A', 'rpc_backend' => 'nova.openstack.common.rpc.impl_qpid', } end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_value('A') } end describe 'with qpid rpc and qpid_sasl_mechanisms array' do let :params do { :sql_connection => 'mysql://user:password@host/database', :qpid_password => 'guest', :qpid_sasl_mechanisms => [ 'DIGEST-MD5', 'GSSAPI', 'PLAIN' ], 'rpc_backend' => 'nova.openstack.common.rpc.impl_qpid', } end it { should contain_nova_config('DEFAULT/qpid_sasl_mechanisms').with_value('DIGEST-MD5 GSSAPI PLAIN') } end describe ""When platform is RedHat"" do let :facts do {:osfamily => 'RedHat'} end it { should contain_package('nova-common').with( 'name' => 'openstack-nova-common', 'ensure' => 'present' )} it { should contain_nova_config('DEFAULT/rootwrap_config').with_value('/etc/nova/rootwrap.conf') } end describe 'with syslog disabled' do it { should contain_nova_config('DEFAULT/use_syslog').with_value(false) } end describe 'with syslog enabled' do let :params do { :use_syslog => 'true', } end it { should contain_nova_config('DEFAULT/use_syslog').with_value(true) } it { should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') } end describe 'with syslog enabled and custom settings' do let :params do { :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' } end it { should contain_nova_config('DEFAULT/use_syslog').with_value(true) } it { should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') } end ",286,296
openstack%2Ftempest~master~I4c05ba16c524b844f3cf43cfe0969ddd20238486,openstack/tempest,master,I4c05ba16c524b844f3cf43cfe0969ddd20238486,stop leaking tempdirs,MERGED,2014-01-30 12:07:48.000000000,2014-01-31 07:35:39.000000000,2014-01-31 07:35:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2014-01-30 12:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b5e22c4c670154415da8d55a8d823df7d0df2df5', 'message': 'stop leaking tempdirs\n\ntest_wrappers built temp dirs for running tests, but never\ncleaned them up. So your /tmp is very full of tempest code now.\n\nFix this with an add cleanup\n\nChange-Id: I4c05ba16c524b844f3cf43cfe0969ddd20238486\n'}, {'number': 2, 'created': '2014-01-30 12:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/caeac29834c64928036aa878a1fa7076a3390609', 'message': 'stop leaking tempdirs\n\ntest_wrappers built temp dirs for running tests, but never\ncleaned them up. So your /tmp is very full of tempest code now.\n\nFix this with an add cleanup\n\nChange-Id: I4c05ba16c524b844f3cf43cfe0969ddd20238486\n'}, {'number': 3, 'created': '2014-01-30 21:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab57f5526e038ed2f06f07149c28210b9778276b', 'message': 'stop leaking tempdirs\n\ntest_wrappers built temp dirs for running tests, but never\ncleaned them up. So your /tmp is very full of tempest code now.\n\nFix this with an add cleanup\n\nChange-Id: I4c05ba16c524b844f3cf43cfe0969ddd20238486\n'}, {'number': 4, 'created': '2014-01-30 21:09:00.000000000', 'files': ['tempest/tests/test_wrappers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/86d3c42ad39232ba73a4d46d101f283539bf8bd9', 'message': 'stop leaking tempdirs\n\ntest_wrappers built temp dirs for running tests, but never\ncleaned them up. So your /tmp is very full of tempest code now.\n\nFix this with an add cleanup\n\nChange-Id: I4c05ba16c524b844f3cf43cfe0969ddd20238486\n'}]",3,70099,86d3c42ad39232ba73a4d46d101f283539bf8bd9,13,6,4,2750,,,0,"stop leaking tempdirs

test_wrappers built temp dirs for running tests, but never
cleaned them up. So your /tmp is very full of tempest code now.

Fix this with an add cleanup

Change-Id: I4c05ba16c524b844f3cf43cfe0969ddd20238486
",git fetch https://review.opendev.org/openstack/tempest refs/changes/99/70099/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/test_wrappers.py'],1,b5e22c4c670154415da8d55a8d823df7d0df2df5,test_filter," self.addCleanup(shutil.rmtree, self.test_dir)",,1,0
openstack%2Fcookbook-openstack-compute~master~I24a11e6f54946d0475a71f489dd7c2631e0736ed,openstack/cookbook-openstack-compute,master,I24a11e6f54946d0475a71f489dd7c2631e0736ed,Remove ambiguity in stubbed methods in spec_helper,MERGED,2014-01-30 10:59:26.000000000,2014-01-31 06:32:28.000000000,2014-01-31 06:32:28.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 425}, {'_account_id': 6714}]","[{'number': 1, 'created': '2014-01-30 10:59:26.000000000', 'files': ['spec/spec_helper.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/74080b4dc132e8664cd874b7d4db0737beee49cf', 'message': 'Remove ambiguity in stubbed methods in spec_helper\n\n- Adjust the stubs in spec/spec_helper.rb to specify the appropriate\n  number of expected variables.\n- Add parathensis around return values in spec_helper.rb\n\nChange-Id: I24a11e6f54946d0475a71f489dd7c2631e0736ed\nCloses-Bug: #1271535\n'}]",0,70084,74080b4dc132e8664cd874b7d4db0737beee49cf,7,4,1,2799,,,0,"Remove ambiguity in stubbed methods in spec_helper

- Adjust the stubs in spec/spec_helper.rb to specify the appropriate
  number of expected variables.
- Add parathensis around return values in spec_helper.rb

Change-Id: I24a11e6f54946d0475a71f489dd7c2631e0736ed
Closes-Bug: #1271535
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/84/70084/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/spec_helper.rb'],1,74080b4dc132e8664cd874b7d4db0737beee49cf,stub_fix," .and_return('bootstrap-token') .and_return('metadata-secret') .with('db', anything) .and_return('') .and_return('rabbit-pass') .and_return('admin') .and_return('nova-pass') .and_return('neutron-pass') .and_return(true)", .and_return 'bootstrap-token' .and_return 'metadata-secret' .and_return '' .and_return 'rabbit-pass' .and_return 'admin' .and_return 'nova-pass' .and_return 'neutron-pass' .and_return true,9,8
openstack%2Fhorizon~master~I6454aca62a01ff6aac855b8c53237896e8494454,openstack/horizon,master,I6454aca62a01ff6aac855b8c53237896e8494454,Javascript force filtering object items,MERGED,2014-01-07 10:53:23.000000000,2014-01-31 06:28:59.000000000,2014-01-31 06:28:58.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 7585}, {'_account_id': 7976}, {'_account_id': 8648}]","[{'number': 1, 'created': '2014-01-07 10:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/229954bfe159f1de4cabf6d013c665db9a00a984', 'message': ""Javascript force filtering object items\n\n    This option requires all for in loops to filter object's items.\nThe for in statement allows for looping through the names of all of\nthe properties of an object including those inherited throught the\nprototype chain. This behavior can lead to unexpected items in your\nobject so it is generally safer to always filter inherited properties\n\nChange-Id: I6454aca62a01ff6aac855b8c53237896e8494454\nImplements: blueprint jshint-codestyle\n""}, {'number': 2, 'created': '2014-01-20 08:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b8bdb24090085c002972edb32853aba375b465c7', 'message': ""Javascript force filtering object items\n\n    This option requires all for in loops to filter object's items.\nThe for in statement allows for looping through the names of all of\nthe properties of an object including those inherited throught the\nprototype chain. This behavior can lead to unexpected items in your\nobject so it is generally safer to always filter inherited properties\n\nChange-Id: I6454aca62a01ff6aac855b8c53237896e8494454\nImplements: blueprint jshint-codestyle\n""}, {'number': 3, 'created': '2014-01-29 09:15:37.000000000', 'files': ['horizon/static/horizon/js/horizon.membership.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f42629cc7d24dbcb31be32a9b591c7ff20f633c9', 'message': ""Javascript force filtering object items\n\n    This option requires all for in loops to filter object's items.\nThe for in statement allows for looping through the names of all of\nthe properties of an object including those inherited throught the\nprototype chain. This behavior can lead to unexpected items in your\nobject so it is generally safer to always filter inherited properties\n\nChange-Id: I6454aca62a01ff6aac855b8c53237896e8494454\nImplements: blueprint jshint-codestyle\n""}]",1,65254,f42629cc7d24dbcb31be32a9b591c7ff20f633c9,34,7,3,7976,,,0,"Javascript force filtering object items

    This option requires all for in loops to filter object's items.
The for in statement allows for looping through the names of all of
the properties of an object including those inherited throught the
prototype chain. This behavior can lead to unexpected items in your
object so it is generally safer to always filter inherited properties

Change-Id: I6454aca62a01ff6aac855b8c53237896e8494454
Implements: blueprint jshint-codestyle
",git fetch https://review.opendev.org/openstack/horizon refs/changes/54/65254/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.membership.js', 'horizon/static/horizon/tests/jshint.js']",2,229954bfe159f1de4cabf6d013c665db9a00a984,bp/jshint-codestyle," 'forin': true,",,39,27
openstack%2Fcookbook-openstack-block-storage~master~Ie91fd2d41b82120673c0b579230228c2f6dc79e3,openstack/cookbook-openstack-block-storage,master,Ie91fd2d41b82120673c0b579230228c2f6dc79e3,Fix the RBD driver class reference,MERGED,2014-01-24 13:59:40.000000000,2014-01-31 06:28:41.000000000,2014-01-31 06:28:41.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 425}, {'_account_id': 1032}, {'_account_id': 6526}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-24 13:59:40.000000000', 'files': ['recipes/volume.rb', 'spec/volume_spec.rb', 'spec/api_spec.rb', 'templates/default/cinder.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/62a6d8ed9a0eb666c087fc56e0b5cc1643f77588', 'message': 'Fix the RBD driver class reference\n\nThe reference for the RBD driver class was wrong.  It was fixed in all\nplaces.\n\nblueprint rbd-for-block-storage\n\nChange-Id: Ie91fd2d41b82120673c0b579230228c2f6dc79e3\n'}]",0,68915,62a6d8ed9a0eb666c087fc56e0b5cc1643f77588,11,8,1,10110,,,0,"Fix the RBD driver class reference

The reference for the RBD driver class was wrong.  It was fixed in all
places.

blueprint rbd-for-block-storage

Change-Id: Ie91fd2d41b82120673c0b579230228c2f6dc79e3
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/15/68915/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/volume.rb', 'spec/volume_spec.rb', 'spec/api_spec.rb', 'templates/default/cinder.conf.erb']",4,62a6d8ed9a0eb666c087fc56e0b5cc1643f77588,bp/rbd-for-block-storage,"<% if node[""openstack""][""block-storage""][""volume""][""driver""] == ""cinder.volume.drivers.rbd.RBDDriver"" %>","<% if node[""openstack""][""block-storage""][""volume""][""driver""] == ""cinder.volume.drivers.RBDDriver"" %>",4,4
openstack%2Fheat~master~I8c27ed6a461c699eba7da5bef8e879f1c0bdaf6b,openstack/heat,master,I8c27ed6a461c699eba7da5bef8e879f1c0bdaf6b,Only update_and_save if the stack exists,MERGED,2014-01-30 20:08:41.000000000,2014-01-31 06:17:29.000000000,2014-01-31 06:17:29.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 7253}]","[{'number': 1, 'created': '2014-01-30 20:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a9d4eb04ade366ff83da6c553a1090bda0af84e', 'message': ""Only update_and_save if the stack exists\n\nThe following error can happen during a stack-delete:\n\n  AttributeError: 'NoneType' object has no attribute 'update_and_save'\n\nOnly update_and_save the stack if it is not None.\n\nChange-Id: I8c27ed6a461c699eba7da5bef8e879f1c0bdaf6b\nCloses-Bug: #1274664\n""}, {'number': 2, 'created': '2014-01-30 21:13:38.000000000', 'files': ['heat/engine/parser.py', 'heat/tests/test_parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/efe3bf1c2252dd35fb6fff2be80f33abb227a51f', 'message': ""Only update_and_save if the stack exists\n\nThe following error can happen during a stack-delete:\n\n  AttributeError: 'NoneType' object has no attribute 'update_and_save'\n\nOnly update_and_save the stack if it is not None.\n\nChange-Id: I8c27ed6a461c699eba7da5bef8e879f1c0bdaf6b\nCloses-Bug: #1274664\n""}]",0,70209,efe3bf1c2252dd35fb6fff2be80f33abb227a51f,11,4,2,7253,,,0,"Only update_and_save if the stack exists

The following error can happen during a stack-delete:

  AttributeError: 'NoneType' object has no attribute 'update_and_save'

Only update_and_save the stack if it is not None.

Change-Id: I8c27ed6a461c699eba7da5bef8e879f1c0bdaf6b
Closes-Bug: #1274664
",git fetch https://review.opendev.org/openstack/heat refs/changes/09/70209/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/parser.py'],1,5a9d4eb04ade366ff83da6c553a1090bda0af84e,state-set-backtrace," if stack is not None: stack.update_and_save({'action': action, 'status': status, 'status_reason': reason})"," stack.update_and_save({'action': action, 'status': status, 'status_reason': reason})",4,3
openstack%2Fcookbook-openstack-compute~master~I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c,openstack/cookbook-openstack-compute,master,I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c,Update recipes to be rubocop compliant,MERGED,2014-01-21 12:07:18.000000000,2014-01-31 06:04:32.000000000,2014-01-31 06:04:32.000000000,"[{'_account_id': 3}, {'_account_id': 26}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-21 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/2efe5d156bbeb9572287530af3d5dc17c768923e', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 2, 'created': '2014-01-22 09:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/d547fadd81f948e5754c4087030c6cccefbc8f71', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 3, 'created': '2014-01-22 16:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/b62ad1af891f3bfde43d082783b806de87839425', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 4, 'created': '2014-01-23 14:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/e639347f83d042c2a031f77e294b5dc6a7ef426a', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 5, 'created': '2014-01-23 14:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/6fb1f02c29a76ddeff854c5cfa2caa11d64aa19f', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 6, 'created': '2014-01-23 15:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/91ca39ab618054742685cf81f40cbd796cbcfe6d', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 7, 'created': '2014-01-23 16:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/f5d4cd6c2ff5329e630f4ad14fe7fe335d88c433', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 8, 'created': '2014-01-29 11:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/e7dcfcda423b6f9a6e099908d3982229a64b6fe4', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 9, 'created': '2014-01-29 12:51:40.000000000', 'files': ['recipes/libvirt.rb', 'recipes/api-ec2.rb', 'recipes/scheduler.rb', 'spec/nova-setup_spec.rb', '.rubocop.yml', 'recipes/api-os-compute.rb', 'recipes/conductor.rb', 'recipes/nova-cert.rb', 'recipes/vncproxy.rb', 'recipes/api-metadata.rb', 'recipes/compute.rb', 'recipes/nova-setup.rb', 'recipes/default.rb', 'recipes/identity_registration.rb', 'recipes/network.rb', 'recipes/nova-common.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/be675315ec798a1155ed734d8892df4abec01937', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Ensure all recipes are rubocop compliant\n\nChange-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c\nAddresses: blueprint rubocop-for-compute\n'}]",39,68094,be675315ec798a1155ed734d8892df4abec01937,41,8,9,2799,,,0,"Update recipes to be rubocop compliant

- Adjust .rubocop.yml to include recipes/**
- Ensure all recipes are rubocop compliant

Change-Id: I7ecb3896b5a2b2d93304014a4ab19cb0e3c2e31c
Addresses: blueprint rubocop-for-compute
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/94/68094/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/libvirt.rb', 'recipes/api-ec2.rb', 'recipes/scheduler.rb', '.rubocop.yml', 'recipes/api-os-compute.rb', 'recipes/conductor.rb', 'recipes/nova-cert.rb', 'recipes/vncproxy.rb', 'recipes/api-metadata.rb', 'recipes/compute.rb', 'recipes/nova-setup.rb', 'recipes/default.rb', 'recipes/identity_registration.rb', 'recipes/network.rb', 'recipes/nova-common.rb']",15,2efe5d156bbeb9572287530af3d5dc17c768923e,bp/rubocop-for-compute,"# encoding: UTF-8# Licensed under the Apache License, Version 2.0 (the 'License');# distributed under the License is distributed on an 'AS IS' BASIS,require 'uri' class ::Chef::Recipe # rubocop:disable Documentationplatform?(%w(fedora redhat centos)) && (include_recipe 'yum::epel') node['openstack']['compute']['syslog']['use'] && (include_recipe 'openstack-common::logging') platform_options = node['openstack']['compute']['platform'] platform_options['common_packages'].each do |pkg| options platform_options['package_overrides']platform_options['memcache_python_packages'].each do |pkg|directory '/etc/nova' do owner node['openstack']['compute']['user'] group node['openstack']['compute']['group']db_user = node['openstack']['compute']['db']['username'] db_pass = get_password 'db', 'nova' sql_connection = db_uri('compute', db_user, db_pass) if node['openstack']['compute']['mq']['service_type'] == 'rabbitmq' node['openstack']['compute']['rabbit']['ha'] && (rabbit_hosts = rabbit_servers) rabbit_pass = get_password 'user', node['openstack']['compute']['rabbit']['username']if node['openstack']['identity']['admin_tenant_name'] && node['openstack']['identity']['admin_user'] ksadmin_tenant_name = node['openstack']['identity']['admin_tenant_name'] ksadmin_user = node['openstack']['identity']['admin_user'] identity_service_role = node['openstack']['compute']['identity_service_chef_role'] ksadmin_tenant_name = keystone['openstack']['identity']['admin_tenant_name'] ksadmin_user = keystone['openstack']['identity']['admin_user'] Chef::Log.debug('openstack-compute::nova-common:keystone|#{keystone}')ksadmin_pass = get_password 'user', ksadmin_user memcache_servers = memcached_servers.join ','identity_endpoint = endpoint 'identity-api' xvpvnc_endpoint = endpoint 'compute-xvpvnc' || {} novnc_endpoint = endpoint 'compute-novnc' || {} compute_api_endpoint = endpoint 'compute-api' || {} ec2_public_endpoint = endpoint 'compute-ec2-api' || {} network_endpoint = endpoint 'network-api' || {} image_endpoint = endpoint 'image-api' Chef::Log.debug('openstack-compute::nova-common:ksadmin_user|#{ksadmin_user}') Chef::Log.debug('openstack-compute::nova-common:ksadmin_tenant_name|#{ksadmin_tenant_name}') Chef::Log.debug('openstack-compute::nova-common:identity_endpoint|#{identity_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:xvpvnc_endpoint|#{xvpvnc_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:novnc_endpoint|#{novnc_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:compute_api_endpoint|#{::URI.decode compute_api_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:ec2_public_endpoint|#{ec2_public_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:network_endpoint|#{network_endpoint.to_s}') Chef::Log.debug('openstack-compute::nova-common:image_endpoint|#{image_endpoint.to_s}') vnc_bind_ip = address_for node['openstack']['compute']['libvirt']['bind_interface'] xvpvnc_proxy_ip = address_for node['openstack']['compute']['xvpvnc_proxy']['bind_interface'] novnc_proxy_ip = address_for node['openstack']['compute']['novnc_proxy']['bind_interface'] if node['openstack']['compute']['network']['service_type'] == 'neutron' neutron_admin_password = get_password 'service', 'openstack-network' neutron_metadata_proxy_shared_secret = secret 'secrets', 'neutron_metadata_secret'template '/etc/nova/nova.conf' do source 'nova.conf.erb' owner node['openstack']['compute']['user'] group node['openstack']['compute']['group'] sql_connection: sql_connection, novncproxy_base_url: novnc_endpoint.to_s, xvpvncproxy_base_url: xvpvnc_endpoint.to_s, xvpvncproxy_bind_host: xvpvnc_proxy_ip, novncproxy_bind_host: novnc_proxy_ip, vncserver_listen: vnc_bind_ip, vncserver_proxyclient_address: vnc_bind_ip, memcache_servers: memcache_servers, rabbit_password: rabbit_pass, rabbit_hosts: rabbit_hosts, identity_endpoint: identity_endpoint, glance_api_ipaddress: image_endpoint.host, glance_api_port: image_endpoint.port, iscsi_helper: platform_options['iscsi_helper'], scheduler_default_filters: node['openstack']['compute']['scheduler']['default_filters'].join(','), osapi_compute_link_prefix: compute_api_endpoint.to_s, network_endpoint: network_endpoint, neutron_admin_password: neutron_admin_password, neutron_metadata_proxy_shared_secret: neutron_metadata_proxy_shared_secrettemplate '/etc/nova/rootwrap.conf' do source 'rootwrap.conf.erb' owner 'root' group 'root'template '/root/openrc' do source 'openrc.erb' owner 'root' group 'root' user: ksadmin_user, tenant: ksadmin_tenant_name, password: ksadmin_pass, identity_endpoint: identity_endpoint, auth_strategy: 'keystone', ec2_url: ec2_public_endpoint.to_sexecute 'enable nova login' do command ""usermod -s /bin/sh #{node['openstack']['compute']['user']}""","# Licensed under the Apache License, Version 2.0 (the ""License"");# distributed under the License is distributed on an ""AS IS"" BASIS,require ""uri"" class ::Chef::Recipeif platform?(%w(fedora redhat centos)) # :pragma-foodcritic: ~FC024 - won't fix this include_recipe ""yum::epel"" end if node[""openstack""][""compute""][""syslog""][""use""] include_recipe ""openstack-common::logging"" end platform_options = node[""openstack""][""compute""][""platform""] platform_options[""common_packages""].each do |pkg| options platform_options[""package_overrides""]platform_options[""memcache_python_packages""].each do |pkg|directory ""/etc/nova"" do owner node[""openstack""][""compute""][""user""] group node[""openstack""][""compute""][""group""]db_user = node[""openstack""][""compute""][""db""][""username""] db_pass = get_password ""db"", ""nova"" sql_connection = db_uri(""compute"", db_user, db_pass) if node[""openstack""][""compute""][""mq""][""service_type""] == ""rabbitmq"" if node[""openstack""][""compute""][""rabbit""][""ha""] rabbit_hosts = rabbit_servers end rabbit_pass = get_password ""user"", node[""openstack""][""compute""][""rabbit""][""username""]if node[""openstack""][""identity""][""admin_tenant_name""] && node[""openstack""][""identity""][""admin_user""] ksadmin_tenant_name = node[""openstack""][""identity""][""admin_tenant_name""] ksadmin_user = node[""openstack""][""identity""][""admin_user""] identity_service_role = node[""openstack""][""compute""][""identity_service_chef_role""] ksadmin_tenant_name = keystone[""openstack""][""identity""][""admin_tenant_name""] ksadmin_user = keystone[""openstack""][""identity""][""admin_user""] Chef::Log.debug(""openstack-compute::nova-common:keystone|#{keystone}"")ksadmin_pass = get_password ""user"", ksadmin_user memcache_servers = memcached_servers.join "",""identity_endpoint = endpoint ""identity-api"" xvpvnc_endpoint = endpoint ""compute-xvpvnc"" || {} novnc_endpoint = endpoint ""compute-novnc"" || {} compute_api_endpoint = endpoint ""compute-api"" || {} ec2_public_endpoint = endpoint ""compute-ec2-api"" || {} network_endpoint = endpoint ""network-api"" || {} image_endpoint = endpoint ""image-api"" Chef::Log.debug(""openstack-compute::nova-common:ksadmin_user|#{ksadmin_user}"") Chef::Log.debug(""openstack-compute::nova-common:ksadmin_tenant_name|#{ksadmin_tenant_name}"") Chef::Log.debug(""openstack-compute::nova-common:identity_endpoint|#{identity_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:xvpvnc_endpoint|#{xvpvnc_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:novnc_endpoint|#{novnc_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:compute_api_endpoint|#{::URI.decode compute_api_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:ec2_public_endpoint|#{ec2_public_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:network_endpoint|#{network_endpoint.to_s}"") Chef::Log.debug(""openstack-compute::nova-common:image_endpoint|#{image_endpoint.to_s}"") vnc_bind_ip = address_for node[""openstack""][""compute""][""libvirt""][""bind_interface""] xvpvnc_proxy_ip = address_for node[""openstack""][""compute""][""xvpvnc_proxy""][""bind_interface""] novnc_proxy_ip = address_for node[""openstack""][""compute""][""novnc_proxy""][""bind_interface""] if node[""openstack""][""compute""][""network""][""service_type""] == ""neutron"" neutron_admin_password = get_password ""service"", ""openstack-network"" neutron_metadata_proxy_shared_secret = secret ""secrets"", ""neutron_metadata_secret""template ""/etc/nova/nova.conf"" do source ""nova.conf.erb"" owner node[""openstack""][""compute""][""user""] group node[""openstack""][""compute""][""group""] :sql_connection => sql_connection, :novncproxy_base_url => novnc_endpoint.to_s, :xvpvncproxy_base_url => xvpvnc_endpoint.to_s, :xvpvncproxy_bind_host => xvpvnc_proxy_ip, :novncproxy_bind_host => novnc_proxy_ip, :vncserver_listen => vnc_bind_ip, :vncserver_proxyclient_address => vnc_bind_ip, :memcache_servers => memcache_servers, :rabbit_password => rabbit_pass, :rabbit_hosts => rabbit_hosts, :identity_endpoint => identity_endpoint, :glance_api_ipaddress => image_endpoint.host, :glance_api_port => image_endpoint.port, :iscsi_helper => platform_options[""iscsi_helper""], :scheduler_default_filters => node[""openstack""][""compute""][""scheduler""][""default_filters""].join("",""), :osapi_compute_link_prefix => compute_api_endpoint.to_s, :network_endpoint => network_endpoint, :neutron_admin_password => neutron_admin_password, :neutron_metadata_proxy_shared_secret => neutron_metadata_proxy_shared_secrettemplate ""/etc/nova/rootwrap.conf"" do source ""rootwrap.conf.erb"" owner ""root"" group ""root""template ""/root/openrc"" do source ""openrc.erb"" owner ""root"" group ""root"" :user => ksadmin_user, :tenant => ksadmin_tenant_name, :password => ksadmin_pass, :identity_endpoint => identity_endpoint, :auth_strategy => ""keystone"", :ec2_url => ec2_public_endpoint.to_sexecute ""enable nova login"" do command ""usermod -s /bin/sh #{node[""openstack""][""compute""][""user""]}""",410,412
openstack%2Fpython-neutronclient~master~Ie6d38b0f6b23d14fe8bf61a15c929453d1ee73b1,openstack/python-neutronclient,master,Ie6d38b0f6b23d14fe8bf61a15c929453d1ee73b1,Updated help text for 'subnet-list' command,ABANDONED,2013-10-29 08:21:09.000000000,2014-01-31 06:03:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 8449}, {'_account_id': 9071}]","[{'number': 1, 'created': '2013-10-29 08:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/04510cc420b8ab3b3a9f50430cf0b273555c91e8', 'message': ""Updated help text for 'subnet-list' command\n\nAdded missing text 'sub' for help text displayed for 'subnet-list'\ncommand.\n\nFollowing was the earlier command:\n$ neutron --help\n:\n  subnet-delete                  Delete a given subnet.\n  subnet-list                    List networks that belong to\na given tenant.\n  subnet-show                    Show information of a given subnet.\n:\n\nFixed one:\n$ neutron --help\n:\n  subnet-delete                  Delete a given subnet.\n  subnet-list                    List subnets that belong to a given\ntenant.\n  subnet-show                    Show information of a given subnet.\n:\n\nChange-Id: Ie6d38b0f6b23d14fe8bf61a15c929453d1ee73b1\n""}, {'number': 2, 'created': '2014-01-19 21:20:11.000000000', 'files': ['neutronclient/neutron/v2_0/subnet.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e6d282f3a6a01e572b208cae19142c32ed8051d3', 'message': ""Updated help text for 'subnet-list' command\n\n(Removed from gate, neutron failure rate too high)\n\nAdded missing text 'sub' for help text displayed for 'subnet-list'\ncommand.\n\nFollowing was the earlier command:\n$ neutron --help\n:\n  subnet-delete                  Delete a given subnet.\n  subnet-list                    List networks that belong to\na given tenant.\n  subnet-show                    Show information of a given subnet.\n:\n\nFixed one:\n$ neutron --help\n:\n  subnet-delete                  Delete a given subnet.\n  subnet-list                    List subnets that belong to a given\ntenant.\n  subnet-show                    Show information of a given subnet.\n:\n\nChange-Id: Ie6d38b0f6b23d14fe8bf61a15c929453d1ee73b1\n""}]",1,54261,e6d282f3a6a01e572b208cae19142c32ed8051d3,11,5,2,9071,,,0,"Updated help text for 'subnet-list' command

(Removed from gate, neutron failure rate too high)

Added missing text 'sub' for help text displayed for 'subnet-list'
command.

Following was the earlier command:
$ neutron --help
:
  subnet-delete                  Delete a given subnet.
  subnet-list                    List networks that belong to
a given tenant.
  subnet-show                    Show information of a given subnet.
:

Fixed one:
$ neutron --help
:
  subnet-delete                  Delete a given subnet.
  subnet-list                    List subnets that belong to a given
tenant.
  subnet-show                    Show information of a given subnet.
:

Change-Id: Ie6d38b0f6b23d14fe8bf61a15c929453d1ee73b1
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/61/54261/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/subnet.py'],1,04510cc420b8ab3b3a9f50430cf0b273555c91e8,bug_id_1244618," """"""List subnets that belong to a given tenant."""""""," """"""List networks that belong to a given tenant.""""""",1,1
openstack%2Fceilometer~master~Ife60240cf4cb823f9f8a6f039c4ecd4de8189c81,openstack/ceilometer,master,Ife60240cf4cb823f9f8a6f039c4ecd4de8189c81,Fix happybase version,ABANDONED,2014-01-22 17:05:55.000000000,2014-01-31 06:03:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 7478}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-01-22 17:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9733487408f6b1a9bf2f710c10c475db03c401fe', 'message': 'Fix happybase version\n\nSince version 0.7 happybase contains a bug https://github.com/wbolster/happybase/issues/54\nIt blocks efficient HBase table scanning. Version 0.6 works ok in this scenario.\n\nChange-Id: Ife60240cf4cb823f9f8a6f039c4ecd4de8189c81\n'}, {'number': 2, 'created': '2014-01-23 09:01:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e848bacf1ea5dd50c6a0996ac5c57b326d421816', 'message': 'Fix happybase version\n\nSince version 0.7 happybase contains a bug https://github.com/wbolster/happybase/issues/54\nIt makes impossible HBase table scanning with filters. Version 0.6 works ok in this scenario.\n\nChange-Id: Ife60240cf4cb823f9f8a6f039c4ecd4de8189c81\n'}]",2,68436,e848bacf1ea5dd50c6a0996ac5c57b326d421816,9,6,2,7478,,,0,"Fix happybase version

Since version 0.7 happybase contains a bug https://github.com/wbolster/happybase/issues/54
It makes impossible HBase table scanning with filters. Version 0.6 works ok in this scenario.

Change-Id: Ife60240cf4cb823f9f8a6f039c4ecd4de8189c81
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/36/68436/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9733487408f6b1a9bf2f710c10c475db03c401fe,happybase,happybase==0.6,happybase>=0.4,1,1
openstack%2Fnova~master~Ie02700d0e1d48ea9b313ddb30c69c05ebfa263c8,openstack/nova,master,Ie02700d0e1d48ea9b313ddb30c69c05ebfa263c8,Fix broken tests,ABANDONED,2014-01-09 16:05:16.000000000,2014-01-31 06:03:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 7579}, {'_account_id': 8688}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-09 16:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0ec83cdfc312e43eff13eee00767c7fb2b5de51', 'message': ""Fix broken tests\n\nLibvirtConnTestCase.test_cpu_features_bug_1217630\n - only passes if your CPU lacks capability 'aes'\n + now skipped\n\nLibvirtConnTestCase.test_xml_and_uri_*\n - failed in a virtualised testenv because sysinfo wasn't returned\n + now those checks are ignored if sysinfo is unavailable\n\nChange-Id: Ie02700d0e1d48ea9b313ddb30c69c05ebfa263c8\n""}, {'number': 2, 'created': '2014-01-10 09:15:52.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/211e50ad24904d956b0c6dc12c5a94b9d8da6d1d', 'message': ""Fix broken tests\n\nLibvirtConnTestCase.test_cpu_features_bug_1217630\n - only passes if your CPU lacks capability 'aes'\n + now skipped\n\nLibvirtConnTestCase.test_xml_and_uri_*\n - failed in a virtualised testenv because sysinfo wasn't returned\n + now those checks are ignored if sysinfo is unavailable\n\nChange-Id: Ie02700d0e1d48ea9b313ddb30c69c05ebfa263c8\n""}]",4,65712,211e50ad24904d956b0c6dc12c5a94b9d8da6d1d,16,7,2,8688,,,0,"Fix broken tests

LibvirtConnTestCase.test_cpu_features_bug_1217630
 - only passes if your CPU lacks capability 'aes'
 + now skipped

LibvirtConnTestCase.test_xml_and_uri_*
 - failed in a virtualised testenv because sysinfo wasn't returned
 + now those checks are ignored if sysinfo is unavailable

Change-Id: Ie02700d0e1d48ea9b313ddb30c69c05ebfa263c8
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/65712/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_libvirt.py'],1,a0ec83cdfc312e43eff13eee00767c7fb2b5de51,master," @test.testtools.skip(""test fails if real CPU has AES capability"") def chksysinfo(i, path, expect): # sysinfo section may not be present in virtualised testenv def f(t): sysinfo = t.find(""sysinfo"") if sysinfo: return path(sysinfo.findall(""system/entry"")[i]) else: return expect check_list.append((f, expect)) data = [(""manufacturer"", version.vendor_string()), (""product"", version.product_string()), (""version"", version.version_string_with_package()), (""serial"", ""cef19ce0-0ca2-11df-855d-b19fbce37686""), (""uuid"", instance['uuid']), ] for i, pair in enumerate(data): def a(t): return t.get(""name"") def b(t): return t.text or '' chksysinfo(i, a, pair[0]) chksysinfo(i, b, pair[1])"," xpath = ""./sysinfo/system/entry"" check = (lambda t: t.findall(xpath)[0].get(""name""), ""manufacturer"") check_list.append(check) check = (lambda t: t.findall(xpath)[0].text, version.vendor_string()) check_list.append(check) check = (lambda t: t.findall(xpath)[1].get(""name""), ""product"") check_list.append(check) check = (lambda t: t.findall(xpath)[1].text, version.product_string()) check_list.append(check) check = (lambda t: t.findall(xpath)[2].get(""name""), ""version"") check_list.append(check) # NOTE(sirp): empty strings don't roundtrip in lxml (they are # converted to None), so we need an `or ''` to correct for that check = (lambda t: t.findall(xpath)[2].text or '', version.version_string_with_package()) check_list.append(check) check = (lambda t: t.findall(xpath)[3].get(""name""), ""serial"") check_list.append(check) check = (lambda t: t.findall(xpath)[3].text, ""cef19ce0-0ca2-11df-855d-b19fbce37686"") check_list.append(check) check = (lambda t: t.findall(xpath)[4].get(""name""), ""uuid"") check_list.append(check) check = (lambda t: t.findall(xpath)[4].text, instance['uuid']) check_list.append(check)",23,36
openstack%2Fhorizon~master~I9b8572e41c6e222cdbdb474ea1c9342224b3bdea,openstack/horizon,master,I9b8572e41c6e222cdbdb474ea1c9342224b3bdea,New column in user table displaying user's projects.,ABANDONED,2014-01-21 20:44:50.000000000,2014-01-31 06:03:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 7585}, {'_account_id': 9347}, {'_account_id': 9409}, {'_account_id': 9498}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-01-21 20:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/866326834c8d54af6051bce66efe2d6f1b262edf', 'message': ""Add user's projects in user edit form.\n\nUsability improvement.\nA list of projects the user is member of was added\nto the edit form as a read only.\nIs just informative, no update to membership can be\nmade from this view.\n\nChange-Id: I9b8572e41c6e222cdbdb474ea1c9342224b3bdea\nCloses-Bug: #1194109\n""}, {'number': 2, 'created': '2014-01-22 20:13:45.000000000', 'files': ['openstack_dashboard/dashboards/admin/users/views.py', 'openstack_dashboard/dashboards/admin/users/tests.py', 'openstack_dashboard/dashboards/admin/users/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/33021456c405c3f2458d47bad3ebb1c24d1a8e3e', 'message': ""New column in user table displaying user's projects.\n\nA new column was added to the index page instead of\nusing the update form to show the projects the user\nbelongs to.\n\nChanges:\n- a new column added to users/tables.py\n- IndexView/getData was modified to add\nthe projects to the user object in users/views.py\n- update tests\n\nChange-Id: I9b8572e41c6e222cdbdb474ea1c9342224b3bdea\nCloses-Bug: 1194109\n""}]",4,68260,33021456c405c3f2458d47bad3ebb1c24d1a8e3e,10,7,2,9409,,,0,"New column in user table displaying user's projects.

A new column was added to the index page instead of
using the update form to show the projects the user
belongs to.

Changes:
- a new column added to users/tables.py
- IndexView/getData was modified to add
the projects to the user object in users/views.py
- update tests

Change-Id: I9b8572e41c6e222cdbdb474ea1c9342224b3bdea
Closes-Bug: 1194109
",git fetch https://review.opendev.org/openstack/horizon refs/changes/60/68260/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/users/templates/users/_update.html', 'openstack_dashboard/dashboards/admin/users/forms.py']",2,866326834c8d54af6051bce66efe2d6f1b262edf,bug/1194109," project_membership = [] roles = api.keystone.roles_for_user(request, user=user_id, project=project.id) if roles: project_membership.append((project.id, project.name)) self.fields['membership'].choices = project_membership membership = forms.MultipleChoiceField(label=_(""User's projects""), required=False, widget=forms.SelectMultiple(attrs={'disabled': 'disabled'})) ",,16,0
openstack%2Fpython-ceilometerclient~master~Icfd23a76b3455526fff686e801b17375bbba3772,openstack/python-ceilometerclient,master,Icfd23a76b3455526fff686e801b17375bbba3772,Sync with oslo,ABANDONED,2014-01-09 16:31:48.000000000,2014-01-31 06:03:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8122}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-01-09 16:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/25bee244e35cf5fcf9fd51879f28c438a5d30789', 'message': 'Sync with oslo\n\nThis fixes some issues with Python 3, which have been handled in oslo.\n\nChange-Id: Icfd23a76b3455526fff686e801b17375bbba3772\n'}, {'number': 2, 'created': '2014-01-15 23:54:35.000000000', 'files': ['ceilometerclient/openstack/common/apiclient/auth.py', 'ceilometerclient/openstack/common/apiclient/__init__.py', 'ceilometerclient/openstack/common/apiclient/base.py', 'ceilometerclient/openstack/common/py3kcompat/__init__.py', 'ceilometerclient/openstack/common/py3kcompat/urlutils.py', 'ceilometerclient/openstack/common/apiclient/fake_client.py', 'ceilometerclient/openstack/common/apiclient/exceptions.py', 'ceilometerclient/openstack/common/strutils.py', 'ceilometerclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/06bf282800441f64420d4bd17e54d3f828ccec83', 'message': 'Sync with oslo\n\nThis fixes some issues with Python 3, which have been handled in oslo.\n\nOslo commit ID: 6827012438c7c88e0f54803f33c612684cf34e86.\n\nChange-Id: Icfd23a76b3455526fff686e801b17375bbba3772\n'}]",0,65716,06bf282800441f64420d4bd17e54d3f828ccec83,14,7,2,8122,,,0,"Sync with oslo

This fixes some issues with Python 3, which have been handled in oslo.

Oslo commit ID: 6827012438c7c88e0f54803f33c612684cf34e86.

Change-Id: Icfd23a76b3455526fff686e801b17375bbba3772
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/16/65716/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/openstack/common/apiclient/auth.py', 'ceilometerclient/openstack/common/apiclient/__init__.py', 'ceilometerclient/openstack/common/apiclient/base.py', 'ceilometerclient/openstack/common/py3kcompat/__init__.py', 'ceilometerclient/openstack/common/py3kcompat/urlutils.py', 'ceilometerclient/openstack/common/apiclient/fake_client.py', 'ceilometerclient/openstack/common/apiclient/exceptions.py', 'ceilometerclient/openstack/common/cliutils.py', 'ceilometerclient/openstack/common/strutils.py']",9,25bee244e35cf5fcf9fd51879f28c438a5d30789,py3_sync_oslo,"from ceilometerclient.openstack.common.gettextutils import _ if six.PY3: return text.encode(encoding, errors).decode(incoming) else: return text.encode(encoding, errors) if six.PY3: return text.encode(encoding, errors).decode(incoming) else: return text.encode(encoding, errors)","from ceilometerclient.openstack.common.gettextutils import _ # noqa return text.encode(encoding, errors) return text.encode(encoding, errors)",26,40
openstack%2Fglance~master~Id1659576079adaebb740d6d73cb49e10b3b0ed51,openstack/glance,master,Id1659576079adaebb740d6d73cb49e10b3b0ed51,Sync latest oslo db code,ABANDONED,2014-01-20 15:14:20.000000000,2014-01-31 06:03:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 7491}, {'_account_id': 8907}]","[{'number': 1, 'created': '2014-01-20 15:14:20.000000000', 'files': ['glance/openstack/common/db/sqlalchemy/__init__.py', 'glance/openstack/common/db/api.py', 'glance/openstack/common/db/sqlalchemy/test_migrations.py', 'glance/openstack/common/db/exception.py', 'glance/openstack/common/db/sqlalchemy/provision.py', 'glance/openstack/common/db/sqlalchemy/utils.py', 'glance/openstack/common/db/sqlalchemy/models.py', 'glance/openstack/common/db/__init__.py', 'glance/openstack/common/db/sqlalchemy/session.py', 'glance/openstack/common/db/sqlalchemy/migration.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d3429cc91fe6fffc97c7d0768fd151fae231f23c', 'message': 'Sync latest oslo db code\n\noslo-incubator commit sha:\n70ebb197a112bbc832bf8528b69dcfc164288539\n\nChange-Id: Id1659576079adaebb740d6d73cb49e10b3b0ed51\n'}]",3,67853,d3429cc91fe6fffc97c7d0768fd151fae231f23c,8,4,1,8907,,,0,"Sync latest oslo db code

oslo-incubator commit sha:
70ebb197a112bbc832bf8528b69dcfc164288539

Change-Id: Id1659576079adaebb740d6d73cb49e10b3b0ed51
",git fetch https://review.opendev.org/openstack/glance refs/changes/53/67853/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/openstack/common/db/sqlalchemy/__init__.py', 'glance/openstack/common/db/api.py', 'glance/openstack/common/db/sqlalchemy/test_migrations.py', 'glance/openstack/common/db/exception.py', 'glance/openstack/common/db/sqlalchemy/provision.py', 'glance/openstack/common/db/sqlalchemy/utils.py', 'glance/openstack/common/db/sqlalchemy/models.py', 'glance/openstack/common/db/__init__.py', 'glance/openstack/common/db/sqlalchemy/migration.py', 'glance/openstack/common/db/sqlalchemy/session.py']",10,d3429cc91fe6fffc97c7d0768fd151fae231f23c,sync_latest_oslo_code," Example:: Examples:: return (model_query(context, models.Foo). filter_by(foo=foo). first()) (model_query(context, models.Foo). filter_by(id=id). update({'foo': newfoo})) a ROLLBACK. Database Errors like IntegrityError will be raised in session's __exit__ handler, and any try/except within the context managed by session will not be triggered. And catching other non-database errors in the session will not trigger the ROLLBACK, so exception handlers should always be outside the session, unless the developer wants to do a partial commit on purpose. If the connection is dropped before this is possible, the database will implicitly roll back the transaction. :: foo_ref = (model_query(context, models.Foo, session). filter_by(id=foo_id). first()) (model_query(context, models.Bar, session). filter_by(id=foo_ref['bar_id']). update({'bar': newbar})) the need for an explicit transaction. It can be expressed like so:: subq = (model_query(context, models.Foo.id). filter_by(id=foo_id). limit(1). subquery()) (model_query(context, models.Bar). filter_by(id=subq.as_scalar()). update({'bar': newbar})) For reference, this emits approximately the following SQL statement:: Note: create_duplicate_foo is a trivially simple example of catching an exception while using ""with session.begin"". Here create two duplicate instances with same primary key, must catch the exception out of context managed by a single session: def create_duplicate_foo(context): foo1 = models.Foo() foo2 = models.Foo() foo1.id = foo2.id = 1 session = get_session() try: with session.begin(): session.add(foo1) session.add(foo2) except exception.DBDuplicateEntry as e: handle_error(e) :: to your model class. For example::* There are two possible ways to mark a record as deleted:: * In almost all cases you should use query.soft_delete(). Some examples:: count = (model_query(BarModel). find(some_condition). soft_delete(synchronize_session=True)) :: then soft delete them you should use query.soft_delete() method:: query = (model_query(BarModel, session=session). find(some_condition)) :: from glance.openstack.common.gettextutils import _ secret=True, secret=True, group='DATABASE'), cfg.DeprecatedOpt('idle_timeout', group='sql')],def get_session(autocommit=True, expire_on_commit=False, sqlite_fk=False, slave_session=False, mysql_traditional_mode=False): engine = get_engine(sqlite_fk=sqlite_fk, slave_engine=slave_session, mysql_traditional_mode=mysql_traditional_mode)# sqlite since 3.7.16: # 1 column - (IntegrityError) UNIQUE constraint failed: k1 # # N columns - (IntegrityError) UNIQUE constraint failed: k1, k2 # ""sqlite"": (re.compile(r""^.*columns?([^)]+)(is|are)\s+not\s+unique$""), re.compile(r""^.*UNIQUE\s+constraint\s+failed:\s+(.+)$"")), ""postgresql"": (re.compile(r""^.*duplicate\s+key.*\""([^\""]+)\""\s*\n.*$""),), ""mysql"": (re.compile(r""^.*\(1062,.*'([^\']+)'\""\)$""),) for pattern in _DUP_KEY_RE_DB[engine_name]: match = pattern.match(integrity_error.message) if match: break else: columns = match.group(1)def get_engine(sqlite_fk=False, slave_engine=False, mysql_traditional_mode=False): engine = create_engine(db_uri, sqlite_fk=sqlite_fk, mysql_traditional_mode=mysql_traditional_mode)def _set_mode_traditional(dbapi_con, connection_rec, connection_proxy): """"""Set engine mode to 'traditional'. Required to prevent silent truncates at insert or update operations under MySQL. By default MySQL truncates inserted string if it longer than a declared field just with warning. That is fraught with data corruption. """""" dbapi_con.cursor().execute(""SET SESSION sql_mode = TRADITIONAL;"") # For the db2, the error code is -30081 since the db2 is still not ready conn_err_codes = ('2002', '2003', '2006', '-30081')def create_engine(sql_connection, sqlite_fk=False, mysql_traditional_mode=False): if mysql_traditional_mode: sqlalchemy.event.listen(engine, 'checkout', _set_mode_traditional) else: LOG.warning(_(""This application has not enabled MySQL traditional"" "" mode, which means silent data corruption may"" "" occur. Please encourage the application"" "" developers to enable this mode."")) LOG.warning(msg % remaining) for filename, line, method, function in traceback.extract_stack(): if filename.endswith('session.py') and method == '_do_query': if filename.endswith('api.py') and method == 'wrapper': if filename.endswith('utils.py') and method == '_inner': if filename.endswith('exception.py') and method == '_wrap': if filename.endswith('db/api.py'): index = filename.rfind('glance') % (filename[index:], line, method, function)","# vim: tabstop=4 shiftwidth=4 softtabstop=4 Example: Examples: return model_query(context, models.Foo).\ filter_by(foo=foo).\ first() model_query(context, models.Foo).\ filter_by(id=id).\ update({'foo': newfoo}) a ROLLBACK. If the connection is dropped before this is possible, the database will implicitly rollback the transaction. foo_ref = model_query(context, models.Foo, session).\ filter_by(id=foo_id).\ first() model_query(context, models.Bar, session).\ filter_by(id=foo_ref['bar_id']).\ update({'bar': newbar}) the need for an explicit transaction. It can be expressed like so: subq = model_query(context, models.Foo.id).\ filter_by(id=foo_id).\ limit(1).\ subquery() model_query(context, models.Bar).\ filter_by(id=subq.as_scalar()).\ update({'bar': newbar}) For reference, this emits approximagely the following SQL statement: to your model class. For example:* There are two possible ways to mark a record as deleted:* In almost all cases you should use query.soft_delete(). Some examples: count = model_query(BarModel).\ find(some_condition).\ soft_delete(synchronize_session=True) then soft delete them you should use query.soft_delete() method: query = model_query(BarModel, session=session).\ find(some_condition)import sqlalchemy.interfacesfrom glance.openstack.common.gettextutils import _ # noqa group='DATABASE')],def get_session(autocommit=True, expire_on_commit=False, sqlite_fk=False, slave_session=False): engine = get_engine(sqlite_fk=sqlite_fk, slave_engine=slave_session) ""sqlite"": re.compile(r""^.*columns?([^)]+)(is|are)\s+not\s+unique$""), ""postgresql"": re.compile(r""^.*duplicate\s+key.*\""([^\""]+)\""\s*\n.*$""), ""mysql"": re.compile(r""^.*\(1062,.*'([^\']+)'\""\)$"") m = _DUP_KEY_RE_DB[engine_name].match(integrity_error.message) if not m: columns = m.group(1)def get_engine(sqlite_fk=False, slave_engine=False): engine = create_engine(db_uri, sqlite_fk=sqlite_fk) conn_err_codes = ('2002', '2003', '2006')def create_engine(sql_connection, sqlite_fk=False): LOG.warn(msg % remaining) for file, line, method, function in traceback.extract_stack(): if file.endswith('session.py') and method == '_do_query': if file.endswith('api.py') and method == 'wrapper': if file.endswith('utils.py') and method == '_inner': if file.endswith('exception.py') and method == '_wrap': if file.endswith('db/api.py'): index = file.rfind('glance') % (file[index:], line, method, function)",399,217
openstack%2Ftripleo-image-elements~master~I0c33d09874dd82242be6e6c2e5bb858819f03d7e,openstack/tripleo-image-elements,master,I0c33d09874dd82242be6e6c2e5bb858819f03d7e,Add element to store sshd keys on ephemeral.,ABANDONED,2014-01-08 16:02:00.000000000,2014-01-31 06:03:31.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 6966}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-08 16:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/477c2cb0fb65b99e99bb17a19adfd4fcd6fd5471', 'message': 'Add element to store sshd keys on ephemeral.\n\nWe can now retain sshd host keys across image rebuilds of instances by\nway of the use-ephemeral element.\n\nChange-Id: I0c33d09874dd82242be6e6c2e5bb858819f03d7e\n'}, {'number': 2, 'created': '2014-01-09 00:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/709297a4835cb03e29c2e0ff47badeec278a8487', 'message': 'Add element to store sshd keys on ephemeral.\n\nWe can now retain sshd host keys across image rebuilds of instances by\nway of the use-ephemeral element.\n\nChange-Id: I0c33d09874dd82242be6e6c2e5bb858819f03d7e\n'}, {'number': 3, 'created': '2014-01-09 17:24:23.000000000', 'files': ['elements/ssh-ephemeral/element-deps', 'elements/ssh-ephemeral/install.d/10-sshd-host-keys-ephemeral', 'elements/ssh-ephemeral/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/543174772db0c1774321237ec14ea0d385334001', 'message': 'Add element to store sshd keys on ephemeral.\n\nWe can now retain sshd host keys across image rebuilds of instances by\nway of the use-ephemeral element.\n\nChange-Id: I0c33d09874dd82242be6e6c2e5bb858819f03d7e\n'}]",9,65492,543174772db0c1774321237ec14ea0d385334001,18,7,3,6449,,,0,"Add element to store sshd keys on ephemeral.

We can now retain sshd host keys across image rebuilds of instances by
way of the use-ephemeral element.

Change-Id: I0c33d09874dd82242be6e6c2e5bb858819f03d7e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/92/65492/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/ssh-ephemeral/element-deps', 'elements/ssh-ephemeral/install.d/10-sshd-host-keys-ephemeral', 'elements/ssh-ephemeral/README.md']",3,477c2cb0fb65b99e99bb17a19adfd4fcd6fd5471,ssh-ephemeral,Configure sshd to store host keys on ephemeral partition. ,,9,0
openstack%2Fsolum~master~I020ac002ad8481f8e35a9b5610d28046d6fe6aea,openstack/solum,master,I020ac002ad8481f8e35a9b5610d28046d6fe6aea,WIP: Add poc git service,ABANDONED,2014-01-08 12:00:43.000000000,2014-01-31 06:03:27.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8443}, {'_account_id': 9094}]","[{'number': 1, 'created': '2014-01-08 12:00:43.000000000', 'files': ['tools/solum-platform-init.sh', 'tools/solum-app-create.py', 'solum/templates/gitlab_env.yaml', 'solum/templates/gitlab.yaml'], 'web_link': 'https://opendev.org/openstack/solum/commit/9b447f6b796849f251f864409dc1c2ab87fe754f', 'message': 'WIP: Add poc git service\n\nThis adds a gitlab heat template that you create with\n./tools/solum-platform-init.sh\n# it takes a while to install (15 mins)\n\nThen there is a script to simulate a user creating an app:\npython tools/solum-app-create.py\n\n(you will need to edit the ip address in the script)\n\nStill heaps to do (just a couple of hours work),\nthe heat template needs:\n- to use trove for the db\n- cinder volume for the git storage\n\nSome gitlab links:\nhttp://www.andrewmunsell.com/blog/how-to-install-gitlab-locally-in-a-vm\nhttps://raw2.github.com/gitlabhq/gitlab-recipes/master/install/ubuntu/ubuntu_server_1204.sh\nhttps://github.com/Itxaka/pyapi-gitlab/blob/develop/docs/index.rst\nhttps://github.com/gitlabhq/gitlabhq/blob/master/LICENSE\n\nChange-Id: I020ac002ad8481f8e35a9b5610d28046d6fe6aea\n'}]",17,65457,9b447f6b796849f251f864409dc1c2ab87fe754f,14,7,1,4715,,,0,"WIP: Add poc git service

This adds a gitlab heat template that you create with
./tools/solum-platform-init.sh
# it takes a while to install (15 mins)

Then there is a script to simulate a user creating an app:
python tools/solum-app-create.py

(you will need to edit the ip address in the script)

Still heaps to do (just a couple of hours work),
the heat template needs:
- to use trove for the db
- cinder volume for the git storage

Some gitlab links:
http://www.andrewmunsell.com/blog/how-to-install-gitlab-locally-in-a-vm
https://raw2.github.com/gitlabhq/gitlab-recipes/master/install/ubuntu/ubuntu_server_1204.sh
https://github.com/Itxaka/pyapi-gitlab/blob/develop/docs/index.rst
https://github.com/gitlabhq/gitlabhq/blob/master/LICENSE

Change-Id: I020ac002ad8481f8e35a9b5610d28046d6fe6aea
",git fetch https://review.opendev.org/openstack/solum refs/changes/57/65457/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/solum-platform-init.sh', 'tools/solum-app-create.py', 'solum/templates/gitlab_env.yaml', 'solum/templates/gitlab.yaml']",4,9b447f6b796849f251f864409dc1c2ab87fe754f,,"heat_template_version: 2013-05-23 description: GitLab on ubuntu 12.04 (hosted on Rackspace public cloud) parameters: key_name: type: string description: Name of an existing key pair to use for the instance flavor: type: string description: flavor (actually an integer) image: type: string description: UUID of image resources: not_tellin: type: OS::Heat::RandomString my_git: type: Rackspace::Cloud::Server properties: name: gitlabrador flavor: {get_param: flavor} image: {get_param: image} key_name: {get_param: key_name} user_data: str_replace: template: | #!/bin/bash -v # This script performs a complete installation of Gitlab for ubuntu server 12.04.1 x64: # TODO pass this mysql password in %password% curl https://raw.github.com/gitlabhq/gitlab-recipes/master/install/ubuntu/ubuntu_server_1204.sh | sudo domain_var=$(curl ifconfig.me) sh params: ""%password%"": { get_attr: [not_tellin, value] } outputs: public_ip: description: Public IP of the git server value: {get_attr: [my_git, PublicIp]} ",,145,0
openstack%2Fneutron~master~I303c482f98e14cbb4bc682da4fe49b494ec82365,openstack/neutron,master,I303c482f98e14cbb4bc682da4fe49b494ec82365,"Test patch, do not review",ABANDONED,2014-01-23 18:12:54.000000000,2014-01-31 06:03:26.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6695}, {'_account_id': 9845}, {'_account_id': 9925}]","[{'number': 1, 'created': '2014-01-23 18:12:54.000000000', 'files': ['neutron/plugins/cisco/foo_3rd_party_test'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3d2f3816fc84e0bb3239678bf974b2c774e953e', 'message': 'Test patch, do not review\n\nChange-Id: I303c482f98e14cbb4bc682da4fe49b494ec82365\n'}]",0,68715,e3d2f3816fc84e0bb3239678bf974b2c774e953e,8,5,1,6695,,,0,"Test patch, do not review

Change-Id: I303c482f98e14cbb4bc682da4fe49b494ec82365
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/68715/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/cisco/foo_3rd_party_test'],1,e3d2f3816fc84e0bb3239678bf974b2c774e953e,third_party_test,This file is for 3rd party testing purposes only. ,,1,0
openstack%2Fnova~master~I7d0d1aa5ac6c23b5f0c3913261832e062252fea0,openstack/nova,master,I7d0d1aa5ac6c23b5f0c3913261832e062252fea0,Fix 'network_name' not assinged,ABANDONED,2014-01-22 10:33:28.000000000,2014-01-31 06:03:21.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7823}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-22 10:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/457f4824121e9db60a40e3a034b781ef16b36ff6', 'message': 'Fix \'network_name\' not assinged\n\nWhen booting a vm with admin role and assigning it with\nanother tenant\'s private network, it\'s fine to work. But\nthe update info cache action will started periodically,\nat this time, the previous mentioned other tenant\'s private\nnetwork is filtered out by function ""get_available_network()""\nThe exception happened since the network utilized is out.\nThe worst affect is the vm can not be deleted normally.\n\nThis patch fix it by give the variable net_ids value to function\n""get_available_network"", so the current using network won\'t be\nout.\n\nChange-Id: I7d0d1aa5ac6c23b5f0c3913261832e062252fea0\nCloses-bug: #1271405\n'}, {'number': 2, 'created': '2014-01-23 05:33:02.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e034d16056d76451368c3412d12cc67b4d51b485', 'message': 'Fix \'network_name\' not assinged\n\nWhen booting a vm with admin role and assigning it with\nanother tenant\'s private network, it\'s fine to work. But\nthe update info cache action will started periodically,\nat this time, the previous mentioned other tenant\'s private\nnetwork is filtered out by function ""get_available_network()""\nThe exception happened since the network utilized is out.\nThe worst affect is the vm can not be deleted normally.\n\nThis patch fix it by give the variable net_ids value to function\n""get_available_network"", so the current using network won\'t be\nout.\n\nChange-Id: I7d0d1aa5ac6c23b5f0c3913261832e062252fea0\nCloses-bug: #1271405\n'}]",0,68348,e034d16056d76451368c3412d12cc67b4d51b485,14,5,2,7823,,,0,"Fix 'network_name' not assinged

When booting a vm with admin role and assigning it with
another tenant's private network, it's fine to work. But
the update info cache action will started periodically,
at this time, the previous mentioned other tenant's private
network is filtered out by function ""get_available_network()""
The exception happened since the network utilized is out.
The worst affect is the vm can not be deleted normally.

This patch fix it by give the variable net_ids value to function
""get_available_network"", so the current using network won't be
out.

Change-Id: I7d0d1aa5ac6c23b5f0c3913261832e062252fea0
Closes-bug: #1271405
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/68348/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,457f4824121e9db60a40e3a034b781ef16b36ff6,fix_1271405," networks = self._get_available_networks( context, instance['project_id'], net_ids=net_ids)"," networks = self._get_available_networks(context, instance['project_id'])",21,16
openstack%2Fnova~master~I376bf8370cc2379e9f7d46af997094ce9f4e3c34,openstack/nova,master,I376bf8370cc2379e9f7d46af997094ce9f4e3c34,respond display_name in os-hypervisors api,ABANDONED,2014-01-17 04:37:39.000000000,2014-01-31 06:03:11.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 6835}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-17 04:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a69ab396d5f5c61b09d4bafbd441fd3a6450d8c4', 'message': 'respond display_name in os-hypervisors api\n\nIn response of this api, the hypervisors.servers[x].name is used\ninstance_name, but not display_name. This is a little misleading. The\nsolution is using instance_name value for key ""instance_name"" or\ndisplay_name for ""name"", or both.\n\nChange-Id: I376bf8370cc2379e9f7d46af997094ce9f4e3c34\nCloses-Bug: #1270038\n'}, {'number': 2, 'created': '2014-01-17 09:19:32.000000000', 'files': ['nova/api/openstack/compute/contrib/hypervisors.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/476e94dbd309225195851df316e40ef34b631b3b', 'message': 'respond display_name in os-hypervisors api\n\nIn response of this api, the hypervisors.servers[x].name is used\ninstance_name, but not display_name. This is a little misleading. The\nsolution is using instance_name value for key ""instance_name"" or\ndisplay_name for ""name"", or both.\n\nChange-Id: I376bf8370cc2379e9f7d46af997094ce9f4e3c34\nCloses-Bug: #1270038\n'}]",0,67370,476e94dbd309225195851df316e40ef34b631b3b,14,6,2,6835,,,0,"respond display_name in os-hypervisors api

In response of this api, the hypervisors.servers[x].name is used
instance_name, but not display_name. This is a little misleading. The
solution is using instance_name value for key ""instance_name"" or
display_name for ""name"", or both.

Change-Id: I376bf8370cc2379e9f7d46af997094ce9f4e3c34
Closes-Bug: #1270038
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/67370/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/hypervisors.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisors.py']",2,a69ab396d5f5c61b09d4bafbd441fd3a6450d8c4,bug/1270038,"TEST_SERVERS = [dict(display_name=""inst1"", uuid=""uuid1"", host=""compute1""), dict(display_name=""inst2"", uuid=""uuid2"", host=""compute2""), dict(display_name=""inst3"", uuid=""uuid3"", host=""compute1""),","TEST_SERVERS = [dict(name=""inst1"", uuid=""uuid1"", host=""compute1""), dict(name=""inst2"", uuid=""uuid2"", host=""compute2""), dict(name=""inst3"", uuid=""uuid3"", host=""compute1""),",4,4
openstack%2Fglance~master~I6e48ff73087c94ae1bee1bcc93cfa81435c7494f,openstack/glance,master,I6e48ff73087c94ae1bee1bcc93cfa81435c7494f,Use 'selects' hub if 'poll' is not available,ABANDONED,2014-01-15 20:53:58.000000000,2014-01-31 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 6484}, {'_account_id': 7884}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-01-15 20:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/897825259c41f62a1bd98c5cb3a6711c9584f8cb', 'message': ""Use 'selects' hub if 'poll' is not available\n\nIf no eventlet hub is specified, try more than just the 'poll' hub. In\nparticular, if 'poll' doesn't work, with this patch Glance will use the\n'selects' hub which is more widely supported.\n\nChange-Id: I6e48ff73087c94ae1bee1bcc93cfa81435c7494f\nCloses-bug: #1269577\n""}, {'number': 2, 'created': '2014-01-15 22:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f971a53bcbb497fb84ba7b7ec03ccf81e65a09ec', 'message': ""Use 'selects' hub if 'poll' is not available\n\nIf no eventlet hub is specified, try more than just the 'poll' hub. In\nparticular, if 'poll' doesn't work, with this patch Glance will use the\n'selects' hub which is more widely supported.\nFixes bug 1269577\n\nChange-Id: I6e48ff73087c94ae1bee1bcc93cfa81435c7494f\nCloses-bug: #1269577\n""}, {'number': 3, 'created': '2014-01-22 02:06:29.000000000', 'files': ['glance/tests/unit/common/test_wsgi.py', 'requirements.txt', 'glance/common/wsgi.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/864c1305c4a8dd0bff4debeefdc9e58966dad194', 'message': ""Use 'selects' hub if 'poll' is not available\n\nIf no eventlet hub is specified, try more than just the 'poll' hub. In\nparticular, if 'poll' doesn't work, with this patch Glance will use the\n'selects' hub which is more widely supported.\nFixes bug 1269577\n\nChange-Id: I6e48ff73087c94ae1bee1bcc93cfa81435c7494f\n""}]",17,66935,864c1305c4a8dd0bff4debeefdc9e58966dad194,20,5,3,616,,,0,"Use 'selects' hub if 'poll' is not available

If no eventlet hub is specified, try more than just the 'poll' hub. In
particular, if 'poll' doesn't work, with this patch Glance will use the
'selects' hub which is more widely supported.
Fixes bug 1269577

Change-Id: I6e48ff73087c94ae1bee1bcc93cfa81435c7494f
",git fetch https://review.opendev.org/openstack/glance refs/changes/35/66935/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/common/test_wsgi.py', 'glance/common/wsgi.py']",2,897825259c41f62a1bd98c5cb3a6711c9584f8cb,bug/1269577," cfg.StrOpt('eventlet_hub', 'appropriate for some platforms. If this option is ' 'not given, \'poll\' will be used if it is available. ' 'See http://eventlet.net/doc/hubs.html for more ' 'details.')),def set_eventlet_hub(): hubs_to_try = ['poll', 'selects'] if cfg.CONF.eventlet_hub: hubs_to_try = [cfg.CONF.eventlet_hub] while True: hub = hubs_to_try.pop(0) try: eventlet.hubs.use_hub(hub) break except Exception: if len(hubs_to_try) > 0: continue msg = _(""eventlet '%s' hub is not available on this platform"") raise exception.WorkerCreationFailure( reason=msg % hub) set_eventlet_hub()"," cfg.StrOpt('eventlet_hub', default='poll', 'appropriate for some platforms. See ' 'http://eventlet.net/doc/hubs.html for more details.')), try: eventlet.hubs.use_hub(cfg.CONF.eventlet_hub) except Exception: msg = _(""eventlet '%s' hub is not available on this platform"") raise exception.WorkerCreationFailure( reason=msg % cfg.CONF.eventlet_hub)",57,10
openstack%2Fcookbook-openstack-compute~master~I2ba55825cf6a80ffa338f849c6c2f274b915886b,openstack/cookbook-openstack-compute,master,I2ba55825cf6a80ffa338f849c6c2f274b915886b,Update spec files to be rubocop compliant,MERGED,2014-01-21 16:49:54.000000000,2014-01-31 06:03:04.000000000,2014-01-31 06:03:03.000000000,"[{'_account_id': 3}, {'_account_id': 26}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 8410}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-21 16:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/45e7bcfd0d4704e32df380637e46c1637d6935c1', 'message': 'Update spec files to be rubocop compliant\n\n- Update .rubocop.yml to include spec/**\n- Update spec files to be rubocop compliant\n\nChange-Id: I2ba55825cf6a80ffa338f849c6c2f274b915886b\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 2, 'created': '2014-01-23 14:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/4e13581387a9e83b3d84de69509ce2b0bf7873d7', 'message': 'Update spec files to be rubocop compliant\n\n- Update .rubocop.yml to include spec/**\n- Update spec files to be rubocop compliant\n\nChange-Id: I2ba55825cf6a80ffa338f849c6c2f274b915886b\nAddresses: blueprint rubocop-for-compute\n'}, {'number': 3, 'created': '2014-01-29 12:02:23.000000000', 'files': ['spec/api-ec2-redhat_spec.rb', 'spec/nova-common-redhat_spec.rb', 'spec/libvirt-redhat_spec.rb', 'spec/vncproxy-redhat_spec.rb', 'spec/nova-cert-redhat_spec.rb', 'spec/nova-common_spec.rb', 'spec/network_spec.rb', 'spec/compute-opensuse_spec.rb', 'spec/libvirt-opensuse_spec.rb', 'spec/compute_spec.rb', 'spec/identity_registration_spec.rb', 'spec/libvirt_spec.rb', 'spec/api-metadata_spec.rb', 'spec/api-os-compute-redhat_spec.rb', 'spec/nova-cert_spec.rb', 'spec/conductor_redhat_spec.rb', 'spec/api-metadata-redhat_spec.rb', 'spec/conductor_spec.rb', 'spec/compute-redhat_spec.rb', 'spec/default_spec.rb', 'spec/nova-setup_spec.rb', '.rubocop.yml', 'spec/api-ec2_spec.rb', 'spec/scheduler_spec.rb', 'spec/vncproxy_spec.rb', 'spec/scheduler-redhat_spec.rb', 'spec/api-os-compute_spec.rb', 'spec/spec_helper.rb', 'spec/network-redhat_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/f9c4e3198ec9bf1c1a50e54e616310c39a3ba371', 'message': 'Update spec files to be rubocop compliant\n\n- Update .rubocop.yml to include spec/**\n- Update spec files to be rubocop compliant\n\nChange-Id: I2ba55825cf6a80ffa338f849c6c2f274b915886b\nAddresses: blueprint rubocop-for-compute\n'}]",2,68168,f9c4e3198ec9bf1c1a50e54e616310c39a3ba371,22,9,3,2799,,,0,"Update spec files to be rubocop compliant

- Update .rubocop.yml to include spec/**
- Update spec files to be rubocop compliant

Change-Id: I2ba55825cf6a80ffa338f849c6c2f274b915886b
Addresses: blueprint rubocop-for-compute
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/68/68168/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/api-ec2-redhat_spec.rb', 'spec/nova-common-redhat_spec.rb', 'spec/libvirt-redhat_spec.rb', 'spec/vncproxy-redhat_spec.rb', 'spec/nova-cert-redhat_spec.rb', 'spec/nova-common_spec.rb', 'spec/network_spec.rb', 'spec/compute-opensuse_spec.rb', 'spec/libvirt-opensuse_spec.rb', 'spec/compute_spec.rb', 'spec/identity_registration_spec.rb', 'spec/libvirt_spec.rb', 'spec/api-metadata_spec.rb', 'spec/api-os-compute-redhat_spec.rb', 'spec/nova-cert_spec.rb', 'spec/conductor_redhat_spec.rb', 'spec/api-metadata-redhat_spec.rb', 'spec/conductor_spec.rb', 'spec/compute-redhat_spec.rb', 'spec/default_spec.rb', 'spec/nova-setup_spec.rb', '.rubocop.yml', 'spec/api-ec2_spec.rb', 'spec/scheduler_spec.rb', 'spec/vncproxy_spec.rb', 'spec/scheduler-redhat_spec.rb', 'spec/api-os-compute_spec.rb', 'spec/spec_helper.rb', 'spec/network-redhat_spec.rb']",29,45e7bcfd0d4704e32df380637e46c1637d6935c1,bp/rubocop-for-compute,# encoding: UTF-8 require_relative 'spec_helper' describe 'openstack-compute::network' do describe 'redhat' do @chef_run.converge 'openstack-compute::network' it 'installs nova network packages' do expect(@chef_run).to upgrade_package 'iptables' expect(@chef_run).to upgrade_package 'openstack-nova-network' it 'starts nova network on boot' do expected = 'openstack-nova-network',"require_relative ""spec_helper"" describe ""openstack-compute::network"" do describe ""redhat"" do @chef_run.converge ""openstack-compute::network"" it ""installs nova network packages"" do expect(@chef_run).to upgrade_package ""iptables"" expect(@chef_run).to upgrade_package ""openstack-nova-network"" it ""starts nova network on boot"" do expected = ""openstack-nova-network""",707,655
openstack%2Fcookbook-openstack-network~master~I56f8482d95908d41e0b33552017166a4e1105177,openstack/cookbook-openstack-network,master,I56f8482d95908d41e0b33552017166a4e1105177,Remove unneeded and redundant rhel setup scripts,MERGED,2014-01-27 22:49:05.000000000,2014-01-31 06:02:49.000000000,2014-01-31 06:02:49.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 425}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 5371}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-27 22:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/72f88de27bc7b6fcbaac827292c0c53664b5a126', 'message': 'Remove unneeded and redundant rhel setup scripts\n\n3 scripts called in rhel/centos/fedora case\n- neutron-dhcp-setup\n- neutron-l3-setup\n- neturon-node-setup (openvswitch)\n\nThey set config options that are already handled, for example:\nmessaging - rpc_backend and qpid_hostname.\nkeystone - auth_url, admin_username, admin_password, admin_tenant_name.\nTesting confirmed no differences in etc/neutron config tree.\n\nblueprint support for centOS/RHEL in openstack-network\n\nChange-Id: I56f8482d95908d41e0b33552017166a4e1105177\n'}, {'number': 2, 'created': '2014-01-29 17:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/e18e19b9b6ebc080c546da0bea0b072738a6ac62', 'message': 'Remove unneeded and redundant rhel setup scripts\n\n3 scripts called in rhel/centos/fedora case\n- neutron-dhcp-setup\n- neutron-l3-setup\n- neturon-node-setup (openvswitch)\n\nThey set config options that are already handled, for example:\nmessaging - rpc_backend and qpid_hostname.\nkeystone - auth_url, admin_username, admin_password, admin_tenant_name.\nTesting confirmed no differences in etc/neutron config tree.\n\nAddresses: blueprint support-for-centOS/RHEL-in-openstack-network\n\nChange-Id: I56f8482d95908d41e0b33552017166a4e1105177\n'}, {'number': 3, 'created': '2014-01-30 16:50:58.000000000', 'files': ['recipes/dhcp_agent.rb', 'recipes/l3_agent.rb', 'recipes/openvswitch.rb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/61e24b607e2a6dece225e4515d6dae38f4deca77', 'message': 'Remove unneeded and redundant rhel setup scripts\n\n3 scripts called in rhel/centos/fedora case\n- neutron-dhcp-setup\n- neutron-l3-setup\n- neturon-node-setup (openvswitch)\n\nThey set config options that are already handled, for example:\nmessaging - rpc_backend and qpid_hostname.\nkeystone - auth_url, admin_username, admin_password, admin_tenant_name.\nTesting confirmed no differences in etc/neutron config tree.\n\nAddresses: blueprint centos-rhel-for-network\n\nChange-Id: I56f8482d95908d41e0b33552017166a4e1105177\n'}]",0,69490,61e24b607e2a6dece225e4515d6dae38f4deca77,27,9,3,7128,,,0,"Remove unneeded and redundant rhel setup scripts

3 scripts called in rhel/centos/fedora case
- neutron-dhcp-setup
- neutron-l3-setup
- neturon-node-setup (openvswitch)

They set config options that are already handled, for example:
messaging - rpc_backend and qpid_hostname.
keystone - auth_url, admin_username, admin_password, admin_tenant_name.
Testing confirmed no differences in etc/neutron config tree.

Addresses: blueprint centos-rhel-for-network

Change-Id: I56f8482d95908d41e0b33552017166a4e1105177
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/90/69490/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/dhcp_agent.rb', 'recipes/l3_agent.rb', 'recipes/openvswitch.rb', 'CHANGELOG.md', 'metadata.rb', 'README.md']",6,72f88de27bc7b6fcbaac827292c0c53664b5a126,bp/centos-rhel-for-network,"| | Mark Vanderwiel(<vanderwl@us.ibm.com>) || | Copyright (c) 2013-2014, IBM Corp. |","| | Copyright (c) 2013, IBM Corp. |",6,17
openstack%2Fcookbook-openstack-object-storage~master~Ia28e8b091895cadfe8eac2f722fc19a5218d2519,openstack/cookbook-openstack-object-storage,master,Ia28e8b091895cadfe8eac2f722fc19a5218d2519,Update providers to be rubocop compliant,MERGED,2014-01-28 23:07:27.000000000,2014-01-31 06:00:32.000000000,2014-01-31 06:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 7769}, {'_account_id': 9894}]","[{'number': 1, 'created': '2014-01-28 23:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/f690d2c323d88fd194157b0729f3442ea3e8cf50', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: rubocop-for-block-storage\n'}, {'number': 2, 'created': '2014-01-28 23:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/dff7850494cc28449c03a2cf3a60ab544fb8926e', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: rubocop-for-image-storage\n'}, {'number': 3, 'created': '2014-01-28 23:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/794f80ed15876f9f22646e4e6ef1e11d6d9b3ab9', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: rubocop-for-object-storage\n'}, {'number': 4, 'created': '2014-01-29 15:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/b8156f250c9010f10d3198a0230a95b5c3eebc6e', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: blueprint rubocop-for-object-storage\n'}, {'number': 5, 'created': '2014-01-29 19:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/4c08d232492cdafcdd4524946f1589e0dd507575', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: blueprint rubocop-for-object-storage\n'}, {'number': 6, 'created': '2014-01-29 19:29:58.000000000', 'files': ['providers/mounts.rb', 'providers/ring_script.rb', 'providers/disk.rb', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/a399e066b90fe418325ceca50fd1c3258319008f', 'message': 'Update providers to be rubocop compliant\n\n- Update rubocop config to include providers/**\n- Update providers to comply with rubocop\n\nChange-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519\nImplements: blueprint rubocop-for-object-storage\n'}]",10,69741,a399e066b90fe418325ceca50fd1c3258319008f,26,7,6,6714,,,0,"Update providers to be rubocop compliant

- Update rubocop config to include providers/**
- Update providers to comply with rubocop

Change-Id: Ia28e8b091895cadfe8eac2f722fc19a5218d2519
Implements: blueprint rubocop-for-object-storage
",git fetch https://review.opendev.org/openstack/cookbook-openstack-object-storage refs/changes/41/69741/1 && git format-patch -1 --stdout FETCH_HEAD,"['providers/mounts.rb', 'providers/ring_script.rb', 'providers/disk.rb', '.rubocop.yml']",4,f690d2c323d88fd194157b0729f3442ea3e8cf50,bp/rubocop-for-object-storage, - providers/**, - providers/**,159,162
openstack%2Fcookbook-openstack-network~master~Id5b5ac26f74046085e3f07d1696189061a03ee2e,openstack/cookbook-openstack-network,master,Id5b5ac26f74046085e3f07d1696189061a03ee2e,Update recipes to be rubocop compliant,MERGED,2014-01-28 16:19:07.000000000,2014-01-31 05:55:23.000000000,2014-01-31 05:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 26}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-01-28 16:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/64dcd871faa2166fc1bfaf0510d02f7a01c25bfb', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Complete rubocop compliancy for recipes/*.rb\n\nChange-Id: Id5b5ac26f74046085e3f07d1696189061a03ee2e\n'}, {'number': 2, 'created': '2014-01-28 16:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/ebec7ecccad62e89fdef6569f31d411049aed3a9', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Complete rubocop compliancy for recipes/*.rb\n\nChange-Id: Id5b5ac26f74046085e3f07d1696189061a03ee2e\nAddresses: blueprint rubo-for-network\n'}, {'number': 3, 'created': '2014-01-29 10:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/f7276d3d16ea81af40d3dfed75bd3f6ee91d1bb9', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Complete rubocop compliancy for recipes/*.rb\n\nChange-Id: Id5b5ac26f74046085e3f07d1696189061a03ee2e\nAddresses: blueprint rubo-for-network\n'}, {'number': 4, 'created': '2014-01-29 13:07:18.000000000', 'files': ['recipes/l3_agent.rb', '.rubocop.yml', 'recipes/common.rb', 'recipes/server.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/11d31927bde647011ba1de97727130e8392478c8', 'message': 'Update recipes to be rubocop compliant\n\n- Adjust .rubocop.yml to include recipes/**\n- Complete rubocop compliancy for recipes/*.rb\n\nChange-Id: Id5b5ac26f74046085e3f07d1696189061a03ee2e\nAddresses: blueprint rubocop-for-network\n'}]",0,69640,11d31927bde647011ba1de97727130e8392478c8,22,8,4,2799,,,0,"Update recipes to be rubocop compliant

- Adjust .rubocop.yml to include recipes/**
- Complete rubocop compliancy for recipes/*.rb

Change-Id: Id5b5ac26f74046085e3f07d1696189061a03ee2e
Addresses: blueprint rubocop-for-network
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/40/69640/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/l3_agent.rb', '.rubocop.yml', 'recipes/common.rb', 'recipes/server.rb']",4,64dcd871faa2166fc1bfaf0510d02f7a01c25bfb,bp/rubocop-for-network,bash 'migrate network database' do,"bash ""migrate network database"" do",5,5
openstack%2Fcookbook-openstack-ops-database~master~Ibb2113e266427b1d9b509d1e66389462e1ff0189,openstack/cookbook-openstack-ops-database,master,Ibb2113e266427b1d9b509d1e66389462e1ff0189,Update recipes to be rubocop compliant,MERGED,2014-01-21 11:25:03.000000000,2014-01-31 05:52:36.000000000,2014-01-31 05:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 26}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6526}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 8410}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-21 11:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/bcf15ee11c86f721f604161cfea9db07107854ff', 'message': 'Update recipes to be rubocop compliant\n\n- Update .rubocop.yml to include recipes/**\n- Update recipes to be rubocop compliant\n\nChange-Id: Ibb2113e266427b1d9b509d1e66389462e1ff0189\nAddresses: blueprint rubocop-for-ops-database\n'}, {'number': 2, 'created': '2014-01-28 09:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/67f47ffe72731e9852a454e1c463d5a6613da1e8', 'message': 'Update recipes to be rubocop compliant\n\n- Update .rubocop.yml to include recipes/**\n- Update recipes to be rubocop compliant\n\nChange-Id: Ibb2113e266427b1d9b509d1e66389462e1ff0189\nAddresses: blueprint rubocop-for-ops-database\n'}, {'number': 3, 'created': '2014-01-29 10:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/08bc7ea985f4ccb48ca5bb4e6568f7f714fdde5c', 'message': 'Update recipes to be rubocop compliant\n\n- Update .rubocop.yml to include recipes/**\n- Update recipes to be rubocop compliant\n\nChange-Id: Ibb2113e266427b1d9b509d1e66389462e1ff0189\nAddresses: blueprint rubocop-for-ops-database\n'}, {'number': 4, 'created': '2014-01-29 10:33:32.000000000', 'files': ['recipes/postgresql-client.rb', 'recipes/postgresql-server.rb', 'recipes/mysql-client.rb', 'recipes/mysql-server.rb', '.rubocop.yml', 'recipes/client.rb', 'recipes/openstack-db.rb', 'recipes/server.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/11cd04ded11e2ea87613a509b35c7b4ad4d575c4', 'message': 'Update recipes to be rubocop compliant\n\n- Update .rubocop.yml to include recipes/**\n- Update recipes to be rubocop compliant\n\nChange-Id: Ibb2113e266427b1d9b509d1e66389462e1ff0189\nAddresses: blueprint rubocop-for-ops-database\n'}]",0,68082,11cd04ded11e2ea87613a509b35c7b4ad4d575c4,31,10,4,2799,,,0,"Update recipes to be rubocop compliant

- Update .rubocop.yml to include recipes/**
- Update recipes to be rubocop compliant

Change-Id: Ibb2113e266427b1d9b509d1e66389462e1ff0189
Addresses: blueprint rubocop-for-ops-database
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/82/68082/4 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/postgresql-client.rb', 'recipes/postgresql-server.rb', 'recipes/mysql-client.rb', 'recipes/mysql-server.rb', '.rubocop.yml', 'recipes/client.rb', 'recipes/openstack-db.rb', 'recipes/server.rb']",8,bcf15ee11c86f721f604161cfea9db07107854ff,bp/rubocop-for-ops-database,"# encoding: UTF-8include_recipe ""openstack-ops-database::#{node['openstack']['db']['service_type']}-server""","include_recipe ""openstack-ops-database::#{node[""openstack""][""db""][""service_type""]}-server""",62,55
openstack%2Fglance~master~Ifde68415707506b56ffac1939c6750b216b87a87,openstack/glance,master,Ifde68415707506b56ffac1939c6750b216b87a87,Retry failed image download from Swift,MERGED,2013-09-30 10:18:13.000000000,2014-01-31 05:51:00.000000000,2014-01-31 05:50:59.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 6549}, {'_account_id': 7817}, {'_account_id': 7884}, {'_account_id': 8759}]","[{'number': 1, 'created': '2013-09-30 10:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5568e07126001d12ecda515795753d8eab2d1d3f', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 2, 'created': '2013-10-23 14:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3a660a19f25f9097d4c1e9051ed76281e2a53558', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 3, 'created': '2013-10-30 15:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/39266101cac15c019782a6e9c44f4656414b7c4a', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 4, 'created': '2013-11-08 12:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ab012c9c703fc63b1382f682463ec21d498fc7af', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 5, 'created': '2013-11-12 15:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/70299e2b6baba1d3e2dd7d2a123216b53d3cdd9d', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 6, 'created': '2013-11-13 10:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/da410dda3e4f54c019c3f41eb79e30587b45e4f7', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 7, 'created': '2013-12-02 10:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/70e7e7c72a05feeacd254a7be469d22879dd0b88', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 8, 'created': '2013-12-09 14:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a36157df2d83b486ee2358641f95e0ea83cfc229', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 9, 'created': '2013-12-09 15:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/93efbb403be6e562cfe004b66f69a78efb6ffe2b', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 10, 'created': '2014-01-10 11:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/30a130f9ad6014f0d3b6b6b08438d26b79f38211', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 11, 'created': '2014-01-10 12:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3668b89b466ac64a66217b5626355d86c2538bf1', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 12, 'created': '2014-01-13 10:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6d4dac770d5f8558f977cc98fbf1c12618acdf42', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 13, 'created': '2014-01-14 12:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/de9e7576699caf6ef479936e290becf955500b24', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 14, 'created': '2014-01-21 13:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/941fa8ad14d4646ff03f92199001f76a7bba3d5e', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}, {'number': 15, 'created': '2014-01-22 10:55:42.000000000', 'files': ['glance/tests/functional/store/test_swift.py', 'etc/glance-api.conf', 'glance/store/swift.py', 'doc/source/configuring.rst', 'glance/tests/unit/test_swift_store.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ae568d7858edeee4d60e52778243dc406651d46d', 'message': 'Retry failed image download from Swift\n\nIf a request to Swift for an image fails before the full image is\ndownloaded, this will reconnect to Swift and download the remainder of\nthe image without having to start from scratch.\n\nDocImpact\n\nblueprint retry-swift-download\n\nChange-Id: Ifde68415707506b56ffac1939c6750b216b87a87\n'}]",37,48913,ae568d7858edeee4d60e52778243dc406651d46d,88,9,15,7817,,,0,"Retry failed image download from Swift

If a request to Swift for an image fails before the full image is
downloaded, this will reconnect to Swift and download the remainder of
the image without having to start from scratch.

DocImpact

blueprint retry-swift-download

Change-Id: Ifde68415707506b56ffac1939c6750b216b87a87
",git fetch https://review.opendev.org/openstack/glance refs/changes/13/48913/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/glance-api.conf', 'glance/store/swift.py', 'doc/source/configuring.rst']",3,5568e07126001d12ecda515795753d8eab2d1d3f,bp/retry-swift-download,* ``swift_store_get_retries_count`` Can only be specified in configuration files. `This option is specific to the Swift storage backend.` Optional. Default: ``0`` The number of times a Swift connection will be retried before the request fails. ,Can only be specified in configuration files. `This option is specific to the Swift storage backend.` ,71,5
openstack%2Fceilometer~master~I2fc422950538135fbcf38c468401b4a5cf8640f2,openstack/ceilometer,master,I2fc422950538135fbcf38c468401b4a5cf8640f2,Fix some typos in architecture doc,MERGED,2014-01-23 18:12:31.000000000,2014-01-31 05:50:11.000000000,2014-01-31 05:50:11.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 4491}, {'_account_id': 6230}, {'_account_id': 6348}, {'_account_id': 6537}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-01-23 18:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/058b692fc574942a054261ef157040f32c28f839', 'message': 'Fix some typos in architecture doc\n\nAs a new person on this project, I found this document to be excellent.\nFixed a few typos found while reading:\nChange where we refer to Havana in the future tense.\nCapitalize Ceilometer when referring to the project.\n\nChange-Id: I2fc422950538135fbcf38c468401b4a5cf8640f2\n'}, {'number': 2, 'created': '2014-01-23 19:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5be7cf36dbf9e4bdeab6d8e31323c3d2a7e1779d', 'message': 'Fix some typos in architecture doc\n\nAs a new person on this project, I found this document to be excellent.\nFixed a few typos found while reading:\nChange where we refer to Havana in the future tense.\nCapitalize Ceilometer when referring to the project.\nOther small typos\n\nChange-Id: I2fc422950538135fbcf38c468401b4a5cf8640f2\n'}, {'number': 3, 'created': '2014-01-24 04:20:30.000000000', 'files': ['doc/source/architecture.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/686e1e93560c0e95c903432c6bb305dd78f0e801', 'message': 'Fix some typos in architecture doc\n\nAs a new person on this project, I found this document to be excellent.\nFixed a few typos found while reading:\nChange where we refer to Havana in the future tense.\nCapitalize Ceilometer when referring to the project.\nOther small typos\n\nChange-Id: I2fc422950538135fbcf38c468401b4a5cf8640f2\n'}]",4,68714,686e1e93560c0e95c903432c6bb305dd78f0e801,29,8,3,6230,,,0,"Fix some typos in architecture doc

As a new person on this project, I found this document to be excellent.
Fixed a few typos found while reading:
Change where we refer to Havana in the future tense.
Capitalize Ceilometer when referring to the project.
Other small typos

Change-Id: I2fc422950538135fbcf38c468401b4a5cf8640f2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/14/68714/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/architecture.rst'],1,058b692fc574942a054261ef157040f32c28f839,(detached,"you. Unfortunately, not all This is a representation of how to access data stored by CeilometerMoreover, end users can also :ref:`send their own application specific data <user-defined-data>` into the The assembly of component making the Ceilometer pipelineThe Alarming component of Ceilometer, first delivered in the HavanaFor more details on this, I recommend you read the blog post byAlthough we have described a list of the metrics Ceilometer shouldmeasure the resources their customers use. This means that Ceilometer","your. Unfortunately, not all This is a representation of how to access data stored by ceilometerMoreover, end users can also :ref:`send their own application centric data <user-defined-data>` into the The assembly of component making the ceilometer pipelineThe Alarming component of Ceilometer, which is being delivered in the HavanaFor more details on this, I recommend you to read the blog post byAlthough we have described a list of the metrics ceilometer shouldmeasure the resources their customers use. This means that ceilometer",8,8
openstack%2Fsahara~master~I8c3c4ebac116be4bc20429f9f9c82feac67c8802,openstack/sahara,master,I8c3c4ebac116be4bc20429f9f9c82feac67c8802,Bump stevedore to >=0.14,MERGED,2014-01-28 10:22:34.000000000,2014-01-31 05:16:46.000000000,2014-01-31 05:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-01-28 10:22:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/427644e754adac74b696ce419f7e3c06e2774bf1', 'message': 'Bump stevedore to >=0.14\n\nCurrent savanna code depends on entry_point_target that was added by\na8150369a045f08f86db00e49a45bda4594fd2d5, which is available in >= 0.13\n\nIt depends on https://review.openstack.org/#/c/69496/\n\nChange-Id: I8c3c4ebac116be4bc20429f9f9c82feac67c8802\nCloses-Bug: #1273459\n'}]",0,69571,427644e754adac74b696ce419f7e3c06e2774bf1,17,9,1,6786,,,0,"Bump stevedore to >=0.14

Current savanna code depends on entry_point_target that was added by
a8150369a045f08f86db00e49a45bda4594fd2d5, which is available in >= 0.13

It depends on https://review.openstack.org/#/c/69496/

Change-Id: I8c3c4ebac116be4bc20429f9f9c82feac67c8802
Closes-Bug: #1273459
",git fetch https://review.opendev.org/openstack/sahara refs/changes/71/69571/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,427644e754adac74b696ce419f7e3c06e2774bf1,,stevedore>=0.14,stevedore>=0.12,1,1
openstack%2Fcinder~master~Id61407c9a5e020d5a823dd7b8c973d237c35cb9b,openstack/cinder,master,Id61407c9a5e020d5a823dd7b8c973d237c35cb9b,VolumeManager: initialize even if a volume can't be found,MERGED,2014-01-20 21:55:20.000000000,2014-01-31 05:11:46.000000000,2014-01-31 05:11:46.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2463}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-20 21:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/69d093f72b350be764edc8c7e3302702c660856b', 'message': ""VolumeManager: don't refuse to initialize if a volume can't be found\n\nIf a volume cannot be exported (for example, because an iSCSI target's\nbacking LV is no longer present), VolumeManager would previously bail\nout, leaving the volume service uninitialized. This left volumes dangling\nin limbo: their state would be reported as available (clearly not a\nreflection of reality), and they could not be deleted (because the volume\nservice that would be responsible for deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAddresses bug 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 2, 'created': '2014-01-20 21:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ac77223823324893116f161d1e9820ff51a31d7', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAddresses bug 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 3, 'created': '2014-01-21 10:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f7e2d9ea705caac335ec8e10f7119e866dd30be', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nCloses-bug: 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 4, 'created': '2014-01-21 13:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ceb519b42ae3adc74881602cbb1c65a64d3d8353', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAlso, add an info message that reflects the actual path and\ncontents of the volume_path file.\n\nCloses-bug: 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 5, 'created': '2014-01-21 19:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e2aad36f8ed81f5341332756627ff2513acc7b2', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAlso, add an info message that reflects the actual path and\ncontents of the volume_path file.\n\nFinally, fix up the tgtadm unit test so that it tests for\nidentical IQNs,\n\nCloses-bug: 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 6, 'created': '2014-01-22 07:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a838f4efecf4824e5e4f5612905b0e1441ca6bc', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAlso, add an info message that reflects the actual path and\ncontents of the volume_path file.\n\nFinally, fix up the tgtadm unit test so that it tests for\nidentical IQNs,\n\nCloses-bug: 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}, {'number': 7, 'created': '2014-01-28 17:59:54.000000000', 'files': ['cinder/volume/manager.py', 'cinder/brick/iscsi/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d386210bc776a599bb31553c96e2a8a43acac61d', 'message': ""VolumeManager: initialize even if a volume can't be found\n\nIf a previously volume cannot be exported (for example, because\nan iSCSI target's backing LV is no longer present), VolumeManager\nwould previously bail out, leaving the volume service uninitialized.\nThis left volumes dangling in limbo: their state would be reported\nas available (clearly not a reflection of reality), and they could\nnot be deleted (because the volume service that would be responsible\nfor deletion was unavailable).\n\nInstead, catch an exception raised by ensure_export() separately,\nlog it, and set the volume to the error state.\n\nFor the tgt backend, this will also remove the volume_path file.\nPreviously this would cause an ISCSITargetRemoveFailed exception\nwhen the volume would be removed. Instead, simply log a warning\nand return, the way other backends (example: RBD) already do.\n\nAlso, add an info message that reflects the actual path and\ncontents of the volume_path file.\n\nFinally, fix up the tgtadm unit test so that it tests for\nidentical IQNs,\n\nCloses-bug: 1270959.\n\nChange-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b\n""}]",6,67966,d386210bc776a599bb31553c96e2a8a43acac61d,26,7,7,2463,,,0,"VolumeManager: initialize even if a volume can't be found

If a previously volume cannot be exported (for example, because
an iSCSI target's backing LV is no longer present), VolumeManager
would previously bail out, leaving the volume service uninitialized.
This left volumes dangling in limbo: their state would be reported
as available (clearly not a reflection of reality), and they could
not be deleted (because the volume service that would be responsible
for deletion was unavailable).

Instead, catch an exception raised by ensure_export() separately,
log it, and set the volume to the error state.

For the tgt backend, this will also remove the volume_path file.
Previously this would cause an ISCSITargetRemoveFailed exception
when the volume would be removed. Instead, simply log a warning
and return, the way other backends (example: RBD) already do.

Also, add an info message that reflects the actual path and
contents of the volume_path file.

Finally, fix up the tgtadm unit test so that it tests for
identical IQNs,

Closes-bug: 1270959.

Change-Id: Id61407c9a5e020d5a823dd7b8c973d237c35cb9b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/67966/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/brick/iscsi/iscsi.py']",2,69d093f72b350be764edc8c7e3302702c660856b,bug/1270959," if not os.path.exists(volume_path): LOG.warning(_('Volume path %s does not exist, ' 'nothing to remove' % volume_path)) return ",,14,1
openstack%2Fglance~master~I3837912e0d1614b9c31a689f71c2e34d453e2dc3,openstack/glance,master,I3837912e0d1614b9c31a689f71c2e34d453e2dc3,VMware Datastore storage backend,MERGED,2013-11-27 23:23:44.000000000,2014-01-31 05:11:43.000000000,2014-01-31 05:11:43.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1653}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 7948}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9171}, {'_account_id': 9604}]","[{'number': 1, 'created': '2013-11-27 23:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/635f67d82fe88e1183318a81f010887a4ce8b7b1', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 2, 'created': '2013-11-27 23:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/86b0e03b163ea86dafe16357494028a9e9055580', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 3, 'created': '2013-11-27 23:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/079fbe9f14a34f5c617e3c67ae834d1877a18b7b', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 4, 'created': '2013-11-27 23:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/487c4be3accb2e583307acc247cd4feb1336a8c0', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 5, 'created': '2013-11-27 23:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c933c57125837083fe95781a7de2f867131be65d', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 6, 'created': '2013-12-04 00:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/13786234ec412c69eeb7272697950e72a75eff11', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 7, 'created': '2013-12-04 21:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ea09f28adce887058df392349c08a3668e738fee', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 8, 'created': '2013-12-05 18:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/df89938a2c343b47a3c3c0bb20caaa16fecc8078', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a vmware/ folder containing the code to manage the\nconnection with vCenter or an ESX(i) host. This code will go away\nas soon as it is merged to Olso (common to Cinder and Nova).\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 9, 'created': '2013-12-06 19:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bab4e0f0d74f2f69ae8dfa717c5cca8f93011a8f', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 10, 'created': '2013-12-14 02:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/647c4a8052943041f2fedb3bc2c6e3fcd98c6f1b', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 11, 'created': '2013-12-14 03:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/36d4e33a1af955b275085e8b35c5ad73053fa1f7', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 12, 'created': '2013-12-18 21:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a91e7fe56fd58ebea211f8742c6476b8460e0c33', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 13, 'created': '2013-12-18 22:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8960b0c68d441c254c69feb746493272786cc8bb', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 14, 'created': '2013-12-18 22:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9269fe9e99a1dce34677d65704fe5bce9e4e9eda', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 15, 'created': '2013-12-19 00:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/65d9f5ba3eca712ababc6013df1690e25296a920', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee bp: https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 16, 'created': '2013-12-21 01:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/20085e4f32644693a33a2b275e683b5b9fb02c56', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova).\nsee https://blueprints.launchpad.net/oslo/+spec/vmware-api\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 17, 'created': '2013-12-21 01:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dad0ea060d9a33027e69649d90cce837cd773738', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 18, 'created': '2013-12-21 02:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/79702ca80afc8c83a0252805855bff70cdd43e12', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 19, 'created': '2013-12-23 19:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/df22538330559609af769d523b2133d4fb7f8aab', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 20, 'created': '2013-12-28 09:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/91591215d32f35f8692fe1bc063880f5ce62c052', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 21, 'created': '2014-01-02 21:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c816c3eac3df01ee33c6fc50171c25288b0a35b6', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 22, 'created': '2014-01-08 20:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7400f22b594236ffc7a3e542c3543e27541c1ed6', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso\n(common to Cinder and Nova) - scheduled for Icehouse-2.\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 23, 'created': '2014-01-08 22:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fed01d96c7862da1d61e63e6de87ab1ffc583e28', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 24, 'created': '2014-01-10 03:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e4edede7cdcdd6ae1630dc7823ae8d4e6edacb86', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 25, 'created': '2014-01-10 03:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dfbff5212651e3abc8678a8f9953aae193e5856c', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 26, 'created': '2014-01-10 18:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/02b654e612e6b3c0fd77e5588158cf2bc6dc7040', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 27, 'created': '2014-01-13 20:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/360cbdc69bf7352456c2b854ec30bd7c043cae61', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 28, 'created': '2014-01-13 23:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8f79d069e82609b0fcf0bceb53e490694fbe4034', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 29, 'created': '2014-01-14 01:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bc19418924d00470cd50a7d750601bb80a22029f', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 30, 'created': '2014-01-15 23:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b13022876106c47529c8be933742e55d5dede7b7', 'message': 'VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a `glance/store/vmware/` folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n'}, {'number': 31, 'created': '2014-01-16 02:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d506fc59e14536b240684d5ca12c9d2e9698f8f0', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 32, 'created': '2014-01-16 22:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/062d5afa3e9a63d835ab825831dbf90047f7ff89', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 33, 'created': '2014-01-17 20:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/585e0600f006f29ee320cf246bb481b7dbe502fb', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 34, 'created': '2014-01-17 20:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/659c382a3d2400a2486ca03a1a9fb0378c758f02', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 35, 'created': '2014-01-21 19:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/77296fc72f2b20ace5225bb2cc1043bf0bb8b474', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 36, 'created': '2014-01-22 05:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c0f293573e82ef82e2533a9ce70f5b40572c463b', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 37, 'created': '2014-01-22 05:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/675f242b40ac806d3309c58dbdbf1e6acb7a7f42', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 38, 'created': '2014-01-22 19:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c90c6e9dcfa3cf8b259991808e0b7bffd36ef030', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 39, 'created': '2014-01-24 01:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f7fc141cb91f469ac608b923344085fcb88944e4', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}, {'number': 40, 'created': '2014-01-31 02:22:34.000000000', 'files': ['glance/tests/unit/test_vmware_store.py', 'glance/store/__init__.py', 'glance/tests/functional/store/test_vmware_datastore.py', 'glance/store/vmware/api.py', 'doc/source/configuring.rst', 'doc/source/glanceapi.rst', 'glance/store/location.py', 'glance/store/vmware/error_util.py', 'etc/glance-cache.conf', 'glance/store/vmware_datastore.py', 'glance/tests/unit/test_store_location.py', 'glance/store/vmware/vim.py', 'requirements.txt', 'glance/store/vmware/vim_util.py', 'etc/glance-api.conf', 'glance/store/vmware/__init__.py', 'glance/tests/unit/base.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f9589bd010795b0daa101adfa18384b4be97e808', 'message': ""VMware Datastore storage backend\n\nCustomers using a VMware environment with OpenStack should be able to\nstore their Glance images in VMware datastores. This is a first step to solve\nthe problem where Nova needs to copy the bits over the network\nfrom Glance to the datastore when spawning an instance.\nAlso, this give the ability to provide some optimizations for specific\nimage formats in the future (fast cloning for example).\n\nThis patch contains a 'glance/store/vmware/' folder with the code\nto manage the connection with vCenter or an ESX(i) host.\nThis code will go away as soon as it is merged to Olso:\nsee review https://review.openstack.org/#/c/65075/\n\nThe current implementation give this ability to specify the vCenter or\nESX(i) IP. In case of a vCenter IP, there is no optimization to reduce\nthe datapath (no host selected).\nConsequently, it is recommended to specify an ESX IP if the ESX host\nAPI endpoint is accessible from Glance.\n\ndocImpact\nImplements bp vmware-datastore-storage-backend\n\nChange-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3\n""}]",212,58883,f9589bd010795b0daa101adfa18384b4be97e808,134,10,40,8759,,,0,"VMware Datastore storage backend

Customers using a VMware environment with OpenStack should be able to
store their Glance images in VMware datastores. This is a first step to solve
the problem where Nova needs to copy the bits over the network
from Glance to the datastore when spawning an instance.
Also, this give the ability to provide some optimizations for specific
image formats in the future (fast cloning for example).

This patch contains a 'glance/store/vmware/' folder with the code
to manage the connection with vCenter or an ESX(i) host.
This code will go away as soon as it is merged to Olso:
see review https://review.openstack.org/#/c/65075/

The current implementation give this ability to specify the vCenter or
ESX(i) IP. In case of a vCenter IP, there is no optimization to reduce
the datapath (no host selected).
Consequently, it is recommended to specify an ESX IP if the ESX host
API endpoint is accessible from Glance.

docImpact
Implements bp vmware-datastore-storage-backend

Change-Id: I3837912e0d1614b9c31a689f71c2e34d453e2dc3
",git fetch https://review.opendev.org/openstack/glance refs/changes/83/58883/40 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_vmware_store.py', 'glance/store/__init__.py', 'glance/tests/functional/store/test_vmware_datastore.py', 'doc/source/man/glanceapi.rst', 'glance/store/vmware/api.py', 'doc/source/configuring.rst', 'doc/source/glanceapi.rst', 'glance/store/location.py', 'glance/store/vmware/error_util.py', 'etc/glance-cache.conf', 'glance/store/vmware_datastore.py', 'glance/tests/__init__.py', 'glance/tests/unit/test_store_location.py', 'glance/store/vmware/vim.py', 'glance/store/vmware/io_util.py', 'glance/store/vmware/vim_util.py', 'etc/glance-api.conf', 'glance/store/vmware/__init__.py', 'glance/api/v1/images.py', 'glance/store/filesystem.py']",20,635f67d82fe88e1183318a81f010887a4ce8b7b1,bp/vmware-datastore-storage-backend, import pdb pdb.set_trace(),,1765,7
openstack%2Ftrove~master~I5d46ba78169ce26c18c05160f02a8b01f88aca40,openstack/trove,master,I5d46ba78169ce26c18c05160f02a8b01f88aca40,Replaces local generate_uuid with common.utils,MERGED,2014-01-25 14:29:18.000000000,2014-01-31 04:55:10.000000000,2014-01-31 04:55:10.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7806}]","[{'number': 1, 'created': '2014-01-25 14:29:18.000000000', 'files': ['trove/tests/unittests/conductor/test_methods.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/1674e9ceea0ad7fcfef4f650e713b7aa0679febc', 'message': 'Replaces local generate_uuid with common.utils\n\nReasons:\n- generate_uuid is defined locally to use truncated uuid,\n  without any specific need.\n- This may result in similar UUIDs.\n- Since tests work fine with usual common.utils.generate_uuid.\n\nReasons:\n- Replaces local generate_uuid with generate_uuid from common.utils.\n\nChange-Id: I5d46ba78169ce26c18c05160f02a8b01f88aca40\nCloses-Bug: #1272685\n'}]",0,69129,1674e9ceea0ad7fcfef4f650e713b7aa0679febc,11,5,1,7806,,,0,"Replaces local generate_uuid with common.utils

Reasons:
- generate_uuid is defined locally to use truncated uuid,
  without any specific need.
- This may result in similar UUIDs.
- Since tests work fine with usual common.utils.generate_uuid.

Reasons:
- Replaces local generate_uuid with generate_uuid from common.utils.

Change-Id: I5d46ba78169ce26c18c05160f02a8b01f88aca40
Closes-Bug: #1272685
",git fetch https://review.opendev.org/openstack/trove refs/changes/29/69129/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/conductor/test_methods.py'],1,1674e9ceea0ad7fcfef4f650e713b7aa0679febc,bug/1272685,"from trove.common import utils self.instance_id = utils.generate_uuid() new_id = utils.generate_uuid() new_id = utils.generate_uuid() tenant_id=utils.generate_uuid(), new_id = utils.generate_uuid() new_bkup_id = utils.generate_uuid() new_iid = utils.generate_uuid()","from uuid import uuid4def generate_uuid(length=16): uuid = [] while len(''.join(uuid)) < length: uuid.append(str(uuid4())) return (''.join(uuid))[:length] self.instance_id = generate_uuid() new_id = generate_uuid() new_id = generate_uuid() tenant_id=generate_uuid(), new_id = generate_uuid() new_bkup_id = generate_uuid() new_iid = generate_uuid()",8,15
openstack%2Fcinder~master~Ib615847f3cbeb74b1e4416d51730162ad1d07a40,openstack/cinder,master,Ib615847f3cbeb74b1e4416d51730162ad1d07a40,Revert initialize_connection changes,MERGED,2014-01-29 04:36:50.000000000,2014-01-31 04:26:53.000000000,2014-01-31 04:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 9236}]","[{'number': 1, 'created': '2014-01-29 04:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8c589312948a26cf45779f33cfb65c282d74f1a', 'message': 'Revert initialize_connection changes\n\nA change was merged that reusulted in interittent\ngate failures.  It seems that in certain cases the\nintitialize is doing an update targets and is\ndeleting the existing targets and not recreating them.\n\nThe idea of this patch was to fix up the iscis targets\nfor cases where volumes are extended.\n\nA better solution is in progress that will remove the\ntarget creation from the create_volume process altogether.\n\nCurrently we seem to have create_export, ensure_export and\nnow initialize that all are designed to do very similar\nthings.\n\nA bug has been filed to address this and will attempt\nto collapse these functions to be done at attach time.\n\nThis particular patch in essence reverts two patches:\ncommit: 18f8f5be94aae3b1747b143479ea1b188872f000\ncommit: a9267644ee09591e2d642d6c1204d94a9fdd8c82\n\nChange-Id: Ib615847f3cbeb74b1e4416d51730162ad1d07a40\nCloses-Bug: 127068\n'}, {'number': 2, 'created': '2014-01-29 13:30:49.000000000', 'files': ['cinder/brick/iscsi/iscsi.py', 'cinder/brick/exception.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0132be46bc9b4bb1b3bf77a623cc1d3b7e9307ea', 'message': 'Revert initialize_connection changes\n\nA change was merged that reusulted in interittent\ngate failures.  It seems that in certain cases the\nintitialize is doing an update targets and is\ndeleting the existing targets and not recreating them.\n\nThe idea of this patch was to fix up the iscis targets\nfor cases where volumes are extended.\n\nA better solution is in progress that will remove the\ntarget creation from the create_volume process altogether.\n\nCurrently we seem to have create_export, ensure_export and\nnow initialize that all are designed to do very similar\nthings.\n\nA bug has been filed to address this and will attempt\nto collapse these functions to be done at attach time.\n\nThis particular patch in essence reverts two patches:\ncommit: 18f8f5be94aae3b1747b143479ea1b188872f000\ncommit: a9267644ee09591e2d642d6c1204d94a9fdd8c82\n\nChange-Id: Ib615847f3cbeb74b1e4416d51730162ad1d07a40\nCloses-Bug: 1270608\n'}]",1,69787,0132be46bc9b4bb1b3bf77a623cc1d3b7e9307ea,23,6,2,2243,,,0,"Revert initialize_connection changes

A change was merged that reusulted in interittent
gate failures.  It seems that in certain cases the
intitialize is doing an update targets and is
deleting the existing targets and not recreating them.

The idea of this patch was to fix up the iscis targets
for cases where volumes are extended.

A better solution is in progress that will remove the
target creation from the create_volume process altogether.

Currently we seem to have create_export, ensure_export and
now initialize that all are designed to do very similar
things.

A bug has been filed to address this and will attempt
to collapse these functions to be done at attach time.

This particular patch in essence reverts two patches:
commit: 18f8f5be94aae3b1747b143479ea1b188872f000
commit: a9267644ee09591e2d642d6c1204d94a9fdd8c82

Change-Id: Ib615847f3cbeb74b1e4416d51730162ad1d07a40
Closes-Bug: 1270608
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/69787/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/iscsi/iscsi.py', 'cinder/brick/exception.py', 'cinder/volume/drivers/lvm.py']",3,a8c589312948a26cf45779f33cfb65c282d74f1a,bug/127068,," def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info. This function overrides the base class implementation so that the iSCSI target can be updated. This is necessary in the event that a user extended the volume before attachement. """""" # update the iSCSI target iscsi_name = ""%s%s"" % (self.configuration.iscsi_target_prefix, volume['name']) try: self.tgtadm.update_iscsi_target(iscsi_name) except brick_exception.ISCSITargetUpdateFailed as e: msg = (_('Failed to initialize iscsi ' 'connection for target: %s.') % iscsi_name) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # continue with the base class behaviour return driver.ISCSIDriver.initialize_connection(self, volume, connector) ",5,48
openstack%2Fnova~master~Id8009b5fd37cef03ca66cb5bf44211039ac895ba,openstack/nova,master,Id8009b5fd37cef03ca66cb5bf44211039ac895ba,Use (# of CPUs) workers by default,MERGED,2014-01-27 03:14:19.000000000,2014-01-31 04:23:07.000000000,2014-01-29 10:28:40.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 2759}, {'_account_id': 2835}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9084}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-27 03:14:19.000000000', 'files': ['nova/service.py', 'nova/conductor/api.py', 'etc/nova/nova.conf.sample', 'nova/utils.py', 'nova/cmd/conductor.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75c96a48fc7e5dfb59d8258142b01422f81b0253', 'message': 'Use (# of CPUs) workers by default\n\nUpdate the default value of the worker configuration options to be\nequal to the number of CPUs on the system.  This is the most common\nvalue that should be used to get ideal performance from nova-conductor\nor nova-api.\n\nThe following options are updated in this change:\n\n    [default]\n    ec2_workers=\n    osapi_compute_workers=\n    metadata_workers=\n\n    [conductor]\n    workers=\n\nDocImpact\nUpgradeImpact\n\nChange-Id: Id8009b5fd37cef03ca66cb5bf44211039ac895ba\n'}]",3,69266,75c96a48fc7e5dfb59d8258142b01422f81b0253,18,11,1,1561,,,0,"Use (# of CPUs) workers by default

Update the default value of the worker configuration options to be
equal to the number of CPUs on the system.  This is the most common
value that should be used to get ideal performance from nova-conductor
or nova-api.

The following options are updated in this change:

    [default]
    ec2_workers=
    osapi_compute_workers=
    metadata_workers=

    [conductor]
    workers=

DocImpact
UpgradeImpact

Change-Id: Id8009b5fd37cef03ca66cb5bf44211039ac895ba
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/69266/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/service.py', 'etc/nova/nova.conf.sample', 'nova/conductor/api.py', 'nova/utils.py', 'nova/cmd/conductor.py', 'nova/tests/test_utils.py']",6,75c96a48fc7e5dfb59d8258142b01422f81b0253,default-workers,"import multiprocessing def test_cpu_count(self): def fake_cpu_count(): return 8 self.stubs.Set(multiprocessing, 'cpu_count', fake_cpu_count) self.assertEqual(8, utils.cpu_count()) def test_cpu_count_not_implemented_returns_1(self): def fake_cpu_count(): raise NotImplementedError() self.stubs.Set(multiprocessing, 'cpu_count', fake_cpu_count) self.assertEqual(1, utils.cpu_count()) ",,43,10
openstack%2Fswift~feature%2Fec~I701890130188527066986d2dc6dcc9783a54471a,openstack/swift,feature/ec,I701890130188527066986d2dc6dcc9783a54471a,Add Storage Policy Support to the Auditor,MERGED,2013-12-30 19:41:25.000000000,2014-01-31 04:07:59.000000000,2014-01-31 04:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 6198}, {'_account_id': 7479}, {'_account_id': 7485}]","[{'number': 1, 'created': '2013-12-30 19:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d648ab055d95a4578b6646d2076f62bdffe7b8b', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass.  It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-01-16 01:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bd75283875cad2f6fec201e29716c91784e0bdbf', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass.  It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 3, 'created': '2014-01-17 23:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aea84cd46f1137eca4a49b2358160e7bf2959649', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass.  It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 4, 'created': '2014-01-18 00:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f0323e5d3b31bdd75db259a231a13c6f341fe64f', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass.  It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 5, 'created': '2014-01-20 19:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bec3ed4795bdeffe2a5b5f6aa03ef467028a9376', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass as well as a few policy specific tests\n(not all tests require policy knowledge to achieve coverage).\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 6, 'created': '2014-01-22 21:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7e3663343ff1544f8c28294c9eb383024edb92be', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass as well as a few policy specific tests\n(not all tests require policy knowledge to achieve coverage).\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}, {'number': 7, 'created': '2014-01-22 22:38:15.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/obj/auditor.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/15097f9c88e35bd0692d5ebfcf174253fb153fea', 'message': 'Add Storage Policy Support to the Auditor\n\nThis patch makes the Auditor policy aware and adds plumbing required\nfor existing test cases to pass as well as a few policy specific tests\n(not all tests require policy knowledge to achieve coverage).\n\nChange-Id: I701890130188527066986d2dc6dcc9783a54471a\nImplements: blueprint storage-policies\n'}]",4,64461,15097f9c88e35bd0692d5ebfcf174253fb153fea,33,8,7,7479,,,0,"Add Storage Policy Support to the Auditor

This patch makes the Auditor policy aware and adds plumbing required
for existing test cases to pass as well as a few policy specific tests
(not all tests require policy knowledge to achieve coverage).

Change-Id: I701890130188527066986d2dc6dcc9783a54471a
Implements: blueprint storage-policies
",git fetch https://review.opendev.org/openstack/swift refs/changes/61/64461/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/auditor.py', 'test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py', 'swift/obj/diskfile.py']",5,7d648ab055d95a4578b6646d2076f62bdffe7b8b,bp/storage-policies," def object_audit_location_generator(self, policy_idx):"," # XXX remove the default of 0 once the auditor has been made policy aware def object_audit_location_generator(self, policy_idx=0):",108,56
openstack%2Fopenstack-manuals~master~I1d2c4eb29b9ddedcdf5281504a28b5a73340a772,openstack/openstack-manuals,master,I1d2c4eb29b9ddedcdf5281504a28b5a73340a772,changes to emc-volume-driver.xml,MERGED,2014-01-30 18:29:45.000000000,2014-01-31 03:49:00.000000000,2014-01-31 03:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-30 18:29:45.000000000', 'files': ['doc/config-reference/block-storage/drivers/emc-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/48a948c16174526cfa691d03bb10b3e8c556d29d', 'message': 'changes to emc-volume-driver.xml\n\nadded ""the"" before user\nrun on sentence, made into 2 separate sentences\n\nChange-Id: I1d2c4eb29b9ddedcdf5281504a28b5a73340a772\n'}]",0,70183,48a948c16174526cfa691d03bb10b3e8c556d29d,6,3,1,9382,,,0,"changes to emc-volume-driver.xml

added ""the"" before user
run on sentence, made into 2 separate sentences

Change-Id: I1d2c4eb29b9ddedcdf5281504a28b5a73340a772
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/83/70183/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/emc-volume-driver.xml'],1,48a948c16174526cfa691d03bb10b3e8c556d29d,Cleanup_emc-volume-driver," driver, can create, delete, attach, and detach volumes. It can also create and delete snapshots, and so on.</para> <para>StorageType is the thin pool where the user wants to"," driver, can create, delete, attach, and detach volumes, create and delete snapshots, and so on.</para> <para>StorageType is the thin pool where user wants to",3,3
openstack%2Fpython-keystoneclient~master~Id856ab4775797d486831f5abb927429b8230c5c1,openstack/python-keystoneclient,master,Id856ab4775797d486831f5abb927429b8230c5c1,Python 3: fix tests/test_utils.py,MERGED,2013-12-16 19:20:34.000000000,2014-01-31 03:34:00.000000000,2014-01-31 03:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2472}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2013-12-16 19:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3354f642a6fa7522840e95874ecaa0e6147dccec', 'message': 'Remove calls to safe_encode() in Python3\n\nThis is definitely not necessary in Python3. Also fixes calls to\nbytes.decode() and disables tests in Python 3, so that the test_print_list_*\ntests work.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 2, 'created': '2014-01-16 18:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3f2a0f7ab6420c0f1a5e357a5156eb3b5b0ef698', 'message': 'Remove calls to safe_encode() in Python3\n\nThis is definitely not necessary in Python3. Also fixes calls to\nbytes.decode().\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 3, 'created': '2014-01-16 23:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3f61064caea849e01bb3945507953856378ca615', 'message': 'Remove calls to safe_encode() in Python3\n\nThis is definitely not necessary in Python3. Also fixes calls to\nbytes.decode().\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 4, 'created': '2014-01-17 02:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b26c806ee5e57073717be32dd61aa29cba82f031', 'message': 'Python 3: fix tests/test_utils.py\n\n* Do not call decode() on a text string;\n* Do not expect a UnicodeEncodeError to be raised if strutils.safe_encode() is\n  not called in print_{dict,list}.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 5, 'created': '2014-01-20 15:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/0286648cb25da41e6e30c27f341d29ebe5f3d711', 'message': 'Python 3: fix tests/test_utils.py\n\n* Remove test_print_dict_unicode_without_encode and\n  test_print_list_unicode_without_encode: they did not make sense;\n* Use six.moves.StringIO rather than six.moves.cStringIO for the fake standard\n  output in the tests, so that Unicode values can be passed to it, thus\n  removing the need to use strutils.safe_encode.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 6, 'created': '2014-01-20 15:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/262f96a32ed4e7567d65d58d18f54be1bcb855bb', 'message': 'Python 3: fix tests/test_utils.py\n\n* Remove test_print_dict_unicode_without_encode and\n  test_print_list_unicode_without_encode: they did not make sense;\n* Use six.moves.StringIO rather than six.moves.cStringIO for the fake standard\n  output in the tests, so that Unicode values can be passed to it, thus\n  removing the need to use strutils.safe_encode.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n'}, {'number': 7, 'created': '2014-01-24 15:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b562acf4e6c24dd5d8281768bf9eab4f4d1a607f', 'message': ""Python 3: fix tests/test_utils.py\n\nOnly call decode('utf-8') on bytes, not on text strings.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n""}, {'number': 8, 'created': '2014-01-28 19:18:58.000000000', 'files': ['keystoneclient/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/31695d1eb54242c3a4976a8a7ee15a489e5d0878', 'message': ""Python 3: fix tests/test_utils.py\n\nOnly call decode('utf-8') on bytes, not on text strings.\n\nChange-Id: Id856ab4775797d486831f5abb927429b8230c5c1\n""}]",31,62450,31695d1eb54242c3a4976a8a7ee15a489e5d0878,42,9,8,8122,,,0,"Python 3: fix tests/test_utils.py

Only call decode('utf-8') on bytes, not on text strings.

Change-Id: Id856ab4775797d486831f5abb927429b8230c5c1
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/50/62450/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/utils.py', 'keystoneclient/tests/test_utils.py']",2,3354f642a6fa7522840e95874ecaa0e6147dccec,fix_print_list_dict,"import testtools value = self.stdout.getvalue() if isinstance(value, six.binary_type): value = value.decode('utf8') self.assertIn(name, value) @testtools.skipIf(six.PY3, ""No need to encode in Python 3"") value = self.stdout.getvalue() if isinstance(value, six.binary_type): value = value.decode('utf8') self.assertIn(name, value) @testtools.skipIf(six.PY3, ""No need to encode in Python 3"")"," self.assertIn(name, self.stdout.getvalue().decode('utf8')) self.assertIn(name, self.stdout.getvalue().decode('utf8')) ",21,4
openstack%2Fdevstack-gate~master~I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7,openstack/devstack-gate,master,I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7,Collect list of installed packages at end of run,MERGED,2013-12-20 23:54:22.000000000,2014-01-31 02:38:22.000000000,2014-01-31 02:38:21.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6786}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-12-20 23:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d746b664f9053e36c77eb1f6a175b9e340c4e575', 'message': 'Collect list of installed packages at end of run\n\nRun dpkg -l at the end of a run so we can easily see what packages and\nversions are installed.  This helps rule out dependency changes as a\nthe cause of bugs.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n'}, {'number': 2, 'created': '2013-12-24 02:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5dd6e2b30a82cc3e560a613d8e1f5580e4b84dd0', 'message': 'Collect list of installed packages at end of run\n\nRun dpkg -l at the end of a run so we can easily see what packages and\nversions are installed.  This helps rule out dependency changes as a\nthe cause of bugs.\n\nOnly try running dpkg -l if dpkg is installed.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n'}, {'number': 3, 'created': '2013-12-26 22:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fc5166db84475c276830d7adfe3f6c4a69be1f5d', 'message': 'Collect list of installed packages at end of run\n\nRun dpkg -l at the end of a run so we can easily see what packages and\nversions are installed.  This helps rule out dependency changes as a\nthe cause of bugs.\n\nCompress the resulting list, when run locally the file size drops to\nunder 20% the original size.\n\nOnly try running dpkg -l if dpkg is installed.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n'}, {'number': 4, 'created': '2013-12-31 03:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/bb2d08614482a34158e87b0da6f7d405f8584934', 'message': ""Collect list of installed packages at end of run\n\nRun 'dpkg -l' or 'rpm -qa' at the end of a run so we can easily see what\npackages and versions are installed.  This helps rule out dependency changes\nas the cause of bugs.\n\nCompress the resulting list, when run locally the file size drops to\nunder 20% the original size.\n\nOnly try running dpkg -l if dpkg is installed and same for rpm.\n\nAlthough we only use dpkg today, there is an effort to support rpm based\ndistros in devstack-gate as well.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n""}, {'number': 5, 'created': '2014-01-27 18:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0a7328c406297ae90dae4c02a707788525fee826', 'message': ""Collect list of installed packages at end of run\n\nRun 'dpkg -l' or 'rpm -qa' at the end of a run so we can easily see what\npackages and versions are installed.  This helps rule out dependency changes\nas the cause of bugs.\n\nCompress the resulting list, when run locally the file size drops to\nunder 20% the original size.\n\nOnly try running dpkg -l if dpkg is installed and same for rpm.\n\nAlthough we only use dpkg today, there is an effort to support rpm based\ndistros in devstack-gate as well.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n""}, {'number': 6, 'created': '2014-01-27 20:09:18.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6d5066d32215bfebe9a17f27081357751d75bfcf', 'message': ""Collect list of installed packages at end of run\n\nRun 'dpkg -l' or 'rpm -qa' at the end of a run so we can easily see what\npackages and versions are installed.  This helps rule out dependency changes\nas the cause of bugs.\n\nCompress the resulting list, when run locally the file size drops to\nunder 20% the original size.\n\nOnly try running dpkg -l if dpkg is installed and same for rpm.\n\nAlthough we only use dpkg today, there is an effort to support rpm based\ndistros in devstack-gate as well.\n\nChange-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7\n""}]",11,63551,6d5066d32215bfebe9a17f27081357751d75bfcf,67,8,6,1849,,,0,"Collect list of installed packages at end of run

Run 'dpkg -l' or 'rpm -qa' at the end of a run so we can easily see what
packages and versions are installed.  This helps rule out dependency changes
as the cause of bugs.

Compress the resulting list, when run locally the file size drops to
under 20% the original size.

Only try running dpkg -l if dpkg is installed and same for rpm.

Although we only use dpkg today, there is an effort to support rpm based
distros in devstack-gate as well.

Change-Id: I2d99ddcc7c20e0ae9ec59fe4103f1a054917c1e7
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/51/63551/6 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,d746b664f9053e36c77eb1f6a175b9e340c4e575,dpkg, dpkg -l> $WORKSPACE/logs/dpkg-l.txt,,1,0
openstack%2Fswift~master~I021b043b927153bacff48cae648d4d8c5bbad765,openstack/swift,master,I021b043b927153bacff48cae648d4d8c5bbad765,Container Sync: Simple HTTP Proxy load balancing,MERGED,2014-01-16 02:05:08.000000000,2014-01-31 02:38:13.000000000,2014-01-31 02:38:13.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 2649}, {'_account_id': 6968}]","[{'number': 1, 'created': '2014-01-16 02:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dff3ceed3e9fdd4673d5a019e6cd7132505dec45', 'message': 'Container Sync: Simple HTTP Proxy load balancing\n\nChange-Id: I021b043b927153bacff48cae648d4d8c5bbad765\n'}, {'number': 2, 'created': '2014-01-23 01:24:42.000000000', 'files': ['swift/container/sync.py', 'etc/container-server.conf-sample', 'test/unit/container/test_sync.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/69d331d0d65d2f316bfdace8b9e018631ef47eba', 'message': 'Container Sync: Simple HTTP Proxy load balancing\n\nChange-Id: I021b043b927153bacff48cae648d4d8c5bbad765\n'}]",4,66989,69d331d0d65d2f316bfdace8b9e018631ef47eba,11,6,2,1216,,,0,"Container Sync: Simple HTTP Proxy load balancing

Change-Id: I021b043b927153bacff48cae648d4d8c5bbad765
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/66989/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/sync.py', 'etc/container-server.conf-sample', 'test/unit/container/test_sync.py']",3,dff3ceed3e9fdd4673d5a019e6cd7132505dec45,container_sync_http_proxies," cs.http_proxies = ['http://proxy'] cs.http_proxies = ['http://proxy'] def test_select_http_proxy_None(self): cs = sync.ContainerSync( {'sync_proxy': ''}, container_ring=FakeRing(), object_ring=FakeRing()) self.assertEqual(cs.select_http_proxy(), None) def test_select_http_proxy_one(self): cs = sync.ContainerSync( {'sync_proxy': 'http://one'}, container_ring=FakeRing(), object_ring=FakeRing()) self.assertEqual(cs.select_http_proxy(), 'http://one') def test_select_http_proxy_multiple(self): cs = sync.ContainerSync( {'sync_proxy': 'http://one,http://two,http://three'}, container_ring=FakeRing(), object_ring=FakeRing()) self.assertTrue(cs.select_http_proxy() in [ 'http://one', 'http://two', 'http://three']) ", cs.proxy = 'http://proxy' cs.proxy = 'http://proxy',35,7
openstack%2Fpython-glanceclient~master~I23924db3000feadcfe823c6cc979ea9752a13fa9,openstack/python-glanceclient,master,I23924db3000feadcfe823c6cc979ea9752a13fa9,Using common method 'bool_from_string' from oslo strutils,MERGED,2014-01-22 03:46:27.000000000,2014-01-31 02:38:12.000000000,2014-01-31 02:38:12.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 6676}, {'_account_id': 9560}]","[{'number': 1, 'created': '2014-01-22 03:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/424f3ba41d1d1be003d8d6655bd4ffc67dac7ae4', 'message': ""Using common method 'bool_from_string' from oslo strutils\n\nUsing common method 'bool_from_string' from oslo strutils to replace\nutils.string_to_bool.\n\npartially implements blueprint common-client-library-2\n\nChange-Id: I23924db3000feadcfe823c6cc979ea9752a13fa9\n""}, {'number': 2, 'created': '2014-01-23 03:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5236659deb46b2ff6e2edd9c33cf2eee5ab1e972', 'message': ""Using common method 'bool_from_string' from oslo strutils\n\nUsing common method 'bool_from_string' from oslo strutils to replace\nutils.string_to_bool.\n\npartially implements blueprint common-client-library-2\n\nChange-Id: I23924db3000feadcfe823c6cc979ea9752a13fa9\n""}, {'number': 3, 'created': '2014-01-23 07:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/74330a95ce266f8987085a48f54626c5f62a496b', 'message': ""Using common method 'bool_from_string' from oslo strutils\n\nUsing common method 'bool_from_string' from oslo strutils to replace\nutils.string_to_bool.\n\npartially implements blueprint common-client-library-2\n\nChange-Id: I23924db3000feadcfe823c6cc979ea9752a13fa9\n""}, {'number': 4, 'created': '2014-01-24 02:08:15.000000000', 'files': ['glanceclient/v1/shell.py', 'glanceclient/v1/images.py', 'glanceclient/v1/legacy_shell.py', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e5f6dee95d7559fafc0e768366b3ac773ac91a4f', 'message': ""Using common method 'bool_from_string' from oslo strutils\n\nUsing common method 'bool_from_string' from oslo strutils to replace\nutils.string_to_bool.\n\npartially implements blueprint common-client-library-2\n\nChange-Id: I23924db3000feadcfe823c6cc979ea9752a13fa9\n""}]",2,68313,e5f6dee95d7559fafc0e768366b3ac773ac91a4f,15,6,4,9560,,,0,"Using common method 'bool_from_string' from oslo strutils

Using common method 'bool_from_string' from oslo strutils to replace
utils.string_to_bool.

partially implements blueprint common-client-library-2

Change-Id: I23924db3000feadcfe823c6cc979ea9752a13fa9
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/13/68313/3 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/v1/shell.py', 'glanceclient/v1/images.py', 'glanceclient/v1/legacy_shell.py', 'glanceclient/common/utils.py']",4,424f3ba41d1d1be003d8d6655bd4ffc67dac7ae4,bp/common-client-library-2," 'boolean': strutils.bool_from_string,"," 'boolean': string_to_bool,def string_to_bool(arg): return arg.strip().lower() in ('t', 'true', 'yes', '1') ",12,15
openstack%2Fswift~feature%2Fec~I19b5dfb59d04ba574a1badd634665c432bf8cbcd,openstack/swift,feature/ec,I19b5dfb59d04ba574a1badd634665c432bf8cbcd,Add Storage Policy Support to the Updater,MERGED,2014-01-02 22:20:06.000000000,2014-01-31 02:17:10.000000000,2014-01-31 02:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-01-02 22:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/38b71726788086e4a17f389cb0ccd173d30b23f5', 'message': 'Add Storage Policy Support to the Updater\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass. It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-01-15 00:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c2cb796ec6794e8959795ba4908472c057a9452e', 'message': 'Add Storage Policy Support to the Updater\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass. It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}, {'number': 3, 'created': '2014-01-15 01:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6a5e8ae0742c99dd5d250db3b50aa5551da89116', 'message': 'Add Storage Policy Support to the Updater\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass. It depends highly on the Diskfile/\nStorage Policy patch (pending) and borrows a few small elements from the\npending Replicator/Storage Policy patch.\n\nMore unit tests will be added to cover multiple policies following\ninitial review/feedback on the functional code changes.\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}, {'number': 4, 'created': '2014-01-22 23:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1ed5f32bdce508880479899f3cdb75bc9f530fca', 'message': 'Add Storage Policy Support to the Updater.\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass as well as test cases required for\npolicy coverage\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}, {'number': 5, 'created': '2014-01-27 22:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/81ca9bff973e1d1b4f5ab1542d1217f81da72ea3', 'message': 'Add Storage Policy Support to the Updater.\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass as well as test cases required for\npolicy coverage\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}, {'number': 6, 'created': '2014-01-30 22:21:22.000000000', 'files': ['swift/obj/updater.py', 'test/unit/common/test_storage_policies.py', 'test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/623670838d1c11704faa339cafec2cfd8dcf7045', 'message': 'Add Storage Policy Support to the Updater\n\nThis patch makes the Updater policy aware and adds plumbing required\nfor existing test cases to pass as well as test cases required for\npolicy coverage.\n\nChange-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd\nImplements: blueprint storage-policies\n'}]",7,64737,623670838d1c11704faa339cafec2cfd8dcf7045,27,7,6,7479,,,0,"Add Storage Policy Support to the Updater

This patch makes the Updater policy aware and adds plumbing required
for existing test cases to pass as well as test cases required for
policy coverage.

Change-Id: I19b5dfb59d04ba574a1badd634665c432bf8cbcd
Implements: blueprint storage-policies
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/64737/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py', 'test/unit/obj/test_updater.py']",4,38b71726788086e4a17f389cb0ccd173d30b23f5,bp/storage-policies,"from swift.common.storage_policy import StoragePolicy, StoragePolicyCollection self.policies = StoragePolicyCollection( [StoragePolicy(0, 'zero', False), StoragePolicy(1, 'one', True)]) 'node_timeout': '5'}, self.policies) 'node_timeout': '5'}, self.policies) cu.object_sweep(self.sda1, 0) 'node_timeout': '15'}, self.policies) 'node_timeout': '15'}, self.policies) 'node_timeout': '15'}, self.policies) 'node_timeout': '15'}, self.policies)", 'node_timeout': '5'}) 'node_timeout': '5'}) cu.object_sweep(self.sda1) 'node_timeout': '15'}) 'node_timeout': '15'}) 'node_timeout': '15'}) 'node_timeout': '15'}),37,13
openstack%2Fdevstack~master~I112309661dadf8b753c3311182f82464d9d3595e,openstack/devstack,master,I112309661dadf8b753c3311182f82464d9d3595e,Set keystone admin_bind_host to KEYSTONE_SERVICE_HOST,MERGED,2013-11-21 01:03:38.000000000,2014-01-31 02:17:08.000000000,2014-01-31 02:17:07.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2218}, {'_account_id': 2556}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 4146}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-11-21 01:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d83362890f654c4c69302f8f8e931a50882d83dc', 'message': ""Change Keystone ports used by devstack.\n\nThis is an ugly workaround for a problem that doesn't appear to have any\nnon ugly solutions. On Linux ports 32768-61000 can be used by just about\nanything needing a socket. Keystone's IANA assigned port is 35357.\nOccasionally something else will be using port 35357 first because Linux\nallows this. Workaround it by using port 32357 instead of 35357 (also\n32358 instead of 35358 for the internal port if TLS is used).\n\nChange-Id: I112309661dadf8b753c3311182f82464d9d3595e\nFixes-bug: 1253482\n""}, {'number': 2, 'created': '2013-11-21 01:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e35414ee25a9708ef9a22114114196d707cf7d84', 'message': ""Change Keystone ports used by devstack.\n\nThis is an ugly workaround for a problem that doesn't appear to have any\nnon ugly solutions. On Linux ports 32768-61000 can be used by just about\nanything needing a socket. Keystone's IANA assigned port is 35357.\nOccasionally something else will be using port 35357 first because Linux\nallows this. Workaround it by using port 32357 instead of 35357 (also\n32358 instead of 35358 for the internal port if TLS is used).\n\nChange-Id: I112309661dadf8b753c3311182f82464d9d3595e\nFixes-bug: 1253482\n""}, {'number': 3, 'created': '2014-01-30 01:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1285cf4c80014215881fd0ce79f1a564f0e4e73c', 'message': 'Set keystone admin_bind_host to KEYSTONE_SERVICE_HOST\n\nOn Linux ports 32768-61000 can be used by just about\nanything needing a socket. Keystone\'s IANA assigned port is 35357.\nOccasionally something else will be using port 35357 first because Linux\nallows this. Workaround is to bind to port 127.0.0.1 instead of 0.0.0.0.\n$KEYSTONE_SERVICE_HOST gets its value from $SERVICE_HOST which is set to\n127.0.0.1 in the gate.\n\n""Ephemeral (client) ports will *never* be sourced from 0.0.0.0, and are\nuniquely identified by the full connection five-tuple (proto, src IP,\nsrc port, dst IP, dst port) anyway, allowing them to overlap src IP/src\nport as long as proto/dst IP/dst port are different. Thus it is up to\nkeystone/devstack to bind more appropriately and not use wildcard bind\naddresses unless explicitly necessary for some reason. For example, in\nthe log output, the URLs are configured with dst IPs of 127.0.0.1\nanyway, so binding explicitly to localhost would change nothing, while\nskirting this particular edge case nicely."" ~Evan Callicoat\n\nCo-Authored-By: Joe Gordon <joe.gordon0@gmail.com>\nChange-Id: I112309661dadf8b753c3311182f82464d9d3595e\nFixes-bug: 1253482\n'}, {'number': 4, 'created': '2014-01-30 01:49:56.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6c57fbab26e40af5c5b19b46fb3da39341f34dab', 'message': 'Set keystone admin_bind_host to KEYSTONE_SERVICE_HOST\n\nOn Linux ports 32768-61000 can be used by just about\nanything needing a socket. Keystone\'s IANA assigned port is 35357.\nOccasionally something else will be using port 35357 first because Linux\nallows this. Workaround is to bind to port 127.0.0.1 instead of 0.0.0.0.\n$KEYSTONE_SERVICE_HOST gets its value from $SERVICE_HOST which is set to\n127.0.0.1 in the gate.\n\n""Ephemeral (client) ports will *never* be sourced from 0.0.0.0, and are\nuniquely identified by the full connection five-tuple (proto, src IP,\nsrc port, dst IP, dst port) anyway, allowing them to overlap src IP/src\nport as long as proto/dst IP/dst port are different. Thus it is up to\nkeystone/devstack to bind more appropriately and not use wildcard bind\naddresses unless explicitly necessary for some reason. For example, in\nthe log output, the URLs are configured with dst IPs of 127.0.0.1\nanyway, so binding explicitly to localhost would change nothing, while\nskirting this particular edge case nicely."" ~Evan Callicoat\n\nThis doesn\'t fix bug 1253482 it works around it while a better solution\nis prepared (running keystone behind apache in devstack).\n\nCo-Authored-By: Joe Gordon <joe.gordon0@gmail.com>\nChange-Id: I112309661dadf8b753c3311182f82464d9d3595e\nRelated-bug: #1253482\n'}]",2,57577,6c57fbab26e40af5c5b19b46fb3da39341f34dab,35,11,4,4146,,,0,"Set keystone admin_bind_host to KEYSTONE_SERVICE_HOST

On Linux ports 32768-61000 can be used by just about
anything needing a socket. Keystone's IANA assigned port is 35357.
Occasionally something else will be using port 35357 first because Linux
allows this. Workaround is to bind to port 127.0.0.1 instead of 0.0.0.0.
$KEYSTONE_SERVICE_HOST gets its value from $SERVICE_HOST which is set to
127.0.0.1 in the gate.

""Ephemeral (client) ports will *never* be sourced from 0.0.0.0, and are
uniquely identified by the full connection five-tuple (proto, src IP,
src port, dst IP, dst port) anyway, allowing them to overlap src IP/src
port as long as proto/dst IP/dst port are different. Thus it is up to
keystone/devstack to bind more appropriately and not use wildcard bind
addresses unless explicitly necessary for some reason. For example, in
the log output, the URLs are configured with dst IPs of 127.0.0.1
anyway, so binding explicitly to localhost would change nothing, while
skirting this particular edge case nicely."" ~Evan Callicoat

This doesn't fix bug 1253482 it works around it while a better solution
is prepared (running keystone behind apache in devstack).

Co-Authored-By: Joe Gordon <joe.gordon0@gmail.com>
Change-Id: I112309661dadf8b753c3311182f82464d9d3595e
Related-bug: #1253482
",git fetch https://review.opendev.org/openstack/devstack refs/changes/77/57577/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,d83362890f654c4c69302f8f8e931a50882d83dc,bug/1253482,KEYSTONE_AUTH_PORT=${KEYSTONE_AUTH_PORT:-32357} KEYSTONE_AUTH_PORT_INT=${KEYSTONE_AUTH_PORT_INT:-32358},KEYSTONE_AUTH_PORT=${KEYSTONE_AUTH_PORT:-35357} KEYSTONE_AUTH_PORT_INT=${KEYSTONE_AUTH_PORT_INT:-35358},2,2
openstack%2Fnova~master~I5fb1bbd56035792f566a6e076edfe7a69df006ef,openstack/nova,master,I5fb1bbd56035792f566a6e076edfe7a69df006ef,Failure during termination should always leave state as Error(Deleting),MERGED,2013-11-27 17:45:29.000000000,2014-01-31 02:08:18.000000000,2014-01-31 02:08:14.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 4395}, {'_account_id': 5652}, {'_account_id': 7461}, {'_account_id': 7532}]","[{'number': 1, 'created': '2013-11-27 17:45:29.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/63381a15ac3c2e36f5521f8a77108664f89bfab5', 'message': ""Failure during termination should always leave state as Error(Deleting)\n\nDelete is a non-reversible operation for the user, and once the\nuser has indicated that they want to delete the instance from that\npoint on is the system's problem to complete the delete as soon as\npossible.\n\nIf anything fails during the delete that the system cannot recover\nfrom then the instance should be left in an Error(Deleting) state.\nAnything else, in particular reverting to an Active(None) state, makes\nit look like the system has ignored the request.\n\nCurrently InstanceTerminationFailure is explicitly caught, but the\nexception does not propagate so the instance_fault wrapper does not\nget a chance to log the failure.  Also terminate_instance is wrapped\nby reverts_task_state which resets the state to Active(None)\n\nThis change removes the revert_task_state wrapper and catches all\nexceptions so that unhandled exceptions always leave the instance\nin Error(Deleting)\n\nChange-Id: I5fb1bbd56035792f566a6e076edfe7a69df006ef\nCloses-Bug: 1254122\n""}]",3,58829,63381a15ac3c2e36f5521f8a77108664f89bfab5,15,9,1,1501,,,0,"Failure during termination should always leave state as Error(Deleting)

Delete is a non-reversible operation for the user, and once the
user has indicated that they want to delete the instance from that
point on is the system's problem to complete the delete as soon as
possible.

If anything fails during the delete that the system cannot recover
from then the instance should be left in an Error(Deleting) state.
Anything else, in particular reverting to an Active(None) state, makes
it look like the system has ignored the request.

Currently InstanceTerminationFailure is explicitly caught, but the
exception does not propagate so the instance_fault wrapper does not
get a chance to log the failure.  Also terminate_instance is wrapped
by reverts_task_state which resets the state to Active(None)

This change removes the revert_task_state wrapper and catches all
exceptions so that unhandled exceptions always leave the instance
in Error(Deleting)

Change-Id: I5fb1bbd56035792f566a6e076edfe7a69df006ef
Closes-Bug: 1254122
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/58829/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,63381a15ac3c2e36f5521f8a77108664f89bfab5,bug/1254122," self.assertRaises(exception.InstanceTerminationFailure, self.compute.terminate_instance, self.context, self._objectify(instance), [], [])"," self.compute.terminate_instance(self.context, self._objectify(instance), [], []) (""terminate_instance"", task_states.DELETING, {'bdms': [], 'reservations': []}),",14,12
openstack%2Ftempest~master~I04977f955ed6a4575fea17b8e97b675a483cc7a9,openstack/tempest,master,I04977f955ed6a4575fea17b8e97b675a483cc7a9,Fixed up an error message,MERGED,2014-01-28 11:08:58.000000000,2014-01-31 02:06:21.000000000,2014-01-31 02:06:20.000000000,"[{'_account_id': 3}, {'_account_id': 1839}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 6348}, {'_account_id': 6509}, {'_account_id': 7872}]","[{'number': 1, 'created': '2014-01-28 11:08:58.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0df88bb64d103f07e85f88bd38b5e7734e6259ac', 'message': 'Fixed up an error message\n\nRemoved the comma and added spaces\n\nChange-Id: I04977f955ed6a4575fea17b8e97b675a483cc7a9\n'}]",2,69577,0df88bb64d103f07e85f88bd38b5e7734e6259ac,11,7,1,8478,,,0,"Fixed up an error message

Removed the comma and added spaces

Change-Id: I04977f955ed6a4575fea17b8e97b675a483cc7a9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/77/69577/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,0df88bb64d103f07e85f88bd38b5e7734e6259ac,," raise RuntimeError(""tearDownClass does not call the super's "" ""exception please do not report this one! "" ""If you are changing tempest code, make sure you """," raise RuntimeError(""tearDownClass does not calls the super's "" ""exception please do not report this one!"" ""If you are changing tempest code, make sure you"",",3,3
openstack%2Ftempest~master~Ie96f88434563e50de4862358be068b975b07cb05,openstack/tempest,master,Ie96f88434563e50de4862358be068b975b07cb05,Add alias as prefix for flavor_rxtx v3,MERGED,2014-01-29 08:55:19.000000000,2014-01-31 01:54:15.000000000,2014-01-31 01:54:14.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 7882}, {'_account_id': 8085}]","[{'number': 1, 'created': '2014-01-29 08:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/578cf26f079de74e4bfb0d848239981d22013661', 'message': 'Add alias as prefix for flavor_rxtx v3\n\nAs v3 api rules, the extended attribute should be with extension\nalias as prefix. So fix this case for flavor-rxtx v3 extension.\n\nChange-Id: Ie96f88434563e50de4862358be068b975b07cb05\nCloses-bug: 1252986\n'}, {'number': 2, 'created': '2014-01-30 05:31:26.000000000', 'files': ['tempest/services/compute/v3/json/flavors_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1bd022d0d297f1a24cfa94f5cd78dca8f3593f0e', 'message': 'Add alias as prefix for flavor_rxtx v3\n\nAs v3 api rules, the extended attribute should be with extension\nalias as prefix. So fix this case for flavor-rxtx v3 extension.\n\nChange-Id: Ie96f88434563e50de4862358be068b975b07cb05\nRelated-Bug: #1226732\n'}]",2,69813,1bd022d0d297f1a24cfa94f5cd78dca8f3593f0e,14,6,2,7882,,,0,"Add alias as prefix for flavor_rxtx v3

As v3 api rules, the extended attribute should be with extension
alias as prefix. So fix this case for flavor-rxtx v3 extension.

Change-Id: Ie96f88434563e50de4862358be068b975b07cb05
Related-Bug: #1226732
",git fetch https://review.opendev.org/openstack/tempest refs/changes/13/69813/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/compute/v3/json/flavors_client.py'],1,578cf26f079de74e4bfb0d848239981d22013661,bug/1252986, post_body['os-flavor-rxtx:rxtx_factor'] = kwargs.get('rxtx'), post_body['rxtx_factor'] = kwargs.get('rxtx'),1,1
openstack%2Ftempest~master~I1bd53d99f2632441ebf648cb0c2929c9b55998b6,openstack/tempest,master,I1bd53d99f2632441ebf648cb0c2929c9b55998b6,Remove network resources created in scenario tests,MERGED,2014-01-30 17:16:16.000000000,2014-01-31 01:54:06.000000000,2014-01-31 01:54:05.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-30 17:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d3f8084efc78863c811a3791ed61f5c0dae9e217', 'message': 'Remove network resources created in scenario tests\n\nChange-Id: I1bd53d99f2632441ebf648cb0c2929c9b55998b6\nCloses-Bug: #1274410\n'}, {'number': 2, 'created': '2014-01-30 18:57:18.000000000', 'files': ['tempest/common/isolated_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf996c653bef62f2ae71331cf45323e5f183b2be', 'message': 'Remove network resources created in scenario tests\n\nChange-Id: I1bd53d99f2632441ebf648cb0c2929c9b55998b6\nCloses-Bug: #1274410\n'}]",0,70169,cf996c653bef62f2ae71331cf45323e5f183b2be,16,6,2,261,,,0,"Remove network resources created in scenario tests

Change-Id: I1bd53d99f2632441ebf648cb0c2929c9b55998b6
Closes-Bug: #1274410
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/70169/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/isolated_creds.py'],1,d3f8084efc78863c811a3791ed61f5c0dae9e217,bug1274410," LOG.debug(""Clearing network: %(network)s, "" ""subnet: %(subnet)s, router: %(router)s"", {'network': network, 'subnet': subnet, 'router': router}) if (not self.network_resources or self.network_resources.get('router')): if (not self.network_resources or self.network_resources.get('network')): if (not self.network_resources or self.network_resources.get('subnet')): if (not self.network_resource or self.network_resources.get('network')):", if self.network_resources.get('router'): if self.network_resources.get('network'): if self.network_resources.get('subnet'): if self.network_resources.get('network'):,11,4
openstack%2Fheat~master~Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628,openstack/heat,master,Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628,Purge remaining heat_keystoneclient v2 code,MERGED,2014-01-17 17:46:37.000000000,2014-01-31 01:53:58.000000000,2014-01-31 01:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-01-17 17:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3ed77f5ce9a1518b934bf73989fcc68c236bd2c', 'message': 'Purge remaining heat_keystoneclient v2 code\n\nRemoves the remaining v2 specific code, and converts the trust\nhandling code to use only the v3 client.\n\nThis completes the keystone-v3-only blueprint.\n\nblueprint: keystone-v3-only\nChange-Id: Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628\n'}, {'number': 2, 'created': '2014-01-23 15:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/18f5e8fa1c5a24e1dc3feadc8a1d17ae5c1774d2', 'message': 'Purge remaining heat_keystoneclient v2 code\n\nRemoves the remaining v2 specific code, and converts the trust\nhandling code to use only the v3 client.\n\nThis completes the keystone-v3-only blueprint.\n\nblueprint: keystone-v3-only\nChange-Id: Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628\n'}, {'number': 3, 'created': '2014-01-28 10:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e17391192c80535c1dc17c8431f7a0aba166afc', 'message': 'Purge remaining heat_keystoneclient v2 code\n\nRemoves the remaining v2 specific code, and converts the trust\nhandling code to use only the v3 client.\n\nThis completes the keystone-v3-only blueprint.\n\nblueprint: keystone-v3-only\nChange-Id: Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628\n'}, {'number': 4, 'created': '2014-01-29 14:08:40.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d67b23a33d8cc50eb9c7526294de5b476d75e4f3', 'message': 'Purge remaining heat_keystoneclient v2 code\n\nRemoves the remaining v2 specific code, and converts the trust\nhandling code to use only the v3 client.\n\nThis completes the keystone-v3-only blueprint.\n\nblueprint: keystone-v3-only\nChange-Id: Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628\n'}]",2,67534,d67b23a33d8cc50eb9c7526294de5b476d75e4f3,26,5,4,4328,,,0,"Purge remaining heat_keystoneclient v2 code

Removes the remaining v2 specific code, and converts the trust
handling code to use only the v3 client.

This completes the keystone-v3-only blueprint.

blueprint: keystone-v3-only
Change-Id: Iac5b7dd73f5827cc5247a3b71d63a0f5ea266628
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/67534/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,c3ed77f5ce9a1518b934bf73989fcc68c236bd2c,bp/instance-users,"from keystoneclient.v3 import client as kc_v3 def _stubs_v3(self, method='token', auth_ok=True, trust_scoped=True, user_id='trustor_user_id', mock_client=True): if mock_client: self.m.StubOutClassWithMocks(kc_v3, ""Client"") self.mock_ks_v3_client = kc_v3.Client( self.mock_ks_v3_client = kc_v3.Client( self.mock_ks_v3_client = kc_v3.Client( trust_id='atrust123', self.mock_ks_v3_client.auth_ref.trust_scoped = trust_scoped self.mock_ks_v3_client.auth_ref.auth_token = 'atrusttoken' self.mock_ks_v3_client.authenticate().AndReturn(auth_ok) self._stubs_v3(method='trust') self.m.StubOutClassWithMocks(kc_v3, ""Client"") mock_admin_client = kc_v3.Client( project_name='service') self._stubs_v3(mock_client=False) self._stubs_v3(method='trust') self.assertIsNotNone(heat_ks_client.client_v3) self._stubs_v3(method='trust', trust_scoped=False) self._stubs_v3(method='trust', user_id='wrong_user_id') self._stubs_v3(method='trust') self.assertIsNotNone(heat_ks_client._client_v3) self._stubs_v3(method='trust') self.assertIsNotNone(heat_ks_client._client_v3)"," def _stubs_v2(self, method='token', auth_ok=True, trust_scoped=True, user_id='trustor_user_id'): self.m.StubOutClassWithMocks(heat_keystoneclient.kc, ""Client"") if method == 'token': self.mock_ks_client = heat_keystoneclient.kc.Client( auth_url=mox.IgnoreArg(), tenant_name='test_tenant', token='abcd1234', cacert=None, cert=None, insecure=False, key=None) self.mock_ks_client.authenticate().AndReturn(auth_ok) elif method == 'password': self.mock_ks_client = heat_keystoneclient.kc.Client( auth_url=mox.IgnoreArg(), tenant_name='test_tenant', tenant_id='test_tenant_id', username='test_username', password='password', cacert=None, cert=None, insecure=False, key=None) self.mock_ks_client.authenticate().AndReturn(auth_ok) if method == 'trust': self.mock_ks_client = heat_keystoneclient.kc.Client( auth_url='http://server.test:5000/v2.0', password='verybadpass', tenant_name='service', username='heat', cacert=None, cert=None, insecure=False, key=None) self.mock_ks_client.authenticate(trust_id='atrust123', tenant_id='test_tenant_id' ).AndReturn(auth_ok) self.mock_ks_client.auth_ref = self.m.CreateMockAnything() self.mock_ks_client.auth_ref.trust_scoped = trust_scoped self.mock_ks_client.auth_ref.auth_token = 'atrusttoken' self.mock_ks_client.auth_ref.user_id = user_id def _stubs_v3(self, method='token', auth_ok=True, user_id=None): self.m.StubOutClassWithMocks(heat_keystoneclient.kc_v3, ""Client"") self.mock_ks_v3_client = heat_keystoneclient.kc_v3.Client( self.mock_ks_v3_client = heat_keystoneclient.kc_v3.Client( self.mock_ks_v3_client = heat_keystoneclient.kc_v3.Client( self.mock_ks_v3_client.authenticate().AndReturn(auth_ok) if user_id: def test_init_v2_password(self): """"""Test creating the client, user/password context."""""" self._stubs_v2(method='password') self.m.ReplayAll() ctx = utils.dummy_context() ctx.auth_token = None ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertIsNotNone(heat_ks_client.client_v2) self.assertIsNone(heat_ks_client._client_v3) def test_init_v2_bad_nocreds(self): """"""Test creating the client without trusts, no credentials."""""" ctx = utils.dummy_context() ctx.auth_token = None ctx.username = None ctx.password = None ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertRaises(exception.AuthorizationFailure, heat_ks_client._v2_client_init) self.assertIsNone(heat_ks_client._client_v2) self.assertIsNone(heat_ks_client._client_v2) self._stubs_v2(method='trust') self.m.StubOutClassWithMocks(heat_keystoneclient.kc, ""Client"") mock_admin_client = heat_keystoneclient.kc.Client( tenant_name='service') self._stubs_v3() self._stubs_v2(method='trust') client_v2 = heat_ks_client.client_v2 self.assertIsNotNone(client_v2) self._stubs_v2(method='trust', trust_scoped=False) self._stubs_v2(method='trust', user_id='wrong_user_id') self._stubs_v2(method='trust') self.assertIsNotNone(heat_ks_client._client_v2) self.assertIsNone(heat_ks_client._client_v3) self._stubs_v2(method='trust') self.assertIsNotNone(heat_ks_client._client_v2) self.assertIsNone(heat_ks_client._client_v3)",66,190
openstack%2Fnova~master~I7ae971469585f072cd039f30faf71a4d48c9fd04,openstack/nova,master,I7ae971469585f072cd039f30faf71a4d48c9fd04,Make fixed_ip_get_by_address() take columns_to_join,MERGED,2014-01-16 16:15:22.000000000,2014-01-31 01:36:31.000000000,2014-01-31 01:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-16 16:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b58fd7644da2b22205ea7a590a6ce98d77f63da7', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 2, 'created': '2014-01-16 18:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2254fd5a347cce171ed8e6d5115fa4cafebc68d0', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 3, 'created': '2014-01-16 20:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac03bcaf116bc751f11353289a032a7742cf65cf', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 4, 'created': '2014-01-17 15:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b44990f290b385f5b97c74eca8bfbdf7f93b910b', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 5, 'created': '2014-01-17 16:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2e451aa15572081a15ab14716af3ac3f63151cb', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 6, 'created': '2014-01-20 16:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42e944e281a3a307516a8b4fcffd299b92226120', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 7, 'created': '2014-01-27 16:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff2191efefe7c9470322ba04c63070a272105202', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 8, 'created': '2014-01-28 18:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/322bff6441ee6606577ad15019dc574b2530d49f', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}, {'number': 9, 'created': '2014-01-30 17:29:39.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4963265c6c5da95647ef80a7ef8685c3249cb866', 'message': 'Make fixed_ip_get_by_address() take columns_to_join\n\nThis will let the FixedIP object make some significantly more\nefficient queries by asking for network and/or instance at the\nsame times as the FixedIP itself.\n\nRelated to nova-network-objects\n\nChange-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04\n'}]",0,67207,4963265c6c5da95647ef80a7ef8685c3249cb866,49,7,9,4393,,,0,"Make fixed_ip_get_by_address() take columns_to_join

This will let the FixedIP object make some significantly more
efficient queries by asking for network and/or instance at the
same times as the FixedIP itself.

Related to nova-network-objects

Change-Id: I7ae971469585f072cd039f30faf71a4d48c9fd04
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/67207/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",3,b58fd7644da2b22205ea7a590a6ce98d77f63da7,bp/nova-network-objects,"def fixed_ip_get_by_address(context, address, columns_to_join=None): return _fixed_ip_get_by_address(context, address, columns_to_join=columns_to_join) def _fixed_ip_get_by_address(context, address, session=None, columns_to_join=None): if columns_to_join is None: columns_to_join = [] result = model_query(context, models.FixedIp, session=session) for column in columns_to_join: result = result.options(joinedload_all(column)) result = result.filter_by(address=address).first()","def fixed_ip_get_by_address(context, address): return _fixed_ip_get_by_address(context, address) def _fixed_ip_get_by_address(context, address, session=None): result = model_query(context, models.FixedIp, session=session).\ filter_by(address=address).\ first()",24,8
openstack%2Fnova~master~I4764fa0bfca355377d2642ddf3fbfe17cf5b761e,openstack/nova,master,I4764fa0bfca355377d2642ddf3fbfe17cf5b761e,Refactor return value of fixed_ip_associate calls,MERGED,2014-01-16 16:15:21.000000000,2014-01-31 01:35:37.000000000,2014-01-31 01:35:34.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-16 16:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a64047062026d7c205a933d2be32142e736e09de', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 2, 'created': '2014-01-16 18:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b5221d83b8d7a8674ed02cb503ca131cfe30565', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 3, 'created': '2014-01-16 20:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/848ba1d55da43c688550e594921ef16192ba32de', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 4, 'created': '2014-01-17 15:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89741643ddeb3b345d3189b6844da754f5834bfd', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 5, 'created': '2014-01-17 16:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a6f72ac00295a51a298b3bd58798e6a5ba51908', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 6, 'created': '2014-01-20 16:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b3a362a647bfd8bcd1155b90b5cae88661b912c', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 7, 'created': '2014-01-27 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f33175dbea6b9510bc6723617c76c779d89b15d', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 8, 'created': '2014-01-27 23:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9887ef6dd714ee99e5d54b48b1eec230ff1eba82', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 9, 'created': '2014-01-28 15:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/225f8ade11d8620b82aec3a5371c6d47c9cad01b', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}, {'number': 10, 'created': '2014-01-30 17:29:33.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0185a36c40259c47d2647ba1dd5275f4088e525d', 'message': 'Refactor return value of fixed_ip_associate calls\n\nThis makes the fixed_ip_associate* calls more object-friendly.\nRather few things outside of the tests care about the return value of\nthese methods, so this is less invasive than it looks. All of the\ntests and manager methods that this touches will be replaced\nas part of the objectification going forward, so this is only\ntransitional.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e\n'}]",4,67206,0185a36c40259c47d2647ba1dd5275f4088e525d,45,7,10,4393,,,0,"Refactor return value of fixed_ip_associate calls

This makes the fixed_ip_associate* calls more object-friendly.
Rather few things outside of the tests care about the return value of
these methods, so this is less invasive than it looks. All of the
tests and manager methods that this touches will be replaced
as part of the objectification going forward, so this is only
transitional.

Related to blueprint nova-network-objects

Change-Id: I4764fa0bfca355377d2642ddf3fbfe17cf5b761e
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/67206/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py', 'nova/db/sqlalchemy/api.py']",3,a64047062026d7c205a933d2be32142e736e09de,bp/nova-network-objects, return fixed_ip_ref return fixed_ip_ref, return fixed_ip_ref['address'] return fixed_ip_ref['address'],35,21
openstack%2Fnova~master~If45020b8264f05b12657bb27f836b9fc60964cd1,openstack/nova,master,If45020b8264f05b12657bb27f836b9fc60964cd1,Make nova-network use Network object for deleting networks,MERGED,2014-01-15 16:06:15.000000000,2014-01-31 01:33:24.000000000,2014-01-31 01:33:21.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-15 16:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/710ef4da7285c3750e5dae8b55aa0dca5a426586', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 2, 'created': '2014-01-16 16:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b63c32bf85a9c783dffc1629d97896552e582d58', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 3, 'created': '2014-01-16 18:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a7ed3f1371a2439e001cbe7356412c1356c2b93', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 4, 'created': '2014-01-16 20:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/128ea19ba01ff85ba17af96a7e338224a7fd6216', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 5, 'created': '2014-01-17 15:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6719eb45a1f5cf0bb32f062ba56a6dc89a3b478', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 6, 'created': '2014-01-17 16:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53f37e7dbfec283c910ed0fe9e68276797d505ac', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 7, 'created': '2014-01-20 16:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eee4258694ec6525efb8df7755d19b12b55c547b', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 8, 'created': '2014-01-27 16:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba68727b46272c4631c918a6e09722211a33754b', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 9, 'created': '2014-01-27 23:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20f5e2a0f4c9d169d54d8077d9177f4f3fcfcc98', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 10, 'created': '2014-01-28 15:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7613819c887ec646d639f8b1196044ee3d0a1587', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}, {'number': 11, 'created': '2014-01-30 17:28:59.000000000', 'files': ['nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5cbdf649aaa6990c3b9ce59772af1949d0e4d20f', 'message': ""Make nova-network use Network object for deleting networks\n\nThis makes nova-network manager use the Network object when\ndeleting networks. Since it results in the same underlying call\nto the database, it doesn't affect tests at all.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: If45020b8264f05b12657bb27f836b9fc60964cd1\n""}]",1,66885,5cbdf649aaa6990c3b9ce59772af1949d0e4d20f,63,9,11,4393,,,0,"Make nova-network use Network object for deleting networks

This makes nova-network manager use the Network object when
deleting networks. Since it results in the same underlying call
to the database, it doesn't affect tests at all.

Related to blueprint nova-network-objects

Change-Id: If45020b8264f05b12657bb27f836b9fc60964cd1
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/66885/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,710ef4da7285c3750e5dae8b55aa0dca5a426586,bp/nova-network-objects, network.delete()," self.db.network_delete_safe(context, network.id)",1,1
openstack%2Ftripleo-image-elements~master~I50ee5721a123ae760797816fb759dd6540df8ad4,openstack/tripleo-image-elements,master,I50ee5721a123ae760797816fb759dd6540df8ad4,Move heat-manage call to heat-engine,MERGED,2014-01-30 23:31:29.000000000,2014-01-31 01:15:29.000000000,2014-01-31 01:15:29.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-30 23:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f9b2bac9131f14ecbacf12055aa7ee82e7152324', 'message': 'Add set -e to heat-api script\n\nWithout set -e, if heat-manage db_sync fails it will be ignored and\nos-collect-config will appear to have completed successfully.\n\nChange-Id: I50ee5721a123ae760797816fb759dd6540df8ad4\n'}, {'number': 2, 'created': '2014-01-30 23:54:33.000000000', 'files': ['elements/heat-engine/os-refresh-config/post-configure.d/79-heat-engine', 'elements/heat-engine/install.d/heat-source-install/10-heat-engine', 'elements/heat-api/os-refresh-config/post-configure.d/79-heat-api', 'elements/heat-api/install.d/heat-source-install/10-heat-api'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/72eae28b16a423514975d875b4f4454cc9ba88f3', 'message': ""Move heat-manage call to heat-engine\n\nheat-api doesn't actually care about calling heat-manage db_sync,\nso move it to heat-engine, which does.\n\nAlso add set -e on the script so errors from heat-manage are caught.\n\nChange-Id: I50ee5721a123ae760797816fb759dd6540df8ad4\n""}]",0,70255,72eae28b16a423514975d875b4f4454cc9ba88f3,8,5,2,6928,,,0,"Move heat-manage call to heat-engine

heat-api doesn't actually care about calling heat-manage db_sync,
so move it to heat-engine, which does.

Also add set -e on the script so errors from heat-manage are caught.

Change-Id: I50ee5721a123ae760797816fb759dd6540df8ad4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/55/70255/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/heat-api/os-refresh-config/post-configure.d/79-heat-api'],1,f9b2bac9131f14ecbacf12055aa7ee82e7152324,heat-manage,set -e ,,2,0
openstack%2Fnova~master~Ia1615a83af102a527d82c4b22e1dcec2e9364c28,openstack/nova,master,Ia1615a83af102a527d82c4b22e1dcec2e9364c28,Make nova-network use Network for associations,MERGED,2014-01-15 15:50:55.000000000,2014-01-31 00:39:34.000000000,2014-01-31 00:39:30.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-15 15:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27ac18f2f643466967c5bdbf354f7a690a423347', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 2, 'created': '2014-01-16 16:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69e2a0f51a2c709bbfd0429b6654b43846d633dd', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 3, 'created': '2014-01-16 18:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d227b29b4fb2bc0084740abc9610e1c89be7451', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 4, 'created': '2014-01-16 20:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11070e43a6e7a77c4872024bd840b0872882a6ca', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 5, 'created': '2014-01-17 15:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bacb2b409d3a1badd6167162921bccb34c42651c', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 6, 'created': '2014-01-17 16:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/daeb0d7c4aa475cf720f2c2735433d5e923cdbfc', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 7, 'created': '2014-01-20 16:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/674444395560f6026e1d5ec5910e8c99cbdb0f6e', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 8, 'created': '2014-01-27 16:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/090a3d5f591ad5ea793cbb7c747a3d27d75d220d', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 9, 'created': '2014-01-28 15:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6cf1c521bfd8d1fde207ccc0cda1114b50d12f1', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}, {'number': 10, 'created': '2014-01-30 17:29:42.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/69f5965a84d2134b242dbe7f04b8167ff95848f4', 'message': 'Make nova-network use Network for associations\n\nThis makes nova-network use the Network object for associate\nand disassociate operations instead of direct database calls.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28\n'}]",2,66877,69f5965a84d2134b242dbe7f04b8167ff95848f4,62,8,10,4393,,,0,"Make nova-network use Network for associations

This makes nova-network use the Network object for associate
and disassociate operations instead of direct database calls.

Related to blueprint nova-network-objects

Change-Id: Ia1615a83af102a527d82c4b22e1dcec2e9364c28
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/66877/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,27ac18f2f643466967c5bdbf354f7a690a423347,bp/nova-network-objects," @mock.patch('nova.db.network_disassociate') def test_disassociate_network(self, disassociate, get): disassociate.return_value = True"," def test_disassociate_network(self, get):",12,11
openstack%2Fnova~master~I109aa8fe3589100cf32a40ce90f7b28ca2e5440a,openstack/nova,master,I109aa8fe3589100cf32a40ce90f7b28ca2e5440a,Make nova-network use Network object for set_host() operation,MERGED,2014-01-14 21:03:27.000000000,2014-01-31 00:38:29.000000000,2014-01-31 00:38:26.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-14 21:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f135d61b1ffffc9b1131bbb27b62ee116012585', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 2, 'created': '2014-01-15 15:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1c87bd06628bcde1ff72fdb76839a0e0fb0a2d4', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 3, 'created': '2014-01-16 16:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bce67c8c70748aff4200492a81f69bc3be83ef1', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 4, 'created': '2014-01-16 18:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7caad41d3380e9fa1906b8831e642aac93011e90', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 5, 'created': '2014-01-16 20:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48b504ca608c2af1fc8794592d55c34802c77f78', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 6, 'created': '2014-01-17 15:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9742b4e70b708cfd52993645ddc93317ba95936', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 7, 'created': '2014-01-17 16:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/268bf7dcafe7ad32400f834d4b88e780cf1af94a', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 8, 'created': '2014-01-20 16:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f9d53c8b6d48fe6f737780b6ccb20882b278b5e', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 9, 'created': '2014-01-27 16:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/696cc2ebfbc8f1b6b7cbcdcc96822ee2c483773b', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 10, 'created': '2014-01-27 23:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7e2356a430dac362d3ccc24ba1b2603e5acc8bf', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 11, 'created': '2014-01-28 15:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dae652b0df3b8ab56cd655830d1bd680a37bdbf5', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}, {'number': 12, 'created': '2014-01-30 17:29:19.000000000', 'files': ['nova/tests/virt/xenapi/test_xenapi.py', 'nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3baaffe1fe0df4effa0af811a03b8dd3e63f3d49', 'message': 'Make nova-network use Network object for set_host() operation\n\nThis makes nova-network manager use the Network object instead\nof the direct-to-database call.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a\n'}]",1,66685,3baaffe1fe0df4effa0af811a03b8dd3e63f3d49,77,9,12,4393,,,0,"Make nova-network use Network object for set_host() operation

This makes nova-network manager use the Network object instead
of the direct-to-database call.

Related to blueprint nova-network-objects

Change-Id: I109aa8fe3589100cf32a40ce90f7b28ca2e5440a
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/66685/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,9f135d61b1ffffc9b1131bbb27b62ee116012585,bp/nova-network-objects," network_ref.host = self.host network_ref.save() return self.host network = self.get_network(context, network_uuid) network_id = network.id network.host = self.host network.save()"," host = self.db.network_set_host(context, network_ref['id'], self.host) return host network_id = self.get_network(context, network_uuid)['id'] self.db.network_set_host(context, network_id, host)",7,6
openstack%2Fnova~master~Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab,openstack/nova,master,Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab,Make nova-network use Network object for updates,MERGED,2014-01-14 20:22:22.000000000,2014-01-31 00:37:35.000000000,2014-01-31 00:37:31.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-14 20:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d88f9538aa4db78d6e974216068cc719495b068', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 2, 'created': '2014-01-15 15:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc2507be301211f58fe0080d232dccafc8938cfb', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 3, 'created': '2014-01-16 16:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a5e3eba5515003c4b1b3d8fd4777a861ab12edf', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 4, 'created': '2014-01-16 18:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3cdd8e5e3d3c905903ea5aeed929a71d417e4b1', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 5, 'created': '2014-01-16 20:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f50d8d739963a3ac2bbb7688c72bf82eff014af', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 6, 'created': '2014-01-17 15:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be3a51f592950a6d88b16b9e9424ef49f34c2dac', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 7, 'created': '2014-01-20 16:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37a8e79f6a2b68812d1827296c904ffc96744520', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 8, 'created': '2014-01-27 16:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce2a77e39008ba29045968e5f53a0efcad1484fb', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 9, 'created': '2014-01-27 23:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7a906d9d355f2681a608e795ce372176fca1daa', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 10, 'created': '2014-01-28 15:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cc35d3355ce76186af250c91932022101aae4fb', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}, {'number': 11, 'created': '2014-01-30 17:29:21.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a3994127e71b0c6efbcefbdf33c53d2902a6dbb8', 'message': 'Make nova-network use Network object for updates\n\nThis makes nova-network manager use the Network object (which is\nalready present in most places) for update operations, in the form\nof save().\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab\n'}]",5,66683,a3994127e71b0c6efbcefbdf33c53d2902a6dbb8,96,10,11,4393,,,0,"Make nova-network use Network object for updates

This makes nova-network manager use the Network object (which is
already present in most places) for update operations, in the form
of save().

Related to blueprint nova-network-objects

Change-Id: Icd1a41f1da67d08ecccf8ef9ebc5b9d1e7b28eab
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/66683/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,8d88f9538aa4db78d6e974216068cc719495b068,bp/nova-network-objects,"from nova.objects import network as network_obj network = network_obj.Network._from_db_object( self.context, network_obj.Network(), dict(test_network.fake_network, **networks[0])) network.vpn_private_address = '192.168.0.2' network = network_obj.Network._from_db_object( self.context, network_obj.Network(), dict(test_network.fake_network, **networks[0])) network.vpn_private_address = '192.168.0.2' new_network_obj = network_obj.Network._from_db_object( self.context, network_obj.Network(), dict(test_network.fake_network, **new_network)) net_manager._setup_network_on_host(ctxt, new_network_obj)"," network = dict(networks[0]) network['vpn_private_address'] = '192.168.0.2' network = dict(networks[0]) network['vpn_private_address'] = '192.168.0.2' net_manager._setup_network_on_host(ctxt, new_network)",26,18
openstack%2Ftrove~master~I71762baa095039f65e97b3413a7ff0fc3e0014ec,openstack/trove,master,I71762baa095039f65e97b3413a7ff0fc3e0014ec,Fix default_datastore migration script,MERGED,2014-01-28 04:52:06.000000000,2014-01-31 00:35:12.000000000,2014-01-31 00:35:12.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-01-28 04:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/524b1461b1d4d16e0fc84de8fc53e1db27649445', 'message': 'Fix default_datastore migration script\n\nFixes the migration script introduced earlier to remove\ndependencies on the Trove database model classes.\n\nChange-Id: I71762baa095039f65e97b3413a7ff0fc3e0014ec\nCloses-Bug: 1259642\n'}, {'number': 2, 'created': '2014-01-29 18:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8da85a4d461aca1b53b2f75eb09bd99f167a2adb', 'message': 'Fix default_datastore migration script\n\nFixes the migration script introduced earlier to remove\ndependencies on the Trove database model classes.\n\nChange-Id: I71762baa095039f65e97b3413a7ff0fc3e0014ec\nCloses-Bug: 1259642\n'}, {'number': 3, 'created': '2014-01-29 18:05:20.000000000', 'files': ['trove/db/sqlalchemy/migrate_repo/versions/019_datastore_fix.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/8fa6f56c502784b00333c0f3fe69760f680bacef', 'message': 'Fix default_datastore migration script\n\nFixes the migration script introduced earlier to remove\ndependencies on the Trove database model classes.\n\nChange-Id: I71762baa095039f65e97b3413a7ff0fc3e0014ec\nCloses-Bug: 1259642\n'}]",5,69537,8fa6f56c502784b00333c0f3fe69760f680bacef,28,9,3,1925,,,0,"Fix default_datastore migration script

Fixes the migration script introduced earlier to remove
dependencies on the Trove database model classes.

Change-Id: I71762baa095039f65e97b3413a7ff0fc3e0014ec
Closes-Bug: 1259642
",git fetch https://review.opendev.org/openstack/trove refs/changes/37/69537/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/db/sqlalchemy/migrate_repo/versions/019_datastore_fix.py'],1,524b1461b1d4d16e0fc84de8fc53e1db27649445,bug/1259642,"from sqlalchemy.sql.expression import insert from sqlalchemy.sql.expression import updatedef migrate_datastore_version(datastores_table, datastore_versions_table, image_id): datastore = select( columns=[""id"", ""name"", ""manager""], from_obj=datastores_table, whereclause=""manager='mysql'"", limit=1 ).execute().fetchone() if not datastore: datastore_id = ""10000000-0000-0000-0000-000000000001"" datastore = insert( table=datastores_table, values=dict(id=datastore_id, name=""Legacy MySQL"", manager=""mysql"") ).execute() version_id = ""20000000-0000-0000-0000-000000000002"" insert( table=datastore_versions_table, values=dict(id=version_id, datastore_id=datastore.id, name=""Unknown Legacy Version"", image_id=image_id, active=False) ).execute() return version_id def find_image(service_name): image_table = Table('service_images', meta, autoload=True) image = select( columns=[""id"", ""image_id"", ""service_name""], from_obj=image_table, whereclause=""service_name='%s'"" % service_name, limit=1 ).execute().fetchone() return image def find_all_instances_wo_datastore_version(instances_table): instances = select( columns=[""id""], from_obj=instances_table, whereclause=""datastore_version_id = NULL"" ).execute() return instances instances = find_all_instances_wo_datastore_version(instance_table) if instances.rowcount > 0: image = find_image(""mysql"") datastores_table = Table('datastores', meta, autoload=True) datastore_versions_table = Table('datastore_versions', meta, autoload=True) version_id = migrate_datastore_version(datastores_table, datastore_versions_table, image_id) update( table=instance_table, whereclause=""id='%s'"" % instance.id, values=dict(datastore_version_id=version_id) ).execute()","from trove.datastore.models import DBDatastore from trove.datastore.models import DBDatastoreVersion from trove.db.sqlalchemy import sessionfrom trove.instance.models import DBInstance session.configure_db(CONF) instances = DBInstance.find_all(datastore_version_id=None) if instances.count() > 0: datastore = DBDatastore.get_by(manager=""mysql"") datastore = datastore or DBDatastore.create( name=""Legacy MySQL"", manager=""mysql"", ) image_table = Table('service_images', meta, autoload=True) image = select( columns=[""id"", ""image_id"", ""service_name""], from_obj=image_table, whereclause=""service_name='mysql'"", limit=1 ).execute().fetchone() version = DBDatastoreVersion.create( datastore_id=datastore.id, name=""Unknown Legacy Version"", image_id=image_id, active=False, ) instance.update_db(datastore_version_id=version.id)",72,27
openstack%2Fnova~master~I6b1764e3c95337982cf4fbf503ddcb755e33cf2b,openstack/nova,master,I6b1764e3c95337982cf4fbf503ddcb755e33cf2b,"Make nova-network use Network object for remaining ""get"" queries",MERGED,2014-01-14 19:06:02.000000000,2014-01-31 00:34:16.000000000,2014-01-31 00:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-14 19:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da0a13cb1ee58a64da26c757bfa20beece5d912c', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 2, 'created': '2014-01-15 15:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8e67dac1cd3bc67a77b6683a9faa0422192aa81', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 3, 'created': '2014-01-16 16:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4dee8c94ce5a9a2355fdcfb600ba2d58d4da9da', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 4, 'created': '2014-01-16 18:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff65c4d66f51f5fe1eea4f076d5bcf7ce60b91c6', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 5, 'created': '2014-01-16 20:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7b3c0ed52a6c02aafd5886bb7f667796a7ecbe0', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 6, 'created': '2014-01-17 15:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff1d58daf496e3db09121e63dab77d6ec420c9e5', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 7, 'created': '2014-01-20 16:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/641ec537e6f65e2ab8938ee12809c882f197f45f', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 8, 'created': '2014-01-27 16:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9c753823a0b2e635657884427b92155ab5779e6', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 9, 'created': '2014-01-27 23:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42a7eed9580b2e84e78bf42d5b5fd8eff199079a', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 10, 'created': '2014-01-28 15:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9ffb3decafc59848f64830e20765b046c6770bf', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}, {'number': 11, 'created': '2014-01-30 17:29:36.000000000', 'files': ['nova/tests/test_nova_manage.py', 'nova/tests/fake_network.py', 'nova/network/manager.py', 'nova/tests/network/test_manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/71f3056ddf36364a9551d83d8a39a0b73e96996a', 'message': 'Make nova-network use Network object for remaining ""get"" queries\n\nThis makes nova-network manager use the Network object for the\nremaining single-item ""get"" queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b\n'}]",5,66669,71f3056ddf36364a9551d83d8a39a0b73e96996a,58,9,11,4393,,,0,"Make nova-network use Network object for remaining ""get"" queries

This makes nova-network manager use the Network object for the
remaining single-item ""get"" queries.

Related to blueprint nova-network-objects

Change-Id: I6b1764e3c95337982cf4fbf503ddcb755e33cf2b
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/66669/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fake_network.py', 'nova/tests/test_nova_manage.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/tests/network/test_manager.py', 'nova/tests/compute/test_compute.py']",6,da0a13cb1ee58a64da26c757bfa20beece5d912c,bp/nova-network-objects,"from nova.tests.objects import test_network @mock.patch('nova.db.network_get') def test_get_all_by_multiple_options_at_once(self, network_get): network_get.return_value = ( dict(test_network.fake_network, **network_manager.db.network_get(None, 1)))", def test_get_all_by_multiple_options_at_once(self):,101,66
openstack%2Fnova~master~Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53,openstack/nova,master,Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53,"Make nova-network use NetworkList for remaining ""all"" queries",MERGED,2014-01-14 17:51:59.000000000,2014-01-31 00:33:21.000000000,2014-01-31 00:33:17.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-14 17:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32489188279cd121cbe80935a73558cf354124ce', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 2, 'created': '2014-01-14 19:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6964c5b48d846958ee122e1cb373838f59c00e76', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 3, 'created': '2014-01-15 15:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e35b55c41e393dd62a035025e5ec32b51e4150b', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 4, 'created': '2014-01-16 16:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5244fdfc3264535f936043d20feba179b53b7321', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 5, 'created': '2014-01-16 18:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8c55773738b527ab314472e0c0e4c9e814aca4b', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 6, 'created': '2014-01-16 20:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68783ca270606c5e0ccf1fc7880c1b331d6cf64e', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 7, 'created': '2014-01-17 15:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab4d760c33f6716cfa1c03cbf4960b149ca2a874', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 8, 'created': '2014-01-20 16:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a4520b72140978be7523b48a82b0962982bc7d5', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 9, 'created': '2014-01-27 16:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ff1f9ada0abb624e7c019fe9fc4eabb094e92bb', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 10, 'created': '2014-01-27 22:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8489e542c15ef8357ccc7fa7bdeee2dc65eb4c7', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 11, 'created': '2014-01-28 15:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/610e65ec050556e816ea0e03665cbd0ab15bc7db', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}, {'number': 12, 'created': '2014-01-30 17:28:46.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d717b35f6eb47270503a7ddb17111ae642ee3cd', 'message': 'Make nova-network use NetworkList for remaining ""all"" queries\n\nThis makes nova-network manager use NetworkList for the remaining\nget_all and get_all_by_uuids queries.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53\n'}]",6,66652,6d717b35f6eb47270503a7ddb17111ae642ee3cd,90,9,12,4393,,,0,"Make nova-network use NetworkList for remaining ""all"" queries

This makes nova-network manager use NetworkList for the remaining
get_all and get_all_by_uuids queries.

Related to blueprint nova-network-objects

Change-Id: Ic3e53bb4dc7b6930ceed14e214bbf66d0cc09f53
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/66652/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,32489188279cd121cbe80935a73558cf354124ce,bp/nova-network-objects," mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) mox.IgnoreArg()).AndReturn( [dict(test_network.fake_network, **net) for net in networks]) @mock.patch('nova.db.network_get_all') def test_get_all_networks(self, get_all): get_all.return_value = [dict(test_network.fake_network, **net) for net in networks]"," project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) project_only=mox.IgnoreArg()).AndReturn(networks[:]) def test_get_all_networks(self): self.mox.StubOutWithMock(manager.db, 'network_get_all') manager.db.network_get_all(mox.IgnoreArg()).AndReturn(networks) self.mox.ReplayAll()",43,25
openstack%2Fnova~master~Id94415ea650bce8009ea2db98f5d175206f7e509,openstack/nova,master,Id94415ea650bce8009ea2db98f5d175206f7e509,Make nova-network use Network object for get-all-by-host query,MERGED,2014-01-14 16:53:46.000000000,2014-01-31 00:32:18.000000000,2014-01-31 00:32:14.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-14 16:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd3cf37eef207e0776fe284f962bb61e6a305dae', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 2, 'created': '2014-01-14 17:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/912b53ad1f5e35f28aaf1eb75c217f367a59378e', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 3, 'created': '2014-01-14 19:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c63f798a575abe22c92f0f77cb8c4dc88eef857', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 4, 'created': '2014-01-15 15:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d97c05a033209d50e2e00c15eb90d839c8dc9915', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 5, 'created': '2014-01-16 16:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce4b7adbbf7e8fb7f37048f730fffbfae5546316', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 6, 'created': '2014-01-16 18:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/513e5663cf7871c1d4203fcfc7ae115bd2f7f373', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 7, 'created': '2014-01-16 20:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcafa1ec633ff7194d37410142891c92053322e7', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 8, 'created': '2014-01-17 15:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21731e9b8b9020555c3a04aa9c35ee2a6502f1e0', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 9, 'created': '2014-01-20 16:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3543558e5b033b47cc42e78580faccd96632376e', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 10, 'created': '2014-01-27 16:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c690cae2c57c139d0c5da8f17c86b364ad1a5b5', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 11, 'created': '2014-01-27 23:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93198f92ee96724930ec74bdaa54c74fc58b04fb', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 12, 'created': '2014-01-28 15:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15e45182bf8526a73fcac4045a299745dcad417c', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}, {'number': 13, 'created': '2014-01-30 17:29:06.000000000', 'files': ['nova/network/manager.py', 'nova/network/linux_net.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/26a5de30d1873f72390a5e0c131fbbe338172cc8', 'message': 'Make nova-network use Network object for get-all-by-host query\n\nThis makes nova-network use the NetworkList.get_by_host() instead\nof the direct-to-database query.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: Id94415ea650bce8009ea2db98f5d175206f7e509\n'}]",5,66634,26a5de30d1873f72390a5e0c131fbbe338172cc8,91,9,13,4393,,,0,"Make nova-network use Network object for get-all-by-host query

This makes nova-network use the NetworkList.get_by_host() instead
of the direct-to-database query.

Related to blueprint nova-network-objects

Change-Id: Id94415ea650bce8009ea2db98f5d175206f7e509
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/66634/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,dd3cf37eef207e0776fe284f962bb61e6a305dae,bp/nova-network-objects," fake_networks = [dict(test_network.fake_network, **n) for n in networks] mox.IgnoreArg() ).MultipleTimes().AndReturn(fake_networks)", mox.IgnoreArg()).MultipleTimes().AndReturn(networks),5,2
openstack%2Fnova~master~I9a98fb943895d0d2d359e0d9d38f09fb0f6ddd5a,openstack/nova,master,I9a98fb943895d0d2d359e0d9d38f09fb0f6ddd5a,"Make nova-network a ""conductor-using service""",MERGED,2014-01-28 15:42:36.000000000,2014-01-31 00:31:24.000000000,2014-01-31 00:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-28 15:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c4da67353ab725bc1cede94e04456972bb218aa', 'message': 'Make nova-network a ""conductor-using service""\n\nIn order for a service to reliably use conductor at startup, it must\nwait for conductor to become available before making any requests.\nThis is indirectly controlled by the ""db_allowed"" flag to the service\nstartup. This should be equivalent to the ""use_local"" setting in\nthe conductor group, so this patch sets this for network so that a\nsubsequent patch can introduce a conductor-using call in init_host().\n\nNote that compute was incorrectly passing this flag always as False,\nso this patch fixes that up as well.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9a98fb943895d0d2d359e0d9d38f09fb0f6ddd5a\n'}, {'number': 2, 'created': '2014-01-30 17:29:02.000000000', 'files': ['nova/cmd/compute.py', 'nova/cmd/network.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c15a1ad01011b316c44cc75f66f99756399c77b2', 'message': 'Make nova-network a ""conductor-using service""\n\nIn order for a service to reliably use conductor at startup, it must\nwait for conductor to become available before making any requests.\nThis is indirectly controlled by the ""db_allowed"" flag to the service\nstartup. This should be equivalent to the ""use_local"" setting in\nthe conductor group, so this patch sets this for network so that a\nsubsequent patch can introduce a conductor-using call in init_host().\n\nNote that compute was incorrectly passing this flag always as False,\nso this patch fixes that up as well.\n\nRelated to blueprint nova-network-objects\n\nChange-Id: I9a98fb943895d0d2d359e0d9d38f09fb0f6ddd5a\n'}]",0,69631,c15a1ad01011b316c44cc75f66f99756399c77b2,36,6,2,4393,,,0,"Make nova-network a ""conductor-using service""

In order for a service to reliably use conductor at startup, it must
wait for conductor to become available before making any requests.
This is indirectly controlled by the ""db_allowed"" flag to the service
startup. This should be equivalent to the ""use_local"" setting in
the conductor group, so this patch sets this for network so that a
subsequent patch can introduce a conductor-using call in init_host().

Note that compute was incorrectly passing this flag always as False,
so this patch fixes that up as well.

Related to blueprint nova-network-objects

Change-Id: I9a98fb943895d0d2d359e0d9d38f09fb0f6ddd5a
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/69631/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/cmd/compute.py', 'nova/cmd/network.py']",2,0c4da67353ab725bc1cede94e04456972bb218aa,bp/nova-network-objects," topic=CONF.network_topic, db_allowed=CONF.conductor.use_local)", topic=CONF.network_topic),3,2
openstack%2Fnova~master~Ia89684bb6531bfdcee565cb1bdd33ed943ec3971,openstack/nova,master,Ia89684bb6531bfdcee565cb1bdd33ed943ec3971,libvirt: Review of the code to use module units,MERGED,2014-01-21 17:06:05.000000000,2014-01-31 00:30:30.000000000,2014-01-31 00:30:27.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 5586}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-21 17:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0b0019924093f77a5ff7f1d5262e7937b0cabee', 'message': 'libvirt: review of the code to use module unit\n\nIn some places we do not use the module nova/unit.py\nto refer bytes type.\n\nChange-Id: Ia89684bb6531bfdcee565cb1bdd33ed943ec3971\n'}, {'number': 3, 'created': '2014-01-21 23:07:25.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/utils.py', 'nova/virt/libvirt/imagebackend.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c445324bc9aacfe882dcf114e221d08d95021904', 'message': 'libvirt: Review of the code to use module units\n\nIn some places we do not use the module units to refer\nbytes type.\n\nChange-Id: Ia89684bb6531bfdcee565cb1bdd33ed943ec3971\n'}, {'number': 2, 'created': '2014-01-21 23:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14408555876b7f57b83f0fb01756011ef499592d', 'message': 'libvirt: Review of the code to use module units\n\nIn some places we do not use the module units to refer\nbytes type.\n\nChange-Id: Ia89684bb6531bfdcee565cb1bdd33ed943ec3971\n'}]",0,68172,c445324bc9aacfe882dcf114e221d08d95021904,25,8,3,7730,,,0,"libvirt: Review of the code to use module units

In some places we do not use the module units to refer
bytes type.

Change-Id: Ia89684bb6531bfdcee565cb1bdd33ed943ec3971
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/68172/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/utils.py', 'nova/virt/libvirt/imagebackend.py']",3,c0b0019924093f77a5ff7f1d5262e7937b0cabee,using-units, size = int(size) * unit.Ki, size = int(size) * 1024,7,6
openstack%2Fnova~master~I506045442d893e91b03ce33e4aab9930966c8ec2,openstack/nova,master,I506045442d893e91b03ce33e4aab9930966c8ec2,xenapi: clean up step decorator fake steps,MERGED,2013-12-19 13:16:27.000000000,2014-01-31 00:29:37.000000000,2014-01-31 00:29:34.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 7730}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-19 13:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07f63412df219bcc8e742297447e629c8a60c1b2', 'message': 'xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjuste the number\nof steps used for a resize up/down.\n\n + This patch adds to the methods used to create step tow new private\n   parameters used to adjuste offset of current and total steps.\n + This patch also add a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n'}, {'number': 2, 'created': '2013-12-19 13:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b94300c4c84e4905008c76095fdcff1e0ae113d9', 'message': 'xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjuste the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps two new private\n   parameters used to adjuste offset of current and total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n'}, {'number': 3, 'created': '2013-12-19 14:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1db72bb7e1fcfebee8ae13c9171200f631d0a43', 'message': 'xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps two new private\n   parameters used to adjust offset of current and total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n'}, {'number': 6, 'created': '2013-12-19 16:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee0410d41c50d85da02004d5323b3fc08bf6efef', 'message': ""xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps a new parameter\n   'offset' to adjust the offset of total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n""}, {'number': 4, 'created': '2013-12-19 16:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aec170eb6125604be7205917a33647cfa1767558', 'message': ""xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps a new parameter\n   'offset' to adjust the offset of total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n""}, {'number': 5, 'created': '2013-12-19 16:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf1cf4297d939333560430dbc6823e5ec3ea4681', 'message': ""xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps a new parameter\n   'offset' to adjust the offset of total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n""}, {'number': 7, 'created': '2014-01-20 14:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83c1ac6098b1c16bbb42271f33011fba9a433787', 'message': ""xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps a new parameter\n   'offset' to adjust the offset of total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n""}, {'number': 8, 'created': '2014-01-30 14:54:22.000000000', 'files': ['nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/794027c520935d9a6ba1475aaa128b281b924630', 'message': ""xenapi: clean up step decorator fake steps\n\nIn vmops.py there are some fake methods to adjust the number\nof steps used for a resize up/down.\n\n + This patch adds to the method used to create steps a new parameter\n   'total_offset' to adjust the offset of total steps.\n + This patch also adds a missing test for a successful resize down.\n\nChange-Id: I506045442d893e91b03ce33e4aab9930966c8ec2\nCloses-Bug: 1235108\n""}]",14,63109,794027c520935d9a6ba1475aaa128b281b924630,59,7,8,7730,,,0,"xenapi: clean up step decorator fake steps

In vmops.py there are some fake methods to adjust the number
of steps used for a resize up/down.

 + This patch adds to the method used to create steps a new parameter
   'total_offset' to adjust the offset of total steps.
 + This patch also adds a missing test for a successful resize down.

Change-Id: I506045442d893e91b03ce33e4aab9930966c8ec2
Closes-Bug: 1235108
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/63109/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/test_vmops.py']",3,07f63412df219bcc8e742297447e629c8a60c1b2,bug/1235108," prog_expected = [ # 1/5: step to show snaphot complete. mock.call(context, instance, 2, 5), mock.call(context, instance, 3, 5), mock.call(context, instance, 4, 5) # 5/5: step to be executed by finish migration. ] prog_expected = [ # 1/5: step to show snaphot complete. mock.call(context, instance, 2, 5), mock.call(context, instance, 3, 5), mock.call(context, instance, 4, 5) # 5/5: step to be executed by finish migration. ] @mock.patch.object(vmops.VMOps, '_resize_ensure_vm_is_shutdown') @mock.patch.object(vmops.VMOps, '_apply_orig_vm_name_label') @mock.patch.object(vmops.VMOps, '_update_instance_progress') @mock.patch.object(vm_utils, 'get_vdi_for_vm_safely') @mock.patch.object(vm_utils, 'resize_disk') @mock.patch.object(vm_utils, 'migrate_vhd') @mock.patch.object(vm_utils, 'destroy_vdi') class MigrateDiskResizingDownTestCase(VMOpsTestBase): def test_migrate_disk_resizing_down_works_no_ephemeral( self, mock_destroy_vdi, mock_migrate_vhd, mock_resize_disk, mock_get_vdi_for_vm_safely, mock_update_instance_progress, mock_apply_orig_vm_name_label, mock_resize_ensure_vm_is_shutdown): context = ""ctx"" instance = {""name"": ""fake"", ""uuid"": ""uuid""} dest = ""dest"" vm_ref = ""vm_ref"" sr_path = ""sr_path"" instance_type = dict(root_gb=1) old_vdi_ref = ""old_ref"" new_vdi_ref = ""new_ref"" new_vdi_uuid = ""new_uuid"" mock_get_vdi_for_vm_safely.return_value = (old_vdi_ref, None) mock_resize_disk.return_value = (new_vdi_ref, new_vdi_uuid) self.vmops._migrate_disk_resizing_down(context, instance, dest, instance_type, vm_ref, sr_path) mock_get_vdi_for_vm_safely.assert_called_once_with( self.vmops._session, vm_ref) mock_resize_ensure_vm_is_shutdown.assert_called_once_with( instance, vm_ref) mock_apply_orig_vm_name_label.assert_called_once_with( instance, vm_ref) mock_resize_disk.assert_called_once_with( self.vmops._session, instance, old_vdi_ref, instance_type) mock_migrate_vhd.assert_called_once_with( self.vmops._session, instance, new_vdi_uuid, dest, sr_path, 0) mock_destroy_vdi.assert_called_once_with( self.vmops._session, new_vdi_ref) prog_expected = [ # 1/5: step to match with resizing up mock.call(context, instance, 2, 5), mock.call(context, instance, 3, 5), mock.call(context, instance, 4, 5) # 5/5: step to be executed by finish migration. ] self.assertEqual(prog_expected, mock_update_instance_progress.call_args_list)"," prog_expected = [mock.call(context, instance, 1, 5), mock.call(context, instance, 2, 5), mock.call(context, instance, 3, 5), mock.call(context, instance, 4, 5)] prog_expected = [mock.call(context, instance, 1, 5), mock.call(context, instance, 2, 5), mock.call(context, instance, 3, 5), mock.call(context, instance, 4, 5)]",92,32
openstack%2Fheat~master~Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a,openstack/heat,master,Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a,Prevent access Parameters key in template dict,MERGED,2014-01-22 03:38:40.000000000,2014-01-31 00:29:24.000000000,2014-01-31 00:29:23.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6456}, {'_account_id': 7256}, {'_account_id': 9331}]","[{'number': 1, 'created': '2014-01-22 03:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f8702dcfef6a31b5eb61eb2275af4623b819b9d8', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 2, 'created': '2014-01-22 14:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/874de7597e2f495cf062f639446948e61b5b74aa', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 3, 'created': '2014-01-22 20:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c545d67cbfb01c69068391d9b69b16222c288e34', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 4, 'created': '2014-01-27 14:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55428f3840b927840d133bc5bf76c36bfa4ba59e', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 5, 'created': '2014-01-28 15:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d65d68864ff89bfe2b0fc71e07a06db1e014dbe', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 6, 'created': '2014-01-28 17:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b4924bb6d8ee33722712f206ade96ce1f6dd7d67', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 7, 'created': '2014-01-29 13:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8a04a57867fbb8219a0784b81f2f4de25408b54', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}, {'number': 8, 'created': '2014-01-30 18:16:33.000000000', 'files': ['heat/engine/hot.py', 'heat/tests/test_engine_service.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0afed449681314ff34c2c9481becc68fc1dad893', 'message': 'Prevent access Parameters key in template dict\n\nThis is the third patch in order to implement native pseudo parameters\nfor HOT templates.\n\nIf someone needs to access to the Parameters section of a template, now\ncan use the parameters() method of Template/HOTemplate classes. In order\nto enforce this as the only way of doing it, if the Parameters section\nis access using the template as a dictionary an exception is raised.\n\nChange-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a\nImplements: blueprint native-pseudo-params\n'}]",14,68312,0afed449681314ff34c2c9481becc68fc1dad893,39,5,8,9331,,,0,"Prevent access Parameters key in template dict

This is the third patch in order to implement native pseudo parameters
for HOT templates.

If someone needs to access to the Parameters section of a template, now
can use the parameters() method of Template/HOTemplate classes. In order
to enforce this as the only way of doing it, if the Parameters section
is access using the template as a dictionary an exception is raised.

Change-Id: Ia60b4d2393370b12bf2681b0985ce1cd6e91ac1a
Implements: blueprint native-pseudo-params
",git fetch https://review.opendev.org/openstack/heat refs/changes/12/68312/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot.py', 'heat/tests/test_engine_service.py', 'heat/engine/template.py', 'heat/tests/test_hot.py']",4,f8702dcfef6a31b5eb61eb2275af4623b819b9d8,bp/native-pseudo-params,," self.assertEqual(tmpl[tmpl.PARAMETERS], {})",16,7
openstack%2Fmistral~master~I046430ffb77abf2d462c89050e9e28e67fa72816,openstack/mistral,master,I046430ffb77abf2d462c89050e9e28e67fa72816,"Fixing access to task ""parameters"" property in DSL",MERGED,2014-01-30 00:50:33.000000000,2014-01-31 00:23:10.000000000,2014-01-31 00:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7227}, {'_account_id': 7821}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10126}]","[{'number': 1, 'created': '2014-01-30 00:50:33.000000000', 'files': ['mistral/engine/actions/action_factory.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/430b5ec2e4878c130cdfdcd4e97a235284492287', 'message': 'Fixing access to task ""parameters"" property in DSL\n\nChange-Id: I046430ffb77abf2d462c89050e9e28e67fa72816\n'}]",0,70029,430b5ec2e4878c130cdfdcd4e97a235284492287,8,7,1,8731,,,0,"Fixing access to task ""parameters"" property in DSL

Change-Id: I046430ffb77abf2d462c89050e9e28e67fa72816
",git fetch https://review.opendev.org/openstack/mistral refs/changes/29/70029/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/engine/actions/action_factory.py'],1,430b5ec2e4878c130cdfdcd4e97a235284492287,fixing_access_to_dsl," task_params = task['task_dsl'].get('parameters', {}) task_params = task['task_dsl'].get('parameters', {})"," task_params = task['task_dsl'].get('parameters', None) task_params = task['task_dsl'].get('parameters', None)",6,2
openstack%2Fmistral-extra~master~I10b7912903e738332be1c5c7294bb4849289e41f,openstack/mistral-extra,master,I10b7912903e738332be1c5c7294bb4849289e41f,"Removing redundant sections from ""webhooks"" example DSL.",MERGED,2014-01-30 00:50:38.000000000,2014-01-31 00:23:00.000000000,2014-01-31 00:23:00.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7227}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10126}]","[{'number': 1, 'created': '2014-01-30 00:50:38.000000000', 'files': ['examples/webhooks/demo.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/a64be7f630df480b4533981904884a7929eade08', 'message': 'Removing redundant sections from ""webhooks"" example DSL.\n\nChange-Id: I10b7912903e738332be1c5c7294bb4849289e41f\n'}]",0,70030,a64be7f630df480b4533981904884a7929eade08,7,6,1,8731,,,0,"Removing redundant sections from ""webhooks"" example DSL.

Change-Id: I10b7912903e738332be1c5c7294bb4849289e41f
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/30/70030/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/webhooks/demo.yaml'],1,a64be7f630df480b4533981904884a7929eade08,remove_parameters_section_from_demo_workflow,, task-parameters: task-parameters: task-parameters: task-parameters: parameters: parameters: parameters: parameters:,0,8
openstack%2Fcookbook-openstack-common~master~Ifb271b5e11f3e26c5a217fcdd64ad546e378447f,openstack/cookbook-openstack-common,master,Ifb271b5e11f3e26c5a217fcdd64ad546e378447f,Add enable flag for RDO yum repository on RHEL,MERGED,2014-01-15 11:19:28.000000000,2014-01-31 00:14:49.000000000,2014-01-31 00:14:49.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 1032}, {'_account_id': 1475}, {'_account_id': 2799}, {'_account_id': 5371}, {'_account_id': 6526}, {'_account_id': 6530}, {'_account_id': 6714}, {'_account_id': 7128}, {'_account_id': 7217}, {'_account_id': 8622}, {'_account_id': 9223}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-01-15 11:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/58aab2e3632da9840d713ddf7a26efe67dd98297', 'message': 'Add enable flag for RDO yum repository on rhel.\n\nFor openstack users, on rhel yum repository is variable. Each user can\nhave its own specific repository for openstack. So under this scenario,\nA flag is required to let user be able to disable the RDO yum\nrepository.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 2, 'created': '2014-01-20 15:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/6ada1e99f08e02f8f67924d4758531603dcbd2ed', 'message': 'Add enable flag for RDO yum repository on rhel.\n\nFor openstack users, on rhel yum repository is variable. Each user can\nhave its own specific repository for openstack. So under this scenario,\nA flag is required to let user be able to disable the RDO yum\nrepository.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 3, 'created': '2014-01-20 15:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/a55758ecd434f3c2881faa61c2ed6dd32db1ec88', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 4, 'created': '2014-01-20 15:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/f290d4c91c448eb65e075bc0b1e7fc95058d082e', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 5, 'created': '2014-01-21 04:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/95e0bbe9388738e9b2443296b3b8e5c306360007', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 6, 'created': '2014-01-21 05:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/404599ec489e84788d3685571dc562b18be70f87', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 7, 'created': '2014-01-21 05:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/9e3953831448984c1d5684d154f178c76e32f497', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 8, 'created': '2014-01-21 06:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/d71c80dc86f099c0be592b45e46bfa4c26f9f8ee', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 9, 'created': '2014-01-21 11:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/d44e9f8c1e2bcfa6dd145477a9f494d05964e5ac', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 10, 'created': '2014-01-21 13:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/3e934741b221a93eaac73ac0084dfe6804860506', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 11, 'created': '2014-01-22 07:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/e2c4a66bc28480a9db56d22d2c1a5b4baed2e862', 'message': 'Configure multiple OpenStack yum repositories.\n\nFor OpenStack users, on rhel yum repository is variable. With this fix, multiple\nyum repositories for OpenStack can be configured.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 12, 'created': '2014-01-23 00:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/0ab3cb4fc14f57840207aa1e9aba7966320d7a5d', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 13, 'created': '2014-01-24 21:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/c105344619b13ba9d81b0c076413230e4e301ce2', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 14, 'created': '2014-01-24 22:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/2e4e0c382e6301457a42232afa2cf47c548651e8', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 15, 'created': '2014-01-28 04:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/35d698827d16983157a2538e76928077b02d24a5', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nCo-Authored-By: Matt Odden <mrodden@us.ibm.com>\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 16, 'created': '2014-01-28 04:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/45cc51ad09884e513ecc04959ad272c4e6cf8b4f', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nCo-Authored-By: Matt Odden <mrodden@us.ibm.com>\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 17, 'created': '2014-01-28 04:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/b08c93ddaec87e217dc213105d57bc5b983f08bd', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nCo-Authored-By: Matt Odden <mrodden@us.ibm.com>\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}, {'number': 18, 'created': '2014-01-29 02:06:01.000000000', 'files': ['spec/support/matchers.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/default-redhat_spec.rb', 'recipes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/06d7521a653ae67deddb468e88bed6b4ba607c01', 'message': 'Add enable flag for RDO yum repository on RHEL\n\nEach user can have their own specific repository for OpenStack.\nUnder this scenario, a flag is required to let user disable\nthe RDO yum repository.\n\nCo-Authored-By: Matt Odden <mrodden@us.ibm.com>\nChange-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f\nCloses-Bug: #1269348\n'}]",23,66803,06d7521a653ae67deddb468e88bed6b4ba607c01,94,14,18,9223,,,0,"Add enable flag for RDO yum repository on RHEL

Each user can have their own specific repository for OpenStack.
Under this scenario, a flag is required to let user disable
the RDO yum repository.

Co-Authored-By: Matt Odden <mrodden@us.ibm.com>
Change-Id: Ifb271b5e11f3e26c5a217fcdd64ad546e378447f
Closes-Bug: #1269348
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/03/66803/18 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'recipes/default.rb']",2,58aab2e3632da9840d713ddf7a26efe67dd98297,bug/1269348," if node['openstack']['yum']['enabled'] yum_key ""RPM-GPG-KEY-RDO-#{node[""openstack""][""release""]}"" do url node[""openstack""][""yum""][""repo-key""] action :add end yum_repository ""RDO-#{node[""openstack""][""release""]}"" do description ""OpenStack RDO repo for #{node[""openstack""][""release""]}"" key ""RPM-GPG-KEY-RDO-#{node[""openstack""][""release""]}"" url node[""openstack""][""yum""][""uri""] enabled 1 end"," yum_key ""RPM-GPG-KEY-RDO-#{node[""openstack""][""release""]}"" do url node[""openstack""][""yum""][""repo-key""] action :add end yum_repository ""RDO-#{node[""openstack""][""release""]}"" do description ""OpenStack RDO repo for #{node[""openstack""][""release""]}"" key ""RPM-GPG-KEY-RDO-#{node[""openstack""][""release""]}"" url node[""openstack""][""yum""][""uri""] enabled 1",12,9
openstack%2Fheat~master~I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01,openstack/heat,master,I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01,Native Pseudo Parameters,MERGED,2014-01-14 17:20:33.000000000,2014-01-31 00:12:03.000000000,2014-01-31 00:12:02.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7193}, {'_account_id': 7256}, {'_account_id': 9331}]","[{'number': 1, 'created': '2014-01-14 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5c87117a7423d9ca3b78ff1ee482cadd9fd1bdbb', 'message': 'Native Pseudo Parameters\n\nThe current pseudo-parameters (AWS:: ones) now are mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\n'}, {'number': 2, 'created': '2014-01-14 20:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7ed31633ba0c0c0f1b55503ac406e2d097cf834d', 'message': 'Native Pseudo Parameters\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 3, 'created': '2014-01-15 13:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa82cd47e85efbc280b93106260cffe1321ea725', 'message': 'Native Pseudo Parameters\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 4, 'created': '2014-01-16 21:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1ef54e29a3f4053ca958891db949ffd1be4b4118', 'message': 'Native Pseudo Parameters\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 5, 'created': '2014-01-17 14:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/83a4260557b4b89f3a061a587d41f3029681461a', 'message': 'Native Pseudo Parameters\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 6, 'created': '2014-01-22 03:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/95dcd2063ea15e2dfef5862bf72c7969606e15a0', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 7, 'created': '2014-01-22 14:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c068fec2f607ecd948f37a34404bcac0894efd4c', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 8, 'created': '2014-01-22 20:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a3f44c212164a4d6005dfd2cf10aed70e5c963c8', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 9, 'created': '2014-01-27 14:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fb925e5d4fb2b794e5728206b673c92e9e3be19d', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 10, 'created': '2014-01-28 15:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/165fd30fc0c14320ca7a2013a0443e4dae04b157', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}, {'number': 11, 'created': '2014-01-30 18:07:52.000000000', 'files': ['heat/tests/test_parameters.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'heat/engine/resources/template_resource.py', 'heat/tests/test_stack_resource.py', 'heat/engine/service.py', 'heat/tests/test_hot.py', 'heat/engine/hot.py', 'heat/engine/parser.py', 'heat/engine/api.py', 'heat/engine/parameters.py', 'heat/engine/stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ff195c471299b429085b7323555d30b7b4a3e0bd', 'message': 'Native Pseudo Parameters\n\nThis is the second patch in order to implement native pseudo parameters\nfor HOT templates.\n\nThe current pseudo-parameters (AWS:: ones) are now mapped to ""native""\nparameter names.\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01\nImplements: blueprint native-pseudo-params\nCloses-Bug: #1229415\n'}]",35,66640,ff195c471299b429085b7323555d30b7b4a3e0bd,49,5,11,9331,,,0,"Native Pseudo Parameters

This is the second patch in order to implement native pseudo parameters
for HOT templates.

The current pseudo-parameters (AWS:: ones) are now mapped to ""native""
parameter names.

Now HOTemplate uses HOTParameters instead of Parameters in order to
set up correctly the stack id, which for the HOTemplates is an uuid and
for CFN templates is an arn.

Change-Id: I6361ef1aae55eee762c3f21c9c01ae6ca4a9ff01
Implements: blueprint native-pseudo-params
Closes-Bug: #1229415
",git fetch https://review.opendev.org/openstack/heat refs/changes/40/66640/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot.py', 'heat/engine/parser.py', 'heat/tests/test_parameters.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'heat/engine/parameters.py', 'heat/engine/resource.py', 'heat/engine/service.py', 'heat/tests/test_hot.py']",9,5c87117a7423d9ca3b78ff1ee482cadd9fd1bdbb,bp/native-pseudo-params," tmpl.params_class(""stack_testit"", tmpl, {'db_name': value})","from heat.engine import parameters parameters.Parameters(""stack_testit"", tmpl, {'db_name': value})",128,74
openstack%2Fheat~master~Ifc914f8f6c943da73da5984452d424cf180b91e7,openstack/heat,master,Ifc914f8f6c943da73da5984452d424cf180b91e7,Use a HeatIdentifier instance to create Parameters,MERGED,2014-01-21 20:31:29.000000000,2014-01-31 00:07:26.000000000,2014-01-31 00:07:25.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7256}, {'_account_id': 9331}]","[{'number': 1, 'created': '2014-01-21 20:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c739e7be47f40f1857c88488f8967599d7ea10ae', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nNow HOTemplate uses HOTParameters instead of Parameters in order to\nset up correctly the stack id, which for the HOTemplates is an uuid and\nfor CFN templates is an arn.\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}, {'number': 2, 'created': '2014-01-22 14:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a357ebc954a4283478586a59b786cbf86a8fae6d', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}, {'number': 3, 'created': '2014-01-22 20:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7b911f8175f46ebdfa41d520aa1433051a4ae3dc', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}, {'number': 4, 'created': '2014-01-27 14:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f4db27329cd84238882a85a14bcfa0300b209e16', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}, {'number': 5, 'created': '2014-01-28 15:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2f09edc88d88b24eb5b7d19774406279ff8085d4', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}, {'number': 6, 'created': '2014-01-30 17:56:38.000000000', 'files': ['heat/tests/test_os_database.py', 'heat/tests/test_parameters.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'heat/tests/test_provider_template.py', 'heat/engine/service.py', 'heat/tests/test_hot.py', 'heat/tests/test_resource.py', 'contrib/rackspace/heat/tests/test_rackspace_dns.py', 'heat/engine/parser.py', 'heat/engine/parameters.py', 'heat/engine/stack_resource.py', 'heat/engine/resource.py', 'heat/tests/test_engine_api_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/99697aa0a965aa9f9152d433fbf42b18494e7140', 'message': 'Use a HeatIdentifier instance to create Parameters\n\nThis is the first commit in order to implement native pseudo parameters\nfor HOT templates.\n\nNow to create a Parameters instance, a HeatIdentifier is used instead\nof two variables (stack_name and stack_id)\n\nChange-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7\nImplements: blueprint native-pseudo-params\n'}]",26,68257,99697aa0a965aa9f9152d433fbf42b18494e7140,25,5,6,9331,,,0,"Use a HeatIdentifier instance to create Parameters

This is the first commit in order to implement native pseudo parameters
for HOT templates.

Now to create a Parameters instance, a HeatIdentifier is used instead
of two variables (stack_name and stack_id)

Change-Id: Ifc914f8f6c943da73da5984452d424cf180b91e7
Implements: blueprint native-pseudo-params
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/68257/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_database.py', 'heat/tests/test_parameters.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'heat/tests/test_provider_template.py', 'heat/engine/service.py', 'heat/tests/test_hot.py', 'heat/tests/test_resource.py', 'contrib/rackspace/heat/tests/test_rackspace_dns.py', 'heat/engine/hot.py', 'heat/engine/parser.py', 'heat/common/exception.py', 'heat/engine/parameters.py', 'heat/engine/resource.py', 'heat/tests/test_engine_api_utils.py']",15,c739e7be47f40f1857c88488f8967599d7ea10ae,bp/native-pseudo-params,"from heat.engine import parameters tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False) tmpl_params = parameters.Parameters(None, tmpl, validate_value=False)"," tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False) tmpl_params = parser.Parameters(None, tmpl, validate_value=False)",185,96
openstack%2Fswift~master~Ib31a059e412ac68ca0a3faef4201fec7560d1178,openstack/swift,master,Ib31a059e412ac68ca0a3faef4201fec7560d1178,Make swift-recon usable on hosts without IPv6,MERGED,2014-01-20 07:13:48.000000000,2014-01-31 00:07:23.000000000,2014-01-31 00:07:22.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-01-20 07:13:48.000000000', 'files': ['bin/swift-recon'], 'web_link': 'https://opendev.org/openstack/swift/commit/866c568cd6d240c00f222bcaa8f85a2a15039aee', 'message': 'Make swift-recon usable on hosts without IPv6\n\nFixes a bug when swift-recon --sockstat is used on hosts without\nIPv6 support.\n\nTested by disabling IPv6 on Ubuntu 12.04 LTS:\n\nAdd ""ipv6.disable=1"" to GRUB_CMDLINE_LINUX_DEFAULT in /etc/default/grub\nsudo update-grub\nsudo /sbin/reboot\n\nCloses-Bug: 1270711\nChange-Id: Ib31a059e412ac68ca0a3faef4201fec7560d1178\n'}]",0,67776,866c568cd6d240c00f222bcaa8f85a2a15039aee,6,3,1,6968,,,0,"Make swift-recon usable on hosts without IPv6

Fixes a bug when swift-recon --sockstat is used on hosts without
IPv6 support.

Tested by disabling IPv6 on Ubuntu 12.04 LTS:

Add ""ipv6.disable=1"" to GRUB_CMDLINE_LINUX_DEFAULT in /etc/default/grub
sudo update-grub
sudo /sbin/reboot

Closes-Bug: 1270711
Change-Id: Ib31a059e412ac68ca0a3faef4201fec7560d1178
",git fetch https://review.opendev.org/openstack/swift refs/changes/76/67776/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-recon'],1,866c568cd6d240c00f222bcaa8f85a2a15039aee,bug/1270711," inuse6[url] = response.get('tcp6_in_use', 0)", inuse6[url] = response['tcp6_in_use'],1,1
openstack%2Fcookbook-openstack-image~master~Ieee6c302cb4bd62f37198867b735bc3867589853,openstack/cookbook-openstack-image,master,Ieee6c302cb4bd62f37198867b735bc3867589853,honor package override platform options,MERGED,2014-01-29 12:08:01.000000000,2014-01-31 00:06:27.000000000,2014-01-31 00:06:27.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 10110}]","[{'number': 1, 'created': '2014-01-29 12:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/d034c7bde44601b0423af34923cdf9155fc925ed', 'message': 'honor package override platform options\n\nThe api and registry recipes did not honor the package_override platform\noptions.\n\nChange-Id: Ieee6c302cb4bd62f37198867b735bc3867589853\n'}, {'number': 2, 'created': '2014-01-29 14:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/9b4a7e5fb4d08c95c1cbb842f93e21638c1ddae0', 'message': 'honor package override platform options\n\nThe api and registry recipes did not honor the package_override platform\noptions.\n\nChange-Id: Ieee6c302cb4bd62f37198867b735bc3867589853\n'}, {'number': 3, 'created': '2014-01-29 15:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/0a67dac6e481158ae10942025ef6e94a35d1825d', 'message': 'honor package override platform options\n\nThe api and registry recipes did not honor the package_override platform\noptions.\n\nChange-Id: Ieee6c302cb4bd62f37198867b735bc3867589853\n'}, {'number': 4, 'created': '2014-01-29 16:18:19.000000000', 'files': ['spec/spec_helper.rb', 'recipes/registry.rb', 'spec/api_spec.rb', 'spec/registry_spec.rb', 'recipes/api.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/6922dc838e10291e8c9b7d828cd17d41ff4c0bdc', 'message': 'honor package override platform options\n\nThe api and registry recipes did not honor the package_override platform\noptions.  This includes some more tests.\n\nChange-Id: Ieee6c302cb4bd62f37198867b735bc3867589853\n'}]",1,69847,6922dc838e10291e8c9b7d828cd17d41ff4c0bdc,19,7,4,10110,,,0,"honor package override platform options

The api and registry recipes did not honor the package_override platform
options.  This includes some more tests.

Change-Id: Ieee6c302cb4bd62f37198867b735bc3867589853
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/47/69847/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/registry.rb', 'recipes/api.rb']",2,d034c7bde44601b0423af34923cdf9155fc925ed,honor_package_options, options platform_options['package_overrides'] options platform_options['package_overrides'],,4,0
openstack%2Fcookbook-openstack-dashboard~master~Id64fae024f8972e87919f837f31f487a43744d5f,openstack/cookbook-openstack-dashboard,master,Id64fae024f8972e87919f837f31f487a43744d5f,Rubocop cleanup - use single .rubocop.yml file,MERGED,2014-01-30 11:55:25.000000000,2014-01-30 23:59:41.000000000,2014-01-30 23:59:41.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-01-30 11:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/399b6f2cb34c32cceaf3bcea732924f27339755b', 'message': 'Rubocop cleanup - use single .rubocop.yml file\n\n- Remove individual directory/.rubocop.yml file\n- Adjust .rubocop.yml to include all other directories\n- Adjust Strainerfile to use the single .rubocop.yml file\n\nChange-Id: Id64fae024f8972e87919f837f31f487a43744d5f\n'}, {'number': 2, 'created': '2014-01-30 14:29:12.000000000', 'files': ['spec/.rubocop.yml', 'recipes/.rubocop.yml', 'Strainerfile', '.rubocop.yml', 'attributes/.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/213a9252809ad8bff2233e54b3b26db14ca3ce3b', 'message': 'Rubocop cleanup - use single .rubocop.yml file\n\n- Remove individual directory/.rubocop.yml file\n- Adjust .rubocop.yml to include all other directories\n- Adjust Strainerfile to use the single .rubocop.yml file\n\nChange-Id: Id64fae024f8972e87919f837f31f487a43744d5f\nAddresses: blueprint rubocop-for-dashboard\n'}]",0,70094,213a9252809ad8bff2233e54b3b26db14ca3ce3b,13,6,2,2799,,,0,"Rubocop cleanup - use single .rubocop.yml file

- Remove individual directory/.rubocop.yml file
- Adjust .rubocop.yml to include all other directories
- Adjust Strainerfile to use the single .rubocop.yml file

Change-Id: Id64fae024f8972e87919f837f31f487a43744d5f
Addresses: blueprint rubocop-for-dashboard
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/94/70094/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/.rubocop.yml', 'recipes/.rubocop.yml', 'Strainerfile', '.rubocop.yml', 'attributes/.rubocop.yml']",5,399b6f2cb34c32cceaf3bcea732924f27339755b,bp/rubocop-for-dashboard,,# embedded attributes make for long lines LineLength: Enabled: false # Allow small arrays before forcing %w or %W WordArray: MinSize: 3 ,20,26
openstack%2Fcookbook-openstack-common~master~Iee05b4f23d7fd20f45ad64f50b1f9eeb19c151f3,openstack/cookbook-openstack-common,master,Iee05b4f23d7fd20f45ad64f50b1f9eeb19c151f3,Rubocop cleanup - removing individual directory .rubocop.yml files,MERGED,2014-01-30 11:46:51.000000000,2014-01-30 23:59:28.000000000,2014-01-30 23:59:28.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-01-30 11:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/d911ca77a2d46ed1e94c853240e3ec59e31b9dbf', 'message': 'Rubocop cleanup - removing individual directory .rubocop.yml files\n\n- Remove .rubocop.yml file from attributes directory.\n- This is already managed by the single .rubocop.yml file ~/.rubocop.yml\n\nChange-Id: Iee05b4f23d7fd20f45ad64f50b1f9eeb19c151f3\n'}, {'number': 2, 'created': '2014-01-30 14:28:17.000000000', 'files': ['attributes/.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/9b777d93c691ce98d74fa0b9fd83c84a1cabc87b', 'message': 'Rubocop cleanup - removing individual directory .rubocop.yml files\n\n- Remove .rubocop.yml file from attributes directory.\n- This is already managed by the single .rubocop.yml file ~/.rubocop.yml\n\nChange-Id: Iee05b4f23d7fd20f45ad64f50b1f9eeb19c151f3\nAddresses: blueprint rubocop-for-common\n'}]",0,70092,9b777d93c691ce98d74fa0b9fd83c84a1cabc87b,13,6,2,2799,,,0,"Rubocop cleanup - removing individual directory .rubocop.yml files

- Remove .rubocop.yml file from attributes directory.
- This is already managed by the single .rubocop.yml file ~/.rubocop.yml

Change-Id: Iee05b4f23d7fd20f45ad64f50b1f9eeb19c151f3
Addresses: blueprint rubocop-for-common
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/92/70092/2 && git format-patch -1 --stdout FETCH_HEAD,['attributes/.rubocop.yml'],1,d911ca77a2d46ed1e94c853240e3ec59e31b9dbf,bp/rubocop-for-common,,# embedded attributes make for long lines LineLength: Enabled: false # %w or %W have not generally been used in attribute files WordArray: Enabled: false ,0,7
openstack%2Fcookbook-openstack-telemetry~master~I4323a1d1b626001c0b0dc05bec473b16c637f485,openstack/cookbook-openstack-telemetry,master,I4323a1d1b626001c0b0dc05bec473b16c637f485,Rubocop cleanup - removing individual directory .rubocop.yml files,MERGED,2014-01-30 12:02:52.000000000,2014-01-30 23:58:40.000000000,2014-01-30 23:58:40.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-01-30 12:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/b382dc95322bd3a7478e22d30c85426e617d1371', 'message': 'Rubocop cleanup - removing individual directory .rubocop.yml files\n\n- Remove directory/.rubocop.yml files\n- Adjust Strainerfile to use the single .rubocop.yml\n- Adjust .rubocop.yml ot reference all directories\n\nChange-Id: I4323a1d1b626001c0b0dc05bec473b16c637f485\n'}, {'number': 2, 'created': '2014-01-30 12:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/770a510a69d14d2b82cba7a35f8ebe0f13384379', 'message': 'Rubocop cleanup - removing individual directory .rubocop.yml files\n\n- Remove directory/.rubocop.yml files\n- Adjust Strainerfile to use the single .rubocop.yml\n- Adjust .rubocop.yml ot reference all directories\n\nChange-Id: I4323a1d1b626001c0b0dc05bec473b16c637f485\n'}, {'number': 3, 'created': '2014-01-30 14:28:48.000000000', 'files': ['spec/.rubocop.yml', 'recipes/.rubocop.yml', 'Strainerfile', '.rubocop.yml', 'attributes/.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/9c98f7510aefdeaf72e8d706119ca029cd958a82', 'message': 'Rubocop cleanup - removing individual directory .rubocop.yml files\n\n- Remove directory/.rubocop.yml files\n- Adjust Strainerfile to use the single .rubocop.yml\n- Adjust .rubocop.yml ot reference all directories\n\nChange-Id: I4323a1d1b626001c0b0dc05bec473b16c637f485\nAddresses: blueprint rubocop-for-metering\n'}]",1,70096,9c98f7510aefdeaf72e8d706119ca029cd958a82,16,6,3,2799,,,0,"Rubocop cleanup - removing individual directory .rubocop.yml files

- Remove directory/.rubocop.yml files
- Adjust Strainerfile to use the single .rubocop.yml
- Adjust .rubocop.yml ot reference all directories

Change-Id: I4323a1d1b626001c0b0dc05bec473b16c637f485
Addresses: blueprint rubocop-for-metering
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/96/70096/3 && git format-patch -1 --stdout FETCH_HEAD,"['spec/.rubocop.yml', 'recipes/.rubocop.yml', 'Strainerfile', '.rubocop.yml', 'attributes/.rubocop.yml']",5,b382dc95322bd3a7478e22d30c85426e617d1371,bp/rubocop-for-metering,,# embedded attributes make for long lines LineLength: Enabled: false # Allow small arrays before forcing %w or %W WordArray: MinSize: 3 ,21,26
openstack%2Fdevstack-gate~master~I97037ef417b829e65dd0065cc0e65a55dd49ce62,openstack/devstack-gate,master,I97037ef417b829e65dd0065cc0e65a55dd49ce62,Capture disk space available at the start of a run,MERGED,2014-01-26 02:22:40.000000000,2014-01-30 23:54:56.000000000,2014-01-30 23:54:56.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-01-26 02:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/808d88cfab76e5841995368d554fc7c005b3fc7b', 'message': 'Capture disk space available at the start of a run\n\nMore debugging of issues is all.\n\nChange-Id: I97037ef417b829e65dd0065cc0e65a55dd49ce62\n'}, {'number': 2, 'created': '2014-01-27 03:51:50.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b27c32045e37357e03e098125ebcfb92585876aa', 'message': 'Capture disk space available at the start of a run\n\nMore debugging of issues is all.\n\nChange-Id: I97037ef417b829e65dd0065cc0e65a55dd49ce62\n'}]",0,69156,b27c32045e37357e03e098125ebcfb92585876aa,11,6,2,4190,,,0,"Capture disk space available at the start of a run

More debugging of issues is all.

Change-Id: I97037ef417b829e65dd0065cc0e65a55dd49ce62
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/56/69156/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,808d88cfab76e5841995368d554fc7c005b3fc7b,,"echo ""Available disk space on this host:"" df -h",,2,0
openstack%2Ftripleo-image-elements~master~I4dfd485ecb0d55b2230a6072f45552c20fee043c,openstack/tripleo-image-elements,master,I4dfd485ecb0d55b2230a6072f45552c20fee043c,Force UTF-8 charset and collation for MySQL,MERGED,2014-01-30 23:33:03.000000000,2014-01-30 23:34:25.000000000,2014-01-30 23:34:25.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2014-01-30 23:33:03.000000000', 'files': ['elements/mysql/os-config-applier/mnt/state/etc/mysql/my.cnf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6e69146bd6a8d4ff2bcfc7d1503dde2bc52e6aef', 'message': ""Force UTF-8 charset and collation for MySQL\n\nDefault is latin1/latin1_swedish_ci. We do not want either of those. The\nconfig change we're making will ignore anything clients specify and just\nuse UTF-8 for everything on the server.\n\nChange-Id: I4dfd485ecb0d55b2230a6072f45552c20fee043c\n""}]",0,70256,6e69146bd6a8d4ff2bcfc7d1503dde2bc52e6aef,4,2,1,6488,,,0,"Force UTF-8 charset and collation for MySQL

Default is latin1/latin1_swedish_ci. We do not want either of those. The
config change we're making will ignore anything clients specify and just
use UTF-8 for everything on the server.

Change-Id: I4dfd485ecb0d55b2230a6072f45552c20fee043c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/56/70256/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql/os-config-applier/mnt/state/etc/mysql/my.cnf'],1,6e69146bd6a8d4ff2bcfc7d1503dde2bc52e6aef,,# UTF8 # character-set-client-handshake = FALSE character-set-server = utf8 collation-server = utf8_unicode_ci ,,5,0
openstack%2Fkeystone~master~I19320e281b7dfa8015b2b42c6b3c0de71357db5d,openstack/keystone,master,I19320e281b7dfa8015b2b42c6b3c0de71357db5d,Add in a mechanism for tests to override default config options,ABANDONED,2014-01-25 02:38:05.000000000,2014-01-30 23:13:43.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7052}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-25 02:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d1805878b179e97493e7705a77fb0eed1c6d23a9', 'message': 'Add in a mechanism for tests to override default configuration options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 2, 'created': '2014-01-25 02:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a3e3e470e76a99c1c0756fe75d77467227973fe', 'message': 'Add in a mechanism for tests to override default configuration options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 4, 'created': '2014-01-25 02:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/162df0874f2550e4fee79bec44b685adbaab96a6', 'message': 'Add in a mechanism for tests to override default configuration options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 3, 'created': '2014-01-25 02:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4303e28c2348a5eeb2769907e0d3518cc9321d02', 'message': 'Add in a mechanism for tests to override default configuration options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 5, 'created': '2014-01-25 02:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eef66b97b0ea198616c54f096e8cd350d2023b4b', 'message': 'Add in a mechanism for tests to override default config options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 6, 'created': '2014-01-25 02:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/300df1d0a01612194ab5ccc264007fc67d906f63', 'message': 'Add in a mechanism for tests to override default config options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 7, 'created': '2014-01-25 07:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/866589e8646f6f79f14567389b7b0a2081140e53', 'message': 'Add in a mechanism for tests to override default config options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 9, 'created': '2014-01-30 20:41:02.000000000', 'files': ['keystone/tests/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/78aae6f2d88b9f60b3095666a8d04d0452ab9555', 'message': 'Add in a mechanism for tests to override default config options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}, {'number': 8, 'created': '2014-01-30 20:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/91de1be2c8584843d7aa58910b4e6f93716b074e', 'message': 'Add in a mechanism for tests to override default config options\n\nIn the case of modelling configuration options in tests instead of\nloading in configuration files, it can be useful to change the\ndefault value of a configuration option so that a config file could\nstill override it.  ``opt_override_default`` has been implemented\non the base Keystone test case class.  This method will ensure\nthat during cleanup phase, the original option default will be\nreset (preventing impact to other tests).  ``opt_override_default``\ncannot override/set a default configuration value on any options\nthat do not already have a default value.\n\nChange-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d\nbp: keystone-parallel-testing\n'}]",1,69077,78aae6f2d88b9f60b3095666a8d04d0452ab9555,16,12,9,2903,,,0,"Add in a mechanism for tests to override default config options

In the case of modelling configuration options in tests instead of
loading in configuration files, it can be useful to change the
default value of a configuration option so that a config file could
still override it.  ``opt_override_default`` has been implemented
on the base Keystone test case class.  This method will ensure
that during cleanup phase, the original option default will be
reset (preventing impact to other tests).  ``opt_override_default``
cannot override/set a default configuration value on any options
that do not already have a default value.

Change-Id: I19320e281b7dfa8015b2b42c6b3c0de71357db5d
bp: keystone-parallel-testing
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/69077/9 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/core.py'],1,d1805878b179e97493e7705a77fb0eed1c6d23a9,bp/keystone-parallel-testing," self._opt_default_reset = [] # Reset any default options to the actual defaults originally defined self.addCleanup(self._cleanup_reset_default_options) def opt_override_default(self, group=None, **kw): """"""Overrides an configuration option default value. Sometimes it is useful to change the default value of a configuration option. This allows for a configuration file to still override the option value (where opt_in_group sets a full override that cannot be overriden by a configuration file). ``opt_override_default`` will ensure that the original default is reset when cleanup is performed. ``opt_override_default`` will not work on options that do not provide a default value. """""" for name, value in kw.iteritems(): opt_info = CONF._get_opt_info(name, group) if 'default' not in opt_info: raise TypeError('Options without a default value cannot have ' 'the default overriden.') self._opt_default_reset.append({'group': group, name: opt_info.get('default')}) CONF.set_default(name, value, group=group) def _cleanup_reset_default_options(self): # This is meant to be run during the cleanup phase and reset # any configuration options to the original defaults. for default_opt_value in self._opt_default_reset: CONF.set_default(**default_opt_value) ",,31,0
openstack%2Fdevstack-gate~master~I55446a6877365a6de5033c4304df176e0a26641e,openstack/devstack-gate,master,I55446a6877365a6de5033c4304df176e0a26641e,Remove reference to Developer Setup in docs,MERGED,2014-01-27 23:04:42.000000000,2014-01-30 23:01:20.000000000,2014-01-30 23:01:20.000000000,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-01-27 23:04:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5bc7f26041a4e9f13ffd7ae2e1932ef1d96c4659', 'message': 'Remove reference to Developer Setup in docs\n\nThe Developer Setup section no longer exists in this document,\nremoving reference from the README.rst\n\nChange-Id: I55446a6877365a6de5033c4304df176e0a26641e\n'}]",0,69494,5bc7f26041a4e9f13ffd7ae2e1932ef1d96c4659,5,2,1,6609,,,0,"Remove reference to Developer Setup in docs

The Developer Setup section no longer exists in this document,
removing reference from the README.rst

Change-Id: I55446a6877365a6de5033c4304df176e0a26641e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/94/69494/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5bc7f26041a4e9f13ffd7ae2e1932ef1d96c4659,readme/rmdevsetupref,and set up parts of the environment expected by devstack-gate testing::,"and set up parts of the environment expected by devstack-gate testing (the ""devstack-vm-gate-dev.sh"" script mentioned below in the `Developer Setup`_ section implements a similar workflow for testing changes to devstack-gate itself, but could be modified to automate much of this for ease of repetition)::",1,5
openstack%2Fnova~master~Idab1ba25a8ec4c7dcc9efbb9d86e7248ae3c351e,openstack/nova,master,Idab1ba25a8ec4c7dcc9efbb9d86e7248ae3c351e,Use utils method when getting instance metadata and system metadata,MERGED,2013-12-03 06:09:25.000000000,2014-01-30 22:58:25.000000000,2014-01-30 22:58:22.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 3031}, {'_account_id': 5441}, {'_account_id': 5652}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-03 06:09:25.000000000', 'files': ['nova/notifications.py', 'nova/api/metadata/password.py', 'nova/virt/baremetal/pxe.py', 'nova/virt/baremetal/tilera.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/999701e2c91433ebd10a92c2665b1533371ac6eb', 'message': 'Use utils method when getting instance metadata and system metadata\n\nChange-Id: Idab1ba25a8ec4c7dcc9efbb9d86e7248ae3c351e\n'}]",0,59629,999701e2c91433ebd10a92c2665b1533371ac6eb,14,8,1,3031,,,0,"Use utils method when getting instance metadata and system metadata

Change-Id: Idab1ba25a8ec4c7dcc9efbb9d86e7248ae3c351e
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/59629/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/notifications.py', 'nova/api/metadata/password.py', 'nova/virt/baremetal/pxe.py', 'nova/virt/baremetal/tilera.py']",4,999701e2c91433ebd10a92c2665b1533371ac6eb,use-meta-utils," metadata=utils.instance_meta(instance),"," metadata=instance['metadata'],",5,4
openstack%2Ftaskflow~master~I08df055559e48223e13b7a362b9e6b62aa987853,openstack/taskflow,master,I08df055559e48223e13b7a362b9e6b62aa987853,Added setup for environment without MySql,ABANDONED,2014-01-30 18:45:34.000000000,2014-01-30 22:51:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}, {'_account_id': 10198}]","[{'number': 1, 'created': '2014-01-30 18:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ad59b706fc56b5cd6e8e2ddbec63efa3d6b63b91', 'message': ""Updated tox template by adding a configuration to run in environments that don't have MySQL installed.\n\nChange-Id: I08df055559e48223e13b7a362b9e6b62aa987853\n""}, {'number': 2, 'created': '2014-01-30 22:14:02.000000000', 'files': ['tox-tmpl.ini', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a625da0fcb9bb93e8d6a75d2aab954f5fc1069af', 'message': 'Added setup for environment without MySql\n\nUpdated tox template by adding a configuration that allows running the tests in environment where MySQL is not installed (avoiding error caused by missing mysql_config utility.)\n\nChange-Id: I08df055559e48223e13b7a362b9e6b62aa987853\n'}]",2,70188,a625da0fcb9bb93e8d6a75d2aab954f5fc1069af,10,4,2,10198,,,0,"Added setup for environment without MySql

Updated tox template by adding a configuration that allows running the tests in environment where MySQL is not installed (avoiding error caused by missing mysql_config utility.)

Change-Id: I08df055559e48223e13b7a362b9e6b62aa987853
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/88/70188/2 && git format-patch -1 --stdout FETCH_HEAD,"['tox-tmpl.ini', 'tox.ini']",2,ad59b706fc56b5cd6e8e2ddbec63efa3d6b63b91,tox_nosql_fix," cover-nosql, py26-nosql, py26-sa7-nosql, py26-sa7-nosql-ev, py26-sa8-nosql, py26-sa8-nosql-ev, py26-sa9-nosql, py26-sa9-nosql-ev, py27-nosql, py27-sa7-nosql, py27-sa7-nosql-ev, py27-sa8-nosql, py27-sa8-nosql-ev, py27-sa9-nosql, py27-sa9-nosql-ev, py33-nosql, py33-sa7-nosql, py33-sa8-nosql, py33-sa9-nosql,[testenv:cover-nosql] basepython = python2.7 deps = {[testenv:py27-sa9-nosql-ev]deps} commands = python setup.py testr --coverage --testr-args='{posargs}' [testenv:py26-nosql] basepython = python2.6 deps = {[testenv:py26-sa7-nosql-ev]deps} [testenv:py27-nosql] basepython = python2.7 deps = {[testenv:py27-sa9-nosql-ev]deps} [testenv:py33-nosql] basepython = python3.3 deps = {[testenv:py33-sa9-nosql]deps} [testenv:py26-sa7-nosql-ev] deps = {[testenv]deps} SQLAlchemy<=0.7.99 eventlet>=0.13.0 basepython = python2.6 [testenv:py26-sa7-nosql] deps = {[testenv]deps} SQLAlchemy<=0.7.99 basepython = python2.6 [testenv:py26-sa8-nosql-ev] deps = {[testenv]deps} SQLAlchemy>=0.8,<=0.8.99 eventlet>=0.13.0 basepython = python2.6 [testenv:py26-sa8-nosql] deps = {[testenv]deps} SQLAlchemy>=0.8,<=0.8.99 basepython = python2.6 [testenv:py26-sa9-nosql-ev] deps = {[testenv]deps} SQLAlchemy>=0.9,<=0.9.99 eventlet>=0.13.0 basepython = python2.6 [testenv:py26-sa9-nosql] deps = {[testenv]deps} SQLAlchemy>=0.9,<=0.9.99 basepython = python2.6 [testenv:py27-sa7-nosql-ev] deps = {[testenv]deps} SQLAlchemy<=0.7.99 eventlet>=0.13.0 basepython = python2.7 [testenv:py27-sa7-nosql] deps = {[testenv]deps} SQLAlchemy<=0.7.99 basepython = python2.7 [testenv:py27-sa8-nosql-ev] deps = {[testenv]deps} SQLAlchemy>=0.8,<=0.8.99 eventlet>=0.13.0 basepython = python2.7 [testenv:py27-sa8-nosql] deps = {[testenv]deps} SQLAlchemy>=0.8,<=0.8.99 basepython = python2.7 [testenv:py27-sa9-nosql-ev] deps = {[testenv]deps} SQLAlchemy>=0.9,<=0.9.99 eventlet>=0.13.0 basepython = python2.7 [testenv:py27-sa9-nosql] deps = {[testenv]deps} SQLAlchemy>=0.9,<=0.9.99 basepython = python2.7 [testenv:py33-sa7-nosql] deps = {[testenv]deps} SQLAlchemy<=0.7.99 basepython = python3.3 [testenv:py33-sa8-nosql] deps = {[testenv]deps} SQLAlchemy>=0.8,<=0.8.99 basepython = python3.3 [testenv:py33-sa9-nosql] deps = {[testenv]deps} SQLAlchemy>=0.9,<=0.9.99 basepython = python3.3 ",,138,1
openstack%2Ftrove~master~I23dafdfbc7b04c24f1b4ddd714005eb615641cd6,openstack/trove,master,I23dafdfbc7b04c24f1b4ddd714005eb615641cd6,Disable redundant DB initialization on guesagent's start,MERGED,2013-11-28 17:06:03.000000000,2014-01-30 22:48:14.000000000,2014-01-30 22:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8259}, {'_account_id': 8415}, {'_account_id': 8491}]","[{'number': 1, 'created': '2013-11-28 17:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6860c1ba3d2a602f759adb7ef374e6d1bdc8ca34', 'message': ""Disable redundant DB initialization on guesagent's start\n\nGuestagent uses conductor to communicate with database.\nNo direct connectgion to DB is required.\nBut GA still initializes DB connection on start.\nThis prevent running guestagent without MySQL installed in guest,\nwhich could be useful for datastores other then MySQL.\n\nThis patch disables DB initialization on GA start\n\nFixes bug: 1256046\n\nChange-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6\n""}, {'number': 2, 'created': '2013-11-29 09:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bc311a3512c7a8064b13ae1e179cfaa722053919', 'message': ""Disable redundant DB initialization on guesagent's start\n\nGuestagent uses conductor to communicate with database.\nNo direct connectgion to DB is required.\nBut GA still initializes DB connection on start.\nThis prevent running guestagent without MySQL installed in guest,\nwhich could be useful for datastores other then MySQL.\n\nThis patch disables DB initialization on GA start\n\nFixes bug: 1256046\n\nChange-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6\n""}, {'number': 3, 'created': '2013-12-03 09:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/39255ea7da721114589c85e64a9a50b0ba86057c', 'message': ""Disable redundant DB initialization on guesagent's start\n\nGuestagent uses conductor to communicate with database.\nNo direct connectgion to DB is required.\nBut GA still initializes DB connection on start.\nThis prevent running guestagent without MySQL installed in guest,\nwhich could be useful for datastores other then MySQL.\n\nThis patch disables DB initialization on GA start\n\nCloses-bug: 1256046\n\nChange-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6\n""}, {'number': 4, 'created': '2013-12-09 13:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5816c4947e5e38281cac1ed9159d9aa0610a3d7b', 'message': ""Disable redundant DB initialization on guesagent's start\n\nGuestagent uses conductor to communicate with database.\nNo direct connectgion to DB is required.\nBut GA still initializes DB connection on start.\nThis prevent running guestagent without MySQL installed in guest,\nwhich could be useful for datastores other then MySQL.\n\nThis patch disables DB initialization on GA start\n\nCloses-bug: 1256046\n\nChange-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6\n""}, {'number': 5, 'created': '2014-01-24 13:45:44.000000000', 'files': ['bin/trove-guestagent'], 'web_link': 'https://opendev.org/openstack/trove/commit/110f20e6a1c2bf09e54469ee7c737850d86bd343', 'message': ""Disable redundant DB initialization on guesagent's start\n\nReasons:\n - Guestagent uses conductor to communicate with database.\n - No direct connection to DB is required.\n   But GA still initializes DB connection on start.\n   This prevent running guestagent without MySQL installed in guest,\n   which could be useful for datastores other then MySQL.\n\nChanges:\n - This patch disables DB initialization on GA start.\n\nCloses-bug: #1256046\nChange-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6\n""}]",3,59078,110f20e6a1c2bf09e54469ee7c737850d86bd343,48,11,5,8491,,,0,"Disable redundant DB initialization on guesagent's start

Reasons:
 - Guestagent uses conductor to communicate with database.
 - No direct connection to DB is required.
   But GA still initializes DB connection on start.
   This prevent running guestagent without MySQL installed in guest,
   which could be useful for datastores other then MySQL.

Changes:
 - This patch disables DB initialization on GA start.

Closes-bug: #1256046
Change-Id: I23dafdfbc7b04c24f1b4ddd714005eb615641cd6
",git fetch https://review.opendev.org/openstack/trove refs/changes/78/59078/5 && git format-patch -1 --stdout FETCH_HEAD,['bin/trove-guestagent'],1,6860c1ba3d2a602f759adb7ef374e6d1bdc8ca34,root,,from trove.db import get_db_api get_db_api().configure_db(CONF),0,2
openstack%2Ftripleo-heat-templates~master~I3ebc1454aba9d2c2587628f9cded6e0f445f3606,openstack/tripleo-heat-templates,master,I3ebc1454aba9d2c2587628f9cded6e0f445f3606,Remove file injection config option.,MERGED,2014-01-30 22:21:41.000000000,2014-01-30 22:40:29.000000000,2014-01-30 22:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-30 22:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24e8262951b46d41cc924909b3324b33efeffbc2', 'message': ""Remove file injection config option.\n\nWe're just forcing it off now that the seed is Neutron based.\n\nChange-Id: I3ebc1454aba9d2c2587628f9cded6e0f445f3606\n""}, {'number': 2, 'created': '2014-01-30 22:23:13.000000000', 'files': ['undercloud-bm-source.yaml', 'undercloud-vm-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6027346b9bcf7c8c4a4f91dbead6c42d2fefdd3d', 'message': ""Remove file injection config option.\n\nWe're just forcing it off now that the seed is Neutron based.\n\nChange-Id: I3ebc1454aba9d2c2587628f9cded6e0f445f3606\n""}]",0,70230,6027346b9bcf7c8c4a4f91dbead6c42d2fefdd3d,6,4,2,4190,,,0,"Remove file injection config option.

We're just forcing it off now that the seed is Neutron based.

Change-Id: I3ebc1454aba9d2c2587628f9cded6e0f445f3606
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/70230/1 && git format-patch -1 --stdout FETCH_HEAD,"['undercloud-bm-source.yaml', 'undercloud-vm-source.yaml']",2,24e8262951b46d41cc924909b3324b33efeffbc2,,," use_file_injection: ""False""",0,2
openstack%2Ftripleo-heat-templates~master~Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb,openstack/tripleo-heat-templates,master,Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb,Prep work for a scalable control plane.,MERGED,2014-01-29 00:37:51.000000000,2014-01-30 22:39:19.000000000,2014-01-30 22:39:18.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6738}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-29 00:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d47e079eb6707c74b364f7693721e9cb6a6537a2', 'message': ""Prep work for a scalable control plane.\n\nThis is complete as far as it goes but it isn't enough to make running\na scaled out control plane actually work. Specifically, the constructs\nto point at API hosts based on looking up a network address aren't\nsuirtable for scaled out - we need to be using the virtual IP or DNS\nround robin or other such resilient configurations, but that is\nlargely / entirely orthogonal to making the template be ready for\nscaling.\n\nChange-Id: Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb\n""}, {'number': 2, 'created': '2014-01-30 22:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00ff0575e2e1b2558421b6b8d3e347aba3f56996', 'message': ""Prep work for a scalable control plane.\n\nThis is complete as far as it goes but it isn't enough to make running\na scaled out control plane actually work. Specifically, the constructs\nto point at API hosts based on looking up a network address aren't\nsuirtable for scaled out - we need to be using the virtual IP or DNS\nround robin or other such resilient configurations, but that is\nlargely / entirely orthogonal to making the template be ready for\nscaling.\n\nChange-Id: Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb\n""}, {'number': 3, 'created': '2014-01-30 22:23:13.000000000', 'files': ['nova-compute-instance.yaml', 'swift-source.yaml', 'notcompute.yaml', 'undercloud-source.yaml', 'ssl-source.yaml', 'block-storage.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4aff0fb3f718ee0e55f39f5d0663feb22a14e9a3', 'message': ""Prep work for a scalable control plane.\n\nThis is complete as far as it goes but it isn't enough to make running\na scaled out control plane actually work. Specifically, the constructs\nto point at API hosts based on looking up a network address aren't\nsuirtable for scaled out - we need to be using the virtual IP or DNS\nround robin or other such resilient configurations, but that is\nlargely / entirely orthogonal to making the template be ready for\nscaling.\n\nChange-Id: Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb\n""}]",1,69758,4aff0fb3f718ee0e55f39f5d0663feb22a14e9a3,12,5,3,4190,,,0,"Prep work for a scalable control plane.

This is complete as far as it goes but it isn't enough to make running
a scaled out control plane actually work. Specifically, the constructs
to point at API hosts based on looking up a network address aren't
suirtable for scaled out - we need to be using the virtual IP or DNS
round robin or other such resilient configurations, but that is
largely / entirely orthogonal to making the template be ready for
scaling.

Change-Id: Ib9e6db5e7d5db84e4746afdabea046d2b8702bbb
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/69758/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova-compute-instance.yaml', 'swift-source.yaml', 'notcompute.yaml', 'undercloud-source.yaml', 'block-storage.yaml', 'ssl-source.yaml', 'overcloud-source.yaml']",7,d47e079eb6707c74b364f7693721e9cb6a6537a2,,"complete condition complete handle - notCompute0 - notCompute0Config notCompute0Key: notCompute0CompletionCondition: DependsOn: notCompute0 Properties: Handle: {Ref: notCompute0CompletionHandle} notCompute0CompletionHandle: NovaApiHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ] } KeystoneHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ] } RabbitHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ] } NeutronHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ] } GlanceHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ] } NovaDSN: {""Fn::Join"": ['', ['mysql://nova:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ]}, '/nova']]} CeilometerDSN: {""Fn::Join"": ['', ['mysql://ceilometer:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ]}, '/ceilometer']]} NeutronDSN: {""Fn::Join"": ['', ['mysql://neutron:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notCompute0, networks]} ]} ]}, '/neutron']]} notCompute0Config: Ref: notCompute0CompletionHandle - notCompute0 - notCompute0 - notCompute0 - notCompute0 - notCompute0 - notCompute0 - notCompute0 - notCompute0 - notCompute0 Ref: notCompute0Key path: notCompute0Config.Metadata - notCompute0Key - notCompute0 notCompute0: Ref: notCompute0Key path: notCompute0Config.Metadata - notCompute0Key - notCompute0"," - notcompute - notcomputeConfig Key: CompletionCondition: DependsOn: notcompute Properties: Handle: {Ref: CompletionHandle} CompletionHandle: NovaApiHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ] } KeystoneHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ] } RabbitHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ] } NeutronHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ] } GlanceHost: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ] } NovaDSN: {""Fn::Join"": ['', ['mysql://nova:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ]}, '/nova']]} CeilometerDSN: {""Fn::Join"": ['', ['mysql://ceilometer:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ]}, '/ceilometer']]} NeutronDSN: {""Fn::Join"": ['', ['mysql://neutron:unset@', {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [notcompute, networks]} ]} ]}, '/neutron']]} notcomputeConfig: Ref: CompletionHandle - notcompute - notcompute - notcompute - notcompute - notcompute - notcompute - notcompute - notcompute - notcompute Ref: Key path: notcomputeConfig.Metadata - Key - notcompute notcompute: Ref: Key path: notcomputeConfig.Metadata - Key - notcompute",61,58
openstack%2Ftripleo-heat-templates~master~If05b99ae3596bcc794e3a899ab1443aeb14ec754,openstack/tripleo-heat-templates,master,If05b99ae3596bcc794e3a899ab1443aeb14ec754,Update overcloud to support N compute hosts.,MERGED,2014-01-28 06:41:32.000000000,2014-01-30 22:36:27.000000000,2014-01-30 22:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-01-28 06:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7755f4df90dd381c385e9f7e4aade89638332fb5', 'message': ""Update overcloud to support N compute hosts.\n\nThis uses the new merge feature earlier in this series.\n\nExporting COMPUTESCALE before running make will build a different\ntemplate. Note that since Make doesn't depend on variable values, you\nneed to delete overcloud.yaml between building with different scales.\n\nChange-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754\n""}, {'number': 2, 'created': '2014-01-28 12:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e2c79c2944dfd8675068e55954f2570660d4b4fb', 'message': ""Update overcloud to support N compute hosts.\n\nThis uses the new merge feature earlier in this series.\n\nExporting COMPUTESCALE before running make will build a different\ntemplate. Note that since Make doesn't depend on variable values, you\nneed to delete overcloud.yaml between building with different scales.\n\nChange-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754\n""}, {'number': 3, 'created': '2014-01-29 00:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7ed26927a6161e56ef4de3dfa6beac9529167a1', 'message': ""Update overcloud to support N compute hosts.\n\nThis uses the new merge feature earlier in this series.\n\nExporting COMPUTESCALE before running make will build a different\ntemplate. Note that since Make doesn't depend on variable values, you\nneed to delete overcloud.yaml between building with different scales.\n\nChange-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754\n""}, {'number': 4, 'created': '2014-01-30 22:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf32d130b2f1663f99fc0c6049fbc9fdb62b74c3', 'message': ""Update overcloud to support N compute hosts.\n\nThis uses the new merge feature earlier in this series.\n\nExporting COMPUTESCALE before running make will build a different\ntemplate. Note that since Make doesn't depend on variable values, you\nneed to delete overcloud.yaml between building with different scales.\n\nChange-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754\n""}, {'number': 5, 'created': '2014-01-30 22:23:13.000000000', 'files': ['nova-compute-instance.yaml', 'Makefile', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9ffb18af9421070fffb9375f1fc5e4c94ede0fde', 'message': ""Update overcloud to support N compute hosts.\n\nThis uses the new merge feature earlier in this series.\n\nExporting COMPUTESCALE before running make will build a different\ntemplate. Note that since Make doesn't depend on variable values, you\nneed to delete overcloud.yaml between building with different scales.\n\nChange-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754\n""}]",1,69548,9ffb18af9421070fffb9375f1fc5e4c94ede0fde,17,4,5,4190,,,0,"Update overcloud to support N compute hosts.

This uses the new merge feature earlier in this series.

Exporting COMPUTESCALE before running make will build a different
template. Note that since Make doesn't depend on variable values, you
need to delete overcloud.yaml between building with different scales.

Change-Id: If05b99ae3596bcc794e3a899ab1443aeb14ec754
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/69548/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova-compute-instance.yaml', 'Makefile', 'overcloud-source.yaml']",3,7755f4df90dd381c385e9f7e4aade89638332fb5,, Count: '1' NovaCompute0Key: Type: FileInclude Path: nova-compute-instance.yaml SubKey: Resources.NovaCompute0Key NovaCompute0CompletionCondition: Type: FileInclude Path: nova-compute-instance.yaml SubKey: Resources.NovaCompute0CompletionCondition NovaCompute0CompletionHandle: Type: FileInclude Path: nova-compute-instance.yaml SubKey: Resources.NovaCompute0CompletionHandle, Count: '2' ComputeKey: Properties: UserName: Ref: ComputeUser Type: AWS::IAM::AccessKey,22,15
openstack%2Ftrove~master~Ieb1ec1c468e863109e71fe5a0277834cbc692169,openstack/trove,master,Ieb1ec1c468e863109e71fe5a0277834cbc692169,Simplify swift storage load logic,MERGED,2013-11-21 23:16:38.000000000,2014-01-30 22:34:10.000000000,2014-01-30 22:34:10.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 7850}, {'_account_id': 8415}]","[{'number': 1, 'created': '2013-11-21 23:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8b304b6772577eb1c2243f7ed2bf908f8dd5c71c', 'message': 'Simply swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nFixes: bug #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 2, 'created': '2013-11-22 02:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/98fa5b3ab4ed600aa013ac0cabcf285f5330ce1a', 'message': 'Simply swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nFixes: bug #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 3, 'created': '2013-11-22 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/545dc53476a6a2a950120cba5b9d52bd27a2c1d4', 'message': 'Simply swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 4, 'created': '2013-11-29 22:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/89cad313b501980ce32ee21a2c1363875ceb8e75', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 5, 'created': '2013-12-02 23:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7ab345bb74cb145c229072819f81d329bd5c0116', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 6, 'created': '2013-12-03 16:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/78a6812a0a27c65b7c9bf73efe1580f9b6a44d06', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 7, 'created': '2013-12-11 20:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1d9381e114670f7615de996b9f80a368c68695ed', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 8, 'created': '2013-12-11 21:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a7077bc0102549163300bf8c9cdcc3cd6e308364', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 9, 'created': '2013-12-12 16:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/eb18e3e5c3eaf24ae768ad96db2bd86679a32985', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 10, 'created': '2013-12-12 17:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1468e3e4a3c22c8c08042e9e7b9288f7a4dfef78', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 11, 'created': '2013-12-12 17:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/34f2cef04a1b18357c1aa38c3bdabf0e36254d3f', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 12, 'created': '2013-12-17 17:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/32cab7df490fe57b684295d911394d9d2878f6c1', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 13, 'created': '2014-01-08 21:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/df944d19aba2da83629e7d9200b93622d0689933', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 14, 'created': '2014-01-09 17:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4ae9549f46f047658d6d9bbcb6e33b530abcf047', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}, {'number': 15, 'created': '2014-01-28 18:28:03.000000000', 'files': ['trove/guestagent/strategies/storage/swift.py', 'trove/tests/unittests/backup/test_storage.py', 'trove/tests/fakes/swift.py', 'trove/guestagent/strategies/restore/base.py', 'trove/guestagent/strategies/storage/base.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/guestagent/backup/backupagent.py', 'trove/tests/unittests/guestagent/test_backups.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/af8ca79a3728b0604e367d33e5f6643c4fed6eea', 'message': 'Simplify swift storage load logic\n\n* Use the swift connect to download files.\n* Consolidate fake swift objects.\n\nCloses-Bug: #1253752\n\nChange-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169\n'}]",2,57796,af8ca79a3728b0604e367d33e5f6643c4fed6eea,84,10,15,6268,,,0,"Simplify swift storage load logic

* Use the swift connect to download files.
* Consolidate fake swift objects.

Closes-Bug: #1253752

Change-Id: Ieb1ec1c468e863109e71fe5a0277834cbc692169
",git fetch https://review.opendev.org/openstack/trove refs/changes/96/57796/7 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/strategies/storage/swift.py', 'trove/tests/unittests/backup/test_storage.py', 'trove/tests/fakes/swift.py', 'trove/guestagent/strategies/restore/base.py', 'trove/guestagent/strategies/storage/base.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/guestagent/backup/backupagent.py']",7,8b304b6772577eb1c2243f7ed2bf908f8dd5c71c,lp-1253752," download_stream = storage_strategy.load(backup.location,"," download_stream = storage_strategy.load(context, backup.location, restore_runner.is_zipped,",109,187
openstack%2Frequirements~master~I1e86d4bdc410c00e108615411fd4c317c4d7b7e9,openstack/requirements,master,I1e86d4bdc410c00e108615411fd4c317c4d7b7e9,Use new hplefthandclient,MERGED,2014-01-06 23:49:13.000000000,2014-01-30 22:19:14.000000000,2014-01-30 22:19:14.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 4355}, {'_account_id': 6043}, {'_account_id': 6593}, {'_account_id': 6722}, {'_account_id': 7051}, {'_account_id': 7389}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-01-06 23:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/bd4330f58f744124dccb06c78b646be5873c86ff', 'message': 'Use new hplefthandclient\n\nThe hplefthandclient is required for HP LeftHand (LH) StoreVirtual\nCinder iSCSI Driver unit tests.\n\nChange-Id: I1e86d4bdc410c00e108615411fd4c317c4d7b7e9\n'}, {'number': 2, 'created': '2014-01-08 19:11:19.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b2090ae05d9b6d23fee6c102b9d6d9c07a7b7fd7', 'message': 'Use new hplefthandclient\n\nThe hplefthandclient is required for HP LeftHand (LH) StoreVirtual\nCinder iSCSI Driver unit tests.\n\nChange-Id: I1e86d4bdc410c00e108615411fd4c317c4d7b7e9\n'}]",2,65179,b2090ae05d9b6d23fee6c102b9d6d9c07a7b7fd7,37,10,2,7389,,,0,"Use new hplefthandclient

The hplefthandclient is required for HP LeftHand (LH) StoreVirtual
Cinder iSCSI Driver unit tests.

Change-Id: I1e86d4bdc410c00e108615411fd4c317c4d7b7e9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/65179/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,bd4330f58f744124dccb06c78b646be5873c86ff,requirements,"hplefthandclient>=1.0,<2.0",,1,0
openstack%2Fpuppet-cinder~master~I50cb2b3deb4bf89b374c063f61eea99e1885906e,openstack/puppet-cinder,master,I50cb2b3deb4bf89b374c063f61eea99e1885906e,rbd: add params and deprecate glance_api_version,MERGED,2014-01-29 00:29:16.000000000,2014-01-30 22:02:25.000000000,2014-01-30 22:02:25.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6838}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-01-29 00:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/75ccd995ff6d69c0890cb20c56c75c39544d50bb', 'message': 'Improve cinder::volume::rbd class (add new params)\n\nAdd all cinder rbd params and update documentation/tests.\n\nChange-Id: I50cb2b3deb4bf89b374c063f61eea99e1885906e\n'}, {'number': 2, 'created': '2014-01-30 01:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/44253d466cff34243c7802e8c8b603e895d4afd0', 'message': 'rbd: add params and deprecate glance_api_version\n\n- Add all cinder rbd params\n- Update documentation/tests.\n- Deprecate glance_api_version but keep backward compatibility.\n  (use glance_api_version => false to avoid duplicate def. with\n  cinder::glance class).\n\nChange-Id: I50cb2b3deb4bf89b374c063f61eea99e1885906e\n'}, {'number': 3, 'created': '2014-01-30 17:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/ebd98426a73c6f61d13d54eb43cd7a8a770eae00', 'message': 'rbd: add params and deprecate glance_api_version\n\n- Add all cinder rbd params\n- Update documentation/tests.\n- Deprecate glance_api_version but keep backward compatibility.\n  (use glance_api_version => false to avoid duplicate def. with\n  cinder::glance class).\n\nChange-Id: I50cb2b3deb4bf89b374c063f61eea99e1885906e\n'}, {'number': 4, 'created': '2014-01-30 18:21:46.000000000', 'files': ['manifests/volume/rbd.pp', 'spec/classes/cinder_volume_rbd_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/388bf2ebb78e30bc5226ed276caaa1a06d2fee22', 'message': 'rbd: add params and deprecate glance_api_version\n\n- Add all cinder rbd params\n- Update documentation/tests\n- Deprecate glance_api_version to avoid duplicate definition\n  with cinder::glance class.\n  (use glance_api_version of cinder::glance class instead.)\n\nChange-Id: I50cb2b3deb4bf89b374c063f61eea99e1885906e\n'}]",9,69756,388bf2ebb78e30bc5226ed276caaa1a06d2fee22,21,7,4,7155,,,0,"rbd: add params and deprecate glance_api_version

- Add all cinder rbd params
- Update documentation/tests
- Deprecate glance_api_version to avoid duplicate definition
  with cinder::glance class.
  (use glance_api_version of cinder::glance class instead.)

Change-Id: I50cb2b3deb4bf89b374c063f61eea99e1885906e
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/56/69756/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/volume/rbd.pp', 'spec/classes/cinder_volume_rbd_spec.rb']",2,75ccd995ff6d69c0890cb20c56c75c39544d50bb,improve_rbd," :rbd_pool => 'volumes', :glance_api_version => '2', :rbd_user => 'test', :rbd_secret_uuid => '0123456789', :rbd_ceph_conf => '/foo/boo/zoo/ceph.conf', :rbd_flatten_volume_from_snapshot => true, :volume_tmp_dir => '/foo/tmp', :rbd_max_clone_depth => '0' should contain_cinder_config('DEFAULT/volume_driver').with_value('cinder.volume.drivers.rbd.RBDDriver') should contain_cinder_config('DEFAULT/rbd_ceph_conf').with_value(req_params[:rbd_ceph_conf]) should contain_cinder_config('DEFAULT/rbd_flatten_volume_from_snapshot').with_value(req_params[:rbd_flatten_volume_from_snapshot]) should contain_cinder_config('DEFAULT/volume_tmp_dir').with_value(req_params[:volume_tmp_dir]) should contain_cinder_config('DEFAULT/rbd_max_clone_depth').with_value(req_params[:rbd_max_clone_depth]) should contain_cinder_config('DEFAULT/rbd_pool').with_value(req_params[:rbd_pool]) should contain_cinder_config('DEFAULT/rbd_user').with_value(req_params[:rbd_user]) should contain_cinder_config('DEFAULT/rbd_secret_uuid').with_value(req_params[:rbd_secret_uuid]) should contain_file('/etc/init/cinder-volume.override').with(:ensure => 'present')"," :rbd_pool => 'volumes', :glance_api_version => '2', :rbd_user => 'test', :rbd_secret_uuid => '0123456789', should contain_cinder_config('DEFAULT/volume_driver').with_value( 'cinder.volume.drivers.rbd.RBDDriver') should contain_cinder_config('DEFAULT/rbd_pool').with_value( 'volumes') should contain_cinder_config('DEFAULT/rbd_user').with_value( 'test') should contain_cinder_config('DEFAULT/rbd_secret_uuid').with_value( '0123456789') should contain_file('/etc/init/cinder-volume.override').with( :ensure => 'present' )",69,27
openstack%2Fpython-solumclient~master~Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a,openstack/python-solumclient,master,Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a,WIP: Argparse-bases simple Solum CLI,ABANDONED,2014-01-14 16:11:54.000000000,2014-01-30 21:57:48.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 739}, {'_account_id': 8334}, {'_account_id': 9094}]","[{'number': 1, 'created': '2014-01-14 16:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/df7341f8e3324f7d86fb14f7c45225d59853ca34', 'message': 'WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the create/delete app/assembly text commands\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n'}, {'number': 2, 'created': '2014-01-14 16:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/3123143a05e463b025de1a95cfb2839e22f02881', 'message': 'WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the create/delete app/assembly text commands\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n'}, {'number': 3, 'created': '2014-01-14 21:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/e3656c3a40a65d0fb565da84c29bdc5bdb6d35cd', 'message': 'WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the create/delete app/assembly text commands\n* Removed unused options and better formatting\n* Fixed an exception issue when parameters were invalid\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n'}, {'number': 4, 'created': '2014-01-15 20:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/43e90ccaaa13d10a4041940c7af2754884c9fb4f', 'message': ""WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the app/assembly create/delete/list text commands\n* Renamed solum_cli.py to solum.py\n* Added full command list to help\n* Removed 'Implement' text and added TODOs instead\n* Added app/assembly list commands\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n""}, {'number': 5, 'created': '2014-01-15 20:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/22bd1f0939e5137cfab5b92c7b1348059c501cbc', 'message': ""WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the app/assembly create/delete/list text commands\n* Renamed solum_cli.py to solum.py\n* Added full command list to help\n* Removed 'Implement' text and added TODOs instead\n* Added app/assembly list commands\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n""}, {'number': 6, 'created': '2014-01-21 16:51:41.000000000', 'files': ['solumclient/common.py', 'solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/fa60571236507cb44fa3cfc22ab143e195bc513c', 'message': ""WIP: Argparse-bases simple Solum CLI\n\n* Uses argparse instead of the OpenStack Client as an option\n* Implements the app/assembly create/delete/list text commands\n* Renamed solum_cli.py to solum.py\n* Added full command list to help\n* Removed 'Implement' text and added TODOs instead\n* Added app/assembly list commands\n\nChange-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a\nImplements: blueprint solum-minimal-cli\n""}]",8,66617,fa60571236507cb44fa3cfc22ab143e195bc513c,43,5,6,9094,,,0,"WIP: Argparse-bases simple Solum CLI

* Uses argparse instead of the OpenStack Client as an option
* Implements the app/assembly create/delete/list text commands
* Renamed solum_cli.py to solum.py
* Added full command list to help
* Removed 'Implement' text and added TODOs instead
* Added app/assembly list commands

Change-Id: Ia53e7a0120a7ba1b54628fe26aed902d93c2b20a
Implements: blueprint solum-minimal-cli
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/17/66617/2 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/solum_cli.py', 'solumclient/common.py']",2,df7341f8e3324f7d86fb14f7c45225d59853ca34,m1-solum-cli,"# Copyright (c) 2014 Rackspace # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. class CommandsBase(object): """"""Base command parsing class"""""" parser = None verbose = False debug = False solum = None def __init__(self, parser): self.parser = parser self._get_global_flags() self.parser.add_argument('action', default='help', help='Action to perform on resource') action = None try: parsed, _ = parser.parse_known_args() self.verbose = parsed.verbose or False self.debug = parsed.debug or False action = parsed.action except SystemExit: # Parser has a habit of doing this when an arg is missing. pass if action in self._actions: try: self.parser.error = self.parser.the_error self._actions[action]() except SystemExit: print(self._actions[action].__doc__) self.parser.print_help() @property def _actions(self): """"""Action handler"""""" return dict((attr, getattr(self, attr)) for attr in dir(self) if not attr.startswith('_') and callable(getattr(self, attr))) def _get_global_flags(self): """"""Get global flags"""""" self.parser.add_argument('--verbose', action='store_true', help='Show verbose output.') self.parser.add_argument('--debug', action='store_true', help='Show debug output.') def help(self): """"""Print this help message"""""" print(self.__doc__) show_help(self._actions, 'actions') def show_help(resources, name='resources'): """"""Help screen"""""" print(""Available %s:"" % name) for resource in sorted(resources): commands = resources.get(resource) docstring = ""<%s %s>"" % (name.capitalize(), resource) if commands.__doc__: docstring = commands.__doc__ print(""\t%-20s%s"" % (resource, docstring)) ",,192,0
openstack%2Fpuppet-neutron~master~I08955679bce7ca5bf2155fee89583ce41fb91116,openstack/puppet-neutron,master,I08955679bce7ca5bf2155fee89583ce41fb91116,Remove use of deprecated include_class matcher,MERGED,2014-01-28 18:46:02.000000000,2014-01-30 21:57:00.000000000,2014-01-30 21:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6754}]","[{'number': 1, 'created': '2014-01-28 18:46:02.000000000', 'files': ['spec/classes/neutron_plugins_nvp_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/27d83b9b16e8a43831c27e1aa681deeff4355e4e', 'message': 'Remove use of deprecated include_class matcher\n\ninclude_class is deprecated since rspec-puppet 1.0.0.\ncontain_class should be used instead.\n\nChange-Id: I08955679bce7ca5bf2155fee89583ce41fb91116\n'}]",0,69694,27d83b9b16e8a43831c27e1aa681deeff4355e4e,6,3,1,7156,,,0,"Remove use of deprecated include_class matcher

include_class is deprecated since rspec-puppet 1.0.0.
contain_class should be used instead.

Change-Id: I08955679bce7ca5bf2155fee89583ce41fb91116
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/94/69694/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/neutron_plugins_nvp_spec.rb'],1,27d83b9b16e8a43831c27e1aa681deeff4355e4e,include_class, it { should contain_class('neutron::params') }, it { should include_class('neutron::params') },1,1
openstack%2Ftripleo-image-elements~master~I24f1d399c7068567c1f18f50e69eb25e52b485b9,openstack/tripleo-image-elements,master,I24f1d399c7068567c1f18f50e69eb25e52b485b9,Disable libvirt file injection.,MERGED,2014-01-27 04:41:32.000000000,2014-01-30 21:55:51.000000000,2014-01-30 21:55:51.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-01-27 04:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0aa123fef35ffe8d216031acebb2d535bee0021b', 'message': ""Disable libvirt file injection.\n\nIts bad for performance and reliability and generally terrible.\n\nIt's also being disabled by default upstream.\n\nChange-Id: I24f1d399c7068567c1f18f50e69eb25e52b485b9\nImplements: blueprint disable-file-injection-by-default\n""}, {'number': 2, 'created': '2014-01-30 21:53:57.000000000', 'files': ['elements/nova/os-apply-config/etc/nova/nova.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a62e86bcc71cdf189593a82ed2548e51aefe48d5', 'message': ""Disable libvirt file injection.\n\nIts bad for performance and reliability and generally terrible.\n\nIt's also being disabled by default upstream.\n\nChange-Id: I24f1d399c7068567c1f18f50e69eb25e52b485b9\nImplements: blueprint disable-file-injection-by-default\n""}]",1,69280,a62e86bcc71cdf189593a82ed2548e51aefe48d5,11,6,2,4190,,,0,"Disable libvirt file injection.

Its bad for performance and reliability and generally terrible.

It's also being disabled by default upstream.

Change-Id: I24f1d399c7068567c1f18f50e69eb25e52b485b9
Implements: blueprint disable-file-injection-by-default
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/80/69280/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova/os-apply-config/etc/nova/nova.conf'],1,0aa123fef35ffe8d216031acebb2d535bee0021b,bp/disable-file-injection-by-default, [libvirt] inject_partition=-2,,3,0
openstack%2Ftripleo-image-elements~master~Iad1e0e92ce9044ffcb1f86ab20c2a52888038215,openstack/tripleo-image-elements,master,Iad1e0e92ce9044ffcb1f86ab20c2a52888038215,Source devtest_variables in tripleo-cd.,MERGED,2014-01-27 04:41:32.000000000,2014-01-30 21:54:50.000000000,2014-01-30 21:54:50.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6966}]","[{'number': 1, 'created': '2014-01-27 04:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/594b3fe1da0221d93474e858b28d8b92257c369f', 'message': 'Source devtest_variables in tripleo-cd.\n\nNew file, needs to be included. Oops :)\n\nChange-Id: Iad1e0e92ce9044ffcb1f86ab20c2a52888038215\n'}, {'number': 2, 'created': '2014-01-30 21:53:57.000000000', 'files': ['elements/tripleo-cd/tripleo-cd.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/31dc7075a9f70f4b0005c4cbb6b63ad890ffa0d8', 'message': 'Source devtest_variables in tripleo-cd.\n\nNew file, needs to be included. Oops :)\n\nChange-Id: Iad1e0e92ce9044ffcb1f86ab20c2a52888038215\n'}]",0,69279,31dc7075a9f70f4b0005c4cbb6b63ad890ffa0d8,12,5,2,4190,,,0,"Source devtest_variables in tripleo-cd.

New file, needs to be included. Oops :)

Change-Id: Iad1e0e92ce9044ffcb1f86ab20c2a52888038215
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/79/69279/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/tripleo-cd/tripleo-cd.sh'],1,594b3fe1da0221d93474e858b28d8b92257c369f,bp/disable-file-injection-by-default, source /opt/stack/tripleo-incubator/scripts/devtest_variables.sh,,1,0
openstack%2Ftripleo-image-elements~master~Idf0eca03f104829896b07693f1f22f31270c91c5,openstack/tripleo-image-elements,master,Idf0eca03f104829896b07693f1f22f31270c91c5,Moving iptables rules to the relevant elements,MERGED,2014-01-21 11:08:08.000000000,2014-01-30 21:41:43.000000000,2014-01-30 21:41:43.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}, {'_account_id': 8532}, {'_account_id': 9976}]","[{'number': 1, 'created': '2014-01-21 11:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ecce77faa62ac31de17b47d96fef671edb5f75ae', 'message': 'Moving iptables rules to the relevant elements\n\nThis patch moves the iptables rules from elements/boot-stack to\nan os-refresh-config/pre-configure.d directory within the element\nthat is relevant to the rule.\nThis patch relies on the add-rule script.\n\nChange-Id: Idf0eca03f104829896b07693f1f22f31270c91c5\n'}, {'number': 2, 'created': '2014-01-28 08:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1ca3e7c4fe584a99d28a4e8398dc8cc03b18177a', 'message': 'Moving iptables rules to the relevant elements\n\nThis patch moves the iptables rules from elements/boot-stack to\nan os-refresh-config/pre-configure.d directory within the element\nthat is relevant to the rule.\nThis patch relies on the add-rule script.\n\nChange-Id: Idf0eca03f104829896b07693f1f22f31270c91c5\n'}, {'number': 3, 'created': '2014-01-28 11:35:41.000000000', 'files': ['elements/boot-stack/os-refresh-config/pre-configure.d/97-fedora-iptables', 'elements/horizon/os-refresh-config/pre-configure.d/97-horizon-fedora-iptables', 'elements/neutron/os-refresh-config/pre-configure.d/97-fedora-neutron-iptables', 'elements/horizon/element-deps', 'elements/ironic-api/os-refresh-config/pre-configure.d/97-fedora-ironic-api-iptables', 'elements/nova-baremetal/os-refresh-config/pre-configure.d/97-fedora-nova-baremetal-iptables', 'elements/ceilometer-api/element-deps', 'elements/keystone/element-deps', 'elements/nova-baremetal/element-deps', 'elements/rabbitmq-server/element-deps', 'elements/glance/os-refresh-config/pre-configure.d/97-glance-fedora-iptables', 'elements/nova-api/os-refresh-config/pre-configure.d/97-nova-api-fedora-iptables', 'elements/nova-api/element-deps', 'elements/keystone/os-refresh-config/pre-configure.d/97-keystone-fedora-iptables', 'elements/ironic-api/element-deps', 'elements/neutron/element-deps', 'elements/ceilometer-api/os-refresh-config/pre-configure.d/97-fedora-ceilometer-api-iptables', 'elements/heat-api/element-deps', 'elements/glance/element-deps', 'elements/heat-api/os-refresh-config/pre-configure.d/97-heat-api-fedora-iptables', 'elements/rabbitmq-server/os-refresh-config/pre-configure.d/97-rabbitmq-server-fedora-iptables'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8fb20e22ce37f2b4b24c234bdd081fc9538cf7f0', 'message': 'Moving iptables rules to the relevant elements\n\nThis patch moves the iptables rules from elements/boot-stack to\nan os-refresh-config/pre-configure.d directory within the element\nthat is relevant to the rule.\nThis patch relies on the add-rule script.\n\nChange-Id: Idf0eca03f104829896b07693f1f22f31270c91c5\n'}]",2,68075,8fb20e22ce37f2b4b24c234bdd081fc9538cf7f0,13,5,3,9976,,,0,"Moving iptables rules to the relevant elements

This patch moves the iptables rules from elements/boot-stack to
an os-refresh-config/pre-configure.d directory within the element
that is relevant to the rule.
This patch relies on the add-rule script.

Change-Id: Idf0eca03f104829896b07693f1f22f31270c91c5
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/75/68075/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/boot-stack/os-refresh-config/pre-configure.d/97-fedora-iptables', 'elements/horizon/os-refresh-config/pre-configure.d/97-horizon-fedora-iptables', 'elements/neutron/os-refresh-config/pre-configure.d/97-fedora-neutron-iptables', 'elements/horizon/element-deps', 'elements/ironic-api/os-refresh-config/pre-configure.d/97-fedora-ironic-api-iptables', 'elements/nova-baremetal/os-refresh-config/pre-configure.d/97-fedora-nova-baremetal-iptables', 'elements/ceilometer-api/element-deps', 'elements/keystone/element-deps', 'elements/nova-baremetal/element-deps', 'elements/rabbitmq-server/element-deps', 'elements/glance/os-refresh-config/pre-configure.d/97-glance-fedora-iptables', 'elements/nova-api/os-refresh-config/pre-configure.d/97-nova-api-fedora-iptables', 'elements/nova-api/element-deps', 'elements/keystone/os-refresh-config/pre-configure.d/97-keystone-fedora-iptables', 'elements/ironic-api/element-deps', 'elements/neutron/element-deps', 'elements/ceilometer-api/os-refresh-config/pre-configure.d/97-fedora-ceilometer-api-iptables', 'elements/heat-api/element-deps', 'elements/glance/element-deps', 'elements/heat-api/os-refresh-config/pre-configure.d/97-heat-api-fedora-iptables', 'elements/rabbitmq-server/os-refresh-config/pre-configure.d/97-rabbitmq-server-fedora-iptables']",21,ecce77faa62ac31de17b47d96fef671edb5f75ae,bug/1269709,#!/bin/bash set -eu # AMQP add-rule INPUT -p tcp --dport 5672 -j ACCEPT ,,60,42
openstack%2Ftripleo-image-elements~master~I64153a9f7869d1d7f7a4ce8f848884ba9fb83a37,openstack/tripleo-image-elements,master,I64153a9f7869d1d7f7a4ce8f848884ba9fb83a37,Fix exit status of haproxy install script,MERGED,2014-01-28 20:40:38.000000000,2014-01-30 21:30:47.000000000,2014-01-30 21:30:47.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 7419}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-01-28 20:40:38.000000000', 'files': ['elements/haproxy/install.d/76-haproxy'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7d519c1208207f00601c1f663a54c411aeffd3f6', 'message': ""Fix exit status of haproxy install script\n\nDon't return non-zero exit status if /etc/default/haproxy file doesn't exist,\nimage build fails then.\n\nChange-Id: I64153a9f7869d1d7f7a4ce8f848884ba9fb83a37\n""}]",0,69716,7d519c1208207f00601c1f663a54c411aeffd3f6,8,5,1,7582,,,0,"Fix exit status of haproxy install script

Don't return non-zero exit status if /etc/default/haproxy file doesn't exist,
image build fails then.

Change-Id: I64153a9f7869d1d7f7a4ce8f848884ba9fb83a37
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/16/69716/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/install.d/76-haproxy'],1,7d519c1208207f00601c1f663a54c411aeffd3f6,haproxy-fix,if [ -f /etc/default/haproxy ]; then sed -i -e 's/ENABLED=0/ENABLED=1/' /etc/default/haproxy fi,[ -f /etc/default/haproxy ] && sed -i -e 's/ENABLED=0/ENABLED=1/' /etc/default/haproxy,3,1
openstack%2Frequirements~master~Ie0a48f759abeef62b8c06b9954c7ccfc76f990be,openstack/requirements,master,Ie0a48f759abeef62b8c06b9954c7ccfc76f990be,psutil >= 1.1.0 is actually on PyPI,MERGED,2014-01-24 16:01:25.000000000,2014-01-30 21:30:27.000000000,2014-01-30 21:30:27.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5756}, {'_account_id': 6316}, {'_account_id': 6524}, {'_account_id': 6593}, {'_account_id': 6786}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-01-24 16:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/62aad66e60575f70a8641513102da5f9db9ff898', 'message': ""psutil >= 1.1.0 is actually on PyPI\n\nIt's insecure to use anything other than this and breaks the gate.\n\nChange-Id: Ie0a48f759abeef62b8c06b9954c7ccfc76f990be\n""}, {'number': 2, 'created': '2014-01-26 20:55:06.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d783e69305f245587df398af16d7704d771c5e5d', 'message': ""psutil >= 1.1.0 is actually on PyPI\n\nIt's insecure to use anything other than this and breaks the gate.\n\nAdditionally, 1.1.0 doesn't work - so exclude it from the version list.\n\nChange-Id: Ie0a48f759abeef62b8c06b9954c7ccfc76f990be\n""}]",0,68946,d783e69305f245587df398af16d7704d771c5e5d,22,9,2,2,,,0,"psutil >= 1.1.0 is actually on PyPI

It's insecure to use anything other than this and breaks the gate.

Additionally, 1.1.0 doesn't work - so exclude it from the version list.

Change-Id: Ie0a48f759abeef62b8c06b9954c7ccfc76f990be
",git fetch https://review.opendev.org/openstack/requirements refs/changes/46/68946/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,62aad66e60575f70a8641513102da5f9db9ff898,68946,psutil>=1.1.0,"psutil>=0.6.1,<1.0",1,1
openstack%2Frequirements~master~I2b9311973116345bbb87a15480c12b9969cbb1ec,openstack/requirements,master,I2b9311973116345bbb87a15480c12b9969cbb1ec,Ignore egg-info directory,MERGED,2014-01-22 16:18:35.000000000,2014-01-30 21:30:26.000000000,2014-01-30 21:30:25.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-01-22 16:18:35.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/requirements/commit/bf3e502266ee1b2813ee00305daa8f0aa7dc3cb8', 'message': 'Ignore egg-info directory\n\nAfter running tox, openstack.requirements.egg-info is created and\nuntracked by git.\n\nChange-Id: I2b9311973116345bbb87a15480c12b9969cbb1ec\n'}]",0,68425,bf3e502266ee1b2813ee00305daa8f0aa7dc3cb8,10,5,1,6676,,,0,"Ignore egg-info directory

After running tox, openstack.requirements.egg-info is created and
untracked by git.

Change-Id: I2b9311973116345bbb87a15480c12b9969cbb1ec
",git fetch https://review.opendev.org/openstack/requirements refs/changes/25/68425/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,bf3e502266ee1b2813ee00305daa8f0aa7dc3cb8,ignore-egg-info,*.egg-info,,1,0
openstack%2Ftrove~master~I186c9e04a91e86fca612078415413468757297ca,openstack/trove,master,I186c9e04a91e86fca612078415413468757297ca,Makes the backup tests less onerous,MERGED,2014-01-27 18:19:38.000000000,2014-01-30 21:24:01.000000000,2014-01-30 21:24:00.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}]","[{'number': 1, 'created': '2014-01-27 18:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6f12f2a2b0ce857c824f167a080beca8e8de5461', 'message': 'Makes the backup tests less onerous\n\nThe backups test code was looking for an exact number of elements to\nbe returned from the backups list calls. This made running the tests\nkind of a pain, so this commit counts the number of backups before a\nbackup is created and uses this for the later assertions.\n\nChange-Id: I186c9e04a91e86fca612078415413468757297ca\n'}, {'number': 2, 'created': '2014-01-27 19:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/06638638cb4fd40dea01e7765380da71bced47c1', 'message': 'Makes the backup tests less onerous\n\nThe backups test code was looking for an exact number of elements to\nbe returned from the backups list calls. This made running the tests\nkind of a pain, so this commit counts the number of backups before a\nbackup is created and uses this for the later assertions.\n\nChange-Id: I186c9e04a91e86fca612078415413468757297ca\n'}, {'number': 3, 'created': '2014-01-28 06:41:48.000000000', 'files': ['trove/tests/api/backups.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/9c926689ae56c830c14098aa2703f14848be1c4c', 'message': 'Makes the backup tests less onerous\n\nThe backups test code was looking for an exact number of elements to\nbe returned from the backups list calls. This made running the tests\nkind of a pain, so this commit counts the number of backups before a\nbackup is created and uses this for the later assertions.\n\nChange-Id: I186c9e04a91e86fca612078415413468757297ca\n'}]",0,69429,9c926689ae56c830c14098aa2703f14848be1c4c,18,6,3,694,,,0,"Makes the backup tests less onerous

The backups test code was looking for an exact number of elements to
be returned from the backups list calls. This made running the tests
kind of a pain, so this commit counts the number of backups before a
backup is created and uses this for the later assertions.

Change-Id: I186c9e04a91e86fca612078415413468757297ca
",git fetch https://review.opendev.org/openstack/trove refs/changes/29/69429/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/api/backups.py'],1,6f12f2a2b0ce857c824f167a080beca8e8de5461,,"backup_count_prior_to_create = 0 backup_count_for_instance_prior_to_create = 0 # Necessary to test that the count increases. global backup_count_prior_to_create backup_count_prior_to_create = len(instance_info.dbaas.backups.list()) global backup_count_for_instance_prior_to_create backup_count_for_instance_prior_to_create = len( instance_info.dbaas.instances.backups(instance_info.id)) instance = instance_info.dbaas.instances.get(instance_info.id) assert_equal(backup_count_prior_to_create + 1, len(result)) assert_equal(backup_count_for_instance_prior_to_create + 1, len(result))"," instance = instance_info.dbaas.instances.list()[0] assert_equal(1, len(result)) assert_equal(1, len(result))",12,4
openstack%2Ftempest~master~I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc,openstack/tempest,master,I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc,Do not assume volume metadata is identical to POST request,MERGED,2014-01-09 17:30:34.000000000,2014-01-30 21:23:32.000000000,2014-01-30 21:23:31.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5196}, {'_account_id': 5538}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6796}, {'_account_id': 7872}, {'_account_id': 8085}, {'_account_id': 9485}]","[{'number': 1, 'created': '2014-01-09 17:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/84662c1c5e971398f813d946e7334c9fd3248dcd', 'message': ""Do not assume volume metadata is identical to POST request\n\nThis change attempts to fix bug 1264418 for Cinder; metadata can\nbe altered by create/update so it's wrong to assertEqual.\n\nChange-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc\nPartial-Bug: 1264418\n""}, {'number': 2, 'created': '2014-01-13 13:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d215e93079a5081cca4bc93634a10bafee790c0a', 'message': ""Do not assume volume metadata is identical to POST request\n\nThis change attempts to fix bug 1264418 for Cinder; metadata can\nbe altered by create/update so it's wrong to assertEqual.\n\nChange-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc\nPartial-Bug: 1264418\n""}, {'number': 3, 'created': '2014-01-21 15:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1641fee71db58422e9a6f66948d581858f65e92e', 'message': ""Do not assume volume metadata is identical to POST request\n\nThis change attempts to fix bug 1264418 for Cinder; metadata can\nbe altered by create/update so it's wrong to assertEqual.\n\nChange-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc\nPartial-Bug: 1264418\n""}, {'number': 4, 'created': '2014-01-23 19:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b906ec3bafac92dab552744ece9f46ae9ef0d27d', 'message': ""Do not assume volume metadata is identical to POST request\n\nThis change attempts to fix bug 1264418 for Cinder; metadata can\nbe altered by create/update so it's wrong to assertEqual.\n\nChange-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc\nPartial-Bug: 1264418\n""}, {'number': 5, 'created': '2014-01-24 13:40:55.000000000', 'files': ['tempest/api/volume/test_volume_metadata.py', 'tempest/api/volume/test_volumes_get.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ed48ce6565cc4d7d14223b424b1ead8e1182fb2', 'message': ""Do not assume volume metadata is identical to POST request\n\nThis change attempts to fix bug 1264418 for Cinder; metadata can\nbe altered by create/update so it's wrong to assertEqual.\n\nChange-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc\nPartial-Bug: 1264418\n""}]",6,65740,5ed48ce6565cc4d7d14223b424b1ead8e1182fb2,35,11,5,6796,,,0,"Do not assume volume metadata is identical to POST request

This change attempts to fix bug 1264418 for Cinder; metadata can
be altered by create/update so it's wrong to assertEqual.

Change-Id: I05d13996fb5dd8c12a81576d7a4fffe2aa198dcc
Partial-Bug: 1264418
",git fetch https://review.opendev.org/openstack/tempest refs/changes/40/65740/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/test_volume_metadata.py', 'tempest/api/volume/test_volumes_get.py']",2,84662c1c5e971398f813d946e7334c9fd3248dcd,bug/1264418," 'The fetched Volume name is different ' 'The fetched Volume id is different ' for item in metadata: self.assertIn(item, fetched_volume['metadata'], 'The fetched Volume metadata is different ' 'from the created Volume') for item in metadata: self.assertIn(item, updated_volume['metadata'])"," 'The fetched Volume is different ' 'The fetched Volume is different ' self.assertEqual(metadata, fetched_volume['metadata'], 'The fetched Volume is different ' 'from the created Volume') self.assertEqual(metadata, updated_volume['metadata']) @attr(type='gate') def test_volume_get_metadata_none(self): # Create a volume without passing metadata, get details, and delete # Create a volume without metadata volume = self.create_volume(metadata={}) # GET Volume resp, fetched_volume = self.client.get_volume(volume['id']) self.assertEqual(200, resp.status) self.assertEqual(fetched_volume['metadata'], {}) ",19,27
openstack%2Ftripleo-incubator~master~I46ccc189ef16dc47effac684f2fd38a92d44781d,openstack/tripleo-incubator,master,I46ccc189ef16dc47effac684f2fd38a92d44781d,"Deploy 2 hypervisors, not 1.",ABANDONED,2014-01-28 06:44:24.000000000,2014-01-30 21:22:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 7144}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-01-28 06:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ca528b79fc2ff828d860932bedb1d5c40786e747', 'message': 'Deploy 2 hypervisors, not 1.\n\nChange-Id: I46ccc189ef16dc47effac684f2fd38a92d44781d\n'}, {'number': 2, 'created': '2014-01-28 12:42:33.000000000', 'files': ['scripts/devtest_testenv.sh', 'scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d6f6e9a34c038de3321230e174f4446260b792de', 'message': 'Deploy 2 hypervisors, not 1.\n\nChange-Id: I46ccc189ef16dc47effac684f2fd38a92d44781d\n'}]",2,69549,d6f6e9a34c038de3321230e174f4446260b792de,13,6,2,4190,,,0,"Deploy 2 hypervisors, not 1.

Change-Id: I46ccc189ef16dc47effac684f2fd38a92d44781d
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/49/69549/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_testenv.sh', 'scripts/devtest_overcloud.sh']",2,ca528b79fc2ff828d860932bedb1d5c40786e747,,make -C $TRIPLEO_ROOT/tripleo-heat-templates overcloud.yaml COMPUTESCALE=2,make -C $TRIPLEO_ROOT/tripleo-heat-templates overcloud.yaml,2,2
openstack%2Ftempest~master~I9d6d610302406d5aa7bee9135c27dbc83896e005,openstack/tempest,master,I9d6d610302406d5aa7bee9135c27dbc83896e005,Removed unnecessary lock from a aggregate test,MERGED,2014-01-28 13:26:41.000000000,2014-01-30 21:22:24.000000000,2014-01-30 21:22:24.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 8085}]","[{'number': 1, 'created': '2014-01-28 13:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9780f25b68f65328991040fff436e327b2b6afca', 'message': 'Removed unused lock from a aggregate test\n\nLock is unused here, as the test is not adding\na host to an aggregate.Previoulsy this lock was\nadded to ensure the faliure will not occur where\na host is added to an availability zone.\nPrevious patchlink:-\nhttps://github.com/openstack/tempest/commit/a80c334c9abacf6b395f740be313983bd35c9dd3yht\n\nChange-Id: I9d6d610302406d5aa7bee9135c27dbc83896e005\n'}, {'number': 2, 'created': '2014-01-28 13:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d04be171599acb84b2958e293768607859215641', 'message': 'Removed unused lock from a aggregate test\n\nLock is unused here, as the test is not adding\na host to an aggregate.Previoulsy this lock was\nadded to ensure the faliure will not occur where\na host is added to an availability zone.\nPrevious patchlink:-\nhttps://github.com/openstack/tempest/commit/a80c334c9abacf6b395f740be313983bd35c9dd3\n\nChange-Id: I9d6d610302406d5aa7bee9135c27dbc83896e005\n'}, {'number': 3, 'created': '2014-01-29 04:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/001347103b484ed1f5d9f1b480a1d5adcbfbe09a', 'message': 'Removed unused lock from a aggregate test\n\nLock is unused here, as the test is not adding\na host to an aggregate.Previoulsy this lock was\nadded to ensure the failure will not occur where\na host is added to an availability zone.\nReference:-\nIaf8a903d92c88c7c3092eaa00a9f7a96e6348ddc\n\nChange-Id: I9d6d610302406d5aa7bee9135c27dbc83896e005\n'}, {'number': 4, 'created': '2014-01-29 07:45:19.000000000', 'files': ['tempest/api/compute/admin/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a61182957e4e82efaecfa3585cbd4d621a2ac55', 'message': 'Removed unnecessary lock from a aggregate test\n\nLock is unnecessary here, as the test is not adding\na host to an aggregate.Previoulsy this lock was\nadded to ensure the failure will not occur where\na host is added to an availability zone.\nReference:-\nIaf8a903d92c88c7c3092eaa00a9f7a96e6348ddc\n\nChange-Id: I9d6d610302406d5aa7bee9135c27dbc83896e005\n'}]",4,69595,7a61182957e4e82efaecfa3585cbd4d621a2ac55,25,8,4,8085,,,0,"Removed unnecessary lock from a aggregate test

Lock is unnecessary here, as the test is not adding
a host to an aggregate.Previoulsy this lock was
added to ensure the failure will not occur where
a host is added to an availability zone.
Reference:-
Iaf8a903d92c88c7c3092eaa00a9f7a96e6348ddc

Change-Id: I9d6d610302406d5aa7bee9135c27dbc83896e005
",git fetch https://review.opendev.org/openstack/tempest refs/changes/95/69595/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_aggregates.py'],1,9780f25b68f65328991040fff436e327b2b6afca,master,, self.useFixture(fixtures.LockFixture('availability_zone')),0,1
openstack%2Fnova~master~I441cf8f2df0b92a9cc4096e77a90c37a06270eb5,openstack/nova,master,I441cf8f2df0b92a9cc4096e77a90c37a06270eb5,Make snapshot_volume_backed use new-world objects,MERGED,2013-11-28 14:45:28.000000000,2014-01-30 21:21:27.000000000,2014-01-30 21:21:23.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 7770}, {'_account_id': 7808}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-28 14:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/950430d91f7431fd397f5847def682583af04fec', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) to the image properties. This flag will be\ntaken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependant on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 2, 'created': '2013-11-29 15:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83f7010bd09579fa1eb68ff8bd0c887621768727', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) to the image properties. This flag will be\ntaken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependant on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 3, 'created': '2013-12-03 21:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ff0d147215e9dcf919d0915d1f7c405d444f4e5', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 4, 'created': '2013-12-03 21:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5db48ea4fae4062464e95ffaa0fa68ef9f230af4', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 5, 'created': '2013-12-03 21:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ef5f95ca28cd788ebab0813529675781d469baa', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 6, 'created': '2013-12-09 13:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a616e8a04922c72260eae058518a05e01c75b5b', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 7, 'created': '2013-12-12 17:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6486c8c59b57277941b4450a048c07b38cbdfecb', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 8, 'created': '2013-12-13 10:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20f4acbfbb83fe6045169fd19e39377388a856d1', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 9, 'created': '2013-12-13 13:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26a92df0bdab77d49038dd01465916a138d0fcf1', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 10, 'created': '2013-12-13 17:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51ec7c773dd3f55e763c99b173ca41fd7255b832', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 11, 'created': '2013-12-17 12:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/311327c2f5eef8806f267570d4625df17f18f96c', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 12, 'created': '2013-12-18 14:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5383a2d19874081e3b87b4c99f45da1efe97cc29', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 13, 'created': '2013-12-19 15:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68708657fa501991a7ac7c42ad2b18a0ddaa8657', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 14, 'created': '2013-12-23 20:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a58124dba709215ad4022d99ac78d8a0f1ac974', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 15, 'created': '2014-01-02 09:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efd00f5be05adeca10d98b2c902f0e2fb39d7a2e', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 16, 'created': '2014-01-03 15:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff8729bc0053a7f94f896a0d2def1594b688c999', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 17, 'created': '2014-01-06 13:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/acec0bd49bf0867e872ecc1956ff68cc61556300', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 18, 'created': '2014-01-06 17:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74985822334c78483aaa187c8d139a246e9f5e11', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 19, 'created': '2014-01-13 14:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04a556a2d2c4bd09373ccaabf9714be65a9bffea', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 20, 'created': '2014-01-14 23:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0726f630d502410da42ed6c08ca0f1eef5928384', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 21, 'created': '2014-01-15 10:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ece80133fb268aee469e2af23c2413872578cd9d', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 22, 'created': '2014-01-17 16:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f6377cef27efebf4a0ae1bc537fecc44f6191d5', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 23, 'created': '2014-01-22 17:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/777e0bd15dd9c0eced56f097d1a1a3c2ba5949fe', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 24, 'created': '2014-01-27 12:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee563678bb16b39e5535ad0ce07a3008e005f530', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}, {'number': 25, 'created': '2014-01-30 14:32:57.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/test_block_device.py', 'nova/block_device.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/33e3d4c6b9e0b11500fe47d861110be1c1981572', 'message': 'Make snapshot_volume_backed use new-world objects\n\nThis patch makes snapshotting of a volume backed instance code path use\nnew-world block device objects, and thus transitions snapshotting to use\nblock device mapping v2 data format.\n\nThis means that all images that are created by snapshotting volume\nbacked instances after this change will have new block device mapping\nformat in their properties. To be able to distinguish between those, an\nadditional field (bdm_v2) was added to the image properties. This flag\nwill be taken into account when booting an instance and all necessary\nconversions will be done so that both formats are supported. The legacy\nblock device format will continue to be supported in images, even when\nwe deprecate it in the API (after v2).\n\nAnother noteworthy point is that block device mapping data added to the\nimage will no longer contain the device name, as it will be dependent on\nthe configuration when booting a new instance. The mapping will however\nkeep the boot order.\n\nThe code in snapshot will also take care that all of the mappings\npresent in the image properties are handled and not re-created on\nbooting an instance from the snapshot image.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5\n'}]",5,59034,33e3d4c6b9e0b11500fe47d861110be1c1981572,121,10,25,5511,,,0,"Make snapshot_volume_backed use new-world objects

This patch makes snapshotting of a volume backed instance code path use
new-world block device objects, and thus transitions snapshotting to use
block device mapping v2 data format.

This means that all images that are created by snapshotting volume
backed instances after this change will have new block device mapping
format in their properties. To be able to distinguish between those, an
additional field (bdm_v2) was added to the image properties. This flag
will be taken into account when booting an instance and all necessary
conversions will be done so that both formats are supported. The legacy
block device format will continue to be supported in images, even when
we deprecate it in the API (after v2).

Another noteworthy point is that block device mapping data added to the
image will no longer contain the device name, as it will be dependent on
the configuration when booting a new instance. The mapping will however
keep the boot order.

The code in snapshot will also take care that all of the mappings
present in the image properties are handled and not re-created on
booting an instance from the snapshot image.

Part of the blueprint: icehouse-objects
Part of the blueprint: clean-up-legacy-block-device-mapping

Change-Id: I441cf8f2df0b92a9cc4096e77a90c37a06270eb5
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/59034/24 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/test_block_device.py', 'nova/block_device.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py']",6,950430d91f7431fd397f5847def682583af04fec,bp/icehouse-objects," self.assertEqual(properties['bdm_v2'], True) self.assertEquals(bdms[0]['boot_index'], 0) self.assertEquals(bdms[0]['source_type'], 'snapshot') self.assertEquals(bdms[0]['destination_type'], 'volume') for fld in ('connection_info', 'id', 'instance_uuid', 'device_name'): self.assertTrue(fld not in bdms[0])"," self.assertEqual(bdms[0]['device_name'], 'vda')",136,63
openstack%2Fnova~master~I967061cef36b4da06073736fce871fc3f3d28f97,openstack/nova,master,I967061cef36b4da06073736fce871fc3f3d28f97,"Make volume_snapshot_{create,delete} use objects",MERGED,2013-11-28 14:45:27.000000000,2014-01-30 21:20:21.000000000,2014-01-30 21:20:17.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 4458}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-28 14:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3833280fc649c13f84d46b39e0362f3a48b3cedc', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Istance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 2, 'created': '2013-11-29 15:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8feed4d8850d10682bf62d1dccc359ca8a6cdf30', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Istance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 3, 'created': '2013-12-03 21:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21504b2d1f5716384ba5dfaca94a00cc3522be56', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 4, 'created': '2013-12-03 21:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6180b3b1bca6fe5ebc9fbdcd9aee1dbdbe15cb87', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 5, 'created': '2013-12-09 13:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cc53634df940c80194790f222e8647c6952e80e', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 6, 'created': '2013-12-12 17:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10849ef634d4b0cef1299f938ce22ac43c94e176', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 7, 'created': '2013-12-13 10:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/384f66661f4d9057dfe0d2af79d40cf6105af419', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 8, 'created': '2013-12-13 13:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97de2ba2acdecd2d9be16becebaef6635d166497', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 9, 'created': '2013-12-13 17:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad323b9475ae1d5fba94a0805ad32a6ed9066a07', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 10, 'created': '2013-12-17 12:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/325ff45f0567456a1411bd62ce9da3b6fc17e294', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 11, 'created': '2013-12-18 14:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/018e821985467bfea601c2f990fb8911c9d24234', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 12, 'created': '2013-12-19 15:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/312fb661c75691b1633fab941240a382b6e833ab', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 13, 'created': '2013-12-23 20:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8320a31fe24286cb023b7e326bc4ca12ce7ecb09', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 14, 'created': '2014-01-02 09:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/becbc6d4435dc26e50ac4988df1b7616045aff9d', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 15, 'created': '2014-01-03 15:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c156582e94e98a1808ba07474a2d65535a27ff9', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 16, 'created': '2014-01-06 13:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3332a43fe9be58e9437c1cbc2599729e5c357f0b', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 17, 'created': '2014-01-06 17:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/606b1a505771305ee1ce0f61468d48e85facfe19', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 18, 'created': '2014-01-13 14:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df485f782c3e4f9e7c6834b17dbf21edeb10c359', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 19, 'created': '2014-01-14 23:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aee3a353fb943d61c6a4b75b4ebc0989e78b734e', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 20, 'created': '2014-01-15 10:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/853a09927b085df8b4a3450ee209e5c72ba4900a', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 21, 'created': '2014-01-17 16:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a0f2c96e0482cd152ab4ad26a2f612c02acc697', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 22, 'created': '2014-01-22 17:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb1d629e2c77f6db4993422ae41fc8014c4e4337', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 23, 'created': '2014-01-27 12:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5201e57e64dc58d4925a39a35f290c954a44ba11', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}, {'number': 24, 'created': '2014-01-30 14:32:59.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/virt/libvirt/driver.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15e91d7a61032ac9cfa8037267850cb31427f993', 'message': 'Make volume_snapshot_{create,delete} use objects\n\nThis patch makes the volume_snapshot_create and delete methods use\nnew-world Instance objects.\n\nIt bumps the version of the compute rpc API, and starts passing objects\nto the rpc layer. It also makes the driver methods that touch instance\nuse the dot notation to access the attributes.\n\nIt also makes sure that the backwards compatibility is kept by\ndecorating the manager methods with object_compat decorator.\n\nPart of the blueprint: icehouse-objects\nPart of the blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I967061cef36b4da06073736fce871fc3f3d28f97\n'}]",4,59033,15e91d7a61032ac9cfa8037267850cb31427f993,120,9,24,5511,,,0,"Make volume_snapshot_{create,delete} use objects

This patch makes the volume_snapshot_create and delete methods use
new-world Instance objects.

It bumps the version of the compute rpc API, and starts passing objects
to the rpc layer. It also makes the driver methods that touch instance
use the dot notation to access the attributes.

It also makes sure that the backwards compatibility is kept by
decorating the manager methods with object_compat decorator.

Part of the blueprint: icehouse-objects
Part of the blueprint: clean-up-legacy-block-device-mapping

Change-Id: I967061cef36b4da06073736fce871fc3f3d28f97
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/59033/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/virt/libvirt/driver.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",7,3833280fc649c13f84d46b39e0362f3a48b3cedc,bp/icehouse-objects," self.instance_object = instance_obj.Instance._from_db_object( self.context, instance_obj.Instance(), fake_instance.fake_db_instance()) self.instance_object, 'fake_id', {}) self.instance_object, 'fake_id', {}) self.instance_object, 'fake_id', 'fake_id2', {}) self.instance_object, 'fake_id', 'fake_id2', {})"," self.instance, 'fake_id', {}) self.instance, 'fake_id', {}) self.instance, 'fake_id', 'fake_id2', {}) self.instance, 'fake_id', 'fake_id2', {})",76,51
openstack%2Ftempest~master~If7d534a83711ef85d4d6f17f9ab18df08ecdc978,openstack/tempest,master,If7d534a83711ef85d4d6f17f9ab18df08ecdc978,attempt visual offset filter,ABANDONED,2014-01-30 12:54:08.000000000,2014-01-30 21:19:54.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-01-30 12:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/eaf3f642f05e7e8b0fa70408a0967953e4158d1a', 'message': 'attempt visual offset filter\n\nChange-Id: If7d534a83711ef85d4d6f17f9ab18df08ecdc978\n'}, {'number': 2, 'created': '2014-01-30 13:05:02.000000000', 'files': ['tools/subunit-trace.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec91c7eaf371bd5326b5f0aee26c2cccd6bd91ac', 'message': 'attempt visual offset filter\n\nChange-Id: If7d534a83711ef85d4d6f17f9ab18df08ecdc978\n'}]",0,70111,ec91c7eaf371bd5326b5f0aee26c2cccd6bd91ac,3,2,2,2750,,,0,"attempt visual offset filter

Change-Id: If7d534a83711ef85d4d6f17f9ab18df08ecdc978
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/70111/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/subunit-trace.py'],1,eaf3f642f05e7e8b0fa70408a0967953e4158d1a,test_filter,"def cleanup_test_name(name): name = name[8:] name = name[:name.find('[')] name = cleanup_test_name(test['id']) worker = ' ' * (8 * int(tag[7:])) duration = ' in %d.%06ds' % ( stream.write('%s%s [%s]%s\n' % ( worker, name, test['status'], duration))"," worker = '(' + tag[7:] + ') ' duration = ' in %ds.%06d' % ( stream.write('%s: %s%s [%s]%s\n' % ( timestr, worker, test['id'], test['status'], duration))",9,4
openstack%2Fironic~master~I9bde8efa614f76b3ba950393cb49c5c619407aa8,openstack/ironic,master,I9bde8efa614f76b3ba950393cb49c5c619407aa8,SSHPower driver raises IronicExceptions,MERGED,2014-01-16 02:17:31.000000000,2014-01-30 21:19:08.000000000,2014-01-30 21:19:08.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8412}]","[{'number': 1, 'created': '2014-01-16 02:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/991b1bec536bfce65fb7f226a23417df4fb1f496', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions).\n\nDocstrings were added to some functions/methods in ssh.py.\n\nFixed some tests that were returning incorrect values for mocked\nprocessutils.ssh_execute calls.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}, {'number': 2, 'created': '2014-01-21 15:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fbbb2a4fa020f2a7a14b858c1a711cc9d794813b', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions).\n\nDocstrings were added to some functions/methods in ssh.py.\n\nFixed some tests that were returning incorrect values for mocked\nprocessutils.ssh_execute calls.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}, {'number': 3, 'created': '2014-01-21 16:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/af5490278e2c041e52809ca53dd43a98d59becf9', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions).\n\nDocstrings were added to some functions/methods in ssh.py.\n\nFixed some tests that were returning incorrect values for mocked\nprocessutils.ssh_execute calls.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}, {'number': 4, 'created': '2014-01-23 16:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/784e63c19f1e8b5c0fb0850e278858f32bb987c2', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions).\n\nDocstrings were added/modified to some functions/methods in ssh.py.\nThis makes it clear as to which methods raise which IronicExceptions.\n\nAlso fixed some tests that were returning incorrect values (lists\ninstead of tuples) for mocked processutils.ssh_execute calls.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}, {'number': 5, 'created': '2014-01-24 02:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/34db07e2746d855cdfe2a6da5cf875604f472bc0', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions).\n\nDocstrings were added/modified to some functions/methods in ssh.py.\nThis makes it clear as to which methods raise which IronicExceptions.\n\nAlso fixed some tests that were returning incorrect values (lists\ninstead of tuples) for mocked processutils.ssh_execute calls.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}, {'number': 6, 'created': '2014-01-29 23:00:00.000000000', 'files': ['ironic/tests/drivers/test_ssh.py', 'ironic/common/exception.py', 'ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f831e5558c0e22b7f1701c214ee5452c1cacce14', 'message': 'SSHPower driver raises IronicExceptions\n\nModified the methods of SSHPower driver to only raise IronicExceptions\n(instead of non-IronicExceptions). Specifically, an SSHCommandFailed\nexception is raised instead of an exception raised by\nprocessutils.ssh_execute().\n\nAlso modified one unit test, to check for an InvalidParameterValue\nexception instead of the more general IronicException.\n\nChange-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8\nPartial-Bug: #1267693\n'}]",35,66990,f831e5558c0e22b7f1701c214ee5452c1cacce14,31,7,6,6618,,,0,"SSHPower driver raises IronicExceptions

Modified the methods of SSHPower driver to only raise IronicExceptions
(instead of non-IronicExceptions). Specifically, an SSHCommandFailed
exception is raised instead of an exception raised by
processutils.ssh_execute().

Also modified one unit test, to check for an InvalidParameterValue
exception instead of the more general IronicException.

Change-Id: I9bde8efa614f76b3ba950393cb49c5c619407aa8
Partial-Bug: #1267693
",git fetch https://review.opendev.org/openstack/ironic refs/changes/90/66990/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/test_ssh.py', 'ironic/common/exception.py', 'ironic/drivers/modules/ssh.py']",3,991b1bec536bfce65fb7f226a23417df4fb1f496,bug/1267693,"def _ssh_execute(ssh_obj, cmd_to_exec): """"""Executes a command via ssh. Executes a command via ssh and returns a list of the lines of the output from the command. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param cmd_to_exec: command to execute. :returns: list of the lines of output from the command. :raises: SSHCommandFailed on an error from ssh. """""" try: output_list = processutils.ssh_execute(ssh_obj, cmd_to_exec)[0].split('\n') except Exception as e: LOG.debug(_(""Cannot execute SSH cmd %(cmd)s. Reason: %(err)s."") % {'cmd': cmd_to_exec, 'err': str(e)}) raise exception.SSHCommandFailed(cmd=cmd_to_exec) return output_list def _parse_driver_info(node): """"""Gets the information needed for accessing the node. :param node: the Node of interest. :returns: dictionary of information. :raises InvalidParameterValue if any required parameters are missing or incorrect. """""" """"""Returns a node's current power state. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_OFF, POWER_ON. :raises: NodeNotFound :raises: SSHCommandFailed on an error from ssh. """""" running_list = _ssh_execute(ssh_obj, cmd_to_exec) """"""Returns an SSH client connected to a node. :param node: the Node. :returns: paramiko.SSHClient, an active ssh connection. :raises: InvalidParameterValue if any connection parameters are incorrect or if ssh failed to connect to the node. """""" try: return utils.ssh_connect(_parse_driver_info(node)) except exception.SSHConnectFailed as e: raise exception.InvalidParameterValue(_(""SSH connection cannot"" "" be established: %s"") % e) """"""Get the name the host uses to reference the node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: the name or None if not found. :raises: SSHCommandFailed on an error from ssh. """""" full_node_list = _ssh_execute(ssh_obj, cmd_to_exec) hosts_node_mac_list = _ssh_execute(ssh_obj, cmd_to_exec) """"""Power ON this node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_ON or ERROR. :raises: NodeNotFound :raises: SSHCommandFailed on an error from ssh. """""" _ssh_execute(ssh_obj, cmd_to_power_on) """"""Power OFF this node. :param ssh_obj: paramiko.SSHClient, an active ssh connection. :param driver_info: information for accessing the node. :returns: one of ironic.common.states POWER_OFF or ERROR. :raises: NodeNotFound :raises: SSHCommandFailed on an error from ssh. """""" _ssh_execute(ssh_obj, cmd_to_power_off) :raises: InvalidParameterValue if any connection parameters are incorrect or if ssh failed to connect to the node. _get_connection(node) :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect or if ssh failed to connect to the node. :raises: NodeNotFound. :raises: SSHCommandFailed on an error from ssh. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect, if ssh failed to connect to the node, or if the desired power state is invalid. :raises: NodeNotFound. :raises: PowerStateFailure if it failed to set power state to pstate. :raises: SSHCommandFailed on an error from ssh. :param task: An instance of `ironic.manager.task_manager.TaskManager`. :raises: InvalidParameterValue if any connection parameters are incorrect or if ssh failed to connect to the node. :raises: NodeNotFound. :raises: PowerStateFailure if it failed to set power state to POWER_ON. :raises: SSHCommandFailed on an error from ssh.","def _parse_driver_info(node): """"""Returns a node's current power state."""""" running_list = processutils.ssh_execute(ssh_obj, cmd_to_exec)[0].split('\n') return utils.ssh_connect(_parse_driver_info(node)) """"""Get the name the host uses to reference the node."""""" full_node_list = processutils.ssh_execute(ssh_obj, cmd_to_exec)[0].split('\n') hosts_node_mac_list = processutils.ssh_execute(ssh_obj, cmd_to_exec)[0].split('\n') """"""Power ON this node."""""" processutils.ssh_execute(ssh_obj, cmd_to_power_on) """"""Power OFF this node."""""" processutils.ssh_execute(ssh_obj, cmd_to_power_off) :raises: InvalidParameterValue try: _get_connection(node) except exception.SSHConnectFailed as e: raise exception.InvalidParameterValue(_(""SSH connection cannot"" "" be established: %s"") % e) :param task: A instance of `ironic.manager.task_manager.TaskManager`. :param task: A instance of `ironic.manager.task_manager.TaskManager`. :raises: exception.IronicException or exception.PowerStateFailure. :param task: A instance of `ironic.manager.task_manager.TaskManager`. :raises: exception.PowerStateFailure.",245,38
openstack%2Fironic~master~If146d80ad9acd33bd5c676e6b2ba2142c9b07a84,openstack/ironic,master,If146d80ad9acd33bd5c676e6b2ba2142c9b07a84,mock's return value for processutils.ssh_execute,MERGED,2014-01-27 21:52:53.000000000,2014-01-30 21:11:59.000000000,2014-01-30 21:11:59.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 8106}]","[{'number': 1, 'created': '2014-01-27 21:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/094256e10d7e6e1a479d674d0f467ae4aeb7a677', 'message': ""mock's return value for processutils.ssh_execute\n\nIn tests/drivers/test_ssh.py, SSHPrivateMethodsTestCase tests are mocking\nprocessutils.ssh_execute() and sets its return value to a list. However,\nprocessutils.ssh_execute() doesn't return a list, it returns a tuple: (stdout, stderr).\n\nThis fixes the tests, by changing the return values to (stdout, stderr) tuples.\n\nChange-Id: If146d80ad9acd33bd5c676e6b2ba2142c9b07a84\nCloses-Bug: #1273452\n""}, {'number': 2, 'created': '2014-01-29 21:15:24.000000000', 'files': ['ironic/tests/drivers/test_ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5978ff38181191f9f844129772c07c865154443a', 'message': ""mock's return value for processutils.ssh_execute\n\nIn tests/drivers/test_ssh.py, SSHPrivateMethodsTestCase tests are mocking\nprocessutils.ssh_execute() and sets its return value to a list. However,\nprocessutils.ssh_execute() doesn't return a list, it returns a tuple: (stdout, stderr).\n\nThis fixes the tests, by changing the return values to (stdout, stderr) tuples.\n\nChange-Id: If146d80ad9acd33bd5c676e6b2ba2142c9b07a84\nCloses-Bug: #1273452\n""}]",0,69479,5978ff38181191f9f844129772c07c865154443a,14,5,2,6618,,,0,"mock's return value for processutils.ssh_execute

In tests/drivers/test_ssh.py, SSHPrivateMethodsTestCase tests are mocking
processutils.ssh_execute() and sets its return value to a list. However,
processutils.ssh_execute() doesn't return a list, it returns a tuple: (stdout, stderr).

This fixes the tests, by changing the return values to (stdout, stderr) tuples.

Change-Id: If146d80ad9acd33bd5c676e6b2ba2142c9b07a84
Closes-Bug: #1273452
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/69479/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/drivers/test_ssh.py'],1,094256e10d7e6e1a479d674d0f467ae4aeb7a677,bug/1273452," # Set up the mock for processutils.ssh_execute because most tests use # it. processutils.ssh_execute returns (stdout, stderr). self.exec_ssh_mock.return_value = ('', '') self.exec_ssh_mock.return_value = ( '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}', '') self.exec_ssh_mock.return_value = ( '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}', '') self.exec_ssh_mock.return_value = ( '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}', '') self.exec_ssh_mock.side_effect = [('NodeName', ''), ('52:54:00:cf:2d:31', '')] self.exec_ssh_mock.side_effect = [('NodeName', ''), ('52:54:00:cf:2d:31', '')]"," #setup the mock for processutils.ssh_execute because most tests use it self.exec_ssh_mock.return_value = [ '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}'] self.exec_ssh_mock.return_value = [ '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}'] self.exec_ssh_mock.return_value = [ '""NodeName"" {b43c4982-110c-4c29-9325-d5f41b053513}'] self.exec_ssh_mock.side_effect = [['NodeName'], ['52:54:00:cf:2d:31']] self.exec_ssh_mock.side_effect = [['NodeName'], ['52:54:00:cf:2d:31']] self.exec_ssh_mock.return_value = None self.exec_ssh_mock.return_value = None self.exec_ssh_mock.return_value = None self.exec_ssh_mock.return_value = None",13,13
openstack%2Foperations-guide~master~Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a,openstack/operations-guide,master,Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a,Address Editor comments for Maintenance chapter,MERGED,2014-01-23 15:44:28.000000000,2014-01-30 21:05:06.000000000,2014-01-30 21:05:06.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 6859}]","[{'number': 1, 'created': '2014-01-23 15:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/20a71340db4601183ff72666d02ce6fe4f633f24', 'message': ""Address Editor comments for Maintancen chapter\n\n* make config tool list a 'tip'\n* turn user file access note into a warning\n* explain acls\n\nChange-Id: Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a\n""}, {'number': 2, 'created': '2014-01-23 15:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6aa9b3071bd175b10e403385278d3d292b470cd1', 'message': ""Address Editor comments for Maintenance chapter\n\n* make config tool list a 'tip'\n* turn user file access note into a warning\n* explain ACLs\n\nChange-Id: Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a\n""}, {'number': 3, 'created': '2014-01-28 23:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6357f84f6054c9dc7cf9b4e578505191be3d9a3f', 'message': ""Address Editor comments for Maintenance chapter\n\n* make config tool list a 'tip'\n* turn user file access note into a warning\n* explain ACLs\n\nChange-Id: Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a\n""}, {'number': 4, 'created': '2014-01-30 20:50:38.000000000', 'files': ['doc/openstack-ops/ch_ops_maintenance.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/7a6608bde0b758ebb6ebe20a37373ccea93b3377', 'message': ""Address Editor comments for Maintenance chapter\n\n* make config tool list a 'tip'\n* turn user file access note into a warning\n* explain ACLs\n\nChange-Id: Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a\n""}]",4,68669,7a6608bde0b758ebb6ebe20a37373ccea93b3377,20,6,4,612,,,0,"Address Editor comments for Maintenance chapter

* make config tool list a 'tip'
* turn user file access note into a warning
* explain ACLs

Change-Id: Ie112e5ac24cc739d0a3bdf4c0c880f0b92ade14a
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/69/68669/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_maintenance.xml'],1,20a71340db4601183ff72666d02ce6fe4f633f24,banderson-config," <warning> </warning> this could change the acls (Access Control Lists, or file permissions, are used to determine which accounts can perform what operations on files and directories) and make the instance <tip><para>Several configuration management tools are available, (http://bcfg2.org).</para></tip>"," <note> </note> this could change the acls and make the instance <para>Several configuration management tools are available, (http://bcfg2.org).</para>",8,5
openstack%2Fpuppet-neutron~stable%2Fhavana~I4b34e47dc9a814c0fbcc0fd6d8fe6033081a51d0,openstack/puppet-neutron,stable/havana,I4b34e47dc9a814c0fbcc0fd6d8fe6033081a51d0,Fixing neutron::server deprecated warnings,MERGED,2014-01-23 17:00:16.000000000,2014-01-30 21:03:38.000000000,2014-01-30 21:03:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 6754}, {'_account_id': 9415}]","[{'number': 1, 'created': '2014-01-23 17:00:16.000000000', 'files': ['manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b799640d219b42955165bd81acde5b32ee0f99f9', 'message': 'Fixing neutron::server deprecated warnings\n\nClearing default values for deprecated reconnect_interval,\nsql_idle_timeout, and sql_max_retries parameters.\n\nChange-Id: I4b34e47dc9a814c0fbcc0fd6d8fe6033081a51d0\nCloses-Bug: #1269623\n(cherry picked from commit b14cee10c155c30dbf7b1645dfa095c4d5b0aa73)\n'}]",0,68696,b799640d219b42955165bd81acde5b32ee0f99f9,8,5,1,9061,,,0,"Fixing neutron::server deprecated warnings

Clearing default values for deprecated reconnect_interval,
sql_idle_timeout, and sql_max_retries parameters.

Change-Id: I4b34e47dc9a814c0fbcc0fd6d8fe6033081a51d0
Closes-Bug: #1269623
(cherry picked from commit b14cee10c155c30dbf7b1645dfa095c4d5b0aa73)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/96/68696/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/server.pp'],1,b799640d219b42955165bd81acde5b32ee0f99f9,,"# [*agent_down_time*] # (optional) Seconds to regard the agent as down; should be at least twice # report_interval, to be sure the agent is down for good. # Defaults to: 9 # # [*report_interval*] # (optional) Seconds between nodes reporting state to server; should be less than # agent_down_time, best if it is half or less than agent_down_time. # Defaults to: 4 # # [*router_scheduler_driver*] # (optional) Driver to use for scheduling router to a default L3 agent. Could be: # neutron.scheduler.l3_agent_scheduler.ChanceScheduler to schedule a router in a random way # neutron.scheduler.l3_agent_scheduler.LeastRoutersScheduler to allocate on an L3 agent with the least number of routers bound. # Defaults to: neutron.scheduler.l3_agent_scheduler.ChanceScheduler # $package_ensure = 'present', $enabled = true, $auth_password = false, $auth_type = 'keystone', $auth_host = 'localhost', $auth_port = '35357', $auth_admin_prefix = false, $auth_tenant = 'services', $auth_user = 'neutron', $auth_protocol = 'http', $auth_uri = false, $sql_connection = false, $connection = 'sqlite:////var/lib/neutron/ovs.sqlite', $max_retries = '10', $sql_max_retries = false, $sql_idle_timeout = false, $idle_timeout = '3600', $reconnect_interval = false, $retry_interval = '10', $log_file = false, $log_dir = '/var/log/neutron', $api_workers = '0', $agent_down_time = '9', $report_interval = '4', $router_scheduler_driver = 'neutron.scheduler.l3_agent_scheduler.ChanceScheduler' 'DEFAULT/api_workers': value => $api_workers; 'DEFAULT/agent_down_time': value => $agent_down_time; 'DEFAULT/report_interval': value => $report_interval; 'DEFAULT/router_scheduler_driver': value => $router_scheduler_driver; 'database/connection': value => $connection_real; 'database/idle_timeout': value => $idle_timeout_real; 'database/retry_interval': value => $retry_interval_real; 'database/max_retries': value => $max_retries_real;"," $package_ensure = 'present', $enabled = true, $auth_password = false, $auth_type = 'keystone', $auth_host = 'localhost', $auth_port = '35357', $auth_admin_prefix = false, $auth_tenant = 'services', $auth_user = 'neutron', $auth_protocol = 'http', $auth_uri = false, $sql_connection = 'sqlite:////var/lib/neutron/ovs.sqlite', $connection = 'sqlite:////var/lib/neutron/ovs.sqlite', $max_retries = '10', $sql_max_retries = '10', $sql_idle_timeout = '3600', $idle_timeout = '3600', $reconnect_interval = '10', $retry_interval = '10', $log_file = false, $log_dir = '/var/log/neutron', $api_workers = '0' 'DEFAULT/api_workers': value => $api_workers; 'database/connection': value => $connection_real; 'database/idle_timeout': value => $idle_timeout_real; 'database/retry_interval': value => $retry_interval_real; 'database/max_retries': value => $max_retries_real;",49,27
openstack%2Fnova~master~Ibfb120ccdeb89291059ffe355957f386aec75007,openstack/nova,master,Ibfb120ccdeb89291059ffe355957f386aec75007,Move compute API is_volume_backed to BDM objects,MERGED,2013-11-21 19:24:18.000000000,2014-01-30 20:58:49.000000000,2014-01-30 20:58:46.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 4458}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-21 19:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56231f5970433d036c56ef5aafd551b614b2a472', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the functionality of the compute API\n_get_bdm_image_metadata method into the block device objects list class,\neffectively duplicating some of the code. This is however necessary,\nsince we still need to be able to deal with old-style block devices\nuntil we deprecate the v2 API.\n\nAdditionally, it adds several useful utility methods to block device\nobject and list classes to make the code using them more expressive.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 2, 'created': '2013-11-28 14:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f8a37bc9a43220ba83d79934df0d0f889092021', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 3, 'created': '2013-11-29 15:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11f4c4411c3842683a111eeb2c8339a5be694e8a', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 4, 'created': '2013-12-03 21:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd60826859336aaa65fa5c0123625665826dbb28', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 5, 'created': '2013-12-03 21:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3ddeaf69cadfbb02c494dc6d603aa1649301251', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 6, 'created': '2013-12-09 13:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a73353cdbea78820e2b38ae019b4db2349ad98ad', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 7, 'created': '2013-12-12 17:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f113c88f221455fc9d971c4c7cb24e72639d26e', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 8, 'created': '2013-12-13 10:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecc63f884ff7059675010f5b1c44629fec875d54', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 9, 'created': '2013-12-13 13:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f55ebd66b34f26440940864a1d999289f97ce93', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 10, 'created': '2013-12-13 17:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/415825c1639bd877302be1d20c1b31a7d575272f', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 11, 'created': '2013-12-17 12:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d6130df1c3e406ffb24ec7f73b17f03ce0c3b69', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 12, 'created': '2013-12-18 14:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a838c8895c1a70141e6313bef944bf0392d0ee8', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 13, 'created': '2013-12-19 15:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8609781f81da2f5a4fa63600f4c39c703236619', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 14, 'created': '2013-12-23 20:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4180efdc9307c02cc2088ed8887163bbef265ac6', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 15, 'created': '2014-01-02 09:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/658d4811080fef1f31c72061ebd8e1e2657f1885', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 16, 'created': '2014-01-03 15:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dc5a622982512b07b33b54405685d34364ce631', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 17, 'created': '2014-01-06 13:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f45af998f6ca59e89f2d14509b4b22db854e58d5', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 18, 'created': '2014-01-06 17:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcf3d260e7f8adc13e3cb7fd6169d214b9688daf', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 19, 'created': '2014-01-13 14:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0b73b335c1997839cd59232e5145e22f3bab662', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 20, 'created': '2014-01-14 23:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c302beaa473237fefc8d28b376f219c49937bb85', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 21, 'created': '2014-01-15 10:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7225e12bfedd66a80cb6fee91aab3647744669fd', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 22, 'created': '2014-01-17 16:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2802f5f6d2b13437a19c1968e3272528ba98c53d', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 23, 'created': '2014-01-22 17:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d520d5bbf6fa0fc11808b7db392afb3729ed381', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 24, 'created': '2014-01-27 12:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/135a1016cce9c51ebea6290a04d7897fc47f1fce', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}, {'number': 25, 'created': '2014-01-30 14:32:58.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9b00f39ccef22be851bba8da71669ae7074c0a7f', 'message': 'Move compute API is_volume_backed to BDM objects\n\nThis patch makes is_volume_backed_instance use block device objects. It\nis a first step towards using new-world BDM objects in code paths that\ndo not need to send them over RPC.\n\nIt will also be the way to go forward when getting rid of legacy block\ndevice usage anywhere outside of the v2 API.\n\nThis patch also moves some of the uses of the compute API\n_get_bdm_image_metadata method over the block device objects list class\nroot_metadata method, which has some of the code duplicated. The\nduplication is however necessary, since we still need to be able to deal\nwith old-style block devices until we deprecate the v2 API.\n\nRelated to blueprint: icehouse-objects\nRelated to blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ibfb120ccdeb89291059ffe355957f386aec75007\n'}]",19,57748,9b00f39ccef22be851bba8da71669ae7074c0a7f,93,8,25,5511,,,0,"Move compute API is_volume_backed to BDM objects

This patch makes is_volume_backed_instance use block device objects. It
is a first step towards using new-world BDM objects in code paths that
do not need to send them over RPC.

It will also be the way to go forward when getting rid of legacy block
device usage anywhere outside of the v2 API.

This patch also moves some of the uses of the compute API
_get_bdm_image_metadata method over the block device objects list class
root_metadata method, which has some of the code duplicated. The
duplication is however necessary, since we still need to be able to deal
with old-style block devices until we deprecate the v2 API.

Related to blueprint: icehouse-objects
Related to blueprint: clean-up-legacy-block-device-mapping

Change-Id: Ibfb120ccdeb89291059ffe355957f386aec75007
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/57748/19 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/objects/test_block_device.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/objects/block_device.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py', 'nova/tests/compute/test_compute.py', 'nova/api/openstack/compute/servers.py']",11,56231f5970433d036c56ef5aafd551b614b2a472,bp/icehouse-objects,"from nova.objects import block_device as block_device_obj bdms = block_device_obj.BlockDeviceMappingList.get_by_instance_uuid( context, instance['uuid']) props = bdms.root_metadata( context, self.compute_api.image_service, self.compute_api.volume_api) image_meta = {'properties': props}"," bdms = self.compute_api.get_instance_bdms(context, instance, legacy=False) # NOTE(Vincent Hou) The private method # _get_bdm_image_metadata only works, when boot # device is set to 'vda'. It needs to be fixed later, # but tentatively we use it here. image_meta = {'properties': self.compute_api. _get_bdm_image_metadata(context, bdms, legacy_bdm=False)}",259,159
openstack%2Fopenstack-manuals~master~I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9,openstack/openstack-manuals,master,I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9,Add new CLI Reference manual,MERGED,2014-01-29 19:15:31.000000000,2014-01-30 20:55:49.000000000,2014-01-30 20:55:48.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-01-29 19:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4ad60777e8e6bc9745985c1cb67f00562b69bcd1', 'message': 'Add new CLI Reference manual\n\nThis is the first version of a CLI Reference manual.\n\nIt takes content from the End User Guide.\n\nChange-Id: I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9\n'}, {'number': 2, 'created': '2014-01-29 19:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8751386bf43be75e6986c317f26543ff8766aec7', 'message': 'Add new CLI Reference manual\n\nThis is the first version of a CLI Reference manual.\n\nIt takes content from the End User Guide.\n\nChange-Id: I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9\n'}, {'number': 3, 'created': '2014-01-30 17:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/28e4c21abc45aa8d8064749bedd95d4d73768615', 'message': 'Add new CLI Reference manual\n\nThis is the first version of a CLI Reference manual.\n\nIt takes content from the End User Guide.\n\nChange-Id: I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9\n'}, {'number': 4, 'created': '2014-01-30 17:49:01.000000000', 'files': ['doc/common/section_cli_version.xml', 'doc/cli-reference/ch_command_reference.xml', 'doc/cli-reference/bk-cli-reference.xml', 'doc/pom.xml', 'doc/cli-reference/ch_cli.xml', 'doc/cli-reference/ch_preface.xml', 'doc/user-guide/ch_cli.xml', 'doc/cli-reference/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9c6ae790a26d8aad088f3334e0770868a366e1ec', 'message': 'Add new CLI Reference manual\n\nThis is the first version of a CLI Reference manual.\n\nIt takes content from the End User Guide.\n\nChange-Id: I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9\n'}]",0,69942,9c6ae790a26d8aad088f3334e0770868a366e1ec,15,5,4,6547,,,0,"Add new CLI Reference manual

This is the first version of a CLI Reference manual.

It takes content from the End User Guide.

Change-Id: I6f3ff1e56975cb7ea1af03ebd0d85f5eb8346af9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/42/69942/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/cli-reference/ch_command_reference.xml', 'doc/cli-reference/bk-cli-reference.xml', 'doc/pom.xml', 'doc/cli-reference/ch_cli.xml', 'doc/cli-reference/ch_preface.xml', 'doc/cli-reference/pom.xml']",6,4ad60777e8e6bc9745985c1cb67f00562b69bcd1,cli-reference,"<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd""> <parent> <groupId>org.openstack.docs</groupId> <artifactId>parent-pom</artifactId> <version>1.0.0-SNAPSHOT</version> <relativePath>../pom.xml</relativePath> </parent> <modelVersion>4.0.0</modelVersion> <artifactId>openstack-cli-reference</artifactId> <packaging>jar</packaging> <name>OpenStack Command Line Interface Reference</name> <properties> <!-- This is set by Jenkins according to the branch. --> <release.path.name>local</release.path.name> <comments.enabled>1</comments.enabled> </properties> <!-- ################################################ --> <!-- USE ""mvn clean generate-sources"" to run this POM --> <!-- ################################################ --> <build> <plugins> <plugin> <groupId>com.rackspace.cloud.api</groupId> <artifactId>clouddocs-maven-plugin</artifactId> <!-- version is set in ../pom.xml file --> <executions> <execution> <id>generate-webhelp</id> <goals> <goal>generate-webhelp</goal> </goals> <phase>generate-sources</phase> <configuration> <!-- These parameters only apply to webhelp --> <enableDisqus>${comments.enabled}</enableDisqus> <disqusShortname>os-image-guide</disqusShortname> <enableGoogleAnalytics>1</enableGoogleAnalytics> <googleAnalyticsId>UA-17511903-1</googleAnalyticsId> <generateToc> appendix toc,title article/appendix nop article toc,title book toc,title,figure,table,example,equation chapter toc section toc part toc preface toc qandadiv toc qandaset toc reference toc,title set toc,title </generateToc> <!-- The following elements sets the autonumbering of sections in output for chapter numbers but no numbered sections--> <sectionAutolabel>0</sectionAutolabel> <formalProcedures>0</formalProcedures> <tocSectionDepth>1</tocSectionDepth> <tocChapterDepth>1</tocChapterDepth> <sectionLabelIncludesComponentLabel>0</sectionLabelIncludesComponentLabel> <webhelpDirname>cli-reference</webhelpDirname> <pdfFilenameBase>cli-reference</pdfFilenameBase> </configuration> </execution> </executions> <configuration> <!-- These parameters apply to pdf and webhelp --> <profileAudience>enduser</profileAudience> <xincludeSupported>true</xincludeSupported> <sourceDirectory>.</sourceDirectory> <includes> bk-cli-reference.xml </includes> <branding>openstack</branding> <canonicalUrlBase>http://docs.openstack.org/cli-reference/content/</canonicalUrlBase> </configuration> </plugin> </plugins> </build> </project> ",,207,0
openstack%2Fnova~master~I24ace8f730978d2e7046986f212c34604c7b7f20,openstack/nova,master,I24ace8f730978d2e7046986f212c34604c7b7f20,Add block device mapping objects implementation,MERGED,2013-11-21 19:24:17.000000000,2014-01-30 20:54:58.000000000,2014-01-30 20:54:54.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 4458}, {'_account_id': 4912}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 7770}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-21 19:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55deaa9a0879a5ae2c2fab8296d050c9926493f3', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 2, 'created': '2013-11-28 14:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/515477533d68d947fc2638e578ee453a27dc9c53', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 3, 'created': '2013-11-29 15:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e11c4a54332f16fc64f2740def50d871f6b15ec3', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 4, 'created': '2013-12-03 21:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63a2b091d990734d79d7b717a6b1333dd3c66e0f', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 5, 'created': '2013-12-09 13:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4b782e00cd35428861c1b9606d45a6763bec86f', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 6, 'created': '2013-12-12 17:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1a0bac5a447f32aaf0cd58be8f91a5080554aa1', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 7, 'created': '2013-12-13 10:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f039f053674db1cf6ed365a790db59d939c5a583', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 8, 'created': '2013-12-13 13:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aedd19691093e7d4df7d13c498b496d32a7b6f36', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 9, 'created': '2013-12-13 17:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d5c3fd921f4362f4569608b231bfc278a52b83d', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 10, 'created': '2013-12-17 12:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38dd523f853e93d59800c19b42c892978db5e857', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 11, 'created': '2013-12-18 14:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8202755aaf798c4b8dfe008dfa34431d81086f7a', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 12, 'created': '2013-12-19 15:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c42d20a4ab67e0b068c176d8e0cfbe99c53626dc', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 13, 'created': '2013-12-23 20:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e82af819f51c7dd630e5fb6dcc3c46fe72f15b3', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 14, 'created': '2014-01-02 09:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab8b094ea39ffcc5edbd59ae65b3c7c9de769106', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 15, 'created': '2014-01-03 15:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bc41c125d0a1c61a7d592f34b52efe3a260c458', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 16, 'created': '2014-01-06 13:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/898338a63ed8e559d12aadcded6d27fdc015d198', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 17, 'created': '2014-01-06 17:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b5393256472c93a449f1cb3f949caec3699563a', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 18, 'created': '2014-01-13 14:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bc0cbc67f2a2efaedf5f3790314fd49dea67448', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 19, 'created': '2014-01-14 23:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfcea8f0192974bc5ac1ed0a942df95c018f0027', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 20, 'created': '2014-01-15 10:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26a5efa678091fa8e6ce85ffcc389ba5f1f91746', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 21, 'created': '2014-01-17 16:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/386c49e36ceb74891a82e2e9f86c9a5f2a01ba0f', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 22, 'created': '2014-01-22 17:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c6afb64800efb20bba82f78f3b3bda8d966a292', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 23, 'created': '2014-01-27 12:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fd60068f45560bc2e26fcf23505d62f9dc80a32', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}, {'number': 24, 'created': '2014-01-30 14:33:04.000000000', 'files': ['nova/exception.py', 'nova/tests/objects/test_block_device.py', 'nova/tests/fake_block_device.py', 'nova/objects/__init__.py', 'nova/objects/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5a7fe0023edc913b844362f6208e37b0aaa3d5ad', 'message': 'Add block device mapping objects implementation\n\nThis patch introduces the basic block device mapping objects and list\nclasses and adds tests for the basic functionality.\n\nRelated to blueprint: icehouse-objects\n\nChange-Id: I24ace8f730978d2e7046986f212c34604c7b7f20\n'}]",43,57747,5a7fe0023edc913b844362f6208e37b0aaa3d5ad,122,12,24,5511,,,0,"Add block device mapping objects implementation

This patch introduces the basic block device mapping objects and list
classes and adds tests for the basic functionality.

Related to blueprint: icehouse-objects

Change-Id: I24ace8f730978d2e7046986f212c34604c7b7f20
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/57747/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_block_device.py', 'nova/tests/fake_block_device.py', 'nova/objects/__init__.py', 'nova/objects/block_device.py']",4,55deaa9a0879a5ae2c2fab8296d050c9926493f3,bp/icehouse-objects,"# Copyright 2013 Red Hat Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import db from nova.objects import base from nova.objects import fields class BlockDeviceMapping(base.NovaPersistentObject, base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'id': fields.IntegerField(), 'instance_uuid': fields.UUIDField(nullable=True), 'source_type': fields.StringField(nullable=True), 'destination_type': fields.StringField(nullable=True), 'guest_format': fields.StringField(nullable=True), 'device_type': fields.StringField(nullable=True), 'disk_bus': fields.StringField(nullable=True), 'boot_index': fields.IntegerField(nullable=True), 'device_name': fields.StringField(nullable=True), 'delete_on_termination': fields.BooleanField(default=False), 'snapshot_id': fields.StringField(nullable=True), 'volume_id': fields.StringField(nullable=True), 'volume_size': fields.IntegerField(nullable=True), 'image_id': fields.StringField(nullable=True), 'no_device': fields.BooleanField(nullable=True), 'connection_info': fields.StringField(nullable=True), } legacy = False # Always use this to pass legacy @staticmethod def _from_db_object(context, block_device, db_block_device): for key in block_device.fields: block_device[key] = db_block_device[key] block_device._context = context block_device.obj_reset_changes() return block_device @base.remotable def save(self, context): updates = self.obj_get_changes() updates.pop('id', None) updated = db.block_device_mapping_update(self._context, self.id, updates, legacy=self.legacy) self._from_db_object(context, self, updated) class BlockDeviceMappingList(base.ObjectListBase, base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'objects': fields.ListOfObjectsField('BlockDeviceMapping'), } @base.remotable_classmethod def get_by_instance_uuid(cls, context, instance_uuid): db_bdms = db.block_device_mapping_get_all_by_instance( context, instance_uuid) return base.obj_make_list(context, cls(), BlockDeviceMapping, db_bdms) ",,201,0
openstack%2Fnova~master~Idb30fca9d392fe5f5b4063ba1b22a967329987f6,openstack/nova,master,Idb30fca9d392fe5f5b4063ba1b22a967329987f6,Remove duplicated method in mock_key_mgr,MERGED,2014-01-29 22:05:33.000000000,2014-01-30 20:48:03.000000000,2014-01-30 20:48:00.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 22:05:33.000000000', 'files': ['nova/keymgr/mock_key_mgr.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7370ca5344d5ad1e9f7cdee9615132a37da392b7', 'message': 'Remove duplicated method in mock_key_mgr\n\nThe method _generate_key_id was duplicated in\nnova/keymgr/mock_key_mgr.py\n\nThis patchset removes one of the duplicates.\n\nChange-Id: Idb30fca9d392fe5f5b4063ba1b22a967329987f6\n'}]",0,69993,7370ca5344d5ad1e9f7cdee9615132a37da392b7,20,5,1,9420,,,0,"Remove duplicated method in mock_key_mgr

The method _generate_key_id was duplicated in
nova/keymgr/mock_key_mgr.py

This patchset removes one of the duplicates.

Change-Id: Idb30fca9d392fe5f5b4063ba1b22a967329987f6
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/69993/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/keymgr/mock_key_mgr.py'],1,7370ca5344d5ad1e9f7cdee9615132a37da392b7,remove_dup_code,, def _generate_key_id(self): key_id = uuidutils.generate_uuid() while key_id in self.keys: key_id = uuidutils.generate_uuid() return key_id ,0,7
openstack%2Ftrove~master~Ib051b5325c0914f2ab3bc293b0052abe8257996d,openstack/trove,master,Ib051b5325c0914f2ab3bc293b0052abe8257996d,Fix Occasional test_one_network_label_exact Fail,MERGED,2014-01-26 02:00:57.000000000,2014-01-30 20:45:18.000000000,2014-01-30 20:45:18.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}]","[{'number': 1, 'created': '2014-01-26 02:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d5b4712e8e5558f9a8df20d103342eb243043228', 'message': 'Fix Occasional test_one_network_label_exact Fail\n\nfixes the occasional tox failure for test_one_network_label_exact by\nsaving and restoring the original conf values before every test.\n\nsee bug details for more information.\n\nCloses-Bug #1272806\n\nChange-Id: Ib051b5325c0914f2ab3bc293b0052abe8257996d\n'}, {'number': 2, 'created': '2014-01-26 02:03:05.000000000', 'files': ['trove/tests/unittests/instance/test_instance_views.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/2f6e8a246c0c1ebf4162b37e360877475fa63126', 'message': 'Fix Occasional test_one_network_label_exact Fail\n\nfixes the occasional tox failure for test_one_network_label_exact by\nsaving and restoring the original conf values before every test.\n\nsee bug details for more information.\n\nCloses-Bug: #1272806\n\nChange-Id: Ib051b5325c0914f2ab3bc293b0052abe8257996d\n'}]",0,69153,2f6e8a246c0c1ebf4162b37e360877475fa63126,11,5,2,8214,,,0,"Fix Occasional test_one_network_label_exact Fail

fixes the occasional tox failure for test_one_network_label_exact by
saving and restoring the original conf values before every test.

see bug details for more information.

Closes-Bug: #1272806

Change-Id: Ib051b5325c0914f2ab3bc293b0052abe8257996d
",git fetch https://review.opendev.org/openstack/trove refs/changes/53/69153/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/instance/test_instance_views.py'],1,d5b4712e8e5558f9a8df20d103342eb243043228,bug/1272806, self.orig_label_regex = CONF.network_label_regex self.orig_ip_regex = CONF.ip_regex CONF.network_label_regex = self.orig_label_regex CONF.ip_regex = self.orig_ip_regex, self.orig_conf = CONF.network_label_regex CONF.network_label_regex = self.orig_conf CONF.ip_start = None,4,3
openstack%2Fhorizon~stable%2Fhavana~I080e6c6d1e426a878c1d088763bbc7e5add15820,openstack/horizon,stable/havana,I080e6c6d1e426a878c1d088763bbc7e5add15820,Specify tenant_id when retrieving LBaaS/VPNaaS resource,MERGED,2013-12-20 10:53:58.000000000,2014-01-30 20:35:03.000000000,2014-01-30 20:35:02.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 7585}]","[{'number': 1, 'created': '2013-12-20 10:53:58.000000000', 'files': ['openstack_dashboard/dashboards/project/firewalls/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/dashboards/project/loadbalancers/tables.py', 'openstack_dashboard/dashboards/project/loadbalancers/forms.py', 'openstack_dashboard/dashboards/project/loadbalancers/tabs.py', 'openstack_dashboard/dashboards/project/vpn/tabs.py', 'openstack_dashboard/dashboards/project/vpn/tests.py', 'openstack_dashboard/dashboards/project/vpn/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/660cd866c0fbccc2962eaa0046b14170cde46a2d', 'message': 'Specify tenant_id when retrieving LBaaS/VPNaaS resource\n\nIn Neutron API, resources from all tenants are listed when\nretrieving a list of resources with admin role. Horizon\nproject dashboard is for project-specific operations,\nso we should retrieve only resources of the given project.\nLBaaS/VPNaaS panels have this problem, but FWaaS does not.\nrouter_list should be called with tenant_id filter too.\n\nThis commit also fixes VPN/FWaaS tests so that it extract tenant_id\nfrom request attribute rather than use tenant_id of test_data.\n\nChange-Id: I080e6c6d1e426a878c1d088763bbc7e5add15820\nCloses-Bug: #1244126\n(cherry picked from commit 630b43349160f8b35d54196aabaa6e1afe5e4d61)\n'}]",0,63376,660cd866c0fbccc2962eaa0046b14170cde46a2d,26,8,1,841,,,0,"Specify tenant_id when retrieving LBaaS/VPNaaS resource

In Neutron API, resources from all tenants are listed when
retrieving a list of resources with admin role. Horizon
project dashboard is for project-specific operations,
so we should retrieve only resources of the given project.
LBaaS/VPNaaS panels have this problem, but FWaaS does not.
router_list should be called with tenant_id filter too.

This commit also fixes VPN/FWaaS tests so that it extract tenant_id
from request attribute rather than use tenant_id of test_data.

Change-Id: I080e6c6d1e426a878c1d088763bbc7e5add15820
Closes-Bug: #1244126
(cherry picked from commit 630b43349160f8b35d54196aabaa6e1afe5e4d61)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/63376/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/firewalls/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/dashboards/project/loadbalancers/tables.py', 'openstack_dashboard/dashboards/project/loadbalancers/forms.py', 'openstack_dashboard/dashboards/project/loadbalancers/tabs.py', 'openstack_dashboard/dashboards/project/vpn/tabs.py', 'openstack_dashboard/dashboards/project/vpn/tests.py', 'openstack_dashboard/dashboards/project/vpn/workflows.py']",9,660cd866c0fbccc2962eaa0046b14170cde46a2d,bug/1244126," tenant_id = request.user.tenant_id routers = api.neutron.router_list(request, tenant_id=tenant_id) tenant_id = self.request.user.tenant_id ikepolicies = api.vpn.ikepolicies_get(request, tenant_id=tenant_id) tenant_id = self.request.user.tenant_id ipsecpolicies = api.vpn.ipsecpolicies_get(request, tenant_id=tenant_id) tenant_id = self.request.user.tenant_id vpnservices = api.vpn.vpnservices_get(request, tenant_id=tenant_id)", routers = api.neutron.router_list(request) ikepolicies = api.vpn.ikepolicies_get(request) ipsecpolicies = api.vpn.ipsecpolicies_get(request) vpnservices = api.vpn.vpnservices_get(request),123,79
openstack%2Fkeystone~master~Ic9cbb739d4729de13f578f160021810e924239d5,openstack/keystone,master,Ic9cbb739d4729de13f578f160021810e924239d5,Rename unused and misspelled argument,ABANDONED,2014-01-25 17:49:17.000000000,2014-01-30 20:26:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-25 17:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9911f513d72aab59ad35141854915c8e7d742218', 'message': ""Remove unused and misspelled argument\n\nThe cumlative_filter_dict argument was not used, so it's removed.\n\nChange-Id: Ic9cbb739d4729de13f578f160021810e924239d5\n""}, {'number': 2, 'created': '2014-01-26 17:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/599b919d58c3232184e8a38a9471c7e0d7b5e9b4', 'message': ""Remove unused and misspelled argument\n\nThe cumlative_filter_dict argument was not used, so it's removed.\n\nChange-Id: Ic9cbb739d4729de13f578f160021810e924239d5\n""}, {'number': 3, 'created': '2014-01-26 20:17:47.000000000', 'files': ['keystone/common/sql/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a2f01ea68584bd335dafcf0151532cc8312728d', 'message': ""Rename unused and misspelled argument\n\nThe cumlative_filter_dict argument was not used, so it's renamed\nto the variable that was used.\n\nChange-Id: Ic9cbb739d4729de13f578f160021810e924239d5\n""}]",3,69143,9a2f01ea68584bd335dafcf0151532cc8312728d,16,4,3,6486,,,0,"Rename unused and misspelled argument

The cumlative_filter_dict argument was not used, so it's renamed
to the variable that was used.

Change-Id: Ic9cbb739d4729de13f578f160021810e924239d5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/69143/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/core.py'],1,9911f513d72aab59ad35141854915c8e7d742218,bp/use-common-oslo-db-code," def exact_filter(model, filter_, hints): :returns filter_dict: updated filter dict filter_dict = exact_filter(model, filter_, hints)"," def exact_filter(model, filter_, cumlative_filter_dict, hints): :param cumlative_filter_dict: a dict that describes the set of exact filters built up so far :returns cumlative_filter_dict: updated cumulative dict filter_dict = exact_filter(model, filter_, filter_dict, hints)",3,5
openstack%2Fopenstack-manuals~master~I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f,openstack/openstack-manuals,master,I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f,Imported Translations from Transifex,MERGED,2014-01-30 06:06:59.000000000,2014-01-30 20:24:25.000000000,2014-01-30 20:24:24.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-30 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d7c1ac6b2992219ff1c28bd0b991395cb48db244', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f\n'}, {'number': 2, 'created': '2014-01-30 06:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2dbcb60c9004babab5637ae7e9f673bfc8011f0e', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f\n'}, {'number': 3, 'created': '2014-01-30 06:26:19.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/training-guides/locale/training-guides.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/he_IL.po', 'doc/common/locale/common.pot', 'doc/training-guides/locale/he_IL.po', 'doc/admin-guide-cloud/locale/he_IL.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/he_IL.po', 'doc/glossary/locale/glossary.pot', 'doc/config-reference/locale/he_IL.po', 'doc/glossary/locale/he_IL.po', 'doc/high-availability-guide/locale/he_IL.po', 'doc/user-guide-admin/locale/he_IL.po', 'doc/image-guide/locale/he_IL.po', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/security-guide/locale/he_IL.po', 'doc/user-guide/locale/he_IL.po', 'doc/security-guide/locale/security-guide.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5a0b1be8e9fb8f26cade7c6870516b6ab5570cd2', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f\n'}]",0,70061,5a0b1be8e9fb8f26cade7c6870516b6ab5570cd2,10,3,3,3,,,0,"Imported Translations from Transifex

Change-Id: I4ce9d9ffe44443cac8dc6e1a18a82aba409a113f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/70061/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/training-guides/locale/training-guides.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/he_IL.po', 'doc/common/locale/common.pot', 'doc/training-guides/locale/he_IL.po', 'doc/admin-guide-cloud/locale/he_IL.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/he_IL.po', 'doc/glossary/locale/glossary.pot', 'doc/config-reference/locale/he_IL.po', 'doc/glossary/locale/he_IL.po', 'doc/high-availability-guide/locale/he_IL.po', 'doc/user-guide-admin/locale/he_IL.po', 'doc/image-guide/locale/he_IL.po', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/security-guide/locale/he_IL.po', 'doc/user-guide/locale/he_IL.po', 'doc/security-guide/locale/security-guide.pot']",22,d7c1ac6b2992219ff1c28bd0b991395cb48db244,transifex/translations,"msgid """" msgstr """" ""Project-Id-Version: PACKAGE VERSION\n"" ""POT-Creation-Date: 2014-01-30 06:05+0000\n"" ""PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: LANGUAGE <LL@li.org>\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:30(None) ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:33(None) msgid ""@@image: 'static/group.png'; md5=aec1f0af66d29c1a5d1f174df1f12812"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:3(title) msgid ""Why and how we wrote this book"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:4(para) msgid ""As OpenStack adoption continues to grow and the product matures, security has become a priority. The OpenStack Security Group has recognized the need for a comprehensive and authoritative security guide. The <emphasis role=\""bold\"">OpenStack Security Guide</emphasis> has been written to provide an overview of security best practices, guidelines, and recommendations for increasing the security of an OpenStack deployment. The authors bring their expertise from deploying and securing OpenStack in a variety of environments."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:5(para) msgid ""The guide augments the <link href=\""http://docs.openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></link> and can be referenced to harden existing OpenStack deployments or to evaluate the security controls of OpenStack cloud providers."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:7(title) msgid ""Objectives"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:9(para) msgid ""Identify the security domains in OpenStack"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:12(para) msgid ""Provide guidance to secure your OpenStack deployment"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:15(para) msgid ""Highlight security concerns and potential mitigations in present day OpenStack"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:18(para) msgid ""Discuss upcoming security features"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:21(para) msgid ""To provide a community driven facility for knowledge capture and dissemination"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:26(title) msgid ""How"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:27(para) msgid ""As with the OpenStack Operations Guide, we followed the book sprint methodology. The book sprint process allows for rapid development and production of large bodies of written work. Coordinators from the OpenStack Security Group re-enlisted the services of Adam Hyde as facilitator. Corporate support was obtained and the project was formally announced during the OpenStack summit in Portland, Oregon."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:28(para) msgid ""The team converged in Annapolis, MD due to the close proximity of some key members of the group. This was a remarkable collaboration between public sector intelligence community members, silicon valley startups and some large, well-known technology companies. The book sprint ran during the last week in June 2013 and the first edition was created in five days."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:36(para) msgid ""The team included:"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:39(para) msgid ""<emphasis role=\""bold\"">Bryan D. Payne</emphasis>, Nebula"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:40(para) msgid ""Dr. Bryan D. Payne is the Director of Security Research at Nebula and co-founder of the OpenStack Security Group (OSSG). Prior to joining Nebula, he worked at Sandia National Labs, the National Security Agency, BAE Systems, and IBM Research. He graduated with a Ph.D. in Computer Science from the Georgia Tech College of Computing, specializing in systems security."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:43(para) msgid ""<emphasis role=\""bold\"">Robert Clark</emphasis>, HP"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:44(para) msgid ""Robert Clark is the Lead Security Architect for HP Cloud Services and co-founder of the OpenStack Security Group (OSSG). Prior to being recruited by HP, he worked in the UK Intelligence Community. Robert has a strong background in threat modeling, security architecture and virtualization technology. Robert has a master's degree in Software Engineering from the University of Wales."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:47(para) msgid ""<emphasis role=\""bold\"">Keith Basil</emphasis>, Red Hat"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:48(para) msgid ""Keith Basil is a Principal Product Manager for Red Hat OpenStack and is focused on Red Hat's OpenStack product management, development and strategy. Within the US public sector, Basil brings previous experience from the design of an authorized, secure, high-performance cloud architecture for Federal civilian agencies and contractors."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:51(para) msgid ""<emphasis role=\""bold\"">Cody Bunch</emphasis>, Rackspace"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:52(para) msgid ""Cody Bunch is a Private Cloud architect with Rackspace. Cody has co-authored an update to \""The OpenStack Cookbook\"" as well as books on VMware automation."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:55(para) msgid ""<emphasis role=\""bold\"">Malini Bhandaru</emphasis>, Intel"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:56(para) msgid ""Malini Bhandaru is a security architect at Intel. She has a varied background, having worked on platform power and performance at Intel, speech products at Nuance, remote monitoring and management at ComBrio, and web commerce at Verizon. She has a Ph.D. in Artificial Intelligence from the University of Massachusetts, Amherst."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:59(para) msgid ""<emphasis role=\""bold\"">Gregg Tally</emphasis>, Johns Hopkins University Applied Physics Laboratory"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:60(para) msgid ""Gregg Tally is the Chief Engineer at JHU/APL's Cyber Systems Group within the Asymmetric Operations Department. He works primarily in systems security engineering. Previously, he has worked at SPARTA, McAfee, and Trusted Information Systems where he was involved in cyber security research projects."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:63(para) msgid ""<emphasis role=\""bold\"">Eric Lopez</emphasis>, Nicira / VMware"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:64(para) msgid ""Eric Lopez is Senior Solution Architect at VMware's Networking and Security Business Unit where he helps customer implement OpenStack and Nicira's Network Virtualization Platform. Prior to joining Nicira, he worked for Q1 Labs, Symantec, Vontu, and Brightmail. He has a B.S in Electrical Engineering/Computer Science and Nuclear Engineering from U.C. Berkeley and MBA from the University of San Francisco."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:67(para) msgid ""<emphasis role=\""bold\"">Shawn Wells</emphasis>, Red Hat"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:68(para) msgid ""Shawn Wells is the Director, Innovation Programs at Red Hat, focused on improving the process of adopting, contributing to, and managing open source technologies within the U.S. Government. Additionally, Shawn is an upstream maintainer of the SCAP Security Guide project which forms virtualization and operating system hardening policy with the U.S. Military, NSA, and DISA. Formerly an NSA civilian, Shawn developed SIGINT collection systems utilizing large distributed computing infrastructures."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:71(para) msgid ""<emphasis role=\""bold\"">Ben de Bont</emphasis>, HP"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:72(para) msgid ""Ben de Bont is the CSO for HP Cloud Services. Prior to his current role Ben led the information security group at MySpace and the incident response team at MSN Security. Ben holds a master's degree in Computer Science from the Queensland University of Technology."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:75(para) msgid ""<emphasis role=\""bold\"">Nathanael Burton</emphasis>, National Security Agency"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:76(para) msgid ""Nathanael Burton is a Computer Scientist at the National Security Agency. He has worked for the Agency for over 10 years working on distributed systems, large-scale hosting, open source initiatives, operating systems, security, storage, and virtualization technology. He has a B.S. in Computer Science from Virginia Tech."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:79(emphasis) msgid ""Vibha Fauver"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:80(para) msgid ""Vibha Fauver, GWEB, CISSP, PMP, has over fifteen years of experience in Information Technology. Her areas of specialization include software engineering, project management and information security. She has a B.S. in Computer &amp; Information Science and a M.S. in Engineering Management with specialization and a certificate in Systems Engineering."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:83(para) msgid ""<emphasis role=\""bold\"">Eric Windisch</emphasis>, Cloudscaling"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:84(para) msgid ""Eric Windisch is a Principal Engineer at Cloudscaling where he has been contributing to OpenStack for over two years. Eric has been in the trenches of hostile environments, building tenant isolation and infrastructure security through more than a decade of experience in the web hosting industry. He has been building cloud computing infrastructure and automation since 2007."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:87(para) msgid ""<emphasis role=\""bold\"">Andrew Hay</emphasis>, CloudPassage"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:88(para) msgid ""Andrew Hay is the Director of Applied Security Research at CloudPassage, Inc. where he leads the security research efforts for the company and its server security products purpose-built for dynamic public, private, and hybrid cloud hosting environments."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:91(emphasis) msgid ""Adam Hyde"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:92(para) msgid ""Adam facilitated this Book Sprint. He also founded the Book Sprint methodology and is the most experienced Book Sprint facilitator around. Adam founded FLOSS Manualsa community of some 3,000 individuals developing Free Manuals about Free Software. He is also the founder and project manager for Booktype, an open source project for writing, editing, and publishing books online and in print."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:95(para) msgid ""During the sprint we also had help from Anne Gentle, Warren Wang, Paul McMillan, Brian Schott and Lorin Hochstein."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:96(para) msgid ""This Book was produced in a 5 day book sprint. A book sprint is an intensely collaborative, facilitated process which brings together a group to produce a book in 3-5 days. It is a strongly facilitated process with a specific methodology founded and developed by Adam Hyde. For more information visit the book sprint web page at <link href=\""http://www.booksprints.net\"">http://www.booksprints.net</link>."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:104(para) msgid ""After initial publication, the following added new content:"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:107(para) msgid ""<emphasis role=\""bold\"">Rodney D. Beede</emphasis>, Seagate Technology"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:110(para) msgid ""Rodney D. Beede is the Cloud Security Engineer for Seagate Technology. He contributed the missing chapter on securing OpenStack Object Storage (Swift). He holds a M.S. in Computer Science from the University of Colorado."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:119(title) msgid ""How to contribute to this book"" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:120(para) msgid ""The initial work on this book was conducted in an overly air-conditioned room that served as our group office for the entirety of the documentation sprint."" msgstr """" #: ./doc/security-guide/ch002_why-and-how-we-wrote-this-book.xml:123(para) msgid ""Learn more about how to contribute to the OpenStack docs: <link href=\""http://wiki.openstack.org/Documentation/HowTo\"">http://wiki.openstack.org/Documentation/HowTo</link>."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:3(title) msgid ""Hypervisor Selection"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:4(para) msgid ""Virtualization provides flexibility and other key benefits that enable cloud building. However, a virtualization stack also needs to be secured appropriately to reduce the risks associated with hypervisor breakout attacks. That is, while a virtualization stack can provide isolation between instances, or guest virtual machines, there are situations where that isolation can be less than perfect. Making intelligent selections for virtualization stack as well as following the best practices outlined in this chapter can be included in a layered approach to cloud security. Finally, securing your virtualization stack is critical in order to deliver on the promise of multi-tenant, either between customers in a public cloud, between business units in a private cloud, or some mixture of the two in a hybrid cloud."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:17(para) msgid ""In this chapter, we discuss the hypervisor selection process. In the chapters that follow, we provide the foundational information needed for securing a virtualization stack."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:19(title) msgid ""Hypervisors in OpenStack"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:20(para) msgid ""Whether OpenStack is deployed within private data centers or as a public cloud service, the underlying virtualization technology provides enterprise-level capabilities in the realms of scalability, resource efficiency, and uptime. While such high-level benefits are generally available across many OpenStack-supported hypervisor technologies, there are significant differences in each hypervisor's security architecture and features, particularly when considering the security threat vectors which are unique to elastic OpenStack environments. As applications consolidate into single Infrastructure as a Service (IaaS) platforms, instance isolation at the hypervisor level becomes paramount. The requirement for secure isolation holds true across commercial, government, and military communities."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:21(para) msgid ""Within the framework of OpenStack you can choose from any number of hypervisor platforms and corresponding OpenStack plugins to optimize your cloud environment. In the context of the OpenStack Security guide, we will be highlighting hypervisor selection considerations as they pertain to feature sets that are critical to security. However, these considerations are not meant to be an exhaustive investigation into the pros and cons of particular hypervisors. NIST provides additional guidance in Special Publication 800-125, \""<emphasis>Guide to Security for Full Virtualization Technologies</emphasis>\""."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:24(title) msgid ""Selection Criteria"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:25(para) msgid ""As part of your hypervisor selection process, you will need to consider a number of important factors to help increase your security posture. Specifically, we will be looking into the following areas:"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:27(para) msgid ""Team Expertise"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:30(para) msgid ""Product or Project maturity"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:33(para) msgid ""Certifications, Attestations"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:36(para) ./doc/security-guide/ch051_vss-intro.xml:300(title) msgid ""Additional Security Features"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:39(para) ./doc/security-guide/ch051_vss-intro.xml:293(title) msgid ""Hypervisor vs. Baremetal"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:42(para) ./doc/security-guide/ch051_vss-intro.xml:255(title) msgid ""Hardware Concerns"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:45(para) ./doc/security-guide/ch051_vss-intro.xml:79(title) msgid ""Common Criteria"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:49(para) msgid ""Has the hypervisor undergone Common Criteria certification? If so, to what levels?"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:52(para) msgid ""Is the underlying cryptography certified by a third-party?"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:48(para) msgid ""Additionally, the following security-related criteria are highly encouraged to be evaluated when selecting a hypervisor for OpenStack deployments:<placeholder-1/><bridgehead>Team Expertise</bridgehead> Most likely, the most important aspect in hypervisor selection is the expertise of your staff in managing and maintaining a particular hypervisor platform. The more familiar your team is with a given product, its configuration, and its eccentricities, the less likely will there be configuration mistakes. Additionally, having staff expertise spread across an organization on a given hypervisor will increase availability of your systems, allow for developing a segregation of duties, and mitigate problems in the event that a team member is unavailable."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:56(title) msgid ""Product or Project Maturity"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:57(para) msgid ""The maturity of a given hypervisor product or project is critical to your security posture as well. Product maturity will have a number of effects once you have deployed your cloud, in the context of this security guide we are interested in the following:"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:59(para) msgid ""Availability of expertise"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:62(para) msgid ""Active developer and user communities"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:65(para) msgid ""Timeliness and Availability of updates"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:68(para) msgid ""Incidence response"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:71(para) msgid ""One of the biggest indicators of a hypervisor's maturity is the size and vibrancy of the community that surrounds it. As this concerns security, the quality of the community will affect the availability of expertise should you need additional cloud operators. It is also a sign of how widely deployed the hypervisor is, in turn leading to the battle readiness of any reference architectures and best practices."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:72(para) msgid ""Further, the quality of community, as it surrounds an open source hypervisor like KVM or Xen, will have a direct impact on the timeliness of bug fixes and security updates. When investigating both commercial and open source hypervisors, you will want to look into their release and support cycles as well as the time delta between the announcement of a bug or security issue and a patch or response. Lastly, the supported capabilities of OpenStack compute vary depending on the hypervisor chosen. Refer to the <link href=\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support Matrix</link> for OpenStack compute feature support by hypervisor."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:75(title) msgid ""Certifications and Attestations"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:76(para) msgid ""One additional consideration when selecting a hypervisor is the availability of various formal certifications and attestations. While they may not be requirements for your specific organization, these certifications and attestations speak to the maturity, production readiness, and thoroughness of the testing a particular hypervisor platform has been subjected to."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:80(para) msgid ""Common Criteria is an internationally standardized software evaluation process, used by governments and commercial companies to validate software technologies perform as advertised. In the government sector, NSTISSP No. 11 mandates that U.S. Government agencies only procure software which has been Common Criteria certified, a policy which has been in place since July 2002. It should be specifically noted that OpenStack has not undergone Common Criteria certification, however many of the available hypervisors have."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:81(para) msgid ""In addition to validating a technologies capabilities, the Common Criteria process evaluates <emphasis>how</emphasis> technologies are developed."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:83(para) msgid ""How is source code management performed?"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:86(para) msgid ""How are users granted access to build systems?"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:89(para) msgid ""Is the technology cryptographically signed before distribution?"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:92(para) msgid ""The KVM hypervisor has been Common Criteria certified through the U.S. Government and commercial distributions, which have been validated to separate the runtime environment of virtual machines from each other, providing foundational technology to enforce instance isolation. In addition to virtual machine isolation, KVM has been Common Criteria certified to"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:94(para) msgid ""\""<emphasis>provide system-inherent separation mechanisms to the resources of virtual machines. This separation ensures that large software component used for virtualizing and simulating devices executing for each virtual machine cannot interfere with each other. Using the SELinux multi-category mechanism, the virtualization and simulation software instances are isolated. The virtual machine management framework configures SELinux multi-category settings transparently to the administrator</emphasis>\"""" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:96(para) msgid ""While many hypervisor vendors, such as Red Hat, Microsoft, and VMWare have achieved Common Criteria Certification their underlying certified feature set differs. It is recommended to evaluate vendor claims to ensure they minimally satisfy the following requirements:"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:103(para) msgid ""Identification and Authentication"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:104(para) msgid ""Identification and authentication using pluggable authentication modules (PAM) based upon user passwords. The quality of the passwords used can be enforced through configuration options."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:107(para) msgid ""Audit"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:108(para) msgid ""The system provides the capability to audit a large number of events including individual system calls as well as events generated by trusted processes. Audit data is collected in regular files in ASCII format. The system provides a program for the purpose of searching the audit records."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:108(para) msgid ""The system administrator can define a rule base to restrict auditing to the events they are interested in. This includes the ability to restrict auditing to specific events, specific users, specific objects or a combination of all of this. "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:108(para) msgid ""Audit records can be transferred to a remote audit daemon."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:111(para) msgid ""Discretionary Access Control"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:113(para) msgid ""Discretionary Access Control (<glossterm>DAC</glossterm>) restricts access to file system objects based on <glossterm baseform=\""access control list\"">Access Control Lists</glossterm> (ACLs) that include the standard UNIX permissions for user, group and others. Access control mechanisms also protect IPC objects from unauthorized access."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:122(para) msgid ""The system includes the ext4 file system, which supports POSIX ACLs. This allows defining access rights to files within this type of file system down to the granularity of a single user."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:130(para) msgid ""Mandatory Access Control"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:131(para) msgid ""Mandatory Access Control (MAC) restricts access to objects based on labels assigned to subjects and objects. Sensitivity labels are automatically attached to processes and objects. The access control policy enforced using these labels is derived from the BellLaPadula access control model."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:131(para) msgid ""SELinux categories are attached to virtual machines and its resources. The access control policy enforced using these categories grant virtual machines access to resources if the category of the virtual machine is identical to the category of the accessed resource."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:131(para) msgid ""The TOE implements non-hierarchical categories to control access to virtual machines."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:134(para) msgid ""Role-Based Access Control"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:135(para) msgid ""Role-based access control (RBAC) allows separation of roles to eliminate the need for an all-powerful system administrator."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:138(para) msgid ""Object Reuse"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:139(para) msgid ""File system objects as well as memory and IPC objects will be cleared before they can be reused by a process belonging to a different user."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:142(para) msgid ""Security Management"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:143(para) msgid ""The management of the security critical parameters of the system is performed by administrative users. A set of commands that require root privileges (or specific roles when RBAC is used) are used for system management. Security parameters are stored in specific files that are protected by the access control mechanisms of the system against unauthorized access by users that are not administrative users."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:146(para) msgid ""Secure Communication"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:147(para) msgid ""The system supports the definition of trusted channels using SSH. Password based authentication is supported. Only a restricted number of cipher suites are supported for those protocols in the evaluated configuration."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:150(para) msgid ""Storage Encryption"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:151(para) msgid ""The system supports encrypted block devices to provide storage confidentiality via dm_crypt."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:154(para) msgid ""TSF Protection"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:155(para) msgid ""While in operation, the kernel software and data are protected by the hardware memory protection mechanisms. The memory and process management components of the kernel ensure a user process cannot access kernel storage or storage belonging to other processes."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:155(para) msgid ""Non-kernel TSF software and data are protected by DAC and process isolation mechanisms. In the evaluated configuration, the reserved user ID root owns the directories and files that define the TSF configuration. In general, files and directories containing internal TSF data, such as configuration files and batch job queues, are also protected from reading by DAC permissions."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:162(para) msgid ""The system and the hardware and firmware components are required to be physically protected from unauthorized access. The system kernel mediates all access to the hardware mechanisms themselves, other than program visible CPU instruction functions."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:162(para) msgid ""In addition, mechanisms for protection against stack overflow attacks are provided."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:169(title) msgid ""Cryptography Standards"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:170(para) msgid ""Several cryptography algorithms are available within OpenStack for identification and authorization, data transfer and protection of data at rest. When selecting a hypervisor, the following are recommended algorithms and implementation standards to ensure the virtualization layer supports:"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:180(emphasis) msgid ""Algorithm"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:181(emphasis) msgid ""Key Length"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:182(emphasis) msgid ""Intended Purpose"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:183(emphasis) msgid ""Security Function"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:184(emphasis) msgid ""Implementation Standard"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:187(para) msgid ""AES"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:188(para) msgid ""128 bits,192 bits,"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:188(para) msgid ""256 bits"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:189(para) ./doc/security-guide/ch051_vss-intro.xml:196(para) msgid ""Encryption / Decryption"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:190(para) msgid ""Protected Data Transfer, Protection for Data at Rest"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:191(para) ./doc/security-guide/ch051_vss-intro.xml:198(para) msgid ""RFC 4253"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:194(para) msgid ""TDES"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:195(para) msgid ""168 bits"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:197(para) msgid ""Protected Data Transfer"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:201(para) msgid ""RSA"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:202(para) msgid ""1024 bits,2048 bits,"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:202(para) msgid ""3072 bits "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:203(para) ./doc/security-guide/ch051_vss-intro.xml:210(para) msgid ""Authentication,Key Exchange "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:204(para) ./doc/security-guide/ch051_vss-intro.xml:211(para) msgid ""Identification and Authentication, Protected Data Transfer"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:205(para) ./doc/security-guide/ch051_vss-intro.xml:212(para) msgid ""U.S. NIST FIPS PUB 186-3"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:208(para) msgid ""DSA"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:209(para) msgid ""L=1024,N=160 bits "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:215(para) msgid ""Serpent"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:216(para) ./doc/security-guide/ch051_vss-intro.xml:223(para) msgid ""128, 196, or256 bit "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:217(para) ./doc/security-guide/ch051_vss-intro.xml:224(para) msgid ""Encryption /Decryption "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:218(para) ./doc/security-guide/ch051_vss-intro.xml:225(para) msgid ""Protection of Data at Rest"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:219(link) msgid ""http://www.cl.cam.ac.uk/~rja14/Papers/serpent.pdf"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:222(para) msgid ""Twofish"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:226(link) msgid ""http://www.schneier.com/paper-twofish-paper.html"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:229(para) msgid ""SHA-1"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:230(para) ./doc/security-guide/ch051_vss-intro.xml:237(para) msgid ""-"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:231(para) ./doc/security-guide/ch051_vss-intro.xml:238(para) msgid ""MessageDigest "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:232(para) msgid ""Protection of Data at Rest,Protected Data Transfer"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:233(para) ./doc/security-guide/ch051_vss-intro.xml:240(para) msgid ""U.S. NIST FIPS 180-3"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:236(para) msgid ""SHA-2(224-, 256-,"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:236(para) msgid ""384-, 512 bit)"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:239(para) msgid ""Protection for Data at Rest,Identification and Authentication "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:246(title) msgid ""FIPS 140-2"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:247(para) msgid ""In the United States the National Institute of Science and Technology (NIST) certifies cryptographic algorithms through a process known the Cryptographic Module Validation Program. NIST certifies algorithms for conformance against Federal Information Processing Standard 140-2 (FIPS 140-2), which ensures:"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:249(emphasis) msgid ""Products validated as conforming to FIPS 140-2 are accepted by the Federal agencies of both countries [United States and Canada] for the protection of sensitive information (United States) or Designated Information (Canada). The goal of the CMVP is to promote the use of validated cryptographic modules and provide Federal agencies with a security metric to use in procuring equipment containing validated cryptographic modules."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:251(para) msgid ""When evaluating base hypervisor technologies, consider if the hypervisor has been certified against FIPS 140-2. Not only is conformance against FIPS 140-2 mandated per U.S. Government policy, formal certification indicates that a given implementation of a cryptographic algorithm has been reviewed for conformance against module specification, cryptographic module ports and interfaces; roles, services, and authentication; finite state model; physical security; operational environment; cryptographic key management; electromagnetic interference/electromagnetic compatibility (EMI/EMC); self-tests; design assurance; and mitigation of other attacks."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:256(para) msgid ""Further, when evaluating a hypervisor platform the supportability of the hardware the hypervisor will run on should be considered. Additionally, consider the additional features available in the hardware and how those features are supported by the hypervisor you chose as part of the OpenStack deployment. To that end, hypervisors will each have their own hardware compatibility lists (HCLs). When selecting compatible hardware it is important to know in advance which hardware-based virtualization technologies are important from a security perspective."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:264(emphasis) msgid ""Description"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:265(emphasis) msgid ""Technology"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:266(emphasis) msgid ""Explanation"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:269(para) msgid ""I/O MMU"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:270(para) msgid ""VT-d / AMD-Vi"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:271(para) msgid ""Required for protecting PCI-passthrough"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:274(para) msgid ""Intel Trusted Execution Technology"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:275(para) msgid ""Intel TXT / SEM"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:276(para) msgid ""Required for dynamic attestation services"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:279(para) msgid ""<anchor xml:id=\""PCI-SIG_I.2FO_virtualization_.28IOV.29\""/>PCI-SIG I/O virtualization"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:280(para) msgid ""SR-IOV, MR-IOV, ATS"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:281(para) msgid ""Required to allow secure sharing of PCI Express devices"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:284(para) msgid ""Network virtualization"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:285(para) msgid ""VT-c"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:286(para) msgid ""Improves performance of network I/O on hypervisors"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:294(para) msgid ""To wrap up our discussion around hypervisor selection, it is important to call out the differences between using LXC (Linux Containers) or Baremetal systems vs using a hypervisor like KVM. Specifically, the focus of this security guide will be largely based on having a hypervisor and virtualization platform. However, should your implementation require the use of a baremetal or LXC environment, you will want to pay attention to the particular differences in regard to deployment of that environment. In particular, you will need to provide your end users with assurances that the node has been properly sanitized of their data prior to re-provisioning. Additionally, prior to reusing a node, you will need to provide assurances that the hardware has not been tampered or otherwise compromised."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:295(para) msgid ""It should be noted that while OpenStack has a baremetal project, a discussion of the particular security implications of running baremetal is beyond the scope of this book."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:296(para) msgid ""Finally, due to the time constraints around a book sprint, the team chose to use KVM as the hypervisor in our example implementations and architectures."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:297(para) msgid ""There is an OpenStack Security Note pertaining to the <link href=\""https://bugs.launchpad.net/ossn/+bug/1098582\"">use of LXC in Nova</link>."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:301(para) msgid ""Another thing to look into when selecting a hypervisor platform is the availability of specific security features. In particular, we are referring to features like Xen Server's XSM or Xen Security Modules, sVirt, Intel TXT, and AppArmor. The presence of these features will help increase your security profile as well as provide a good foundation."" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:302(para) msgid ""The following table calls out these features by common hypervisor platforms. "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:315(para) ./doc/security-guide/ch051_vss-intro.xml:327(para) ./doc/security-guide/ch051_vss-intro.xml:336(para) ./doc/security-guide/ch051_vss-intro.xml:338(para) ./doc/security-guide/ch051_vss-intro.xml:340(para) ./doc/security-guide/ch051_vss-intro.xml:341(para) ./doc/security-guide/ch051_vss-intro.xml:346(para) ./doc/security-guide/ch051_vss-intro.xml:347(para) ./doc/security-guide/ch051_vss-intro.xml:348(para) ./doc/security-guide/ch051_vss-intro.xml:350(para) ./doc/security-guide/ch051_vss-intro.xml:351(para) ./doc/security-guide/ch051_vss-intro.xml:352(para) ./doc/security-guide/ch051_vss-intro.xml:356(para) ./doc/security-guide/ch051_vss-intro.xml:357(para) ./doc/security-guide/ch051_vss-intro.xml:358(para) ./doc/security-guide/ch051_vss-intro.xml:359(para) ./doc/security-guide/ch051_vss-intro.xml:360(para) ./doc/security-guide/ch051_vss-intro.xml:361(para) ./doc/security-guide/ch051_vss-intro.xml:362(para) ./doc/security-guide/ch012_configuration-management.xml:95(para) ./doc/security-guide/ch012_configuration-management.xml:100(emphasis) msgid "" "" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:316(para) msgid ""KSM"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:317(para) msgid ""XSM"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:318(para) msgid ""sVirt"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:319(para) msgid ""TXT"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:320(para) msgid ""AppArmor"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:321(para) msgid ""cGroups"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:322(para) msgid ""MAC Policy"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:325(para) msgid ""KVM"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:326(para) ./doc/security-guide/ch051_vss-intro.xml:328(para) ./doc/security-guide/ch051_vss-intro.xml:329(para) ./doc/security-guide/ch051_vss-intro.xml:337(para) msgid ""X"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:330(address) ./doc/security-guide/ch051_vss-intro.xml:331(para) ./doc/security-guide/ch051_vss-intro.xml:332(para) ./doc/security-guide/ch051_vss-intro.xml:342(para) msgid ""x"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:335(para) msgid ""Xen"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:339(para) ./doc/security-guide/ch051_vss-intro.xml:349(para) msgid "" X"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:345(para) msgid ""ESXi"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:355(para) msgid ""Hyper-V"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:367(link) msgid ""KSM: Kernel Samepage Merging"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:368(link) msgid ""XSM: Xen Security Modules"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:369(link) msgid ""xVirt: Mandatory Access Control for Linux-based virtualization"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:370(link) msgid ""TXT: Intel Trusted Execution Technology"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:371(link) msgid ""AppArmor: Linux security module implementing MAC"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:372(link) msgid ""cgroups: Linux kernel feature to control resource usage"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:373(para) msgid ""MAC Policy: Mandatory Access Control; may be implemented with SELinux or other operating systems"" msgstr """" #: ./doc/security-guide/ch051_vss-intro.xml:374(para) msgid ""* Features in this table may not be applicable to all hypervisors or directly mappable between hypervisors."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:3(title) msgid ""Introduction to SSL/TLS"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:4(para) msgid ""OpenStack services receive requests on behalf of users on public networks as well as from other internal services over management networks. Inter-service communications can also occur over public networks depending on deployment and architecture choices."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:5(para) msgid ""While it is commonly accepted that data over public networks should be secured using cryptographic measures, such as Secure Sockets Layer or Transport Layer Security (SSL/TLS) protocols, it is insufficient to rely on security domain separation to protect internal traffic. Using a security-in-depth approach, we recommend securing all domains with SSL/TLS, including the management domain services. It is important that should a tenant escape their VM isolation and gain access to the hypervisor or host resources, compromise an API endpoint, or any other service, they must not be able to easily inject or capture messages, commands, or otherwise affect or control management capabilities of the cloud. SSL/TLS provides the mechanisms to ensure authentication, non-repudiation, confidentiality, and integrity of user communications to the OpenStack services and between the OpenStack services themselves."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:6(para) msgid ""Public Key Infrastructure (PKI) is the set of hardware, software, and policies to operate a secure system which provides authentication, non-repudiation, confidentiality, and integrity. The core components of PKI are:"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:8(para) msgid ""End Entity - user, process, or system that is the subject of a certificate"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:11(para) msgid ""Certification Authority (<glossterm>CA</glossterm>) - defines certificate policies, management, and issuance of certificates"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:14(para) msgid ""Registration Authority (RA) - an optional system to which a CA delegates certain management functions"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:17(para) msgid ""Repository - Where the end entity certificates and certificate revocation lists are stored and looked up - sometimes referred to as the \""certificate bundle\"""" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:20(para) msgid ""Relying Party - The end point that is trusting that the CA is valid."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:23(para) msgid ""PKI builds the framework on which to provide encryption algorithms, cipher modes, and protocols for securing data and authentication. We strongly recommend securing all services with Public Key Infrastructure (PKI), including the use of SSL/TLS for API endpoints. It is impossible for the encryption or signing of transports or messages alone to solve all these problems. Hosts themselves must be secure and implement policy, namespaces, and other controls to protect their private credentials and keys. However, the challenges of key management and protection do not reduce the necessity of these controls, or lessen their importance."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:25(title) msgid ""Certification Authorities"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:26(para) msgid ""Many organizations have an established Public Key Infrastructure with their own certification authority (CA), certificate policies, and management for which they should use to issue certificates for internal OpenStack users or services. Organizations in which the public security domain is Internet facing will additionally need certificates signed by a widely recognized public CA. For cryptographic communications over the management network, it is recommended one not use a public CA. Instead, we expect and recommend most deployments deploy their own internal CA."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:27(para) msgid ""It is recommended that the OpenStack cloud architect consider using separate PKI deployments for internal systems and customer facing services. This allows the cloud deployer to maintain control of their PKI infrastructure and among other things makes requesting, signing and deploying certificates for internal systems easier. Advanced configurations may use separate PKI deployments for different security domains. This allows deployers to maintain cryptographic separation of environments, ensuring that certificates issued to one are not recognised by another."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:28(para) msgid ""Certificates used to support SSL/TLS on internet facing cloud endpoints (or customer interfaces where the customer is not expected to have installed anything other than standard operating system provided certificate bundles) should be provisioned using Certificate Authorities that are installed in the operating system certificate bundle. Typical well known vendors include Verisign and Thawte but many others exist."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:29(para) msgid ""There are many management, policy, and technical challenges around creating and signing certificates as such is an area where cloud architects or operators may wish to seek the advice of industry leaders and vendors in addition to the guidance recommended here."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:32(title) msgid ""SSL/TLS Libraries"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:33(para) msgid ""Various components, services, and applications within the OpenStack ecosystem or dependencies of OpenStack are implemented and can be configured to use SSL/TLS libraries. The SSL/TLS and HTTP services within OpenStack are typically implemented using OpenSSL which has been proven to be fairly secure and has a module that has been validated for FIPS 140-2. However, keep in mind that each application or service can still introduce weaknesses in how they use the OpenSSL libraries."" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:36(title) msgid ""Cryptographic Algorithms, Cipher Modes, and Protocols"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:37(para) msgid ""We recommend only using TLS v1.1 or v1.2. SSLv3 and TLSv1.0 may be used for compatibility but we recommend using caution and only enabling these protocols if you have a strong requirement to do so. Other SSL/TLS versions, explicitly older versions, should not be used. These older versions include SSLv1 and SSLv2. As this book does not intend to be a thorough reference on cryptography we do not wish to be prescriptive about what specific algorithms or cipher modes you should enable or disable in your OpenStack services. However, there are some authoritative references we would like to recommend for further information:"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:39(link) msgid ""National Security Agency, Suite B Cryptography"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:42(link) msgid ""OWASP Guide to Cryptography"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:45(link) msgid ""OWASP Transport Layer Protection Cheat Sheet"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:48(link) msgid ""SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate trust model enhancements"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:51(link) msgid ""The Most Dangerous Code in the World: Validating SSL Certificates in Non-Browser Software"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:54(link) msgid ""OpenSSL and FIPS 140-2"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:59(title) msgid ""Summary"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:60(para) msgid ""Given the complexity of the OpenStack components and the number of deployment possibilities, you must take care to ensure that each component gets the appropriate configuration of SSL certificates, keys, and CAs. The following services will be discussed in later sections of this book where SSL and PKI is available (either natively or possible via SSL proxy):"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:62(para) msgid ""Compute API endpoints"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:65(para) msgid ""Identity API endpoints"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:68(para) msgid ""Networking API endpoints"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:71(para) msgid ""Storage API endpoints"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:74(para) msgid ""Messaging server"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:77(para) msgid ""Database server"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:80(para) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:23(title) ./doc/security-guide/ch004_book-introduction.xml:186(title) ./doc/security-guide/ch025_web-dashboard.xml:8(title) msgid ""Dashboard"" msgstr """" #: ./doc/security-guide/ch017_threat-models-confidence-and-confidentiality.xml:83(para) msgid ""Throughout this book we will use SSL as shorthand to refer to these recommendations for SSL/TLS protocols."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:8(title) msgid ""Continuous Systems Management"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:9(para) msgid ""A cloud will always have bugs. Some of these will be security problems. For this reason, it is critically important to be prepared to apply security updates and general software updates. This involves smart use of configuration management tools, which are discussed below. This also involves knowing when an upgrade is necessary."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:16(title) ./doc/security-guide/ch063_compliance-activities.xml:43(title) msgid ""Vulnerability Management"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:17(para) msgid ""For announcements regarding security relevant changes, subscribe to the <link href=\""http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-announce\"">OpenStack Announce mailing list</link>. The security notifications are also posted through the downstream packages for example through Linux distributions that you may be subscribed to as part of the package updates."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:24(para) msgid ""The OpenStack components are only a small fraction of the software in a cloud. It is important to keep up to date with all of these other components, too. While the specific data sources will be deployment specific, the key idea is to ensure that a cloud administrator subscribes to the necessary mailing lists for receiving notification of any related security updates. Often this is as simple as tracking an upstream Linux distribution."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:36(para) msgid ""OpenStack Security Advisories (OSSA) are created by the OpenStack Vulnerability Management Team (VMT). They pertain to security holes in core OpenStack services. More information on the VMT can be found here: <link href=\""https://wiki.openstack.org/wiki/Vulnerability_Management\"">https://wiki.openstack.org/wiki/Vulnerability_Management</link>"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:44(para) msgid ""OpenStack Security Notes (OSSN) were created by the OpenStack Security Group (OSSG) to support the work of the VMT. OSSN address issues in supporting software and common deployment configurations. They're referenced throughout this guide. Security Notes are archived at <link href=\""https://launchpad.net/ossn/\"">https://launchpad.net/ossn/</link>"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:33(para) msgid ""OpenStack releases security information through two channels. <placeholder-1/>"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:56(title) msgid ""Triage"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:57(para) msgid ""After you are notified of a security update, the next step is to determine how critical this update is to a given cloud deployment. In this case, it is useful to have a pre-defined policy. Existing vulnerability rating systems such as the common vulnerability scoring system (CVSS) v2 do not properly account for cloud deployments."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:63(para) msgid ""In this example we introduce a scoring matrix that places vulnerabilities in three categories: Privilege Escalation, Denial of Service and Information Disclosure. Understanding the type of vulnerability and where it occurs in your infrastructure will enable you to make reasoned response decisions."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:69(para) msgid ""Privilege Escalation describes the ability of a user to act with the privileges of some other user in a system, bypassing appropriate authorization checks. For example, a standard Linux user running code or performing an operation that allows them to conduct further operations with the privileges of the root users on the system."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:75(para) msgid ""Denial of Service refers to an exploited vulnerability that may cause service or system disruption. This includes both distributed attacks to overwhelm network resources, and single-user attacks that are typically caused through resource allocation bugs or input induced system failure flaws."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:80(para) msgid ""Information Disclosure vulnerabilities reveal information about your system or operations. These vulnerabilities range from debugging information disclosure, to exposure of critical security data, such as authentication credentials and passwords."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:96(emphasis) msgid ""Attacker Position / Privilege Level"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:102(emphasis) msgid ""External"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:103(emphasis) msgid ""Cloud User"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:105(emphasis) msgid ""Cloud Admin"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:107(emphasis) msgid ""Control Plane"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:111(emphasis) msgid ""Privilege Elevation (3 levels)"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:113(para) ./doc/security-guide/ch012_configuration-management.xml:121(para) ./doc/security-guide/ch012_configuration-management.xml:122(para) ./doc/security-guide/ch012_configuration-management.xml:129(para) ./doc/security-guide/ch012_configuration-management.xml:130(para) ./doc/security-guide/ch012_configuration-management.xml:131(para) msgid ""Critical"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:114(para) ./doc/security-guide/ch012_configuration-management.xml:115(para) ./doc/security-guide/ch012_configuration-management.xml:116(para) ./doc/security-guide/ch012_configuration-management.xml:123(para) ./doc/security-guide/ch012_configuration-management.xml:124(para) ./doc/security-guide/ch012_configuration-management.xml:132(para) msgid ""n/a"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:119(emphasis) msgid ""Privilege Elevation (2 levels)"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:127(emphasis) msgid ""Privilege Elevation (1 level)"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:135(emphasis) msgid ""Denial of Service"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:137(para) msgid ""High"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:138(para) msgid ""Medium"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:139(para) ./doc/security-guide/ch012_configuration-management.xml:140(para) ./doc/security-guide/ch012_configuration-management.xml:148(para) msgid ""Low"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:143(emphasis) msgid ""Information Disclosure"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:145(para) ./doc/security-guide/ch012_configuration-management.xml:146(para) msgid ""Critical / High"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:147(para) msgid ""Medium / Low"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:152(para) msgid ""This table illustrates a generic approach to measuring the impact of a vulnerability based on where it occurs in your deployment and the effect. For example, a single level privilege escalation on a Compute API node potentially allows a standard user of the API to escalate to have the same privileges as the root user on the node."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:158(para) msgid ""We suggest that cloud administrators use this table as a model to help define which actions to take for the various security levels. For example, a critical-level security update might require the cloud to be upgraded on a specified time line, whereas a low-level update might be more relaxed."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:165(title) msgid ""Testing the Updates"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:166(para) msgid ""You should test any update before you deploy it in a production environment. Typically this requires having a separate test cloud setup that first receives the update. This cloud should be as close to the production cloud as possible, in terms of software and hardware. Updates should be tested thoroughly in terms of performance impact, stability, application impact, and more. Especially important is to verify that the problem theoretically addressed by the update, such as a specific vulnerability, is actually fixed."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:177(title) msgid ""Deploying the Updates"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:178(para) msgid ""Once the updates are fully tested, they can be deployed to the production environment. This deployment should be fully automated using the configuration management tools described below."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:185(title) msgid ""Configuration Management"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:186(para) msgid ""A production quality cloud should always use tools to automate configuration and deployment. This eliminates human error, and allows the cloud to scale much more rapidly. Automation also helps with continuous integration and testing."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:191(para) msgid ""When building an OpenStack cloud it is strongly recommended to approach your design and implementation with a configuration management tool or framework in mind. Configuration management allows you to avoid the many pitfalls inherent in building, managing, and maintaining an infrastructure as complex as OpenStack. By producing the manifests, cookbooks, or templates required for a configuration management utility, you are able to satisfy a number of documentation and regulatory reporting requirements. Further, configuration management can also function as part of your BCP and DR plans wherein you can rebuild a node or service back to a known state in a DR event or given a compromise."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:203(para) msgid ""Additionally, when combined with a version control system such as Git or SVN, you can track changes to your environment over time and re-mediate unauthorized changes that may occur. For example, a <filename>nova.conf</filename> file or other configuration file falls out of compliance with your standard, your configuration management tool can revert or replace the file and bring your configuration back into a known state. Finally a configuration management tool can also be used to deploy updates; simplifying the security patch process. These tools have a broad range of capabilities that are useful in this space. The key point for securing your cloud is to choose a tool for configuration management and use it."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:215(para) msgid ""There are many configuration management solutions; at the time of this writing there are two in the marketplace that are robust in their support of OpenStack environments: <glossterm>Chef</glossterm> and <glossterm>Puppet</glossterm>. A non-exhaustive listing of tools in this space is provided below:"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:223(para) msgid ""Chef"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:226(para) msgid ""Puppet"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:229(para) msgid ""Salt Stack"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:232(para) msgid ""Ansible"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:236(title) msgid ""Policy Changes"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:237(para) msgid ""Whenever a policy or configuration management is changed, it is good practice to log the activity, and backup a copy of the new set. Often, such policies and configurations are stored in a version controlled repository such as git."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:244(title) msgid ""Secure Backup and Recovery"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:245(para) msgid ""It is important to include Backup procedures and policies in the overall System Security Plan. For a good overview of OpenStack's Backup and Recovery capabilities and procedures, please refer to the OpenStack Operations Guide."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:250(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:45(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:82(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:113(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:132(title) ./doc/security-guide/ch026_compute.xml:23(title) ./doc/security-guide/ch026_compute.xml:57(title) msgid ""Security Considerations"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:253(para) msgid ""Ensure only authenticated users and backup clients have access to the backup server."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:257(para) msgid ""Use data encryption options for storage and transmission of backups."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:261(para) msgid ""Use a dedicated and hardened backup servers. The logs for the backup server must be monitored daily and accessible by only few individuals."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:266(para) msgid ""Test data recovery options regularly. One of the things that can be restored from secured backups is the images. In case of a compromise, the best practice would be to terminate running instances immediately and then relaunch the instances from the images in the secured backup repository."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:276(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:64(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:123(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:157(title) ./doc/security-guide/ch026_compute.xml:33(title) ./doc/security-guide/ch026_compute.xml:70(title) ./doc/security-guide/ch058_forensicsincident-response.xml:43(title) msgid ""References"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:279(para) msgid ""<citetitle>OpenStack Operations Guide</citetitle> on <link href=\""http://docs.openstack.org/trunk/openstack-ops/content/backup_and_recovery.html\"">backup and recovery</link>"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:287(link) msgid ""http://www.sans.org/reading_room/whitepapers/backup/security-considerations-enterprise-level-backups_515"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:291(link) msgid ""OpenStack Security Primer"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:297(title) msgid ""Security Auditing Tools"" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:298(para) msgid ""Security auditing tools can complement the configuration management tools. Security auditing tools automate the process of verifying that a large number of security controls are satisfied for a given system configuration. These tools help to bridge the gap from security configuration guidance documentation (for example, the STIG and NSA Guides) to a specific system installation. For example, <link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP</link> can compare a running system to a pre-defined profile. SCAP outputs a report detailing which controls in the profile were satisfied, which ones failed, and which ones were not checked."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:310(para) msgid ""Combining configuration management and security auditing tools creates a powerful combination. The auditing tools will highlight deployment concerns. And the configuration management tools simplify the process of changing each system to address the audit concerns. Used together in this fashion, these tools help to maintain a cloud that satisfies security requirements ranging from basic hardening to compliance validation."" msgstr """" #: ./doc/security-guide/ch012_configuration-management.xml:317(para) msgid ""Configuration management and security auditing tools will introduce another layer of complexity into the cloud. This complexity brings additional security concerns with it. We view this as an acceptable risk trade-off, given their security benefits. Securing the operational use of these tools is beyond the scope of this guide."" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:3(title) msgid ""Case Studies: Monitoring and Logging"" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address monitoring and logging in the public vs a private cloud. In both instances, time synchronization and a centralized store of logs become extremely important for performing proper assessments and troubleshooting of anomalies. Just collecting logs is not very useful, a robust monitoring system must be built to generate actionable events."" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:6(title) ./doc/security-guide/ch039_case-studies-messaging.xml:6(title) ./doc/security-guide/ch066_case-studies-compliance.xml:6(title) ./doc/security-guide/ch028_case-studies-identity-management.xml:6(title) ./doc/security-guide/ch044_case-studies-database.xml:6(title) ./doc/security-guide/ch009_case-studies.xml:6(title) ./doc/security-guide/ch056_case-studies-instance-management.xml:6(title) ./doc/security-guide/ch022_case-studies-api-endpoints.xml:6(title) ./doc/security-guide/ch015_case-studies-management.xml:29(title) ./doc/security-guide/ch018_case-studies-pkissl.xml:6(title) ./doc/security-guide/ch035_case-studies-networking.xml:6(title) ./doc/security-guide/ch049_case-studies-tenant-data.xml:6(title) ./doc/security-guide/ch053_case-studies-instance-isolation.xml:6(title) msgid ""Alice's Private Cloud"" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:7(para) msgid ""In the private cloud, Alice has a better understanding of the tenants requirements and accordingly can add appropriate oversight and compliance on monitoring and logging. Alice should identify critical services and data and ensure that logging is turned at least on those services and is being aggregated to a central log server. She should start with simple and known use cases and implement correlation and alerting to limit the number of false positives. To implement correlation and alerting, she sends the log data to her organization's existing SIEM tool. Security monitoring should be an ongoing process and she should continue to define use cases and alerts as she has better understanding of the network traffic activity and usage over time."" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:10(title) ./doc/security-guide/ch039_case-studies-messaging.xml:10(title) ./doc/security-guide/ch066_case-studies-compliance.xml:13(title) ./doc/security-guide/ch028_case-studies-identity-management.xml:12(title) ./doc/security-guide/ch044_case-studies-database.xml:10(title) ./doc/security-guide/ch009_case-studies.xml:11(title) ./doc/security-guide/ch056_case-studies-instance-management.xml:12(title) ./doc/security-guide/ch022_case-studies-api-endpoints.xml:10(title) ./doc/security-guide/ch015_case-studies-management.xml:34(title) ./doc/security-guide/ch018_case-studies-pkissl.xml:10(title) ./doc/security-guide/ch035_case-studies-networking.xml:24(title) ./doc/security-guide/ch049_case-studies-tenant-data.xml:23(title) ./doc/security-guide/ch053_case-studies-instance-isolation.xml:12(title) msgid ""Bob's Public Cloud"" msgstr """" #: ./doc/security-guide/ch059_case-studies-monitoring-logging.xml:11(para) msgid ""When it comes to logging, as a public cloud provider, Bob is interested in logging both for situational awareness as well as compliance. That is, compliance that Bob as a provider is subject to as well as his ability to provide timely and relevant logs or reports on the behalf of his customers for their compliance audits. With that in mind, Bob configures all of his instances, nodes, and infrastructure devices to perform time synchronization with an external, known good time device. Additionally, Bob's team has built a Django based web applications for his customers to perform self-service log retrieval from Bob's SIEM tool. Bob also uses this SIEM tool along with a robust set of alerts and integration with his CMDB to provide operational awareness to both customers and cloud administrators."" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:6(title) msgid ""OpenStack Security Guide"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:14(orgname) ./doc/security-guide/bk_openstack-sec-guide.xml:19(holder) msgid ""OpenStack Foundation"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:18(year) msgid ""2013"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:21(releaseinfo) msgid ""havana"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:22(productname) msgid ""OpenStack"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:26(remark) msgid ""Copyright details are filled in by the template."" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:31(para) msgid ""This book provides best practices and conceptual information about securing an OpenStack cloud."" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:38(date) msgid ""2013-12-02"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:42(para) msgid ""Chapter on Object Storage added."" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:48(date) msgid ""2013-10-17"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:52(para) msgid ""Havana release."" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:58(date) msgid ""2013-07-02"" msgstr """" #: ./doc/security-guide/bk_openstack-sec-guide.xml:62(para) msgid ""Initial creation..."" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:3(title) msgid ""Privacy"" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:4(para) msgid ""Privacy is an increasingly important element of a compliance program. Businesses are being held to a higher standard by their customers, who have increased interest in understanding how their data is treated from a privacy perspective."" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:5(para) msgid ""An OpenStack deployment will likely need to demonstrate compliance with an organizations Privacy Policy, with the U.S.  E.U. Safe Harbor framework, the ISO/IEC 29100:2011 privacy framework or with other privacy-specific guidelines. In the U.S. the AICPA has <link href=\""http://www.aicpa.org/interestareas/informationtechnology/resources/privacy/generallyacceptedprivacyprinciples/\"">defined 10 privacy areas of focus</link>, OpenStack deployments within a commercial environment may desire to attest to some or all of these principles."" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:6(para) msgid ""To aid OpenStack architects in the protection of personal data, it is recommended that OpenStack architects review the NIST publication 800-122, titled \""<emphasis>Guide to Protecting the Confidentiality of Personally Identifiable Information (PII)</emphasis>.\"" This guide steps through the process of protecting:"" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:8(para) msgid ""\""<emphasis>any information about an individual maintained by an agency, including (1) any information that can be used to distinguish or trace an individuals identity, such as name, social security number, date and place of birth, mothers maiden name, or biometric records; and (2) any other information that is linked or linkable to an individual, such as medical, educational, financial, and employment information</emphasis>\"""" msgstr """" #: ./doc/security-guide/ch065_privacy.xml:10(para) msgid ""Comprehensive privacy management requires significant preparation, thought and investment. Additional complications are introduced when building global OpenStack clouds, for example navigating the differences between U.S. and more restrictive E.U. privacy laws. In addition, extra care needs to be taken when dealing with sensitive PII that may include information such as credit card numbers or medical records. This sensitive data is not only subject to privacy laws but also regulatory and governmental regulations. By deferring to established best practices, including those published by governments, a holistic privacy management policy may be created and practiced for OpenStack deployments."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:3(title) msgid ""Networking Services"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:4(para) msgid ""In the initial architectural phases of designing your OpenStack Network infrastructure it is important to ensure appropriate expertise is available to assist with the design of the physical networking infrastructure, to identify proper security controls and auditing mechanisms."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:5(para) msgid ""OpenStack Networking adds a layer of virtualized network services - giving tenants the capability to architect their own, virtual networks. These virtualized services are not as currently as mature as their traditional networking counterparts. It is important to be aware of the current state of these virtualized services and what controls may need to be implemented at the virtualized and traditional network boundary."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:7(title) msgid ""L2 Isolation using VLANs and Tunneling"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:8(para) msgid ""OpenStack networking can employ two different mechanisms for traffic segregation on a per tenant/network combination: VLANs (IEEE 802.1Q tagging) or L2 tunnels using GRE encapsulation. Which method you choose for traffic segregation and isolation is determined by the scope and scale of your OpenStack deployment."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:10(title) msgid ""VLANs"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:11(para) msgid ""VLANs are realized as packets on a specific physical network containing IEEE 802.1Q headers with a specific VLAN ID (VID) field value. VLAN networks sharing the same physical network are isolated from each other at L2, and can even have overlapping IP address spaces. Each distinct physical network supporting VLAN networks is treated as a separate VLAN trunk, with a distinct space of VID values. Valid VID values are 1 through 4094."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:12(para) msgid ""VLAN configuration complexity depends on your OpenStack design requirements. In order to allow OpenStack Networking to efficiently use VLANs, you must allocate a VLAN range (one for each tenant) and turn each compute node physical switch port into a VLAN trunk port."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:14(para) msgid ""NOTE: If you intend for your network to support more than 4094 tenants VLAN is probably not the correct option for you as multiple 'hacks' are required to extend the VLAN tags to more than 4094 tenants."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:18(title) msgid ""L2 Tunneling"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:19(para) msgid ""Network tunneling encapsulates each tenant/network combination with a unique \""tunnel-id\"" that is used to identify the network traffic belonging to that combination. The tenant's L2 network connectivity is independent of physical locality or underlying network design. By encapsulating traffic inside IP packets, that traffic can cross Layer-3 boundaries, removing the need for preconfigured VLANs and VLAN trunking. Tunneling adds a layer of obfuscation to network data traffic, reducing the visibility of individual tenant traffic from a monitoring point of view."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:20(para) msgid ""OpenStack Networking currently only supports GRE encapsulation with planned future support of VXLAN due in the Havana release."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:21(para) msgid ""The choice of technology to provide L2 isolation is dependent upon the scope and size of tenant networks that will be created in your deployment. If your environment has limited VLAN ID availability or will have a large number of L2 networks, it is our recommendation that you utilize tunneling."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:25(title) msgid ""Network Services"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:26(para) msgid ""The choice of tenant network isolation affects how the network security and control boundary is implemented for tenant services. The following additional network services are either available or currently under development to enhance the security posture of the OpenStack network architecture."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:28(title) msgid ""Access Control Lists"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:29(para) msgid ""OpenStack Compute supports tenant network traffic access controls directly when deployed with the legacy nova-network service, or may defer access control to the OpenStack Networking service."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:30(para) msgid ""Note, legacy nova-network security groups are applied to all virtual interface ports on an instance using IPTables."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:31(para) msgid ""Security groups allow administrators and tenants the ability to specify the type of traffic, and direction (ingress/egress) that is allowed to pass through a virtual interface port. Security groups rules are stateful L2-L4 traffic filters."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:32(para) msgid ""It is our recommendation that you enable security groups via OpenStack Networking."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:35(title) msgid ""L3 Routing and NAT"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:36(para) msgid ""OpenStack Networking routers can connect multiple L2 networks, and can also provide a <emphasis>gateway</emphasis> that connects one or more private L2 networks to a shared <emphasis>external</emphasis> network, such as a public network for access to the Internet."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:37(para) msgid ""The L3 router provides basic Network Address Translation (NAT) capabilities on <emphasis>gateway</emphasis> ports that uplink the router to external networks. This router SNATs (Static NAT) all traffic by default, and supports floating IPs, which creates a static one-to-one mapping from a public IP on the external network to a private IP on one of the other subnets attached to the router."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:38(para) msgid ""It is our recommendation to leverage per tenant L3 routing and Floating IPs for more granular connectivity of tenant VMs."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:41(title) msgid ""Quality of Service (QoS)"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:42(para) msgid ""The ability to set QoS on the virtual interface ports of tenant instances is a current deficiency for OpenStack Networking. The application of QoS for traffic shaping and rate-limiting at the physical network edge device is insufficient due to the dynamic nature of workloads in an OpenStack deployment and can not be leveraged in the traditional way. QoS-as-a-Service (QoSaaS) is currently in development for the OpenStack Networking Havana release as an experimental feature. QoSaaS is planning to provide the following services:"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:44(para) msgid ""Traffic shaping via DSCP markings"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:47(para) msgid ""Rate-limiting on a per port/network/tenant basis."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:50(para) msgid ""Port mirroring (via open source or third-party plugins)"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:53(para) msgid ""Flow analysis (via open source or third-party plugins)"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:56(para) msgid ""Tenant traffic port mirroring or Network Flow monitoring is currently not an exposed feature in OpenStack Networking. There are third-party plugin extensions that do provide Port Mirroring on a per port/network/tenant basis. If Open vSwitch is used on the networking hypervisor, it is possible to enable sFlow and port mirroring, however it will require some operational effort to implement."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:59(title) msgid ""Load Balancing"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:60(para) msgid ""An experimental feature in the Grizzly release of OpenStack Networking is Load-Balancer-as-a-service (LBaaS). The LBaaS API gives early adopters and vendors a chance to build implementations of the technology. The reference implementation however, is still experimental and should likely not be run in a production environment. The current reference implementation is based on HA-Proxy. There are third-party plugins in development for extensions in OpenStack Networking to provide extensive L4-L7 functionality for virtual interface ports."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:63(title) msgid ""Firewalls"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:64(para) msgid ""FW-as-a-Service (FWaaS) is currently in development for the OpenStack Networking Havana release as an experimental feature. FWaaS will address the need to manage and leverage the rich set of security features provided by typical firewall products which are typically far more comprehensive than what is currently provided by security groups. There are third-party plugins in development for extensions in OpenStack Networking to support this."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:65(para) msgid ""It is critical during the design of an OpenStack Networking infrastructure to understand the current features and limitations of network services that are available. Understanding where the boundaries of your virtual and physical networks will help you add the required security controls in your environment."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:69(title) msgid ""Network Services Extensions"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:70(para) msgid ""Here is a list of known plugins provided by the open source community or by SDN companies that work with OpenStack Networking:"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:71(para) msgid ""Big Switch Controller Plugin, Brocade Neutron Plugin Brocade Neutron Plugin, Cisco UCS/Nexus Plugin, Cloudbase Hyper-V Plugin, Extreme Networks Plugin, Juniper Networks Neutron Plugin, Linux Bridge Plugin, Mellanox Neutron Plugin, MidoNet Plugin, NEC OpenFlow Plugin, Nicira Network Virtualization Platform (NVP) Plugin, Open vSwitch Plugin, PLUMgrid Plugin, Ruijie Networks Plugin, Ryu OpenFlow Controller Plugin"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:72(para) msgid ""For a more detailed comparison of all features provided by plugins as of the Folsom release, see <link href=\""http://www.sebastien-han.fr/blog/2012/09/28/quantum-plugin-comparison/\"">Sebastien Han's comparison</link>."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:75(title) msgid ""Networking Services Limitations"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:76(para) msgid ""OpenStack Networking has the following known limitations:"" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:78(para) msgid ""<emphasis role=\""bold\"">Overlapping IP addresses</emphasis>  If nodes that run either <literal>neutron-l3-agent</literal> or <literal>neutron-dhcp-agent</literal> use overlapping IP addresses, those nodes must use Linux network namespaces. By default, the DHCP and L3 agents use Linux network namespaces. However, if the host does not support these namespaces, run the DHCP and L3 agents on different hosts."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:79(para) msgid ""If network namespace support is not present, a further limitation of the L3 Agent is that only a single logical router is supported."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:82(para) msgid ""<emphasis role=\""bold\"">Multi-Host DHCP-agent</emphasis>  OpenStack Networking supports multiple l3-agent and dhcp-agents with load balancing. However, tight coupling of the location of the virtual machine is not supported."" msgstr """" #: ./doc/security-guide/ch032_networking-best-practices.xml:85(para) msgid ""<emphasis role=\""bold\"">No IPv6 Support for L3 agents</emphasis>  The neutron-l3-agent, used by many plugins to implement L3 forwarding, supports only IPv4 forwarding."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch055_security-services-for-instances.xml:47(None) ./doc/security-guide/ch055_security-services-for-instances.xml:50(None) msgid ""@@image: 'static/filteringWorkflow1.png'; md5=c144af5cbdee1bd17a7bde0bea5b5fe7"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:3(title) msgid ""Security Services for Instances"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:4(para) msgid ""One of the virtues of running instances in a virtualized environment is that it opens up new opportunities for security controls that are not typically available when deploying onto bare metal. There are several technologies that can be applied to the virtualization stack that bring improved information assurance for cloud tenants."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:5(para) msgid ""Deployers or users of OpenStack with strong security requirements may want to consider deploying these technologies. Not all are applicable in every situation, indeed in some cases technologies may be ruled out for use in a cloud because of prescriptive business requirements. Similarly some technologies inspect instance data such as run state which may be undesirable to the users of the system."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:6(para) msgid ""In this chapter we explore these technologies and describe the situations where they can be used to enhance security for instances or underlying instances. We also seek to highlight where privacy concerns may exist. These include data pass through, introspection, or providing a source of entropy. In this section we highlight the following additional security services:"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:8(para) msgid ""Entropy to Instances"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:11(para) ./doc/security-guide/ch055_security-services-for-instances.xml:28(title) msgid ""Scheduling Instances to Nodes"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:14(para) ./doc/security-guide/ch055_security-services-for-instances.xml:88(title) msgid ""Trusted Images"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:17(para) ./doc/security-guide/ch055_security-services-for-instances.xml:153(title) msgid ""Instance Migrations"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:21(title) msgid ""Entropy To Instances"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:22(para) msgid ""We consider entropy to refer to the quality and source of random data that is available to an instance. Cryptographic technologies typically rely heavily on randomness, requiring a high quality pool of entropy to draw from. It is typically hard for a virtual machine to get enough entropy to support these operations. Entropy starvation can manifest in instances as something seemingly unrelated for example, slow boot times because the instance is waiting for ssh key generation. Entropy starvation may also motivate users to employ poor quality entropy sources from within the instance, making applications running in the cloud less secure overall."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:23(para) msgid ""Fortunately, a cloud architect may address these issues by providing a high quality source of entropy to the cloud instances. This can be done by having enough hardware random number generators (HRNG) in the cloud to support the instances. In this case, \""enough\"" is somewhat domain specific. For everyday operations, a modern HRNG is likely to produce enough entropy to support 50-100 compute nodes. High bandwidth HRNGs, such as the RdRand instruction available with Intel Ivy Bridge and newer processors could potentially handle more nodes. For a given cloud, an architect needs to understand the application requirements to ensure that sufficient entropy is available."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:24(para) msgid ""Once the entropy is available in the cloud, the next step is getting that entropy into the instances. Tools such as the entropy gathering daemon (<link href=\""http://egd.sourceforge.net/\"">EGD</link>) provide a way to fairly and securely distribute entropy through a distributed system. Support exists for using the EGD as an entropy source for LibVirt."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:25(para) msgid ""Compute support for these features is not generally available, but it would only require a moderate amount of work for implementors to integrate this functionality."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:29(para) msgid ""Before an instance is created, a host for the image instantiation must be selected. This selection is performed by the <systemitem class=\""service\"">nova-scheduler</systemitem> which determines how to dispatch compute and volume requests."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:30(para) msgid ""The default nova scheduler in Grizzly is the Filter Scheduler, although other schedulers exist (see the section <link href=\""http://docs.openstack.org/trunk/config-reference/content/section_compute-scheduler.html\"">Scheduling</link> in the <citetitle>OpenStack Configuration Reference</citetitle>). The filter scheduler works in collaboration with 'filters' to decide where an instance should be started. This process of host selection allows administrators to fulfill many different security requirements. Depending on the cloud deployment type for example, one could choose to have tenant instances reside on the same hosts whenever possible if data isolation was a primary concern, conversely one could attempt to have instances for a tenant reside on as many different hosts as possible for availability or fault tolerance reasons. The following diagram demonstrates how the filter scheduler works:"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:53(para) msgid ""The use of scheduler filters may be used to segregate customers, data, or even discard machines of the cloud that cannot be attested as secure. This generally applies to all OpenStack projects offering a scheduler. When building a cloud, you may choose to implement scheduling filters for a variety of security-related purposes."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:54(para) msgid ""Below we highlight a few of the filters that may be useful in a security context, depending on your requirements, the full set of filter documentation is documented in the <link href=\""http://docs.openstack.org/trunk/config-reference/content/filter-scheduler.html\"">Filter Scheduler</link> section of the <citetitle>OpenStack Configuration Reference</citetitle>."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:55(emphasis) msgid ""Tenant Driven Whole Host Reservation"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:56(para) msgid ""There currently exists a <link href=\""https://blueprints.launchpad.net/nova/+spec/whole-host-allocation\"">blueprint for whole host reservation</link> - This would allow a tenant to exclusively reserve hosts for only it's instances, incurring extra costs."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:58(title) msgid ""Host Aggregates"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:59(para) msgid ""While not a filter in themselves, host aggregates allow administrators to assign key-value pairs to groups of machines. This allows cloud administrators, not users, to partition up their compute host resources. Each node can have multiple aggregates (see the <link href=\""http://docs.openstack.org/trunk/config-reference/content/host-aggregates.html\"">Host Aggregates</link> section of the <citetitle>OpenStack Configuration Reference</citetitle> for more information on creating and managing aggregates)."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:70(title) msgid ""AggregateMultiTenancyIsolation"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:71(para) msgid ""Isolates tenants to specific host aggregates. If a host is in an aggregate that has the metadata key <literal>filter_tenant_id</literal> it will only create instances from that tenant (or list of tenants). A host can be in multiple aggregates. If a host does not belong to an aggregate with the metadata key, it can create instances from all tenants."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:74(title) msgid ""DifferentHostFilter"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:75(para) msgid ""Schedule the instance on a different host from a set of instances. To take advantage of this filter, the requester must pass a scheduler hint, using <literal>different_host</literal> as the key and a list of instance uuids as the value. This filter is the opposite of the <literal>SameHostFilter</literal>."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:78(title) msgid ""GroupAntiAffinityFilter"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:79(para) msgid ""The GroupAntiAffinityFilter ensures that each instance in a group is on a different host. To take advantage of this filter, the requester must pass a scheduler hint, using <literal>group</literal> as the key and a list of instance uuids as the value."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:82(title) msgid ""Trusted Compute Pools"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:83(para) msgid ""There exists a scheduler filter which integrates with the <link href=\""https://github.com/OpenAttestation/OpenAttestation\"">Open Attestation Project</link> (OATS) to define scheduler behavior according to the attestation of PCRs received from a system using Intel TXT."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:84(para) msgid ""It is unclear if this feature is compatible with AMD's similar SEM, although the OpenAttestation agent relies on the vendor-agnostic <link href=\""http://trousers.sourceforge.net/\"">TrouSerS library</link>."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:89(para) msgid ""With regards to images, users will be working with pre-installed images or images that they upload themselves. In both cases, users will want to ensure that the image they are ultimately running has not been tampered with. This requires some source of truth such as a checksum for the known good version of an image as well as verification of the running image. This section describes the current best practices around image handling, while also calling out some of the existing gaps in this space."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:91(title) msgid ""Image Creation Process"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:92(para) msgid ""The OpenStack Documentation provides guidance on how to create and upload an image to Glance. Additionally it is assumed that you have a process by which you install and harden operating systems. Thus, the following items will provide additional guidance on how to ensure your images are built securely prior to upload. There are a variety of options for obtaining images. Each has specific steps that help validate the image's provenance."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:93(para) msgid ""The first option is to obtain boot media from a trusted source."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:103(para) msgid ""The second option is to use the <link href=\""http://docs.openstack.org/trunk/image-guide/content/\""><citetitle>OpenStack Virtual Machine Image Guide</citetitle></link>. In this case, you will want to follow your organizations OS hardening guidelines or those provided by a trusted third-party such as the <link href=\""http://iase.disa.mil/stigs/os/unix/red_hat.html\"">RHEL6 STIG</link>."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:104(para) msgid ""The final option is to use an automated image builder. The following example uses the Oz image builder. The OpenStack community has recently created a newer tool worth investigating: disk-image-builder. We have not evaluated this tool from a security perspective."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:105(para) msgid ""Example of RHEL 6 CCE-26976-1 which will help implement NIST 800-53 Section <emphasis>AC-19(d) in</emphasis> Oz."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:142(para) msgid ""Note, it is the recommendation of this guide to shy away from the manual image building process as it is complex and prone to error. Further, using an automated system like Oz or disk-image-builder for image building, or a configuration management utility like Chef or Puppet for post boot image hardening gives you the ability to produce a consistent image as well as track compliance of your base image to its respective hardening guidelines over time."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:143(para) msgid ""If subscribing to a public cloud service, you should check with the cloud provider for an outline of the process used to produce their default images. If the provider allows you to upload your own images, you will want to ensure that you are able to verify that your image was not modified before you spin it up. To do this, refer to the following section on Image Provenance."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:146(title) msgid ""Image Provenance and Validation"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:147(para) msgid ""Unfortunately, it is not currently possible to force Compute to validate an image hash immediately prior to starting an instance. To understand the situation, we begin with a brief overview of how images are handled around the time of image launch."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:148(para) msgid ""Images come from the glance service to the nova service on a node. This transfer should be protected by running over SSL. Once the image is on the node, it is verified with a basic checksum and then it's disk is expanded based on the size of the instance being launched. If, at a later time, the same image is launched with the same instance size on this node, it will be launched from the same expanded image. Since this expanded image is not re-verified before launching, it could be tampered with and the user would not have any way of knowing, beyond a manual inspection of the files in the resulting image."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:149(para) msgid ""We hope that future versions of Compute and/or the Image Service will offer support for validating the image hash before each instance launch. An alternative option that would be even more powerful would be allow users to sign an image and then have the signature validated when the instance is launched."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:154(para) msgid ""OpenStack and the underlying virtualization layers provide for the Live Migration of images between OpenStack nodes allowing you to seamlessly perform rolling upgrades of your OpenStack Compute nodes without instance downtime. However, Live Migrations also come with their fair share of risk. To understand the risks involved, it is important to first understand how a live migration works. The following are the high level steps preformed during a live migration."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:156(para) msgid ""Start instance on destination host"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:157(para) msgid ""Transfer memory"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:158(para) msgid ""Stop the guest &amp; sync disks"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:159(para) msgid ""Transfer state"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:160(para) msgid ""Start the guest"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:163(title) msgid ""Live Migration Risks"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:164(para) msgid ""At various stages of the live migration process the contents of an instances run time memory and disk are transmitted over the network in plain text. Thus there are several risks that need to be addressed when using live migration. The following in-exhaustive list details some of these risks:"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:166(para) msgid ""<emphasis>Denial of Service (DoS)</emphasis> : If something fails during the migration process, the instance could be lost."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:169(para) msgid ""<emphasis>Data Exposure</emphasis> : Memory or disk transfers must be handled securely."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:172(para) msgid ""<emphasis>Data Manipulation</emphasis> : If memory or disk transfers are not handled securely, then an attacker could manipulate user data during the migration."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:175(para) msgid ""<emphasis>Code Injection</emphasis> : If memory or disk transfers are not handled securely, then an attacker could manipulate executables, either on disk or in memory, during the migration."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:180(title) msgid ""Live Migration Mitigations"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:181(para) msgid ""There are several methods to mitigate some of the risk associated with live migrations, the following list details some of these:"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:183(para) ./doc/security-guide/ch055_security-services-for-instances.xml:193(title) msgid ""Disable Live Migration"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:186(para) msgid ""Isolated Migration Network"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:189(para) ./doc/security-guide/ch055_security-services-for-instances.xml:204(title) msgid ""Encrypted Live Migration"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:194(para) msgid ""At this time, live migration is enabled in OpenStack by default. Live migrations can be disabled by adding the following lines to the nova policy.json file:"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:200(title) msgid ""Migration Network"" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:201(para) msgid ""As a general practice, live migration traffic should be restricted to the management security domain. Indeed live migration traffic, due to its plain text nature and the fact that you are transferring the contents of disk and memory of a running instance, it is recommended you further separate live migration traffic onto a dedicated network. Isolating the traffic to a dedicated network can reduce the risk of exposure."" msgstr """" #: ./doc/security-guide/ch055_security-services-for-instances.xml:205(para) msgid ""If your use case involves keeping live migration enabled, then libvirtd can provide tunneled, encrypted live migrations. That said, this feature is not currently exposed in OpenStack Dashboard, nor the nova-client commands and can only be accessed through manual configuration of libvritd. Encrypted live migration modifies the live migration process by first copying the instance data from the running hypervisor to libvirtd. From there an encrypted tunnel is created between the libvirtd processes on both hosts. Finally, the destination libvirtd process copies the instance back to the underlying hypervisor."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:3(title) msgid ""Compliance Overview"" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:4(para) msgid ""An OpenStack deployment may require compliance activities for many purposes, such as regulatory and legal requirements, customer need, privacy considerations, and security best practices. Compliance, when done correctly, unifies and strengthens the other security topics discussed in this guide. This chapter has several objectives:"" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:6(para) msgid ""Review common security principles."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:9(para) msgid ""Discuss common control frameworks and certification resources to achieve industry certifications or regulator attestations."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:12(para) msgid ""Act as a reference for auditors when evaluating OpenStack deployments."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:15(para) msgid ""Introduce privacy considerations specific to OpenStack and cloud environments."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:19(title) msgid ""Security Principles"" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:20(para) msgid ""Industry standard security principles provide a baseline for compliance certifications and attestations. If these principles are considered and referenced throughout an OpenStack deployment, certification activities may be simplified."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:22(para) msgid ""<emphasis>Layered Defenses</emphasis>: Identify where risks exist in a cloud architecture and apply controls to mitigate the risks. In areas of significant concern, layered defences provide multiple complementary controls to further mitigate risk. For example, to ensure adequate isolation between cloud tenants, we recommend hardening QEMU, using a hypervisor with SELinux support, enforcing mandatory access control policies, and reducing the overall attack surface. The foundational principle is to harden an area of concern with multiple layers of defense such that if any one layer is compromised, other layers will exist to offer protection and minimize exposure."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:25(para) msgid ""<emphasis>Fail Securely</emphasis>: In the case of failure, systems should be configured to fail into a closed secure state. For example, SSL certificate verification should fail closed by severing the network connection if the CNAME doesn't match the server's DNS name. Software often fails open in this situation, allowing the connection to proceed without a CNAME match, which is less secure and not recommended."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:28(para) msgid ""<emphasis>Least Privilege</emphasis>: Only the minimum level of access for users and system services is granted. This access is based upon role, responsibility and job function. This security principal of least privilege is written into several international government security policies, such as NIST 800-53 Section AC-6 within the United States. "" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:31(para) msgid ""<emphasis>Compartmentalize</emphasis>: Systems should be segregated in a such way that if one machine, or system-level service, is compromised the security of the other systems will remain intact. Practically, the enablement and proper usage of SELinux helps accomplish this goal."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:34(para) msgid ""<emphasis>Promote Privacy</emphasis>: The amount of information that can be gathered about a system and its users should be minimized."" msgstr """" #: ./doc/security-guide/ch061_compliance-overview.xml:37(para) msgid ""<emphasis>Logging Capability</emphasis>: Appropriate logging is implemented to monitor for unauthorized use, incident response and forensics. It is highly recommended that selected audit subsystems be Common Criteria certified, which provides non-attestable event records in most countries."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:8(title) msgid ""Certification &amp; Compliance Statements"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:9(para) msgid ""Compliance and security are not exclusive, and must be addressed together. OpenStack deployments are unlikely to satisfy compliance requirements without security hardening. The listing below provides an OpenStack architect foundational knowledge and guidance to achieve compliance against commercial and government certifications and standards."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:17(title) msgid ""Commercial Standards"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:18(para) msgid ""For commercial deployments of OpenStack, it is recommended that SOC 1/2 combined with ISO 2700 1/2 be considered as a starting point for OpenStack certification activities. The required security activities mandated by these certifications facilitate a foundation of security best practices and common control criteria that can assist in achieving more stringent compliance activities, including government attestations and certifications."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:26(para) msgid ""After completing these initial certifications, the remaining certifications are more deployment specific. For example, clouds processing credit card transactions will need PCI-DSS, clouds storing health care information require HIPAA, and clouds within the federal government may require FedRAMP/FISMA, and ITAR, certifications. "" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:34(title) msgid ""SOC 1 (SSAE 16) / ISAE 3402"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:35(para) msgid ""Service Organization Controls (SOC) criteria are defined by the <link href=\""http://www.aicpa.org/\"">American Institute of Certified Public Accountants</link> (AICPA). SOC controls assess relevant financial statements and assertions of a service provider, such as compliance with the Sarbanes-Oxley Act. SOC 1 is a replacement for Statement on Auditing Standards No. 70 (SAS 70) Type II report. These controls commonly include physical data centers in scope."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:44(para) msgid ""There are two types of SOC 1 reports:"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:47(para) ./doc/security-guide/ch064_certifications-compliance-statements.xml:84(para) msgid ""Type 1  report on the fairness of the presentation of management's description of the service organization's system and the suitability of the design of the controls to achieve the related control objectives included in the description as of a specified date."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:54(para) msgid ""Type 2  report on the fairness of the presentation of management's description of the service organization's system and the suitability of the design and operating effectiveness of the controls to achieve the related control objectives included in the description throughout a specified period"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:62(para) msgid ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/AssuranceAdvisoryServices/Pages/AICPASOC1Report.aspx\"">AICPA Report on Controls at a Service Organization Relevant to User Entities Internal Control over Financial Reporting</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:70(title) msgid ""SOC 2"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:71(para) msgid ""Service Organization Controls (SOC) 2 is a self attestation of controls that affect the security, availability, and processing integrity of the systems a service organization uses to process users' data and the confidentiality and privacy of information processed by these system. Examples of users are those responsible for governance of the service organization; customers of the service organization; regulators; business partners; suppliers and others who have an understanding of the service organization and its controls."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:81(para) msgid ""There are two types of SOC 2 reports:"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:91(para) msgid ""Type 2  report on the fairness of the presentation of management's description of the service organization's system and the suitability of the design and operating effectiveness of the controls to achieve the related control objectives included in the description throughout a specified period."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:99(para) msgid ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/AssuranceAdvisoryServices/Pages/AICPASOC2Report.aspx\"">AICPA Report on Controls at a Service Organization Relevant to Security, Availability, Processing Integrity, Confidentiality or Privacy</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:108(title) msgid ""SOC 3"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:109(para) msgid ""Service Organization Controls (SOC) 3 is a trust services report for service organizations. These reports are designed to meet the needs of users who want assurance on the controls at a service organization related to security, availability, processing integrity, confidentiality, or privacy but do not have the need for or the knowledge necessary to make effective use of a SOC 2 Report. These reports are prepared using the AICPA/Canadian Institute of Chartered Accountants (CICA) Trust Services Principles, Criteria, and Illustrations for Security, Availability, Processing Integrity, Confidentiality, and Privacy. Because they are general use reports, SOC 3 Reports can be freely distributed or posted on a website as a seal."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:121(para) msgid ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/AssuranceAdvisoryServices/Pages/AICPASOC3Report.aspx\"">AICPA Trust Services Report for Service Organizations</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:128(title) msgid ""ISO 27001/2"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:129(para) msgid ""The ISO/IEC 27001/2 standards replace BS7799-2, and are specifications for an Information Security Management System (ISMS). An ISMS is a comprehensive set of policies and processes that an organization creates and maintains to manage risk to information assets. These risks are based upon the confidentiality, integrity, and availability (CIA) of user information. The CIA security triad has been used as a foundation for much of the chapters in this book."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:137(para) msgid ""For more details see <link href=\""http://www.27000.org/iso-27001.htm\"">ISO 27001</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:143(title) msgid ""HIPAA / HITECH"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:144(para) msgid ""The Health Insurance Portability and Accountability Act (HIPAA) is a United States congressional act that governs the collection, storage, use and destruction of patient health records. The act states that Protected Health Information (PHI) must be rendered \""unusable, unreadable, or indecipherable\"" to unauthorized persons and that encryption for data 'at-rest' and 'inflight' should be addressed."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:151(para) msgid ""HIPAA is not a certification, rather a guide for protecting healthcare data. Similar to the PCI-DSS, the most important issues with both PCI and HIPPA is that a breach of credit card information, and health data, does not occur. In the instance of a breach the cloud provider will be scrutinized for compliance with PCI and HIPPA controls. If proven compliant, the provider can be expected to immediately implement remedial controls, breach notification responsibilities, and significant expenditure on additional compliance activities. If not compliant, the cloud provider can expect on-site audit teams, fines, potential loss of merchant ID (PCI), and massive reputation impact."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:163(para) msgid ""Users or organizations that possess PHI must support HIPAA requirements and are HIPAA covered entities. If an entity intends to use a service, or in this case, an OpenStack cloud that might use, store or have access to that PHI, then a Business Associate Agreement must be signed. The BAA is a contract between the HIPAA covered entity and the OpenStack service provider that requires the provider to handle that PHI in accordance with HIPAA requirements. If the service provider does not handle the PHI, such as with security controls and hardening, then they are subject to HIPAA fines and penalties."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:174(para) msgid ""OpenStack architects interpret and respond to HIPAA statements, with data encryption remaining a core practice. Currently this would require any protected health information contained within an OpenStack deployment to be encrypted with industry standard encryption algorithms. Potential future OpenStack projects such as object encryption will facilitate HIPAA guidelines for compliance with the act."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:181(para) msgid ""For more details see the <link href=\""https://www.cms.gov/Regulations-and-Guidance/HIPAA-Administrative-Simplification/HIPAAGenInfo/downloads/HIPAALaw.pdf\"">Health Insurance Portability And Accountability Act</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:187(title) msgid ""PCI-DSS"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:188(para) msgid ""The Payment Card Industry Data Security Standard (PCI DSS) is defined by the Payment Card Industry Standards Council, and created to increase controls around card holder data to reduce credit card fraud. Annual compliance validation is assessed by an external Qualified Security Assessor (QSA) who creates a Report on Compliance (ROC), or by a Self-Assessment Questionnaire (SAQ) dependent on volume of card-holder transactions. "" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:196(para) msgid ""OpenStack deployments which stores, processes, or transmits payment card details are in scope for the PCI-DSS. All OpenStack components that are not properly segmented from systems or networks that handle payment data fall under the guidelines of the PCI-DSS. Segmentation in the context of PCI-DSS does not support multi-tenancy, but rather physical separation (host/network). "" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:203(para) msgid ""For more details see <link href=\""https://www.pcisecuritystandards.org/security_standards/\"">PCI security standards</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:209(title) msgid ""Government Standards"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:212(title) msgid ""FedRAMP"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:213(para) msgid ""\""The <link href=\""http://www.fedramp.gov\"">Federal Risk and Authorization Management Program</link> (FedRAMP) is a government-wide program that provides a standardized approach to security assessment, authorization, and continuous monitoring for cloud products and services\"". NIST 800-53 is the basis for both FISMA and FedRAMP which mandates security controls specifically selected to provide protection in cloud environments. FedRAMP can be extremely intensive from specificity around security controls, and the volume of documentation required to meet government standards."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:223(para) msgid ""For more details see <link href=\""http://www.gsa.gov/portal/category/102371\"">http://www.gsa.gov/portal/category/102371</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:229(title) msgid ""ITAR"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:230(para) msgid ""The International Traffic in Arms Regulations (ITAR) is a set of United States government regulations that control the export and import of defense-related articles and services on the United States Munitions List (USML) and related technical data. ITAR is often approached by cloud providers as an \""operational alignment\"" rather than a formal certification. This typically involves implementing a segregated cloud environment following practices based on the NIST 800-53 framework, as per FISMA requirements, complemented with additional controls restricting access to \""U.S. Persons\"" only and background screening."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:241(para) msgid ""For more details see <link href=\""http://pmddtc.state.gov/regulations_laws/itar_official.html\"">http://pmddtc.state.gov/regulations_laws/itar_official.html</link>."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:247(title) msgid ""FISMA"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:248(para) msgid ""The Federal Information Security Management Act requires that government agencies create a comprehensive plan to implement numerous government security standards, and was enacted within the E-Government Act of 2002. FISMA outlines a process, which utilizing multiple NIST publications, prepares an information system to store and process government data."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:255(para) msgid ""This process is broken apart into three primary categories:"" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:259(para) msgid ""<emphasis role=\""bold\"">System Categorization</emphasis>The information system will receive a security category as defined in Federal Information Processing Standards Publication 199 (FIPS 199). These categories reflect the potential impact of system compromise."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:267(para) msgid ""<emphasis role=\""bold\"">Control Selection</emphasis>Based upon system security category as defined in FIPS 199, an organization utilizes FIPS 200 to identify specific security control requirements for the information system. For example, if a system is categorized as moderate a requirement may be introduced to mandate secure passwords."" msgstr """" #: ./doc/security-guide/ch064_certifications-compliance-statements.xml:276(para) msgid ""<emphasis role=\""bold\"">Control Tailoring</emphasis>Once system security controls are identified, an OpenStack architect will utilize NIST 800-53 to extract tailored control selection. For example, specification of what constitutes a secure password."" msgstr """" #: ./doc/security-guide/ch039_case-studies-messaging.xml:3(title) msgid ""Case Studies: Messaging"" msgstr """" #: ./doc/security-guide/ch039_case-studies-messaging.xml:4(para) msgid ""The message queue is a critical piece of infrastructure that supports a number of OpenStack services but is most strongly associated with the Compute service. Due to the nature of the message queue service, Alice and Bob have similar security concerns. One of the larger concerns that remains is that many systems have access to this queue and there is no way for a consumer of the queue messages to verify which host or service placed the messages on the queue. An attacker who is able to successfully place messages on the queue is able to create and delete VM instances, attach the block storage of any tenant and a myriad of other malicious actions. There are a number of solutions on the horizon to fix this, with several proposals for message signing and encryption making their way through the OpenStack development process."" msgstr """" #: ./doc/security-guide/ch039_case-studies-messaging.xml:7(para) msgid ""In this case Alice's controls mimic those Bob has deployed for the public cloud."" msgstr """" #: ./doc/security-guide/ch039_case-studies-messaging.xml:11(para) msgid ""Bob assumes that at some point infrastructure or networks underpinning the Compute service may become compromised. Due to this, he recognizes the importance of locking down access to the message queue. To do this Bob deploys his RabbitMQ servers with SSL and X.509 client auth for access control. This in turn limits the capabilities of an attacker who has compromised a system that does not have queue access."" msgstr """" #: ./doc/security-guide/ch039_case-studies-messaging.xml:12(para) msgid ""Additionally, Bob adds strong network ACL rulesets to enforce which endpoints can communicate with the message servers. This second control provides some additional assurance should the other protections fail."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:3(title) msgid ""Case Studies: Compliance"" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address common compliance requirements. The preceding chapter refers to a wide variety of compliance certifications and standards. Alice will address compliance in a private cloud, while Bob will be focused on compliance for a public cloud."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:7(para) msgid ""Alice is building an OpenStack private cloud for the United States government, specifically to provide elastic compute environments for signal processing. Alice has researched government compliance requirements, and has identified that her private cloud will be required to certify against FISMA and follow the FedRAMP accreditation process, which is required for all federal agencies, departments and contractors to become a Certified Cloud Provider (CCP). In this particular scenario for signal processing, the FISMA controls required will most likely be FISMA High, which indicates possible \""severe or catastrophic adverse effects\"" should the information system become compromised. In addition to FISMA Moderate controls Alice must ensure her private cloud is FedRAMP certified, as this is a requirement for all agencies that currently utilize, or host federal information within a cloud environment."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:8(para) msgid ""To meet these strict government regulations Alice undertakes a number of activities. Scoping of requirements is particularly important due to the volume of controls that must be implemented, which will be defined in NIST Publication 800-53."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:9(para) msgid ""All technology within her private cloud must be FIPS certified technology, as mandated within NIST 800-53 and FedRAMP. As the U.S. Department of Defense is involved, Security Technical Implementation Guides (STIGs) will come into play, which are the configuration standards for DOD IA and IA-enabled devices / systems. Alice notices a number of complications here as there is no STIG for OpenStack, so she must address several underlying requirements for each OpenStack service; for example, the networking SRG and Application SRG will both be applicable (<link href=\""http://iase.disa.mil/srgs/index.html\"">list of SRGs</link>). Other critical controls include ensuring that all identities in the cloud use PKI, that SELinux is enabled, that encryption exists for all wire-level communications, and that continuous monitoring is in place and clearly documented. Alice is not concerned with object encryption, as this will be the tenants responsibility rather than the provider."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:10(para) msgid ""If Alice has adequately scoped and executed these compliance activities, she may begin the process to become FedRAMP compliant by hiring an approved third-party auditor. Typically this process takes up to 6 months, after which she will receive an Authority to Operate and can offer OpenStack cloud services to the government."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:14(para) msgid ""Bob is tasked with compliance for a new OpenStack public cloud deployment, that is focused on providing cloud services to both small developers and startups, as well as large enterprises. Bob recognizes that individual developers are not necessarily concerned with compliance certifications, but to larger enterprises certifications are critical. Specifically Bob desires to achieve SOC 1, SOC 2 Security, as well as ISO 27001/2 as quickly as possible. Bob references the Cloud Security Alliance Cloud Control Matrix (CCM) to assist in identifying common controls across these three certifications (such as periodic access reviews, auditable logging and monitoring services, risk assessment activities, security reviews, etc). Bob then engages an experienced audit team to conduct a gap analysis on the public cloud deployment, reviews the results and fills any gaps identified. Bob works with other team members to ensure that these security controls and activities are regularly conducted for a typical audit period (~6-12 months)."" msgstr """" #: ./doc/security-guide/ch066_case-studies-compliance.xml:31(para) msgid ""At the end of the audit period Bob has arranged for an external audit team to review in-scope security controls at randomly sampled points of time over a 6 month period. The audit team provides Bob with an official report for SOC 1 and SOC 2, and separately for ISO 27001/2. As Bob has been diligent in ensuring security controls are in place for his OpenStack public cloud, there are no additional gaps exposed on the report. Bob can now provide these official reports to his customers under NDA, and advertise that he is SOC 1, SOC 2 and ISO 27001/2 compliant on his website."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:3(title) msgid ""API Endpoint Configuration Recommendations"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:4(para) msgid ""This chapter provides recommendations for improving the security of both public and internal endpoints."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:6(title) msgid ""Internal API Communications"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:7(para) msgid ""OpenStack provides both public facing and private API endpoints. By default, OpenStack components use the publicly defined endpoints. The recommendation is to configure these components to use the API endpoint within the proper security domain."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:8(para) msgid ""Services select their respective API endpoints based on the OpenStack service catalog. The issue here is these services may not obey the listed public or internal API end point values. This can lead to internal management traffic being routed to external API endpoints."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:10(title) msgid ""Configure Internal URLs in Identity Service Catalog"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:11(para) msgid ""The Identity Service catalog should be aware of your internal URLs. While this feature is not utilized by default, it may be leveraged through configuration. Additionally, it should be forward-compatible with expectant changes once this behavior becomes the default."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:12(para) msgid ""To register an internal URL for an endpoint:"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:22(title) msgid ""Configure Applications for Internal URLs"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:23(para) msgid ""Some services can be forced to use specific API endpoints. Therefore, it is recommended that each OpenStack service communicating to the API of another service must be explicitly configured to access the proper internal API endpoint."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:24(para) msgid ""Each project may present an inconsistent way of defining target API endpoints. Future releases of OpenStack seek to resolve these inconsistencies through consistent use of the Identity Service catalog."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:26(title) msgid ""Configuration Example #1: Nova"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:37(title) msgid ""Configuration Example #2: Cinder"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:44(title) msgid ""Paste and Middleware"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:45(para) msgid ""Most API endpoints and other HTTP services in OpenStack utilize the Python Paste Deploy library. This is important to understand from a security perspective as it allows for manipulation of the request filter pipeline through the application's configuration. Each element in this chain is referred to as <emphasis>middleware</emphasis>. Changing the order of filters in the pipeline or adding additional middleware may have unpredictable security impact."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:46(para) msgid ""It is not uncommon that implementors will choose to add additional middleware to extend OpenStack's base functionality. We recommend implementors make careful consideration of the potential exposure introduced by the addition of non-standard software components to their HTTP request pipeline."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:47(para) msgid ""Additional information on Paste Deploy may be found at <link href=\""http://pythonpaste.org/deploy/\"">http://pythonpaste.org/deploy/</link>."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:51(title) msgid ""API Endpoint Process Isolation &amp; Policy"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:52(para) msgid ""API endpoint processes, especially those that reside within the public security domain should be isolated as much as possible. Where deployments allow, API endpoints should be deployed on separate hosts for increased isolation."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:54(title) ./doc/security-guide/ch038_transport-security.xml:119(title) msgid ""Namespaces"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:55(para) msgid ""Many operating systems now provide compartmentalization support. Linux supports namespaces to assign processes into independent domains. System compartmentalization is covered in more detail in other parts of the guide."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:58(title) ./doc/security-guide/ch038_transport-security.xml:124(title) msgid ""Network Policy"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:59(para) msgid ""API endpoints typically bridge multiple security domains, as such particular attention should be paid to the compartmentalization of the API processes. See the <emphasis>Security Domain Bridging</emphasis> section for additional information in this area."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:60(para) msgid ""With careful modeling, network ACLs and IDS technologies can be use to enforce explicit point to point communication between network services. As critical cross domain service, this type of explicit enforcement works well for OpenStack's message queue service."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:61(para) msgid ""Policy enforcement can be implemented through the configuration of services, host-based firewalls (such as IPTables), local policy (SELinux or AppArmor), and optionally enforced through global network policy."" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:64(title) ./doc/security-guide/ch038_transport-security.xml:129(title) ./doc/security-guide/ch052_devices.xml:90(title) msgid ""Mandatory Access Controls"" msgstr """" #: ./doc/security-guide/ch021_paste-and-middleware.xml:65(para) msgid ""API endpoint processes should be isolated from each other and other processes on a machine. The configuration for those processes should be restricted to those processes not only by Discretionary Access Controls, but through Mandatory Access Controls. The goal of these enhanced access control is to aid in the containment and escalation of API endpoint security breaches. With mandatory access controls, such breaches will severely limit access to resources and provide earlier alerting on such events."" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:3(title) msgid ""Database Backend Considerations"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:4(para) msgid ""The choice of database server is an important consideration in the security of an OpenStack deployment. While security considerations are not the only basis on which a database server must be chosen, security considerations are the only ones within the scope of this book. In practice, OpenStack only supports two database types: PostgreSQL and MySQL."" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:5(para) msgid ""PostgreSQL has a number of desirable security features such as Kerberos authentication, object-level security, and encryption support. The PostgreSQL community has done well to provide solid guidance, documentation, and tooling to promote positive security practices."" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:6(para) msgid ""MySQL has a large community, wide-spread adoption, and provides high availability options. MySQL also has the ability to provide enhanced client authentication by way of plug-in authentication mechanisms. Forked distributions in the MySQL community provide many options for consideration. It is important to choose a specific implementation of MySQL based on a thorough evaluation of the security posture and the level of support provided for the given distribution."" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:8(title) msgid ""Security References for Database Backends"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:9(para) msgid ""Those deploying MySQL or PostgreSQL are advised to refer to existing security guidance. Some references are listed below:"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:10(para) msgid ""MySQL:"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:12(link) msgid ""OWASP MySQL Hardening"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:15(link) msgid ""MySQL Pluggable Authentication"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:18(link) msgid ""Security in MySQL"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:21(para) msgid ""PostgreSQL:"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:23(link) msgid ""OWASP PostgreSQL Hardening"" msgstr """" #: ./doc/security-guide/ch041_database-backend-considerations.xml:26(link) msgid ""Total security in a PostgreSQL database"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:3(title) msgid ""Management Interfaces"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:4(para) msgid ""It is necessary for administrators to perform command and control over the cloud for various operational functions. It is important these command and control facilities are understood and secured."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:5(para) msgid ""OpenStack provides several management interfaces for operators and tenants:"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:7(para) msgid ""OpenStack Dashboard (Horizon)"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:10(para) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:69(title) msgid ""OpenStack API"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:13(para) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:93(title) msgid ""Secure Shell (SSH)"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:16(para) msgid ""OpenStack Management Utilities (nova-manage, glance-manage, etc.)"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:19(para) msgid ""Out-of-Band Management Interfaces (IPMI, etc.)"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:24(para) msgid ""The OpenStack Dashboard (Horizon) provides administrators and tenants a web-based graphical interface to provision and access cloud-based resources. The dashboard communicates with the back-end services via calls to the OpenStack API (discussed above)."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:26(title) ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:72(title) ./doc/security-guide/ch026_compute.xml:13(title) ./doc/security-guide/ch026_compute.xml:40(title) msgid ""Capabilities"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:28(para) msgid ""As a cloud administrator, the dashboard provides an overall view of the size and state of your cloud. You can create users and tenants/projects, assign users to tenant/projects and set limits on the resources available for them."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:31(para) msgid ""The dashboard provides tenant-users a self-service portal to provision their own resources within the limits set by administrators."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:34(para) msgid ""The dashboard provides GUI support for routers and load-balancers. For example, the dashboard now implements all of the main Networking features."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:37(para) msgid ""It is an extensible <glossterm>Django</glossterm> web application that allows easy plug-in of third-party products and services, such as billing, monitoring, and additional management tools."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:40(para) msgid ""The dashboard can also be branded for service providers and other commercial vendors."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:47(para) msgid ""The dashboard requires cookies and JavaScript to be enabled in the web browser."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:50(para) msgid ""The web server that hosts dashboard should be configured for SSL to ensure data is encrypted."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:53(para) msgid ""Both the Horizon web service and the OpenStack API it uses to communicate with the back-end are susceptible to web attack vectors such as denial of service and must be monitored."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:56(para) msgid ""It is now possible (though there are numerous deployment/security implications) to upload an image file directly from a users hard disk to Glance through Horizon. For multi-GB images it is still strongly recommended that the upload be done using the Glance CLI"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:59(para) msgid ""Create and manage security groups through dashboard. The security groups allows L3-L4 packet filtering for security policies to protect virtual machines"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:65(citetitle) msgid ""Grizzly Release Notes"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:70(para) msgid ""The OpenStack API is a RESTful web service endpoint to access, provision and automate cloud-based resources. Operators and users typically access the API through command-line utilities (i.e. Nova, Glance, etc.), language-specific libraries, or third-party tools."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:74(para) msgid ""To the cloud administrator the API provides an overall view of the size and state of the cloud deployment and allows the creation of users, tenants/projects, assigning users to tenants/projects and specifying resource quotas on a per tenant/project basis."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:77(para) msgid ""The API provides a tenant interface for provisioning, managing, and accessing their resources."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:84(para) msgid ""The API service should be configured for SSL to ensure data is encrypted."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:87(para) msgid ""As a web service, OpenStack API is susceptible to familiar web site attack vectors such as denial of service attacks."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:94(para) msgid ""It has become industry practice to use secure shell (SSH) access for the management of Linux and Unix systems. SSH uses secure cryptographic primitives for communication. With the scope and importance of SSH in typical OpenStack deployments, it is important to understand best practices for deploying SSH."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:96(title) msgid ""Host Key Fingerprints"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:97(para) msgid ""Often overlooked is the need for key management for SSH hosts. As most or all hosts in an OpenStack deployment will provide an SSH service, it is important to have confidence in connections to these hosts. It cannot be understated that failing to provide a reasonably secure and accessible method to verify SSH host key fingerprints is ripe for abuse and exploitation."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:98(para) msgid ""All SSH daemons have private host keys and, upon connection, offer a host key fingerprint. This host key fingerprint is the hash of an unsigned public key. It is important these host key fingerprints are known in advance of making SSH connections to those hosts. Verification of host key fingerprints is instrumental in detecting man-in-the-middle attacks."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:99(para) msgid ""Typically, when an SSH daemon is installed, host keys will be generated. It is necessary that the hosts have sufficient entropy during host key generation. Insufficient entropy during host key generation can result in the possibility to eavesdrop on SSH sessions."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:100(para) msgid ""Once the SSH host key is generated, the host key fingerprint should be stored in a secure and queriable location. One particularly convenient solution is DNS using SSHFP resource records as defined in RFC-4255. For this to be secure, it is necessary that DNSSEC be deployed."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:104(title) msgid ""Management Utilities"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:105(para) msgid ""The OpenStack Management Utilities are open-source Python command-line clients that make API calls. There is a client for each OpenStack service (nova, glance, etc.). In addition to the standard CLI client, most of the services have a management command line which makes direct calls to the database. These dedicated management utilities are slowly being deprecated."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:115(para) msgid ""The dedicated management utilities (*-manage) in some cases use the direct database connection."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:118(para) msgid ""Ensure that the .rc file which has your credential information is secured."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:124(para) msgid ""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://docs.openstack.org/user-guide/content/section_cli_overview.html\"">command line clients overview</link>"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:125(para) msgid ""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://docs.openstack.org/user-guide/content/cli_openrc.html\"">Download and source the OpenStack RC file</link>"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:129(title) msgid ""Out-of-Band Management Interface"" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:130(para) msgid ""OpenStack management relies on out-of-band management interfaces such as the IPMI protocol to access into nodes running OpenStack components. IPMI is a very popular specification to remotely manage, diagnose and reboot servers whether the operating system is running or the system has crashed."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:134(para) msgid ""Use strong passwords and safeguard them, or use client-side SSL authentication."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:137(para) msgid ""Ensure that the network interfaces are on their own private(management or a separate) network. Segregate management domains with firewalls or other network gear."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:140(para) msgid ""If you use a web interface to interact with the <glossterm>BMC</glossterm>/IPMI, always use the SSL interface, such as https or port 443. This SSL interface should <emphasis role=\""bold\"">NOT</emphasis> use self-signed certificates, as is often default, but should have trusted certificates using the correctly defined fully qualified domain names (FQDNs)."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:149(para) msgid ""Monitor the traffic on the management network. The anomalies might be easier to track than on the busier compute nodes."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:154(para) msgid ""Out of band management interfaces also often include graphical machine console access. It is often possible, although not necessarily default, that these interfaces are encrypted. Consult with your system software documentation for encrypting these interfaces."" msgstr """" #: ./doc/security-guide/ch014_best-practices-for-operator-mode-access.xml:158(link) msgid ""Hacking servers that are turned off"" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:3(title) msgid ""Case Studies: Identity Management"" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address configuration of OpenStack core services. These include the Keystone Identity service, Dashboard, and Compute services. Alice will be concerned with integration into the existing government directory services, while Bob will need to provide access to the public."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:7(para) msgid ""Alice's enterprise has a well-established directory service with two-factor authentication for all users. She configures Keystone to support an external authentication service supporting authentication with government-issued access cards. She also uses an external LDAP server to provide role information for the users that is integrated with the access control policy. Due to FedRAMP compliance requirements, Alice implements two-factor authentication on the Management network for all administrator access."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:8(para) msgid ""Alice also deploys the Dashboard to manage many aspects of the cloud. She deploys the Dashboard with HSTS to ensure that only HTTPS is used. The Dashboard resides within an internal subdomain of the private network domain name system."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:9(para) msgid ""Alice decides to use SPICE instead of VNC for the virtual console. She wants to take advantage of the emerging capabilities in SPICE."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:13(para) msgid ""Bob must support authentication by the general public, so he elects to use provide for username / password authentication. He has concerns about brute force attacks attempting to crack user passwords, so he also uses an external authentication extension that throttles the number of failed login attempts. Bob's Management network is separate from the other networks within his cloud, but can be reached from his corporate network via ssh. As recommended earlier, Bob requires administrators to use two-factor authentication on the Management network to reduce the risk from compromised administrator passwords."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:14(para) msgid ""Bob also deploys the Dashboard to manage many aspects of the cloud. He deploys the Dashboard with HSTS to ensure that only HTTPS is used. He has ensured that the Dashboard is deployed on a second-level domain due to the limitations of the same-origin policy. He also disables HORIZON_IMAGES_ALLOW_UPLOAD to prevent resource exhaustion."" msgstr """" #: ./doc/security-guide/ch028_case-studies-identity-management.xml:15(para) msgid ""Bob decides to use VNC for his virtual console for its maturity and security features."" msgstr """" #: ./doc/security-guide/ch037_risks.xml:3(title) msgid ""Message Queuing Architecture"" msgstr """" #: ./doc/security-guide/ch037_risks.xml:4(para) msgid ""Inter-process communication within OpenStack is facilitated via message queueing services. Today, three messaging service backends are supported:"" msgstr """" #: ./doc/security-guide/ch037_risks.xml:6(para) msgid ""RabbitMQ"" msgstr """" #: ./doc/security-guide/ch037_risks.xml:9(para) msgid ""Qpid"" msgstr """" #: ./doc/security-guide/ch037_risks.xml:12(para) msgid ""ZeroMQ"" msgstr """" #: ./doc/security-guide/ch037_risks.xml:15(para) msgid ""Both RabbitMQ and Qpid are Advanced Message Queuing Protocol (AMQP) frameworks which provide message queues for peer-to-peer communication. Queue implementations are typically deployed as centralized or decentralized pool of queue servers. ZeroMQ differs by communicating directly using TCP sockets between peers."" msgstr """" #: ./doc/security-guide/ch037_risks.xml:16(para) msgid ""Message queues effectively facilitate command and control functions across OpenStack deployments. Once access to the queue is permitted no further authorization checks are performed. Services accessible via the queue do validate the contexts and tokens within the actual message payload. However, awareness of the token's expiration value should be noted as these tokens are potentially replayable and may provide authorization for other services within the infrastructure."" msgstr """" #: ./doc/security-guide/ch037_risks.xml:17(para) msgid ""OpenStack does not support message-level confidence (i.e., message signing). Because of this, the message transport itself must be secured and authentication to the queue server must be performed. For HA configurations, queue to queue authentication and encryption should to be performed as well."" msgstr """" #: ./doc/security-guide/ch037_risks.xml:18(para) msgid ""With ZeroMQ messaging, IPC sockets are used on individual machines. These sockets may be vulnerable to attack for local message injection and snooping unless secured by an operator."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:3(title) ./doc/security-guide/ch004_book-introduction.xml:122(title) msgid ""Compute"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:4(para) msgid ""The Compute Service (Nova) is one of the more complex OpenStack services. It runs in many locations throughout the cloud and interacts with a variety of internal services. For this reason, most of our recommendations regarding best practices for Compute Service configuration are distributed throughout this book. We provide specific details in the sections on Management, API Endpoints, Messaging, and Database."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:6(title) msgid ""Virtual Console Selection"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:7(para) msgid ""One decision a cloud architect will need to make regarding Compute Service configuration is whether to use VNC or SPICE. Below we provide some details on the differences between these options."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:9(title) msgid ""Virtual Network Computer (VNC)"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:10(para) msgid ""OpenStack can be configured to provide remote desktop console access to instances for tenants and/or administrators using the Virtual Network Computer (VNC) protocol. "" msgstr """" #: ./doc/security-guide/ch026_compute.xml:15(para) msgid ""The OpenStack Dashboard (Horizon) can provide a VNC console for instances directly on the web page using the HTML5 noVNC client. This requires the <systemitem class=\""service\"">nova-novncproxy</systemitem> service to bridge from the public network to the management network."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:18(para) msgid ""The nova command line utility can return a URL for the VNC console for access by the nova Java VNC client. This requires the nova-xvpvncproxy service to bridge from the public network to the management network."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:25(para) msgid ""The <systemitem class=\""service\"">nova-novncproxy</systemitem>and nova-xvpvncproxy services by default open public-facing ports that are token authenticated."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:28(para) msgid ""By default, the remote desktop traffic is not encrypted. Havana is expected to have VNC connections secured by Kerberos."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:34(link) msgid ""Secure Connections to VNC ports"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:37(title) msgid ""Simple Protocol for Independent Computing Environments (SPICE)"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:38(para) msgid ""As an alternative to VNC, OpenStack provides remote desktop access to guest virtual machines using the Simple Protocol for Independent Computing Environments (SPICE) protocol."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:42(para) msgid ""SPICE is supported by the OpenStack Dashboard (Horizon) directly on the instance web page. This requires the nova-spicehtml5proxy service."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:45(para) msgid ""The nova command line utility can return a URL for SPICE console for access by a SPICE-html client."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:50(title) msgid ""Limitations"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:52(para) msgid ""Although SPICE has many advantages over VNC, the spice-html5 browser integration currently doesn't really allow admins to take advantage of any of the benefits. To take advantage of SPICE features like multi-monitor, USB pass through, etc. admins are recommended to use a standalone SPICE client within the Management Network."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:59(para) msgid ""The nova-spicehtml5proxy service by default opens public-facing ports that are token authenticated."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:62(para) msgid ""The functionality and integration are still evolving. We will access the features in the next release and make recommendations."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:65(para) msgid ""As is the case for VNC, at this time we recommend using SPICE from the management network in addition to limiting use to few individuals."" msgstr """" #: ./doc/security-guide/ch026_compute.xml:71(link) msgid ""SPICE Console"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:72(link) msgid ""Red Hat bug 913607"" msgstr """" #: ./doc/security-guide/ch026_compute.xml:73(link) msgid ""SPICE support in RDO Grizzly"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch013_node-bootstrapping.xml:60(None) ./doc/security-guide/ch013_node-bootstrapping.xml:65(None) msgid ""@@image: 'static/node-provisioning-pxe.png'; md5=51b76c5aced74f935490b37ba921dc43"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:8(title) msgid ""Integrity Life-cycle"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:9(para) msgid ""We define integrity life cycle as a deliberate process that provides assurance that we are always running the expected software with the expected configurations throughout the cloud. This process begins with secure bootstrapping and is maintained through configuration management and security monitoring. This chapter provides recommendations on how to approach the integrity life-cycle process."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:17(title) msgid ""Secure Bootstrapping"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:18(para) msgid ""Nodes in the cloud -- including compute, storage, network, service, and hybrid nodes -- should have an automated provisioning process. This ensures that nodes are provisioned consistently and correctly. This also facilitates security patching, upgrading, bug fixing, and other critical changes. Since this process installs new software that runs at the highest privilege levels in the cloud, it is important to verify that the correct software is installed. This includes the earliest stages of the boot process."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:27(para) msgid ""There are a variety of technologies that enable verification of these early boot stages. These typically require hardware support such as the trusted platform module (TPM), Intel Trusted Execution Technology (TXT), dynamic root of trust measurement (DRTM), and Unified Extensible Firmware Interface (UEFI) secure boot. In this book, we will refer to all of these collectively as <emphasis>secure boot technologies</emphasis>. We recommend using secure boot, while acknowledging that many of the pieces necessary to deploy this require advanced technical skills in order to customize the tools for each environment. Utilizing secure boot will require deeper integration and customization than many of the other recommendations in this guide. TPM technology, while common in most business class laptops and desktops for several years, and is now becoming available in servers together with supporting BIOS. Proper planning is essential to a successful secure boot deployment."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:43(para) msgid ""A complete tutorial on secure boot deployment is beyond the scope of this book. Instead, here we provide a framework for how to integrate secure boot technologies with the typical node provisioning process. For additional details, cloud architects should refer to the related specifications and software configuration manuals."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:50(title) msgid ""Node Provisioning"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:51(para) msgid ""Nodes should use Preboot eXecution Environment (PXE) for provisioning. This significantly reduces the effort required for redeploying nodes. The typical process involves the node receiving various boot stages (i.e., progressively more complex software to execute) from a server."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:68(para) msgid ""We recommend using a separate, isolated network within the management security domain for provisioning. This network will handle all PXE traffic, along with the subsequent boot stage downloads depicted above. Note that the node boot process begins with two insecure operations: DHCP and TFTP. Then the boot process downloads over SSL the remaining information required to deploy the node. This information might include an initramfs and a kernel. This concludes by downloading the remaining information needed to deploy the node. This may be an operating system installer, a basic install managed by <link href=\""http://www.opscode.com/chef/\"">Chef</link> or <link href=\""https://puppetlabs.com/\"">Puppet</link>, or even a complete file system image that is written directly to disk."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:82(para) msgid ""While utilizing SSL during the PXE boot process is somewhat more challenging, common PXE firmware projects, such as iPXE, provide this support. Typically this involves building the PXE firmware with knowledge of the allowed SSL certificate chain(s) so that it can properly validate the server certificate. This raises the bar for an attacker by limiting the number of insecure, plain text network operations."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:92(title) msgid ""Verified Boot"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:93(para) msgid ""In general, there are two different strategies for verifying the boot process. Traditional <emphasis>secure boot</emphasis> will validate the code run at each step in the process, and stop the boot if code is incorrect. <emphasis>Boot attestation</emphasis> will record which code is run at each step, and provide this information to another machine as proof that the boot process completed as expected. In both cases, the first step is to measure each piece of code before it is run. In this context, a measurement is effectively a SHA-1 hash of the code, taken before it is executed. The hash is stored in a platform configuration register (PCR) in the TPM."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:105(para) msgid ""Note: SHA-1 is used here because this is what the TPM chips support."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:107(para) msgid ""Each TPM has at least 24 PCRs. The TCG Generic Server Specification, v1.0, March 2005, defines the PCR assignments for boot-time integrity measurements. The table below shows a typical PCR configuration. The context indicates if the values are determined based on the node hardware (firmware) or the software provisioned onto the node. Some values are influenced by firmware versions, disk sizes, and other low-level information. Therefore, it is important to have good practices in place around configuration management to ensure that each system deployed is configured exactly as desired."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:127(emphasis) msgid ""Register"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:128(emphasis) msgid ""What Is Measured"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:131(emphasis) msgid ""Context"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:134(para) msgid ""PCR-00"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:135(para) msgid ""Core Root of Trust Measurement (CRTM), Bios code, Host platform extensions"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:137(para) ./doc/security-guide/ch013_node-bootstrapping.xml:142(para) ./doc/security-guide/ch013_node-bootstrapping.xml:147(para) msgid ""Hardware"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:140(para) msgid ""PCR-01"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:141(para) msgid ""Host Platform Configuration"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:145(para) msgid ""PCR-02"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:146(para) msgid ""Option ROM Code "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:150(para) msgid ""PCR-03"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:151(para) msgid ""Option ROM Configuration and Data "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:152(para) msgid ""Hardware "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:155(para) msgid ""PCR-04"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:156(para) msgid ""Initial Program Loader (IPL) Code. For example, master boot record."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:158(para) ./doc/security-guide/ch013_node-bootstrapping.xml:163(para) ./doc/security-guide/ch013_node-bootstrapping.xml:168(para) ./doc/security-guide/ch013_node-bootstrapping.xml:173(para) ./doc/security-guide/ch013_node-bootstrapping.xml:179(para) ./doc/security-guide/ch013_node-bootstrapping.xml:184(para) ./doc/security-guide/ch013_node-bootstrapping.xml:189(para) msgid ""Software "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:161(para) msgid ""PCR-05"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:162(para) msgid ""IPL Code Configuration and Data "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:166(para) msgid ""PCR-06"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:167(para) msgid ""State Transition and Wake Events "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:171(para) msgid ""PCR-07"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:172(para) msgid ""Host Platform Manufacturer Control "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:176(para) msgid ""PCR-08"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:177(para) msgid ""Platform specific, often Kernel, Kernel Extensions, and Drivers"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:182(para) msgid ""PCR-09"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:183(para) msgid ""Platform specific, often Initramfs"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:187(para) msgid ""PCR-10 to PCR-23"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:188(para) msgid ""Platform specific "" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:194(para) msgid ""At the time of this writing, very few clouds are using secure boot technologies in a production environment. As a result, these technologies are still somewhat immature. We recommend planning carefully in terms of hardware selection. For example, ensure that you have a TPM and Intel TXT support. Then verify how the node hardware vendor populates the PCR values. For example, which values will be available for validation. Typically the PCR values listed under the software context in the table above are the ones that a cloud architect has direct control over. But even these may change as the software in the cloud is upgraded. Configuration management should be linked into the PCR policy engine to ensure that the validation is always up to date."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:207(para) msgid ""Each manufacturer must provide the BIOS and firmware code for their servers. Different servers, hypervisors, and operating systems will choose to populate different PCRs. In most real world deployments, it will be impossible to validate every PCR against a known good quantity (\""golden measurement\""). Experience has shown that, even within a single vendor's product line, the measurement process for a given PCR may not be consistent. We recommend establishing a baseline for each server and monitoring the PCR values for unexpected changes. Third-party software may be available to assist in the TPM provisioning and monitoring process, depending upon your chosen hypervisor solution."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:219(para) msgid ""The initial program loader (IPL) code will most likely be the PXE firmware, assuming the node deployment strategy outlined above. Therefore, the secure boot or boot attestation process can measure all of the early stage boot code, such as, bios, firmware, and the like, the PXE firmware, and the node kernel. Ensuring that each node has the correct versions of these pieces installed provides a solid foundation on which to build the rest of the node software stack."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:227(para) msgid ""Depending on the strategy selected, in the event of a failure the node will either fail to boot or it can report the failure back to another entity in the cloud. For secure boot, the node will fail to boot and a provisioning service within the management security domain must recognize this and log the event. For boot attestation, the node will already be running when the failure is detected. In this case the node should be immediately quarantined by disabling its network access. Then the event should be analyzed for the root cause. In either case, policy should dictate how to proceed after a failure. A cloud may automatically attempt to re-provision a node a certain number of times. Or it may immediately notify a cloud administrator to investigate the problem. The right policy here will be deployment and failure mode specific."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:243(title) msgid ""Node Hardening"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:244(para) msgid ""At this point we know that the node has booted with the correct kernel and underlying components. There are many paths for hardening a given operating system deployment. The specifics on these steps are outside of the scope of this book. We recommend following the guidance from a hardening guide specific to your operating system. For example, the <link href=\""http://iase.disa.mil/stigs/\"">security technical implementation guides</link> (STIG) and the <link href=\""http://www.nsa.gov/ia/mitigation_guidance/security_configuration_guides/\"">NSA guides</link> are useful starting places."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:254(para) msgid ""The nature of the nodes makes additional hardening possible. We recommend the following additional steps for production nodes:"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:259(para) msgid ""Use a read-only file system where possible. Ensure that writeable file systems do not permit execution. This can be handled through the mount options provided in <literal>/etc/fstab</literal>."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:265(para) msgid ""Use a mandatory access control policy to contain the instances, the node services, and any other critical processes and data on the node. See the discussions on sVirt / SELinux and AppArmor below."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:271(para) msgid ""Remove any unnecessary software packages. This should result in a very stripped down installation because a compute node has a relatively small number of dependencies."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:277(para) msgid ""Finally, the node kernel should have a mechanism to validate that the rest of the node starts in a known good state. This provides the necessary link from the boot validation process to validating the entire system. The steps for doing this will be deployment specific. As an example, a kernel module could verify a hash over the blocks comprising the file system before mounting it using <link href=\""https://code.google.com/p/cryptsetup/wiki/DMVerity\"">dm-verity</link>."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:289(title) msgid ""Runtime Verification"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:290(para) msgid ""Once the node is running, we need to ensure that it remains in a good state over time. Broadly speaking, this includes both configuration management and security monitoring. The goals for each of these areas are different. By checking both, we achieve higher assurance that the system is operating as desired. We discuss configuration management in the management section, and security monitoring below."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:298(title) msgid ""Intrusion Detection System"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:299(para) msgid ""Host-based intrusion detection tools are also useful for automated validation of the cloud internals. There are a wide variety of host-based intrusion detection tools available. Some are open source projects that are freely available, while others are commercial. Typically these tools analyze data from a variety of sources and produce security alerts based on rule sets and/or training. Typical capabilities include log analysis, file integrity checking, policy monitoring, and rootkit detection. More advanced -- often custom -- tools can validate that in-memory process images match the on-disk executable and validate the execution state of a running process."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:311(para) msgid ""One critical policy decision for a cloud architect is what to do with the output from a security monitoring tool. There are effectively two options. The first is to alert a human to investigate and/or take corrective action. This could be done by including the security alert in a log or events feed for cloud administrators. The second option is to have the cloud take some form of remedial action automatically, in addition to logging the event. Remedial actions could include anything from re-installing a node to performing a minor service configuration. However, automated remedial action can be challenging due to the possibility of false positives."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:322(para) msgid ""False positives occur when the security monitoring tool produces a security alert for a benign event. Due to the nature of security monitoring tools, false positives will most certainly occur from time to time. Typically a cloud administrator can tune security monitoring tools to reduce the false positives, but this may also reduce the overall detection rate at the same time. These classic trade-offs must be understood and accounted for when setting up a security monitoring system in the cloud."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:331(para) msgid ""The selection and configuration of a host-based intrusion detection tool is highly deployment specific. We recommend starting by exploring the following open source projects which implement a variety of host-based intrusion detection and file monitoring features."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:339(link) msgid ""OSSEC"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:343(link) msgid ""Samhain"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:348(link) msgid ""Tripwire"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:352(link) msgid ""AIDE"" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:355(para) msgid ""Network intrusion detection tools complement the host-based tools. OpenStack doesn't have a specific network IDS built-in, but OpenStack's networking component, Neutron, provides a plugin mechanism to enable different technologies via the Neutron API. This plugin architecture will allow tenants to develop API extensions to insert and configure their own advanced networking services like a firewall, an intrusion detection system, or a VPN between the VMs."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:363(para) msgid ""Similar to host-based tools, the selection and configuration of a network-based intrusion detection tool is deployment specific. <link href=\""http://www.snort.org/\"">Snort</link> is the leading open source networking intrusion detection tool, and a good starting place to learn more."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:369(para) msgid ""There are a few important security considerations for network and host-based intrusion detection systems."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:373(para) msgid ""It is important to consider the placement of the Network IDS on the cloud (for example, adding it to the network boundary and/or around sensitive networks). The placement depends on your network environment but make sure to monitor the impact the IDS may have on your services depending on where you choose to add it. Encrypted traffic, such as SSL, cannot generally be inspected for content by a Network IDS. However, the Network IDS may still provide some benefit in identifying anomalous unencrypted traffic on the network."" msgstr """" #: ./doc/security-guide/ch013_node-bootstrapping.xml:385(para) msgid ""In some deployments it may be required to add host-based IDS on sensitive components on security domain bridges. A host-based IDS may detect anomalous activity by compromised or unauthorized processes on the component. The IDS should transmit alert and log information on the Management network."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:3(title) msgid ""Messaging Security"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:4(para) msgid ""This chapter discusses security hardening approaches for the three most common message queuing solutions use in OpenStack: RabbitMQ, Qpid, and ZeroMQ."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:6(title) msgid ""Messaging Transport Security"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:7(para) msgid ""AMQP based solutions (Qpid and RabbitMQ) support transport-level security using SSL. ZeroMQ messaging does not natively support SSL, but transport-level security is possible using labelled IPSec or CIPSO network labels."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:8(para) msgid ""We highly recommend enabling transport-level cryptography for your message queue. Using SSL for the messaging client connections provides protection of the communications from tampering and eavesdropping in-transit to the messaging server. Below is guidance on how SSL is typically configured for the two popular messaging servers Qpid and RabbitMQ. When configuring the trusted certificate authority (CA) bundle that your messaging server uses to verify client connections, it is recommended that this be limited to only the CA used for your nodes, preferably an internally managed CA. The bundle of trusted CAs will determine which client certificates will be authorized and pass the client-server verification step of the setting up the SSL connection. Note, when installing the certificate and key files, ensure that the file permissions are restricted, for example chmod 0600, and the ownership is restricted to the messaging server daemon user to prevent unauthorized access by other processes and users on the messaging server."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:10(title) msgid ""RabbitMQ Server SSL Configuration"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:11(para) msgid ""The following lines should be added to the system-wide RabbitMQ configuration file, typically /etc/rabbitmq/rabbitmq.config:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:24(para) msgid ""Note, the 'tcp_listeners' option is set to '[]' to prevent it from listening an on non-SSL port. 'ssl_listeners' option should be restricted to only listen on the management network for the services."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:25(para) msgid ""For more information on RabbitMQ SSL configuration see:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:27(link) msgid ""RabbitMQ Configuration"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:30(link) msgid ""RabbitMQ SSL"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:35(title) msgid ""Qpid Server SSL Configuration"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:36(para) msgid ""The Apache Foundation has a messaging security guide for Qpid. See:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:38(link) msgid ""Apache Qpid SSL"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:44(title) msgid ""Queue Authentication and Access Control"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:45(para) msgid ""RabbitMQ and Qpid offer authentication and access control mechanisms for controlling access to queues. ZeroMQ offers no such mechanisms."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:46(para) msgid ""Simple Authentication and Security Layer (SASL) is a framework for authentication and data security in Internet protocols. Both RabbitMQ and Qpid offer SASL and other pluggable authentication mechanisms beyond simple usernames and passwords that allow for increased authentication security. While RabbitMQ supports SASL, support in OpenStack does not currently allow for requesting a specific SASL authentication mechanism. RabbitMQ support in OpenStack allows for either username and password authentication over an unencrypted connection or username and password in conjunction with X.509 client certificates to establish the secure SSL connection."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:47(para) msgid ""We recommend configuring X.509 client certificates on all the OpenStack service nodes for client connections to the messaging queue and where possible (currently only Qpid) perform authentication with X.509 client certificates. When using usernames and passwords, accounts should be created per-service and node for finer grained auditability of access to the queue."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:48(para) msgid ""The SSL libraries in use by these queuing servers should also be considered prior to deployment. Qpid uses Mozilla's NSS library, whereas RabbitMQ uses Erlang's SSL module which uses OpenSSL."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:50(title) msgid ""Authentication Configuration Example - RabbitMQ"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:51(para) msgid ""On the RabbitMQ server, delete the default 'guest' user:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:54(para) msgid ""On the RabbitMQ server, for each OpenStack service or node that communicates with the message queue set up user accounts and privileges:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:58(para) msgid ""For additional configuration information see:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:60(link) msgid ""RabbitMQ Access Control"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:63(link) msgid ""RabbitMQ Authentication"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:66(link) msgid ""RabbitMQ Plugins"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:69(link) msgid ""RabbitMQ SASL External Auth"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:74(title) msgid ""OpenStack Service Configuration - RabbitMQ"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:86(para) msgid ""NOTE: A bug exists in the current version of OpenStack Grizzly where if 'kombu_ssl_version' is currently specified in the configuration file for any of the OpenStack services it will cause the following python traceback error: 'TypeError: an integer is required'. The current workaround is to remove 'kombu_ssl_version' from the configuration file. Refer to <link href=\""https://bugs.launchpad.net/oslo/+bug/1195431\"">bug report 1195431</link> for current status."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:89(title) msgid ""Authentication Configuration Example - Qpid"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:90(para) msgid ""For configuration information see:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:92(link) msgid ""Apache Qpid Authentication"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:95(link) msgid ""Apache Qpid Authorization"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:100(title) msgid ""OpenStack Service Configuration - Qpid"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:109(para) msgid ""Optionally, if using SASL with Qpid specify the SASL mechanisms in use by adding:"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:115(title) msgid ""Message Queue Process Isolation &amp; Policy"" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:116(para) msgid ""Each project provides a number of services which send and consume messages. Each binary which sends a message is expected to consume messages, if only replies, from the queue."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:117(para) msgid ""Message queue service processes should be isolated from each other and other processes on a machine."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:120(para) msgid ""Network namespaces are highly recommended for all services running on OpenStack Compute Hypervisors. This will help prevent against the bridging of network traffic between VM guests and the management network."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:121(para) msgid ""When using ZeroMQ messaging, each host must run at least one ZeroMQ message receiver to receive messages from the network and forward messages to local processes via IPC. It is possible and advisable to run an independent message receiver per project within an IPC namespace, along with other services within the same project."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:125(para) msgid ""Queue servers should only accept connections from the management network. This applies to all implementations. This should be implemented through configuration of services and optionally enforced through global network policy."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:126(para) msgid ""When using ZeroMQ messaging, each project should run a separate ZeroMQ receiver process on a port dedicated to services belonging to that project. This is equivalent to the AMQP concept of control exchanges."" msgstr """" #: ./doc/security-guide/ch038_transport-security.xml:130(para) msgid ""The configuration for these processes should be restricted to those processes, not only by Directory Access Controls, but through Mandatory Access Controls. The goal of such restrictions is to prevent isolation from other processes running on the same machine(s)."" msgstr """" #: ./doc/security-guide/ch044_case-studies-database.xml:3(title) msgid ""Case Studies: Database"" msgstr """" #: ./doc/security-guide/ch044_case-studies-database.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address database selection and configuration for their respective private and public clouds."" msgstr """" #: ./doc/security-guide/ch044_case-studies-database.xml:7(para) msgid ""Alice's organization has high availability concerns, so she has elected to use MySQL for the database. She further places the database on the Management network and uses SSL with mutual authentication among the services to ensure secure access. Given there will be no external access of the database, she uses certificates signed with the organization's self-signed root certificate on the database and its access endpoints. Alice creates separate user accounts for each database user, and configures the database to use both passwords and X.509 certificates for authentication. She elects not to use the <systemitem class=\""service\"">nova-conductor</systemitem> sub-service due to the desire for fine-grained access control policies and audit support."" msgstr """" #: ./doc/security-guide/ch044_case-studies-database.xml:11(para) msgid ""Bob is concerned about strong separation of his tenants' data, so he has elected to use the Postgres database , known for its stronger security features. The database resides on the Management network and uses SSL with mutual authentication with the services. Since the database is on the Management network, the database uses certificates signed with the company's self-signed root certificate. Bob creates separate user accounts for each database user, and configures the database to use both passwords and X.509 certificates for authentication. He elects not to use the <systemitem class=\""service\"">nova-conductor</systemitem> sub-service due to a desire for fine-grained access control."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch001_acknowledgements.xml:8(None) ./doc/security-guide/ch001_acknowledgements.xml:11(None) msgid ""@@image: 'static/book-sprint-all-logos.png'; md5=f2d97c3130c32f31412f5af41ad72d39"" msgstr """" #: ./doc/security-guide/ch001_acknowledgements.xml:3(title) msgid ""Acknowledgments"" msgstr """" #: ./doc/security-guide/ch001_acknowledgements.xml:4(para) msgid ""The OpenStack Security Group would like to acknowledge contributions from the following organizations who were instrumental in making this book possible. These are:"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch033_securing-neutron-services.xml:24(None) ./doc/security-guide/ch033_securing-neutron-services.xml:27(None) msgid ""@@image: 'static/1aa-logical-neutron-flow.png'; md5=63bd2e81863b9b381adb1c6951517498"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:3(title) msgid ""Securing OpenStack Networking Services"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:4(para) msgid ""In order to secure OpenStack Networking, an understanding of the workflow process for tenant instance creation needs to be mapped to security domains. "" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:5(para) msgid ""There are four main services that interact with OpenStack Networking. In a typical OpenStack deployment these services map to the following security domains:"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:7(para) msgid ""OpenStack Dashboard: Public and Management"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:10(para) msgid ""OpenStack Identity: Management"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:13(para) msgid ""OpenStack Compute Node: Management and Guest"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:16(para) msgid ""OpenStack Network Node: Management, Guest, and possibly Public depending upon neutron-plugin in use."" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:19(para) msgid ""SDN Services Node: Management, Guest and possibly Public depending upon product used."" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:30(para) msgid ""In order to isolate sensitive data communication between the OpenStack Networking services and other OpenStack core services, we strongly recommend that these communication channels be configured to only allow communications over an isolated management network."" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:32(title) msgid ""OpenStack Networking Service Configuration"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:34(title) msgid ""Restrict Bind Address of the API server: neutron-server"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:35(para) msgid ""To restrict the interface or IP address on which the OpenStack Networking API service binds a network socket for incoming client connections, specify the bind_host and bind_port in the neutron.conf file as shown:"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:44(title) msgid ""Restrict DB and RPC communication of the OpenStack Networking services:"" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:45(para) msgid ""Various components of the OpenStack Networking services use either the messaging queue or database connections to communicate with other components in OpenStack Networking."" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:46(para) msgid ""It is recommended that you follow the guidelines provided in the Database Authentication and Access Control chapter in the Database section for all components that require direct DB connections."" msgstr """" #: ./doc/security-guide/ch033_securing-neutron-services.xml:47(para) msgid ""It is recommended that you follow the guidelines provided in the Queue Authentication and Access Control chapter in the Messaging section for all components that require RPC communication."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch004_book-introduction.xml:113(None) ./doc/security-guide/ch004_book-introduction.xml:118(None) msgid ""@@image: 'static/marketecture-diagram.png'; md5=4ab13a64f80c210be3120abc5c7aee8a"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:8(title) msgid ""Introduction to OpenStack"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:9(para) msgid ""This guide provides security insight into OpenStack deployments. The intended audience is cloud architects, deployers, and administrators. In addition, cloud users will find the guide both educational and helpful in provider selection, while auditors will find it useful as a reference document to support their compliance certification efforts. This guide is also recommended for anyone interested in cloud security."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:16(para) msgid ""Each OpenStack deployment embraces a wide variety of technologies, spanning Linux distributions, database systems, messaging queues, OpenStack components themselves, access control policies, logging services, security monitoring tools, and much more. It should come as no surprise that the security issues involved are equally diverse, and their in-depth analysis would require several guides. We strive to find a balance, providing enough context to understand OpenStack security issues and their handling, and provide external references for further information. The guide could be read from start to finish or sampled as necessary like a reference."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:27(para) msgid ""We briefly introduce the kinds of clouds: private, public, and hybrid before presenting an overview of the OpenStack components and their related security concerns in the remainder of the chapter."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:32(title) msgid ""Cloud types"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:33(para) msgid ""OpenStack is a key enabler in adoption of cloud technology and has several common deployment use cases. These are commonly known as Public, Private, and Hybrid models. The following sections use the National Institute of Standards and Technology (NIST) <link href=\""http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\"">definition of cloud</link> to introduce these different types of cloud as they apply to OpenStack."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:42(title) msgid ""Public cloud"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:43(para) msgid ""According to NIST, a public cloud is one in which the infrastructure is open to the general public for consumption. OpenStack public clouds are typically run by a service provider and can be consumed by individuals, corporations, or any paying customer. A public cloud provider may expose a full set of features such as software defined networking, block storage, in addition to multiple instance types. Due to the nature of public clouds, they are exposed to a higher degree of risk. As a consumer of a public cloud you should validate that your selected provider has the necessary certifications, attestations, and other regulatory considerations. As a public cloud provider, depending on your target customers, you may be subject to one or more regulations. Additionally, even if not required to meet regulatory requirements, a provider should ensure tenant isolation as well as protecting management infrastructure from external attacks."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:61(title) msgid ""Private cloud"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:62(para) msgid ""At the opposite end of the spectrum is the private cloud. As NIST defines it, a private cloud is provisioned for exclusive use by a single organization comprising multiple consumers, such as business units. It may be owned, managed, and operated by the organization, a third-party, or some combination of them, and it may exist on or off premises. Private cloud use cases are diverse, as such, their individual security concerns vary."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:72(title) msgid ""Community cloud"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:73(para) msgid ""NIST defines a community cloud as one whose infrastructure is provisioned for the exclusive use by a specific community of consumers from organizations that have shared concerns. For example, mission, security requirements, policy, and compliance considerations. It may be owned, managed, and operated by one or more of the organizations in the community, a third-party, or some combination of them, and it may exist on or off premises."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:83(title) msgid ""Hybrid cloud"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:84(para) msgid ""A hybrid cloud is defined by NIST as a composition of two or more distinct cloud infrastructures, such as private, community, or public, that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability, such as cloud bursting for load balancing between clouds. For example an online retailer may have their advertising and catalogue presented on a public cloud that allows for elastic provisioning. This would enable them to handle seasonal loads in a flexible, cost-effective fashion. Once a customer begins to process their order, they are transferred to the more secure private cloud backend that is PCI compliant."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:96(para) msgid ""For the purposes of this document, we treat Community and Hybrid similarly, dealing explicitly only with the extremes of Public and Private clouds from a security perspective. Your security measures depend where your deployment falls upon the private public continuum."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:104(title) msgid ""OpenStack service overview"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:105(para) msgid ""OpenStack embraces a modular architecture to provide a set of core services that facilitates scalability and elasticity as core design tenets. This chapter briefly reviews OpenStack components, their use cases and security considerations."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:123(para) msgid ""OpenStack Compute Service (Nova) provides services to support the management of virtual machine instances at scale, instances that host multi-tiered applications, dev/test environments, \""Big Data\"" crunching Hadoop clusters, and/or high performance computing."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:128(para) msgid ""The Compute Service facilitates this management through an abstraction layer that interfaces with supported hypervisors, which we address later on in more detail."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:131(para) msgid ""Later in the guide, we focus generically on the virtualization stack as it relates to hypervisors."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:133(para) msgid ""For information about the current state of feature support, see <link href=\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support Matrix</link>."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:137(para) msgid ""The security of Compute is critical for an OpenStack deployment. Hardening techniques should include support for strong instance isolation, secure communication between Compute sub-components, and resiliency of public-facing <glossterm>API</glossterm> endpoints."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:144(title) ./doc/security-guide/ch027_storage.xml:8(title) msgid ""Object Storage"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:145(para) msgid ""The OpenStack Object Storage Service (Swift) provides support for storing and retrieving arbitrary data in the cloud. The Object Storage Service provides both a native API and an Amazon Web Services S3 compatible API. The service provides a high degree of resiliency through data replication and can handle petabytes of data."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:151(para) msgid ""It is important to understand that object storage differs from traditional file system storage. It is best used for static data such as media files (MP3s, images, videos), virtual machine images, and backup files."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:155(para) msgid ""Object security should focus on access control and encryption of data in transit and at rest. Other concerns may relate to system abuse, illegal or malicious content storage, and cross authentication attack vectors."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:161(title) msgid ""Block Storage"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:162(para) msgid ""The OpenStack Block Storage service (Cinder) provides persistent block storage for compute instances. The Block Storage Service is responsible for managing the life-cycle of block devices, from the creation and attachment of volumes to instances, to their release."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:167(para) msgid ""Security considerations for block storage are similar to that of object storage."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:171(title) msgid ""OpenStack Networking"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:172(para) msgid ""The OpenStack Networking Service (Neutron, previously called Quantum) provides various networking services to cloud users (tenants) such as IP address management, <glossterm>DNS</glossterm>, <glossterm>DHCP</glossterm>, load balancing, and security groups (network access rules, like firewall policies). It provides a framework for software defined networking (SDN) that allows for pluggable integration with various networking solutions."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:180(para) msgid ""OpenStack Networking allows cloud tenants to manage their guest network configurations. Security concerns with the networking service include network traffic isolation, availability, integrity and confidentiality."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:187(para) msgid ""The OpenStack Dashboard Service (Horizon) provides a web-based interface for both cloud administrators and cloud tenants. Through this interface administrators and tenants can provision, manage, and monitor cloud resources. Horizon is commonly deployed in a public facing manner with all the usual security concerns of public web portals."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:195(title) msgid ""Identity Service"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:196(para) msgid ""The OpenStack Identity Service (Keystone) is a <emphasis role=\""bold\"">shared service</emphasis> that provides authentication and authorization services throughout the entire cloud infrastructure. The Identity Service has pluggable support for multiple forms of authentication."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:201(para) msgid ""Security concerns here pertain to trust in authentication, management of authorization tokens, and secure communication."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:206(title) msgid ""Image Service"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:207(para) msgid ""The OpenStack Image Service (Glance) provides disk image management services. The Image Service provides image discovery, registration, and delivery services to Compute, the compute service, as needed."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:211(para) msgid ""Trusted processes for managing the life cycle of disk images are required, as are all the previously mentioned issues with respect to data security."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:216(title) msgid ""Other supporting technology"" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:217(para) msgid ""OpenStack relies on messaging for internal communication between several of its services. By default, OpenStack uses message queues based on the Advanced Message Queue Protocol (<glossterm>AMQP</glossterm>). Similar to most OpenStack services, it supports pluggable components. Today the implementation backend could be <glossterm>RabbitMQ</glossterm>, <glossterm>Qpid</glossterm>, or <glossterm>ZeroMQ</glossterm>."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:226(para) msgid ""As most management commands flow through the message queueing system, it is a primary security concern for any OpenStack deployment. Message queueing security is discussed in detail later in this guide."" msgstr """" #: ./doc/security-guide/ch004_book-introduction.xml:230(para) msgid ""Several of the components use databases though it is not explicitly called out. Securing the access to the databases and their contents is yet another security concern, and consequently discussed in more detail later in this guide."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:3(title) msgid ""Compliance Activities"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:4(para) msgid ""There are a number of standard activities that will greatly assist with the compliance process. In this chapter we outline some of the most common compliance activities. These are not specific to OpenStack, however we provide references to relevant sections in this book as useful context."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:6(title) msgid ""Information Security Management System (ISMS)"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:7(para) msgid ""An Information Security Management System (ISMS) is a comprehensive set of policies and processes that an organization creates and maintains to manage risk to information assets. The most common ISMS for cloud deployments is <link href=\""http://www.27000.org/iso-27001.htm\"">ISO/IEC 27001/2</link>, which creates a solid foundation of security controls and practices for achieving more stringent compliance certifications."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:10(title) msgid ""Risk Assessment"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:11(para) msgid ""A Risk Assessment framework identifies risks within an organization or service, and specifies ownership of these risks, along with implementation and mitigation strategies. Risks apply to all areas of the service, from technical controls to environmental disaster scenarios and human elements, for example a malicious insider (or rogue employee). Risks can be rated using a variety of mechanisms, for example likelihood vs impact. An OpenStack deployment risk assessment can include control gaps that are described in this book."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:14(title) msgid ""Access &amp; Log Reviews"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:15(para) msgid ""Periodic access and log reviews are required to ensure authentication, authorization, and accountability in a service deployment. Specific guidance for OpenStack on these topics are discussed in-depth in the logging section."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:18(title) msgid ""Backup and Disaster Recovery"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:19(para) msgid ""Disaster Recovery (DR) and Business Continuity Planning (BCP) plans are common requirements for ISMS and compliance activities. These plans must be periodically tested as well as documented. In OpenStack key areas are found in the management security domain, and anywhere that single points of failure (SPOFs) can be identified. See the section on secure backup and recovery for additional details."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:22(title) msgid ""Security Training"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:23(para) msgid ""Annual, role-specific, security training is a mandatory requirement for almost all compliance certifications and attestations. To optimise the effectiveness of security training, a common method is to provide role specific training, for example to developers, operational personnel, and non-technical employees. Additional cloud security or OpenStack security training based on this hardening guide would be ideal."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:26(title) msgid ""Security Reviews"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:27(para) msgid ""As OpenStack is a popular open source project, much of the codebase and architecture has been scrutinized by individual contributors, organizations and enterprises. This can be advantageous from a security perspective, however the need for security reviews is still a critical consideration for service providers, as deployments vary, and security is not always the primary concern for contributors. A comprehensive security review process may include architectural review, threat modelling, source code analysis and penetration testing. There are many techniques and recommendations for conducting security reviews that can be found publicly posted. A well-tested example is the <link href=\""http://www.microsoft.com/security/sdl/process/release.aspx\"">Microsoft SDL</link>, created as part of the Microsoft Trustworthy Computing Initiative."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:44(para) msgid ""Security updates are critical to any IaaS deployment, whether private or public. Vulnerable systems expand attack surfaces, and are obvious targets for attackers. Common scanning technologies and vulnerability notification services can help mitigate this threat. It is important that scans are authenticated and that mitigation strategies extend beyond simple perimeter hardening. Multi-tenant architectures such as OpenStack are particularly prone to hypervisor vulnerabilities, making this a critical part of the system for vulnerability management. See the section on instance isolation for additional details."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:47(title) msgid ""Data Classification"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:48(para) msgid ""Data Classification defines a method for classifying and handling information, often to protect customer information from accidental or deliberate theft, loss, or inappropriate disclosure. Most commonly this involves classifying information as sensitive or non-sensitive, or as personally identifiable information (PII). Depending on the context of the deployment various other classifying criteria may be used (government, health-care etc). The underlying principle is that data classifications are clearly defined and in-use. The most common protective mechanisms include industry standard encryption technologies. See the data security section for additional details."" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:51(title) msgid ""Exception Process"" msgstr """" #: ./doc/security-guide/ch063_compliance-activities.xml:52(para) msgid ""An exception process is an important component of an ISMS. When certain actions are not compliant with security policies that an organization has defined, they must be logged. Appropriate justification, description and mitigation details need to be included, and signed off by appropriate authorities. OpenStack default configurations may vary in meeting various compliance criteria, areas that fail to meet compliance requirements should be logged, with potential fixes considered for contribution to the community."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch027_storage.xml:53(None) msgid ""@@image: 'static/swift_network_diagram-1.png'; md5=83c094bb051cbe5e6161d3f7442f6136"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch027_storage.xml:108(None) ./doc/security-guide/ch027_storage.xml:113(None) msgid ""@@image: 'static/swift_network_diagram-2.png'; md5=69f8effe3f5d0f3cbccfb8c5a5dd299e"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:9(para) msgid ""OpenStack Object Storage (Swift) is a service that provides storage and retrieval of data over HTTP. Objects (blobs of data) are stored in an organizational hierarchy that offers anonymous read-only access or ACL defined access based on the authentication mechanism."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:14(para) msgid ""A consumer can store objects, modify them, or access them using the HTTP protocol and REST APIs. Backend components of Object Storage use different protocols for keeping the information synchronized in a redundant cluster of services. For more details on the API and the backend components see the <link href=\""http://docs.openstack.org/api/openstack-object-storage/1.0/content/\"">OpenStack Storage documentation</link>."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:22(para) msgid ""For this document the components will be grouped into the following primary groups:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:26(para) msgid ""Proxy services"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:29(para) msgid ""Auth services"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:32(para) msgid ""Storage services"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:35(para) ./doc/security-guide/ch027_storage.xml:159(td) msgid ""Account service"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:38(para) ./doc/security-guide/ch027_storage.xml:164(td) msgid ""Container service"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:41(para) ./doc/security-guide/ch027_storage.xml:169(td) msgid ""Object service"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:47(title) msgid ""An example diagram from the OpenStack Object Storage Administration Guide (2013)"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:58(para) msgid ""An Object Storage environment does not have to necessarily be on the Internet and could also be a private cloud with the \""Public Switch\"" being part of the organization's internal network infrastructure."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:64(title) msgid ""First thing to secure  the network"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:65(para) msgid ""The first aspect of a secure architecture design for Object Storage is in the networking component. The Storage service nodes use rsync between each other for copying data to provide replication and high availability. In addition, the proxy service communicates with the Storage service when relaying data back and forth between the end-point client and the cloud environment."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:73(para) msgid ""None of these use any type of encryption or authentication at this layer/tier."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:76(para) msgid ""This is why you see a \""Private Switch\"" or private network ([V]LAN) in architecture diagrams. This data domain should be separate from other OpenStack data networks as well. For further discussion on security domains please see <xref linkend=\""ch005_security-domains\""/>."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:83(para) msgid ""<emphasis>Rule:</emphasis> Use a private (V)LAN network segment for your Storage services in the data domain."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:87(para) msgid ""This necessitates that the Proxy service nodes have dual interfaces (physical or virtual):"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:91(para) msgid ""One as a \""public\"" interface for consumers to reach"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:95(para) msgid ""Another as a \""private\"" interface with access to the storage nodes"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:99(para) msgid ""The following figure demonstrates one possible network architecture."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:102(title) msgid ""Object storage network architecture with a management node (OSAM)"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:120(title) msgid ""Securing services  general"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:122(title) msgid ""Service runas user"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:123(para) msgid ""It is recommended that you configure each service to run under a non-root (UID 0) service account. One recommendation is the username \""swift\"" with primary group \""swift.\"""" msgstr """" #: ./doc/security-guide/ch027_storage.xml:129(title) msgid ""File permissions"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:130(para) msgid ""/etc/swift contains information about the ring topology and environment configuration. The following permissions are recommended:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:138(para) msgid ""This restricts only root to be able to modify configuration files while allowing the services to read them via their group membership in \""swift.\"""" msgstr """" #: ./doc/security-guide/ch027_storage.xml:146(title) msgid ""Securing storage services"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:147(para) msgid ""The following are the default listening ports for the various storage services:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:152(td) msgid ""Service Name"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:153(td) msgid ""Port"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:154(td) msgid ""Type"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:160(td) msgid ""6002"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:161(td) ./doc/security-guide/ch027_storage.xml:166(td) ./doc/security-guide/ch027_storage.xml:171(td) ./doc/security-guide/ch027_storage.xml:176(td) msgid ""TCP"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:165(td) msgid ""6001"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:170(td) msgid ""6000"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:174(td) msgid ""Rsync"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:175(td) msgid ""873"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:180(para) msgid ""Authentication does not happen at this level in Object Storage. If someone was able to connect to a Storage service node on one of these ports they could access or modify data without authentication. In order to secure against this issue you should follow the recommendations given previously about using a private storage network."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:188(title) msgid ""Object storage \""account\"" terminology"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:189(para) msgid ""An Object Storage \""Account\"" is not a user account or credential. The following explains the relations:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:195(td) msgid ""OpenStack Object Storage Account"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:196(td) msgid ""Collection of containers; not user accounts or authentication. Which users are associated with the account and how they may access it depends on the authentication system used. See authentication systems later. Referred to in this document as OSSAccount."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:205(td) msgid ""OpenStack Object Storage Containers"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:206(td) msgid ""Collection of objects. Metadata on the container is available for ACLs. The meaning of ACLs is dependent on the authentication system used."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:212(td) msgid ""OpenStack Object Storage Objects"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:213(td) msgid ""The actual data objects. ACLs at the object level are also possible with metadata. It is dependent on the authentication system used."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:221(para) msgid ""<?dbhtml bgcolor=\""#DDFADE\"" ?><?dbfo bgcolor=\""#DDFADE\"" ?> Another way of thinking about the above would be: A single shelf (Account) holds zero or more -&gt; buckets (Containers) which each hold zero or more -&gt; objects. A garage (Object Storage cloud environment) may have multiple shelves (Accounts) with each shelf belonging to zero or more users."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:231(para) msgid ""At each level you may have ACLs that dictate who has what type of access. ACLs are interpreted based on what authentication system is in use. The two most common types of authentication providers used are Keystone and SWAuth. Custom authentication providers are also possible. Please see the Object Storage Authentication section for more information."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:242(title) msgid ""Securing proxy services"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:243(para) msgid ""A Proxy service node should have at least two interfaces (physical or virtual): one public and one private. The public interface may be protected via firewalls or service binding. The public facing service is an HTTP web server that processes end-point client requests, authenticates them, and performs the appropriate action. The private interface does not require any listening services but is instead used to establish outgoing connections to storage service nodes on the private storage network."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:253(title) msgid ""Use SSL/TLS"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:254(para) msgid ""The built-in or included web server that comes with Swift supports SSL, but it does not support transmission of the entire SSL certificate chain. This causes issues when you use a third party trusted and signed certificate, such as Verisign, for your cloud. The current work around is to not use the built-in web server but an alternative web server instead that supports sending both the public server certificate as well as the CA signing authorities intermediate certificate(s). This allows for end-point clients that have the CA root certificate in their trust store to be able to successfully validate your cloud environment's SSL certificate and chain. An example of how to do this with mod_wsgi and Apache is given below. Also consult the <link href=\""http://docs.openstack.org/developer/swift/apache_deployment_guide.html\"">Apache Deployment Guide</link>"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:272(para) msgid ""Modify file <filename>/etc/apache2/envvars</filename> with"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:279(para) msgid ""An alternative is to modify your Apache conf file with"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:285(para) msgid ""Create a \""swift\"" directory in your Apache document root:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:288(para) msgid ""Create the file <filename>$YOUR_APACHE_DOC_ROOT/swift/proxy-server.wsgi</filename>:"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:294(title) msgid ""HTTP listening port"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:295(para) msgid ""You should run your Proxy service web server as a non-root (no UID 0) user such as \""swift\"" mentioned before. The use of a port greater than 1024 is required to make this easy and avoid running any part of the web container as root. Doing so is not a burden as end-point clients are not typically going to type in the URL manually into a web browser to browse around in the object storage. Additionally, for clients using the HTTP REST API and performing authentication they will normally automatically grab the full REST API URL they are to use as provided by the authentication response. OpenStacks REST API allows for a client to authenticate to one URL and then be told to use a completely different URL for the actual service. Example: Client authenticates to <uri>https://identity.cloud.example.org:55443/v1/auth</uri> and gets a response with their authentication key and Storage URL (the URL of the proxy nodes or load balancer) of <uri>https://swift.cloud.example.org:44443/v1/AUTH_8980</uri>."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:315(para) msgid ""The method for configuring your web server to start and run as a non-root user varies by web server and OS."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:320(title) msgid ""Load balancer"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:321(para) msgid ""If the option of using Apache is not feasible or for performance you wish to offload your SSL work you may employ a dedicated network device load balancer. This is also the common way to provide redundancy and load balancing when using multiple proxy nodes."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:326(para) msgid ""If you choose to offload your SSL ensure that the network link between the load balancer and your proxy nodes is on a private (V)LAN segment such that other nodes on the network (possibly compromised) cannot wiretap (sniff) the unencrypted traffic. If such a breach were to occur the attacker could gain access to end-point client or cloud administrator credentials and access the cloud data."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:334(para) msgid ""The authentication service you use, such as Keystone or SWAuth, will determine how you configure a different URL in the responses to end-clients so they use your load balancer instead of an individual Proxy service node."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:343(title) msgid ""Object storage authentication"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:344(para) msgid ""Object Storage uses wsgi to provide a middleware for authentication of end-point clients. The authentication provider defines what roles and user types exist. Some use traditional username and password credentials while others may leverage API key tokens or even client-side x.509 SSL certificates. Custom providers can be integrated in using the wsgi model."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:352(title) msgid ""Keystone"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:353(para) msgid ""Keystone is the commonly used Identity provider in OpenStack. It may also be used for authentication in Object Storage. Coverage of securing Keystone is already provided in <xref linkend=\""ch024_authentication\""/>."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:360(title) msgid ""SWAuth"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:361(para) msgid ""SWAuth is another alternative to Keystone. In contrast to Keystone it stores the user accounts, credentials, and metadata in object storage itself. More information can be found on the SWAuth website at <link href=\""http://gholt.github.io/swauth/\"">http://gholt.github.io/swauth/</link>."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:371(title) msgid ""Other notable items"" msgstr """" #: ./doc/security-guide/ch027_storage.xml:372(para) msgid ""In /etc/swift/swift.conf on every service node there is a \""swift_hash_path_suffix\"" setting. This is provided to reduce the chance of hash collisions for objects being stored and avert one user overwriting the data of another user."" msgstr """" #: ./doc/security-guide/ch027_storage.xml:377(para) msgid ""This value should be initially set with a cryptographically secure random number generator and consistent across all service nodes. Ensure that it is protected with proper ACLs and that you have a backup copy to avoid data loss."" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:8(title) msgid ""Introduction to Case Studies"" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:9(para) msgid ""This guide refers to two running case studies, which are introduced here and referred to at the end of each chapter."" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:12(title) msgid ""Case Study : Alice the private cloud builder"" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:13(para) msgid ""Alice deploys a private cloud for use by a government department in the US. The cloud must comply with relevant standards, such as FedRAMP. The security paperwork requirements for this cloud are very high. It must have no direct access to the internet: its API endpoints, compute instances, and other resources must be exposed to only systems within the department's network, which is entirely air-gapped from all other networks. The cloud can access other network services on the Organization's Intranet. For example, the authentication and logging services."" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:25(title) msgid ""Case Study : Bob the public cloud provider"" msgstr """" #: ./doc/security-guide/ch006_introduction-to-case-studies.xml:26(para) msgid ""Bob is a lead architect for a company that deploys a large greenfield public cloud. This cloud provides IaaS for the masses and enables any consumer with a valid credit card access to utility computing and storage, but the primary focus is enterprise customers. Data privacy concerns are a big priority for Bob as they are seen as a major barrier to large-scale adoption of the cloud by organizations."" msgstr """" #: ./doc/security-guide/ch030_state-of-networking.xml:3(title) msgid ""State of Networking"" msgstr """" #: ./doc/security-guide/ch030_state-of-networking.xml:4(para) msgid ""OpenStack Networking in the Grizzly release enables the end-user or tenant to define, utilize, and consume networking resources in new ways that had not been possible in previous OpenStack Networking releases. OpenStack Networking provides a tenant-facing API for defining network connectivity and IP addressing for instances in the cloud in addition to orchestrating the network configuration. With the transition to an API-centric networking service, cloud architects and administrators should take into consideration best practices to secure physical and virtual network infrastructure and services."" msgstr """" #: ./doc/security-guide/ch030_state-of-networking.xml:5(para) msgid ""OpenStack Networking was designed with a plug-in architecture that provides extensibility of the API via open source community or third-party services. As you evaluate your architectural design requirements, it is important to determine what features are available in OpenStack Networking core services, any additional services that are provided by third-party products, and what supplemental services are required to be implemented in the physical infrastructure."" msgstr """" #: ./doc/security-guide/ch030_state-of-networking.xml:6(para) msgid ""This section is a high-level overview of what processes and best practices should be considered when implementing OpenStack Networking. We will talk about the current state of services that are available, what future services will be implemented, and the current limitations in this project."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:3(title) msgid ""Database Transport Security"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:4(para) msgid ""This chapter covers issues related to network communications to and from the database server. This includes IP address bindings and encrypting network traffic with SSL."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:6(title) msgid ""Database Server IP Address Binding"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:7(para) msgid ""To isolate sensitive database communications between the services and the database, we strongly recommend that the database server(s) be configured to only allow communications to and from the database over an isolated management network. This is achieved by restricting the interface or IP address on which the database server binds a network socket for incoming client connections."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:9(title) msgid ""Restricting Bind Address for MySQL"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:10(para) ./doc/security-guide/ch043_database-transport-security.xml:33(para) msgid ""In my.cnf:"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:17(title) msgid ""Restricting Listen Address for PostgreSQL"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:18(para) msgid ""In postgresql.conf:"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:24(title) msgid ""Database Transport"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:25(para) msgid ""In addition to restricting database communications to the management network, we also strongly recommend that the cloud administrator configure their database backend to require SSL. Using SSL for the database client connections protects the communications from tampering and eavesdropping. As will be discussed in the next section, using SSL also provides the framework for doing database user authentication via X.509 certificates (commonly referred to as PKI). Below is guidance on how SSL is typically configured for the two popular database backends MySQL and PostgreSQL."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:27(para) msgid ""NOTE: When installing the certificate and key files, ensure that the file permissions are restricted, for example <literal>chmod 0600</literal>, and the ownership is restricted to the database daemon user to prevent unauthorized access by other processes and users on the database server."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:31(title) msgid ""MySQL SSL Configuration"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:32(para) msgid ""The following lines should be added in the system-wide MySQL configuration file:"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:40(para) ./doc/security-guide/ch043_database-transport-security.xml:50(para) msgid ""Optionally, if you wish to restrict the set of SSL ciphers used for the encrypted connection. See <link href=\""http://www.openssl.org/docs/apps/ciphers.html\"">http://www.openssl.org/docs/apps/ciphers.html</link> for a list of ciphers and the syntax for specifying the cipher string:"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:46(title) msgid ""PostgreSQL SSL Configuration"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:47(para) msgid ""The following lines should be added in the system-wide PostgreSQL configuration file, <literal>postgresql.conf</literal>."" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:53(para) msgid ""The server certificate, key, and certificate authority (CA) files should be placed in the $PGDATA directory in the following files:"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:55(para) msgid ""$PGDATA/server.crt - Server certificate"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:58(para) msgid ""$PGDATA/server.key - Private key corresponding to server.crt"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:61(para) msgid ""$PGDATA/root.crt - Trusted certificate authorities"" msgstr """" #: ./doc/security-guide/ch043_database-transport-security.xml:64(para) msgid ""$PGDATA/root.crl - Certificate revocation list"" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:3(title) msgid ""Key Management"" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:4(para) msgid ""To address the often mentioned concern of tenant data privacy and limiting cloud provider liability, there is greater interest within the OpenStack community to make data encryption more ubiquitous. It is relatively easy for an end-user to encrypt their data prior to saving it to the cloud, and this is a viable path for tenant objects such as media files, database archives among others. However, when client side encryption is used for virtual machine images, block storage etc, client intervention is necessary in the form of presenting keys to unlock the data for further use. To seamlessly secure the data and yet have it accessible without burdening the client with having to manage their keys and interactively provide them calls for a key management service within OpenStack. Providing encryption and key management services as part of OpenStack eases data-at-rest security adoption, addresses customer concerns about the privacy and misuse of their data with the added advantage of limiting cloud provider liability. Provider liability is of concern in multi-tenant public clouds with respect to handing over tenant data during a misuse investigation."" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:5(para) msgid ""A key management service is in the early stages of being developed and has a way to go before becoming an official component of OpenStack. Refer to <link href=\""https://github.com/cloudkeep/barbican/wiki/_pages\"">https://github.com/cloudkeep/barbican/wiki/_pages</link> for details."" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:6(para) msgid ""It shall support the creation of keys, and their secure saving (with a service master-key). Some of the design questions still being debated are how much of the Key Management Interchange Protocol (KMIP) to support, key formats, and certificate management. The key manager will be pluggable to facilitate deployments that need a third-party Hardware Security Module (HSM)."" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:7(para) msgid ""OpenStack Block Storage, Cinder, is the first service looking to integrate with the key manager to provide volume encryption."" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:9(title) msgid ""References:"" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:11(link) msgid ""Barbican"" msgstr """" #: ./doc/security-guide/ch048_key-management.xml:14(link) msgid ""KMIP"" msgstr """" #: ./doc/security-guide/ch009_case-studies.xml:3(title) msgid ""Case Studies: System Documentation"" msgstr """" #: ./doc/security-guide/ch009_case-studies.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address their system documentation requirements. The documentation suggested above includes hardware and software records, network diagrams, and system configuration details."" msgstr """" #: ./doc/security-guide/ch009_case-studies.xml:7(para) msgid ""Alice needs detailed documentation to satisfy FedRamp requirements. She sets up a configuration management database (CMDB) to store information regarding all of the hardware, firmware, and software versions used throughout the cloud. She also creates a network diagram detailing the cloud architecture, paying careful attention to the security domains and the services that span multiple security domains."" msgstr """" #: ./doc/security-guide/ch009_case-studies.xml:8(para) msgid ""Alice also needs to record each network service running in the cloud, what interfaces and ports it binds to, the security domains for each service, and why the service is needed. Alice decides to build automated tools to log into each system in the cloud over secure shell (SSH) using the <link href=\""http://fabfile.org\"">Python Fabric library</link>. The tools collect and store the information in the CMDB, which simplifies the audit process."" msgstr """" #: ./doc/security-guide/ch009_case-studies.xml:12(para) msgid ""In this case, Bob will approach these steps the same as Alice."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:3(title) msgid ""Case Studies: Instance Management"" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would architect their clouds with respect to instance entropy, scheduling instances, trusted images, and instance migrations."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:7(para) msgid ""Alice has a need for lots of high quality entropy in the instances. For this reason, she decides to purchase hardware with Intel Ivy Bridge chip sets that support the RdRand instruction on each compute node. Using the entropy gathering daemon (EGD) and LibVirt's EGD support, Alice ensures that this entropy pool is distributed to the instances on each compute node."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:8(para) msgid ""For instance scheduling, Alice uses the trusted compute pools to ensure that all cloud workloads are deployed to nodes that presented a proper boot time attestation. Alice decides to disable user permissions for image uploading to help ensure that the images used in the cloud are generated in a known and trusted manner by the cloud administrators."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:9(para) msgid ""Finally, Alice disables instance migrations as this feature is less critical for the high performance application workloads expected to run in this cloud. This helps avoid the various security concerns related to instance migrations."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:13(para) msgid ""Bob is aware that entropy will be a concern for some of his customers, such as those in the financial industry. However, due to the added cost and complexity, Bob has decided to forgo integrating hardware entropy into the first iteration of his cloud. He adds hardware entropy as a fast-follow to do for a later improvement for the second generation of his cloud architecture."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:14(para) msgid ""Bob is interested in ensuring that customers receive a high quality of service. He is concerned that providing too much explicit user control over instance scheduling could negatively impact the quality of service. So he disables this feature. Bob provides images in the cloud from a known trusted source for users to use. Additionally, he also allows users to upload their own images. However, users cannot generally share their images. This helps prevent a user from sharing a malicious image, which could negatively impact the security of other users in the cloud."" msgstr """" #: ./doc/security-guide/ch056_case-studies-instance-management.xml:15(para) msgid ""For migrations, Bob wants to enable secure instance migrations in order to support rolling upgrades with minimal user downtime. Bob ensures that all migrations occur on an isolated VLAN. He plans to defer implementing encrypted migrations until this is better supported in Nova client tools. However, he makes a note to track this carefully and switch to encrypted migrations as soon as possible."" msgstr """" #: ./doc/security-guide/ch_preface.xml:10(title) msgid ""Preface"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch008_system-roles-types.xml:101(None) ./doc/security-guide/ch008_system-roles-types.xml:106(None) msgid ""@@image: 'static/services-protocols-ports.png'; md5=fb1e9f47d969127b7a5ca683d38cfe20"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:8(title) msgid ""System Documentation Requirements"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:9(para) msgid ""The system documentation for an OpenStack cloud deployment should follow the templates and best practices for the Enterprise Information Technology System in your organization. Organizations often have compliance requirements which may require an overall System Security Plan to inventory and document the architecture of a given system. There are common challenges across the industry related to documenting the dynamic cloud infrastructure and keeping the information up-to-date."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:18(title) msgid ""System Roles &amp; Types"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:19(para) msgid ""The two broadly defined types of nodes that generally make up an OpenStack installation are:"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:23(para) msgid ""Infrastructure nodes. The nodes that run the cloud related services such as the OpenStack Identity Service, the message queuing service, storage, networking, and other services required to support the operation of the cloud."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:30(para) msgid ""Compute, storage, or other resource nodes. Provide storage capacity or virtual machines for your cloud."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:37(title) msgid ""System Inventory"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:38(para) msgid ""Documentation should provide a general description of the OpenStack environment and cover all systems used (production, development, test, etc.). Documenting system components, networks, services, and software often provides the bird's-eye view needed to thoroughly cover and consider security concerns, attack vectors and possible security domain bridging points. A system inventory may need to capture ephemeral resources such as virtual machines or virtual disk volumes that would otherwise be persistent resources in a traditional IT system."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:48(title) msgid ""Hardware Inventory"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:49(para) msgid ""Clouds without stringent compliance requirements for written documentation might benefit from having a Configuration Management Database (<glossterm>CMDB</glossterm>). CMDBs are normally used for hardware asset tracking and overall life-cycle management. By leveraging a CMDB, an organization can quickly identify cloud infrastructure hardware. For example, compute nodes, storage nodes, and network devices that exist on the network but that might not be adequately protected and/or forgotten. OpenStack provisioning system might provide some CMDB-like functions especially if auto-discovery features of hardware attributes are available."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:63(title) msgid ""Software Inventory"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:64(para) msgid ""Just as with hardware, all software components within the OpenStack deployment should be documented. Components here should include system databases; OpenStack software components and supporting sub-components; and, supporting infrastructure software such as load-balancers, reverse proxies, and network address translators. Having an authoritative list like this may be critical toward understanding total system impact due to a compromise or vulnerability of a specific class of software."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:76(title) msgid ""Network Topology"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:77(para) msgid ""A Network Topology should be provided with highlights specifically calling out the data flows and bridging points between the security domains. Network ingress and egress points should be identified along with any OpenStack logical system boundaries. Multiple diagrams may be needed to provide complete visual coverage of the system. A network topology document should include virtual networks created on behalf of tenants by the system along with virtual machine instances and gateways created by OpenStack."" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:88(title) msgid ""Services, Protocols and Ports"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:89(para) msgid ""The Service, Protocols and Ports table provides important additional detail of an OpenStack deployment. A table view of all services running within the cloud infrastructure can immediately inform, guide, and help check security procedures. Firewall configuration, service port conflicts, security remediation areas, and compliance requirements become easier to manage when you have concise information available. Consider the following table:"" msgstr """" #: ./doc/security-guide/ch008_system-roles-types.xml:109(para) msgid ""Referencing a table of services, protocols and ports can help in understanding the relationship between OpenStack components. It is highly recommended that OpenStack deployments have information similar to this on record."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:9(para) msgid ""Horizon is the OpenStack dashboard that provides users a self-service portal to provision their own resources within the limits set by administrators. These include provisioning users, defining instance flavors, uploading VM images, managing networks, setting up security groups, starting instances, and accessing the instances via a console."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:14(para) msgid ""The dashboard is based on the Django web framework, therefore secure deployment practices for Django apply directly to Horizon. This guide provides a popular set of Django security recommendations, further information can be found by reading the <link href=\""https://docs.djangoproject.com/en/1.5/#security\"">Django deployment and security documentation</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:21(para) msgid ""The dashboard ships with reasonable default security settings, and has good <link href=\""http://docs.openstack.org/developer/horizon/topics/deployment.html\"">deployment and configuration documentation</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:26(title) msgid ""Basic Web Server Configuration"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:27(para) msgid ""The dashboard should be deployed as a Web Services Gateway Interface (WSGI) application behind an HTTPS proxy such as Apache or nginx. If Apache is not already in use, we recommend nginx since it is lighter weight and easier to configure correctly."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:32(para) msgid ""When using nginx, we recommend <link href=\""http://docs.gunicorn.org/en/latest/deploy.html\"">gunicorn</link> as the wsgi host with an appropriate number of synchronous workers. We strongly advise against deployments using fastcgi, scgi, or uWSGI. We strongly advise against the use of synthetic performance benchmarks when choosing a wsgi server."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:39(para) msgid ""When using Apache, we recommend <link href=\""https://docs.djangoproject.com/en/1.5/howto/deployment/wsgi/modwsgi/\"">mod_wsgi</link> to host dashboard."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:44(title) msgid ""HTTPS"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:45(para) msgid ""The dashboard should be deployed behind a secure HTTPS server using a valid, trusted certificate from a recognized certificate authority (CA). Private organization-issued certificates are only appropriate when the root of trust is pre-installed in all user browsers."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:50(para) msgid ""HTTP requests to the dashboard domain should be configured to redirect to the fully qualified HTTPS URL."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:54(title) msgid ""HTTP Strict Transport Security (HSTS)"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:55(para) msgid ""It is highly recommended to use HTTP Strict Transport Security (HSTS)."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:57(para) msgid ""NOTE: If you are using an HTTPS proxy in front of your web server, rather than using an HTTP server with HTTPS functionality, follow the <link href=\""https://docs.djangoproject.com/en/1.5/ref/settings/#secure-proxy-ssl-header\"">Django documentation on modifying the SECURE_PROXY_SSL_HEADER variable</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:63(para) msgid ""See the chapter on PKI/SSL Everywhere for more specific recommendations and server configurations for HTTPS configurations, including the configuration of HSTS."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:68(title) msgid ""Front end Caching"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:69(para) msgid ""Since dashboard is rendering dynamic content passed directly from OpenStack API requests, we do not recommend front end caching layers such as varnish. In Django, static media is directly served from Apache or nginx and already benefits from web host caching."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:76(title) msgid ""Domain Names"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:77(para) msgid ""Many organizations typically deploy web applications at subdomains of an overarching organization domain. It is natural for users to expect a domain of the form <uri>openstack.example.org</uri>. In this context, there are often many other applications deployed in the same second-level namespace, often serving user-controlled content. This name structure is convenient and simplifies name server maintenance."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:85(para) msgid ""We strongly recommend deploying horizon to a <emphasis>second-level domain</emphasis>, such as <uri>https://example.com</uri>, and advise against deploying horizon on a <emphasis>shared subdomain</emphasis> of any level, for example <uri>https://openstack.example.org</uri> or <uri>https://horizon.openstack.example.org</uri>. We also advise against deploying to bare internal domains like <uri>https://horizon/</uri>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:93(para) msgid ""This recommendation is based on the limitations browser same-origin-policy. The recommendations in this guide cannot effectively protect users against known attacks if dashboard is deployed on a domain which also hosts user-generated content, such as scripts, images, or uploads of any kind, even if the user-generated content is on a different subdomain. This approach is used by most major web presences, such as googleusercontent.com, fbcdn.com, github.io, and twimg.com, to ensure that user generated content stays separate from cookies and security tokens."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:103(para) msgid ""Additionally, if you decline to follow this recommendation above about second-level domains, it is vital that you avoid the cookie backed session store and employ HTTP Strict Transport Security (HSTS). When deployed on a subdomain, dashboard's security is only as strong as the weakest application deployed on the same second-level domain."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:111(title) msgid ""Static Media"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:112(para) msgid ""Dashboard's static media should be deployed to a subdomain of the dashboard domain and served by the web server. The use of an external content delivery network (CDN) is also acceptable. This subdomain should not set cookies or serve user-provided content. The media should also be served with HTTPS."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:117(para) msgid ""Django media settings are documented at <link href=\""https://docs.djangoproject.com/en/1.5/ref/settings/#static-root\"">https://docs.djangoproject.com/en/1.5/ref/settings/#static-root</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:120(para) msgid ""Dashboard's default configuration uses <link href=\""http://django-compressor.readthedocs.org/\"">django_compressor</link> to compress and minify css and JavaScript content before serving it. This process should be statically done before deploying dashboard, rather than using the default in-request dynamic compression and copying the resulting files along with deployed code or to the CDN server. Compression should be done in a non-production build environment. If this is not practical, we recommend disabling resource compression entirely. Online compression dependencies (less, nodejs) should not be installed on production machines."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:134(title) msgid ""Secret Key"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:135(para) msgid ""Dashboard depends on a shared SECRET_KEY setting for some security functions. It should be a randomly generated string at least 64 characters long. It must be shared across all active Horizon instances. Compromise of this key may allow a remote attacker to execute arbitrary code. Rotating this key invalidates existing user sessions and caching. Do not commit this key to public repositories."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:144(title) msgid ""Session Backend"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:145(para) msgid ""Horizon's default session backend (<emphasis>django.contrib.sessions.backends.signed_cookies</emphasis>) stores user data in <emphasis>signed</emphasis> but <emphasis>unencrypted </emphasis>cookies stored in the browser. This approach allows the most simple session backend scaling since each Horizon instance is stateless, but it comes at the cost of <emphasis>storing sensitive access tokens in the client browser</emphasis> and transmitting them with every request. This backend ensures that session data has not been tampered with, but the data itself is not encrypted other than the encryption provided by HTTPS."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:156(para) msgid ""If your architecture allows it, we recommend using <emphasis>django.contrib.sessions.backends.cache</emphasis> as your session backend with memcache as the cache. Memcache must not be exposed publicly, and should communicate over a secured private channel. If you choose to use the signed cookies backend, refer to the Django documentation understand the security trade-offs."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:163(para) msgid ""For further details, consult the <link href=\""https://docs.djangoproject.com/en/1.5/topics/http/sessions/#configuring-the-session-engine\"">Django session backend documentation</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:168(title) msgid ""Allowed Hosts"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:169(para) msgid ""Configure the ALLOWED_HOSTS setting with the domain or domains where Horizon is available. Failure to configure this setting (especially if not following the recommendation above regarding second level domains) opens Horizon to a number of serious attacks. Wild card domains should be avoided."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:174(para) msgid ""For further details, see the <link href=\""https://docs.djangoproject.com/en/1.5/ref/settings/#allowed-hosts\"">Django documentation on settings</link>."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:179(title) msgid ""Cookies"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:180(para) msgid ""Session Cookies should be set to HTTPONLY:"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:183(para) msgid ""Never configure CSRF or session cookies to have a wild card domain with a leading dot. Horizon's session and CSRF cookie should be secured when deployed with HTTPS:"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:191(title) msgid ""Password Auto Complete"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:192(para) msgid ""We recommend that implementers do not change the default password auto complete behavior. Users choose stronger passwords in environments that allow them to use the secure browser password manager. Organizations which forbid the browser password manager should enforce this policy at the desktop level."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:200(title) msgid ""Cross Site Request Forgery (CSRF)"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:201(para) msgid ""Django has a dedicated middleware for <link href=\""https://docs.djangoproject.com/en/1.5/ref/contrib/csrf/#how-it-works\"">cross-site request forgery</link> (CSRF)."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:204(para) msgid ""Dashboard is designed to discourage developers from introducing cross-site scripting vulnerabilities with custom dashboards. However, it is important to audit custom dashboards, especially ones that are javascript-heavy for inappropriate use of the @csrf_exempt decorator. Dashboards which do not follow these recommended security settings should be carefully evaluated before restrictions are relaxed."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:213(title) msgid ""Cross Site Scripting (XSS)"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:214(para) msgid ""Unlike many similar systems, OpenStack dashboard allows the entire Unicode character set in most fields. This means developers have less latitude to make escaping mistakes that open attack vectors for cross-site scripting (XSS)."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:218(para) msgid ""Dashboard provides tools for developers to avoid creating XSS vulnerabilities, but they only work if developers use them correctly. Audit any custom dashboards, paying particular attention to use of the mark_safe function, use of is_safe with custom template tags, the safe template tag, anywhere auto escape is turned off, and any JavaScript which might evaluate improperly escaped data."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:227(title) msgid ""Cross Origin Resource Sharing (CORS)"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:228(para) msgid ""Configure your web server to send a restrictive CORS header with each response, allowing only the Horizon domain and protocol:"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:233(para) msgid ""Never allow the wild card origin."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:236(title) msgid ""Horizon Image Upload"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:237(para) msgid ""We recommend that implementers <link href=\""http://docs.openstack.org/developer/horizon/topics/deployment.html#file-uploads\"">disable HORIZON_IMAGES_ALLOW_UPLOAD</link> unless they have implemented a plan to prevent resource exhaustion and denial of service."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:244(title) msgid ""Upgrading"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:245(para) msgid ""Django security releases are generally well tested and aggressively backwards compatible. In almost all cases, new major releases of Django are also fully backwards compatible with previous releases. Dashboard implementers are strongly encouraged to run the latest stable release of Django with up-to-date security releases."" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:253(title) msgid ""Debug"" msgstr """" #: ./doc/security-guide/ch025_web-dashboard.xml:254(para) msgid ""Make sure DEBUG is set to False in production. In Django, DEBUG displays stack traces and sensitive web server state information on any exception."" msgstr """" #: ./doc/security-guide/ch022_case-studies-api-endpoints.xml:3(title) msgid ""Case Studies: API Endpoints"" msgstr """" #: ./doc/security-guide/ch022_case-studies-api-endpoints.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address endpoint configuration to secure their private and public clouds. Alice's cloud is not publicly accessible, but she is still concerned about securing the endpoints against improper use. Bob's cloud, being public, must take measures to reduce the risk of attacks by external adversaries."" msgstr """" #: ./doc/security-guide/ch022_case-studies-api-endpoints.xml:7(para) msgid ""Alice's organization requires that the security architecture protect the access to the public and private endpoints, so she elects to use the Apache SSL proxy on both public and internal services. Alice's organization has implemented its own certificate authority. Alice contacts the PKI office in her agency that manages her PKI and certificate issuance. Alice obtains certificates issued by this CA and configures the services within both the public and management security domains to use these certificates. Since Alice's OpenStack deployment exists entirely on a disconnected from the Internet network, she makes sure to remove all default CA bundles that contain external public CA providers to ensure the OpenStack services only accept client certificates issued by her agency's CA. Alice has registered all of the services in the Keystone Services Catalog, using the internal URLs for access by internal services. She has installed host-based intrusion detection on all of the API endpoints."" msgstr """" #: ./doc/security-guide/ch022_case-studies-api-endpoints.xml:11(para) msgid ""Bob must also protect the access to the public and private endpoints, so he elects to use the Apache SSL proxy on both public and internal services. On the public services, he has configured the certificate key files with certificates signed by a well-known Certificate Authority. He has used his organization's self-signed CA to sign certificates in the internal services on the Management network. Bob has registered his services in the Keystone Services Catalog, using the internal URLs for access by internal services. Bob's public cloud runs services on SELinux, which he has configured with a mandatory access control policy to reduce the impact of any publicly accessible services that may be compromised. He has also configured the endpoints with a host-based IDS."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:3(title) msgid ""Data Privacy Concerns"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:4(para) msgid ""OpenStack is designed to support multitenancy and those tenants will most probably have different data requirements. As a cloud builder and operator you need to ensure your OpenStack environment can address various data privacy concerns and regulations. In this chapter we will address the following topics around Data Privacy as it pertains to OpenStack implementations:"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:6(para) ./doc/security-guide/ch046_data-residency.xml:13(title) msgid ""Data Residency"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:9(para) ./doc/security-guide/ch046_data-residency.xml:64(title) msgid ""Data Disposal"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:14(para) msgid ""The privacy and isolation of data has consistently been cited as the primary barrier to cloud adoption over the past few years. Concerns over who owns data in the cloud and whether the cloud operator can be ultimately trusted as a custodian of this data have been significant issues in the past."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:15(para) msgid ""Numerous OpenStack services maintain data and metadata belonging to tenants or reference tenant information."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:16(para) msgid ""Tenant data stored in an OpenStack cloud may include the following items:"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:18(para) msgid ""Swift objects"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:21(para) msgid ""Compute instance ephemeral filesystem storage"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:24(para) msgid ""Compute instance memory"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:27(para) ./doc/security-guide/ch046_data-residency.xml:113(title) msgid ""Cinder volume data"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:30(para) msgid ""Public keys for Compute Access"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:33(para) msgid ""Virtual Machine Images in Glance"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:36(para) msgid ""Machine snapshots"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:39(para) msgid ""Data passed to OpenStack Compute's configuration-drive extension"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:42(para) msgid ""Metadata stored by an OpenStack cloud includes the following non-exhaustive items:"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:44(para) msgid ""Organization name"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:47(para) msgid ""User's \""Real Name\"""" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:50(para) msgid ""Number or size of running instances, buckets, objects, volumes, and other quota-related items"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:53(para) msgid ""Number of hours running instances or storing data"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:56(para) msgid ""IP addresses of users"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:59(para) msgid ""Internally generated private keys for compute image bundling"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:65(para) msgid ""OpenStack operators should strive to provide a certain level of tenant data disposal assurance. Best practices suggest that the operator sanitize cloud system media (digital and non-digital) prior to disposal, release out of organization control or release for reuse. Sanitization methods should implement an appropriate level of strength and integrity given the specific security domain and sensitivity of the information."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:67(para) msgid ""\""Sanitization is the process used to remove information from system media such that there is reasonable assurance that the information cannot be retrieved or reconstructed. Sanitization techniques, including clearing, purging, and destroying media information, prevent the disclosure of organizational information to unauthorized individuals when such media is reused or released for disposal.\"" [NIST Special Publication 800-53 Revision 3]"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:69(para) msgid ""General data disposal and sanitization guidelines as adopted from NIST recommended security controls. Cloud Operators should:"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:71(para) msgid ""Track, document and verify media sanitization and disposal actions."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:74(para) msgid ""Test sanitation equipment and procedures to verify proper performance."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:78(para) msgid ""Sanitize portable, removable storage devices prior to connecting such devices to the cloud infrastructure."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:81(para) msgid ""Destroy cloud system media that cannot be sanitized."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:84(para) msgid ""In an OpenStack deployment you will need to address the following:"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:86(para) msgid ""Secure data erasure"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:89(para) ./doc/security-guide/ch046_data-residency.xml:106(title) msgid ""Instance memory scrubbing"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:92(para) msgid ""Block Storage volume data"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:95(para) ./doc/security-guide/ch046_data-residency.xml:119(title) msgid ""Compute instance ephemeral storage"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:98(para) ./doc/security-guide/ch046_data-residency.xml:126(title) msgid ""Bare metal server sanitization"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:102(title) msgid ""Data not securely erased"" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:103(para) msgid ""Within OpenStack some data may be deleted, but not securely erased in the context of the NIST standards outlined above. This is generally applicable to most or all of the above-defined metadata and information stored in the database. This may be remediated with database and/or system configuration for auto vacuuming and periodic free-space wiping."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:107(para) msgid ""Specific to various hypervisors is the treatment of instance memory. This behavior is not defined in OpenStack Compute, although it is generally expected of hypervisors that they will make a best effort to scrub memory either upon deletion of an instance, upon creation of an instance, or both."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:108(para) msgid ""Xen explicitly assigns dedicated memory regions to instances and scrubs data upon the destruction of instances (or domains in Xen parlance). KVM depends more greatly on Linux page management; A complex set of rules related to KVM paging is defined in the <link href=\""http://www.linux-kvm.org/page/Memory\"">KVM documentation</link>."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:109(para) msgid ""It is important to note that use of the Xen memory balloon feature is likely to result in information disclosure. We strongly recommended to avoid use of this feature."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:110(para) msgid ""For these and other hypervisors, we recommend referring to hypervisor-specific documentation."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:114(para) msgid ""Plugins to OpenStack Block Storage will store data in a variety of ways. Many plugins are specific to a vendor or technology, whereas others are more DIY solutions around filesystems such as LVM or ZFS. Methods to securely destroy data will vary from one plugin to another, from one vendor's solution to another, and from one filesystem to another."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:115(para) msgid ""Some backends such as ZFS will support copy-on-write to prevent data exposure. In these cases, reads from unwritten blocks will always return zero. Other backends such as LVM may not natively support this, thus the Cinder plugin takes the responsibility to override previously written blocks before handing them to users. It is important to review what assurances your chosen volume backend provides and to see what mediations may be available for those assurances not provided."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:116(para) msgid ""Finally, while not a feature of OpenStack, vendors and implementors may choose to add or support encryption of volumes. In this case, destruction of data is as simple as throwing away the key."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:120(para) msgid ""The creation and destruction of ephemeral storage will be somewhat dependent on the chosen hypervisor and the OpenStack Compute plugin."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:121(para) msgid ""The libvirt plugin for compute may maintain ephemeral storage directly on a filesystem, or in LVM. Filesystem storage generally will not overwrite data when it is removed, although there is a guarantee that dirty extents are not provisioned to users."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:122(para) msgid ""When using LVM backed ephemeral storage, which is block-based, it is necessary that the OpenStack Compute software securely erases blocks to prevent information disclosure. There have in the past been information disclosure vulnerabilities related to improperly erased ephemeral block storage devices."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:123(para) msgid ""Filesystem storage is a more secure solution for ephemeral block storage devices than LVM as dirty extents cannot be provisioned to users. However, it is important to be mindful that user data is not destroyed, so it is suggested to encrypt the backing filesystem."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:127(para) msgid ""A bare metal server driver for Nova was under development and has since moved into a separate project called <link href=\""https://wiki.openstack.org/wiki/Ironic\"">Ironic</link>. At the time of this writing, Ironic does not appear to address sanitization of tenant data resident the physical hardware."" msgstr """" #: ./doc/security-guide/ch046_data-residency.xml:128(para) msgid ""Additionally, it is possible for tenants of a bare metal system to modify system firmware. TPM technology, described in ##link:Management/Node Bootstrapping##, provides a solution for detecting unauthorized firmware changes."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:3(title) msgid ""Understanding the Audit Process"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:4(para) msgid ""Information system security compliance is reliant on the completion of two foundational processes:"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:6(para) msgid ""<emphasis role=\""bold\"">Implementation and Operation of Security Controls</emphasis>Aligning the information system with in-scope standards and regulations involves internal tasks which must be conducted before a formal assessment. Auditors may be involved at this state to conduct gap analysis, provide guidance, and increase the likelihood of successful certification."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:9(para) msgid ""<emphasis role=\""bold\"">Independent Verification and Validation</emphasis>Demonstration to a neutral third-party that system security controls are implemented and operating effectively, in compliance with in-scope standards and regulations, is required before many information systems achieve certified status. Many certifications require periodic audits to ensure continued certification, considered part of an overarching continuous monitoring practice. "" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:13(title) msgid ""Determining Audit Scope"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:14(para) msgid ""Determining audit scope, specifically what controls are needed and how to design or modify an OpenStack deployment to satisfy them, should be the initial planning step."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:15(para) msgid ""When scoping OpenStack deployments for compliance purposes, consider prioritizing controls around sensitive services, such as command and control functions and the base virtualization technology. Compromises of these facilities may impact an OpenStack environment in its entirety."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:16(para) msgid ""Scope reduction helps ensure OpenStack architects establish high quality security controls which are tailored to a particular deployment, however it is paramount to ensure these practices do not omit areas or features from security hardening. A common example is applicable to PCI-DSS guidelines, where payment related infrastructure may be scrutinized for security issues, but supporting services are left ignored, and vulnerable to attack."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:17(para) msgid ""When addressing compliance, you can increase efficiency and reduce work effort by identifying common areas and criteria that apply across multiple certifications. Much of the audit principles and guidelines discussed in this book will assist in identifying these controls, additionally a number of external entities provide comprehensive lists. The following are some examples:"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:18(para) msgid ""The <link href=\""https://cloudsecurityalliance.org/research/ccm/\"">Cloud Security Alliance Cloud Controls Matrix</link> (CCM) assists both cloud providers and consumers in assessing the overall security of a cloud provider. The CSA CMM provides a controls framework that map to many industry-accepted standards and regulations including the ISO 27001/2, ISACA, COBIT, PCI, NIST, Jericho Forum and NERC CIP."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:19(para) msgid ""The <link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP Security Guide</link> is another useful reference. This is still an emerging source, but we anticipate that this will grow into a tool with controls mappings that are more focused on the US federal government certifications and recommendations. For example, the SCAP Security Guide currently has some mappings for security technical implementation guides (STIGs) and NIST-800-53."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:20(para) msgid ""These control mappings will help identify common control criteria across certifications, and provide visibility to both auditors and auditees on problem areas within control sets for particular compliance certifications and attestations."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:23(title) msgid ""Internal Audit"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:24(para) msgid ""Once a cloud is deployed, it is time for an internal audit. This is the time compare the controls you identified above with the design, features, and deployment strategies utilized in your cloud. The goal is to understand how each control is handled and where gaps exist. Document all of the findings for future reference."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:25(para) msgid ""When auditing an OpenStack cloud it is important to appreciate the multi-tenant environment inherent in the OpenStack architecture. Some critical areas for concern include data disposal, hypervisor security, node hardening, and authentication mechanisms."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:28(title) msgid ""Prepare for External Audit"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:29(para) msgid ""Once the internal audit results look good, it is time to prepare for an external audit. There are several key actions to take at this stage, these are outlined below:"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:31(para) msgid ""Maintain good records from your internal audit. These will prove useful during the external audit so you can be prepared to answer questions about mapping the compliance controls to a particular deployment."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:34(para) msgid ""Deploy automated testing tools to ensure that the cloud remains compliant over time."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:37(para) msgid ""Select an auditor."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:40(para) msgid ""Selecting an auditor can be challenging. Ideally, you are looking for someone with experience in cloud compliance audits. OpenStack experience is another big plus. Often it is best to consult with people who have been through this process for referrals. Cost can vary greatly depending on the scope of the engagement and the audit firm considered."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:43(title) msgid ""External Audit"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:44(para) msgid ""This is the formal audit process. Auditors will test security controls in scope for a specific certification, and demand evidentiary requirements to prove that these controls were also in place for the audit window (for example SOC 2 audits generally evaluate security controls over a 6-12 months period). Any control failures are logged, and will be documented in the external auditors final report. Dependent on the type of OpenStack deployment, these reports may be viewed by customers, so it is important to avoid control failures. This is why audit preparation is so important."" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:47(title) msgid ""Compliance Maintenance"" msgstr """" #: ./doc/security-guide/ch062_audit-guidance.xml:48(para) msgid ""The process doesn't end with a single external audit. Most certifications require continual compliance activities which means repeating the audit process periodically. We recommend integrating automated compliance verification tools into a cloud to ensure that it is compliant at all times. This should be in done in addition to other security monitoring tools. Remember that the goal is both security <emphasis>and</emphasis> compliance. Failing on either of these fronts will significantly complicate future audits."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch042_database-overview.xml:13(None) ./doc/security-guide/ch042_database-overview.xml:16(None) msgid ""@@image: 'static/databaseusername.png'; md5=a6a5dadedbc1517069ca388c7ac5940a"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch042_database-overview.xml:37(None) ./doc/security-guide/ch042_database-overview.xml:40(None) msgid ""@@image: 'static/databaseusernamessl.png'; md5=9c43242c47eb159b6f61ac41f3d8bced"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch042_database-overview.xml:101(None) ./doc/security-guide/ch042_database-overview.xml:104(None) msgid ""@@image: 'static/novaconductor.png'; md5=dbc1ba139bd1af333f0415bb48704843"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:3(title) msgid ""Database Access Control"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:4(para) msgid ""Each of the core OpenStack services (Compute, Identity, Networking, Block Storage) store state and configuration information in databases. In this chapter, we discuss how databases are used currently in OpenStack. We also explore security concerns, and the security ramifications of database backend choices."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:6(title) msgid ""OpenStack Database Access Model"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:7(para) msgid ""All of the services within an OpenStack project access a single database. There are presently no reference policies for creating table or row based access restrictions to the database."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:8(para) msgid ""There are no general provisions for granular control of database operations in OpenStack. Access and privileges are granted simply based on whether a node has access to the database or not. In this scenario, nodes with access to the database may have full privileges to DROP, INSERT, or UPDATE functions."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:10(title) msgid ""Granular Access Control"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:11(para) msgid ""By default, each of the OpenStack services and their processes access the database using a shared set of credentials. This makes auditing database operations and revoking access privileges from a service and its processes to the database particularly difficult."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:21(title) ./doc/security-guide/ch042_database-overview.xml:96(title) msgid ""Nova Conductor"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:22(para) msgid ""The compute nodes are the least trusted of the services in OpenStack because they host tenant instances. The <systemitem class=\""service\"">nova-conductor</systemitem> service has been introduced to serve as a database proxy, acting as an intermediary between the compute nodes and the database. We discuss its ramifications later in this chapter."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:23(para) msgid ""We strongly recommend:"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:25(para) msgid ""All database communications be isolated to a management network"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:28(para) msgid ""Securing communications using SSL"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:31(para) msgid ""Creating unique database user accounts per OpenStack service endpoint (illustrated below)"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:47(title) msgid ""Database Authentication and Access Control"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:48(para) msgid ""Given the risks around access to the database, we strongly recommend that unique database user accounts be created per node needing access to the database. Doing this facilitates better analysis and auditing for ensuring compliance or in the event of a compromise of a node allows you to isolate the compromised host by removing access for that node to the database upon detection. When creating these per service endpoint database user accounts, care should be taken to ensure that they are configured to require SSL. Alternatively, for increased security it is recommended that the database accounts be configured using X.509 certificate authentication in addition to usernames and passwords."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:50(title) msgid ""Privileges"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:51(para) msgid ""A separate database administrator (DBA) account should be created and protected that has full privileges to create/drop databases, create user accounts, and update user privileges. This simple means of separation of responsibility helps prevent accidental misconfiguration, lowers risk and lowers scope of compromise."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:52(para) msgid ""The database user accounts created for the OpenStack services and for each node should have privileges limited to just the database relevant to the service where the node is a member."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:56(title) msgid ""Require User Accounts to Require SSL Transport"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:58(title) ./doc/security-guide/ch042_database-overview.xml:75(title) msgid ""Configuration Example #1: (MySQL)"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:63(title) ./doc/security-guide/ch042_database-overview.xml:82(title) msgid ""Configuration Example #2: (PostgreSQL)"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:64(para) msgid ""In file pg_hba.conf:"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:67(para) msgid ""Note this command only adds the ability to communicate over SSL and is non-exclusive. Other access methods that may allow unencrypted transport should be disabled so that SSL is the sole access method."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:68(para) msgid ""The 'md5' parameter defines the authentication method as a hashed password. We provide a secure authentication example in the section below."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:72(title) msgid ""Authentication with X.509 Certificates"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:73(para) msgid ""Security may be enhanced by requiring X.509 client certificates for authentication. Authenticating to the database in this manner provides greater identity assurance of the client making the connection to the database and ensures that the communications are encrypted."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:88(title) msgid ""OpenStack Service Database Configuration"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:89(para) msgid ""If your database server is configured to require X.509 certificates for authentication you will need to specify the appropriate SQLAlchemy query parameters for the database backend. These parameters specify the certificate, private key, and certificate authority information for use with the initial connection string."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:90(para) msgid ""Example of an <literal>:sql_connection</literal> string for X.509 certificate authentication to MySQL:"" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:97(para) msgid ""OpenStack Compute offers a sub-service called <systemitem class=\""service\"">nova-conductor</systemitem> which proxies database connections, with the primary purpose of having the nova compute nodes interfacing with <systemitem class=\""service\"">nova-conductor</systemitem> to meet data persistence needs as opposed to directly communicating with the database."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:98(para) msgid ""Nova-conductor receives requests over RPC and performs actions on behalf of the calling service without granting granular access to the database, its tables, or data within. Nova-conductor essentially abstracts direct database access away from compute nodes."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:99(para) msgid ""This abstraction offers the advantage of restricting services to executing methods with parameters, similar to stored procedures, preventing a large number of systems from directly accessing or modifying database data. This is accomplished without having these procedures stored or executed within the context or scope of the database itself, a frequent criticism of typical stored procedures."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:107(para) msgid ""Unfortunately, this solution complicates the task of more fine-grained access control and the ability to audit data access. Because the <systemitem class=\""service\"">nova-conductor</systemitem> service receives requests over RPC, it highlights the importance of improving the security of messaging. Any node with access to the message queue may execute these methods provided by the <systemitem class=\""service\"">nova-conductor</systemitem> and effectively modifying the database."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:108(para) msgid ""Finally, it should be noted that as of the Grizzly release, gaps exist where <systemitem class=\""service\"">nova-conductor</systemitem> is not used throughout OpenStack Compute. Depending on one's configuration, the use of <systemitem class=\""service\"">nova-conductor</systemitem> may not allow deployers to avoid the necessity of providing database GRANTs to individual compute host systems."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:109(para) msgid ""Note, as <systemitem class=\""service\"">nova-conductor</systemitem> only applies to OpenStack Compute, direct database access from compute hosts may still be necessary for the operation of other OpenStack components such as Telemetry (Ceilometer), Networking, and Block Storage."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:110(para) msgid ""Implementors should weigh the benefits and risks of both configurations before enabling or disabling the <systemitem class=\""service\"">nova-conductor</systemitem> service. We are not yet prepared to recommend the use of <systemitem class=\""service\"">nova-conductor</systemitem> in the Grizzly release. However, we do believe that this recommendation will change as additional features are added into OpenStack."" msgstr """" #: ./doc/security-guide/ch042_database-overview.xml:111(para) msgid ""To disable the <systemitem class=\""service\"">nova-conductor</systemitem>, place the following into your <filename>nova.conf</filename> file (on your compute hosts):"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:3(title) msgid ""Identity"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:4(para) msgid ""The OpenStack Identity Service (Keystone) supports multiple methods of authentication, including username &amp; password, LDAP, and external authentication methods. Upon successful authentication, The Identity Service provides the user with an authorization token used for subsequent service requests."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:5(para) msgid ""Transport Layer Security TLS/SSL provides authentication between services and persons using X.509 certificates. Although the default mode for SSL is server-side only authentication, certificates may also be used for client authentication."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:7(title) msgid ""Authentication"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:9(title) msgid ""Invalid Login Attempts"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:10(para) msgid ""The Identity Service does not provide a method to limit access to accounts after repeated unsuccessful login attempts. Repeated failed login attempts are likely brute-force attacks (Refer figure Attack-types). This is a more significant issue in Public clouds."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:11(para) msgid ""Prevention is possible by using an external authentication system that blocks out an account after some configured number of failed login attempts. The account then may only be unlocked with further side-channel intervention."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:12(para) msgid ""If prevention is not an option, detection can be used to mitigate damage.Detection involves frequent review of access control logs to identify unauthorized attempts to access accounts. Possible remediation would include reviewing the strength of the user password, or blocking the network source of the attack via firewall rules. Firewall rules on the keystone server that restrict the number of connections could be used to reduce the attack effectiveness, and thus dissuade the attacker."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:13(para) msgid ""In addition, it is useful to examine account activity for unusual login times and suspicious actions, with possibly disable the account. Often times this approach is taken by credit card providers for fraud detection and alert."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:16(title) msgid ""Multi-factor Authentication"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:17(para) msgid ""Employ multi-factor authentication for network access to privileged user accounts. The Identity Service supports external authentication services through the Apache web server that can provide this functionality. Servers may also enforce client-side authentication using certificates."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:18(para) msgid ""This recommendation provides insulation from brute force, social engineering, and both spear and mass phishing attacks that may compromise administrator passwords."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:22(title) msgid ""Authentication Methods"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:24(title) msgid ""Internally Implemented Authentication Methods"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:25(para) msgid ""The Identity Service can store user credentials in an SQL Database, or may use an LDAP-compliant directory server. The Identity database may be separate from databases used by other OpenStack services to reduce the risk of a compromise of the stored credentials."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:26(para) msgid ""When authentication is provided via username and password, the Identity Service does not enforce policies on password strength, expiration, or failed authentication attempts as recommended by NIST Special Publication 800-118 (draft). Organizations that desire to enforce stronger password policies should consider using Keystone Identity Service Extensions or external authentication services."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:27(para) msgid ""LDAP simplifies integration of Identity authentication into an organization's existing directory service and user account management processes."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:28(para) msgid ""Authentication and authorization policy in OpenStack may be delegated to an external LDAP server. A typical use case is an organization that seeks to deploy a private cloud and already has a database of employees, the users. This may be in an LDAP system. Using LDAP as a source of authority authentication, requests to Identity Service are delegated to the LDAP service, which will authorize or deny requests based on locally set policies. A token is generated on successful authentication."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:29(para) msgid ""Note that if the LDAP system has attributes defined for the user such as admin, finance, HR etc, these must be mapped into roles and groups within Identity for use by the various OpenStack services. The <emphasis>etc/keystone.conf</emphasis> file provides the mapping from the LDAP attributes to Identity attributes."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:30(para) msgid ""The Identity Service <emphasis role=\""bold\"">MUST NOT</emphasis> be allowed to write to LDAP services used for authentication outside of the OpenStack deployment as this would allow a sufficiently privileged keystone user to make changes to the LDAP directory. This would allow privilege escalation within the wider organization or facilitate unauthorized access to other information and resources. In such a deployment, user provisioning would be out of the realm of the OpenStack deployment."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:32(para) msgid ""There is an <link href=\""https://bugs.launchpad.net/ossn/+bug/1168252\"">OpenStack Security Note (OSSN) regarding keystone.conf permissions</link>."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:33(para) msgid ""There is an <link href=\""https://bugs.launchpad.net/ossn/+bug/1155566\"">OpenStack Security Note (OSSN) regarding potential DoS attacks</link>."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:37(title) msgid ""External Authentication Methods"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:38(para) msgid ""Organizations may desire to implement external authentication for compatibility with existing authentication services or to enforce stronger authentication policy requirements. Although passwords are the most common form of authentication, they can be compromised through numerous methods, including keystroke logging and password compromise. External authentication services can provide alternative forms of authentication that minimize the risk from weak passwords."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:39(para) msgid ""These include:"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:41(para) msgid ""Password Policy Enforcement: Requires user passwords to conform to minimum standards for length, diversity of characters, expiration, or failed login attempts."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:44(para) msgid ""Multi-factor authentication: The authentication service requires the user to provide information based on something they have, such as a one-time password token or X.509 certificate, and something they know, such as a password."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:51(para) msgid ""Kerberos"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:57(title) msgid ""Authorization"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:58(para) msgid ""The Identity Service supports the notion of groups and roles. Users belong to groups. A group has a list of roles. OpenStack services reference the roles of the user attempting to access the service. The OpenStack policy enforcer middleware takes into consideration the policy rule associated with each resource and the user's group/roles and tenant association to determine if he/she has access to the requested resource."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:59(para) msgid ""The Policy enforcement middleware enables fine-grained access control to OpenStack resources. Only admin users can provision new users and have access to various management functionality. The cloud tenant would be able to only spin up instances, attach volumes, etc."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:61(title) msgid ""Establish Formal Access Control Policies"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:62(para) msgid ""Prior to configuring roles, groups, and users, document your required access control policies for the OpenStack installation. The policies should be consistent with any regulatory or legal requirements for the organization. Future modifications to access control configuration should be done consistently with the formal policies. The policies should include the conditions and processes for creating, deleting, disabling, and enabling accounts, and for assigning privileges to the accounts. Periodically review the policies and ensure that configuration is in compliance with approved policies."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:65(title) msgid ""Service Authorization"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:66(para) msgid ""As described in the <link href=\""http://docs.openstack.org/admin-guide-cloud/content/index.html\""><citetitle>OpenStack Cloud Administrator Guide</citetitle></link>, cloud administrators must define a user for each service, with a role of Admin. This service user account provides the service with the authorization to authenticate users."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:67(para) msgid ""The Compute and Object Storage services can be configured to use either the \""tempAuth\"" file or Identity Service to store authentication information. The \""tempAuth\"" solution MUST NOT be deployed in a production environment since it stores passwords in plain text."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:68(para) msgid ""The Identity Service supports client authentication for SSL which may be enabled. SSL client authentication provides an additional authentication factor, in addition to the username / password, that provides greater reliability on user identification. It reduces the risk of unauthorized access when user names and passwords may be compromised. However, there is additional administrative overhead and cost to issue certificates to users that may not be feasible in every deployment."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:78(para) msgid ""We recommend that you use client authentication with SSL for the authentication of services to the Identity Service."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:80(para) msgid ""The cloud administrator should protect sensitive configuration files for unauthorized modification. This can be achieved with mandatory access control frameworks such as SELinux, including <literal>/etc/keystone.conf</literal> and X.509 certificates."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:82(para) msgid ""For client authentication with SSL, you need to issue certificates. These certificates can be signed by an external authority or by the cloud administrator. OpenStack services by default check the signatures of certificates and connections fail if the signature cannot be checked. If the administrator uses self-signed certificates, the check might need to be disabled. To disable these certificates, set <code>insecure=False</code> in the <code>[filter:authtoken]</code> section in the <filename>/etc/nova/api.paste.ini</filename> file. This setting also disables certificates for other components."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:96(title) msgid ""Administrative Users"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:97(para) msgid ""We recommend that admin users authenticate using Identity Service and an external authentication service that supports 2-factor authentication, such as a certificate. This reduces the risk from passwords that may be compromised. This recommendation is in compliance with NIST 800-53 IA-2(1) guidance in the use of multi factor authentication for network access to privileged accounts."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:106(title) msgid ""End Users"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:107(para) msgid ""The Identity Service can directly provide end-user authentication, or can be configured to use external authentication methods to conform to an organization's security policies and requirements."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:111(title) msgid ""Policies"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:112(para) msgid ""Each OpenStack service has a policy file in json format, called <emphasis role=\""bold\"">policy.json</emphasis>. The policy file specifies rules, and the rule that governs each resource. A resource could be API access, the ability to attach to a volume, or to fire up instances."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:113(para) msgid ""The policies can be updated by the cloud administrator to further control access to the various resources. The middleware could also be further customized. Note that your users must be assigned to groups/roles that you refer to in your policies."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:114(para) msgid ""Below is a snippet of the Block Storage service policy.json file."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:133(para) msgid ""Note the <emphasis role=\""bold\"">default</emphasis> rule specifies that the user must be either an admin or the owner of the volume. It essentially says only the owner of a volume or the admin may create/delete/update volumes. Certain other operations such as managing volume types are accessible only to admin users."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:136(title) msgid ""Tokens"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:137(para) msgid ""Once a user is authenticated, a token is generated and used internally in OpenStack for authorization and access. The default token <emphasis role=\""bold\"">lifespan</emphasis> is<emphasis role=\""bold\""> 24 hours</emphasis>. It is recommended that this value be set lower but caution needs to be taken as some internal services will need sufficient time to complete their work. The cloud may not provide services if tokens expire too early. An example of this would be the time needed by the Compute Service to transfer a disk image onto the hypervisor for local caching."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:138(para) msgid ""The following example shows a PKI token. Note that, in practice, the token id value is about 3500 bytes. We shorten it in this example."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:153(para) msgid ""Note that the token is often passed within the structure of a larger context of an Identity Service response. These responses also provide a catalog of the various OpenStack services. Each service is listed with its name, access endpoints for internal, admin, and public access."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:154(para) msgid ""The Identity Service supports token revocation. This manifests as an API to revoke a token, to list revoked tokens and individual OpenStack services that cache tokens to query for the revoked tokens and remove them from their cache and append the same to their list of cached revoked tokens."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:157(title) msgid ""Future"" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:158(para) msgid ""Domains are high-level containers for projects, users and groups. As such, they can be used to centrally manage all Keystone-based identity components. With the introduction of account Domains, server, storage and other resources can now be logically grouped into multiple Projects (previously called Tenants) which can themselves be grouped under a master account-like container. In addition, multiple users can be managed within an account Domain and assigned roles that vary for each Project."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:159(para) msgid ""Keystone's V3 API supports multiple domains. Users of different domains may be represented in different authentication backends and even have different attributes that must be mapped to a single set of roles and privileges, that are used in the policy definitions to access the various service resources."" msgstr """" #: ./doc/security-guide/ch024_authentication.xml:160(para) msgid ""Where a rule may specify access to only admin users and users belonging to the tenant, the mapping may be trivial. In other scenarios the cloud administrator may need to approve the mapping routines per tenant."" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:9(title) msgid ""Case Studies: Management Interfaces"" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:10(para) msgid ""Previously we discussed typical OpenStack management interfaces and associated backplane issues. We will now approach these issues by returning to our Alice and Bob case study. Specifically, we will look into how both Alice and Bob will address:"" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:16(para) msgid ""Cloud Administration"" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:19(para) msgid ""Self Service"" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:22(para) msgid ""Data Replication &amp; Recovery"" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:25(para) msgid ""SLA &amp; Security Monitoring."" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:30(para) msgid ""When building her private cloud, while air-gapped, Alice still needs to consider her service management interfaces. Before deploying her private cloud, Alice has completed her system documentation. Specifically she has identified which OpenStack services will exist in each security domain. From there Alice has further restricted access to management interfaces by deploying a combination of IDS, SSL encryption, and physical network isolation. Additionally, Alice requires high availability and redundant services. Thus, Alice sets up redundant infrastructure for various OpenStack API services."" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:31(para) msgid ""Alice also needs to provide assurances that the physical servers and hypervisors have been built from a known secure state into a well-defined configuration. To enable this, Alice uses a combination of a Configuration Management platform to configure each machine according to the standards and regulations she must comply with. It will also enable Alice to report periodically on the state of her cloud and perform remediation to a known state should anything be out of the ordinary. Additionally, Alice provides hardware assurances by using a PXE system to build her nodes from a known set of base images. During the boot process, Alice provides further assurances by enabling Intel TXT and related trusted boot technologies provided by the hardware."" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:35(para) msgid ""As a public cloud provider, Bob is concerned with both the continuous availability of management interfaces and the security of transactions to the management interfaces. To that end Bob implements multiple redundant OpenStack API endpoints for the services his cloud will run. Additionally on the public network Bob uses SSL to encrypt all transactions between his customers and his cloud interfaces. To isolate his cloud operations Bob has physically isolated his management, instance migration, and storage networks."" msgstr """" #: ./doc/security-guide/ch015_case-studies-management.xml:36(para) msgid ""To ease scaling and reduce management overhead Bob implements a configuration management system. For customer data assurances, Bob offers a backup as a service product as requirements will vary between customers. Finally, Bob does not provide a \""baremetal\"" or the ability to schedule an entire node, so to reduce management overhead and increase operational efficiency Bob does not implement any node boot time security."" msgstr """" #: ./doc/security-guide/ch018_case-studies-pkissl.xml:3(title) msgid ""Case Studies: PKI and Certificate Management"" msgstr """" #: ./doc/security-guide/ch018_case-studies-pkissl.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address deployment of PKI certification authorities (CA) and certificate management."" msgstr """" #: ./doc/security-guide/ch018_case-studies-pkissl.xml:7(para) msgid ""Alice as a cloud architect within a government agency knows that her agency operates its own certification authority. Alice contacts the PKI office in her agency that manages her PKI and certificate issuance. Alice obtains certificates issued by this CA and configures the services within both the public and management security domains to use these certificates. Since Alice's OpenStack deployment exists entirely on a disconnected from the Internet network, she makes sure to remove all default CA bundles that contain external public CA providers to ensure the OpenStack services only accept client certificates issued by her agency's CA."" msgstr """" #: ./doc/security-guide/ch018_case-studies-pkissl.xml:11(para) msgid ""Bob is architecting a public cloud and needs to ensure that the publicly facing OpenStack services are using certificates issued by a major public CA. Bob acquires certificates for his public OpenStack services and configures the services to use PKI and SSL and includes the public CAs in his trust bundle for the services. Additionally, Bob also wants to further isolate the internal communications amongst the services within the management security domain. Bob contacts the team within his organization that is responsible for managing his organizations PKI and issuance of certificates using their own internal CA. Bob obtains certificates issued by this internal CA and configures the services that communicate within the management security domain to use these certificates and configures the services to only accept client certificates issued by his internal CA."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch031_neutron-architecture.xml:24(None) ./doc/security-guide/ch031_neutron-architecture.xml:27(None) msgid ""@@image: 'static/sdn-connections.png'; md5=3fb0f3e2bea0784fea8832526d2b2832"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch031_neutron-architecture.xml:36(None) ./doc/security-guide/ch031_neutron-architecture.xml:39(None) msgid ""@@image: 'static/1aa-network-domains-diagram.png'; md5=57ae4448b05a3852180f75f3995711b9"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:3(title) msgid ""Networking Architecture"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:4(para) msgid ""OpenStack Networking is a standalone service that often involves deploying several processes across a number of nodes. These processes interact with each other and with other OpenStack services. The main process of the OpenStack Networking service is neutron-server, a Python daemon that exposes the OpenStack Networking API and passes tenant requests to a suite of plugins for additional processing."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:5(para) msgid ""OpenStack Networking components encompasses the following elements:"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:7(para) msgid ""<emphasis role=\""bold\"">neutron server</emphasis> (<literal>neutron-server</literal> and <literal>neutron-*-plugin</literal>): This service runs on the network node to service the Networking API and its extensions. It also enforces the network model and IP addressing of each port. The neutron-server and plugin agents require access to a database for persistent storage and access to a message queue for inter-communication."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:10(para) msgid ""<emphasis role=\""bold\"">plugin agent</emphasis> (<literal>neutron-*-agent</literal>): Runs on each compute node to manage local virtual switch (vswitch) configuration. The agents to be run will depend on which plugin you are using. This service requires message queue access. <emphasis>Optional depending on plugin.</emphasis>"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:13(para) msgid ""<emphasis role=\""bold\"">DHCP agent</emphasis> (<literal>neutron-dhcp-agent</literal>): Provides DHCP services to tenant networks. This agent is the same across all plugins and is responsible for maintaining DHCP configuration. The neutron-dhcp-agent requires message queue access."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:16(para) msgid ""<emphasis role=\""bold\"">l3 agent</emphasis> (<literal>neutron-l3-agent</literal>): Provides L3/NAT forwarding for external network access of VMs on tenant networks. Requires message queue access. <emphasis>Optional depending on plugin.</emphasis>"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:19(para) msgid ""<emphasis role=\""bold\"">network provider services</emphasis> (SDN server/services). Provide additional networking services that are provided to tenant networks. These SDN services may interact with the neutron-server, neutron-plugin, and/or plugin-agents via REST APIs or other communication channels."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:22(para) msgid ""The figure that follows provides an architectural and networking flow diagram of the OpenStack Networking components:"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:31(title) msgid ""OS Networking Service placement on Physical Servers"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:32(para) msgid ""In this guide, we focus primarily on a standard architecture that includes a <emphasis>cloud controller</emphasis> host, a <emphasis>network</emphasis> host, and a set of <emphasis>compute</emphasis> hypervisors for running VMs."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:34(title) msgid ""Network Connectivity of Physical Servers"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:42(para) msgid ""A standard OpenStack Networking setup has up to four distinct physical data center networks:"" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:44(para) msgid ""<emphasis role=\""bold\"">Management network</emphasis> Used for internal communication between OpenStack Components. The IP addresses on this network should be reachable only within the data center and is considered the Management Security Domain."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:47(para) msgid ""<emphasis role=\""bold\"">Guest network</emphasis> Used for VM data communication within the cloud deployment. The IP addressing requirements of this network depend on the OpenStack Networking plugin in use and the network configuration choices of the virtual networks made by the tenant. This network is considered the Guest Security Domain."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:50(para) msgid ""<emphasis role=\""bold\"">External network</emphasis> Used to provide VMs with Internet access in some deployment scenarios. The IP addresses on this network should be reachable by anyone on the Internet and is considered to be in the Public Security Domain."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:53(para) msgid ""<emphasis role=\""bold\"">API network</emphasis> Exposes all OpenStack APIs, including the OpenStack Networking API, to tenants. The IP addresses on this network should be reachable by anyone on the Internet. This may be the same network as the external network, as it is possible to create a subnet for the external network that uses IP allocation ranges to use only less than the full range of IP addresses in an IP block. This network is considered the Public Security Domain."" msgstr """" #: ./doc/security-guide/ch031_neutron-architecture.xml:56(para) msgid ""For additional information see the <link href=\""http://docs.openstack.org/admin-guide-cloud/content/ch_networking.html\"">Networking chapter</link> in the <citetitle>OpenStack Cloud Administrator Guide</citetitle>."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:3(title) msgid ""Data Encryption"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:4(para) msgid ""The option exists for implementors to encrypt tenant data wherever it is stored on disk or transported over a network. This is above and beyond the general recommendation that users encrypt their own data before sending it to their provider."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:5(para) msgid ""The importance of encrypting data on behalf of tenants is largely related to the risk assumed by a provider that an attacker could access tenant data. There may be requirements here in government, as well as requirements per-policy, in private contract, or even in case law in regard to private contracts for public cloud providers. It is recommended that a risk assessment and legal consul advised before choosing tenant encryption policies."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:6(para) msgid ""Per-instance or per-object encryption is preferable over, in descending order, over per-project, per-tenant, per-host, and per-cloud aggregations. This recommendation is inverse to the complexity and difficulty of implementation. Presently, in some projects it is difficult or impossible to implement encryption as loosely granular as even per-tenant. We recommend implementors make a best-effort in encrypting tenant data."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:7(para) msgid ""Often, data encryption relates positively to the ability to reliably destroy tenant and per-instance data, simply by throwing away the keys. It should be noted that in doing so, it becomes of great importance to destroy those keys in a reliable and secure manner."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:8(para) msgid ""Opportunities to encrypt data for users are present:"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:10(para) msgid ""Object Storage objects"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:13(para) msgid ""Block Storage volumes &amp; Instance Ephemeral Filesystems"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:16(para) msgid ""Network data"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:20(title) msgid ""Object Storage Objects"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:21(para) msgid ""The ability to encrypt objects in Object Storage is presently limited to disk-level encryption per node. However, there does exist third-party extensions and modules for per-object encryption. These modules have been proposed upstream, but have not per this writing been formally accepted. Below are some pointers: "" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:22(link) msgid ""https://github.com/Mirantis/swift-encrypt"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:23(link) msgid ""http://www.mirantis.com/blog/on-disk-encryption-prototype-for-openstack-swift/"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:26(title) msgid ""Block Storage Volumes &amp; Instance Ephemeral Filesystems"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:27(para) msgid ""The ability to encrypt volumes depends on the service backends chosen. Some backends may not support this at all."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:28(para) msgid ""As both block storage and compute support LVM backed storage, we can easily provide an example applicable to both systems. In deployments using LVM, encryption may be performed against the backing physical volumes. An encrypted block device would be created using the standard Linux tools, with the LVM physical volume (PV) created on top of the decrypted block device using pvcreate. Then, the vgcreate or vgmodify tool may be used to add the encrypted physical volume to an LVM volume group (VG)."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:29(para) msgid ""A feature aimed for the Havana release provides encryption of the VM's data before it is written to disk. This allows the privacy of data to be maintained while residing on the storage device. The idea is similar to how self-encrypting drives work. This feature presents a normal block storage device to the VM but encrypts the bytes in the virtualization host before writing them to the disk. The block server operates exactly as it does when reading and writing unencrypted blocks, except special handling will be required for Block Storage features such as snapshots and live migration. Note that this feature uses an independent key manager."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:32(title) msgid ""Network Data"" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:33(para) msgid ""Tenant data for compute could be encrypted over IPSec or other tunnels. This is not functionality common or standard in OpenStack, but is an option available to motivated and interested implementors."" msgstr """" #: ./doc/security-guide/ch047_data-encryption.xml:37(para) msgid ""Block storage supports a variety of mechanisms for supplying mountable volumes. It is outside the scope of this guide to specify recommendations for each Block Storage backend driver. For the purpose of performance, many storage protocols are unencrypted. Some protocols such as iSCSI can provide authentication and encrypted sessions, it is our recommendation to enable these features."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch005_security-domains.xml:24(None) ./doc/security-guide/ch005_security-domains.xml:27(None) msgid ""@@image: 'static/untrusted_trusted.png'; md5=a582dac2ad0b3f439fd4b08386853056"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch005_security-domains.xml:55(None) ./doc/security-guide/ch005_security-domains.xml:58(None) msgid ""@@image: 'static/bridging_security_domains_1.png'; md5=0d5ca26c51882ce3253405e91a597715"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch005_security-domains.xml:63(None) ./doc/security-guide/ch005_security-domains.xml:66(None) msgid ""@@image: 'static/bridging_domains_clouduser.png'; md5=17c8a233ee7de17d2f600c7f6f6afe24"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch005_security-domains.xml:95(None) ./doc/security-guide/ch005_security-domains.xml:98(None) msgid ""@@image: 'static/threat_actors.png'; md5=114c2f9bd9d0319bdd83f9e229d44649"" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch005_security-domains.xml:116(None) ./doc/security-guide/ch005_security-domains.xml:119(None) msgid ""@@image: 'static/high-capability.png'; md5=b7ab599c8b40558a52c0ca86aad89741"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:3(title) msgid ""Security Boundaries and Threats"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:4(para) msgid ""A cloud can be abstracted as a collection of logical components by virtue of their function, users, and shared security concerns, which we call security domains. Threat actors and vectors are classified based on their motivation and access to resources. Our goal is to provide you a sense of the security concerns with respect to each domain depending on your risk/vulnerability protection objectives."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:6(title) msgid ""Security Domains"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:7(para) msgid ""A security domain comprises users, applications, servers or networks that share common trust requirements and expectations within a system. Typically they have the same authentication and authorization (AuthN/Z) requirements and users."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:8(para) msgid ""Although you may desire to break these domains down further (we later discuss where this may be appropriate), we generally refer to four distinct security domains which form the bare minimum that is required to deploy any OpenStack cloud securely. These security domains are:"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:10(para) ./doc/security-guide/ch005_security-domains.xml:31(title) msgid ""Public"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:13(para) ./doc/security-guide/ch005_security-domains.xml:36(title) msgid ""Guest"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:16(para) ./doc/security-guide/ch005_security-domains.xml:41(title) msgid ""Management"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:19(para) ./doc/security-guide/ch005_security-domains.xml:46(title) msgid ""Data"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:22(para) msgid ""We selected these security domains because they can be mapped independently or combined to represent the majority of the possible areas of trust within a given OpenStack deployment. For example, some deployment topologies combine both guest and data domains onto one physical network versus others, which have these networks physically separated. In each case, the cloud operator should be aware of the appropriate security concerns. Security domains should be mapped out against your specific OpenStack deployment topology. The domains and their trust requirements depend upon whether the cloud instance is public, private, or hybrid."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:32(para) msgid ""The public security domain is an entirely untrusted area of the cloud infrastructure. It can refer to the Internet as a whole or simply to networks over which you have no authority. Any data that transits this domain with confidentiality or integrity requirements should be protected using compensating controls."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:33(para) msgid ""This domain should always be considered <emphasis>untrusted</emphasis>."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:37(para) msgid ""Typically used for compute instance-to-instance traffic, the guest security domain handles compute data generated by instances on the cloud but not services that support the operation of the cloud, such as API calls."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:38(para) msgid ""Public cloud providers and private cloud providers who do not have stringent controls on instance use or who allow unrestricted internet access to VMs should consider this domain to be <emphasis>untrusted</emphasis>. Private cloud providers may want to consider this network as internal and therefore <emphasis>trusted</emphasis> only if they have controls in place to assert that they trust instances and all their tenants."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:42(para) msgid ""The management security domain is where services interact. Sometimes referred to as the \""control plane\"", the networks in this domain transport confidential data such as configuration parameters, usernames, and passwords. Command and Control traffic typically resides in this domain, which necessitates strong integrity requirements. Access to this domain should be highly restricted and monitored. At the same time, this domain should still employ all of the security best practices described in this guide."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:43(para) msgid ""In most deployments this domain is considered <emphasis>trusted</emphasis>. However, when considering an OpenStack deployment, there are many systems that bridge this domain with others, potentially reducing the level of trust you can place on this domain. See <xref linkend=\""ch005_security-domains-idp61360\""/> for more information."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:47(para) msgid ""The data security domain is concerned primarily with information pertaining to the storage services within OpenStack. Much of the data that crosses this network has high integrity and confidentiality requirements and depending on the type of deployment there may also be strong availability requirements."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:48(para) msgid ""The trust level of this network is heavily dependent on deployment decisions and as such we do not assign this any default level of trust."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:52(title) msgid ""Bridging Security Domains"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:53(para) msgid ""A <emphasis>bridge</emphasis> is a component that exists inside more than one security domain. Any component that bridges security domains with different trust levels or authentication requirements must be carefully configured. These bridges are often the weak points in network architecture. A bridge should always be configured to meet the security requirements of the highest trust level of any of the domains it is bridging. In many cases the security controls for bridges should be a primary concern due to the likelihood of attack."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:61(para) msgid ""The diagram above shows a compute node bridging the data and management domains, as such the compute node should be configured to meet the security requirements of the management domain. Similarly the API Endpoint in this diagram is bridging the untrusted public domain and the management domain, and should be configured to protect against attacks from the public domain propagating through to the management domain."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:69(para) msgid ""In some cases deployers may want to consider securing a bridge to a higher standard than any of the domains in which it resides. Given the above example of an API endpoint, an adversary could potentially target the API endpoint from the public domain, leveraging it in the hopes of compromising or gaining access to the management domain."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:70(para) msgid ""The design of OpenStack is such that separation of security domains is difficult - as core services will usually bridge at least two domains, special consideration must be given when applying security controls to them."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:73(title) msgid ""Threat Classification, Actors and Attack Vectors"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:74(para) msgid ""Most types of cloud deployment, public or private, are exposed to some form of attack. In this chapter we categorize attackers and summarize potential types of attacks in each security domain."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:76(title) msgid ""Threat Actors"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:77(para) msgid ""A threat actor is an abstract way to refer to a class of adversary that you may attempt to defend against. The more capable the actor, the more expensive the security controls that are required for successful attack mitigation and prevention. Security is a tradeoff between cost, usability and defense. In some cases it will not be possible to secure a cloud deployment against all of the threat actors we describe here. Those deploying an OpenStack cloud will have to decide where the balance lies for their deployment / usage."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:79(para) msgid ""<emphasis role=\""bold\"">Intelligence Services</emphasis>  Considered by this guide as the most capable adversary. Intelligence Services and other state actors can bring tremendous resources to bear on a target. They have capabilities beyond that of any other actor. It is very difficult to defend against these actors without incredibly stringent controls in place, both human and technical."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:82(para) msgid ""<emphasis role=\""bold\"">Serious Organized Crime</emphasis>  Highly capable and financially driven groups of attackers. Able to fund in-house exploit development and target research. In recent years the rise of organizations such as the Russian Business Network, a massive cyber-criminal enterprise has demonstrated how cyber attacks have become a commodity. Industrial espionage falls within the SOC group."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:85(para) msgid ""<emphasis role=\""bold\"">Highly Capable Groups</emphasis>  This refers to 'Hacktivist' type organizations who are not typically commercially funded but can pose a serious threat to service providers and cloud operators."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:88(para) msgid ""<emphasis role=\""bold\"">Motivated Individuals</emphasis>  Acting alone, these attackers come in many guises, such as rogue or malicious employees, disaffected customers, or small-scale industrial espionage."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:91(para) msgid ""<emphasis role=\""bold\"">Script Kiddies</emphasis>  Automated vulnerability scanning/exploitation. Non-targeted attacks. Often only a nuisance, compromise by one of these actors presents a major risk to an organization's reputation."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:103(title) msgid ""Public / Private Considerations"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:104(para) msgid ""Private clouds are typically deployed by enterprises or institutions inside their networks and behind their firewalls. Enterprises will have strict policies on what data is allowed to exit their network and may even have different clouds for specific purposes. Users of a private cloud are typically employees of the organization that owns the cloud and are able to be held accountable for their actions. Employees often attend training sessions before accessing the cloud and will likely take part in regular scheduled security awareness training. Public clouds by contrast cannot make any assertions about their users, cloud use-cases or user motivations. This immediately pushes the guest security domain into a completely <emphasis>untrusted</emphasis> state for public cloud providers."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:105(para) msgid ""A notable difference in the attack surface of public clouds is that they must provide internet access to their services. Instance connectivity, access to files over the internet and the ability to interact with the cloud controlling fabric such as the API endpoints and dashboard are must-haves for the public cloud."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:106(para) msgid ""Privacy concerns for public and private cloud users are typically diametrically opposed. The data generated and stored in private clouds is normally owned by the operator of the cloud, who is able to deploy technologies such as data loss prevention (DLP) protection, file inspection, deep packet inspection and prescriptive firewalling. In contrast, privacy is one of the primary barriers to adoption for the public cloud, as many of these controls do not exist."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:109(title) msgid ""Outbound attacks and reputational risk"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:110(para) msgid ""Careful consideration should be given to potential outbound abuse from a cloud deployment. Whether public or private, clouds tend to have lots of resource available. An attacker who has established a point of presence within the cloud, either through hacking in or via entitled access (rogue employee), can bring these resources to bear against the internet at large. Clouds with compute services make for ideal DDoS and brute force engines. This is perhaps a more pressing issue for public clouds as their users are largely unaccountable, and can quickly spin up numerous disposable instances for outbound attacks. Major damage can be inflicted upon a company's reputation if it becomes known for hosting malicious software or launching attacks on other networks. Methods of prevention include egress security groups, outbound traffic inspection, customer education and awareness, and fraud and abuse mitigation strategies."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:113(title) msgid ""Attack Types"" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:114(para) msgid ""The diagram shows the types of attacks that may be expected from the actors described in the previous section. Note that there will always be exceptions to this diagram but in general, this describes the sorts of attack that could be typical for each actor."" msgstr """" #: ./doc/security-guide/ch005_security-domains.xml:122(para) msgid ""The prescriptive defense for each form of attack is beyond the scope of this document. The above diagram can assist you in making an informed decision about which types of threats, and threat actors, should be protected against. For commercial public cloud deployments this might include prevention against serious crime. For those deploying private clouds for government use, more stringent protective mechanisms should be in place, including carefully protected facilities and supply chains. In contrast those standing up basic development or test environments will likely require less restrictive controls (middle of the spectrum)."" msgstr """" #: ./doc/security-guide/ch035_case-studies-networking.xml:3(title) msgid ""Case Studies: Networking"" msgstr """" #: ./doc/security-guide/ch035_case-studies-networking.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would address providing networking services to the user."" msgstr """" #: ./doc/security-guide/ch035_case-studies-networking.xml:7(para) msgid ""A key objective of Alice's cloud is to integrate with the existing auth services and security resources. The key design parameters for this private cloud are a limited scope of tenants, networks and workload type. This environment can be designed to limit what available network resources are available to the tenant and what are the various default quotas and security policies are available. The network policy engine can be modified to restrict creation and changes to network resources. In this environment, Alice might want to leverage nova-network in the application of security group polices on a per instance basis vs. Neutron's application of security group polices on a per port basis. L2 isolation in this environment would leverage VLAN tagging. The use of VLAN tags will allow great visibility of tenant traffic by leveraging existing features and tools of the physical infrastructure."" msgstr """" #: ./doc/security-guide/ch035_case-studies-networking.xml:25(para) msgid ""A major business driver for Bob is to provide an advanced networking services to his customers. Bob's customers would like to deploy multi-tiered application stacks. This multi-tiered application are either existing enterprise application or newly deployed applications. Since Bob's public cloud is a multi-tenancy enterprise service, the choice to use for L2 isolation in this environment is to use overlay networking. Another aspect of Bob's cloud is the self-service aspect where the customer can provision available networking services as needed. These networking services encompass L2 networks, L3 Routing, Network <glossterm>ACL</glossterm> and NAT. It is important that per-tenant quota's be implemented in this environment."" msgstr """" #: ./doc/security-guide/ch035_case-studies-networking.xml:38(para) msgid ""An added benefit with utilizing OpenStack Networking is when new advanced networking services become available, these new features can be easily provided to the end customers."" msgstr """" #: ./doc/security-guide/ch011_management-introduction.xml:3(title) msgid ""Management Introduction"" msgstr """" #: ./doc/security-guide/ch011_management-introduction.xml:4(para) msgid ""A cloud deployment is a living system. Machines age and fail, software becomes outdated, vulnerabilities are discovered. When errors or omissions are made in configuration, or when software fixes must be applied, these changes must be made in a secure, but convenient, fashion. These changes are typically solved through configuration management."" msgstr """" #: ./doc/security-guide/ch011_management-introduction.xml:5(para) msgid ""Likewise, it is important to protect the cloud deployment from being configured or manipulated by malicious entities. With many systems in a cloud employing compute and networking virtualization, there are distinct challenges applicable to OpenStack which must be addressed through integrity lifecycle management."" msgstr """" #: ./doc/security-guide/ch011_management-introduction.xml:6(para) msgid ""Finally, administrators must perform command and control over the cloud for various operational functions. It is important these command and control facilities are understood and secured."" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:3(title) msgid ""Case Studies: Tenant Data"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:4(para) msgid ""Returning to Alice and Bob, we will use this section to dive into their particular tenant data privacy requirements. Specifically, we will look into how Alice and Bob both handle tenant data, data destruction, and data encryption."" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:7(para) msgid ""As stated during the introduction to Alice's case study, data protection is of an extremely high priority. She needs to ensure that a compromise of one tenant's data does not cause loss of other tenant data. She also has strong regulator requirements that require documentation of data destruction activities. Alice does this using the following:"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:15(para) msgid ""Establishing procedures to sanitize tenant data when a program or project ends"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:16(para) msgid ""Track the destruction of both the tenant data and metadata via ticketing in a CMDB"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:17(para) ./doc/security-guide/ch049_case-studies-tenant-data.xml:28(para) msgid ""For Volume storage:"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:18(para) ./doc/security-guide/ch049_case-studies-tenant-data.xml:29(para) msgid ""Physical Server Issues"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:19(para) msgid ""To provide secure ephemeral instance storage, Alice implements qcow2 files on an encrypted filesystem."" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:24(para) msgid ""As stated during the introduction to Bob's case study, tenant privacy is of an extremely high priority. In addition to the requirements and actions Bob will take to isolate tenants from one another at the infrastructure layer, Bob also needs to provide assurances for tenant data privacy. Bob does this using the following:"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:26(para) msgid ""Establishing procedures to sanitize customer data when a customer churns"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:27(para) msgid ""Track the destruction of both the customer data and metadata via ticketing in a CMDB"" msgstr """" #: ./doc/security-guide/ch049_case-studies-tenant-data.xml:30(para) msgid ""To provide secure ephemeral instance storage, Bob implements qcow2 files on an encrypted filesystems."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:3(title) msgid ""Case Studies: Instance Isolation"" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:4(para) msgid ""In this case study we discuss how Alice and Bob would ensure that their instances are properly isolated. First we consider hypervisor selection, and then techniques for hardening QEMU and applying mandatory access controls."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:7(para) msgid ""Alice chooses Xen for the hypervisor in her cloud due to a strong internal knowledge base and a desire to use the Xen security modules (XSM) for fine-grained policy enforcement."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:8(para) msgid ""Alice is willing to apply a relatively large amount of resources to software packaging and maintenance. She will use these resources to build a highly customized version of QEMU that has many components removed, thereby reducing the attack surface. She will also ensure that all compiler hardening options are enabled for QEMU. Alice accepts that these decisions will increase long-term maintenance costs."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:9(para) msgid ""Alice writes XSM policies (for Xen) and SELinux policies (for Linux domain 0, and device domains) to provide stronger isolation between the instances. Alice also uses the Intel TXT support in Xen to measure the hypervisor launch in the TPM."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:13(para) msgid ""Bob is very concerned about instance isolation since the users in a public cloud represent anyone with a credit card, meaning they are inherently untrusted. Bob has just started hiring the team that will deploy the cloud, so he can tailor his candidate search for specific areas of expertise. With this in mind, Bob chooses a hypervisor based on its technical features, certifications, and community support. KVM has an EAL 4+ common criteria rating, with a layered security protection profile (LSPP) to provide added assurance for instance isolation. This, combined with the strong support for KVM within the OpenStack community drives Bob's decision to use KVM."" msgstr """" #: ./doc/security-guide/ch053_case-studies-instance-isolation.xml:14(para) msgid ""Bob weighs the added cost of repackaging QEMU and decides that he cannot commit those resources to the project. Fortunately, his Linux distribution has already enabled the compiler hardening options. So he decides to use this QEMU package. Finally, Bob leverages sVirt to manage the SELinux polices associated with the virtualization stack."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:3(title) msgid ""Networking Services Security Best Practices"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:4(para) msgid ""This section discusses OpenStack Networking configuration best practices as they apply to tenant network security within your OpenStack deployment."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:6(title) msgid ""Tenant Network Services Workflow"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:7(para) msgid ""OpenStack Networking provides users real self services of network resources and configurations. It is important that Cloud Architects and Operators evaluate their design use cases in providing users the ability to create, update, and destroy available network resources."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:10(title) msgid ""Networking Resource Policy Engine"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:11(para) msgid ""A policy engine and its configuration file, <filename>policy.json</filename>, within OpenStack Networking provides a method to provide finer grained authorization of users on tenant networking methods and objects. It is important that cloud architects and operators evaluate their design and use cases in providing users and tenants the ability to create, update, and destroy available network resources as it has a tangible effect on tenant network availability, network security, and overall OpenStack security. For a more detailed explanation of OpenStack Networking policy definition, please refer to the <link href=\""http://docs.openstack.org/admin-guide-cloud/content/section_auth.html\"">Authentication and authorization section</link> in the <citetitle>OpenStack Cloud Administrator Guide</citetitle>."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:25(address) msgid ""It is important to review the default networking resource policy and modify the policy appropriately for your security posture."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:26(para) msgid ""If your deployment of OpenStack provides multiple external access points into different security domains it is important that you limit the tenant's ability to attach multiple vNICs to multiple external access points -- this would bridge these security domains and could lead to unforeseen security compromise. It is possible mitigate this risk by utilizing the host aggregates functionality provided by OpenStack Compute or through splitting the tenant VMs into multiple tenant projects with different virtual network configurations."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:29(title) msgid ""Security Groups"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:30(para) msgid ""The OpenStack Networking Service provides security group functionality using a mechanism that is more flexible and powerful than the security group capabilities built into OpenStack Compute. Thus, when using OpenStack Networking, <emphasis>nova.conf</emphasis> should always disable built-in security groups and proxy all security group calls to the OpenStack Networking API. Failure to do so will result in conflicting security policies being simultaneously applied by both services. To proxy security groups to OpenStack Networking, use the following configuration values:"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:32(para) msgid ""firewall_driver : must be set to 'nova.virt.firewall.NoopFirewallDriver' so that <systemitem class=\""service\"">nova-compute</systemitem> does not perform iptables-based filtering itself."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:35(para) msgid ""security_group_api : must be set to 'neutron' so that all security group requests are proxied to the OpenStack Network Service."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:38(para) msgid ""Security groups and security group rules allow administrators and tenants the ability to specify the type of traffic and direction (ingress/egress) that is allowed to pass through a virtual interface port. A security group is a container for security group rules. When a virtual interface port is created in OpenStack Networking it is associated with a security group. If a security group is not specified, the port will be associated with a 'default' security group. By default this group will drop all ingress traffic and allow all egress. Rules can be added to this group in order to change the behaviour."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:39(para) msgid ""When using the security group API through OpenStack Compute, security groups are applied to all virtual interface ports on an instance. The reason for this is that OpenStack Compute security group APIs are instance based and not virtual interface port based as OpenStack Networking."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:42(title) msgid ""Quotas"" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:43(para) msgid ""Quotas provide the ability to limit the number of network resources available to tenants. You can enforce default quotas for all tenants."" msgstr """" #: ./doc/security-guide/ch034_tenant-secure-networking-best-practices.xml:70(para) msgid ""OpenStack Networking also supports per-tenant quotas limit via a quota extension API. To enable per-tenant quotas, you need to set <literal>quota_driver</literal> in <literal>neutron.conf</literal>."" msgstr """" #. When image changes, this message will be marked fuzzy or untranslated for you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/security-guide/ch052_devices.xml:131(None) ./doc/security-guide/ch052_devices.xml:134(None) msgid ""@@image: 'static/sVirt Diagram 1.png'; md5=ffcdbb45d9054670ad4c270a7c7d3925"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:3(title) msgid ""Hardening the Virtualization Layers"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:4(para) msgid ""In the beginning of this chapter we discuss the use of both physical and virtual hardware by instances, the associated security risks, and some recommendations for mitigating those risks. We conclude the chapter with a discussion of sVirt, an open source project for integrating SELinux mandatory access controls with the virtualization components."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:6(title) msgid ""Physical Hardware (PCI Passthrough)"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:7(para) msgid ""Many hypervisors offer a functionality known as PCI passthrough. This allows an instance to have direct access to a piece of hardware on the node. For example, this could be used to allow instances to access video cards offering the compute unified device architecture (CUDA) for high performance computation. This feature carries two types of security risks: direct memory access and hardware infection."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:8(para) msgid ""Direct memory access (DMA) is a feature that permits certain hardware devices to access arbitrary physical memory addresses in the host computer. Often video cards have this capability. However, an instance should not be given arbitrary physical memory access because this would give it full view of both the host system and other instances running on the same node. Hardware vendors use an input/output memory management unit (IOMMU) to manage DMA access in these situations. Therefore, cloud architects should ensure that the hypervisor is configured to utilize this hardware feature."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:10(para) msgid ""KVM: <link href=\""http://www.linux-kvm.org/page/How_to_assign_devices_with_VT-d_in_KVM\"">How to assign devices with VT-d in KVM</link>"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:13(para) msgid ""Xen: <link href=\""http://wiki.xen.org/wiki/VTd_HowTo\"">VTd Howto</link>"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:17(para) msgid ""The IOMMU feature is marketed as VT-d by Intel and AMD-Vi by AMD."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:19(para) msgid ""A hardware infection occurs when an instance makes a malicious modification to the firmware or some other part of a device. As this device is used by other instances, or even the host OS, the malicious code can spread into these systems. The end result is that one instance can run code outside of its security domain. This is a potential problem in any hardware sharing scenario. The problem is specific to this scenario because it is harder to reset the state of physical hardware than virtual hardware."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:20(para) msgid ""Solutions to the hardware infection problem are domain specific. The strategy is to identify how an instance can modify hardware state then determine how to reset any modifications when the instance is done using the hardware. For example, one option could be to re-flash the firmware after use. Clearly there is a need to balance hardware longevity with security as some firmwares will fail after a large number of writes. TPM technology, described in <literal>link:Management/Node Bootstrapping</literal>, provides a solution for detecting unauthorized firmware changes. Regardless of the strategy selected, it is important to understand the risks associated with this kind of hardware sharing so that they can be properly mitigated for a given deployment scenario."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:21(para) msgid ""Additionally, due to the risk and complexities associated with PCI passthrough, it should be disabled by default. If enabled for a specific need, you will need to have appropriate processes in place to ensure the hardware is clean before re-issue."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:24(title) msgid ""Virtual Hardware (QEMU)"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:25(para) msgid ""When running a virtual machine, virtual hardware is a software layer that provides the hardware interface for the virtual machine. Instances use this functionality to provide network, storage, video, and other devices that may be needed. With this in mind, most instances in your environment will exclusively use virtual hardware, with a minority that will require direct hardware access. The major open source hypervisors use QEMU for this functionality. While QEMU fills an important need for virtualization platforms, it has proven to be a very challenging software project to write and maintain. Much of the functionality in QEMU is implemented with low-level code that is difficult for most developers to comprehend. Furthermore, the hardware virtualized by QEMU includes many legacy devices that have their own set of quirks. Putting all of this together, QEMU has been the source of many security problems, including hypervisor breakout attacks."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:41(para) msgid ""For the reasons stated above, it is important to take proactive steps to harden QEMU. We recommend three specific steps: minimizing the code base, using compiler hardening, and using mandatory access controls, such as sVirt, SELinux, or AppArmor."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:47(title) msgid ""Minimizing the Qemu Code base"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:48(para) msgid ""One classic security principle is to remove any unused components from your system. QEMU provides support for many different virtual hardware devices. However, only a small number of devices are needed for a given instance. Most instances will use the virtio devices. However, some legacy instances will need access to specific hardware, which can be specified using glance metadata:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:54(para) msgid ""A cloud architect should decide what devices to make available to cloud users. Anything that is not needed should be removed from QEMU. This step requires recompiling QEMU after modifying the options passed to the QEMU configure script. For a complete list of up-to-date options simply run <literal>./configure --help</literal> from within the QEMU source directory. Decide what is needed for your deployment, and disable the remaining options."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:57(title) msgid ""Compiler Hardening"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:58(para) msgid ""The next step is to harden QEMU using compiler hardening options. Modern compilers provide a variety of compile time options to improve the security of the resulting binaries. These features, which we will describe in more detail below, include relocation read-only (RELRO), stack canaries, never execute (NX), position independent executable (PIE), and address space layout randomization (ASLR)."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:59(para) msgid ""Many modern linux distributions already build QEMU with compiler hardening enabled, so you may want to verify your existing executable before proceeding with the information below. One tool that can assist you with this verification is called <link href=\""http://www.trapkit.de/tools/checksec.html\""><literal>checksec.sh</literal></link>."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:61(para) msgid ""<emphasis>RELocation Read-Only (RELRO)</emphasis>: Hardens the data sections of an executable. Both full and partial RELRO modes are supported by gcc. For QEMU full RELRO is your best choice. This will make the global offset table read-only and place various internal data sections before the program data section in the resulting executable."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:64(para) msgid ""<emphasis>Stack Canaries</emphasis>: Places values on the stack and verifies their presence to help prevent buffer overflow attacks."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:67(para) msgid ""<emphasis>Never eXecute (NX)</emphasis>: Also known as Data Execution Prevention (DEP), ensures that data sections of the executable can not be executed."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:70(para) msgid ""<emphasis>Position Independent Executable (PIE)</emphasis>: Produces a position independent executable, which is necessary for ASLR. "" msgstr """" #: ./doc/security-guide/ch052_devices.xml:73(para) msgid ""<emphasis>Address Space Layout Randomization (ASLR)</emphasis> : This ensures that both code and data regions will be randomized. Enabled by the kernel (all modern linux kernels support ASLR), when the executable is built with PIE."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:76(para) msgid ""Putting this all together, and adding in some additional useful protections, we recommend the following compiler options for gcc when compiling QEMU:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:79(para) msgid ""We recommend testing your QEMU executable file after it is compiled to ensure that the compiler hardening worked properly."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:80(para) msgid ""Most cloud deployments will not want to build software such as QEMU by hand. It is better to use packaging to ensure that the process is repeatable and to ensure that the end result can be easily deployed throughout the cloud. The references below provide some additional details on applying compiler hardening options to existing packages."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:82(para) msgid ""DEB packages: <link href=\""http://wiki.debian.org/HardeningWalkthrough\"">Hardening Walkthrough</link>"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:85(para) msgid ""RPM packages: <link href=\""http://fedoraproject.org/wiki/How_to_create_an_RPM_package\"">How to create an RPM package</link>"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:91(para) msgid ""Compiler hardening makes it more difficult to attack the QEMU process. However, if an attacker does succeed, we would like to limit the impact of the attack. Mandatory access controls accomplish this by restricting the privileges on QEMU process to only what is needed. This can be accomplished using sVirt / SELinux or AppArmor. When using sVirt, SELinux is configured to run every QEMU process under a different security context. AppArmor can be configured to provide similar functionality. We provide more details on sVirt in the instance isolation section below."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:95(title) msgid ""sVirt: SELinux + Virtualization"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:96(para) msgid ""With unique kernel-level architecture and National Security Agency (NSA) developed security mechanisms, KVM provides foundational isolation technologies for multi tenancy. With developmental origins dating back to 2002, the Secure Virtualization (sVirt) technology is the application of SELinux against modern day virtualization. SELinux, which was designed to apply separation control based upon labels, has been extended to provide isolation between virtual machine processes, devices, data files and system processes acting upon their behalf."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:105(para) msgid ""OpenStack's sVirt implementation aspires to protect hypervisor hosts and virtual machines against two primary threat vectors:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:107(para) msgid ""<emphasis role=\""bold\"">Hypervisor threats</emphasis> A compromised application running within a virtual machine attacks the hypervisor to access underlying resources. For example, the host OS, applications, or devices within the physical machine. This is a threat vector unique to virtualization and represents considerable risk as the underlying real machine can be compromised due to vulnerability in a single virtual application."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:117(para) msgid ""<emphasis role=\""bold\"">Virtual Machine (multi-tenant) threats</emphasis> A compromised application running within a VM attacks the hypervisor to access/control another virtual machine and its resources. This is a threat vector unique to virtualization and represents considerable risk as a multitude of virtual machine file images could be compromised due to vulnerability in a single application. This virtual network attack is a major concern as the administrative techniques for protecting real networks do not directly apply to the virtual environment."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:129(para) msgid ""Each KVM-based virtual machine is a process which is labeled by SELinux, effectively establishing a security boundary around each virtual machine. This security boundary is monitored and enforced by the Linux kernel, restricting the virtual machine's access to resources outside of its boundary such as host machine data files or other VMs."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:137(para) msgid ""As shown above, sVirt isolation is provided regardless of the guest Operating System running inside the virtual machine -- Linux or Windows VMs can be used. Additionally, many Linux distributions provide SELinux within the operating system, allowing the virtual machine to protect internal virtual resources from threats. "" msgstr """" #: ./doc/security-guide/ch052_devices.xml:139(title) msgid ""Labels and Categories"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:140(para) msgid ""KVM-based virtual machine instances are labelled with their own SELinux data type, known as svirt_image_t. Kernel level protections prevent unauthorized system processes, such as malware, from manipulating the virtual machine image files on disk. When virtual machines are powered off, images are stored as svirt_image_t as shown below:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:146(para) msgid ""The svirt_image_t label uniquely identifies image files on disk, allowing for the SELinux policy to restrict access. When a KVM-based Compute image is powered on, sVirt appends a random numerical identifier to the image. sVirt is technically capable of assigning numerical identifiers to 524,288 virtual machines per hypervisor node, however OpenStack deployments are highly unlikely to encounter this limitation."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:147(para) msgid ""This example shows the sVirt category identifier:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:152(title) msgid ""Booleans"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:153(para) msgid ""To ease the administrative burden of managing SELinux, many enterprise Linux platforms utilize SELinux Booleans to quickly change the security posture of sVirt."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:154(para) msgid ""Red Hat Enterprise Linux-based KVM deployments utilize the following sVirt booleans:"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:161(emphasis) msgid ""sVirt SELinux Boolean"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:162(emphasis) msgid "" Description"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:165(para) msgid ""virt_use_common"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:166(para) msgid ""Allow virt to use serial/parallel communication ports."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:169(para) msgid ""virt_use_fusefs"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:170(para) msgid ""Allow virt to read FUSE mounted files."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:173(para) msgid ""virt_use_nfs"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:174(para) msgid ""Allow virt to manage NFS mounted files."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:177(para) msgid ""virt_use_samba"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:178(para) msgid ""Allow virt to manage CIFS mounted files."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:181(para) msgid ""virt_use_sanlock"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:182(para) msgid ""Allow confined virtual guests to interact with the sanlock."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:185(para) msgid ""virt_use_sysfs"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:186(para) msgid ""Allow virt to manage device configuration (PCI)."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:189(para) msgid ""virt_use_usb"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:190(para) msgid ""Allow virt to use USB devices."" msgstr """" #: ./doc/security-guide/ch052_devices.xml:193(para) msgid ""virt_use_xserver"" msgstr """" #: ./doc/security-guide/ch052_devices.xml:194(para) msgid ""Allow virtual machine to interact with the X Window System."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:3(title) msgid ""SSL Proxies and HTTP Services"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:4(para) msgid ""OpenStack endpoints are HTTP services providing APIs to both end-users on public networks and to other OpenStack services within the same deployment operating over the management network. It is highly recommended these requests, both those internal and external, operate over SSL."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:5(para) msgid ""In order for API requests to be encrypted by SSL it's necessary to position the API services behind a proxy that will establish and terminate SSL sessions. The following table offers a non-exhaustive list of software services that can proxy SSL traffic for API requests:"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:7(link) msgid ""Pound"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:10(link) ./doc/security-guide/ch020_ssl-everywhere.xml:80(title) msgid ""Stud"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:13(link) ./doc/security-guide/ch020_ssl-everywhere.xml:119(title) msgid ""nginx"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:16(link) msgid ""Apache httpd"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:19(para) msgid ""Hardware appliance SSL acceleration proxies"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:22(para) msgid ""It is important to be mindful of the size of requests that will be processed by any chosen SSL proxy."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:24(title) msgid ""Examples"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:25(para) msgid ""Below we provide some sample configuration setting for enabling SSL in some of the most popular web servers/SSL terminators with recommended configurations. Note that we have SSL v3 enabled in some of these examples as this will be required in many deployments for client compatibility."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:27(title) msgid ""Pound - with AES-NI acceleration"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:81(para) msgid ""This stud example enables SSL v3 for client compatibility. The ciphers line can be tweaked based on your needs, however this is a reasonable starting place."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:120(para) msgid ""This nginx example requires TLS v1.1 or v1.2 for maximum security. The ssl_ciphers line can be tweaked based on your needs, however this is a reasonable starting place."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:137(title) msgid ""Apache"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:163(para) msgid ""Compute API SSL endpoint in Apache2, which needs to be paired with a short WSGI script."" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:188(title) msgid ""HTTP Strict Transport Security"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:189(para) msgid ""We recommend that all production deployments use HSTS. This header prevents browsers from making insecure connections after they have made a single secure one. If you have deployed your HTTP services on a public or an untrusted domain, HSTS is especially important. To enable HSTS, configure your web server to send a header like this with all requests:"" msgstr """" #: ./doc/security-guide/ch020_ssl-everywhere.xml:192(para) msgid ""Start with a short timeout of 1 day during testing, and raise it to one year after testing has shown that you haven't introduced problems for users. Note that once this header is set to a large timeout, it is (by design) very difficult to disable."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:3(title) msgid ""Forensics and Incident Response"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:4(para) msgid ""A lot of activity goes on within a cloud environment. It is a mix of hardware, operating systems, virtual machine managers, the OpenStack services, cloud-user activity such as creating instances and attaching storage, the network underlying the whole, and finally end-users using the applications running on the various instances."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:5(para) msgid ""The generation and collection of logs is an important component of securely monitoring an OpenStack infrastructure. Logs provide visibility into the day-to-day actions of administrators, tenants, and guests, in addition to the activity in the compute, networking, and storage and other components that comprise your OpenStack deployment."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:6(para) msgid ""The basics of logging: configuration, setting log level, location of the log files, and how to use and customize logs, as well as how to do centralized collections of logs is well covered in the <link href=\""http://docs.openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></link>."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:7(para) msgid ""Logs are not only valuable for proactive security and continuous compliance activities, but they are also a valuable information source for investigating and responding to incidents."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:8(para) msgid ""For instance, analyzing the access logs of Identity Service or its replacement authentication system would alert us to failed logins, their frequency, origin IP, whether the events are restricted to select accounts etc. Log analysis supports detection."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:9(para) msgid ""On detection, further action may be to black list an IP, or recommend strengthening user passwords, or even de-activating a user account if it is deemed dormant."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:11(title) msgid ""Monitoring Use Cases"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:12(para) msgid ""Monitoring events is more pro-active and provides real-time detection and response. There are several tools to aid in monitoring."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:13(para) msgid ""In the case of an OpenStack cloud instance, we need to monitor the hardware, the OpenStack services, and the cloud resource usage. The last stems from wanting to be elastic, to scale to the dynamic needs of the users."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:14(para) msgid ""Here are a few important use cases to consider when implementing log aggregation, analysis and monitoring. These use cases can be implemented and monitored through various commercial and open source tools, homegrown scripts, etc. These tools and scripts can generate events that can then be sent to the administrators through email or integrated dashboard. It is important to consider additional use cases that may apply to your specific network and what you may consider anomalous behavior."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:16(para) msgid ""Detecting the absence of log generation is an event of high value. Such an event would indicate a service failure or even an intruder who has temporarily switched off logging or modified the log level to hide their tracks."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:20(para) msgid ""Application events such as start and/or stop that were unscheduled would also be events to monitor and examine for possible security implications."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:24(para) msgid ""OS events on the OpenStack service machines such as user logins, restarts also provide valuable insight into use/misuse"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:28(para) msgid ""Being able to detect the load on the OpenStack servers also enables responding by way of introducing additional servers for load balancing to ensure high availability."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:32(para) msgid ""Other events that are actionable are networking bridges going down, ip tables being flushed on compute nodes and consequential loss of access to instances resulting in unhappy customers. "" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:36(para) msgid ""To reduce security risks from orphan instances on a user/tenant/domain deletion in the Identity service there is discussion to generate notifications in the system and have OpenStack components respond to these events as appropriate such as terminating instances, disconnecting attached volumes, reclaiming CPU and storage resources etc. "" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:39(para) msgid ""A cloud will host many virtual instances, and monitoring these instances goes beyond hardware monitoring and log files which may just contain CRUD events."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:40(para) msgid ""Security monitoring controls such as intrusion detection software, antivirus software, and spyware detection and removal utilities can generate logs that show when and how an attack or intrusion took place. Deploying these tools on the cloud machines provides value and protection. Cloud users, those running instances on the cloud may also want to run such tools on their instances."" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:44(link) msgid ""http://www.mirantis.com/blog/openstack-monitoring/"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:45(link) msgid ""http://blog.sflow.com/2012/01/host-sflow-distributed-agent.html"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:46(link) msgid ""http://blog.sflow.com/2009/09/lan-and-wan.html"" msgstr """" #: ./doc/security-guide/ch058_forensicsincident-response.xml:47(link) msgid ""http://blog.sflow.com/2013/01/rapidly-detecting-large-flows-sflow-vs.html"" msgstr """" #. Put one translator per line, in the form of NAME <EMAIL>, YEAR1, YEAR2 #: ./doc/security-guide/ch058_forensicsincident-response.xml:0(None) msgid ""translator-credits"" msgstr """" ",,175506,0
openstack%2Fnova~master~I469e2a415c1f1924010f47d3927ca18c45a7b8f8,openstack/nova,master,I469e2a415c1f1924010f47d3927ca18c45a7b8f8,XenAPI: Speedup get_vhd_parent_uuid,MERGED,2013-11-27 13:08:24.000000000,2014-01-30 19:51:50.000000000,2014-01-30 19:51:47.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 6735}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-27 13:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce7bb8bd2efd7152453232b763aecb82d3cc0836', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 2, 'created': '2013-11-27 21:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/591319c14749c672cb6ec4921435b27b6c3839b7', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 3, 'created': '2013-11-28 23:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adf5b0c696685a64cd71911025960d3307af0a89', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 4, 'created': '2013-11-29 09:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/224028dec337aaaaae0254c76dd2320f9d2bc421', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 5, 'created': '2013-12-02 17:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04c9dbc89de1aa40141075061d3efe1c3554e824', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 6, 'created': '2013-12-03 14:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9f54244189a67e16abad1c9f20599385046a1ad', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 7, 'created': '2013-12-11 11:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f493a92b5a2db0025dd747d77a0f6a3f97ef50b', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 8, 'created': '2013-12-17 11:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/472dcb1bf30e95434955b7897f79529101ac6492', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 9, 'created': '2014-01-13 11:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/360b08b5d2d58e5bf3347a1e56e9868782e51210', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 10, 'created': '2014-01-14 11:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a98b0e8291be7e3a08c295c18324c87c49f6514', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 11, 'created': '2014-01-22 15:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e7408efb9f658b46758f541199e7dda639db88a', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}, {'number': 12, 'created': '2014-01-24 10:17:03.000000000', 'files': ['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bfe19826eca204a8da9c63c3616a0deee9fa8237', 'message': 'XenAPI: Speedup get_vhd_parent_uuid\n\nIn many cases the VDI record has already been retrieved.\nUse it rather than expensively getting a new VDI record from XAPI.\n\nChange-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8\n'}]",4,58755,bfe19826eca204a8da9c63c3616a0deee9fa8237,59,7,12,6735,,,0,"XenAPI: Speedup get_vhd_parent_uuid

In many cases the VDI record has already been retrieved.
Use it rather than expensively getting a new VDI record from XAPI.

Change-Id: I469e2a415c1f1924010f47d3927ca18c45a7b8f8
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/58755/12 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/vm_utils.py'],1,ce7bb8bd2efd7152453232b763aecb82d3cc0836,speedup,"def _get_vhd_parent_uuid(session, vdi_ref, vdi_rec=None): if vdi_rec is None: vdi_rec = session.call_xenapi(""VDI.get_record"", vdi_ref) parent_uuid = _get_vhd_parent_uuid(session, vdi_ref, vdi_rec) parent_uuid = _get_vhd_parent_uuid(session, ref, rec) vdi_rec = session.call_xenapi('VDI.get_record', vdi_ref) vdi_uuid = vdi_rec['uuid'] parent_vdi_uuid = _get_vhd_parent_uuid(session, vdi_ref, vdi_rec)","def _get_vhd_parent_uuid(session, vdi_ref): vdi_rec = session.call_xenapi(""VDI.get_record"", vdi_ref) parent_uuid = _get_vhd_parent_uuid(session, vdi_ref) parent_uuid = _get_vhd_parent_uuid(session, ref) vdi_uuid = session.call_xenapi('VDI.get_record', vdi_ref)['uuid'] parent_vdi_uuid = _get_vhd_parent_uuid(session, vdi_ref)",8,6
openstack%2Fnova~master~I4725c3f1fdebdf1737941cb7db69b19afb22df9f,openstack/nova,master,I4725c3f1fdebdf1737941cb7db69b19afb22df9f,XenAPI: Tidy calls to get_all_ref_and_rec,MERGED,2013-11-27 13:08:22.000000000,2014-01-30 19:50:47.000000000,2014-01-30 19:50:43.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 5441}, {'_account_id': 6735}, {'_account_id': 6904}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-27 13:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46426bc8f48792606e183d845b94da71ba7fb785', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nUse in fewer places, and where it is still used, use the more\nefficient get_all_records\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 2, 'created': '2013-11-27 21:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bafb83a5c7c661a60e9339fedf5dc591697f5c86', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nUse in fewer places, and where it is still used, use the more\nefficient get_all_records\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 3, 'created': '2013-11-28 23:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d836393ad6a8eba3a153ad59ff0f02d0e55b6fb2', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nUse in fewer places, and where it is still used, use the more\nefficient get_all_records\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 4, 'created': '2013-11-29 09:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b5df2544fd67e5dfb63dc44d60fa19be5b38c22', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nUse in fewer places, and where it is still used, use the more\nefficient get_all_records\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 5, 'created': '2013-12-02 17:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1af9bbebcf86114de9c5235f61702e6aeb9fb972', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 6, 'created': '2013-12-03 14:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/443689e5fd2dac986f68655e0c5969e740249516', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 7, 'created': '2013-12-11 11:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6b460f6bb21d14068362d7f7d934ba8afb0568c', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 8, 'created': '2013-12-17 11:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9a050c9f7766bc78d963511d6115bbb84aad42e', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 9, 'created': '2014-01-13 11:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d50d1266140665069282680f84ceec04b9bf507', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 10, 'created': '2014-01-14 11:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fbfdd67385f055dda0d31db1eec635ea5c7c68e', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 11, 'created': '2014-01-14 18:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04c1c5dd0c9477465a38eb238f685e5ecceab758', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 12, 'created': '2014-01-22 15:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a9ccaa076714a2033937a59474d2c410f5da4c6', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}, {'number': 13, 'created': '2014-01-24 10:13:36.000000000', 'files': ['nova/virt/xenapi/client/session.py', 'nova/virt/xenapi/vm_utils.py', 'nova/virt/xenapi/fake.py', 'nova/virt/xenapi/volume_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/virt/xenapi/test_volume_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7fcbe6f3e4e27f58611a6d3ca5410461845cbabd', 'message': 'XenAPI: Tidy calls to get_all_ref_and_rec\n\nget_all_records is more efficient than getting them individually in the\nold get_all_ref_and_rec implementation.\n\nReplaced some cases of get_all_records with a faster and more\nspecific API call.\n\nChange-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f\n'}]",18,58754,7fcbe6f3e4e27f58611a6d3ca5410461845cbabd,67,9,13,6735,,,0,"XenAPI: Tidy calls to get_all_ref_and_rec

get_all_records is more efficient than getting them individually in the
old get_all_ref_and_rec implementation.

Replaced some cases of get_all_records with a faster and more
specific API call.

Change-Id: I4725c3f1fdebdf1737941cb7db69b19afb22df9f
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/58754/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/client/session.py', 'nova/virt/xenapi/vm_utils.py', 'nova/virt/xenapi/volume_utils.py']",3,46426bc8f48792606e183d845b94da71ba7fb785,bug/1192528," sr_ref = session.call_xenapi(""SR.get_by_uuid"", sr_uuid) return sr_ref"," for sr_ref, sr_rec in session.get_all_refs_and_recs('SR'): if sr_rec['uuid'] == sr_uuid: return sr_ref return None",11,16
openstack%2Ftempest~master~I4fc99d44073598513653cd87fd73a82a0b0093da,openstack/tempest,master,I4fc99d44073598513653cd87fd73a82a0b0093da,Convert network api tests to use global CONF object,MERGED,2014-01-29 19:28:40.000000000,2014-01-30 19:50:33.000000000,2014-01-30 19:50:33.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5689}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-29 19:28:40.000000000', 'files': ['tempest/api/network/test_floating_ips.py', 'tempest/api/network/test_networks.py', 'tempest/api/network/test_vpnaas_extensions.py', 'tempest/api/network/base.py', 'tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/03b48df5c5613869e1ae803c624b710bb3ba1082', 'message': 'Convert network api tests to use global CONF object\n\nThis commit takes all the uses of config in the network api tests\nand converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: I4fc99d44073598513653cd87fd73a82a0b0093da\n'}]",0,69950,03b48df5c5613869e1ae803c624b710bb3ba1082,8,5,1,5196,,,0,"Convert network api tests to use global CONF object

This commit takes all the uses of config in the network api tests
and converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: I4fc99d44073598513653cd87fd73a82a0b0093da
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/69950/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_floating_ips.py', 'tempest/api/network/test_networks.py', 'tempest/api/network/test_vpnaas_extensions.py', 'tempest/api/network/base.py', 'tempest/api/network/test_routers.py']",5,03b48df5c5613869e1ae803c624b710bb3ba1082,bp/config-cleanup,"from tempest import configCONF = config.CONF ""network_id"": CONF.network.public_network_id}, CONF.network.public_network_id) CONF.network.public_network_id) network_id=CONF.network.public_network_id, CONF.network.public_network_id) 'network_id': CONF.network.public_network_id}) {'network_id': CONF.network.public_network_id}) 'network_id': CONF.network.public_network_id, {'network_id': CONF.network.public_network_id, 'network_id': CONF.network.public_network_id, {'network_id': CONF.network.public_network_id, external_network_id=CONF.network.public_network_id) network_id=CONF.network.public_network_id, external_network_id=CONF.network.public_network_id) 'network_id': CONF.network.public_network_id, {'network_id': CONF.network.public_network_id,"," ""network_id"": self.network_cfg.public_network_id}, self.network_cfg.public_network_id) self.network_cfg.public_network_id) network_id=self.network_cfg.public_network_id, self.network_cfg.public_network_id) 'network_id': self.network_cfg.public_network_id}) {'network_id': self.network_cfg.public_network_id}) 'network_id': self.network_cfg.public_network_id, {'network_id': self.network_cfg.public_network_id, 'network_id': self.network_cfg.public_network_id, {'network_id': self.network_cfg.public_network_id, external_network_id=self.network_cfg.public_network_id) network_id=self.network_cfg.public_network_id, external_network_id=self.network_cfg.public_network_id) 'network_id': self.network_cfg.public_network_id, {'network_id': self.network_cfg.public_network_id,",43,29
openstack%2Fnova~master~Ib45a04d34704bc259ef6e457d6dfb6f79c929edf,openstack/nova,master,Ib45a04d34704bc259ef6e457d6dfb6f79c929edf,Remove XML support from admin_password V3 API plugin,MERGED,2014-01-29 12:43:07.000000000,2014-01-30 19:49:35.000000000,2014-01-30 19:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 6348}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 12:43:07.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/admin_password.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/669da100e5dd130abdabf80e72431e0e450f0e82', 'message': 'Remove XML support from admin_password V3 API plugin\n\nRemoves all XML support from the V3 API admin_password\nplugin.\n\nPartially implements blueprint remove-v3-xml-api\n\nChange-Id: Ib45a04d34704bc259ef6e457d6dfb6f79c929edf\nDocImpact: XML no longer suported for the admin_password plugin\n'}]",0,69851,669da100e5dd130abdabf80e72431e0e450f0e82,15,7,1,5292,,,0,"Remove XML support from admin_password V3 API plugin

Removes all XML support from the V3 API admin_password
plugin.

Partially implements blueprint remove-v3-xml-api

Change-Id: Ib45a04d34704bc259ef6e457d6dfb6f79c929edf
DocImpact: XML no longer suported for the admin_password plugin
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/69851/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/admin_password.py'],1,669da100e5dd130abdabf80e72431e0e450f0e82,bp/remove-v3-xml-api,,"from nova.api.openstack import xmlutilclass ChangePasswordDeserializer(wsgi.XMLDeserializer): def default(self, string): dom = xmlutil.safe_minidom_parse_string(string) action_node = dom.childNodes[0] action_name = action_node.tagName action_data = None if action_node.hasAttribute(""admin_password""): action_data = {'admin_password': action_node.getAttribute(""admin_password"")} return {'body': {action_name: action_data}} @wsgi.deserializers(xml=ChangePasswordDeserializer)",0,14
openstack%2Ftempest~master~Ic305ce82d2bd5d0ef8293fe25c6a4c835633b0e8,openstack/tempest,master,Ic305ce82d2bd5d0ef8293fe25c6a4c835633b0e8,Convert image and identity api tests to use global CONF object,MERGED,2014-01-29 19:28:39.000000000,2014-01-30 19:49:21.000000000,2014-01-30 19:49:20.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 19:28:39.000000000', 'files': ['tempest/api/identity/admin/v3/test_trusts.py', 'tempest/api/image/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ba84e3ddd6d9f4bfdc558f5ac357076932d5925', 'message': 'Convert image and identity api tests to use global CONF object\n\nThis commit takes all the uses of config in the image and identity api\ntests and converts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Ic305ce82d2bd5d0ef8293fe25c6a4c835633b0e8\n'}]",0,69949,5ba84e3ddd6d9f4bfdc558f5ac357076932d5925,7,4,1,5196,,,0,"Convert image and identity api tests to use global CONF object

This commit takes all the uses of config in the image and identity api
tests and converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: Ic305ce82d2bd5d0ef8293fe25c6a4c835633b0e8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/69949/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/admin/v3/test_trusts.py', 'tempest/api/image/base.py']",2,5ba84e3ddd6d9f4bfdc558f5ac357076932d5925,bp/config-cleanup,from tempest import configCONF = config.CONF if not CONF.service_available.glance: if CONF.compute.allow_tenant_isolation: if not CONF.image_feature_enabled.api_v1: if CONF.compute.allow_tenant_isolation: if not CONF.image_feature_enabled.api_v2: if CONF.compute.allow_tenant_isolation:, if not cls.config.service_available.glance: if cls.config.compute.allow_tenant_isolation: if not cls.config.image_feature_enabled.api_v1: if cls.config.compute.allow_tenant_isolation: if not cls.config.image_feature_enabled.api_v2: if cls.config.compute.allow_tenant_isolation:,10,7
openstack%2Fnova~master~I4f3785fbdac7257370458a3bdd859d46ef83f415,openstack/nova,master,I4f3785fbdac7257370458a3bdd859d46ef83f415,Remove XML support from some extension v3 API plugins,MERGED,2014-01-29 03:47:32.000000000,2014-01-30 19:48:31.000000000,2014-01-30 19:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 7641}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:47:32.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/extended_server_attributes.py', 'nova/api/openstack/compute/plugins/v3/extended_volumes.py', 'nova/api/openstack/compute/plugins/v3/extended_status.py', 'nova/api/openstack/compute/plugins/v3/extension_info.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8dacfbc4b3672c5cd2677f2a507a1e905c0a906b', 'message': 'Remove XML support from some extension v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - extended_server_attributes\n - extended_status\n - extended_volumes\n - extension_info\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I4f3785fbdac7257370458a3bdd859d46ef83f415\n'}]",0,69782,8dacfbc4b3672c5cd2677f2a507a1e905c0a906b,23,6,1,7641,,,0,"Remove XML support from some extension v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - extended_server_attributes
 - extended_status
 - extended_volumes
 - extension_info

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: I4f3785fbdac7257370458a3bdd859d46ef83f415
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/69782/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/extended_server_attributes.py', 'nova/api/openstack/compute/plugins/v3/extended_volumes.py', 'nova/api/openstack/compute/plugins/v3/extended_status.py', 'nova/api/openstack/compute/plugins/v3/extension_info.py']",4,8dacfbc4b3672c5cd2677f2a507a1e905c0a906b,bp/remove-v3-xml-api,,"from nova.api.openstack import wsgi from nova.api.openstack import xmlutildef make_ext(elem): elem.set('name') elem.set('namespace') elem.set('alias') elem.set('version') desc = xmlutil.SubTemplateElement(elem, 'description') desc.text = 'description' ext_nsmap = {None: xmlutil.XMLNS_COMMON_V10, 'atom': xmlutil.XMLNS_ATOM} class ExtensionTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('extension', selector='extension') make_ext(root) return xmlutil.MasterTemplate(root, 1, nsmap=ext_nsmap) class ExtensionsTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('extensions') elem = xmlutil.SubTemplateElement(root, 'extension', selector='extensions') make_ext(elem) return xmlutil.MasterTemplate(root, 1, nsmap=ext_nsmap) @wsgi.serializers(xml=ExtensionsTemplate) @wsgi.serializers(xml=ExtensionTemplate)",1,129
openstack%2Ftempest~master~Iac92d6ac88200222392a131b4c95411594c509ba,openstack/tempest,master,Iac92d6ac88200222392a131b4c95411594c509ba,Convert compute api tests to global CONF object,MERGED,2014-01-29 19:28:39.000000000,2014-01-30 19:48:18.000000000,2014-01-30 19:48:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-01-29 19:28:39.000000000', 'files': ['tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/servers/test_servers_negative.py', 'tempest/api/compute/test_authorization.py', 'tempest/api/compute/v3/images/test_list_image_filters.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/api/compute/v3/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/servers/test_servers_negative.py', 'tempest/api/compute/security_groups/test_security_groups_negative.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/api/compute/v3/servers/test_list_server_filters.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions_negative.py', 'tempest/api/compute/v3/images/test_images.py', 'tempest/api/compute/base.py', 'tempest/api/compute/floating_ips/test_list_floating_ips_negative.py', 'tempest/api/compute/test_extensions.py', 'tempest/api/compute/v3/test_extensions.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/api/compute/v3/images/test_image_metadata.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/api/compute/images/test_list_images.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/volumes/test_volumes_negative.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/admin/test_quotas.py', 'tempest/api/compute/v3/images/test_images_oneserver.py', 'tempest/api/compute/security_groups/test_security_group_rules.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/images/test_images_oneserver.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b0a78fc30a8f2165414a775faf44cdd22a0f8182', 'message': 'Convert compute api tests to global CONF object\n\nThis commit takes all the uses of config in the compute api tests and\nconverts them to use the global CONF object.\n\nPartially implements bp config-cleanup\n\nChange-Id: Iac92d6ac88200222392a131b4c95411594c509ba\n'}]",0,69948,b0a78fc30a8f2165414a775faf44cdd22a0f8182,6,3,1,5196,,,0,"Convert compute api tests to global CONF object

This commit takes all the uses of config in the compute api tests and
converts them to use the global CONF object.

Partially implements bp config-cleanup

Change-Id: Iac92d6ac88200222392a131b4c95411594c509ba
",git fetch https://review.opendev.org/openstack/tempest refs/changes/48/69948/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/servers/test_servers_negative.py', 'tempest/api/compute/test_authorization.py', 'tempest/api/compute/v3/images/test_list_image_filters.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/api/compute/v3/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/servers/test_servers_negative.py', 'tempest/api/compute/security_groups/test_security_groups_negative.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/api/compute/v3/servers/test_list_server_filters.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions_negative.py', 'tempest/api/compute/v3/images/test_images.py', 'tempest/api/compute/base.py', 'tempest/api/compute/floating_ips/test_list_floating_ips_negative.py', 'tempest/api/compute/test_extensions.py', 'tempest/api/compute/v3/test_extensions.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/api/compute/v3/images/test_image_metadata.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/api/compute/images/test_list_images.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/volumes/test_volumes_negative.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images_oneserver_negative.py', 'tempest/api/compute/v3/admin/test_quotas.py', 'tempest/api/compute/v3/images/test_images_oneserver.py', 'tempest/api/compute/security_groups/test_security_group_rules.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/images/test_images_oneserver.py']",36,b0a78fc30a8f2165414a775faf44cdd22a0f8182,bp/config-cleanup, if not CONF.service_available.glance: if CONF.compute.allow_tenant_isolation:, if not cls.config.service_available.glance: if cls.config.compute.allow_tenant_isolation:,141,74
openstack%2Fpython-ironicclient~master~I003b89ccc741af9933c045506c6d092b8982f8db,openstack/python-ironicclient,master,I003b89ccc741af9933c045506c6d092b8982f8db,Sync apiclient and strutils from Oslo,MERGED,2013-12-06 14:47:31.000000000,2014-01-30 19:39:02.000000000,2014-01-30 19:28:45.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7491}, {'_account_id': 7763}, {'_account_id': 8106}, {'_account_id': 8415}, {'_account_id': 8968}, {'_account_id': 9545}, {'_account_id': 9550}, {'_account_id': 9583}]","[{'number': 1, 'created': '2013-12-06 14:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4a737a71cdd18d3bb204376ee0b66b78d3fbd880', 'message': 'Sync exceptions from Oslo\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 2, 'created': '2013-12-06 15:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4eff922d14e42ac34c6a0935435996d1563223ca', 'message': 'Use improved exceptions functionality from Oslo\nblueprint common-client-library-2\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 3, 'created': '2013-12-06 15:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8ba2dc4fc242198315be58d093de15126230900f', 'message': 'Use improved exceptions functionality from Oslo\n\nblueprint common-client-library-2\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 4, 'created': '2013-12-10 13:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2e3117229f6740ff62a036b70c4e0b4be6cb70f1', 'message': 'Use improved exceptions functionality from Oslo\n\nblueprint common-client-library-2\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 5, 'created': '2013-12-10 13:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/0f92ac018dcc9d02a3030a6883222cbdabb6c4fc', 'message': 'Import exceptions functionality from Oslo\n\nblueprint common-client-library-2\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 6, 'created': '2013-12-10 14:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/d1db4a4396cd175f2ef1f0c1a5ecdb3e8319848a', 'message': 'Import exceptions functionality from Oslo\n\nNeed for future using in clients\n\nblueprint common-client-library-2\n\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 7, 'created': '2013-12-10 15:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5b09aebd2aa8f952be5d23020afd361c66705343', 'message': 'Import exceptions functionality from Oslo\n\nBecause of clients unification, it is requered to reuse common functionality from Oslo\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 8, 'created': '2013-12-10 15:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3575149c6a9713d1335a038e00b8ca6f13a672b0', 'message': 'Import exceptions functionality from Oslo\n\nBecause of clients unification, it is requered to reuse common functionality from Oslo\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 9, 'created': '2013-12-11 10:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f6d3b15cff24ea586dc1914aaf453036ad7090bb', 'message': 'Import exceptions functionality from Oslo\n\nBecause of clients unification, it is requered to reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 10, 'created': '2013-12-18 15:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c4cad67f6e15f46f972d472be362428ece038de1', 'message': 'Sync base, exceptions and strutils from Oslo\n\nBecause of clients unification, we should reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 11, 'created': '2013-12-20 11:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/b1eac0bdf68b848ba0cfc0f3873714d8cdf892b6', 'message': 'Sync base, exceptions and strutils from Oslo\n\nBecause of clients unification, we should reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 12, 'created': '2013-12-27 14:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/020c08ad9702b3504375fe8b6257a7d4752537bd', 'message': 'Sync apiclient and strutils from Oslo\n\nBecause of clients unification, we should reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 13, 'created': '2014-01-08 14:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e1135a71fa6b47418f46719b04b81b5120b953db', 'message': 'Sync apiclient and strutils from Oslo\n\nBecause of clients unification, we should reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}, {'number': 14, 'created': '2014-01-17 10:09:00.000000000', 'files': ['ironicclient/openstack/common/strutils.py', 'ironicclient/openstack/common/apiclient/base.py', 'ironicclient/openstack/common/apiclient/exceptions.py', 'ironicclient/openstack/common/apiclient/fake_client.py', 'ironicclient/openstack/common/apiclient/__init__.py', 'openstack-common.conf', 'ironicclient/openstack/common/apiclient/auth.py', 'ironicclient/openstack/common/apiclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9784de9e726a1f656a911f9ca347a408874e90f3', 'message': 'Sync apiclient and strutils from Oslo\n\nBecause of clients unification, we should reuse common\nfunctionality from Oslo. This patch is aimed only to import classes\nto the project, all the integration work will be done in a separate\npatch.\n\nImplements: blueprint common-client-library-2\nChange-Id: I003b89ccc741af9933c045506c6d092b8982f8db\n'}]",26,60528,9784de9e726a1f656a911f9ca347a408874e90f3,80,14,14,9583,,,0,"Sync apiclient and strutils from Oslo

Because of clients unification, we should reuse common
functionality from Oslo. This patch is aimed only to import classes
to the project, all the integration work will be done in a separate
patch.

Implements: blueprint common-client-library-2
Change-Id: I003b89ccc741af9933c045506c6d092b8982f8db
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/28/60528/2 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/openstack/common/apiclient/exceptions.py'],1,4a737a71cdd18d3bb204376ee0b66b78d3fbd880,bp/common-client-library-2,"# Copyright 2010 Jacob Kaplan-Moss # Copyright 2011 Nebula, Inc. # Copyright 2013 Alessio Ababilov # Copyright 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exception definitions. """""" import inspect import sys import six class ClientException(Exception): """"""The base exception class for all exceptions this library raises. """""" pass class MissingArgs(ClientException): """"""Supplied arguments are not sufficient for calling a function."""""" def __init__(self, missing): self.missing = missing msg = ""Missing argument(s): %s"" % "", "".join(missing) super(MissingArgs, self).__init__(msg) class ValidationError(ClientException): """"""Error in validation on API client side."""""" pass class UnsupportedVersion(ClientException): """"""User is trying to use an unsupported version of the API."""""" pass class CommandError(ClientException): """"""Error in CLI tool."""""" pass class AuthorizationFailure(ClientException): """"""Cannot authorize API client."""""" pass class AuthPluginOptionsMissing(AuthorizationFailure): """"""Auth plugin misses some options."""""" def __init__(self, opt_names): super(AuthPluginOptionsMissing, self).__init__( ""Authentication failed. Missing options: %s"" % "", "".join(opt_names)) self.opt_names = opt_names class AuthSystemNotFound(AuthorizationFailure): """"""User has specified a AuthSystem that is not installed."""""" def __init__(self, auth_system): super(AuthSystemNotFound, self).__init__( ""AuthSystemNotFound: %s"" % repr(auth_system)) self.auth_system = auth_system class NoUniqueMatch(ClientException): """"""Multiple entities found instead of one."""""" pass class EndpointException(ClientException): """"""Something is rotten in Service Catalog."""""" pass class EndpointNotFound(EndpointException): """"""Could not find requested endpoint in Service Catalog."""""" pass class AmbiguousEndpoints(EndpointException): """"""Found more than one matching endpoint in Service Catalog."""""" def __init__(self, endpoints=None): super(AmbiguousEndpoints, self).__init__( ""AmbiguousEndpoints: %s"" % repr(endpoints)) self.endpoints = endpoints class HttpError(ClientException): """"""The base exception class for all HTTP exceptions. """""" http_status = 0 message = ""HTTP Error"" def __init__(self, message=None, details=None, response=None, request_id=None, url=None, method=None, http_status=None): self.http_status = http_status or self.http_status self.message = message or self.message self.details = details self.request_id = request_id self.response = response self.url = url self.method = method formatted_string = ""%s (HTTP %s)"" % (self.message, self.http_status) if request_id: formatted_string += "" (Request-ID: %s)"" % request_id super(HttpError, self).__init__(formatted_string) class HTTPClientError(HttpError): """"""Client-side HTTP error. Exception for cases in which the client seems to have erred. """""" message = ""HTTP Client Error"" class HttpServerError(HttpError): """"""Server-side HTTP error. Exception for cases in which the server is aware that it has erred or is incapable of performing the request. """""" message = ""HTTP Server Error"" class BadRequest(HTTPClientError): """"""HTTP 400 - Bad Request. The request cannot be fulfilled due to bad syntax. """""" http_status = 400 message = ""Bad Request"" class Unauthorized(HTTPClientError): """"""HTTP 401 - Unauthorized. Similar to 403 Forbidden, but specifically for use when authentication is required and has failed or has not yet been provided. """""" http_status = 401 message = ""Unauthorized"" class PaymentRequired(HTTPClientError): """"""HTTP 402 - Payment Required. Reserved for future use. """""" http_status = 402 message = ""Payment Required"" class Forbidden(HTTPClientError): """"""HTTP 403 - Forbidden. The request was a valid request, but the server is refusing to respond to it. """""" http_status = 403 message = ""Forbidden"" class NotFound(HTTPClientError): """"""HTTP 404 - Not Found. The requested resource could not be found but may be available again in the future. """""" http_status = 404 message = ""Not Found"" class MethodNotAllowed(HTTPClientError): """"""HTTP 405 - Method Not Allowed. A request was made of a resource using a request method not supported by that resource. """""" http_status = 405 message = ""Method Not Allowed"" class NotAcceptable(HTTPClientError): """"""HTTP 406 - Not Acceptable. The requested resource is only capable of generating content not acceptable according to the Accept headers sent in the request. """""" http_status = 406 message = ""Not Acceptable"" class ProxyAuthenticationRequired(HTTPClientError): """"""HTTP 407 - Proxy Authentication Required. The client must first authenticate itself with the proxy. """""" http_status = 407 message = ""Proxy Authentication Required"" class RequestTimeout(HTTPClientError): """"""HTTP 408 - Request Timeout. The server timed out waiting for the request. """""" http_status = 408 message = ""Request Timeout"" class Conflict(HTTPClientError): """"""HTTP 409 - Conflict. Indicates that the request could not be processed because of conflict in the request, such as an edit conflict. """""" http_status = 409 message = ""Conflict"" class Gone(HTTPClientError): """"""HTTP 410 - Gone. Indicates that the resource requested is no longer available and will not be available again. """""" http_status = 410 message = ""Gone"" class LengthRequired(HTTPClientError): """"""HTTP 411 - Length Required. The request did not specify the length of its content, which is required by the requested resource. """""" http_status = 411 message = ""Length Required"" class PreconditionFailed(HTTPClientError): """"""HTTP 412 - Precondition Failed. The server does not meet one of the preconditions that the requester put on the request. """""" http_status = 412 message = ""Precondition Failed"" class RequestEntityTooLarge(HTTPClientError): """"""HTTP 413 - Request Entity Too Large. The request is larger than the server is willing or able to process. """""" http_status = 413 message = ""Request Entity Too Large"" def __init__(self, *args, **kwargs): try: self.retry_after = int(kwargs.pop('retry_after')) except (KeyError, ValueError): self.retry_after = 0 super(RequestEntityTooLarge, self).__init__(*args, **kwargs) class RequestUriTooLong(HTTPClientError): """"""HTTP 414 - Request-URI Too Long. The URI provided was too long for the server to process. """""" http_status = 414 message = ""Request-URI Too Long"" class UnsupportedMediaType(HTTPClientError): """"""HTTP 415 - Unsupported Media Type. The request entity has a media type which the server or resource does not support. """""" http_status = 415 message = ""Unsupported Media Type"" class RequestedRangeNotSatisfiable(HTTPClientError): """"""HTTP 416 - Requested Range Not Satisfiable. The client has asked for a portion of the file, but the server cannot supply that portion. """""" http_status = 416 message = ""Requested Range Not Satisfiable"" class ExpectationFailed(HTTPClientError): """"""HTTP 417 - Expectation Failed. The server cannot meet the requirements of the Expect request-header field. """""" http_status = 417 message = ""Expectation Failed"" class UnprocessableEntity(HTTPClientError): """"""HTTP 422 - Unprocessable Entity. The request was well-formed but was unable to be followed due to semantic errors. """""" http_status = 422 message = ""Unprocessable Entity"" class InternalServerError(HttpServerError): """"""HTTP 500 - Internal Server Error. A generic error message, given when no more specific message is suitable. """""" http_status = 500 message = ""Internal Server Error"" # NotImplemented is a python keyword. class HttpNotImplemented(HttpServerError): """"""HTTP 501 - Not Implemented. The server either does not recognize the request method, or it lacks the ability to fulfill the request. """""" http_status = 501 message = ""Not Implemented"" class BadGateway(HttpServerError): """"""HTTP 502 - Bad Gateway. The server was acting as a gateway or proxy and received an invalid response from the upstream server. """""" http_status = 502 message = ""Bad Gateway"" class ServiceUnavailable(HttpServerError): """"""HTTP 503 - Service Unavailable. The server is currently unavailable. """""" http_status = 503 message = ""Service Unavailable"" class GatewayTimeout(HttpServerError): """"""HTTP 504 - Gateway Timeout. The server was acting as a gateway or proxy and did not receive a timely response from the upstream server. """""" http_status = 504 message = ""Gateway Timeout"" class HttpVersionNotSupported(HttpServerError): """"""HTTP 505 - HttpVersion Not Supported. The server does not support the HTTP protocol version used in the request. """""" http_status = 505 message = ""HTTP Version Not Supported"" # _code_map contains all the classes that have http_status attribute. _code_map = dict( (getattr(obj, 'http_status', None), obj) for name, obj in six.iteritems(vars(sys.modules[__name__])) if inspect.isclass(obj) and getattr(obj, 'http_status', False) ) def from_response(response, method, url): """"""Returns an instance of :class:`HttpError` or subclass based on response. :param response: instance of `requests.Response` class :param method: HTTP method used for request :param url: URL used for request """""" kwargs = { ""http_status"": response.status_code, ""response"": response, ""method"": method, ""url"": url, ""request_id"": response.headers.get(""x-compute-request-id""), } if ""retry-after"" in response.headers: kwargs[""retry_after""] = response.headers[""retry-after""] content_type = response.headers.get(""Content-Type"", """") if content_type.startswith(""application/json""): try: body = response.json() except ValueError: pass else: if hasattr(body, ""keys""): error = body[body.keys()[0]] kwargs[""message""] = error.get(""message"", None) kwargs[""details""] = error.get(""details"", None) elif content_type.startswith(""text/""): kwargs[""details""] = response.text try: cls = _code_map[response.status_code] except KeyError: if 500 <= response.status_code < 600: cls = HttpServerError elif 400 <= response.status_code < 500: cls = HTTPClientError else: cls = HttpError return cls(**kwargs) ",,439,0
openstack%2Fnova~master~If34053c1dce851dc6b3fd2bd1b8ebd03849bae53,openstack/nova,master,If34053c1dce851dc6b3fd2bd1b8ebd03849bae53,Remove XML support from certificates v3 API,MERGED,2014-01-29 08:03:56.000000000,2014-01-30 19:37:48.000000000,2014-01-30 19:37:44.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 7641}, {'_account_id': 8430}, {'_account_id': 9578}, {'_account_id': 9581}]","[{'number': 1, 'created': '2014-01-29 08:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ea4ce4fb53092ce648689c07d3c63c5e2283eb0', 'message': 'Remove XML support from certificates v3 API plugins\n\nThis patch removes XML support from certificates v3 API plugins.\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If34053c1dce851dc6b3fd2bd1b8ebd03849bae53\n'}, {'number': 2, 'created': '2014-01-29 08:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a7502e0a40da85c5e8750088af1502f025e61cf', 'message': 'Remove XML support from certificates v3 API\n\nThis patch removes XML support from certificates v3 API.\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If34053c1dce851dc6b3fd2bd1b8ebd03849bae53\n'}, {'number': 3, 'created': '2014-01-29 10:25:28.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/certificates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/03f991730f7932b5008eb9660f72694d6284f7ef', 'message': 'Remove XML support from certificates v3 API\n\nThis patch removes XML support from certificates v3 API.\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If34053c1dce851dc6b3fd2bd1b8ebd03849bae53\n'}]",0,69807,03f991730f7932b5008eb9660f72694d6284f7ef,29,7,3,9581,,,0,"Remove XML support from certificates v3 API

This patch removes XML support from certificates v3 API.

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: If34053c1dce851dc6b3fd2bd1b8ebd03849bae53
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/69807/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/certificates.py'],1,7ea4ce4fb53092ce648689c07d3c63c5e2283eb0,bp/remove-v3-xml-api,,"def make_certificate(elem): elem.set('data') elem.set('private_key') class CertificateTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('certificate', selector='certificate') make_certificate(root) return xmlutil.MasterTemplate(root, 1) @wsgi.serializers(xml=CertificateTemplate) @wsgi.serializers(xml=CertificateTemplate)",0,15
openstack%2Ftrove~master~I87304b8451f89b113a50bfdb07195cad3497f719,openstack/trove,master,I87304b8451f89b113a50bfdb07195cad3497f719,Provide guest_info per datastore,ABANDONED,2013-11-26 16:42:48.000000000,2014-01-30 19:29:27.000000000,,"[{'_account_id': 3}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8491}]","[{'number': 1, 'created': '2013-11-26 16:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0e78d45ea1a14cbc341047c0a051a0ffc8c8a15d', 'message': 'Provide guest_info per datastore\n\nReason:\n - Trove configs holding more then one options for different datastores,\n   best way to simplify main config is to externalize config per datastore,\n   which would handle datastore specific parameters\nChanges:\n - Refactoring jinja2 code in common/templates.py;\n - Using jinja for loading {datastore}/guest_info.config;\n - Updating file injection flow at all possible variants:\n\t- _create_server_volume;\n\t- _create_server_volume_heat;\n\t- _create_server_volume_individually.\n - Updating heat template to expect guest_info and guest_config parameters;\n - Testing;\n - Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}, {'number': 2, 'created': '2013-11-26 18:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e8ba9755686f6772484ea80836423f3f62d4c518', 'message': 'Provide guest_info per datastore\n\nReason:\n - Trove configs holding more then one options for different datastores,\n   best way to simplify main config is to externalize config per datastore,\n   which would handle datastore specific parameters\nChanges:\n - Refactoring jinja2 code in common/templates.py;\n - Using jinja for loading {datastore}/guest_info.config;\n - Updating file injection flow at all possible variants:\n\t- _create_server_volume;\n\t- _create_server_volume_heat;\n\t- _create_server_volume_individually.\n - Updating heat template to expect guest_info and guest_config parameters;\n - Testing;\n - Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}, {'number': 3, 'created': '2013-11-27 10:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e8857567547b78dd47a9e1068ad7bf4cd2644246', 'message': 'Provide guest_info per datastore\n\nReason:\n - Trove configs holding more then one options for different datastores,\n   best way to simplify main config is to externalize config per datastore,\n   which would handle datastore specific parameters\nChanges:\n - Refactoring jinja2 code in common/templates.py;\n - Using jinja for loading {datastore}/guest_info.config;\n - Updating file injection flow at all possible variants:\n\t- _create_server_volume;\n\t- _create_server_volume_heat;\n\t- _create_server_volume_individually.\n - Updating heat template to expect guest_info and guest_config parameters;\n - Testing;\n - Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}, {'number': 4, 'created': '2013-11-28 16:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e755bfd340424cc19566060c6c9692e93480a256', 'message': 'Provide guest_info per datastore\n\nReason:\n- Trove configs holding more then one options for different datastores,\nbest way to simplify main config is to externalize config per datastore,\nwhich would handle datastore specific parameters\nChanges:\n- Refactoring jinja2 code in common/templates.py;\n- Using jinja for loading {datastore}/guest_info.config;\n- Updating file injection flow at all possible variants:\n- _create_server_volume;\n- _create_server_volume_heat;\n- _create_server_volume_individually.\n- Updating heat template to expect guest_info and guest_config parameters;\n- Testing;\n- Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}, {'number': 5, 'created': '2013-11-28 16:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7a7d033514e4019ca30e208ef689e045ba1e2f8a', 'message': 'Provide guest_info per datastore\n\nReason:\n- Trove configs holding more then one options for different datastores,\nbest way to simplify main config is to externalize config per datastore,\nwhich would handle datastore specific parameters\nChanges:\n- Refactoring jinja2 code in common/templates.py;\n- Using jinja for loading {datastore}/guest_info.config;\n- Updating file injection flow at all possible variants:\n- _create_server_volume;\n- _create_server_volume_heat;\n- _create_server_volume_individually.\n- Updating heat template to expect guest_info and guest_config parameters;\n- Testing;\n- Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}, {'number': 6, 'created': '2013-11-28 16:51:14.000000000', 'files': ['etc/trove/trove-guestagent.conf.sample', 'trove/common/cfg.py', 'trove/templates/mysql/heat.template', 'trove/templates/mysql/guest_info.config', 'trove/tests/unittests/common/test_template.py', 'trove/taskmanager/models.py', 'trove/common/template.py', 'doc/source/dev/configuration.rst', 'trove/tests/unittests/taskmanager/test_models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/70e336e3ff6fccd31f6dd0b828ccce05ee5d7d9d', 'message': 'Provide guest_info per datastore\n\nReason:\n- Trove configs holding more then one options for different datastores,\nbest way to simplify main config is to externalize config per datastore,\nwhich would handle datastore specific parameters\nChanges:\n- Refactoring jinja2 code in common/templates.py;\n- Using jinja for loading {datastore}/guest_info.config;\n- Updating file injection flow at all possible variants:\n- _create_server_volume;\n- _create_server_volume_heat;\n- _create_server_volume_individually.\n- Updating heat template to expect guest_info and guest_config parameters;\n- Testing;\n- Adding docs which explains how to use such feature.\n\nChange-Id: I87304b8451f89b113a50bfdb07195cad3497f719\nImplements: blueprint template-config-per-datastore\n'}]",7,58574,70e336e3ff6fccd31f6dd0b828ccce05ee5d7d9d,38,5,6,8415,,,0,"Provide guest_info per datastore

Reason:
- Trove configs holding more then one options for different datastores,
best way to simplify main config is to externalize config per datastore,
which would handle datastore specific parameters
Changes:
- Refactoring jinja2 code in common/templates.py;
- Using jinja for loading {datastore}/guest_info.config;
- Updating file injection flow at all possible variants:
- _create_server_volume;
- _create_server_volume_heat;
- _create_server_volume_individually.
- Updating heat template to expect guest_info and guest_config parameters;
- Testing;
- Adding docs which explains how to use such feature.

Change-Id: I87304b8451f89b113a50bfdb07195cad3497f719
Implements: blueprint template-config-per-datastore
",git fetch https://review.opendev.org/openstack/trove refs/changes/74/58574/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/trove/trove-guestagent.conf.sample', 'trove/templates/mysql/heat.template', 'trove/templates/mysql/guest_info.config', 'trove/tests/unittests/common/test_template.py', 'trove/taskmanager/models.py', 'trove/common/template.py', 'doc/source/dev/configuration.rst', 'trove/tests/unittests/taskmanager/test_models.py']",8,0e78d45ea1a14cbc341047c0a051a0ffc8c8a15d,bp/template-config-per-datastore," with NamedTemporaryFile(prefix='mysql', suffix="".cloudinit"", delete=False) as f: when(taskmanager_models.template).load_guest_info(any()).thenReturn( ""blah-blah=blah-blah"") def test_instance_create_fail_on_missing_guest_info(self): self.assertRaises(TroveError, self.freshinstancetasks._create_server, None, None, None, ""mysql_blah"", None, None) None, None, None, ""mysql"", None, None) self.assertIsNotNone(server.files['/etc/guest_info']) None, None, None, 'mysql', None, availability_zone='nova') None, None, None, 'mysql', None, 'nova') None, None, None, 'mysql', None, None)"," with NamedTemporaryFile(suffix="".cloudinit"", delete=False) as f: None, None, None, ""test"", None, None) None, None, None, None, None, availability_zone='nova') None, None, None, None, None, 'nova') None, None, None, None, None, None)",146,43
openstack%2Fpython-ironicclient~master~Ide0bb6bcef845d5cf746d71eaed38d425403e17a,openstack/python-ironicclient,master,Ide0bb6bcef845d5cf746d71eaed38d425403e17a,Reuse Resource from oslo,MERGED,2013-12-18 15:59:00.000000000,2014-01-30 19:28:46.000000000,2014-01-30 19:28:46.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 6172}, {'_account_id': 6773}, {'_account_id': 7491}, {'_account_id': 7763}, {'_account_id': 8106}, {'_account_id': 8968}, {'_account_id': 9545}]","[{'number': 2, 'created': '2013-12-18 15:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/052a18719c8e57dd0e4cae9e6e3e0d41cb5ec6fc', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}, {'number': 3, 'created': '2013-12-18 15:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/25ece776395931aad2e4c350782fddf8433f62a5', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}, {'number': 1, 'created': '2013-12-18 15:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/d813e5de32f00581b333c729d4794b6d2061a0ff', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}, {'number': 6, 'created': '2013-12-30 13:18:29.000000000', 'files': ['ironicclient/common/base.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/64c9492855bfc5b3ad7a09a7aed2322c61cca8c3', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}, {'number': 4, 'created': '2013-12-30 13:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/06f625eca5fc773d24c4d6136929db03f1359c7a', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}, {'number': 5, 'created': '2013-12-30 13:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5d4ee024de00e139f3d46242df78f090ba88b4ab', 'message': 'Reuse Resource from oslo\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nRelated to blueprint common-client-library-2\n\nChange-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a\n'}]",4,62921,64c9492855bfc5b3ad7a09a7aed2322c61cca8c3,52,11,6,9545,,,0,"Reuse Resource from oslo

In the process of unification of the clients code we should
reuse common functionality from Oslo.

Related to blueprint common-client-library-2

Change-Id: Ide0bb6bcef845d5cf746d71eaed38d425403e17a
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/21/62921/6 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/common/base.py'],1,052a18719c8e57dd0e4cae9e6e3e0d41cb5ec6fc,bp/common-client-library-2,from ironicclient.openstack.common.apiclient import baseclass Resource(base.Resource):,"import sixclass Resource(object): def __init__(self, manager, info, loaded=False): self.manager = manager self._info = info self._add_details(info) self._loaded = loaded def _add_details(self, info): for (k, v) in six.iteritems(info): setattr(self, k, v) def __getattr__(self, k): if k not in self.__dict__: # NOTE(bcwaldon): disallow lazy-loading if already loaded once if not self.is_loaded(): self.get() return self.__getattr__(k) raise AttributeError(k) else: return self.__dict__[k] def __repr__(self): reprkeys = sorted(k for k in self.__dict__.keys() if k[0] != '_' and k != 'manager') info = "", "".join(""%s=%s"" % (k, getattr(self, k)) for k in reprkeys) return ""<%s %s>"" % (self.__class__.__name__, info) def get(self): # set_loaded() first ... so if we have to bail, we know we tried. self.set_loaded(True) if not hasattr(self.manager, 'get'): return new = self.manager.get(self.id) if new: self._add_details(new._info) def __eq__(self, other): if not isinstance(other, self.__class__): return False if hasattr(self, 'id') and hasattr(other, 'id'): return self.id == other.id return self._info == other._info def is_loaded(self): return self._loaded def set_loaded(self, val): self._loaded = val",2,51
openstack%2Fopenstack-manuals~master~I8ed19c2b5e149a84d5bd52ec7a35c9c7eca17490,openstack/openstack-manuals,master,I8ed19c2b5e149a84d5bd52ec7a35c9c7eca17490,change to hds-volume-driver.xml,ABANDONED,2014-01-30 18:38:14.000000000,2014-01-30 19:23:54.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-30 18:38:14.000000000', 'files': ['doc/config-reference/block-storage/drivers/hds-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5e5bcdcb8416f7c6f03715bf44751d502020fe85', 'message': 'change to hds-volume-driver.xml\n\nextra . was removed from beginning of sentence\n\nChange-Id: I8ed19c2b5e149a84d5bd52ec7a35c9c7eca17490\n'}]",0,70185,5e5bcdcb8416f7c6f03715bf44751d502020fe85,3,2,1,9382,,,0,"change to hds-volume-driver.xml

extra . was removed from beginning of sentence

Change-Id: I8ed19c2b5e149a84d5bd52ec7a35c9c7eca17490
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/70185/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hds-volume-driver.xml'],1,5e5bcdcb8416f7c6f03715bf44751d502020fe85,hds-volume-driverr, </footnote>Each respective service label associates with, </footnote>. Each respective service label associates with,1,1
openstack%2Fnova~master~I9cf3017668774e93d4679067e41da2c8301606a0,openstack/nova,master,I9cf3017668774e93d4679067e41da2c8301606a0,Remove XML support from some v3 API plugins,MERGED,2014-01-28 22:55:47.000000000,2014-01-30 19:23:19.000000000,2014-01-30 19:23:16.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5754}, {'_account_id': 6348}, {'_account_id': 9578}, {'_account_id': 9581}]","[{'number': 1, 'created': '2014-01-28 22:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bcabeeb92d11854755fb1315a5d28be4519fdd3', 'message': 'Remove XML support from some v3 API plugins\n\nRemove XML support from the following v3 API plugins:\n\n - access_ips\n - agents\n - availability_zone\n - block_device_mapping\n - cells\n - extended_availability_zone\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9cf3017668774e93d4679067e41da2c8301606a0\n'}, {'number': 2, 'created': '2014-01-28 23:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9096f22af4633d0050e23a58359fe1f4b6230034', 'message': 'Remove XML support from some v3 API plugins\n\nRemove XML support from the following v3 API plugins:\n\n - access_ips\n - agents\n - availability_zone\n - block_device_mapping\n - cells\n - extended_availability_zone\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9cf3017668774e93d4679067e41da2c8301606a0\n'}, {'number': 3, 'created': '2014-01-28 23:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a5010fbc616a22f56404dad8f360d2cad5e723f', 'message': 'Remove XML support from some v3 API plugins\n\nRemove XML support from the following v3 API plugins:\n\n - access_ips\n - agents\n - availability_zone\n - block_device_mapping\n - cells\n - extended_availability_zone\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9cf3017668774e93d4679067e41da2c8301606a0\n'}, {'number': 4, 'created': '2014-01-28 23:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3401912c7be46bff501347dc78631ad4b2c5632c', 'message': 'Remove XML support from some v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - access_ips\n - agents\n - availability_zone\n - block_device_mapping\n - cells\n - extended_availability_zone\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9cf3017668774e93d4679067e41da2c8301606a0\n'}, {'number': 5, 'created': '2014-01-30 14:58:55.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/extended_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/plugins/v3/access_ips.py', 'nova/api/openstack/compute/plugins/v3/agents.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d33b661418f74bc1ed3c7c548438f3e3ef0fbe27', 'message': 'Remove XML support from some v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - access_ips\n - agents\n - availability_zone\n - block_device_mapping\n - cells\n - extended_availability_zone\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9cf3017668774e93d4679067e41da2c8301606a0\n'}]",0,69739,d33b661418f74bc1ed3c7c548438f3e3ef0fbe27,27,8,5,1561,,,0,"Remove XML support from some v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - access_ips
 - agents
 - availability_zone
 - block_device_mapping
 - cells
 - extended_availability_zone

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: I9cf3017668774e93d4679067e41da2c8301606a0
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/69739/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/extended_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/plugins/v3/access_ips.py', 'nova/api/openstack/compute/plugins/v3/agents.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py']",6,5bcabeeb92d11854755fb1315a5d28be4519fdd3,bp/remove-v3-xml-api,,"from nova.api.openstack import commonfrom nova.api.openstack import xmlutildef make_availability_zone(elem): elem.set('name', 'zone_name') zoneStateElem = xmlutil.SubTemplateElement(elem, 'zone_state', selector='zone_state') zoneStateElem.set('available') hostsElem = xmlutil.SubTemplateElement(elem, 'hosts', selector='hosts') hostElem = xmlutil.SubTemplateElement(hostsElem, 'host', selector=xmlutil.get_items) hostElem.set('name', 0) svcsElem = xmlutil.SubTemplateElement(hostElem, 'services', selector=1) svcElem = xmlutil.SubTemplateElement(svcsElem, 'service', selector=xmlutil.get_items) svcElem.set('name', 0) svcStateElem = xmlutil.SubTemplateElement(svcElem, 'service_state', selector=1) svcStateElem.set('available') svcStateElem.set('active') svcStateElem.set('updated_at') # Attach metadata node elem.append(common.MetadataTemplate()) class AvailabilityZonesTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('availability_zones') zoneElem = xmlutil.SubTemplateElement(root, 'availability_zone', selector='availability_zone_info') make_availability_zone(zoneElem) return xmlutil.MasterTemplate(root, 1, nsmap={ AvailabilityZone.alias: AvailabilityZone.namespace}) @wsgi.serializers(xml=AvailabilityZonesTemplate) @wsgi.serializers(xml=AvailabilityZonesTemplate) def server_xml_extract_server_deserialize(self, server_node, server_dict): availability_zone = server_node.getAttribute(ATTRIBUTE_NAME) if availability_zone: server_dict[ATTRIBUTE_NAME] = availability_zone",0,256
openstack%2Fnova~master~I58a29974253a5acfb04f42cf4712ba290203cb5a,openstack/nova,master,I58a29974253a5acfb04f42cf4712ba290203cb5a,Remove XML support from some v3 API plugins(e.g. services),MERGED,2014-01-29 05:10:42.000000000,2014-01-30 19:22:25.000000000,2014-01-30 19:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 05:10:42.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/config_drive.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/plugins/v3/services.py', 'nova/api/openstack/compute/plugins/v3/versions.py', 'nova/api/openstack/compute/plugins/v3/user_data.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/08007b8adaa1993d0ffafc858e524df0464151b6', 'message': 'Remove XML support from some v3 API plugins(e.g. services)\n\nRemove XML support from the following v3 compute API plugins:\n\n - config_drive\n - services\n - simple_tenant_usage\n - versions\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I58a29974253a5acfb04f42cf4712ba290203cb5a\n'}]",2,69794,08007b8adaa1993d0ffafc858e524df0464151b6,9,5,1,7641,,,0,"Remove XML support from some v3 API plugins(e.g. services)

Remove XML support from the following v3 compute API plugins:

 - config_drive
 - services
 - simple_tenant_usage
 - versions

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: I58a29974253a5acfb04f42cf4712ba290203cb5a
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/69794/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/config_drive.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/plugins/v3/services.py', 'nova/api/openstack/compute/plugins/v3/versions.py', 'nova/api/openstack/compute/plugins/v3/user_data.py']",5,08007b8adaa1993d0ffafc858e524df0464151b6,bp/remove-v3-xml-api,," def server_xml_extract_server_deserialize(self, server_node, server_dict): user_data = server_node.getAttribute(ATTRIBUTE_NAME) if user_data: server_dict[ATTRIBUTE_NAME] = user_data",0,100
openstack%2Fkeystone~master~I78cba95f05647858fb33840fcc3cb47e9d2d95af,openstack/keystone,master,I78cba95f05647858fb33840fcc3cb47e9d2d95af,Add a docstring and rename mapping tests,MERGED,2014-01-29 21:03:36.000000000,2014-01-30 19:22:11.000000000,2014-01-30 19:22:10.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-01-29 21:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/04097047f58522ec232344cf5cb79e1e15ab583b', 'message': 'Add a docstring and rename mapping tests\n\nRenamed MappingTests to MappingCRUDTests, in order to account\nfor new rules processing tests. Also added a docstring.\n\nChange-Id: I78cba95f05647858fb33840fcc3cb47e9d2d95af\n'}, {'number': 2, 'created': '2014-01-29 21:29:03.000000000', 'files': ['keystone/tests/test_v3_federation.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0a72039dfc85346b160e996cd84fa480e6c6f773', 'message': 'Add a docstring and rename mapping tests\n\nRenamed MappingTests to MappingCRUDTests, in order to account\nfor new rules processing tests. Also added a docstring.\n\nChange-Id: I78cba95f05647858fb33840fcc3cb47e9d2d95af\n'}]",0,69977,0a72039dfc85346b160e996cd84fa480e6c6f773,14,4,2,6482,,,0,"Add a docstring and rename mapping tests

Renamed MappingTests to MappingCRUDTests, in order to account
for new rules processing tests. Also added a docstring.

Change-Id: I78cba95f05647858fb33840fcc3cb47e9d2d95af
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/69977/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_v3_federation.py'],1,04097047f58522ec232344cf5cb79e1e15ab583b,add_doc_string,"class MappingCRUDTests(FederationTests): """"""A class for testing CRUD operations for Mappings.""""""",class MappingTests(FederationTests):,2,1
openstack%2Ftripleo-image-elements~master~Ia8a61bf55f4337f40ee40b0fd381b2f776f67312,openstack/tripleo-image-elements,master,Ia8a61bf55f4337f40ee40b0fd381b2f776f67312,Add nova-ironic element to replace nova-baremetal,MERGED,2014-01-13 23:54:34.000000000,2014-01-30 19:19:49.000000000,2014-01-30 19:19:49.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6488}, {'_account_id': 6738}, {'_account_id': 7419}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-01-13 23:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/38278486d68ed3a52838874787e8ddfa22fbb6cf', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 2, 'created': '2014-01-28 16:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4f502aecf8f4bc3e3c9314fbb6225927d10cda28', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 3, 'created': '2014-01-29 17:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/37817c5cb8d2f89fffca680e735180cc9e665f2f', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together. This\npatch also moves the Ironic ssh power key to /mnt/state.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 4, 'created': '2014-01-29 18:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/96d558267fc2e663b4e3c69370f944e2cc709d66', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together. This\npatch also moves the Ironic ssh power key to /mnt/state.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 5, 'created': '2014-01-29 18:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1c391a1ebf66bfdba936fd1a32c58820e7f48c3a', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together. This\npatch also moves the Ironic ssh power key to /mnt/state.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 6, 'created': '2014-01-30 15:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c0a15f1160992d46b824ae602094692c75bdd12d', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together. This\npatch also moves the Ironic ssh power key to /mnt/state.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}, {'number': 7, 'created': '2014-01-30 16:56:41.000000000', 'files': ['elements/nova-ironic/os-refresh-config/configure.d/81-nat-metadata', 'elements/nova-ironic/element-deps', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/nova-ironic/os-refresh-config/configure.d/80-ironic-ssh-power-key', 'elements/nova-ironic/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/023c58dd05399c718c45f364a51863564df7a8b9', 'message': 'Add nova-ironic element to replace nova-baremetal\n\nAdd new nova-ironic element which can be used in place of the existing\nnova-baremetal element. These are not meant to be used together. This\npatch also moves the Ironic ssh power key to /mnt/state.\n\nNOTE: Nova ""ironic"" driver has not landed upstream yet, but this image\ncan be built with it ahead of time by setting the following:\n\n  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova\n  export DIB_REPOREF_nova=refs/changes/28/51328\n\nChange-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312\n'}]",26,66461,023c58dd05399c718c45f364a51863564df7a8b9,31,8,7,2889,,,0,"Add nova-ironic element to replace nova-baremetal

Add new nova-ironic element which can be used in place of the existing
nova-baremetal element. These are not meant to be used together. This
patch also moves the Ironic ssh power key to /mnt/state.

NOTE: Nova ""ironic"" driver has not landed upstream yet, but this image
can be built with it ahead of time by setting the following:

  export DIB_REPOLOCATION_nova=https://review.openstack.org/openstack/nova
  export DIB_REPOREF_nova=refs/changes/28/51328

Change-Id: Ia8a61bf55f4337f40ee40b0fd381b2f776f67312
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/61/66461/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova-ironic/os-refresh-config/configure.d/81-nat-metadata', 'elements/nova-ironic/element-deps', 'elements/nova-ironic/install.d/80-pxelinux', 'elements/nova-ironic/os-refresh-config/configure.d/80-ironic-tftpboot-dir', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/nova-ironic/os-refresh-config/configure.d/80-ironic-ssh-power-key', 'elements/nova-ironic/README.md']",7,38278486d68ed3a52838874787e8ddfa22fbb6cf,(detached,Nova Ironic services ----------------------- Configures the nova-ironic directories on disk and pulls the nova-ironic driver from the gerrit review: https://review.openstack.org/#/c/51328 ,,88,0
openstack%2Fironic~master~Ib9de6636cf900a02b8f22c0403b0edd3604b1cad,openstack/ironic,master,Ib9de6636cf900a02b8f22c0403b0edd3604b1cad,Update method doc strings in pxe.py,MERGED,2014-01-16 03:11:25.000000000,2014-01-30 19:14:08.000000000,2014-01-30 19:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-01-16 03:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/32052a14355674a5ca56a8027d50041243f2db4b', 'message': 'Update method doc strings in pxe.py\n\nChange-Id: Ib9de6636cf900a02b8f22c0403b0edd3604b1cad\n'}, {'number': 2, 'created': '2014-01-21 23:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0f3a493dfef90a609df1b7b31d178f682d656b5e', 'message': 'Update method doc strings in pxe.py\n\nChange-Id: Ib9de6636cf900a02b8f22c0403b0edd3604b1cad\n'}, {'number': 3, 'created': '2014-01-28 22:17:09.000000000', 'files': ['ironic/drivers/modules/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/819809d6fdf6a2c97d64827db69bc7ecfe80a47b', 'message': 'Update method doc strings in pxe.py\n\nChange-Id: Ib9de6636cf900a02b8f22c0403b0edd3604b1cad\n'}]",1,66996,819809d6fdf6a2c97d64827db69bc7ecfe80a47b,33,10,3,2889,,,0,"Update method doc strings in pxe.py

Change-Id: Ib9de6636cf900a02b8f22c0403b0edd3604b1cad
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/66996/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/pxe.py'],1,32052a14355674a5ca56a8027d50041243f2db4b,doc-update," Creates a temporary keystone token file, updates the Neutron DHCP port options for next boot, and issues a reboot request to the power driver. This causes the node to boot into the deployment ramdisk and triggers the next phase of PXE-based deployment via VendorPassthru._continue_deploy(). Power off the node. All actual clean-up is done in the clean_up() method which should be called separately. """"""Prepare the deployment environment for this node. Generates the TFTP configuration for PXE-booting both the deployment and user images, fetches the images from Glance and adds them to the local cache. :param task: a TaskManager instance. :param node: the Node to act upon. """""" """"""Clean up the deployment environment for this node. Delete the deploy and user images from the local cache, if no remaining active nodes require them. Removes the TFTP configuration files for this node. As a precaution, this method also ensures the keystone auth token file was removed. :param task: a TaskManager instance. :param node: the Node to act upon. """""""," This method validates whether the 'driver_info' property of the supplied node contains the required information for this driver to deploy images to the node. Given a node with complete metadata, deploy the indicated image to the node. Given a node that has been previously deployed to, do all cleanup and tear down necessary to ""un-deploy"" that node.",26,8
openstack%2Fironic~master~Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db,openstack/ironic,master,Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db,Minor documentation update,MERGED,2014-01-16 03:11:25.000000000,2014-01-30 19:14:07.000000000,2014-01-30 19:14:06.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-16 03:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/669c9fc059684f17928e819d6c1283d96d30910a', 'message': ""Minor documentation update\n\n* Update the index page's description.\n* Add a section about the hash ring to architecture.\n* Add some new modules to, and remove some old modules from,\n  the developer doc quick links, to make the list of quicklinks\n  shorter and more useful.\n* Correct a few broken links in the developer docs.\n* Rename /dev to /developer.\n\nChange-Id: Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db\n""}, {'number': 2, 'created': '2014-01-21 23:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0faca5d4a15e9c2a6a774d01f67153705ae3e3ab', 'message': ""Minor documentation update\n\n* Update the index page's description.\n* Add a section about the hash ring to architecture.\n* Add some new modules to, and remove some old modules from,\n  the developer doc quick links, to make the list of quicklinks\n  shorter and more useful.\n* Correct a few broken links in the developer docs.\n* Rename /dev to /developer.\n\nChange-Id: Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db\n""}, {'number': 3, 'created': '2014-01-28 21:42:56.000000000', 'files': ['doc/source/index.rst', 'doc/source/dev/api.rst', 'doc/source/dev/db.rst', 'doc/source/dev/architecture.rst', 'doc/source/dev/common.rst', 'doc/source/dev/cmd.rst', 'doc/source/dev/drivers.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/017f99120b1fd72b052833be9c6808da81bc1544', 'message': ""Minor documentation update\n\n* Update the index page's description.\n* Add a section about the hash ring to architecture.\n* Add some new modules to, and remove some old modules from,\n  the developer doc quick links, to make the list of quicklinks\n  shorter and more useful.\n* Correct a few broken links in the developer docs.\n\nChange-Id: Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db\n""}]",6,66995,017f99120b1fd72b052833be9c6808da81bc1544,25,9,3,2889,,,0,"Minor documentation update

* Update the index page's description.
* Add a section about the hash ring to architecture.
* Add some new modules to, and remove some old modules from,
  the developer doc quick links, to make the list of quicklinks
  shorter and more useful.
* Correct a few broken links in the developer docs.

Change-Id: Ifac1dc355631a2d77b7ccdea362fb83ffbe6a4db
",git fetch https://review.opendev.org/openstack/ironic refs/changes/95/66995/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer/dev-quickstart.rst', 'doc/source/developer/architecture.rst', 'doc/source/developer/contributing.rst', 'doc/source/dev/cmd.rst', 'doc/source/developer/common.rst', 'doc/source/index.rst', 'doc/source/developer/conductor.rst', 'doc/source/dev/db.rst', 'doc/source/developer/api.rst', 'doc/source/dev/drivers.rst', 'doc/source/developer/drivers.rst', 'doc/source/developer/db.rst']",12,669c9fc059684f17928e819d6c1283d96d30910a,doc-update,.. _db: ============ DB API Layer ============ .. toctree:: ../api/ironic.db.api ../api/ironic.db.sqlalchemy.models ,,67,59
openstack%2Fceilometer~master~I45a84769d6ee46d53e580ae08cbbf32ed20562b1,openstack/ceilometer,master,I45a84769d6ee46d53e580ae08cbbf32ed20562b1,Fix measurement docs to correctly represent Existance meters,MERGED,2014-01-28 17:29:55.000000000,2014-01-30 19:12:36.000000000,2014-01-30 19:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-01-28 17:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c8a6e7741f5881c5f678e97cab9f74231eaae67', 'message': 'Fix measurement docs around various meters to represent\nExistance instead of Duration\n\nThere are various meters in the measurement docs that\nwrongly note the meter as Duration instead of its\nexistance. The meters fixed include network, port,\nrouter, subnet, floating ip, volume.\n\nfixes bug #1252988\n\nChange-Id: I45a84769d6ee46d53e580ae08cbbf32ed20562b1\n'}, {'number': 2, 'created': '2014-01-28 18:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3bc01d34f55b3f48d87a3a6c2cd84335ce258d94', 'message': 'Fix measurement docs to correctly represent Existance meters\n\nThere are various meters in the measurement docs that\nwrongly note the meter as Duration instead of its\nexistance. The meters fixed include network, port,\nrouter, subnet, floating ip, volume.\n\nfixes bug #1252988\n\nChange-Id: I45a84769d6ee46d53e580ae08cbbf32ed20562b1\n'}, {'number': 3, 'created': '2014-01-29 13:10:14.000000000', 'files': ['doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/65ae6da03cfa8e0806c63a1fd6aa3d3a63aa243c', 'message': 'Fix measurement docs to correctly represent Existance meters\n\nThere are various meters in the measurement docs that\nwrongly note the meter as Duration instead of its\nexistance. The meters fixed include network, port,\nrouter, subnet, floating ip, volume.\n\nfixes bug #1252988\n\nChange-Id: I45a84769d6ee46d53e580ae08cbbf32ed20562b1\n'}]",1,69675,65ae6da03cfa8e0806c63a1fd6aa3d3a63aa243c,17,6,3,6924,,,0,"Fix measurement docs to correctly represent Existance meters

There are various meters in the measurement docs that
wrongly note the meter as Duration instead of its
existance. The meters fixed include network, port,
router, subnet, floating ip, volume.

fixes bug #1252988

Change-Id: I45a84769d6ee46d53e580ae08cbbf32ed20562b1
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/75/69675/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/measurements.rst'],1,5c8a6e7741f5881c5f678e97cab9f74231eaae67,bug/1252988,network Gauge network netw ID notification Existance of networksubnet Gauge subnet subnt ID notification Existance of subnetport Gauge port port ID notification Existance of portrouter Gauge router rtr ID notification Existance of routerip.floating Gauge ip ip ID both Existance of floating ipvolume Gauge volume vol ID notification Existance of volume,network Gauge network netw ID notification Duration of networksubnet Gauge subnet subnt ID notification Duration of subnetport Gauge port port ID notification Duration of portrouter Gauge router rtr ID notification Duration of routerip.floating Gauge ip ip ID both Duration of floating ipvolume Gauge volume vol ID notification Duration of volume,6,6
openstack%2Fceilometer~master~I902606928fc59f5663d638d05f237fe3e5e1175d,openstack/ceilometer,master,I902606928fc59f5663d638d05f237fe3e5e1175d,Fix docs on what an instance meter represents,MERGED,2014-01-15 01:54:38.000000000,2014-01-30 19:11:59.000000000,2014-01-30 19:11:58.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7450}, {'_account_id': 7478}, {'_account_id': 9320}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-01-15 01:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c9dc94397d8ae2be4eb8ef63d5116fdb68c12a47', 'message': 'Fix docs on what an instance meter represents\n\ninstance meter is a gauge which meters an instance\nitself. The current description of duration of\ninstance is misleading.\n\nfixes bug #1266313\n\nChange-Id: I902606928fc59f5663d638d05f237fe3e5e1175d\n'}, {'number': 2, 'created': '2014-01-27 20:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e00be6d6f3ddc7ec8b57e80d7b0a0a987bd2ffac', 'message': 'Fix docs on what an instance meter represents\n\ninstance meter is a gauge which meters an instance\nitself. The current description of duration of\ninstance is misleading.\n\nfixes bug #1266313\n\nChange-Id: I902606928fc59f5663d638d05f237fe3e5e1175d\n'}, {'number': 3, 'created': '2014-01-28 17:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/005c9ed06452fc797b82978551f6fe11c256a289', 'message': 'Fix docs on what an instance meter represents\n\ninstance meter is a gauge which meters an instance\nitself. The current description of duration of\ninstance is misleading.\n\nfixes bug #1266313\n\nChange-Id: I902606928fc59f5663d638d05f237fe3e5e1175d\n'}, {'number': 4, 'created': '2014-01-29 13:11:10.000000000', 'files': ['doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/39f545c19af76c0f655cc7dcb150e820bea816fc', 'message': 'Fix docs on what an instance meter represents\n\ninstance meter is a gauge which meters an instance\nitself. The current description of duration of\ninstance is misleading.\n\nfixes bug #1266313\n\nChange-Id: I902606928fc59f5663d638d05f237fe3e5e1175d\n'}]",7,66746,39f545c19af76c0f655cc7dcb150e820bea816fc,41,11,4,6924,,,0,"Fix docs on what an instance meter represents

instance meter is a gauge which meters an instance
itself. The current description of duration of
instance is misleading.

fixes bug #1266313

Change-Id: I902606928fc59f5663d638d05f237fe3e5e1175d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/46/66746/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/measurements.rst'],1,c9dc94397d8ae2be4eb8ef63d5116fdb68c12a47,bug/1266313,instance Gauge instance inst ID both instance instance:<type> Gauge instance inst ID both instance <type> (openstack types),instance Gauge instance inst ID both Duration of instance instance:<type> Gauge instance inst ID both Duration of instance <type> (openstack types),2,2
openstack%2Fnova~master~I49da82632c884cdac36ee37674a4d0fc360fdd83,openstack/nova,master,I49da82632c884cdac36ee37674a4d0fc360fdd83,Remove XML support from v3 API plugins,MERGED,2014-01-29 03:23:49.000000000,2014-01-30 19:08:56.000000000,2014-01-30 19:08:52.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:23:49.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/instance_actions.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/ips.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/keypairs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43cbe96a7ff841e8caeabd1c99feaf82977328eb', 'message': 'Remove XML support from v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - hosts\n - hypervisors\n - instance_actions\n - ips\n - keypairs\n\nPart of blueprint remove-v3-xml-api\nDocImpact\n\nChange-Id: I49da82632c884cdac36ee37674a4d0fc360fdd83\n'}]",0,69779,43cbe96a7ff841e8caeabd1c99feaf82977328eb,9,5,1,7641,,,0,"Remove XML support from v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - hosts
 - hypervisors
 - instance_actions
 - ips
 - keypairs

Part of blueprint remove-v3-xml-api
DocImpact

Change-Id: I49da82632c884cdac36ee37674a4d0fc360fdd83
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/69779/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/instance_actions.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/ips.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/keypairs.py']",5,43cbe96a7ff841e8caeabd1c99feaf82977328eb,bp/remove-v3-xml-api,,"from nova.api.openstack import xmlutilclass KeypairTemplate(xmlutil.TemplateBuilder): def construct(self): return xmlutil.MasterTemplate(xmlutil.make_flat_dict('keypair'), 1) class KeypairsTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('keypairs') elem = xmlutil.make_flat_dict('keypair', selector='keypairs', subselector='keypair') root.append(elem) return xmlutil.MasterTemplate(root, 1) @wsgi.serializers(xml=KeypairTemplate) @wsgi.serializers(xml=KeypairTemplate) @wsgi.serializers(xml=KeypairsTemplate)class ServerKeyNameTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('server') root.set('key_name', 'key_name') return xmlutil.SlaveTemplate(root, 1) class ServersKeyNameTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('servers') elem = xmlutil.SubTemplateElement(root, 'server', selector='servers') elem.set('key_name', 'key_name') return xmlutil.SlaveTemplate(root, 1) resp_obj.attach(xml=ServerKeyNameTemplate()) resp_obj.attach(xml=ServersKeyNameTemplate())",0,226
openstack%2Fpython-troveclient~master~I73219d29efd71185cdf6ff56a7fe41165541681f,openstack/python-troveclient,master,I73219d29efd71185cdf6ff56a7fe41165541681f,Fixes troveclient raising undefined exception ConnectionError,MERGED,2014-01-30 14:12:38.000000000,2014-01-30 19:06:19.000000000,2014-01-30 19:06:19.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8311}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-01-30 14:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5c6792fc4a5001d255b9e2060740fa5d96d9beff', 'message': 'troveclient raises undefined exception ConnectionError\n\nReason: ConnectionError exception is raised which is not defined in\n        python-troveclient/troveclient/openstack/common/apiclient/exceptions.py\n\nReasolution: ConnectionError should be renamed to ConnectionRefused.\n\nCloses-Bug: #1269336\n\nChange-Id: I73219d29efd71185cdf6ff56a7fe41165541681f\n'}, {'number': 2, 'created': '2014-01-30 14:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/10490632c9571fc1d3bd954fa23791db53ff6977', 'message': 'Fixes troveclient raising undefined exception ConnectionError\n\nReason: ConnectionError exception is raised which is not defined in\n        python-troveclient/troveclient/openstack/common/apiclient/exceptions.py\n\nReasolution: ConnectionError should be renamed to ConnectionRefused.\n\nCloses-Bug: #1269336\n\nChange-Id: I73219d29efd71185cdf6ff56a7fe41165541681f\n'}, {'number': 3, 'created': '2014-01-30 14:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d8e33ae375f2ee87cd6c0793f209637bcc55fce0', 'message': 'Fixes troveclient raising undefined exception ConnectionError\n\nReason: ConnectionError exception is raised which is not defined in\n        python-troveclient/troveclient/openstack/common/apiclient/exceptions.py\n\nReasolution: ConnectionError should be renamed to ConnectionRefused.\n\nCloses-Bug: #1240950\n\nChange-Id: I73219d29efd71185cdf6ff56a7fe41165541681f\n'}, {'number': 4, 'created': '2014-01-30 17:24:16.000000000', 'files': ['troveclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/1fe0e4ee604ea9b6951eb3cc8e573b0e3b81bfde', 'message': 'Fixes troveclient raising undefined exception ConnectionError\n\nReason: ConnectionError exception is raised which is not defined in\n        python-troveclient/troveclient/openstack/common/apiclient/exceptions.py\n\nChange: ConnectionError should be renamed to ConnectionRefused.\n\nCloses-Bug: #1240950\n\nChange-Id: I73219d29efd71185cdf6ff56a7fe41165541681f\n'}]",1,70119,1fe0e4ee604ea9b6951eb3cc8e573b0e3b81bfde,24,7,4,8311,,,0,"Fixes troveclient raising undefined exception ConnectionError

Reason: ConnectionError exception is raised which is not defined in
        python-troveclient/troveclient/openstack/common/apiclient/exceptions.py

Change: ConnectionError should be renamed to ConnectionRefused.

Closes-Bug: #1240950

Change-Id: I73219d29efd71185cdf6ff56a7fe41165541681f
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/19/70119/3 && git format-patch -1 --stdout FETCH_HEAD,['troveclient/client.py'],1,5c6792fc4a5001d255b9e2060740fa5d96d9beff,patch, raise exceptions.ConnectionRefused(msg), raise exceptions.ConnectionError(msg),1,1
openstack%2Fironic~master~I05115e1a66974244e03020652b560829884ebaac,openstack/ironic,master,I05115e1a66974244e03020652b560829884ebaac,Delete the iscsi target,MERGED,2014-01-20 17:11:44.000000000,2014-01-30 19:03:07.000000000,2014-01-30 19:03:06.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-20 17:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c61e3e91758aab7d062c8b08a3f48694aef86f3e', 'message': ""Delete the iscsi target the deploy\n\nAfter writing the image on the disk and logout the iscsi session,\nwe also need to delete that session to cleanup things, making sure it\ndoesn't appear as an available iscsi node to connect to.\n\nPartial-Bug: #1261644\nChange-Id: I05115e1a66974244e03020652b560829884ebaac\n""}, {'number': 2, 'created': '2014-01-20 17:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f8fc964eb84b25e1c6c8dc383e4f0ccb9b761e3f', 'message': ""Delete the iscsi target\n\nAfter writing the image on the disk and logout the iscsi session,\nwe also need to delete that session to cleanup things, making sure it\ndoesn't appear as an available iscsi node to connect to.\n\nPartial-Bug: #1261644\nChange-Id: I05115e1a66974244e03020652b560829884ebaac\n""}, {'number': 3, 'created': '2014-01-20 17:18:18.000000000', 'files': ['ironic/drivers/modules/deploy_utils.py', 'ironic/tests/drivers/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/12da86c10f235befd3ac829e8f0404d7035f553b', 'message': ""Delete the iscsi target\n\nAfter writing the image on the disk and logout the iscsi session,\nwe also need to delete that session to cleanup things, making sure it\ndoesn't appear as an available iscsi node to connect to.\n\nPartial-Bug: #1261644\nChange-Id: I05115e1a66974244e03020652b560829884ebaac\n""}]",3,67877,12da86c10f235befd3ac829e8f0404d7035f553b,16,9,3,6773,,,0,"Delete the iscsi target

After writing the image on the disk and logout the iscsi session,
we also need to delete that session to cleanup things, making sure it
doesn't appear as an available iscsi node to connect to.

Partial-Bug: #1261644
Change-Id: I05115e1a66974244e03020652b560829884ebaac
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/67877/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/deploy_utils.py', 'ironic/tests/drivers/test_deploy_utils.py']",2,c61e3e91758aab7d062c8b08a3f48694aef86f3e,iscsiadm-delete," 'logout_iscsi', 'delete_iscsi', 'make_partitions', 'is_block_device', 'dd', 'mkswap', 'block_uuid', 'switch_pxe_config', 'notify'] mock.call.delete_iscsi(address, port, iqn), def test_always_logout_and_delete_iscsi(self): """"""logout_iscsi() and delete_iscsi() must be called once login_iscsi() is called."""""" 'logout_iscsi', 'delete_iscsi', 'work_on_disk'] mock.call.logout_iscsi(address, port, iqn), mock.call.delete_iscsi(address, port, iqn)]"," 'logout_iscsi', 'make_partitions', 'is_block_device', 'dd', 'mkswap', 'block_uuid', 'switch_pxe_config', 'notify'] def test_always_logout_iscsi(self): """"""logout_iscsi() must be called once login_iscsi() is called."""""" 'logout_iscsi', 'work_on_disk'] mock.call.logout_iscsi(address, port, iqn)]",22,7
openstack%2Fironic~master~I44e21c287510f355907fa45cbcb14b7f8c493a96,openstack/ironic,master,I44e21c287510f355907fa45cbcb14b7f8c493a96,Run mkfs as root,MERGED,2014-01-21 17:27:03.000000000,2014-01-30 18:59:35.000000000,2014-01-30 18:59:35.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-21 17:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f67efc143c06886c14318329681a782c6e4472a2', 'message': 'Add rootwrap filters for mkfs\n\nThe the mkfs command requires root permission to write the filesystem\non certain devices.\n\nCloses-Bug: #1271243\nChange-Id: I44e21c287510f355907fa45cbcb14b7f8c493a96\n'}, {'number': 2, 'created': '2014-01-21 17:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa5255f54d2f3f3701b7fce3aaf51dc884b7eb6b', 'message': 'Run mkfs as root\n\nThe the mkfs command requires root permission to write the filesystem on\ncertain devices. This patch is adding the run_as_root=True flag for the\nexecute() in the mkfs() function in common.utils.py, and is also adding\nthe mkfs to the rootwrap filters.\n\nCloses-Bug: #1271243\nChange-Id: I44e21c287510f355907fa45cbcb14b7f8c493a96\n'}, {'number': 3, 'created': '2014-01-21 19:12:33.000000000', 'files': ['ironic/tests/test_utils.py', 'etc/ironic/rootwrap.d/ironic-deploy-helper.filters', 'ironic/common/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7553dbfd6802a797bc52091994882bf8e3dd956c', 'message': 'Run mkfs as root\n\nThe mkfs command requires root permission to write the filesystem on\ncertain devices. This patch is adding the run_as_root=True flag for the\nexecute() in the mkfs() function in common/utils.py, and is also adding\nthe mkfs to the rootwrap filters.\n\nCloses-Bug: #1271243\nChange-Id: I44e21c287510f355907fa45cbcb14b7f8c493a96\n'}]",6,68182,7553dbfd6802a797bc52091994882bf8e3dd956c,17,8,3,6773,,,0,"Run mkfs as root

The mkfs command requires root permission to write the filesystem on
certain devices. This patch is adding the run_as_root=True flag for the
execute() in the mkfs() function in common/utils.py, and is also adding
the mkfs to the rootwrap filters.

Closes-Bug: #1271243
Change-Id: I44e21c287510f355907fa45cbcb14b7f8c493a96
",git fetch https://review.opendev.org/openstack/ironic refs/changes/82/68182/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/test_utils.py', 'etc/ironic/rootwrap.d/ironic-deploy-helper.filters', 'ironic/common/utils.py']",3,f67efc143c06886c14318329681a782c6e4472a2,mkfs-rootwrap," execute(*args, run_as_root=True)", execute(*args),13,10
openstack%2Fironic~master~Ia5a3c25ca809edcfeaefd423609b43f2658f1870,openstack/ironic,master,Ia5a3c25ca809edcfeaefd423609b43f2658f1870,Removed unused exceptions,MERGED,2014-01-24 05:44:57.000000000,2014-01-30 18:53:05.000000000,2014-01-30 18:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 7069}, {'_account_id': 7711}, {'_account_id': 8125}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-24 05:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6e2aba6fef91e5558136510c84200afc82e17324', 'message': ""Removed unused exceptions\n\nThere's a bunch of exceptions that were copied over from nova-baremetal into ironic that are currently unused and don't have any immediate applicability.\n\nChange-Id: Ia5a3c25ca809edcfeaefd423609b43f2658f1870\nCloses-Bug: 1271283\n""}, {'number': 2, 'created': '2014-01-24 06:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/444f86ed54f9121fe3eaf7586108738a77bee945', 'message': ""Removed unused exceptions\n\nThere's a bunch of exceptions that were copied over from nova-baremetal\ninto ironic that are currently unused and don't have any immediate\napplicability.\n\nChange-Id: Ia5a3c25ca809edcfeaefd423609b43f2658f1870\nCloses-Bug: 1271283\n""}, {'number': 3, 'created': '2014-01-28 21:25:17.000000000', 'files': ['ironic/common/exception.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/77ea8ae5a977558dee45a7a0bfc2ea0669de9816', 'message': ""Removed unused exceptions\n\nThere's a bunch of exceptions that were copied over from nova-baremetal\ninto ironic that are currently unused and don't have any immediate\napplicability.\n\nChange-Id: Ia5a3c25ca809edcfeaefd423609b43f2658f1870\nCloses-Bug: 1271283\n""}]",1,68852,77ea8ae5a977558dee45a7a0bfc2ea0669de9816,26,7,3,8125,,,0,"Removed unused exceptions

There's a bunch of exceptions that were copied over from nova-baremetal
into ironic that are currently unused and don't have any immediate
applicability.

Change-Id: Ia5a3c25ca809edcfeaefd423609b43f2658f1870
Closes-Bug: 1271283
",git fetch https://review.opendev.org/openstack/ironic refs/changes/52/68852/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/exception.py'],1,6e2aba6fef91e5558136510c84200afc82e17324,fix-1273472,,"class AdminRequired(NotAuthorized): message = _(""User does not have admin privileges"") class PolicyNotAuthorized(NotAuthorized): message = _(""Policy doesn't allow %(action)s to be performed."") class InvalidCPUInfo(Invalid): message = _(""Unacceptable CPU info: %(reason)s"") class InvalidIpAddressError(Invalid): message = _(""%(address)s is not a valid IP v4/6 address."") class InvalidDiskFormat(Invalid): message = _(""Disk format %(disk_format)s is not acceptable"") class DiskNotFound(NotFound): message = _(""No disk at %(location)s"") class HostNotFound(NotFound): message = _(""Host %(host)s could not be found."") class ConsoleNotFound(NotFound): message = _(""Console %(console_id)s could not be found."") class FileNotFound(NotFound): message = _(""File %(file_path)s could not be found."") class NoValidHost(NotFound): message = _(""No valid host was found. %(reason)s"") class NodeInUse(InvalidState): message = _(""Unable to complete the requested action because node "" ""%(node)s is currently in use by another process."") class NodeNotConfigured(InvalidState): message = _(""Can not change power state because node %(node)s "" ""is not fully configured."") class HTTPException(IronicException): message = _(""Requested version of OpenStack Images API is not available."") ",0,54
openstack%2Fironic~master~I6a89a15012ba044f094d9043b32657c36ca01e20,openstack/ironic,master,I6a89a15012ba044f094d9043b32657c36ca01e20,Bump version of sphinxcontrib-pecanwsme,MERGED,2014-01-10 22:58:30.000000000,2014-01-30 18:51:41.000000000,2014-01-30 18:51:41.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-10 22:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bfe1f354c2adf02422ce59b95a03d21005f8b6b1', 'message': 'Bump version of sphinxcontrib-pecanwsme\n\nVersion bump to add PATCH and DELETE support to API docs.\n\nChange-Id: I6a89a15012ba044f094d9043b32657c36ca01e20\nCloses-bug: 1261917\n'}, {'number': 2, 'created': '2014-01-28 21:15:11.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4a3dd7da2511e8452d68049cfb5ce6a923b89251', 'message': 'Bump version of sphinxcontrib-pecanwsme\n\nVersion bump to add PATCH and DELETE support to API docs.\n\nChange-Id: I6a89a15012ba044f094d9043b32657c36ca01e20\nCloses-bug: #1261917\n'}]",1,66078,4a3dd7da2511e8452d68049cfb5ce6a923b89251,24,5,2,2889,,,0,"Bump version of sphinxcontrib-pecanwsme

Version bump to add PATCH and DELETE support to API docs.

Change-Id: I6a89a15012ba044f094d9043b32657c36ca01e20
Closes-bug: #1261917
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/66078/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,bfe1f354c2adf02422ce59b95a03d21005f8b6b1,fix-1273472,sphinxcontrib-pecanwsme>=0.6,sphinxcontrib-pecanwsme>=0.5,1,1
openstack%2Fironic~master~I7282d86d0919d5057baff92010e4c1715126709e,openstack/ironic,master,I7282d86d0919d5057baff92010e4c1715126709e,Remove deploy kernel and ramdisk global config,MERGED,2014-01-30 15:29:57.000000000,2014-01-30 18:50:21.000000000,2014-01-30 18:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}]","[{'number': 1, 'created': '2014-01-30 15:29:57.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/12b524c076fd0d129cd7b855fce7fd565a2641fb', 'message': 'Remove deploy kernel and ramdisk global config\n\nThis options are not very useful since ironic can deploy to\nmultiple archs and any config change will require a service restart.\n\nChange-Id: I7282d86d0919d5057baff92010e4c1715126709e\nCloses-Bug: #1272741\n'}]",0,70140,12b524c076fd0d129cd7b855fce7fd565a2641fb,6,3,1,1726,,,0,"Remove deploy kernel and ramdisk global config

This options are not very useful since ironic can deploy to
multiple archs and any config change will require a service restart.

Change-Id: I7282d86d0919d5057baff92010e4c1715126709e
Closes-Bug: #1272741
",git fetch https://review.opendev.org/openstack/ironic refs/changes/40/70140/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/pxe.py']",2,12b524c076fd0d129cd7b855fce7fd565a2641fb,no_dhcp_template," d_info['deploy_kernel'] = info.get('pxe_deploy_kernel', None) d_info['deploy_ramdisk'] = info.get('pxe_deploy_ramdisk', None)"," cfg.StrOpt('deploy_kernel', help='Default kernel image ID used in deployment phase'), cfg.StrOpt('deploy_ramdisk', help='Default ramdisk image ID used in deployment phase'), d_info['deploy_kernel'] = info.get('pxe_deploy_kernel', CONF.pxe.deploy_kernel) d_info['deploy_ramdisk'] = info.get('pxe_deploy_ramdisk', CONF.pxe.deploy_ramdisk)",2,16
openstack%2Fmurano-deployment~master~I8398d6a0740997585037bc2c3d692edc90fca42d,openstack/murano-deployment,master,I8398d6a0740997585037bc2c3d692edc90fca42d,Fixing dependency.list,MERGED,2013-10-17 15:39:50.000000000,2014-01-30 18:49:22.000000000,2014-01-30 18:49:22.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-10-17 15:39:50.000000000', 'files': ['image-builder/dependency.list', 'image-builder/share/scripts/ws-2008r2-std/wpi.ps1', 'image-builder/share/scripts/wpi.ps1', 'image-builder/share/scripts/ws-2012-std/wpi.ps1', 'image-builder/share/scripts/ws-2012-core/wpi.ps1', 'image-builder/share/scripts/ws-2008r2-core/wpi.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/0998e1ba82ffb616bec067dd4827f5fb60f60aa4', 'message': 'Fixing dependency.list\n\n * setting name for sysinternals zipfile\n * setting name for muranoagent zipfile\n * correcting git reference in ws-2012-std/wpi.ps1\n * adding url for powershell v3\n * adding url for .net 4.0\n * adding url for .net 4.5\n\nChange-Id: I8398d6a0740997585037bc2c3d692edc90fca42d\n'}]",0,52427,0998e1ba82ffb616bec067dd4827f5fb60f60aa4,7,3,1,1032,,,0,"Fixing dependency.list

 * setting name for sysinternals zipfile
 * setting name for muranoagent zipfile
 * correcting git reference in ws-2012-std/wpi.ps1
 * adding url for powershell v3
 * adding url for .net 4.0
 * adding url for .net 4.5

Change-Id: I8398d6a0740997585037bc2c3d692edc90fca42d
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/27/52427/1 && git format-patch -1 --stdout FETCH_HEAD,"['image-builder/dependency.list', 'image-builder/share/scripts/ws-2008r2-std/wpi.ps1', 'image-builder/share/scripts/wpi.ps1', 'image-builder/share/scripts/ws-2012-std/wpi.ps1', 'image-builder/share/scripts/ws-2012-core/wpi.ps1', 'image-builder/share/scripts/ws-2008r2-core/wpi.ps1']",6,0998e1ba82ffb616bec067dd4827f5fb60f60aa4,,,,20,15
openstack%2Fzaqar~master~Ib7e6f42e98f31af1c731c0b69fd26de1572b4471,openstack/zaqar,master,Ib7e6f42e98f31af1c731c0b69fd26de1572b4471,chore: Fix pylint errors,MERGED,2014-01-23 17:34:55.000000000,2014-01-30 18:48:13.000000000,2014-01-30 18:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-01-23 17:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/51dd88b2ab0f1072bba8164f7a5b28e8d77d64f2', 'message': 'chore: Fix pylint errors\n\nFixed a couple pylint errors and disabled remaining false positives.\n\nChange-Id: Ib7e6f42e98f31af1c731c0b69fd26de1572b4471\n'}, {'number': 2, 'created': '2014-01-23 19:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d3eb246db5492f70c54d784970d7ed93c50e4646', 'message': 'chore: Fix pylint errors\n\nFixed a couple pylint errors and disabled remaining false positives.\n\nChange-Id: Ib7e6f42e98f31af1c731c0b69fd26de1572b4471\n'}, {'number': 3, 'created': '2014-01-27 20:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/59e5a298a72d6cbc9e3b2b4a47149bf85c9311f9', 'message': 'chore: Fix pylint errors\n\nFixed a couple pylint errors and disabled remaining false positives.\n\nChange-Id: Ib7e6f42e98f31af1c731c0b69fd26de1572b4471\n'}, {'number': 4, 'created': '2014-01-30 17:18:10.000000000', 'files': ['marconi/queues/storage/sharding.py', 'marconi/queues/transport/base.py', 'marconi/tests/queues/storage/base.py', 'marconi/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9e3eb1336fbcd3de186738b9119f97e9f448afca', 'message': 'chore: Fix pylint errors\n\nFixed a couple pylint errors and disabled remaining false positives.\n\nChange-Id: Ib7e6f42e98f31af1c731c0b69fd26de1572b4471\n'}]",1,68701,9e3eb1336fbcd3de186738b9119f97e9f448afca,25,5,4,6427,,,0,"chore: Fix pylint errors

Fixed a couple pylint errors and disabled remaining false positives.

Change-Id: Ib7e6f42e98f31af1c731c0b69fd26de1572b4471
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/01/68701/4 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/storage/sharding.py', 'marconi/queues/transport/base.py', 'marconi/tests/queues/storage/base.py', 'marconi/tests/functional/base.py']",4,51dd88b2ab0f1072bba8164f7a5b28e8d77d64f2,lint, if (self.cfg.marconi.run_server and not self.server): # pylint: disable=not-callable, if (self.cfg.marconi.run_server and not self.server):,10,4
openstack%2Fnova~master~I3ce2bcb1a7d7e152b0bfb96316ce8f1aab10061d,openstack/nova,master,I3ce2bcb1a7d7e152b0bfb96316ce8f1aab10061d,Remove XML support from quota and scheduler_hints v3 API plugins,MERGED,2014-01-29 03:21:04.000000000,2014-01-30 18:47:32.000000000,2014-01-30 18:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 6348}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:21:04.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/quota_classes.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7bfe20cdd65beb13f0ccd4a0b18f16e62873253', 'message': 'Remove XML support from quota and scheduler_hints v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - quota_classes\n - quota_sets\n - scheduler_hints\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I3ce2bcb1a7d7e152b0bfb96316ce8f1aab10061d\n'}]",2,69777,a7bfe20cdd65beb13f0ccd4a0b18f16e62873253,10,6,1,7641,,,0,"Remove XML support from quota and scheduler_hints v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - quota_classes
 - quota_sets
 - scheduler_hints

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: I3ce2bcb1a7d7e152b0bfb96316ce8f1aab10061d
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/69777/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/quota_classes.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py']",3,a7bfe20cdd65beb13f0ccd4a0b18f16e62873253,bp/remove-v3-xml-api,," def __init__(self, extension_info): super(SchedulerHints, self).__init__(extension_info) self.xml_deserializer = wsgi.XMLDeserializer() def server_xml_extract_server_deserialize(self, server_node, server_dict): scheduler_hints = self._extract_scheduler_hints(server_node) if scheduler_hints: server_dict[ALIAS + ':scheduler_hints'] = scheduler_hints def _extract_scheduler_hints(self, server_node): """"""Marshal the scheduler hints attribute of a parsed request."""""" node = self.xml_deserializer.find_first_child_named_in_namespace( server_node, ""http://docs.openstack.org/compute/ext/scheduler-hints/api/v3"", ""scheduler_hints"") if node: scheduler_hints = {} for child in self.xml_deserializer.extract_elements(node): scheduler_hints.setdefault(child.nodeName, []) value = self.xml_deserializer.extract_text(child).strip() scheduler_hints[child.nodeName].append(value) return scheduler_hints else: return None",0,76
openstack%2Fnova~master~I9745285cb6053dcb634c23002f1f24412dc62021,openstack/nova,master,I9745285cb6053dcb634c23002f1f24412dc62021,Remove XML support from flavor v3 API plugins,MERGED,2014-01-29 03:24:38.000000000,2014-01-30 18:46:28.000000000,2014-01-30 18:46:25.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:24:38.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/api/openstack/compute/plugins/v3/flavor_rxtx.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/flavors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4803d7c7e084e0ff13cc4054b4fa1455495bd395', 'message': 'Remove XML support from flavor v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - flavor_access\n - flavor_manage\n - flavor_rxtx\n - flavors\n - flavors_extraspecs\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: I9745285cb6053dcb634c23002f1f24412dc62021\n'}]",0,69780,4803d7c7e084e0ff13cc4054b4fa1455495bd395,9,5,1,7641,,,0,"Remove XML support from flavor v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - flavor_access
 - flavor_manage
 - flavor_rxtx
 - flavors
 - flavors_extraspecs

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: I9745285cb6053dcb634c23002f1f24412dc62021
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/69780/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/api/openstack/compute/plugins/v3/flavor_rxtx.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/flavors.py']",5,4803d7c7e084e0ff13cc4054b4fa1455495bd395,bp/remove-v3-xml-api,,"from nova.api.openstack import xmlutildef make_flavor(elem, detailed=False): elem.set('name') elem.set('id') if detailed: elem.set('ram') elem.set('disk') elem.set('vcpus') elem.set('swap') elem.set('ephemeral') elem.set('disabled') xmlutil.make_links(elem, 'links') flavor_nsmap = {None: xmlutil.XMLNS_V11, 'atom': xmlutil.XMLNS_ATOM} class FlavorTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('flavor', selector='flavor') make_flavor(root, detailed=True) return xmlutil.MasterTemplate(root, 1, nsmap=flavor_nsmap) class MinimalFlavorsTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('flavors') elem = xmlutil.SubTemplateElement(root, 'flavor', selector='flavors') make_flavor(elem) return xmlutil.MasterTemplate(root, 1, nsmap=flavor_nsmap) class FlavorsTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('flavors') elem = xmlutil.SubTemplateElement(root, 'flavor', selector='flavors') make_flavor(elem, detailed=True) return xmlutil.MasterTemplate(root, 1, nsmap=flavor_nsmap) @wsgi.serializers(xml=MinimalFlavorsTemplate) @wsgi.serializers(xml=FlavorsTemplate) @wsgi.serializers(xml=FlavorTemplate)",0,141
openstack%2Fnova~master~If3e8d82d6db2a2ff328ba477bffd5081f098be9a,openstack/nova,master,If3e8d82d6db2a2ff328ba477bffd5081f098be9a,Remove XML support from some server v3 API plugins,MERGED,2014-01-29 03:20:00.000000000,2014-01-30 18:29:49.000000000,2014-01-30 18:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 6348}, {'_account_id': 7641}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 03:20:00.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/compute/plugins/v3/server_usage.py', 'nova/api/openstack/compute/plugins/v3/server_metadata.py', 'nova/api/openstack/compute/plugins/v3/server_password.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2f4c901b6f26cf3d31b29eef7222338179afa3c', 'message': 'Remove XML support from some server v3 API plugins\n\nRemove XML support from the following v3 compute API plugins:\n\n - security_groups\n - server_diagnostics\n - server_metadata\n - server_password\n - server_usage\n\nPart of blueprint remove-v3-xml-api\n\nDocImpact\n\nChange-Id: If3e8d82d6db2a2ff328ba477bffd5081f098be9a\n'}]",0,69776,b2f4c901b6f26cf3d31b29eef7222338179afa3c,15,6,1,7641,,,0,"Remove XML support from some server v3 API plugins

Remove XML support from the following v3 compute API plugins:

 - security_groups
 - server_diagnostics
 - server_metadata
 - server_password
 - server_usage

Part of blueprint remove-v3-xml-api

DocImpact

Change-Id: If3e8d82d6db2a2ff328ba477bffd5081f098be9a
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/69776/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/compute/plugins/v3/server_usage.py', 'nova/api/openstack/compute/plugins/v3/server_metadata.py', 'nova/api/openstack/compute/plugins/v3/server_password.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py']",5,b2f4c901b6f26cf3d31b29eef7222338179afa3c,bp/remove-v3-xml-api,,"from nova.api.openstack import xmlutil resp_obj.attach(xml=SecurityGroupServerTemplate()) resp_obj.attach(xml=SecurityGroupServersTemplate())class SecurityGroupsTemplateElement(xmlutil.TemplateElement): def will_render(self, datum): return ""security_groups"" in datum def make_server(elem): secgrps = SecurityGroupsTemplateElement('security_groups') elem.append(secgrps) secgrp = xmlutil.SubTemplateElement(secgrps, 'security_group', selector=""security_groups"") secgrp.set('name') class SecurityGroupServerTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('server') make_server(root) return xmlutil.SlaveTemplate(root, 1) class SecurityGroupServersTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('servers') elem = xmlutil.SubTemplateElement(root, 'server', selector='servers') make_server(elem) return xmlutil.SlaveTemplate(root, 1) def __init__(self, extension_info): super(SecurityGroups, self).__init__(extension_info) self.xml_deserializer = wsgi.XMLDeserializer() def _extract_security_groups(self, server_node): """"""Marshal the security_groups attribute of a parsed request."""""" node = self.xml_deserializer.find_first_child_named_in_namespace( server_node, self.namespace, 'security_groups') if node is not None: security_groups = [] for sg_node in self.xml_deserializer.find_children_named( node, ""security_group""): item = {} name = self.xml_deserializer.find_attribute_or_element( sg_node, 'name') if name: item[""name""] = name security_groups.append(item) return security_groups else: return None def server_xml_extract_server_deserialize(self, server_node, server_dict): security_groups = self._extract_security_groups(server_node) if security_groups is not None: server_dict[ATTRIBUTE_NAME] = security_groups ",0,143
openstack%2Fnova~master~Ibae554f11490f8504bcf9ea6d87a8f91ca353401,openstack/nova,master,Ibae554f11490f8504bcf9ea6d87a8f91ca353401,NetworkInfoAsyncWrapper.__str__ can deadlock when invoked from a log message,ABANDONED,2014-01-30 07:15:52.000000000,2014-01-30 18:22:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 5441}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-30 07:15:52.000000000', 'files': ['nova/tests/network/test_network_info_async.py', 'nova/network/model.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/09057ed39d56a770d60ed16c5e1a5638851684e5', 'message': 'NetworkInfoAsyncWrapper.__str__ can deadlock when invoked from a log message\n\nChange-Id: Ibae554f11490f8504bcf9ea6d87a8f91ca353401\nCloses-Bug: #1273478\n'}]",0,70066,09057ed39d56a770d60ed16c5e1a5638851684e5,5,4,1,10186,,,0,"NetworkInfoAsyncWrapper.__str__ can deadlock when invoked from a log message

Change-Id: Ibae554f11490f8504bcf9ea6d87a8f91ca353401
Closes-Bug: #1273478
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/70066/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_network_info_async.py', 'nova/network/model.py']",2,09057ed39d56a770d60ed16c5e1a5638851684e5,async_wrapper_deadlock," if self._gt: return ""<%s at 0x%s>"" % (self.__class__.__name__, id(self)) else: return super(NetworkInfoAsyncWrapper, self).__str__(*args, **kwargs) if self._gt: return ""<%s at 0x%s>"" % (self.__class__.__name__, id(self)) else: return super(NetworkInfoAsyncWrapper, self).__repr__( *args, **kwargs)"," fn = super(NetworkInfoAsyncWrapper, self).__str__ return self._sync_wrapper(fn, *args, **kwargs) fn = super(NetworkInfoAsyncWrapper, self).__repr__ return self._sync_wrapper(fn, *args, **kwargs)",77,4
openstack%2Ftempest~master~I35849526778e3ad9428ee9c791a78cf0b86b190f,openstack/tempest,master,I35849526778e3ad9428ee9c791a78cf0b86b190f,Remove baremetal xml support,MERGED,2014-01-15 15:56:04.000000000,2014-01-30 18:19:04.000000000,2014-01-30 18:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6623}, {'_account_id': 7872}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-01-15 15:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/07f1c0395b8cdf4954a271b952fec2fbf15b3db8', 'message': 'Remove baremetal xml support\n\nIronic decided to not to support xml in API, therefore we remove\ncorresponding workpiece from the tests.\n\nChange-Id: I35849526778e3ad9428ee9c791a78cf0b86b190f\n'}, {'number': 2, 'created': '2014-01-15 16:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b27f38ae3d6248cd2894a05cb091342445c33a8d', 'message': 'Remove baremetal xml support\n\nIronic decided to not to support xml in API, therefore we remove\ncorresponding workpiece from the tests.\n\nChange-Id: I35849526778e3ad9428ee9c791a78cf0b86b190f\n'}, {'number': 3, 'created': '2014-01-28 22:51:14.000000000', 'files': ['tempest/clients.py', 'tempest/services/baremetal/v1/client_xml.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e0a8de0283c741cdbe803f0a6d4596690fbb146', 'message': 'Remove baremetal xml support\n\nIronic decided to not to support xml in API, therefore we remove\ncorresponding workpiece from the tests.\n\nChange-Id: I35849526778e3ad9428ee9c791a78cf0b86b190f\n'}]",0,66878,2e0a8de0283c741cdbe803f0a6d4596690fbb146,20,6,3,8968,,,0,"Remove baremetal xml support

Ironic decided to not to support xml in API, therefore we remove
corresponding workpiece from the tests.

Change-Id: I35849526778e3ad9428ee9c791a78cf0b86b190f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/66878/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/baremetal/v1/client_xml.py'],1,07f1c0395b8cdf4954a271b952fec2fbf15b3db8,remove_baremetal_xml_support,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import rest_client from tempest.services.baremetal.v1 import base_v1 as base from tempest.services.compute.xml import common as xml class BaremetalClientXML(rest_client.RestClientXML, base.BaremetalClientV1): """"""Tempest REST client for Ironic XML API v1."""""" def __init__(self, config, username, password, auth_url, tenant_name=None): super(BaremetalClientXML, self).__init__(config, username, password, auth_url, tenant_name) self.serialize = self.json_to_xml self.deserialize = xml.xml_to_json def json_to_xml(self, object_type, object_dict): """""" Brainlessly converts a specification of an object to XML string. :param object_type: Kind of the object. :param object_dict: Specification of the object attributes as a dict. :return: An XML string that corresponds to the specification. """""" root = xml.Element(object_type) for attr_name, value in object_dict: # Handle nested dictionaries if isinstance(value, dict): value = self.json_to_xml(attr_name, value) root.append(xml.Element(attr_name, value)) return str(xml.Document(root)) def _patch_request(self, resource_name, uuid, patch_object): """"""Changes Content-Type header to application/json for jsonpatch."""""" self.headers['Content-Type'] = 'application/json' try: super(self)._patch_request(self, resource_name, uuid, patch_object) finally: self.headers['Content-Type'] = 'application/xml' ",0,57
openstack%2Fpuppet-heat~master~I5507147b71874149972635ed974fc96724441bb1,openstack/puppet-heat,master,I5507147b71874149972635ed974fc96724441bb1,Add syslog support to heat module,MERGED,2014-01-29 16:01:26.000000000,2014-01-30 17:57:42.000000000,2014-01-30 17:57:42.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-01-29 16:01:26.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/0f263b4580c22a85efb1d6429e6f023208978a8f', 'message': 'Add syslog support to heat module\n\nChange-Id: I5507147b71874149972635ed974fc96724441bb1\n'}]",0,69889,0f263b4580c22a85efb1d6429e6f023208978a8f,6,4,1,7155,,,0,"Add syslog support to heat module

Change-Id: I5507147b71874149972635ed974fc96724441bb1
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/89/69889/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/heat_init_spec.rb']",2,0f263b4580c22a85efb1d6429e6f023208978a8f,add_syslog_support," it_configures 'with syslog disabled' it_configures 'with syslog enabled' it_configures 'with syslog enabled and custom settings' shared_examples_for 'with syslog disabled' do it { should contain_heat_config('DEFAULT/use_syslog').with_value(false) } end shared_examples_for 'with syslog enabled' do before do params.merge!( :use_syslog => 'true' ) end it do should contain_heat_config('DEFAULT/use_syslog').with_value(true) should contain_heat_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') end end shared_examples_for 'with syslog enabled and custom settings' do before do params.merge!( :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' ) end it do should contain_heat_config('DEFAULT/use_syslog').with_value(true) should contain_heat_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') end end ",,57,1
openstack%2Foperations-guide~master~If06ab896a1625515fe386ee61e9dab06b3566f60,openstack/operations-guide,master,If06ab896a1625515fe386ee61e9dab06b3566f60,Revert of Nephos PDF link,MERGED,2014-01-25 07:40:32.000000000,2014-01-30 17:57:00.000000000,2014-01-30 17:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 6859}]","[{'number': 1, 'created': '2014-01-25 07:40:32.000000000', 'files': ['doc/openstack-ops/ch_ops_advanced_configuration.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/8877f4100faaffb317a2e774f5e94c3883c80c80', 'message': 'Revert of Nephos PDF link\n\nRemoves the mention of the Nephos PDF for enhancing IPv6 support in\nHavana.\n\nChange-Id: If06ab896a1625515fe386ee61e9dab06b3566f60\n'}]",0,69109,8877f4100faaffb317a2e774f5e94c3883c80c80,10,4,1,6859,,,0,"Revert of Nephos PDF link

Removes the mention of the Nephos PDF for enhancing IPv6 support in
Havana.

Change-Id: If06ab896a1625515fe386ee61e9dab06b3566f60
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/09/69109/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_advanced_configuration.xml'],1,8877f4100faaffb317a2e774f5e94c3883c80c80,revert-ipv6-havana," <para>The Havana release with OpenStack Networking (Neutron) does not offer complete support of IPv6. Better support is planned for the Icehouse release. You can follow along the progress being made by watching the Neutron IPv6 Subteam at work (<link xlink:href=""https://wiki.openstack.org/wiki/Meetings/Neutron-IPv6-Subteam"" >https://wiki.openstack.org/wiki/Meetings/Neutron-IPv6-Subteam</link>). </para>"," <para>The Havana release with OpenStack Networking (Neutron) does not offer complete support of IPv6 IP addresses due to known issues with Open vSwitch and dnsmasq, as documented in this white paper (<link xlink:href=""http://www.nephos6.com/pdf/OpenStack-Havana-on-IPv6.pdf"" >http://www.nephos6.com/pdf/OpenStack-Havana-on-IPv6.pdf</link>). Their support definition includes both setting up the infrastructure nodes to communicate by IPv6 and enabling virtual machines to be assigned IPv6 IP addresses and gain connectivity to networks.</para>",9,9
openstack%2Foperations-guide~master~Ic1fd2f9a3a6c4ba3a6f3e7131b9f12f36699d7b4,openstack/operations-guide,master,Ic1fd2f9a3a6c4ba3a6f3e7131b9f12f36699d7b4,Updates the DAIR use case,MERGED,2014-01-29 21:54:54.000000000,2014-01-30 17:56:28.000000000,2014-01-30 17:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-01-29 21:54:54.000000000', 'files': ['doc/openstack-ops/app_usecases.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/c43ece293abae300095ae3a4fed7273db6b528d1', 'message': 'Updates the DAIR use case\n\nThis commit makes a small changes to the DAIR use case.\n\nChange-Id: Ic1fd2f9a3a6c4ba3a6f3e7131b9f12f36699d7b4\n'}]",0,69988,c43ece293abae300095ae3a4fed7273db6b528d1,7,3,1,6859,,,0,"Updates the DAIR use case

This commit makes a small changes to the DAIR use case.

Change-Id: Ic1fd2f9a3a6c4ba3a6f3e7131b9f12f36699d7b4
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/88/69988/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/app_usecases.xml'],1,c43ece293abae300095ae3a4fed7273db6b528d1,dair-use-case-update, Grizzly.</para>, Folsom.</para>,1,1
openstack%2Fnova~master~I6e44ac788426ba41f1674a5df3d04300eb7c05cc,openstack/nova,master,I6e44ac788426ba41f1674a5df3d04300eb7c05cc,"Revert ""Allow deleting instances while uuid lock is held""",MERGED,2014-01-29 21:51:54.000000000,2014-01-30 17:56:09.000000000,2014-01-30 15:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1528}, {'_account_id': 1561}, {'_account_id': 5292}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-01-29 21:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d3b6c4994d2c721b9b5e700fc5ae11344617ed2', 'message': 'Revert ""Allow deleting instances while uuid lock is held""\n\nThis reverts commit 05f4f7170ab67c20e7f7b3f9f304ccc7ca163490.\n\nWe\'re seeing a huge increase in the occurrence of bug 1258848 since\nsometime on 1/28, which is the day this patch merged.  This is just a\ntest revert to see if it makes a difference.\n\nChange-Id: I6e44ac788426ba41f1674a5df3d04300eb7c05cc\n'}, {'number': 2, 'created': '2014-01-30 01:10:01.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6b7304d8d38c0f04643bdcd031d682c688c91b28', 'message': 'Revert ""Allow deleting instances while uuid lock is held""\n\nThis reverts commit 05f4f7170ab67c20e7f7b3f9f304ccc7ca163490.\n\nWe\'re seeing a huge increase in the occurrence of bug 1258848 since\nthis patch merged.  This patch effectively allows a delete to occur,\neven if the creation hasn\'t finished yet, which would explain the race\nwe\'re seeing leading to the new flood of these errors.\n\nRelated-bug: #1258848\nChange-Id: I6e44ac788426ba41f1674a5df3d04300eb7c05cc\n'}]",0,69987,6b7304d8d38c0f04643bdcd031d682c688c91b28,27,8,2,1561,,,0,"Revert ""Allow deleting instances while uuid lock is held""

This reverts commit 05f4f7170ab67c20e7f7b3f9f304ccc7ca163490.

We're seeing a huge increase in the occurrence of bug 1258848 since
this patch merged.  This patch effectively allows a delete to occur,
even if the creation hasn't finished yet, which would explain the race
we're seeing leading to the new flood of these errors.

Related-bug: #1258848
Change-Id: I6e44ac788426ba41f1674a5df3d04300eb7c05cc
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/69987/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,8d3b6c4994d2c721b9b5e700fc5ae11344617ed2,bug/1258848, @utils.synchronized(instance['uuid'])," @utils.synchronized(instance['uuid'] + "".delete"")",1,1
openstack%2Ftaskflow~master~I94d7b8e0a447708e448c8c5d3dd7232f67c7adda,openstack/taskflow,master,I94d7b8e0a447708e448c8c5d3dd7232f67c7adda,Tests: don't pass 'values' to task constructor,MERGED,2014-01-23 12:13:36.000000000,2014-01-30 17:49:41.000000000,2014-01-30 17:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-01-23 12:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/28c7ad9c2f4420d089c17cb3fb4e6f02a55cbce4', 'message': ""Tests: don't pass 'values' to task constructor\n\nThis might make it easier for worker-based engine to run it.\n\nChange-Id: I94d7b8e0a447708e448c8c5d3dd7232f67c7adda\n""}, {'number': 2, 'created': '2014-01-30 17:12:20.000000000', 'files': ['taskflow/tests/utils.py', 'taskflow/tests/unit/test_action_engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/39da9727670b0baa06982fe3ea977545ffa034b4', 'message': ""Tests: don't pass 'values' to task constructor\n\nThis might make it easier for worker-based engine to run it.\n\nChange-Id: I94d7b8e0a447708e448c8c5d3dd7232f67c7adda\n""}]",0,68621,39da9727670b0baa06982fe3ea977545ffa034b4,11,5,2,7366,,,0,"Tests: don't pass 'values' to task constructor

This might make it easier for worker-based engine to run it.

Change-Id: I94d7b8e0a447708e448c8c5d3dd7232f67c7adda
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/21/68621/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/utils.py', 'taskflow/tests/unit/test_action_engine.py']",2,28c7ad9c2f4420d089c17cb3fb4e6f02a55cbce4,," flow = utils.SaveOrderTask(name='task1') flow = utils.SaveOrderTask(name='task1') flow = utils.FailingTask('fail') utils.SaveOrderTask(name='task1') utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2') utils.SaveOrderTask('task1'), utils.SaveOrderTask('task2') utils.FailingTask('fail'), utils.SaveOrderTask('task1'), utils.SaveOrderTask('task2'), utils.FailingTask('fail') utils.FailingTask('fail1') utils.SaveOrderTask(name='task1', sleep=0.01) utils.SaveOrderTask(name='task1', sleep=0.01), utils.SaveOrderTask(name='task2', sleep=0.01) utils.FailingTask(sleep=0.1) utils.SaveOrderTask(name='task1', provides='x1'), utils.SaveOrderTask(name='task2', provides='x2') utils.SaveOrderTask(name='task1', sleep=0.01), utils.FailingTask(name='fail', sleep=0.01), utils.SaveOrderTask(name='task2', sleep=0.01) 'fail reverted(Failure: RuntimeError: Woot!)', utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2'), utils.SaveOrderTask(name='task3', sleep=0.1), utils.FailingTask(name='fail', sleep=0.01) 'task3', 'task3 reverted(5)', 'fail reverted(Failure: RuntimeError: Woot!)']) utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2'), utils.SaveOrderTask(name='task3', sleep=0.1), utils.FailingTask(sleep=0.01, name='fail') 'task3', 'task3 reverted(5)', 'fail reverted(Failure: RuntimeError: Woot!)']) utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2'), utils.SaveOrderTask(name='task3', sleep=0.1), utils.FailingTask(name='fail', sleep=0.01) 'task3', 'task3 reverted(5)', 'fail reverted(Failure: RuntimeError: Woot!)']) utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2'), utils.SaveOrderTask(name='task3', sleep=0.1), utils.FailingTask(name='fail', sleep=0.01) utils.SaveOrderTask(name='task1', sleep=0.01), utils.SaveOrderTask(name='task2', sleep=0.01), utils.SaveOrderTask(name='task3'), utils.FailingTask(name='fail', sleep=0.01) 'fail reverted(Failure: RuntimeError: Woot!)', utils.SaveOrderTask(name='task1') utils.SaveOrderTask(name='task1'), utils.SaveOrderTask(name='task2') utils.SaveOrderTask(name='task2', requires=['a']), utils.SaveOrderTask(name='task1', provides='a') .add(utils.SaveOrderTask(name='task4', .add(utils.SaveOrderTask(name='task2', .add(utils.SaveOrderTask(name='task3', .add(utils.SaveOrderTask(name='task1', utils.SaveOrderTask(name='task4', utils.SaveOrderTask(name='task2', utils.FailingTask(name='task3', utils.SaveOrderTask(name='task1', provides='a')) utils.FailingTask(name='task3', requires=['b']), utils.SaveOrderTask(name='task1', provides='a'))"," flow = utils.SaveOrderTask(self.values, name='task1') flow = utils.SaveOrderTask(self.values, name='task1') flow = utils.FailingTask(self.values, 'fail') utils.SaveOrderTask(self.values, name='task1') utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2') utils.SaveOrderTask(self.values, 'task1'), utils.SaveOrderTask(self.values, 'task2') utils.FailingTask(self.values, 'fail'), utils.SaveOrderTask(self.values, 'task1'), utils.SaveOrderTask(self.values, 'task2'), utils.FailingTask(self.values, 'fail') utils.FailingTask(self.values, 'fail1') utils.SaveOrderTask(self.values, name='task1', sleep=0.01) utils.SaveOrderTask(self.values, name='task1', sleep=0.01), utils.SaveOrderTask(self.values, name='task2', sleep=0.01) utils.FailingTask(self.values, sleep=0.1) utils.SaveOrderTask(self.values, name='task1', provides='x1'), utils.SaveOrderTask(self.values, name='task2', provides='x2') utils.SaveOrderTask(self.values, name='task1', sleep=0.01), utils.FailingTask(sleep=0.01), utils.SaveOrderTask(self.values, name='task2', sleep=0.01) def test_parallel_revert_exception_is_reraised_(self): flow = lf.Flow('p-r-reraise').add( utils.SaveOrderTask(self.values, name='task1', sleep=0.01), utils.NastyTask(), utils.FailingTask(sleep=0.01), utils.SaveOrderTask(self.values, name='task2') # this should not get reverted ) engine = self._make_engine(flow) self.assertRaisesRegexp(RuntimeError, '^Gotcha', engine.run) result = set(self.values) self.assertEqual(result, set(['task1'])) utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2'), utils.SaveOrderTask(self.values, name='task3', sleep=0.1), utils.FailingTask(sleep=0.01) 'task3', 'task3 reverted(5)']) utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2'), utils.SaveOrderTask(self.values, name='task3', sleep=0.1), utils.FailingTask(sleep=0.01) 'task3', 'task3 reverted(5)']) utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2'), utils.SaveOrderTask(self.values, name='task3', sleep=0.1), utils.FailingTask(sleep=0.01) 'task3', 'task3 reverted(5)']) utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2'), utils.SaveOrderTask(self.values, name='task3', sleep=0.1), utils.FailingTask(self.values, name='fail', sleep=0.01) utils.SaveOrderTask(self.values, name='task1', sleep=0.01), utils.SaveOrderTask(self.values, name='task2', sleep=0.01), utils.SaveOrderTask(self.values, name='task3'), utils.FailingTask(sleep=0.01) utils.SaveOrderTask(self.values, name='task1') utils.SaveOrderTask(self.values, name='task1'), utils.SaveOrderTask(self.values, name='task2') utils.SaveOrderTask(self.values, name='task2', requires=['a']), utils.SaveOrderTask(self.values, name='task1', provides='a') .add(utils.SaveOrderTask(self.values, name='task4', .add(utils.SaveOrderTask(self.values, name='task2', .add(utils.SaveOrderTask(self.values, name='task3', .add(utils.SaveOrderTask(self.values, name='task1', utils.SaveOrderTask(self.values, name='task4', utils.SaveOrderTask(self.values, name='task2', utils.FailingTask(self.values, name='task3', utils.SaveOrderTask(self.values, name='task1', provides='a')) utils.FailingTask(self.values, name='task3', requires=['b']), utils.SaveOrderTask(self.values, name='task1', provides='a'))",72,81
openstack%2Fopenstack-manuals~master~Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839,openstack/openstack-manuals,master,Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839,small cleanup security_guide  ch037_risks,MERGED,2014-01-28 20:58:24.000000000,2014-01-30 17:48:54.000000000,2014-01-30 17:48:53.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 9382}]","[{'number': 1, 'created': '2014-01-28 20:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f751b5cd40ad1eb289976003e910deb42910b28f', 'message': 'small cleanup security_guide  ch037_risks\n\ntypo queueuing to Queuing\nminor grammar edit, added comma\n\nChange-Id: Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839\n'}, {'number': 2, 'created': '2014-01-30 05:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5021229b11d655fe94f3956c82922d59c40d05e6', 'message': 'small cleanup security_guide  ch037_risks\n\ntypo queueuing to Queuing\nminor grammar edit, added comma\nMade changes to sentence formats\n\nChange-Id: Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839\n'}, {'number': 3, 'created': '2014-01-30 17:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/70c35956cdddb68daafae436594e5c5002770658', 'message': 'small cleanup security_guide  ch037_risks\n\ntypo queueuing to Queuing\nminor grammar edit, added comma\nMade changes to sentence formats\nremoved extra paragraph for 1 sentence, added 0MQ, removed space afer </para>\n\nChange-Id: Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839\n'}, {'number': 4, 'created': '2014-01-30 17:27:26.000000000', 'files': ['doc/security-guide/ch037_risks.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c46acabfe695fb838f61868860ff54c6a600a309', 'message': 'small cleanup security_guide  ch037_risks\n\ntypo queueuing to Queuing\nminor grammar edit, added comma\nMade changes to sentence formats\nremoved extra paragraph for 1 sentence, added 0MQ, removed space afer </para>\n\nChange-Id: Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839\n'}]",8,69717,c46acabfe695fb838f61868860ff54c6a600a309,15,5,4,9382,,,0,"small cleanup security_guide  ch037_risks

typo queueuing to Queuing
minor grammar edit, added comma
Made changes to sentence formats
removed extra paragraph for 1 sentence, added 0MQ, removed space afer </para>

Change-Id: Idb7b7cce09e2a38c2e2838c06e023a4ebf4b4839
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/69717/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/security-guide/ch037_risks.xml'],1,f751b5cd40ad1eb289976003e910deb42910b28f,ch037-risks," <para>Inter-process communication within OpenStack is facilitated via message queuing services. Today, three messaging service backends are supported:</para> <para>Both RabbitMQ and Qpid are Advanced Message Queuing Protocol (AMQP) frameworks, which provide message queues for peer-to-peer communication. Queue implementations are typically deployed as centralized or decentralized pool of queue servers. ZeroMQ differs by communicating directly using TCP sockets between peers.</para>"," <para>Inter-process communication within OpenStack is facilitated via message queueing services. Today, three messaging service backends are supported:</para> <para>Both RabbitMQ and Qpid are Advanced Message Queuing Protocol (AMQP) frameworks which provide message queues for peer-to-peer communication. Queue implementations are typically deployed as centralized or decentralized pool of queue servers. ZeroMQ differs by communicating directly using TCP sockets between peers.</para>",2,2
openstack%2Fmurano-deployment~release-0.4~If359789737221c1ab6a19d060d1c45dcf9866282,openstack/murano-deployment,release-0.4,If359789737221c1ab6a19d060d1c45dcf9866282,Image builder update,MERGED,2014-01-28 12:47:04.000000000,2014-01-30 17:48:52.000000000,2014-01-30 17:48:52.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 8040}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-01-28 12:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/40310cf29161809a5ea7e5c689b99c7ff3a77fec', 'message': 'Image builder updated\n\n* Installation script makes full system preparation\n* README updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 2, 'created': '2014-01-29 08:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/46a54624c35262cd3f0f1bab709c15f3b25c8e27', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 3, 'created': '2014-01-29 14:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/9181d30140ef1410a103c40e22e0f8aa440d68c3', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 4, 'created': '2014-01-29 14:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/396821b93eb1561d9601123f3b9189cfa9a54f27', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 5, 'created': '2014-01-29 15:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5a9995b4fb83417d38c482698a4ac9c95f34319d', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 6, 'created': '2014-01-29 15:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/d6618dd03dbaeada0e2244b54a3868555eeb6875', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 7, 'created': '2014-01-29 16:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/ec2111a68d74dbf49eafee3a9bcb41c94b57ba25', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 8, 'created': '2014-01-29 16:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/f1ce763fcc696571ad113d148db584e0217a5af4', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n* Encoding changed for wpi.ps1 files\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 9, 'created': '2014-01-29 16:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/3df1e20e630df1e476d445f27f6c7bbba8ff4ca4', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n* Encoding changed for wpi.ps1 files\n* Code style fixes in wpi.ps1\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 10, 'created': '2014-01-30 08:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/9ea2d86e27981304cc917db56cfb4d7bf9894ffa', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 11, 'created': '2014-01-30 10:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5ab5186997ab52fdb4321ad8e20d7fcea9dbbf76', 'message': 'Image builder update\n\n!!! DO NOT MERGE, WORK IN PROGRESS !!!\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n* A section for Windows Server 2012 R2 added\n* Minor updates in functions\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 12, 'created': '2014-01-30 10:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5d9c586b815be0c181ef1258bf59da74a176460e', 'message': 'Image builder update\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n* A section for Windows Server 2012 R2 added\n* Minor updates in functions\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}, {'number': 13, 'created': '2014-01-30 10:58:27.000000000', 'files': ['image-builder/dependency.list', 'image-builder/Makefile', 'image-builder/share/files/ws-2012-core/unattend.xml.template', 'image-builder/share/files/ws-2012-std/autounattend.xml.template', 'image-builder/functions.sh', 'image-builder/share/files/ws-2008r2-std/unattend.xml.template', 'image-builder/depmgr.sh', 'image-builder/share/files/ws-2012-core/autounattend.xml.template', 'image-builder/config.ini', 'image-builder/share/files/ws-2008r2-core/unattend.xml.template', 'image-builder/share/files/ws-2008r2-std/autounattend.xml.template', 'image-builder/substvars.sh', 'image-builder/install.sh', 'image-builder/process_config.sh', 'image-builder/install-vm.sh', 'image-builder/share/files/ws-2008r2-core/autounattend.xml.template', 'image-builder/share/files/ws-2012-std/unattend.xml.template', 'image-builder/README.rst'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/02b3b3fde512f28388613dae9560f8672d7a8cfe', 'message': 'Image builder update\n\n* Installation script makes full system preparation\n* README updated\n* Functions moved to a separate file\n* A few helper scripts added\n* Ability to modify autounattended files added to Makefile\n* Config file updated\n* Unattended files updated\n* Obsolete files removed\n* VirtIO URL and file name updated\n* A section for Windows Server 2012 R2 added\n* Minor updates in functions\n\nThis change also includes modifications from https://review.openstack.org/#/c/68894/\n\nRelated-Bug: 1230471\n\nChange-Id: If359789737221c1ab6a19d060d1c45dcf9866282\n'}]",4,69589,02b3b3fde512f28388613dae9560f8672d7a8cfe,36,6,13,7562,,,0,"Image builder update

* Installation script makes full system preparation
* README updated
* Functions moved to a separate file
* A few helper scripts added
* Ability to modify autounattended files added to Makefile
* Config file updated
* Unattended files updated
* Obsolete files removed
* VirtIO URL and file name updated
* A section for Windows Server 2012 R2 added
* Minor updates in functions

This change also includes modifications from https://review.openstack.org/#/c/68894/

Related-Bug: 1230471

Change-Id: If359789737221c1ab6a19d060d1c45dcf9866282
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/89/69589/8 && git format-patch -1 --stdout FETCH_HEAD,"['image-builder/install.sh', 'image-builder/README.rst']",2,40310cf29161809a5ea7e5c689b99c7ff3a77fec,bug/1230471,"During build preparation this folder will be copied entirely to the **/opt/image-builder** folder. In this document we refer to that folder using variable **IMAGE_BUILDER_ROOT**.The following ISO files **MUST** be placed under **$IMAGE_BUILDER_ROOT/libvirt/images** folder:Files that **MUST** be placed under **$IMAGE_BUILDER_ROOT/share/files** are described in README file under **share/files** subfolder.1. Run **install.sh** to install required prerequisites and configure system. This script will create folder structure, install required packages and configures Samba share required by build script. 2. Run **make build-root** to update build root directory content. 3. Copy prerequisite files to their folders. 4. Run **make test-build-files** to ensure that all files are in place. 5. Run **make** to show available image targets. 6. Run **make <image target>** to build image. 7. Image file should be saved under **$IMAGE_BUILDER_ROOT/libvirt/images** folder.","During build preparation this folder will be copied entirely to the **/opt/image-builder** folder. We refer to that folder using variable **BUILD_ROOT**.The following ISO files **MUST** be placed under **$BUILD_ROOT/libvirt/images** folder:Files that **MUST** be placed under **$BUILD_ROOT/share/files** are described in README file under **share/files** subfolder.1. Run **make build-root** to create directory structure. It will be built under '/opt/image-builder' folder, which is internally referred by **BUILD_ROOT** variable. 2. Copy prerequisite files to their folders. 3. Run **make test-build-files** to ensure that all files are in place. 4. Run **make** to show available image targets. 5. Run **make <image target>** to build image. 6. Image file should be saved under **$BUILD_ROOT/libvirt/images** folder.",193,32
openstack%2Fzaqar~master~I87716f9feb80da63a6b8c1f629178b396dbeb4c6,openstack/zaqar,master,I87716f9feb80da63a6b8c1f629178b396dbeb4c6,test(functional): Don't use a dead test server,MERGED,2014-01-29 19:12:15.000000000,2014-01-30 17:07:40.000000000,2014-01-30 17:07:40.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-01-29 19:12:15.000000000', 'files': ['marconi/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7a9c45a5b24877afe2f19150c898d4d1eea456a5', 'message': ""test(functional): Don't use a dead test server\n\nIt appears that when running in the gate, the wsgiref server sometimes\ngoes away. This adds a check to only reuse a server instance if it\nis still alive.\n\nChange-Id: I87716f9feb80da63a6b8c1f629178b396dbeb4c6\n""}]",1,69941,7a9c45a5b24877afe2f19150c898d4d1eea456a5,6,3,1,6427,,,0,"test(functional): Don't use a dead test server

It appears that when running in the gate, the wsgiref server sometimes
goes away. This adds a check to only reuse a server instance if it
is still alive.

Change-Id: I87716f9feb80da63a6b8c1f629178b396dbeb4c6
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/41/69941/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/tests/functional/base.py'],1,7a9c45a5b24877afe2f19150c898d4d1eea456a5,functional," if self.cfg.marconi.run_server: if not (self.server and self.server.is_alive()): self.server = self.server_class() self.server.start(self.mconf) def is_alive(self): """"""Returns True IFF the server is running."""""" if self.process is None: return False return self.process.is_alive() ", if (self.cfg.marconi.run_server and not self.server): self.server = self.server_class() self.server.start(self.mconf) servers = {},12,5
openstack%2Fkeystone~stable%2Fhavana~Ia5e743afd59f33bfc7006ff98c39e32e63733803,openstack/keystone,stable/havana,Ia5e743afd59f33bfc7006ff98c39e32e63733803,Import strutils from oslo,MERGED,2013-12-05 23:56:50.000000000,2014-01-30 17:05:52.000000000,2014-01-30 17:05:51.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2218}, {'_account_id': 4328}, {'_account_id': 7052}, {'_account_id': 7191}, {'_account_id': 7244}]","[{'number': 1, 'created': '2013-12-05 23:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d7d4188de6319cfca80313bc11eabde07f4943c8', 'message': 'Import strutils from oslo\n\nHandles common UTF8 encoding and decoding situations.\n\nRelated-Bug: 1253905\n\nChange-Id: Ia5e743afd59f33bfc7006ff98c39e32e63733803\n'}, {'number': 2, 'created': '2013-12-15 23:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/caeee97ba69c774bbd238fdb21adb14f5fa31b80', 'message': 'Import strutils from oslo\n\nHandles common UTF8 encoding and decoding situations.\n\nRelated-Bug: 1253905\n\nChange-Id: Ia5e743afd59f33bfc7006ff98c39e32e63733803\n'}, {'number': 3, 'created': '2014-01-17 04:54:18.000000000', 'files': ['keystone/openstack/common/strutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/152eba3a915b1652c116e02d6a07bf7f32b50ce9', 'message': 'Import strutils from oslo\n\nHandles common UTF8 encoding and decoding situations.\n\nRelated-Bug: 1253905\nChange-Id: Ia5e743afd59f33bfc7006ff98c39e32e63733803\n'}]",0,60386,152eba3a915b1652c116e02d6a07bf7f32b50ce9,31,9,3,1955,,,0,"Import strutils from oslo

Handles common UTF8 encoding and decoding situations.

Related-Bug: 1253905
Change-Id: Ia5e743afd59f33bfc7006ff98c39e32e63733803
",git fetch https://review.opendev.org/openstack/keystone refs/changes/86/60386/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/strutils.py', 'openstack-common.conf']",2,d7d4188de6319cfca80313bc11eabde07f4943c8,bug/1253905,module=strutils,,219,0
openstack%2Ftempest~master~Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e,openstack/tempest,master,Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e,Update 'Member' with option 'operator_role' in tempest.conf,MERGED,2014-01-10 14:16:59.000000000,2014-01-30 17:05:44.000000000,2014-01-30 17:05:43.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5803}, {'_account_id': 6873}, {'_account_id': 7139}, {'_account_id': 9933}]","[{'number': 1, 'created': '2014-01-10 14:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/205b3d95bd9f1fd439734e745ce5f179bcb064f7', 'message': ""Update 'Member' with option 'operator_role' in tempest.conf\n\nIn function _get_object_storage_client(), it is better to use the\noption 'operator_role' in tempest.conf than hard code the role\nto 'Member' here.\n\nChange-Id: Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e\nCloses-Bug: #1267857\n""}, {'number': 2, 'created': '2014-01-22 02:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/895e472fa96ea13de50d9bd5c9b66f5cc8e60334', 'message': ""Update 'Member' with option 'operator_role' in tempest.conf\n\nIn function _get_object_storage_client(), it is better to use the\noption 'operator_role' in tempest.conf than hard code the role\nto 'Member' here.\n\nChange-Id: Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e\nCloses-Bug: #1267857\n""}, {'number': 3, 'created': '2014-01-26 19:43:42.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5384ef569b36abaa8078f4114ec0187d9280f47b', 'message': ""Update 'Member' with option 'operator_role' in tempest.conf\n\nIn function _get_object_storage_client(), it is better to use the\noption 'operator_role' in tempest.conf than hard code the role\nto 'Member' here.\n\nChange-Id: Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e\nCloses-Bug: #1267857\n""}]",2,65964,5384ef569b36abaa8078f4114ec0187d9280f47b,29,8,3,9933,,,0,"Update 'Member' with option 'operator_role' in tempest.conf

In function _get_object_storage_client(), it is better to use the
option 'operator_role' in tempest.conf than hard code the role
to 'Member' here.

Change-Id: Id1de7ee55159f6583a0a93ee87e26a5deaacfd6e
Closes-Bug: #1267857
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/65964/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,205b3d95bd9f1fd439734e745ce5f179bcb064f7,bug/1267857, operator_role = self.config.object_storage.operator_role member_role = [role for role in roles if role.name == operator_role][0], member_role = [role for role in roles if role.name == 'Member'][0],2,1
openstack%2Fkeystone~master~I80f0e5b4bdc275db2d6cd06a81968cef33423a4d,openstack/keystone,master,I80f0e5b4bdc275db2d6cd06a81968cef33423a4d,Add required properties field to rules schema,MERGED,2014-01-29 20:58:23.000000000,2014-01-30 17:05:35.000000000,2014-01-30 17:05:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-01-29 20:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/95d8a66fe7d6d94b2ec15c314f5595d2aeee0cc4', 'message': 'Add required properties field to rules schema\n\nAdded an extra field in the JSON schema for mapping rules,\nthat specifies which properites are required.\n\nThere is a specific remote rule that may only have a type key.\nThis ensures that no other keys are specified.\n\nChange-Id: I80f0e5b4bdc275db2d6cd06a81968cef33423a4d\n'}, {'number': 2, 'created': '2014-01-29 21:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fadeb8001e147f97097e38ed5b840a42911ce1d9', 'message': 'Add required properties field to rules schema\n\nAdded an extra field in the JSON schema for mapping rules,\nthat specifies which properites are required.\n\nThere is a specific remote rule that may only have a type key.\nThis ensures that no other keys are specified.\n\nChange-Id: I80f0e5b4bdc275db2d6cd06a81968cef33423a4d\n'}, {'number': 3, 'created': '2014-01-30 05:21:33.000000000', 'files': ['keystone/tests/test_v3_federation.py', 'keystone/contrib/federation/utils.py', 'keystone/tests/mapping_fixtures.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/77c0fe4a1c2bf38d08ebae02e7d7057f277fd6c7', 'message': 'Add required properties field to rules schema\n\nAdded an extra field in the JSON schema for mapping rules,\nthat specifies which properites are required.\n\nThere is a specific remote rule that may only have a type key.\nThis ensures that no other keys are specified.\n\nChange-Id: I80f0e5b4bdc275db2d6cd06a81968cef33423a4d\n'}]",1,69976,77c0fe4a1c2bf38d08ebae02e7d7057f277fd6c7,13,6,3,6482,,,0,"Add required properties field to rules schema

Added an extra field in the JSON schema for mapping rules,
that specifies which properites are required.

There is a specific remote rule that may only have a type key.
This ensures that no other keys are specified.

Change-Id: I80f0e5b4bdc275db2d6cd06a81968cef33423a4d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/76/69976/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/utils.py'],1,95d8a66fe7d6d94b2ec15c314f5595d2aeee0cc4,add_type_schema," ""required"": ['type'],",,1,0
openstack%2Fnova~master~Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05,openstack/nova,master,Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05,Adds lock server extension for V3 API,MERGED,2013-11-25 12:12:02.000000000,2014-01-30 17:04:46.000000000,2014-01-30 17:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 8430}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2013-11-25 12:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e40bd97e02fa0b4b3848d8546b8f5641d85db930', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 2, 'created': '2013-11-26 03:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8dff50635f7af8f80b89041ae5f7e63b7ab91bf6', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements v3-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 3, 'created': '2013-11-26 12:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07ea88e4ff98832e2955c3878153029681c736c4', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 4, 'created': '2013-11-26 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/446c18bc4074a9e3a17ce87e49ce6750fc52b3f7', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 5, 'created': '2013-11-28 05:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8668501bd1a0c93a3d58aa56a53a0191c3cfb682', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 6, 'created': '2013-11-28 06:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d5d7c27c239a3fc4b33fdebbd46192fb88c02ff', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 7, 'created': '2013-12-16 03:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6270126896744da5692140fe5b041ad07e4f2d2', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 8, 'created': '2014-01-04 10:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33a71e32dea3eb93e08bc3c4ae5b2155fb358fe3', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 9, 'created': '2014-01-10 15:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da66db92bd14a49e40e6dfde3945d65b4c873ba7', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 10, 'created': '2014-01-16 15:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b770b1ed9116bfdbe79f4efbf74dbc8f7914f6f0', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 11, 'created': '2014-01-28 15:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa6b0e18775848055ec38105033ec99aed74600a', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file so tests which are split out from\ntest_admin_actions as their corresponding features are separated\nfrom the admin_actions extension can continue to share code.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 12, 'created': '2014-01-29 02:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d2da7afb3946aaff929c672e187ec7a49c5874f', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file. This allows tests which are\nsplit out from test_admin_actions (as their corresponding features\nare separated from the admin_actions extension) can continue to\nshare code.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-lock-server extension and moves lock/unlock\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 13, 'created': '2014-01-29 22:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/074466e238ab55ebe9dceac56aea8b097547eaa2', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file. This allows tests which are\nsplit out from test_admin_actions (as their corresponding features\nare separated from the admin_actions extension) can continue to\nshare code.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-lock-server extension and moves lock/unlock\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}, {'number': 14, 'created': '2014-01-29 23:43:55.000000000', 'files': ['doc/v3/api_samples/os-lock-server/server-post-req.json', 'doc/v3/api_samples/os-lock-server/server-post-resp.json', 'nova/tests/integrated/v3/test_admin_actions.py', 'doc/v3/api_samples/os-lock-server/unlock-server.json', 'doc/v3/api_samples/os-lock-server/lock-server.json', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'doc/v3/api_samples/os-admin-actions/admin-actions-lock-server.xml', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-resp.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'nova/tests/integrated/v3/test_lock_server.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/lock_server.py', 'doc/v3/api_samples/os-admin-actions/admin-actions-unlock-server.xml', 'nova/tests/integrated/v3/api_samples/os-lock-server/unlock-server.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/admin_only_action_common.py', 'nova/tests/api/openstack/compute/plugins/v3/test_lock_server.py', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-admin-actions/admin-actions-lock-server.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-admin-actions/admin-actions-unlock-server.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-lock-server/lock-server.json.tpl', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-req.json.tpl', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/237e990926a3d85325dbe35b0011e3459b30e035', 'message': 'Adds lock server extension for V3 API\n\nMoves the lock/unlock server functionality out of admin_actions into\nits own extension. This part of the larger\nblueprint v3-api-admin-actions-split allows more selective enablement of\nfeatures contained in the admin actions extension.\n\nSome setup work is done in the tests directory with an\nadmin_only_action_common.py file. This allows tests which are\nsplit out from test_admin_actions (as their corresponding features\nare separated from the admin_actions extension) can continue to\nshare code.\n\nNote that XML api samples are no longer generated because\nbp remove-v3-xml-api has been approved.\n\nPartially implements bp v3-api-admin-actions-split\nDocImpact: Adds os-lock-server extension and moves lock/unlock\nfunctionality out of os-admin-actions into this new extension\n\nChange-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05\n'}]",41,58267,237e990926a3d85325dbe35b0011e3459b30e035,92,15,14,5292,,,0,"Adds lock server extension for V3 API

Moves the lock/unlock server functionality out of admin_actions into
its own extension. This part of the larger
blueprint v3-api-admin-actions-split allows more selective enablement of
features contained in the admin actions extension.

Some setup work is done in the tests directory with an
admin_only_action_common.py file. This allows tests which are
split out from test_admin_actions (as their corresponding features
are separated from the admin_actions extension) can continue to
share code.

Note that XML api samples are no longer generated because
bp remove-v3-xml-api has been approved.

Partially implements bp v3-api-admin-actions-split
DocImpact: Adds os-lock-server extension and moves lock/unlock
functionality out of os-admin-actions into this new extension

Change-Id: Ie4b6e856c2f5c33de5575aa8666e0b2784b58d05
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/58267/14 && git format-patch -1 --stdout FETCH_HEAD,"['doc/v3/api_samples/os-lock-server/unlock-server.xml', 'doc/v3/api_samples/os-lock-server/lock-server.json', 'nova/tests/integrated/v3/test_lock_server.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/lock_server.py', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-req.xml.tpl', 'nova/tests/api/openstack/compute/plugins/v3/admin_only_action_common.py', 'doc/v3/api_samples/os-lock-server/server-post-resp.xml', 'nova/tests/integrated/v3/api_samples/os-lock-server/unlock-server.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-lock-server/lock-server.json.tpl', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-req.json.tpl', 'doc/v3/api_samples/os-lock-server/server-post-req.xml', 'doc/v3/api_samples/os-lock-server/lock-server.xml', 'doc/v3/api_samples/os-lock-server/server-post-req.json', 'doc/v3/api_samples/os-lock-server/server-post-resp.json', 'nova/tests/integrated/v3/test_admin_actions.py', 'doc/v3/api_samples/os-lock-server/unlock-server.json', 'nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-resp.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'nova/tests/integrated/v3/api_samples/os-lock-server/lock-server.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-lock-server/unlock-server.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_lock_server.py', 'nova/tests/integrated/v3/api_samples/os-lock-server/server-post-resp.xml.tpl', 'nova/tests/fake_policy.py', 'setup.cfg']",26,e40bd97e02fa0b4b3848d8546b8f5641d85db930,bp/v3-api-admin-actions-split, lock_server = nova.api.openstack.compute.plugins.v3.lock_server:LockServer,,409,57
openstack%2Fnova~master~I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254,openstack/nova,master,I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254,Use block_device_info at post_live_migration_at_destination,MERGED,2014-01-23 02:03:30.000000000,2014-01-30 17:03:53.000000000,2014-01-30 17:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 782}, {'_account_id': 1313}, {'_account_id': 1333}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 9578}, {'_account_id': 9645}]","[{'number': 1, 'created': '2014-01-23 02:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34b5048d894baa6d2824c7839cbad54f3636f910', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when excute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 2, 'created': '2014-01-23 02:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd5b0c60d29b51324c3fc56723997933029eb109', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when excute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 3, 'created': '2014-01-23 09:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc86a9f3f678c79bf77206027a233c7e194186ec', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when excute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 4, 'created': '2014-01-27 01:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc6d88b261b56d93fa850ffd5cdbecc14a75fd4c', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when execute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 5, 'created': '2014-01-27 01:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/360d7791429fca2b96fd70351044ec83bab7a02e', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when execute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 6, 'created': '2014-01-27 04:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2474083c62b586013a6965c36a2a8d6a12140b0', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when execute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}, {'number': 7, 'created': '2014-01-27 07:34:06.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0486647e1c85947bc48cbdd279b3f49824a6e692', 'message': 'Use block_device_info at post_live_migration_at_destination\n\npost_live_migration_at_destination make libvirt.xml to destination\nhost. when execute (live) block migration for vm made by bootable\nvolume, method post_live_migration_at_destination write a\nlibvirt.xml in destination host.\nbut it missed block disk information so moved libvirt.xml always\nhas a wrong disk information.\nI add block_device_info in blockinfo.get_disk_info at\npost_live_migration_at_destination.\nThis change will make libvirt.xml with valid block disk information.\n\nChange-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254\nCloses-Bug: 1271780\n'}]",2,68537,0486647e1c85947bc48cbdd279b3f49824a6e692,27,9,7,1333,,,0,"Use block_device_info at post_live_migration_at_destination

post_live_migration_at_destination make libvirt.xml to destination
host. when execute (live) block migration for vm made by bootable
volume, method post_live_migration_at_destination write a
libvirt.xml in destination host.
but it missed block disk information so moved libvirt.xml always
has a wrong disk information.
I add block_device_info in blockinfo.get_disk_info at
post_live_migration_at_destination.
This change will make libvirt.xml with valid block disk information.

Change-Id: I31b3f2ef5f03f9ef61524bdb7ae089b18e4cd254
Closes-Bug: 1271780
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/68537/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,34b5048d894baa6d2824c7839cbad54f3636f910,bug/1271780," CONF.libvirt.virt_type, instance, block_device_info)"," CONF.libvirt.virt_type, instance)",58,1
openstack%2Fnova~master~I8d87cc1e3331c5ea135702ae4e03788ff2841642,openstack/nova,master,I8d87cc1e3331c5ea135702ae4e03788ff2841642,Remove trace XML from unittests,MERGED,2014-01-29 00:54:13.000000000,2014-01-30 16:50:39.000000000,2014-01-30 16:50:36.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 00:54:13.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_hypervisors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6e98dad2b882c28e6532ea49157b9d9a27a922e', 'message': 'Remove trace XML from unittests\n\nRemoves some trace bits of XML test classes\nfrom the unitests\n\nPart of blueprint remove-v3-xml-api\n\nChange-Id: I8d87cc1e3331c5ea135702ae4e03788ff2841642\n'}]",0,69764,e6e98dad2b882c28e6532ea49157b9d9a27a922e,8,4,1,5292,,,0,"Remove trace XML from unittests

Removes some trace bits of XML test classes
from the unitests

Part of blueprint remove-v3-xml-api

Change-Id: I8d87cc1e3331c5ea135702ae4e03788ff2841642
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/69764/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_hypervisors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_simple_tenant_usage.py']",2,e6e98dad2b882c28e6532ea49157b9d9a27a922e,bp/remove-v3-xml-api,,"class SimpleTenantUsageSerializerTest(test.TestCase): def _verify_server_usage(self, raw_usage, tree): self.assertEqual('server_usage', tree.tag) # Figure out what fields we expect not_seen = set(raw_usage.keys()) for child in tree: self.assertIn(child.tag, not_seen) not_seen.remove(child.tag) self.assertEqual(str(raw_usage[child.tag]), child.text) self.assertEqual(len(not_seen), 0) def _verify_tenant_usage(self, raw_usage, tree): self.assertEqual('tenant_usage', tree.tag) # Figure out what fields we expect not_seen = set(raw_usage.keys()) for child in tree: self.assertIn(child.tag, not_seen) not_seen.remove(child.tag) if child.tag == 'server_usages': for idx, gr_child in enumerate(child): self._verify_server_usage(raw_usage['server_usages'][idx], gr_child) else: self.assertEqual(str(raw_usage[child.tag]), child.text) self.assertEqual(len(not_seen), 0) ",0,66
openstack%2Ffuel-main~master~I7227bd474e4586689f6bd1fce7ead491b0715f9e,openstack/fuel-main,master,I7227bd474e4586689f6bd1fce7ead491b0715f9e,Flexible way for logging configuration,MERGED,2014-01-30 13:12:50.000000000,2014-01-30 16:41:18.000000000,2014-01-30 16:41:18.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8767}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-30 13:12:50.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/891c90c7b931feb6f032cfa423874ee1119df359', 'message': 'Flexible way for logging configuration\n\nChange-Id: I7227bd474e4586689f6bd1fce7ead491b0715f9e\n'}]",0,70114,891c90c7b931feb6f032cfa423874ee1119df359,8,4,1,8882,,,0,"Flexible way for logging configuration

Change-Id: I7227bd474e4586689f6bd1fce7ead491b0715f9e
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/14/70114/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/settings.py']",2,891c90c7b931feb6f032cfa423874ee1119df359,master,"DEBUG_MODE = os.environ.get('DEBUG_MODE', 'true') == 'true'",,5,2
openstack%2Fopenstacksdk~master~Ie7e68c64a8c8faa1ab423ea248d19e84f6c7dd94,openstack/openstacksdk,master,Ie7e68c64a8c8faa1ab423ea248d19e84f6c7dd94,Initial pystack strawman docs,MERGED,2014-01-29 16:00:00.000000000,2014-01-30 16:27:17.000000000,2014-01-30 16:27:17.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 6714}, {'_account_id': 7680}, {'_account_id': 9473}]","[{'number': 1, 'created': '2014-01-29 16:00:00.000000000', 'files': ['api_strawman/pystack/overview.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/aa360429e02ed31c2458427c373b5314c6d2a88a', 'message': 'Initial pystack strawman docs\n\nChange-Id: Ie7e68c64a8c8faa1ab423ea248d19e84f6c7dd94\n'}]",2,69888,aa360429e02ed31c2458427c373b5314c6d2a88a,8,5,1,1063,,,0,"Initial pystack strawman docs

Change-Id: Ie7e68c64a8c8faa1ab423ea248d19e84f6c7dd94
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/88/69888/1 && git format-patch -1 --stdout FETCH_HEAD,['api_strawman/pystack/overview.rst'],1,aa360429e02ed31c2458427c373b5314c6d2a88a,,"============ Quick Start ============ Let's start by looking at some typical code; after that, we'll explain what each part is doing and why it works that way. Here is how you authenticate and get a list of your compute resources:: import pystack context = pystack.identity.KeystoneIdentity(""username"", ""password"", ""tenant_id"") context.authenticate() clt = context.RegionOne.compute.client # Get a list of servers clt.list() # Get a list of all images clt.list_images() # Get a list of just saved snapshots clt.list_snapshots() ==================== The Context Object ==================== In order to access your OpenStack resources, you need to authenticate. Once authenticated, you have access to the services returned in the service catalog. The context object handles the details of this for you. You may create multiple context objects if you need to work with more than one user, tenant, or even different OpenStack providers. The context object provides all of the client objects you need to work with the various services available to you. The primary class for context objects is **KeystoneIdentity**; if your provider requires a different authentication mechanism, they will need to provide an appropriate subclass to handle the differences. You can pass in your credentials when you create the instance, pass them as arguments to the `authenticate()` call, use the `keyring_auth()` method to use credentials stored in your system's keychain, or use environment variables to hold that information. Once you have authenticated, the context object holds the information you need to work with your OpenStack provider: * **regions**: Returns a list of all available regions for your provider. * **services**: Returns a dictionary whose keys are the service names, and whose values are Service objects. * **service_catalog**: Holds the service catalog returned by the provider. -------------------- Clients -------------------- In order to work with a service, you need to get a reference to the **client** object for that service. The client is specific to the authenticated user and the chosen region. You use standard dot notation to access the desired client. As an example, let's assume that your provider has four regions: North, East, South, and West. To get the compute client for the East region, you can do either of the following:: clt = context.East.compute.client # -or- clt = context.compute.East.client Why the duplication? Well, it's because sometimes you need to determine all the services available in a given region, and at other times you may need to determine all of the regions that a particular service is available in. Pystack handles the resolution of both of these cases for you. For example:: >> print context.East {'compute': <pystack.identity.Endpoint at 0x106142dd0>, 'ec2': <pystack.identity.Endpoint at 0x1062c6490>, 'identity': <pystack.identity.Endpoint at 0x1062c6510>, 'image': <pystack.identity.Endpoint at 0x1061428d0>, 's3': <pystack.identity.Endpoint at 0x106142e10>, 'volume': <pystack.identity.Endpoint at 0x1062c6210>} >> print context.compute {u'RegionOne': <pystack.identity.Endpoint at 0x106142dd0>} As you can see, referencing ``context.<region>`` returns a dictionary of Endpoint objects, with the available services as the keys, and referencing ``context.<service>`` returns a dictionary keyed by region. ---------------------- Working with Clients ---------------------- Once you have a client, you can call its methods to interact with the service. Clients have several standard methods that correspond to the basic REST methods: * ``list()``: Lists the available resources. This supports basic paging arguments. * ``create(*args, **kwargs)``: Creates a new resource. The particular arguments required depend on the service. * ``update(obj, **kwargs)``: Updates an existing resource with the supplied values. * ``delete(obj)``: Deletes an existing resource. ",,95,0
openstack%2Fcookbook-openstack-identity~master~Ie598d312d1a2d79db43793dd90b346618a6804f5,openstack/cookbook-openstack-identity,master,Ie598d312d1a2d79db43793dd90b346618a6804f5,refactor specs to improve speed and maintenance,MERGED,2014-01-28 22:41:30.000000000,2014-01-30 16:20:26.000000000,2014-01-30 11:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 6714}, {'_account_id': 9894}]","[{'number': 2, 'created': '2014-01-28 22:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/8aba7f4c33780c69efe6d7ec53cae9df8008a4ee', 'message': ""refactor specs to improve speed and maintenance\n\nuse of `let()', shared_context, and removal of instance vars, etc.\n\nChange-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5\nImplements: blueprint refactor-spec-files\n""}, {'number': 3, 'created': '2014-01-29 17:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/29eb030b325b217f12d5868b4c0e88ee0dbf1158', 'message': ""refactor specs to improve speed and maintenance\n\nuse of `let()', shared_context, and removal of instance vars, etc.\n\nChange-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5\nImplements: blueprint refactor-spec-files\n""}, {'number': 4, 'created': '2014-01-29 23:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/15e34149d19d4a0fdb5dae696e221da422e04836', 'message': ""refactor specs to improve speed and maintenance\n\nuse of `let()', shared_context, and removal of instance vars, etc.\n\nChange-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5\nImplements: blueprint refactor-spec-files\n""}, {'number': 5, 'created': '2014-01-29 23:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/ba4a36b9336b839bf3361e52c7f14888fd9dc7e7', 'message': ""refactor specs to improve speed and maintenance\n\nuse of `let()', shared_context, and removal of instance vars, etc.\n\nChange-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5\nImplements: blueprint refactor-spec-files\n""}, {'number': 6, 'created': '2014-01-29 23:58:34.000000000', 'files': ['spec/server-redhat_spec.rb', 'recipes/registration.rb', 'spec/spec_helper.rb', 'spec/registration_spec.rb', 'spec/server-opensuse_spec.rb', 'spec/default_spec.rb', 'spec/server_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/63b934299938f5df055c81f9e46b07f2b4f43a6a', 'message': ""refactor specs to improve speed and maintenance\n\nuse of `let()', shared_context, and removal of instance vars, etc.\n\nChange-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5\nImplements: blueprint refactor-spec-files\n""}]",11,69737,63b934299938f5df055c81f9e46b07f2b4f43a6a,20,5,5,9894,,,0,"refactor specs to improve speed and maintenance

use of `let()', shared_context, and removal of instance vars, etc.

Change-Id: Ie598d312d1a2d79db43793dd90b346618a6804f5
Implements: blueprint refactor-spec-files
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/37/69737/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/server-redhat_spec.rb', 'spec/spec_helper.rb', 'spec/registration_spec.rb', 'spec/server-opensuse_spec.rb', 'spec/default_spec.rb', 'spec/server_spec.rb']",6,8aba7f4c33780c69efe6d7ec53cae9df8008a4ee,bp/refactor-spec-files," let(:runner) { ChefSpec::Runner.new(UBUNTU_OPTS) } let(:node) { runner.node } let(:chef_run) do node.set_unless['openstack']['endpoints']['identity-api'] = { 'host' => '127.0.1.1', 'port' => '5000', 'scheme' => 'https' } node.set_unless['openstack']['endpoints']['identity-admin'] = { 'host' => '127.0.1.1', 'port' => '35357', 'scheme' => 'https' } runner.converge(described_recipe) include_context 'identity_stubs' node.set['openstack']['identity']['syslog']['use'] = true expect(chef_run).to include_recipe('openstack-common::logging') expect(chef_run).not_to include_recipe('openstack-common::logging') expect { chef_run }.to_not raise_error expect(chef_run).to install_package('python-mysqldb') expect(chef_run).to install_package('python-memcache') expect(chef_run).to upgrade_package('keystone') expect(chef_run).to enable_service('keystone') expect(chef_run.service('keystone')).to notify( let(:dir) { chef_run.directory('/etc/keystone') } expect(dir.owner).to eq('keystone') expect(dir.group).to eq('keystone') expect(sprintf('%o', dir.mode)).to eq('700') let(:ssl_dir) { '/etc/keystone/ssl' } expect(chef_run).not_to create_directory(ssl_dir) before { node.set['openstack']['auth']['strategy'] = 'pki' } let(:dir_resource) { chef_run.directory(ssl_dir) } expect(chef_run).to create_directory(ssl_dir) expect(dir_resource.owner).to eq('keystone') expect(dir_resource.group).to eq('keystone') expect(sprintf('%o', dir_resource.mode)).to eq('700') expect(chef_run).to delete_file('/var/lib/keystone/keystone.db') expect(chef_run).not_to delete_file('/var/lib/keystone/keystone.db') let(:cmd) { 'keystone-manage pki_setup' } expect(chef_run).to_not run_execute(cmd).with( before { node.set['openstack']['auth']['strategy'] = 'pki' } expect(chef_run).to run_execute(cmd).with( expect(chef_run).not_to run_execute(cmd).with( let(:template) { chef_run.template '/etc/keystone/keystone.conf' } expect(template.owner).to eq('keystone') expect(template.group).to eq('keystone') expect(sprintf('%o', template.mode)).to eq('644') expect(chef_run).to render_file(template.name).with_content(match) expect(chef_run).to render_file(template.name).with_content( expect(chef_run).to render_file(template.name).with_content( expect(chef_run).to render_file(template.name).with_content(match) expect(template).to notify('service[keystone]').to(:restart) expect(chef_run).not_to render_file(template.name).with_content( expect(chef_run).to render_file(template.name).with_content( expect(chef_run).to render_file(template.name).with_content( let(:file) { '/etc/keystone/default_catalog.templates' } expect(chef_run).not_to render_file(file) node.set['openstack']['identity']['catalog']['backend'] = 'templated' let(:template) { chef_run.template(file) } expect(chef_run).to render_file(file) expect(template.owner).to eq('keystone') expect(template.group).to eq('keystone') expect(sprintf('%o', template.mode)).to eq '644' expect(template).to notify('service[keystone]').to(:restart) end #describe 'with templated' end #describe 'default_catalog.templates' let(:cmd) { 'keystone-manage db_sync' } expect(chef_run).to run_execute(cmd).with( it 'does not run migrations' do node.set['openstack']['db']['identity']['migrate'] = false expect(chef_run).not_to run_execute(cmd).with( user: 'keystone', group: 'keystone' ) end end #describe 'db_sync' do end #describe 'ubuntu'"," before { identity_stubs } before do @chef_run = ::ChefSpec::Runner.new ::UBUNTU_OPTS do |n| n.set['openstack']['identity']['syslog']['use'] = true n.set['openstack']['endpoints']['identity-api'] = { 'host' => '127.0.1.1', 'port' => '5000', 'scheme' => 'https' } n.set['openstack']['endpoints']['identity-admin'] = { 'host' => '127.0.1.1', 'port' => '35357', 'scheme' => 'https' } end @chef_run.converge 'openstack-identity::server' expect(@chef_run).to include_recipe 'openstack-common::logging' chef_run = ::ChefSpec::Runner.new ::UBUNTU_OPTS chef_run.converge 'openstack-identity::server' expect(chef_run).not_to include_recipe 'openstack-common::logging' chef_run = ::ChefSpec::Runner.new ::UBUNTU_OPTS node = chef_run.node chef_run.converge 'openstack-identity::server' expect(@chef_run).to install_package 'python-mysqldb' chef_run = ::ChefSpec::Runner.new ::UBUNTU_OPTS node = chef_run.node chef_run.converge 'openstack-identity::server' expect(@chef_run).to install_package 'python-memcache' expect(@chef_run).to upgrade_package 'keystone' expect(@chef_run).to enable_service('keystone') expect(@chef_run.service('keystone')).to notify( before do @dir = @chef_run.directory '/etc/keystone' end expect(@dir.owner).to eq('keystone') expect(@dir.group).to eq('keystone') expect(sprintf('%o', @dir.mode)).to eq '700' before { @dir = '/etc/keystone/ssl' } chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) chef_run.converge 'openstack-identity::server' expect(chef_run).not_to create_directory @dir before do @chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) do |n| n.set['openstack']['auth']['strategy'] = 'pki' end @chef_run.converge 'openstack-identity::server' @directory = @chef_run.directory @dir end expect(@chef_run).to create_directory @directory.name expect(@directory.owner).to eq('keystone') expect(@directory.group).to eq('keystone') expect(sprintf('%o', @directory.mode)).to eq '700' expect(@chef_run).to delete_file '/var/lib/keystone/keystone.db' chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) node = chef_run.node chef_run.converge 'openstack-identity::server' expect(chef_run).not_to delete_file '/var/lib/keystone/keystone.db' before { @cmd = 'keystone-manage pki_setup' } chef_run = ::ChefSpec::Runner.new ::UBUNTU_OPTS chef_run.converge 'openstack-identity::server' expect(chef_run).to_not run_execute(@cmd).with( before do @chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) do |n| n.set['openstack']['auth']['strategy'] = 'pki' end end @chef_run.converge 'openstack-identity::server' expect(@chef_run).to run_execute(@cmd).with( @chef_run.converge 'openstack-identity::server' expect(@chef_run).not_to run_execute(@cmd).with( before do @template = @chef_run.template '/etc/keystone/keystone.conf' end expect(@template.owner).to eq('keystone') expect(@template.group).to eq('keystone') expect(sprintf('%o', @template.mode)).to eq '644' expect(@chef_run).to render_file(@template.name).with_content(match) expect(@chef_run).to render_file(@template.name).with_content( expect(@chef_run).to render_file(@template.name).with_content( expect(@chef_run).to render_file(@template.name).with_content( match) expect(@template).to notify('service[keystone]').to(:restart) expect(@chef_run).not_to render_file(@template.name).with_content( expect(@chef_run).to render_file(@template.name).with_content( expect(@chef_run).to render_file(@template.name).with_content( before { @file = '/etc/keystone/default_catalog.templates' } chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) chef_run.converge 'openstack-identity::server' expect(chef_run).not_to render_file(@file) @chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) do |n| n.set['openstack']['identity']['catalog']['backend'] = 'templated' end @chef_run.converge 'openstack-identity::server' @template = @chef_run.template @file expect(@chef_run).to render_file(@file) expect(@template.owner).to eq('keystone') expect(@template.group).to eq('keystone') expect(sprintf('%o', @template.mode)).to eq '644' expect(@template).to notify('service[keystone]').to(:restart) end end before do @cmd = 'keystone-manage db_sync' end expect(@chef_run).to run_execute(@cmd).with( user: 'keystone', group: 'keystone' ) end it 'does not run migrations' do chef_run = ::ChefSpec::Runner.new(::UBUNTU_OPTS) do |n| n.set['openstack']['db']['identity']['migrate'] = false end chef_run.converge 'openstack-identity::server' expect(chef_run).not_to run_execute(@cmd).with( end end",198,264
openstack%2Fopenstack-manuals~master~Ib81654070b9c58314815dbc45711a8875fec31b1,openstack/openstack-manuals,master,Ib81654070b9c58314815dbc45711a8875fec31b1,Update of pom.xml files,MERGED,2014-01-28 16:58:00.000000000,2014-01-30 16:19:58.000000000,2014-01-30 16:19:56.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1441}]","[{'number': 1, 'created': '2014-01-28 16:58:00.000000000', 'files': ['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/image-guide/pom.xml', 'doc/user-guide-admin/pom.xml', 'doc/user-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/install-guide/pom.xml', 'doc/config-reference/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9d72389c09a459738b753939d885ab376ab6099f', 'message': 'Update of pom.xml files\n\n* Add canonicalUrlBase everywhere\n* Add glossaryCollection everywhere - this will not build the glossary,\n  but make glossterms work and silence build warnings\n* Remove profileSecurity and security settings, we should always use the\n  default of external.\n\nCloses-Bug: #1273135\n\nChange-Id: Ib81654070b9c58314815dbc45711a8875fec31b1\n'}]",0,69660,9d72389c09a459738b753939d885ab376ab6099f,6,3,1,6547,,,0,"Update of pom.xml files

* Add canonicalUrlBase everywhere
* Add glossaryCollection everywhere - this will not build the glossary,
  but make glossterms work and silence build warnings
* Remove profileSecurity and security settings, we should always use the
  default of external.

Closes-Bug: #1273135

Change-Id: Ib81654070b9c58314815dbc45711a8875fec31b1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/60/69660/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/image-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/user-guide-admin/pom.xml', 'doc/user-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/install-guide/pom.xml', 'doc/config-reference/pom.xml']",10,9d72389c09a459738b753939d885ab376ab6099f,canonnicalUrlBase, <glossaryCollection>${basedir}/../glossary/glossary-terms.xml</glossaryCollection>, <profileSecurity>reviewer</profileSecurity>,13,9
openstack%2Fopenstack-manuals~master~I9cf386725fa8841b1f2fdd9ccbb1331897aaca9d,openstack/openstack-manuals,master,I9cf386725fa8841b1f2fdd9ccbb1331897aaca9d,Moves one section about image properties to Cloud Admin Guide,MERGED,2014-01-29 22:18:28.000000000,2014-01-30 16:19:02.000000000,2014-01-30 16:19:02.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-29 22:18:28.000000000', 'files': ['doc/admin-guide-cloud/image/section_glance-property-protection.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/config-reference/ch_imageservice.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fc2d0b4e6eaffc8ec6c52b20dd440ad0014140b1', 'message': 'Moves one section about image properties to Cloud Admin Guide\n\nrather than the Config Reference.\n\nChange-Id: I9cf386725fa8841b1f2fdd9ccbb1331897aaca9d\n'}]",0,69996,fc2d0b4e6eaffc8ec6c52b20dd440ad0014140b1,6,3,1,964,,,0,"Moves one section about image properties to Cloud Admin Guide

rather than the Config Reference.

Change-Id: I9cf386725fa8841b1f2fdd9ccbb1331897aaca9d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/69996/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/image/section_glance-property-protection.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/config-reference/ch_imageservice.xml']",3,fc2d0b4e6eaffc8ec6c52b20dd440ad0014140b1,image-admin-cloud, <para>You can modify many options in the OpenStack Image Service. The following tables provide a comprehensive list.</para>," <para>You can modify many of the OpenStack Image Catalogue and Delivery Service. The following tables provide a comprehensive list.</para> <xi:include href=""image/section_glance-property-protection.xml""/>",6,128
openstack%2Fopenstack-manuals~master~I805a642ee6020ca53c27c120a811ca7349a2f14f,openstack/openstack-manuals,master,I805a642ee6020ca53c27c120a811ca7349a2f14f,Revised wording regarding HA capabilites,MERGED,2014-01-30 02:12:07.000000000,2014-01-30 16:16:25.000000000,2014-01-30 16:16:24.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-30 02:12:07.000000000', 'files': ['doc/admin-guide-cloud/section_networking_high_avail.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/486de8c5aa2d2c8ced926fd42b8c3025380ea6f0', 'message': 'Revised wording regarding HA capabilites\n\nText originally stated that HA prevents node failures, which may result\nin a mismatch with user expectations. Revised statement to clarify that\nHA helps mitigate the impact of individual node failures.\n\nChange-Id: I805a642ee6020ca53c27c120a811ca7349a2f14f\nPartial-Bug: #1217503\n'}]",0,70040,486de8c5aa2d2c8ced926fd42b8c3025380ea6f0,6,3,1,9930,,,0,"Revised wording regarding HA capabilites

Text originally stated that HA prevents node failures, which may result
in a mismatch with user expectations. Revised statement to clarify that
HA helps mitigate the impact of individual node failures.

Change-Id: I805a642ee6020ca53c27c120a811ca7349a2f14f
Partial-Bug: #1217503
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/70040/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/section_networking_high_avail.xml'],1,486de8c5aa2d2c8ced926fd42b8c3025380ea6f0,Conventions-1217503," helps mitigate the impact of individual node failures. In general, you"," helps prevent individual node failures. In general, you",1,1
openstack%2Fpython-blazarclient~master~Ib1db84a0a8b56f1135ea9d73c688b55d18fa683a,openstack/python-blazarclient,master,Ib1db84a0a8b56f1135ea9d73c688b55d18fa683a,Fix exception rendering for client,MERGED,2014-01-24 14:43:18.000000000,2014-01-30 16:14:54.000000000,2014-01-30 16:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2928}, {'_account_id': 3012}, {'_account_id': 6582}, {'_account_id': 7075}, {'_account_id': 7166}, {'_account_id': 7535}]","[{'number': 1, 'created': '2014-01-24 14:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/18c13f1104d4cfd9da02833d2ffed96fa0757878', 'message': 'Fix exception rendering for client\n\nExceptions from the API were not properly catched.\n\nChange-Id: Ib1db84a0a8b56f1135ea9d73c688b55d18fa683a\nCloses-Bug: #1272352\n'}, {'number': 2, 'created': '2014-01-29 11:22:38.000000000', 'files': ['climateclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/f4987456dbff4ce8ea09b33cc7151aac8639028a', 'message': 'Fix exception rendering for client\n\nExceptions from the API were not properly catched.\n\nChange-Id: Ib1db84a0a8b56f1135ea9d73c688b55d18fa683a\nCloses-Bug: #1272352\n'}]",2,68927,f4987456dbff4ce8ea09b33cc7151aac8639028a,10,8,2,7166,,,0,"Fix exception rendering for client

Exceptions from the API were not properly catched.

Change-Id: Ib1db84a0a8b56f1135ea9d73c688b55d18fa683a
Closes-Bug: #1272352
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/27/68927/1 && git format-patch -1 --stdout FETCH_HEAD,['climateclient/base.py'],1,18c13f1104d4cfd9da02833d2ffed96fa0757878,bug/1272352,"from climateclient.openstack.common.gettextutils import _ # noqa body = _(""ERROR: "") + body.get('error_message', body) raise exception.ClimateClientException(body, code=resp.status_code)"," raise exception.ClimateClientException(resp.body, code=resp.status_code)",3,2
openstack%2Fdiskimage-builder~master~Ic74d138da922ecc99c38c27f105170d90009a84a,openstack/diskimage-builder,master,Ic74d138da922ecc99c38c27f105170d90009a84a,Add ability to use local cloud image,MERGED,2014-01-21 14:53:39.000000000,2014-01-30 15:51:45.000000000,2014-01-30 15:51:45.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 3068}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7732}, {'_account_id': 8449}, {'_account_id': 8532}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-01-21 14:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c102d2c13d451bfba562534877a38e2af2fc8762', 'message': ""Add ability to use local cloud image\n\nAdds the ability to set $DIB_LOCAL_IMAGE to use as the base cloud image\nfor a Fedora image build. There are many repetitve tasks that are done\nevery image build. With this change you can build an image with the\nfedora and vm element and then reuse the resulting image as input to\nfuture image builds. This greatly reduces future image build times.\n\nFor instance 99-up-to-date is already taking almost 2 minutes (even with\nrpm downloads already cached) for Fedora 20, and is only going to keep\ntaking longer. By having a local up to date Fedora cloud image, this\ntime can be saved on each image build.\n\nThere is one minor change in 15-fedora-remove-grub to support this since\nthe /tmp/grub directory will already exist on a reused image, so we need\nto allow for that (didn't think this was worth a seperate commit).\n\nChange-Id: Ic74d138da922ecc99c38c27f105170d90009a84a\n""}, {'number': 2, 'created': '2014-01-27 21:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0a497be4231b8a479c858f8d9a3666368e7f2644', 'message': ""Add ability to use local cloud image\n\nAdds the ability to set $DIB_LOCAL_IMAGE to use as the base cloud image\nfor a Fedora image build. There are many repetitve tasks that are done\nevery image build. With this change you can build an image with the\nfedora and vm element and then reuse the resulting image as input to\nfuture image builds. This greatly reduces future image build times.\n\nFor instance 99-up-to-date is already taking almost 2 minutes (even with\nrpm downloads already cached) for Fedora 20, and is only going to keep\ntaking longer. By having a local up to date Fedora cloud image, this\ntime can be saved on each image build.\n\nThere is one minor change in 15-fedora-remove-grub to support this since\nthe /tmp/grub directory will already exist on a reused image, so we need\nto allow for that (didn't think this was worth a seperate commit).\n\nChange-Id: Ic74d138da922ecc99c38c27f105170d90009a84a\n""}, {'number': 3, 'created': '2014-01-28 16:02:48.000000000', 'files': ['elements/fedora/pre-install.d/15-fedora-remove-grub', 'elements/fedora/finalise.d/99-cleanup-tmp-grub', 'elements/fedora/README.md', 'elements/fedora/root.d/10-fedora-cloud-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/15960f01cdf476d5bee928b6f780d12f98ba9acd', 'message': ""Add ability to use local cloud image\n\nAdds the ability to set $DIB_LOCAL_IMAGE to use as the base cloud image\nfor a Fedora image build. There are many repetitve tasks that are done\nevery image build. With this change you can build an image with the\nfedora and vm element and then reuse the resulting image as input to\nfuture image builds. This greatly reduces future image build times.\n\nFor instance 99-up-to-date is already taking almost 2 minutes (even with\nrpm downloads already cached) for Fedora 20, and is only going to keep\ntaking longer. By having a local up to date Fedora cloud image, this\ntime can be saved on each image build.\n\nThere is one minor change to support this in that /tmp/grub needs to get\ncleaned up at the end of image builds so that the image can be reused.\nPlus, there is no reason for it to stick around anyway.  (didn't think\nthis was worth a seperate commit).\n\nChange-Id: Ic74d138da922ecc99c38c27f105170d90009a84a\n""}]",6,68133,15960f01cdf476d5bee928b6f780d12f98ba9acd,26,11,3,7144,,,0,"Add ability to use local cloud image

Adds the ability to set $DIB_LOCAL_IMAGE to use as the base cloud image
for a Fedora image build. There are many repetitve tasks that are done
every image build. With this change you can build an image with the
fedora and vm element and then reuse the resulting image as input to
future image builds. This greatly reduces future image build times.

For instance 99-up-to-date is already taking almost 2 minutes (even with
rpm downloads already cached) for Fedora 20, and is only going to keep
taking longer. By having a local up to date Fedora cloud image, this
time can be saved on each image build.

There is one minor change to support this in that /tmp/grub needs to get
cleaned up at the end of image builds so that the image can be reused.
Plus, there is no reason for it to stick around anyway.  (didn't think
this was worth a seperate commit).

Change-Id: Ic74d138da922ecc99c38c27f105170d90009a84a
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/33/68133/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/fedora/pre-install.d/15-fedora-remove-grub', 'elements/fedora/root.d/10-fedora-cloud-image']",2,c102d2c13d451bfba562534877a38e2af2fc8762,local-image,"DIB_LOCAL_IMAGE=${DIB_LOCAL_IMAGE:-""""} if [ -n ""$DIB_LOCAL_IMAGE"" ]; then IMAGE_LOCATION=$DIB_LOCAL_IMAGE # No need to copy a local image into the cache directory, so just specify # the cached path as the original path. CACHED_IMAGE=$IMAGE_LOCATION BASE_IMAGE_FILE=`basename $DIB_LOCAL_IMAGE` BASE_IMAGE_TAR=$BASE_IMAGE_FILE.tgz else DIB_RELEASE=${DIB_RELEASE:-20} DIB_CLOUD_IMAGES=${DIB_CLOUD_IMAGES:-http://cloud.fedoraproject.org} BASE_IMAGE_FILE=${BASE_IMAGE_FILE:-fedora-$DIB_RELEASE.$ARCH.qcow2} BASE_IMAGE_TAR=$DIB_RELEASE-Cloud-$ARCH-$DIB_RELEASE.tgz IMAGE_LOCATION=$DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE CACHED_IMAGE=$DIB_IMAGE_CACHE/$BASE_IMAGE_FILE fi if [ -z ""$DIB_LOCAL_IMAGE"" ]; then echo ""Fetching Base Image"" # There seems to be some bad Fedora mirrors returning http 404's for the cloud image. # If the image fails to download due to a 404 we retry once. set +e $TMP_HOOKS_PATH/bin/cache-url $IMAGE_LOCATION $CACHED_IMAGE RV=$? set -e if [ ""$RV"" == ""44"" ] ; then $TMP_HOOKS_PATH/bin/cache-url $IMAGE_LOCATION $CACHED_IMAGE elif [ ""$RV"" != ""0"" ] ; then exit 1 fi $CACHED_IMAGE -nt $CACHED_TAR ] ; then qemu-img convert -f qcow2 -O raw $CACHED_IMAGE $WORKING/$RAW_FILE mv $WORKING/tmp.tar $CACHED_TAR else echo ""Using cached tar from $CACHED_TAR""echo ""Extracting base root image from $CACHED_TAR"" sudo tar -C $TARGET_ROOT --numeric-owner -xzf $CACHED_TAR","DIB_RELEASE=${DIB_RELEASE:-20} DIB_CLOUD_IMAGES=${DIB_CLOUD_IMAGES:-http://cloud.fedoraproject.org} BASE_IMAGE_FILE=${BASE_IMAGE_FILE:-fedora-$DIB_RELEASE.$ARCH.qcow2} BASE_IMAGE_TAR=$DIB_RELEASE-Cloud-$ARCH-$DIB_RELEASE.tgz echo ""Fetching Base Image"" # There seems to be some bad Fedora mirrors returning http 404's for the cloud image. # If the image fails to download due to a 404 we retry once. set +e $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE $DIB_IMAGE_CACHE/$BASE_IMAGE_FILE RV=$? set -e if [ ""$RV"" == ""44"" ] ; then $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE $DIB_IMAGE_CACHE/$BASE_IMAGE_FILE elif [ ""$RV"" != ""0"" ] ; then exit 1 $DIB_IMAGE_CACHE/$BASE_IMAGE_FILE -nt $CACHED_TAR ] ; then qemu-img convert -f qcow2 -O raw $DIB_IMAGE_CACHE/$BASE_IMAGE_FILE $WORKING/$RAW_FILE mv $WORKING/tmp.tar $DIB_IMAGE_CACHE/$BASE_IMAGE_TARsudo tar -C $TARGET_ROOT --numeric-owner -xzf $DIB_IMAGE_CACHE/$BASE_IMAGE_TAR",42,20
openstack%2Fnova~master~I1fd516b5a01f1ce2b4d42320594616a49b66952d,openstack/nova,master,I1fd516b5a01f1ce2b4d42320594616a49b66952d,Remove V3 API XML entry points,MERGED,2014-01-29 13:06:56.000000000,2014-01-30 15:49:07.000000000,2014-01-30 15:49:04.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 8430}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-29 13:06:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/7157859926a3483cc0a1894b29094e658e2bc21a', 'message': 'Remove V3 API XML entry points\n\nRemoves the entry points defined in setup.cfg for\nthe V3 API XML. These are no longer called.\n\nPartially implements blueprint remove-v3-xml-api\n\nChange-Id: I1fd516b5a01f1ce2b4d42320594616a49b66952d\n'}]",0,69856,7157859926a3483cc0a1894b29094e658e2bc21a,14,6,1,5292,,,0,"Remove V3 API XML entry points

Removes the entry points defined in setup.cfg for
the V3 API XML. These are no longer called.

Partially implements blueprint remove-v3-xml-api

Change-Id: I1fd516b5a01f1ce2b4d42320594616a49b66952d
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/69856/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,7157859926a3483cc0a1894b29094e658e2bc21a,bp/remove-v3-xml-api,,nova.api.v3.extensions.server.create.deserialize = access_ips = nova.api.openstack.compute.plugins.v3.access_ips:AccessIPs availability_zone = nova.api.openstack.compute.plugins.v3.availability_zone:AvailabilityZone block_device_mapping = nova.api.openstack.compute.plugins.v3.block_device_mapping:BlockDeviceMapping config_drive = nova.api.openstack.compute.plugins.v3.config_drive:ConfigDrive multiple_create = nova.api.openstack.compute.plugins.v3.multiple_create:MultipleCreate scheduler_hints = nova.api.openstack.compute.plugins.v3.scheduler_hints:SchedulerHints security_groups = nova.api.openstack.compute.plugins.v3.security_groups:SecurityGroups user_data = nova.api.openstack.compute.plugins.v3.user_data:UserData nova.api.v3.extensions.server.rebuild.deserialize = access_ips = nova.api.openstack.compute.plugins.v3.access_ips:AccessIPs ,0,13
openstack%2Fnova~master~Idc337c4a7ed024f236ca2b60d91e2c30f7d54536,openstack/nova,master,Idc337c4a7ed024f236ca2b60d91e2c30f7d54536,"Define ""supported_instances"" for fake compute",MERGED,2013-12-13 16:04:06.000000000,2014-01-30 15:48:12.000000000,2014-01-30 15:48:09.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 6873}, {'_account_id': 7179}, {'_account_id': 7494}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-13 16:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8f140a825c9dc2b791a38780dec68daaf30615e', 'message': 'Fixes bug 1260771: Fake compute driver cannot deploy image with hypervisor_type attribute\n\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 2, 'created': '2013-12-13 23:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/314c2552621033c1d69230cb0454e8f5d2c6b3f7', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used\nin multi hypervisor_type deployments.\n\nCloses-bug: 1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 3, 'created': '2013-12-16 20:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9f64c8e7875e34d9f0b7f8d6e99daf6c43415b3', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nIt is useful for testing applications on top of OpenStask\nby taking advantages of fake computes (fast, no physical\nlimits) while still being able to deploy ""real"" instances.\n\nCloses-bug: 1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 4, 'created': '2013-12-16 22:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c791f65823150d18010c84abd8c7f4254f3c3802', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeploiement allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: 1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 5, 'created': '2013-12-17 01:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22addffe5a371f895ff549855c8562efea9287a1', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: 1260771\nDocImpact\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 6, 'created': '2013-12-19 00:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edafd3488ccc522b377c2b87abc6efa667158bc3', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: 1260771\nDocImpact\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 7, 'created': '2013-12-25 22:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b3af1ca5b8e66d5742134c5014ac7e503007815', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and setted to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: #1260771\nDocImpact\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 8, 'created': '2014-01-09 13:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153178d4f05e23bed4bc08d41789893d05f7f3c5', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and set to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: #1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 9, 'created': '2014-01-15 22:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e7943a1a3f9d765502aee51f5c20a6f59c656f7', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and set to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: #1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 11, 'created': '2014-01-24 21:05:18.000000000', 'files': ['nova/virt/fake.py', 'doc/source/devref/development.environment.rst', 'nova/tests/virt/test_virt_drivers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bdecc8d2339e3e0dd87c7258244ac8568b5b965e', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and set to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: #1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}, {'number': 10, 'created': '2014-01-24 21:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4773dc71305548c2e18305ea49320cdd5ff6131d', 'message': 'Define ""supported_instances"" for fake compute\n\nAllow fake computes to deploy images with hypervisor_type\ndefined and set to ""fake"" and by extension to be used in\nmulti hypervisor_type deployments.\nMixing fake and ""real"" computes on the same OpenStack\ndeployment allows to create many fake instances and some\nworking instances for testing applications on top of\nOpenStack (ie: fake instances for stress tests, working\nones for functional tests).\n\nCloses-bug: #1260771\nChange-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536\n'}]",39,62024,bdecc8d2339e3e0dd87c7258244ac8568b5b965e,72,12,11,8124,,,0,"Define ""supported_instances"" for fake compute

Allow fake computes to deploy images with hypervisor_type
defined and set to ""fake"" and by extension to be used in
multi hypervisor_type deployments.
Mixing fake and ""real"" computes on the same OpenStack
deployment allows to create many fake instances and some
working instances for testing applications on top of
OpenStack (ie: fake instances for stress tests, working
ones for functional tests).

Closes-bug: #1260771
Change-Id: Idc337c4a7ed024f236ca2b60d91e2c30f7d54536
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/62024/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/fake.py'],1,d8f140a825c9dc2b791a38780dec68daaf30615e,bug/1260771,"from nova.openstack.common import jsonutils 'supported_instances': [(None, 'fake', None)], 'cpu_info': '?', 'supported_instances': jsonutils.dumps([(None, 'fake', None)])}", 'cpu_info': '?'},4,1
openstack%2Fnova~master~Ic443913883d80bdbc95385f8d3e21c0d855bb7db,openstack/nova,master,Ic443913883d80bdbc95385f8d3e21c0d855bb7db,Allow run_image_cache_manager_pass to hit db slave,MERGED,2013-12-10 05:37:24.000000000,2014-01-30 15:47:17.000000000,2014-01-30 15:47:13.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 4912}, {'_account_id': 5441}, {'_account_id': 7179}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-10 05:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9bf23b72e21e94640697004f620900c8a72982e', 'message': 'Allow run_image_cache_manager_pass to hit db slave\n\nDeployments that have a slave_connection configured can offload\nread queries there. For deployments with no slav behavior\nremains the same.\n\nChange-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db\nPartially-implements: blueprint periodc-tasks-to-db-slave\n'}, {'number': 2, 'created': '2013-12-10 22:40:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66e0b7dd57084cabe2775f4758e6add4074ae9fe', 'message': 'Allow run_image_cache_manager_pass to hit db slave\n\nDeployments that have a slave_connection configured can offload\nread queries there. For deployments with no slav behavior\nremains the same.\n\nChange-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db\nPartially-implements: blueprint periodc-tasks-to-db-slave\n'}, {'number': 3, 'created': '2013-12-11 21:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6d40fc3132691cb3a073ce4ee8d0a825c6ea6fe', 'message': 'Allow run_image_cache_manager_pass to hit db slave\n\nDeployments that have a slave_connection configured can offload\nread queries there. For deployments with no slave behavior\nremains the same.\n\nChange-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db\nPartially-implements: blueprint periodc-tasks-to-db-slave\n'}, {'number': 4, 'created': '2013-12-11 23:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/995079b7b4ab0035927cb1ac5fc508e50b417a0f', 'message': 'Allow run_image_cache_manager_pass to hit db slave\n\nDeployments that have a slave_connection configured can offload\nread queries there. For deployments with no slave behavior\nremains the same.\n\nChange-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db\nPartially-implements: blueprint periodic-tasks-to-db-slave\n'}, {'number': 5, 'created': '2014-01-15 01:16:38.000000000', 'files': ['nova/tests/virt/libvirt/test_imagecache.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1023e703bd41c2a42b1159af0d9e907e94440b34', 'message': 'Allow run_image_cache_manager_pass to hit db slave\n\nDeployments that have a slave_connection configured can offload\nread queries there. For deployments with no slave behavior\nremains the same.\n\nChange-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db\nPartially-implements: blueprint periodic-tasks-to-db-slave\n'}]",2,61011,1023e703bd41c2a42b1159af0d9e907e94440b34,41,7,5,4912,,,0,"Allow run_image_cache_manager_pass to hit db slave

Deployments that have a slave_connection configured can offload
read queries there. For deployments with no slave behavior
remains the same.

Change-Id: Ic443913883d80bdbc95385f8d3e21c0d855bb7db
Partially-implements: blueprint periodic-tasks-to-db-slave
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/61011/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,f9bf23b72e21e94640697004f620900c8a72982e,bp/periodic-tasks-to-db-slave," filtered_instances = instance_obj.InstanceList.get_by_filters(context, filters, expected_attrs=[], use_slave=True)"," filtered_instances = self.conductor_api.instance_get_all_by_filters( context, filters, columns_to_join=[])",2,2
openstack%2Fnova~master~I980326f1f15907bf57060acdd132011254289079,openstack/nova,master,I980326f1f15907bf57060acdd132011254289079,"Ensure that headers are utf8, not unicode",MERGED,2013-11-26 13:55:04.000000000,2014-01-30 15:46:23.000000000,2014-01-30 15:46:19.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 782}, {'_account_id': 5441}, {'_account_id': 5652}, {'_account_id': 7040}, {'_account_id': 7494}, {'_account_id': 9578}, {'_account_id': 9645}]","[{'number': 1, 'created': '2013-11-26 13:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01f9f151499d4b0b70881610d16d08b3bc565826', 'message': 'Ensure that headers are utf8, not unicode\n\nAltough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}, {'number': 2, 'created': '2013-11-27 22:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d827cc3730525607bd8219298561e36a7e6aad5', 'message': 'Ensure that headers are utf8, not unicode\n\nAlthough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}, {'number': 3, 'created': '2013-11-28 09:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb5f132171b532c740e248503112f714f94bf798', 'message': 'Ensure that headers are utf8, not unicode\n\nAlthough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}, {'number': 5, 'created': '2013-11-28 09:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/031d00ff35a6119558e402d8ddfdd2bae65417e7', 'message': 'Ensure that headers are utf8, not unicode\n\nAlthough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}, {'number': 4, 'created': '2013-11-28 09:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9961f4eee47cce9c06af10068e15f1eed6e64ed5', 'message': 'Ensure that headers are utf8, not unicode\n\nAlthough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}, {'number': 6, 'created': '2013-11-28 09:31:05.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/ec2/cloud.py', 'nova/tests/api/openstack/test_wsgi.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/148b6458642e810f57f9f85818b415e4029cb439', 'message': 'Ensure that headers are utf8, not unicode\n\nAlthough the api.openstack.wsgi.ResponseObject converted the headers to\nutf8 strings to comply with RFC for HTTP this was not enough, since some\nresponses that contained unicode strings were returned, causing an error\nwhen running nova behind an http server like Apache. This change ensures\nthat headers are always an utf8 encoded string.\n\nCloses-Bug: 1254017\n\nChange-Id: I980326f1f15907bf57060acdd132011254289079\n'}]",4,58523,148b6458642e810f57f9f85818b415e4029cb439,30,9,6,91,,,0,"Ensure that headers are utf8, not unicode

Although the api.openstack.wsgi.ResponseObject converted the headers to
utf8 strings to comply with RFC for HTTP this was not enough, since some
responses that contained unicode strings were returned, causing an error
when running nova behind an http server like Apache. This change ensures
that headers are always an utf8 encoded string.

Closes-Bug: 1254017

Change-Id: I980326f1f15907bf57060acdd132011254289079
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/58523/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/test_wsgi.py']",2,01f9f151499d4b0b70881610d16d08b3bc565826,bug/1254017," def test_resource_headers_are_utf8(self): resp = webob.Response(status_int=202) resp.headers['x-header1'] = 1 resp.headers['x-header2'] = u'header2' resp.headers[u'x-header3'] = u'header3' class Controller(object): def index(self, req): return resp req = webob.Request.blank('/tests') app = fakes.TestRouter(Controller()) response = req.get_response(app) for hdr, val in response.headers.iteritems(): # All headers must be utf8 self.assertIsInstance(hdr, str) self.assertIsInstance(val, str) self.assertEqual(response['x-header1'], '1') self.assertEqual(response['x-header2'], 'header2') self.assertEqual(response['x-header3'], 'header3') robj[u'X-header-unicode'] = u'header-unicode' for hdr, val in response.headers.iteritems(): # All headers must be utf8 self.assertIsInstance(hdr, str) self.assertIsInstance(val, str)",,37,4
openstack%2Fnova~master~Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48,openstack/nova,master,Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48,VMware: Only include connected hosts in cluster stats,MERGED,2013-12-14 00:58:25.000000000,2014-01-30 15:45:20.000000000,2014-01-30 15:45:17.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 7575}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-14 00:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31e2c135ec83f586b8deadc0f95d7b322c9f862c', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state.\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 2, 'created': '2013-12-14 04:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/259a903fd56c864aa0c5df0cb14fa6cbe381d15a', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state.\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 3, 'created': '2014-01-07 03:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a41f6349f33ab1e32fc68acb3e329fea0ff92f6', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 4, 'created': '2014-01-07 18:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/320b9d0e24a5fea741378e2ed413e7e475c73a92', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 5, 'created': '2014-01-07 19:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e30f37bde8206ea4ff39d5b2de3a7d0a14eabae8', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 6, 'created': '2014-01-21 20:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f551a5cc96fb2daf2c626d358875b705571caf6d', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 8, 'created': '2014-01-22 22:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e58065f11fdfb42856e185f63b591c03afbc5b8e', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 9, 'created': '2014-01-22 22:51:43.000000000', 'files': ['nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/virt/vmwareapi/test_vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6248cea77d221ac0f37a7be7481a235f457f7267', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}, {'number': 7, 'created': '2014-01-22 22:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/429248e42801ecc81c0242dfaf47dcd2fa825ba9', 'message': 'VMware: Only include connected hosts in cluster stats\n\nCurrently the driver includes all hosts connected to VC\n(including disconnected hosts) when calculating available\nvcpus. The patch enforces that the reported available stats\nonly include resources of hosts that are connected to the\nVC.\n\nNote: A host can be connected to a VC, but have a disconnected\nhost state\n\nChange-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48\nCloses-Bug: 1257998\n'}]",10,62118,6248cea77d221ac0f37a7be7481a235f457f7267,71,12,9,9046,,,0,"VMware: Only include connected hosts in cluster stats

Currently the driver includes all hosts connected to VC
(including disconnected hosts) when calculating available
vcpus. The patch enforces that the reported available stats
only include resources of hosts that are connected to the
VC.

Note: A host can be connected to a VC, but have a disconnected
host state

Change-Id: Iba9d80f894cc2b7471a7f9c87b7367fd93bacb48
Closes-Bug: 1257998
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/62118/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/driver.py', 'nova/tests/virt/vmwareapi/test_vmwareapi_vm_util.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py']",4,31e2c135ec83f586b8deadc0f95d7b322c9f862c,bug/1257998," ""HostSystem"", host_mors, [""summary.hardware"", ""summary.runtime""]) runtime_summary = obj.propSet[1].val if runtime_summary.connectionState == ""connected"": # Total vcpus is the sum of all pCPUs of individual hosts # The overcommitment ratio is factored in by the scheduler cpu_info['vcpus'] += hardware_summary.numCpuThreads cpu_info['cores'] += hardware_summary.numCpuCores cpu_info['vendor'].append(hardware_summary.vendor) cpu_info['model'].append(hardware_summary.cpuModel)"," ""HostSystem"", host_mors, [""summary.hardware""]) # Total vcpus is the sum of all pCPUs of individual hosts # The overcommitment ratio is factored in by the scheduler cpu_info['vcpus'] += hardware_summary.numCpuThreads cpu_info['cores'] += hardware_summary.numCpuCores cpu_info['vendor'].append(hardware_summary.vendor) cpu_info['model'].append(hardware_summary.cpuModel)",78,9
openstack%2Ffuel-web~master~I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe,openstack/fuel-web,master,I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe,Fixed bypass of Public GW check,MERGED,2014-01-28 11:11:35.000000000,2014-01-30 15:43:25.000000000,2014-01-30 15:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8935}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-01-28 11:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/983133d7c80846ffb35a3f0966a3cada1f70a48e', 'message': ""Fixed bypass of Public GW check\n\nWhen Public network has only one IP range set\nthe check of intersection between GW and IP ranges of Public network was skipped.\nIt's fixed now. Tests are added. Slight tests refactoring is made.\n\nCloses-Bug: #1273175\n\nChange-Id: I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe\n""}, {'number': 2, 'created': '2014-01-28 11:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/14f4442e3e2ecd6c5ac30bca4b3bcf94fffc9db6', 'message': ""Fixed bypass of Public GW check\n\nWhen Public network has only one IP range set\nthe check of intersection between GW and IP ranges of Public network was skipped.\nIt's fixed now. Tests are added. Slight tests refactoring is made.\n\nCloses-Bug: #1273175\n\nChange-Id: I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe\n""}, {'number': 3, 'created': '2014-01-28 12:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d2ca27222318fef5fe8a7083dfcfea2d4cc0d735', 'message': ""Fixed bypass of Public GW check\n\nWhen Public network has only one IP range set\nthe check of intersection between GW and IP ranges of Public network was skipped.\nIt's fixed now. Tests are added. Slight tests refactoring is made.\n\nCloses-Bug: #1273175\n\nChange-Id: I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe\n""}, {'number': 4, 'created': '2014-01-28 14:28:38.000000000', 'files': ['nailgun/nailgun/test/integration/test_network_validation.py', 'nailgun/nailgun/network/checker.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/11449a601aef24e2e87677540ca82ecfc9971fe5', 'message': ""Fixed bypass of Public GW check\n\nWhen Public network has only one IP range set\nthe check of intersection between GW and IP ranges of Public network was skipped.\nBoth Nova-Net and Neutron. It's fixed here.\nTests are added. Slight tests refactoring is made.\n\nCloses-Bug: #1273175\n\nChange-Id: I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe\n""}]",0,69578,11449a601aef24e2e87677540ca82ecfc9971fe5,29,6,4,8392,,,0,"Fixed bypass of Public GW check

When Public network has only one IP range set
the check of intersection between GW and IP ranges of Public network was skipped.
Both Nova-Net and Neutron. It's fixed here.
Tests are added. Slight tests refactoring is made.

Closes-Bug: #1273175

Change-Id: I0f6ca9e43a5c21aebefb9b38f9b8cb59c02126fe
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/78/69578/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_network_validation.py', 'nailgun/nailgun/network/checker.py']",2,983133d7c80846ffb35a3f0966a3cada1f70a48e,1273175, for net in nets: if pub_gw in net: # Check that Public IP ranges are in Public CIDR if ng['name'] == 'public': # Check intersection between Public GW and IP ranges for net in ranges: if public_gw in net:, if pub_gw in npair[0] or pub_gw in npair[1]: # Check that Public IP ranges are in Public CIDR if ng['name'] == 'public': for net in nets: if public_gw in npair[0] or public_gw in npair[1]:,88,174
openstack%2Fheat~master~I812f308ef38833e89dfa2ce01263a297032f563a,openstack/heat,master,I812f308ef38833e89dfa2ce01263a297032f563a,API tolerate None environment string,MERGED,2014-01-29 14:00:13.000000000,2014-01-30 15:27:24.000000000,2014-01-30 15:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 7253}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-01-29 14:00:13.000000000', 'files': ['heat/tests/test_environment_format.py', 'heat/common/environment_format.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7530b165137df4470f304f72d5d831e8a0ca7ad1', 'message': 'API tolerate None environment string\n\nIf an API request has a None environment argument, we should not\nreject the request, but treat it the same as an empty environment.\n\nChange-Id: I812f308ef38833e89dfa2ce01263a297032f563a\nCloses-Bug: #1273993\n'}]",0,69868,7530b165137df4470f304f72d5d831e8a0ca7ad1,11,8,1,4328,,,0,"API tolerate None environment string

If an API request has a None environment argument, we should not
reject the request, but treat it the same as an empty environment.

Change-Id: I812f308ef38833e89dfa2ce01263a297032f563a
Closes-Bug: #1273993
",git fetch https://review.opendev.org/openstack/heat refs/changes/68/69868/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_environment_format.py', 'heat/common/environment_format.py']",2,7530b165137df4470f304f72d5d831e8a0ca7ad1,bug/1273993, if env_str is None: return {} , This includes determination of whether the string is using the JSON or YAML format.,6,2
openstack%2Fblazar~master~Ia34e16c636d1fa8d200873334f55b9868866f97f,openstack/blazar,master,Ia34e16c636d1fa8d200873334f55b9868866f97f,Implement basic plugin for VM management,MERGED,2013-10-01 11:52:54.000000000,2014-01-30 15:01:04.000000000,2014-01-30 15:01:04.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6786}, {'_account_id': 7075}, {'_account_id': 7166}, {'_account_id': 7535}]","[{'number': 2, 'created': '2013-10-01 11:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/5f1f32a2cb9202dbdb319c68f83b2ec3b428d39d', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 1, 'created': '2013-10-01 11:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/33259adbe8d60030a963b2f18ca1cc0625939ba0', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 3, 'created': '2013-10-07 11:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e763bbf71211d8b2dc14a519ff9b16fd6c289746', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 4, 'created': '2013-10-07 11:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e40a0c173f5eec098a74e4210d853bd902f7f838', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 5, 'created': '2013-10-14 09:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/78c3e182030714bf89a26c20c0d19f19e44f2db4', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 6, 'created': '2013-10-14 10:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/253024798b27cb5249d3288f211b9f098be4b6f6', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 7, 'created': '2013-10-15 15:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d6f005c4ee0d73f6cc08b6f5956e7a339c6cac88', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 8, 'created': '2013-10-16 09:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/9bac0be9aeea896bfce98ac9261ad1ba008c7dab', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 9, 'created': '2013-10-16 09:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/81e3fd6d30945753eec3a41ecfb3e083e1eb24f5', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 10, 'created': '2013-10-16 15:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e2bc9ef6274d741daf683690aea6d1cc486d7497', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 11, 'created': '2013-10-16 16:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f828fefa1e6a311c2f180da1fa3264382616e3e1', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 12, 'created': '2013-10-17 07:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/eac462d6b701279c2cce015d29b66931319cbb7e', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 13, 'created': '2013-10-17 10:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/5ec1fa3b97883aa54f566c0fa0d05e73e7038405', 'message': 'Implement basic plugin for vm management\n\nWORK IN PROGRESS\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 14, 'created': '2013-10-29 10:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/858dc95e0c4a9da05a9ac1cd314cc217a3be261c', 'message': 'Implement basic plugin for vm management\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 15, 'created': '2013-11-12 06:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/03ae4be0e915d59f0a8504082c04afca1a8be24d', 'message': 'Implement basic plugin for vm management\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 16, 'created': '2013-12-09 09:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/bb615afb21f91ee493da59d043fdbc3580b7bb1b', 'message': 'Implement basic plugin for vm management\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 17, 'created': '2013-12-17 08:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6f6f643c87b35ed34f8c422da02cc6e6ac8eac23', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 18, 'created': '2013-12-17 09:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d0e871eac0d9fb85e17be17b14cdb939aa56b3bb', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 19, 'created': '2013-12-17 12:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/acf94a7f3defbb477b12cb968a59dbcff9709562', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 20, 'created': '2013-12-19 05:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f93284c1748d81d119bda530ab69e5acc607a5ac', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 21, 'created': '2013-12-24 10:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/66d029977ae5ccc4b0b9fa97425fab33d0c768f5', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 22, 'created': '2013-12-25 09:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/fa62de73a286cf75a8994a0659eeb8f7a2fd7d39', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 23, 'created': '2014-01-09 10:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/3785fbc39050c0429fe5a3bf20c748dfa179b3dd', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 24, 'created': '2014-01-10 11:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/055e54ab16906cfb7bac6aca00917adad6590df5', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 25, 'created': '2014-01-14 09:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/1481813c7addcfbe6b713700cb6ee236d8bbf5e1', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 26, 'created': '2014-01-15 07:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/7673ab65f2f921735db889d4e04440765dc62710', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 27, 'created': '2014-01-15 15:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/318a943e1d1b9a939ed4cdcee1fe6a726776eb14', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 29, 'created': '2014-01-15 15:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/c4354eb26a052351e5f1be8e044f79ac605a814c', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 28, 'created': '2014-01-15 15:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6c43610e288d009bd2e2b29a33f9e08d31592c30', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 31, 'created': '2014-01-17 10:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/dc2ea0d1d875b276e5af3c1e94d385884d90d5c8', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 30, 'created': '2014-01-17 10:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d5a53af9c950144221cd2b620abeb11f0f24554d', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 32, 'created': '2014-01-18 09:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/0e426b6d9b9b7bd6af94c92daa650c2c2f376747', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 33, 'created': '2014-01-20 11:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e42903f8b9e090c33874168d51e31ae61fad8000', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 34, 'created': '2014-01-21 10:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f1182b02953ad1dc0f683e4d628b170ca0c98b32', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 35, 'created': '2014-01-21 14:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/52aeda7612a187f3f6a4262b86d53fd774c1df87', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 36, 'created': '2014-01-21 16:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/c0ce73e4e6634855eb8d453e12f8bbc716cc6709', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 37, 'created': '2014-01-22 07:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/35ae4d9a28494e2330e741b43723053b399d8fc0', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 39, 'created': '2014-01-22 11:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/ef7454ce4b59c7243d26cec29d8e094614d29498', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 38, 'created': '2014-01-22 11:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/240ec3ec31e4679c564bdc4ab712be1130c2951b', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 40, 'created': '2014-01-24 09:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/8dd37c604492fc4169f6029e91400a7f2fb1796d', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 41, 'created': '2014-01-24 11:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/092c8de7c3b63ee91ec10e07ad520b5a7bb76918', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 42, 'created': '2014-01-24 13:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/cd38808c1c13c05f118ccb04bb77cbb246c111b9', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 43, 'created': '2014-01-24 14:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/641d2a1d55c0ddf90c37bfd27f20351a9a3f3794', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 44, 'created': '2014-01-24 16:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/859e941c7ea77a61bd3929c75d31ce421d01e93f', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 45, 'created': '2014-01-26 19:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/5b437e9582bd7a5ee6c528e5234357002d031414', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 46, 'created': '2014-01-27 06:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/91f769c5f08fd6e4dff4bf2f2f1b709085a224e9', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 48, 'created': '2014-01-27 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/75f60efe01265cabb29f3d60c025f3c86beb6cc1', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 47, 'created': '2014-01-27 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/41374b7bac91950147accbe485580e9612a3a167', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 49, 'created': '2014-01-29 09:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/8b72669aecdadeae6427dcd9ee044c2b6f1f1d07', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 50, 'created': '2014-01-29 12:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/b4d850185e45e5bc9eb488f9ba34889bb49c4881', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 51, 'created': '2014-01-29 16:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/5b254210fe82e8fe22ae337190ed7a2e3cf8798e', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}, {'number': 52, 'created': '2014-01-29 18:00:52.000000000', 'files': ['climate/tests/plugins/instances/__init__.py', 'climate/plugins/instances/__init__.py', 'climate/plugins/instances/vm_plugin.py', 'climate/exceptions.py', 'climate/tests/utils/openstack/test_nova.py', 'climate/utils/openstack/nova.py', 'climate/tests/plugins/instances/test_vm_plugin.py', 'setup.cfg', 'etc/climate.conf.example'], 'web_link': 'https://opendev.org/openstack/blazar/commit/0177cd884133ffb532ce44656e52c355dcb5454c', 'message': 'Implement basic plugin for VM management\n\nThis commit implements basic VM management plugin for Climate.\nAs decided we use nova shelved instances to support our reservation\nmodel. The only one thing we do for ""on_start"" lease action -\n\'unshelve\' instance. As decided we support configurable opts for\n""on_end"" lease action, by default it set to snapshot and delete VM.\n\nImplements bp:basic-vm-plugin\n\nChange-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f\n'}]",88,49142,0177cd884133ffb532ce44656e52c355dcb5454c,176,6,52,7535,,,0,"Implement basic plugin for VM management

This commit implements basic VM management plugin for Climate.
As decided we use nova shelved instances to support our reservation
model. The only one thing we do for ""on_start"" lease action -
'unshelve' instance. As decided we support configurable opts for
""on_end"" lease action, by default it set to snapshot and delete VM.

Implements bp:basic-vm-plugin

Change-Id: Ia34e16c636d1fa8d200873334f55b9868866f97f
",git fetch https://review.opendev.org/openstack/blazar refs/changes/42/49142/51 && git format-patch -1 --stdout FETCH_HEAD,"['climate/plugins/basic/__init__.py', 'climate/plugins/basic/vm_plugin.py']",2,5f1f32a2cb9202dbdb319c68f83b2ec3b428d39d,bp/basic-vm-plugin,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from climate.plugins import base class VMPlugin(base.BasePlugin): """"""Base plugin for VM reservation"""""" def __init__(self): self.name = 'basic.vm.plugin' self.resource_type = 'virtual:instance' def get_title(self): return ""Basic VM Plugin"" def get_description(self): description = ( ""This is basic plugin for VM management. "" ""It can start, suspend snapshot and shutdown VMs"" ) return description def wake_up(self, resource_id): pass def suspend(self, resource_id): pass def shutdown(self, resource_id): pass def snapshot(self, resource_id): pass ",,59,0
openstack%2Fpython-neutronclient~master~I4292252952c8f55536f5960d6ef88e6897de500e,openstack/python-neutronclient,master,I4292252952c8f55536f5960d6ef88e6897de500e,[don't review] make floating-ip floating_network_id optional,ABANDONED,2014-01-24 15:32:55.000000000,2014-01-30 14:59:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-24 15:32:55.000000000', 'files': ['neutronclient/neutron/v2_0/floatingip.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bcaf448bd4cae7f9da8e39184527d03913377606', 'message': ""[don't review] make floating-ip floating_network_id optional\n\nPoC patch depends of neutron part:\nhttps://review.openstack.org/68933\n\nChange-Id: I4292252952c8f55536f5960d6ef88e6897de500e\n""}]",0,68938,bcaf448bd4cae7f9da8e39184527d03913377606,2,1,1,2813,,,0,"[don't review] make floating-ip floating_network_id optional

PoC patch depends of neutron part:
https://review.openstack.org/68933

Change-Id: I4292252952c8f55536f5960d6ef88e6897de500e
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/38/68938/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/floatingip.py'],1,bcaf448bd4cae7f9da8e39184527d03913377606,sileht/floating_network_id-optional," 'floating_network_id', metavar='FLOATING_NETWORK', nargs=""?"", if parsed_args.floating_network_id: _network_id = neutronV20.find_resourceid_by_name_or_id( self.get_client(), 'network', parsed_args.floating_network_id) info = {'floating_network_id': _network_id} else: info = {} body = {self.resource: info}"," 'floating_network_id', metavar='FLOATING_NETWORK', _network_id = neutronV20.find_resourceid_by_name_or_id( self.get_client(), 'network', parsed_args.floating_network_id) body = {self.resource: {'floating_network_id': _network_id}}",8,4
openstack%2Fhorizon~master~Ibe3cf1677195e772ca449761a924763b7a78581a,openstack/horizon,master,Ibe3cf1677195e772ca449761a924763b7a78581a,[don't review] make floating-ip floating_network_id optional,ABANDONED,2014-01-24 15:28:13.000000000,2014-01-30 14:59:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-01-24 15:28:13.000000000', 'files': ['openstack_dashboard/api/neutron.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b7771904bf423c1e60d2e48e093e418405d52eb', 'message': ""[don't review] make floating-ip floating_network_id optional\n\nPoC patch depends of neutron part: https://review.openstack.org/68933\n\nChange-Id: Ibe3cf1677195e772ca449761a924763b7a78581a\n""}]",0,68934,3b7771904bf423c1e60d2e48e093e418405d52eb,2,1,1,2813,,,0,"[don't review] make floating-ip floating_network_id optional

PoC patch depends of neutron part: https://review.openstack.org/68933

Change-Id: Ibe3cf1677195e772ca449761a924763b7a78581a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/68934/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/neutron.py'],1,3b7771904bf423c1e60d2e48e093e418405d52eb,sileht/floating_network_id-optional,"AUTOMATIC_POOL_ID=""<AUTOMATIC_POOL_ID>"" return [FloatingIpPool({'name': 'Automatic', 'id': AUTOMATIC_POOL_ID})] + \ [FloatingIpPool(pool) for pool if pool == AUTOMATIC_POOL_ID: pool = None", return [FloatingIpPool(pool) for pool,8,1
openstack%2Fneutron~master~Ieb10249cf1c940cf68ef465768851ae573e7d80e,openstack/neutron,master,Ieb10249cf1c940cf68ef465768851ae573e7d80e,make floating_network_id optional,ABANDONED,2014-01-24 15:21:43.000000000,2014-01-30 14:59:37.000000000,,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 2813}, {'_account_id': 6659}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}]","[{'number': 1, 'created': '2014-01-24 15:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61847a0f0a85ac7b3ccf2696c4044b3c869749b9', 'message': 'make floating_network_id optionnal\n\nThis change make floating_network_id optional. Instead it selects the\nfirst external network with floating available.\n\nChange-Id: Ieb10249cf1c940cf68ef465768851ae573e7d80e\n'}, {'number': 2, 'created': '2014-01-24 15:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8c26bfcf5707acb01a10fc1b491b7957dfda7084', 'message': 'make floating_network_id optional\n\nThis change make floating_network_id optional. Instead it selects the\nfirst external network with floating available.\n\nChange-Id: Ieb10249cf1c940cf68ef465768851ae573e7d80e\n'}, {'number': 3, 'created': '2014-01-24 15:56:33.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/extensions/l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6be3bd12a83250a8ae6ae6d0d8710926b98314ad', 'message': 'make floating_network_id optional\n\nThis change make floating_network_id optional. Instead it selects the\nfirst external network with floating available.\n\nChange-Id: Ieb10249cf1c940cf68ef465768851ae573e7d80e\n'}]",4,68933,6be3bd12a83250a8ae6ae6d0d8710926b98314ad,18,9,3,2813,,,0,"make floating_network_id optional

This change make floating_network_id optional. Instead it selects the
first external network with floating available.

Change-Id: Ieb10249cf1c940cf68ef465768851ae573e7d80e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/68933/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/extensions/l3.py', 'neutron/db/l3_db.py']",3,61847a0f0a85ac7b3ccf2696c4044b3c869749b9,sileht/floating_network_id-optional,"from neutron.extensions import external_net if not fip['floating_network_id']: nets = self._core_plugin.get_networks( context, filters={external_net.EXTERNAL: [True]}) for net in nets: fip['floating_network_id'] = net['id'] try: return self._create_floatingip(context, fip) except q_exc.ExternalIpAddressExhausted: continue else: net_id=nets[0]['id'] if len(nets) == 1 else '' raise q_exc.ExternalIpAddressExhausted(net_id=net_id) else: return self._create_floatingip(context, fip) def _create_floatingip(self, context, fip):",,33,3
openstack%2Fopenstack-manuals~master~I4306c110198e32d2db1c1a528d89aae972a13d01,openstack/openstack-manuals,master,I4306c110198e32d2db1c1a528d89aae972a13d01,Fixes a small typo in the glance-verify section,MERGED,2014-01-30 14:38:21.000000000,2014-01-30 14:51:43.000000000,2014-01-30 14:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7020}]","[{'number': 1, 'created': '2014-01-30 14:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/63637e2b691ee4b96b243c1e990570a4b43870d8', 'message': 'Fixes a small typo in the glance-verify section\n\nChange-Id: I4306c110198e32d2db1c1a528d89aae972a13d01\n'}, {'number': 2, 'created': '2014-01-30 14:42:46.000000000', 'files': ['doc/install-guide/section_glance-verify.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9a3651c899ebddee11069e42ed7daf1f6d442a08', 'message': 'Fixes a small typo in the glance-verify section\n\nbackport: havana\nChange-Id: I4306c110198e32d2db1c1a528d89aae972a13d01\n'}]",0,70123,9a3651c899ebddee11069e42ed7daf1f6d442a08,7,3,2,7020,,,0,"Fixes a small typo in the glance-verify section

backport: havana
Change-Id: I4306c110198e32d2db1c1a528d89aae972a13d01
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/70123/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_glance-verify.xml'],1,63637e2b691ee4b96b243c1e990570a4b43870d8,typo_glance," the value is not used anywhere, it is safe to always specify <literal>bare</literal> as the container format.</para>"," the value is not used anywhere, it safe to always specify <literal>bare</literal> as the container format.</para>",3,3
openstack%2Freviewstats~master~I43d264b83ed2fe4f776b6c099c8be0bbbc48b3fa,openstack/reviewstats,master,I43d264b83ed2fe4f776b6c099c8be0bbbc48b3fa,Add mistral with subprojects,MERGED,2014-01-28 18:12:13.000000000,2014-01-30 14:48:18.000000000,2014-01-30 14:48:18.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-01-28 18:12:13.000000000', 'files': ['projects/mistral.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/5f3f70b48347f57f18617f89f353aaa2df0e1215', 'message': 'Add mistral with subprojects\n\nChange-Id: I43d264b83ed2fe4f776b6c099c8be0bbbc48b3fa\n'}]",0,69683,5f3f70b48347f57f18617f89f353aaa2df0e1215,6,3,1,6786,,,0,"Add mistral with subprojects

Change-Id: I43d264b83ed2fe4f776b6c099c8be0bbbc48b3fa
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/83/69683/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/mistral.json'],1,5f3f70b48347f57f18617f89f353aaa2df0e1215,,"{ ""name"": ""mistral"", ""unofficial"": true, ""subprojects"": [ ""stackforge/mistral"", ""stackforge/mistral-extra"", ""stackforge/python-mistralclient"" ], ""core-team"": [ ""rakhmerov"" ] } ",,12,0
openstack%2Fpbr~master~I4b548e9830586f11b82539d334dd5cf4b0445a36,openstack/pbr,master,I4b548e9830586f11b82539d334dd5cf4b0445a36,package: read a specific Python version requirement file,MERGED,2013-12-19 23:02:25.000000000,2014-01-30 14:38:42.000000000,2014-01-30 14:38:42.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6786}, {'_account_id': 6928}, {'_account_id': 7450}, {'_account_id': 7491}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2013-12-19 23:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/44caf7079d447a937706fb8b91d7755b72456504', 'message': ""package: read a specific Python version requirement file\n\nThis change makes pbr reads a specific requirement file tight to the\nmajor Python version has he's used.\n\nChange-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36\n""}, {'number': 2, 'created': '2013-12-20 00:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/0adefa57c673b9b76fd0ea7fe920608b9ce38a9e', 'message': ""package: read a specific Python version requirement file\n\nThis change makes pbr reads a specific requirement file tight to the\nmajor Python version has he's used.\n\nChange-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36\n""}, {'number': 3, 'created': '2013-12-20 22:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/b0c1e2781c28108c4e6cc862fc9437263d132a65', 'message': ""package: read a specific Python version requirement file\n\nThis change makes pbr reads a specific requirement file tight to the\nmajor Python version has he's used.\n\nChange-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36\n""}, {'number': 4, 'created': '2014-01-08 14:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/fe300f40b467cd83db8181478eb7f58b3349bee9', 'message': 'package: read a specific Python version requirement file\n\nThis change makes pbr reads a specific requirement file tight to the\nmajor Python version that is used. So you can add a file such as\nrequirements-py3.txt to have a specific requirement file for Python\xa03,\nor requirements-py2.txt to have a specific requirement file for\nPython\xa02.\n\nChange-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36\n'}, {'number': 5, 'created': '2014-01-28 11:30:23.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/packaging.py', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/pbr/commit/44803433a7da66b5e7404806290237469f07fd5d', 'message': 'package: read a specific Python version requirement file\n\nThis change makes pbr reads a specific requirement file tight to the\nmajor Python version that is used. So you can add a file such as\nrequirements-py3.txt to have a specific requirement file for Python\xa03,\nor requirements-py2.txt to have a specific requirement file for\nPython\xa02.\n\nChange-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36\n'}]",7,63236,44803433a7da66b5e7404806290237469f07fd5d,39,21,5,1669,,,0,"package: read a specific Python version requirement file

This change makes pbr reads a specific requirement file tight to the
major Python version that is used. So you can add a file such as
requirements-py3.txt to have a specific requirement file for Python3,
or requirements-py2.txt to have a specific requirement file for
Python2.

Change-Id: I4b548e9830586f11b82539d334dd5cf4b0445a36
",git fetch https://review.opendev.org/openstack/pbr refs/changes/36/63236/5 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'pbr/packaging.py']",2,44caf7079d447a937706fb8b91d7755b72456504,jd/python3," return (map(('-py' + str(sys.version_info[0])).join, map(os.path.splitext, REQUIREMENTS_FILES)) + list(REQUIREMENTS_FILES))", return REQUIREMENTS_FILES,10,1
