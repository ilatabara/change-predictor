id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftempest~master~I1fc92d4405226ac34058853df598be75bf921691,openstack/tempest,master,I1fc92d4405226ac34058853df598be75bf921691,Pass wait_until arg in create_test_server call,MERGED,2015-05-24 08:09:03.000000000,2015-05-28 07:00:24.000000000,2015-05-28 07:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10300}, {'_account_id': 10388}, {'_account_id': 11075}, {'_account_id': 14965}]","[{'number': 1, 'created': '2015-05-24 08:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ad68e29ac64602bdf5cfbc191ac5312ca7c08472', 'message': 'Pass wait_until arg in create_test_server call\n\nwait_until argument is not passed when when calling\ncreate_test_server due to which it returns server details and then\ntest cleanup goes for deleting server which is still in build state\ncausing it to leave behind volume if server is booted using bootable\nvolume. passing wait_until arg fixes the issue.\n\nChange-Id: I1fc92d4405226ac34058853df598be75bf921691\n'}, {'number': 2, 'created': '2015-05-24 18:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5790faa75daa62f60bd69053de72828be39f6558', 'message': 'Pass wait_until arg in create_test_server call\n\nwait_until argument is not passed when calling\ncreate_test_server due to which it returns server details and then\ntest cleanup goes for deleting server which is still in build state\ncausing it to leave behind volume if server is booted using bootable\nvolume. passing wait_until arg fixes the issue. Also name variable\nis getting ignored so adding condition to use name variable if passed.\n\nChange-Id: I1fc92d4405226ac34058853df598be75bf921691\n'}, {'number': 3, 'created': '2015-05-26 05:32:06.000000000', 'files': ['tempest/api/compute/servers/test_multiple_create.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6edb4be879142377a9f080545f62a22bd662c5a', 'message': 'Pass wait_until arg in create_test_server call\n\nwait_until argument is not passed when calling\ncreate_test_server due to which it returns server details and then\ntest cleanup goes for deleting server which is still in build state\ncausing it to leave behind volume if server is booted using bootable\nvolume. passing wait_until arg fixes the issue. Also name variable\nis getting ignored so adding condition to use name variable if passed.\n\nChange-Id: I1fc92d4405226ac34058853df598be75bf921691\nCloses-Bug: 1458295\n'}]",1,185266,e6edb4be879142377a9f080545f62a22bd662c5a,30,10,3,14965,,,0,"Pass wait_until arg in create_test_server call

wait_until argument is not passed when calling
create_test_server due to which it returns server details and then
test cleanup goes for deleting server which is still in build state
causing it to leave behind volume if server is booted using bootable
volume. passing wait_until arg fixes the issue. Also name variable
is getting ignored so adding condition to use name variable if passed.

Change-Id: I1fc92d4405226ac34058853df598be75bf921691
Closes-Bug: 1458295
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/185266/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_multiple_create.py'],1,ad68e29ac64602bdf5cfbc191ac5312ca7c08472,bug/1458295," body = self.create_test_server(wait_until=wait_until, **kwargs)", body = self.create_test_server(**kwargs),1,1
openstack%2Foperations-guide~master~Iae9778fb9c447854813b8b0aebedf9dce3511485,openstack/operations-guide,master,Iae9778fb9c447854813b8b0aebedf9dce3511485,Imported Translations from Transifex,MERGED,2015-05-28 06:01:01.000000000,2015-05-28 06:59:08.000000000,2015-05-28 06:59:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-28 06:01:01.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/62dfb56f5d803e7dda11ab5c15a5a75ddb021af2', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iae9778fb9c447854813b8b0aebedf9dce3511485\n'}]",0,186265,62dfb56f5d803e7dda11ab5c15a5a75ddb021af2,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iae9778fb9c447854813b8b0aebedf9dce3511485
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/65/186265/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po']",2,62dfb56f5d803e7dda11ab5c15a5a75ddb021af2,transifex/translations,"""POT-Creation-Date: 2015-05-27 09:52+0000\n"" ""PO-Revision-Date: 2015-05-25 14:49+0000\n""msgid ""\""Hey Alvaro, can you run a VLAN on top of a VLAN?\"""" msgstr ""「Alvaro、VLAN 上に VLAN って作れるのかい？」""msgid ""\""The Issue\"""" msgstr ""「あの問題」""msgid ""&lt;uuid of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの UUID&gt;""msgid ""&lt;uuid of original image of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの元イメージの UUID&gt;""msgid ""* <code>schedule_run_instance</code>"" msgstr ""* <code>schedule_run_instance</code>""msgid ""/var/lib/nova/instances"" msgstr ""/var/lib/nova/instances""msgid ""/var/log/apache2/"" msgstr ""/var/log/apache2/""msgid ""/var/log/cinder"" msgstr ""/var/log/cinder""msgid ""/var/log/glance"" msgstr ""/var/log/glance""msgid ""/var/log/keystone"" msgstr ""/var/log/keystone""msgid ""/var/log/nova"" msgstr ""/var/log/nova""msgid ""/var/log/rsyslog/c01.example.com/nova.log"" msgstr ""/var/log/rsyslog/c01.example.com/nova.log""msgid ""/var/log/rsyslog/c02.example.com/nova.log"" msgstr ""/var/log/rsyslog/c02.example.com/nova.log""msgid ""/var/log/rsyslog/nova.log"" msgstr ""/var/log/rsyslog/nova.log""msgid ""/var/log/syslog"" msgstr ""/var/log/syslog""msgid ""0 GB"" msgstr ""0 GB"" msgid ""1"" msgstr ""1"" msgid ""1 GB"" msgstr ""1 GB"" msgid ""1 TB disk"" msgstr ""1TBディスク"" msgid ""10"" msgstr ""10"" msgid ""10 GB"" msgstr ""10 GB"" msgid ""10 GB first disk, 30 GB second disk"" msgstr ""1 番目のディスク 10 GB、2 番目のディスク 30 GB"" msgid ""100"" msgstr ""100"" msgid ""10s of TBs of dataset storage"" msgstr ""数十TBのデータセットストレージ"" msgid ""15"" msgstr ""15"" msgid ""16 GB"" msgstr ""16 GB"" msgid ""160 GB"" msgstr ""160 GB"" msgid ""2"" msgstr ""2"" msgid ""2 GB"" msgstr ""2 GB"" msgid ""20"" msgstr ""20"" msgid ""20 GB"" msgstr ""20 GB"" msgid ""200 physical cores."" msgstr ""物理コア 200 個"" msgid ""2010.1"" msgstr ""2010.1"" msgid ""2011.1"" msgstr ""2011.1"" msgid ""2011.2"" msgstr ""2011.2"" msgid ""2011.3"" msgstr ""2011.3"" msgid ""2011.3.1"" msgstr ""2011.3.1"" msgid ""2012.1"" msgstr ""2012.1"" msgid ""2012.1.1"" msgstr ""2012.1.1"" msgid ""2012.1.2"" msgstr ""2012.1.2"" msgid ""2012.1.3"" msgstr ""2012.1.3"" msgid ""2012.2"" msgstr ""2012.2"" msgid ""2012.2.1"" msgstr ""2012.2.1"" msgid ""2012.2.2"" msgstr ""2012.2.2"" msgid ""2012.2.3"" msgstr ""2012.2.3"" msgid ""2012.2.4"" msgstr ""2012.2.4""msgid ""2013.2"" msgstr ""2013.2""msgid ""2013.2.1"" msgstr ""2013.2.1""msgid ""21"" msgstr ""21""msgid ""22"" msgstr ""22""msgid ""3"" msgstr ""3""msgid ""4"" msgstr ""4""msgid ""4 GB"" msgstr ""4 GB""msgid ""40 GB"" msgstr ""40 GB""msgid ""5"" msgstr ""5""msgid ""512 MB"" msgstr ""512 MB""msgid ""8"" msgstr ""8""msgid ""8 GB"" msgstr ""8 GB""msgid ""80 GB"" msgstr ""80 GB""msgid ""98"" msgstr ""98""msgid ""99"" msgstr ""99""msgid ""<code>/var/lib/cinder</code> should also be backed up."" msgstr ""<code>/var/lib/cinder</code>もまたバックアップされるべきです。""msgid ""<code>/var/lib/nova/instances</code> contains two types of directories.""""<code>/var/lib/nova/instances</code> には 2 種類のディレクトリがあります。""""<emphasis>High</emphasis> if the bug prevents a key feature from working "" ""properly for some users (or with a workaround)""""<emphasis>High</emphasis> このバグにより、目玉となる機能が何人かユーザで正常"" ""に動作しない場合 (または簡単なワークアラウンドで動作する場合)""""<emphasis>KVM</emphasis> as a <glossterm>hypervisor</glossterm> complements "" ""the choice of Ubuntu—being a matched pair in terms of support, and also "" ""because of the significant degree of attention it garners from the OpenStack "" ""development community (including the authors, who mostly use KVM). It is "" ""also feature complete, free from licensing charges and restrictions."" ""<indexterm class=\""singular\""><primary>kernel-based VM (KVM) hypervisor</"" ""primary></indexterm><indexterm class=\""singular\""><primary>hypervisors</"" ""primary><secondary>KVM</secondary></indexterm>""""<emphasis>KVM</emphasis> は <glossterm>ハイパーバイザー</glossterm> として "" ""Ubuntu の選択を補完します。これらはサポート面で対応する一対であり、OpenStack "" ""開発コミュニティ (主に KVM を使用する作成者) から集まる注目度が高いのも理由で"" ""す。また、機能が完全で、ライセンスの料金や制限がありません。<indexterm class="" ""\""singular\""><primary>kernel-based VM (KVM) ハイパーバイザー</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ハイパーバイザー</"" ""primary><secondary>KVM</secondary></indexterm>""""<emphasis>Live Migration</emphasis> is supported by way of shared storage, "" ""with <emphasis>NFS</emphasis> as the distributed file system.""""<emphasis>ライブマイグレーション</emphasis> は、共有ストレージを使用すること"" ""によってサポートされます。分散ファイルシステムには <emphasis>NFS</emphasis> "" ""を使用します。""msgid ""<emphasis>Low</emphasis> if the bug is mostly cosmetic"" msgstr ""<emphasis>Low</emphasis> このバグが多くの場合で軽微な場合""""<emphasis>Medium</emphasis> if the bug prevents a secondary feature from "" ""working properly""""<emphasis>Medium</emphasis> このバグにより、ある程度重要な機能が正常に動作し"" ""ない場合""""<emphasis>MySQL</emphasis> follows a similar trend. Despite its recent "" ""change of ownership, this database is the most tested for use with OpenStack "" ""and is heavily documented. We deviate from the default database, "" ""<emphasis>SQLite</emphasis>, because SQLite is not an appropriate database "" ""for production usage.""""<emphasis>MySQL</emphasis> も同様の傾向に沿っています。最近所有権が移転したに"" ""も関わらず、このデータベースは OpenStack での使用では最も検証されており、十分"" ""に文書化されています。<emphasis>SQLite</emphasis> は本番環境での使用には適し"" ""てないため、デフォルトのデータベースでは対象外とします。""""<glossterm baseform=\""Availability zone\"">Availability zones</glossterm> and "" ""host aggregates, which merely divide a single Compute deployment.""""<glossterm baseform=\""Availability zone\"">アベイラビリティゾーン</glossterm> "" ""およびホストアグリゲート。コンピュートのデプロイメントの分割のみを行います。""""<glossterm>Dashboard</glossterm>: You probably want to offer a dashboard, "" ""but your users may be more interested in API access only."" msgstr """" ""<glossterm>ダッシュボード</glossterm>: ダッシュボードの提供を考慮されているか"" ""もしれませんが、ユーザーは API アクセスのみの方に対する関心の方が高い可能性が"" ""あります。"" msgid """"""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""dev/14696\"">instances losing IP address while running, due to No DHCPOFFER</"" ""link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)""""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""dev/14696\"">DHCPOFFERが送信されない事による、起動中のインスタンスのIPアドレス"" ""の消失</link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)""""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""operators/18197\"">Problem with Heavy Network IO and Dnsmasq</link> (http://"" ""www.gossamer-threads.com/lists/openstack/operators/18197)"" msgstr """" ""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""operators/18197\"">高負荷ネットワークIOとdnsmasqの問題</link> (http://www."" ""gossamer-threads.com/lists/openstack/operators/18197)"" msgid """" ""<link href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> or <link href=\""http://openstack.redhat.com/"" ""Frequently_Asked_Questions\"">RDO</link>*"" msgstr """" ""<link href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> または <link href=\""http://openstack.redhat.com/"" ""Frequently_Asked_Questions\"">RDO</link>*"" msgid ""<literal>nova-manage</literal> service list"" msgstr ""<literal>nova-manage</literal> サービス一覧"" msgid """" ""<xref linkend=\""controller-hardware-sizing\""/> contains common "" ""considerations to review when sizing hardware for the cloud controller "" ""design.<indexterm class=\""singular\""><primary>cloud controllers</"" ""primary><secondary>hardware sizing considerations</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Active Directory</primary></"" ""indexterm><indexterm class=\""singular\""><primary>dashboard</primary></"" ""indexterm>"" msgstr """" ""<xref linkend=\""controller-hardware-sizing\""/> クラウドコントローラー設計の"" ""ハードウェアサイジングにおける一般的な考慮事項<indexterm class=\""singular"" ""\""><primary>クラウドコントローラー</primary><secondary>ハードウェアサイジング"" ""に関する考慮事項</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>Active Directory</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ダッシュボード</primary></indexterm>"" msgid """" ""<xref linkend=\""openstack_storage\""/> explains the different storage "" ""concepts provided by OpenStack.<indexterm class=\""singular\""><primary>block "" ""device</primary></indexterm><indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>overview of concepts</secondary></indexterm>"" msgstr """" ""<xref linkend=\""openstack_storage\""/> は、OpenStack で提供されているさまざま"" ""なストレージのコンセプトについて説明しています。<indexterm class=\""singular"" ""\""><primary>ブロックデバイス</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>oコンセプトの概要</secondary></"" ""indexterm>"" msgid """" ""<xref linkend=\""segragation_methods\""/> provides a comparison view of each "" ""segregation method currently provided by OpenStack Compute.<indexterm class="" ""\""singular\""><primary>endpoints</primary><secondary>API endpoint</""""<xref linkend=\""segragation_methods\""/> では、OpenStack Compute が現在提供し"" ""ている各分割メソッドの比較ビューを提供しています。<indexterm class=\""singular"" ""\""><primary>エンドポイント</primary><secondary>API エンドポイント</"" ""secondary></indexterm>""#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all.""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST""""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST""#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all.""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST""""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST""#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST""""A <glossterm>block device</glossterm> that can be partitioned, formatted, "" ""and mounted (such as, /dev/vdc)""""パーティション分割、フォーマット、マウントが可能な <glossterm>ブロックデバイ"" ""ス</glossterm> (/dev/vdc など)"" msgid """" ""A <glossterm>management network</glossterm> (a separate network for use by "" ""your cloud operators) typically consists of a separate switch and separate "" ""NICs (network interface cards), and is a recommended option. This "" ""segregation prevents system administration and the monitoring of system "" ""access from being disrupted by traffic generated by guests.<indexterm class="" ""\""singular\""><primary>NICs (network interface cards)</primary></"" ""indexterm><indexterm class=\""singular\""><primary>management network</"" ""primary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>management network</secondary></indexterm>"" msgstr """" "" <glossterm>管理用ネットワーク</glossterm> (クラウド管理者用の別のネットワー"" ""ク) は一般的には別のスイッチ別のNIC(Network Interface Cards)で構成する事が推"" ""奨されます。この構成ではゲストのトラフィックによって監視と管理のためのアクセ"" ""スが妨げられることを防ぎます。<indexterm class=\""singular\""><primary>NIC "" ""(network interface cards)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>管理ネットワーク</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ネットワークデザイン</primary><secondary>管理ネットワーク</"" ""secondary></indexterm>"" msgid """" ""A boolean to indicate whether the volume should be deleted when the instance "" ""is terminated. True can be specified as <literal>True</literal> or "" ""<literal>1</literal>. False can be specified as <literal>False</literal> or "" ""<literal>0</literal>."" msgstr """" ""インスタンスが終了したときに、ボリュームが削除されるかどうかを指示する論理値"" ""です。真は <literal>True</literal> または <literal>1</literal> として指定でき"" ""ます。偽は <literal>False</literal> または <literal>0</literal> として指定で"" ""きます。"" msgid """" ""A cloud controller's hardware can be the same as a compute node, though you "" ""may want to further specify based on the size and type of cloud that you run."" ""<indexterm class=\""singular\""><primary>hardware</primary><secondary>design "" ""considerations</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>design considerations</primary><secondary>hardware "" ""considerations</secondary></indexterm>"" msgstr """" ""クラウドの大きさやタイプによってハードウェアを指定したいかもしれませんが、ク"" ""ラウドコントローラーのハードウェアはコンピュートノードと同じ物を利用する事が"" ""できます。<indexterm class=\""singular\""><primary>ハードウェア</"" ""primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class="" ""\""singular\""><primary>設計上の考慮事項</primary><secondary>ハードウェアの考慮"" ""点</secondary></indexterm>"" msgid """" ""A cloud with multiple sites where you can schedule VMs \""anywhere\"" or on a "" ""particular site."" msgstr """" ""複数サイトで構成されるクラウドで、仮想マシンを「任意のサイト」または特定のサ"" ""イトにスケジューリングしたい場合"" msgid """" ""A cloud with multiple sites, where you schedule VMs to a particular site and "" ""you want a shared infrastructure."" msgstr """" ""複数サイトで構成されるクラウドで、仮想マシンを特定のサイトに対してスケジュー"" ""リングでき、かつ共有インフラを利用したい場合"" msgid """" ""A common use of host aggregates is to provide information for use with the "" ""<literal>nova-scheduler</literal>. For example, you might use a host "" ""aggregate to group a set of hosts that share specific flavors or images."" msgstr """" ""ホストアグリゲートの一般的な用途は <literal>nova-scheduler</literal> で使用す"" ""る情報を提供することです。例えば、ホストアグリゲートを使って、特定のフレー"" ""バーやイメージを共有するホストの集合を作成することができます。"" msgid """" ""A critical part of a cloud's scalability is the amount of effort that it "" ""takes to run your cloud. To minimize the operational cost of running your "" ""cloud, set up and use an automated deployment and configuration "" ""infrastructure with a configuration management system, such as Puppet or "" ""Chef. Combined, these systems greatly reduce manual effort and the chance "" ""for operator error.<indexterm class=\""singular\""><primary>cloud computing</"" ""primary><secondary>minimizing costs of</secondary></indexterm>"" msgstr """" ""クラウドのスケーラビリティにおける重要な部分の一つは、クラウドを運用するのに"" ""必要な労力にあります。クラウドの運用コストを最小化するために、Puppet や Chef "" ""などの設定管理システムを使用して、自動化されたデプロイメントおよび設定インフ"" ""ラストラクチャーを設定、使用してください。これらのシステムを統合すると、工数"" ""やオペレーターのミスを大幅に減らすことができます。<indexterm class=\""singular"" ""\""><primary>クラウドコンピューティング</primary><secondary>コストの最小化</"" ""secondary></indexterm>"" msgid ""A different API endpoint for every region."" msgstr ""リージョン毎に別々のAPIエンドポイントが必要"" msgid """" ""A distributed, shared file system. As of Gluster version 3.3, you can use "" ""Gluster to consolidate your object storage and file storage into one unified "" ""file and object storage solution, which is called Gluster For OpenStack "" ""(GFO). GFO uses a customized version of swift that enables Gluster to be "" ""used as the backend storage."" msgstr """" ""分散型の共有ファイルシステム。Gluster バージョン 3.3 以降、Gluster を使用し"" ""て、オブジェクトストレージとファイルストレージを1 つの統合ファイルとオブジェ"" ""クトストレージソリューションにまとめることができるようになりました。これは"" ""Gluster For OpenStack (GFO) と呼ばれます。GFO は、swift のカスタマイズバー"" ""ジョンを使用しており、Gluster がバックエンドストレージを使用できるようになっ"" ""ています。"" msgid ""A few nights later, it happened again."" msgstr ""数日後、それは再び起こった。"" msgid ""A file system"" msgstr ""ファイルシステム"" msgid """" ""A good document describing the Object Storage architecture is found within "" ""<link href=\""http://docs.openstack.org/developer/swift/overview_architecture."" ""html\"" title=\""OpenStack wiki\"">the developer documentation</link>—read this "" ""first. Once you understand the architecture, you should know what a proxy "" ""server does and how zones work. However, some important points are often "" ""missed at first glance."" msgstr """" ""オブジェクトストレージのアーキテクチャーについて詳しく説明したドキュメントは "" ""<link href=\""http://docs.openstack.org/developer/swift/overview_architecture."" ""html\"" title=\""OpenStack wiki\"">the developer documentation</link>にありま"" ""す。これをまず参照してください。アーキテクチャーを理解したら、プロキシサー"" ""バーの役割やゾーンの機能について理解できるはずです。しかし、少し見ただけで"" ""は、頻繁に重要なポイントを逃してしまうことがあります。""msgid ""A new service, nova-cells."" msgstr ""新規サービス、nova-cells""""A note about DAIR's architecture: <filename>/var/lib/nova/instances</"" ""filename> is a shared NFS mount. This means that all compute nodes have "" ""access to it, which includes the <code>_base</code> directory. Another "" ""centralized area is <filename>/var/log/rsyslog</filename> on the cloud "" ""controller. This directory collects all OpenStack logs from all compute "" ""nodes. I wondered if there were any entries for the file that <placeholder-1/"" ""> is reporting: <placeholder-2/>""""DAIR のアーキテクチャは <filename>/var/lib/nova/instances</filename> が共有 "" ""NFS マウントであることに注意したい。これは、全てのコンピュートノードがその"" ""ディレクトリにアクセスし、その中に <code>_base</code> ディレクトリが含まれる"" ""ことを意味していた。その他の集約化エリアはクラウドコントローラーの "" ""<filename>/var/log/rsyslog</filename> だ。このディレクトリは全コンピュート"" ""ノードの全ての OpenStack ログが収集されていた。私は、<placeholder-1/> が報告"" ""したファイルに関するエントリがあるのだろうかと思った。 <placeholder-2/>"" msgid """" ""A range of publicly routable, IPv4 network addresses to be used by OpenStack "" ""Networking for floating IPs. You may be restricted in your access to IPv4 "" ""addresses; a large range of IPv4 addresses is not necessary."" msgstr """" ""OpenStack Networking が Floating IP に使用する、パブリックにルーティング可能"" ""な IPv4 ネットワークアドレスの範囲。IPv4 アドレスへのアクセスは制限される可能"" ""性があります。IPv4 アドレスの範囲を大きくする必要はありません。"" msgid """" ""A scalable storage solution that replicates data across commodity storage "" ""nodes. Ceph was originally developed by one of the founders of DreamHost and "" ""is currently used in production there."" msgstr """" ""商用ストレージノード全体でデータを複製する拡張性の高いストレージソリューショ"" ""ン。Ceph は、DreamHost の創設者により開発され、現在は実稼動環境で使用されてい"" ""ます。"" msgid """" ""A similar approach can be taken with public IP addresses, taking note that "" ""large, flat ranges are preferred for use with guest instance IPs. Take into "" ""account that for some OpenStack networking options, a public IP address in "" ""the range of a guest instance public IP address is assigned to the "" ""<literal>nova-compute</literal> host."" msgstr """" ""パブリックIPアドレスの場合でも同様のアプローチが取れます。但し、ゲストインス"" ""タンス用のIPとして使用する場合には、大きなフラットなアドレスレンジの方が好ま"" ""れることに注意した方がよいでしょう。また、OpenStack のネットワーク方式によっ"" ""ては、ゲストインスタンス用のパブリックIPアドレスレンジのうち一つが "" ""<literal>nova-compute </literal>ホストに割り当てられることも考慮する必要があ"" ""ります。"" msgid """" ""A single <glossterm>API endpoint</glossterm> for compute, or you require a "" ""second level of scheduling."" msgstr """" ""コンピュート資源に対する単一の <glossterm>API エンドポイント</glossterm>、も"" ""しくは２段階スケジューリングが必要な場合"" msgid ""A single-site cloud with equipment fed by separate power supplies."" msgstr ""分離された電源供給ラインを持つ設備で構成される、単一サイトのクラウド。"" msgid """" ""A snapshot captures the state of the file system, but not the state of the "" ""memory. Therefore, to ensure your snapshot contains the data that you want, "" ""before your snapshot you need to ensure that:"" msgstr """" ""スナップショットは、ファイルシステムの状態をキャプチャーしますが、メモリーの"" ""状態をキャプチャーしません。そのため、スナップショットに期待するデータが含ま"" ""れることを確実にするために、次のことを確実にする必要があります。"" msgid ""A user recently tried launching a CentOS instance on that node"" msgstr """" ""最近、あるユーザがそのノード上で CentOS のインスタンスを起動しようとした。"" msgid ""API endpoints"" msgstr ""APIエンドポイント"" msgid ""Accessed through…"" msgstr ""アクセス方法"" msgid ""Accessible from…"" msgstr ""アクセス可能な場所"" msgid ""Acknowledgments"" msgstr ""謝辞"" msgid ""Actions which delete things should not be enabled by default."" msgstr ""何かを削除する操作はデフォルトで有効化されるべきではない。"" msgid ""Adam Hyde"" msgstr ""Adam Hyde"" msgid """" ""Adam Powell in Racker IT supplied us with bandwidth each day and second "" ""monitors for those of us needing more screens."" msgstr """" ""Rackspace IT部門 の Adam Powell は、私たちに毎日のネットワーク帯域を提供して"" ""くれました。また、より多くのスクリーンが必要となったため、セカンドモニタを提"" ""供してくれました。"" msgid """" ""Add additional OpenStack Block Storage hosts (see <xref linkend=\""maintenance"" ""\""/>)."" msgstr """" ""追加で OpenStack Block Storage ホストを増やす (see <xref linkend="" ""\""maintenance\""/> 参照)。"" msgid ""Add additional cloud controllers (see <xref linkend=\""maintenance\""/>)."" msgstr """" ""追加でクラウドコントローラーを増やす (<xref linkend=\""maintenance\""/> を参"" ""照)。"" msgid ""Add additional persistent storage to a virtual machine (VM)"" msgstr ""永続的なストレージを仮想マシン（VM）へ追加する"" msgid """" ""Add all raw disks to one large RAID array, either hardware or software "" ""based. You can partition this large array with the boot, root, swap, and LVM "" ""areas. This option is simple to implement and uses all partitions. However, "" ""disk I/O might suffer."" msgstr """" ""すべてのローディスクを 1 つの大きな RAID 配列に追加します。ここでは、ソフト"" ""ウェアベースでもハードウェアベースでも構いません。この大きなRAID 配列を "" ""boot、root、swap、LVM 領域に分割します。この選択肢はシンプルですべてのパー"" ""ティションを利用することができますが、I/O性能に悪影響がでる可能性があります。"" msgid """" ""Add an OpenStack Storage service (see the Object Storage chapter in the "" ""<emphasis>OpenStack Installation Guide</emphasis> for your distribution)."" msgstr """" ""OpenStack Storage Service を追加する (お使いのディストリビューション向けの "" ""<emphasis>OpenStack インストールガイド</emphasis> で Object Storage の章を参"" ""照してください)"" msgid ""Adding Cloud Controller Nodes"" msgstr ""クラウドコントローラーノードの追加"" msgid ""Adding Custom Logging Statements"" msgstr ""カスタムログの追加"" msgid ""Adding Images"" msgstr ""イメージの追加"" msgid ""Adding Projects"" msgstr ""プロジェクトの追加"" msgid ""Adding a Compute Node"" msgstr ""コンピュートノードの追加"" msgid ""Adding an Object Storage Node"" msgstr ""オブジェクトストレージノードの追加"" msgid """" ""Adding more public-facing control services or guest instance IPs should "" ""always be part of your plan."" msgstr """" ""パブリック側に置かれるコントローラーサービスやゲストインスタンスのIPの追加"" ""は、必ずアドレス計画の一部として入れておくべきです。"" msgid """" ""Adding to a RAID array (RAID stands for redundant array of independent "" ""disks), based on the number of disks you have available, so that you can add "" ""capacity as your cloud grows. Some options are described in more detail "" ""below."" msgstr """" ""使用可能なディスクの数をもとに、RAID 配列 (RAID は Redundant Array of "" ""Independent Disks の略) に追加します。 こうすることで、クラウドが大きくなった"" ""場合も容量を追加できます。オプションは、以下で詳しく説明しています。"" msgid """" ""Additionally, this instance in question was responsible for a very, very "" ""large backup job each night. While \""The Issue\"" (as we were now calling it) "" ""didn't happen exactly when the backup happened, it was close enough (a few "" ""hours) that we couldn't ignore it."" msgstr """" ""加えて、問題のインスタンスは毎晩非常に長いバックアップジョブを担っていた。"" ""「あの問題」（今では我々はこの障害をこう呼んでいる）はバックアップが行われて"" ""いる最中には起こらなかったが、（数時間たっていて）「あの問題」が起こるまであ"" ""と少しのところだった。"" msgid ""Administrative Command-Line Tools"" msgstr ""管理系コマンドラインツール"" msgid """" ""Administrator configuration of size settings, known as <emphasis>flavors</"" ""emphasis>"" msgstr ""<emphasis>フレーバー</emphasis> として知られる管理者のサイズ設定"" msgid ""Advanced Configuration"" msgstr ""高度な設定"" msgid ""After a Cloud Controller or Storage Proxy Reboots"" msgstr ""クラウドコントローラーまたはストレージプロキシの再起動後"" msgid ""After a Compute Node Reboots"" msgstr ""コンピュートノードの再起動後"" msgid ""After a few minutes of troubleshooting, I saw the following details:"" msgstr ""数分間のトラブル調査の後、以下の詳細が判明した。"" msgid """" ""After finding the instance ID we headed over to <filename>/var/lib/nova/"" ""instances</filename> to find the <filename>console.log</filename>: "" ""<placeholder-1/>"" msgstr """" ""インスタンスIDの発見後、<filename>console.log</filename> を探すため "" ""<filename>/var/lib/nova/instances</filename> にアクセスした。<placeholder-1/>"" msgid """" ""After reproducing the problem several times, I came to the unfortunate "" ""conclusion that this cloud did indeed have a problem. Even worse, my time "" ""was up in Kelowna and I had to return back to Calgary."" msgstr """" ""何度か問題が再現した後、私はこのクラウドが実は問題を抱えているという不幸な結"" ""論に至った。更に悪いことに、私がケロウナから出発する時間になっており、カルガ"" ""リーに戻らなければならなかった。"" msgid """" ""After restarting the instance, everything was back up and running. We "" ""reviewed the logs and saw that at some point, network communication stopped "" ""and then everything went idle. We chalked this up to a random occurrence."" msgstr """" ""インスタンスの再起動後、全ては元通りに動くようになった。我々はログを見直し、"" ""問題の箇所（ネットワーク通信が止まり、全ては待機状態になった）を見た。我々は"" ""ランダムな事象の原因はこのインスタンスだと判断した。"" msgid """" ""After the change is reviewed, accepted, and lands in master, it "" ""automatically moves to:"" msgstr """" ""変更がレビューされ、受理されて、マスターブランチにマージされると、バグの状態"" ""は自動的に以下のようになります。"" msgid """" ""After the packet is on this NIC, it transfers to the compute node's default "" ""gateway. The packet is now most likely out of your control at this point. "" ""The diagram depicts an external gateway. However, in the default "" ""configuration with multi-host, the compute host is the gateway."" msgstr """" ""パケットはこのNICに送られた後、コンピュートノードのデフォルトゲートウェイに転"" ""送されます。パケットはこの時点で、おそらくあなたの管理範囲外でしょう。図には"" ""外部ゲートウェイを描いていますが、マルチホストのデフォルト構成では、コン"" ""ピュートホストがゲートウェイです。"" msgid """" ""After you consider these factors, you can determine how many cloud "" ""controller cores you require. A typical eight core, 8 GB of RAM server is "" ""sufficient for up to a rack of compute nodes — given the above caveats."" msgstr """" ""これらの要素を検討した後、クラウドコントローラにどのくらいのコア数が必要なの"" ""か決定することができます。上記で説明した留意事項の下、典型的には、ラック 1 本"" ""分のコンピュートノードに対して8 コア、メモリ 8GB のサーバで充分です。"" msgid """" ""After you establish that the instance booted properly, the task is to figure "" ""out where the failure is."" msgstr """" ""インスタンスが正しく起動した後、この手順でどこが問題かを切り分けることができ"" ""ます。"" msgid """" ""After you have the list, you can use the nova command to start each instance:"" msgstr """" ""一覧を取得した後、各インスタンスを起動するために nova コマンドを使用できま"" ""す。"" msgid """" ""Again, it turns out that the image was a snapshot. The three other instances "" ""that successfully started were standard cloud images. Was it a problem with "" ""snapshots? That didn't make sense."" msgstr """" ""再度、イメージがスナップショットであることが判明した。無事に起動した他の３イ"" ""ンスタンスは標準のクラウドイメージであった。これはスナップショットの問題か？"" ""それは意味が無かった。"" msgid """" ""Again, the right answer depends on your environment. You have to make your "" ""decision based on the trade-offs between space utilization, simplicity, and "" ""I/O performance."" msgstr """" ""ここでも、環境によって適したソリューションが変わります。スペース使用状況、シ"" ""ンプルさ、I/O パフォーマンスの長所、短所をベースに意思決定していく必要があり"" ""ます。"" msgid ""Ah-hah! So OpenStack was deleting it. But why?"" msgstr ""あっはっは！じゃぁ、OpenStack が削除したのか。でも何故？"" msgid """" ""All AMQP—Advanced Message Queue Protocol—messages for services are received "" ""and sent according to the queue broker<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgstr """" ""サービスのためのすべてのAMQP（Advavnced Message Queue Protocol）メッセージは"" ""キューブローカーによって送受信されます。<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgid ""All nova services"" msgstr ""すべての Nova サービス"" msgid """" ""All public access, whether direct, through a command-line client, or through "" ""the web-based dashboard, uses the API service. Find the API reference at "" ""<link href=\""http://api.openstack.org/\""/>.<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</"" ""primary><secondary>design considerations</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>design considerations</primary><secondary>API "" ""support</secondary></indexterm>"" msgstr """" ""すべてのパブリックアクセス（直接アクセス、コマンドライン、ウェブベースダッ"" ""シュボード）はすべてAPIサービスを使用します。APIリファレンスは<link href="" ""\""http://api.openstack.org/\""/>です。<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</primary><secondary>設計"" ""上の考慮事項</secondary></indexterm><indexterm class=\""singular\""><primary>設"" ""計上の考慮事項</primary><secondary>API サポート</secondary></indexterm>"" msgid """" ""All servers running OpenStack components should be able to access an "" ""appropriate NTP server. You may decide to set up one locally or use the "" ""public pools available from the <link href=\""http://www.pool.ntp.org/en/\""> "" ""Network Time Protocol project</link>."" msgstr """" ""OpenStack コンポーネントが稼働しているすべてのサーバは適切なNTPサーバにアクセ"" ""ス可能であるべきです。<link href=\""http://www.pool.ntp.org/en/\""> Network "" ""Time Protocol project</link>が提供しているパブリックサーバかローカルにNTPサー"" ""バを構築するか決定する必要があるでしょう。"" msgid ""Allows you to fetch images from Amazon S3."" msgstr ""Amazon S3からイメージを取得する事を許可します。"" msgid """" ""Allows you to fetch images from a web server. You cannot write images by "" ""using this mode."" msgstr """" ""イメージをウェブサーバから取得する事を許可します。このモードではイメージの書"" ""き込みはできません。"" msgid ""Allows you to store images as objects."" msgstr ""イメージをオブジェクトとして格納する事を許可します"" msgid ""Also check that it is functioning:"" msgstr ""また、正しく機能していることを確認します。"" msgid ""Also ensure that it has successfully connected to the AMQP server:"" msgstr ""AMQP サーバーに正常に接続できることも確認します。"" msgid """" ""Also, you need to decide whether you want to support object storage in your "" ""cloud. The two common use cases for providing object storage in a compute "" ""cloud are:"" msgstr """" ""クラウド内でオブジェクトストレージの利用を検討する必要があります。コンピュー"" ""トクラウドで提供されるオブジェクトストレージの一般的な利用方法は以下の二つで"" ""す。"" msgid """" ""Although the title of this story is much more dramatic than the actual "" ""event, I don't think, or hope, that I'll have the opportunity to use "" ""\""Valentine's Day Massacre\"" again in a title."" msgstr """" ""この物語のタイトルは実際の事件よりかなりドラマティックだが、私はタイトル中に"" ""「バレンタインデーの大虐殺」を使用する機会が再びあるとは思わない（し望まな"" ""い）。"" msgid """" ""Although this method is not documented or supported, you can use it when "" ""your compute node is permanently offline but you have instances locally "" ""stored on it."" msgstr """" ""この方法はドキュメントに書かれておらず、サポートされていない方法ですが、コン"" ""ピュートノードが完全にオフラインになってしまったが、インスタンスがローカルに"" ""保存されているときに、この方法を使用できます。"" msgid """" ""Among <glossterm>object</glossterm>, <glossterm>container</glossterm>, and "" ""<glossterm>account server</glossterm>s"" msgstr """" ""<glossterm>object server</glossterm> 、 <glossterm>container server</"" ""glossterm> 、 <glossterm>account server</glossterm> 間"" msgid ""Amount of available physical storage"" msgstr ""利用可能な物理ディスクの総量で決まる"" msgid """" ""An IP address plan might be broken down into the following sections:"" ""<indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>sections of</secondary></indexterm>"" msgstr """" ""IPアドレス計画としては次のような用途で分類されるでしょう：<indexterm class="" ""\""singular\""><primary>IPアドレス</primary><secondary>分類</secondary></""msgid """" ""An OpenStack cloud does not have much value without users. This chapter "" ""covers topics that relate to managing users, projects, and quotas. This "" ""chapter describes users and projects as described by version 2 of the "" ""OpenStack Identity API."" msgstr """" ""OpenStack クラウドは、ユーザーなしでは特に価値はありません。本章では、ユー"" ""ザー、プロジェクト、クォータの管理に関するトピックを記載します。また、"" ""OpenStack Identity API のバージョン 2 で説明されているように、ユーザーとプロ"" ""ジェクトについても説明します。"" msgid """" ""An OpenStack installation can potentially have many subnets (ranges of IP "" ""addresses) and different types of services in each. An IP address plan can "" ""assist with a shared understanding of network partition purposes and "" ""scalability. Control services can have public and private IP addresses, and "" ""as noted above, there are a couple of options for an instance's public "" ""addresses.<indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>address planning</secondary></indexterm><indexterm class="" ""\""singular\""><primary>network design</primary><secondary>IP address "" ""planning</secondary></indexterm>"" msgstr """" ""OpenStackのインストールでは潜在的に多くのサブネット(IPアドレスの範囲) とそれ"" ""ぞれに異なるタイプのサービスを持つ可能性があります。あるIPアドレスプランは、"" ""ネットワーク分割の目的とスケーラビリティの共有された理解を手助けします。コン"" ""トロールサービスはパブリックとプライベートIPアドレスを持つ事ができ、上記の通"" ""り、インスタンスのパブリックアドレスとして2種類のオプションが存在します。"" ""<indexterm class=\""singular\""><primary>IPアドレス</primary><secondary>アドレ"" ""ス計画</secondary></indexterm><indexterm class=\""singular\""><primary>ネット"" ""ワーク設計</primary><secondary>IPアドレス計画</secondary></indexterm>"" msgid """" ""An advanced use of this general concept allows different flavor types to run "" ""with different CPU and RAM allocation ratios so that high-intensity "" ""computing loads and low-intensity development and testing systems can share "" ""the same cloud without either starving the high-use systems or wasting "" ""resources on low-utilization systems. This works by setting "" ""<parameter>metadata</parameter> in your host aggregates and matching "" ""<parameter>extra_specs</parameter> in your flavor types."" msgstr """" ""この一般的なコンセプトを高度なレベルで使用すると、集中度の高いコンピュート"" ""ロードや負荷の低い開発やテストシステムが使用量の多いシステムのリソースが不足"" ""したり、使用量の低いシステムでリソースを無駄にしたりしないで、同じクラウドを"" ""共有できるように、異なるフレーバーの種別が、異なる CPU および RAM 割当の比率"" ""で実行できるようになります。 これは、ホストアグリゲートに "" ""<parameter>metadata</parameter> を設定して、フレーバー種別の"" ""<parameter>extra_specs</parameter> と一致させると機能します。"" msgid """" ""An asterisk (*) indicates when the example architecture deviates from the "" ""settings of a default installation. We'll offer explanations for those "" ""deviations next.<indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>object storage</secondary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>object storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>migration</"" ""primary></indexterm><indexterm class=\""singular\""><primary>live migration</"" ""primary></indexterm><indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>floating</secondary></indexterm><indexterm class="" ""\""singular\""><primary>floating IP address</primary></indexterm><indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>block storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>block storage</"" ""primary></indexterm><indexterm class=\""singular\""><primary>dashboard</"" ""primary></indexterm><indexterm class=\""singular\""><primary>legacy networking "" ""(nova)</primary><secondary>features supported by</secondary></indexterm>"" msgstr """" ""アスタリスク (*) は、アーキテクチャの例がデフォルトインストールの設定から逸脱"" ""している箇所を示しています。この逸脱については、次のセクションで説明します。"" ""<indexterm class=\""singular\""><primary>オブジェクト</"" ""primary><secondary>Object Storage</secondary></indexterm><indexterm class="" ""\""singular\""><primary>ストレージ</primary><secondary>Object Storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>マイグレーション"" ""</primary></indexterm><indexterm class=\""singular\""><primary>ライブマイグレー"" ""ション</primary></indexterm><indexterm class=\""singular\""><primary>IP アドレ"" ""ス</primary><secondary>floating</secondary></indexterm><indexterm class="" ""\""singular\""><primary>floating IP address</primary></indexterm><indexterm "" ""class=\""singular\""><primary>ストレージ</primary><secondary>ブロックストレージ"" ""</secondary></indexterm><indexterm class=\""singular\""><primary>ブロックスト"" ""レージ</primary></indexterm><indexterm class=\""singular\""><primary>ダッシュ"" ""ボード</primary></indexterm><indexterm class=\""singular\""><primary>レガシー"" ""ネットワーク (nova)</primary><secondary>サポート対象機能</secondary></"" ""indexterm>"" msgid """" ""An automated deployment system installs and configures operating systems on "" ""new servers, without intervention, after the absolute minimum amount of "" ""manual work, including physical racking, MAC-to-IP assignment, and power "" ""configuration. Typically, solutions rely on wrappers around PXE boot and "" ""TFTP servers for the basic operating system install and then hand off to an "" ""automated configuration management system.<indexterm class=\""singular"" ""\""><primary>deployment</primary><see>provisioning/deployment</see></"" ""indexterm><indexterm class=\""singular\""><primary>provisioning/deployment</"" ""primary><secondary>automated deployment</secondary></indexterm>"" msgstr """" ""自動のデプロイメントシステムは、物理ラッキング、MAC から IP アドレスの割当、"" ""電源設定など、必要最小限の手作業のみで、介入なしに新規サーバー上にオペレー"" ""ティングシステムのインストールと設定を行います。ソリューションは通常、PXE "" ""ブートや TFTP サーバー関連のラッパーに依存して基本のオペレーティングシステム"" ""をインストールして、次に自動設定管理システムに委譲されます。<indexterm class="" ""\""singular\""><primary>デプロイメント</primary><see>プロビジョニング/デプロイ"" ""メント</see></indexterm><indexterm class=\""singular\""><primary>プロビジョニン"" ""グ/デプロイメント</primary><secondary>自動デプロイメント</secondary></"" ""indexterm>"" msgid """" ""An hour later I received the same alert, but for another compute node. Crap. "" ""OK, now there's definitely a problem going on. Just like the original node, "" ""I was able to log in by SSH. The bond0 NIC was DOWN but the 1gb NIC was "" ""active."" msgstr """" ""１時間後、私は同じ警告を受信したが、別のコンピュートノードだった。拍手。OK、"" ""問題は間違いなく現在進行中だ。元のノードと全く同様に、私は SSH でログインする"" ""ことが出来た。bond0 NIC は DOWN だったが、1Gb NIC は有効だった。"" msgid """" ""An initial idea was to just increase the lease time. If the instance only "" ""renewed once every week, the chances of this problem happening would be "" ""tremendously smaller than every minute. This didn't solve the problem, "" ""though. It was just covering the problem up."" msgstr """" ""最初のアイデアは、単にリース時間を増やすことだった。もしインスタンスが毎週１"" ""回だけIPアドレスを更新するのであれば、毎分更新する場合よりこの問題が起こる可"" ""能性は極端に低くなるだろう。これはこの問題を解決しないが、問題を単に取り繕う"" ""ことはできる。"" msgid """" ""An integral part of a configuration-management system is the items that it "" ""controls. You should carefully consider all of the items that you want, or "" ""do not want, to be automatically managed. For example, you may not want to "" ""automatically format hard drives with user data."" msgstr """" ""設定管理システムの不可欠な部分は、このシステムが制御する項目です。自動管理を"" ""する項目、しない項目をすべて慎重に検討していく必要があります。例えば、ユー"" ""ザーデータが含まれるハードドライブは自動フォーマットは必要ありません。"" msgid """" ""And the best part: the same user had just tried creating a CentOS instance. "" ""What?"" msgstr """" ""そして、最も重要なこと。同じユーザが CentOS インスタンスを作成しようとしたば"" ""かりだった。何だと？"" msgid ""Another example is displaying all properties for a certain image:"" msgstr """" ""もう一つの例は、特定のイメージに関するすべてのプロパティを表示することです。"" msgid """" ""Another fact that's often forgotten is that when a new file is being "" ""uploaded, the proxy server must write out as many streams as there are "" ""replicas—giving a multiple of network traffic. For a three-replica cluster, "" ""10 Gbps in means 30 Gbps out. Combining this with the previous high "" ""bandwidth<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>private vs. public network recommendations</secondary></"" ""indexterm> demands of replication is what results in the recommendation that "" ""your private network be of significantly higher bandwidth than your public "" ""need be. Oh, and OpenStack Object Storage communicates internally with "" ""unencrypted, unauthenticated rsync for performance—you do want the private "" ""network to be private."" msgstr """" ""また、新規ファイルがアップロードされると、プロキシサーバーはレプリカの数だけ"" ""書き込みが行われ、複数のネットワークトラフィックが発生するという点も頻繁に忘"" ""れられています。 レプリカが３つのクラスターでは、受信トラフィックが 10 Gbps "" ""とすると、送信トラフィックは 30 Gbps ということになります。これを以前のレプリ"" ""カの帯域幅の需要が<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>プライベート vs. パブリックネットワークの推奨事項</"" ""secondary></indexterm> 高いことと合わせて考えると、パブリックネットワークよ"" ""りもプライベートネットワークのほうがはるかに高い帯域幅が必要であることが分か"" ""ります。OpenStack Object Storage はパフォーマンスを保つために内部では、暗号化"" ""なし、認証なしの rsync と通信します (プライベートネットワークをプライベートに"" ""保つため)。"" msgid ""Anywhere"" msgstr ""どこからでも"" msgid """" ""Apache Qpid offers 100 percent compatibility with the Advanced Message "" ""Queuing Protocol Standard, and its broker is available for both C++ and Java."" msgstr """" ""Apache Qpid は、Advanced Message Queuing Protocol の標準との 100% の互換性を"" ""提供し、ブローカーは C++ と Java の両方で利用可能です。"" msgid ""Application Programming Interface (API)"" msgstr ""Application Programming Interface (API)"" msgid ""Apr 11, 2013"" msgstr ""2013年4月11日"" msgid ""Apr 15, 2011"" msgstr ""2011年4月15日"" msgid ""Apr 4, 2013"" msgstr ""2013年4月4日"" msgid ""Apr 5, 2012"" msgstr ""2012年4月5日"" msgid ""Architecture"" msgstr ""アーキテクチャ"" msgid """" ""Armed with a patched qemu and a way to reproduce, we set out to see if we've "" ""finally solved The Issue. After 48 hours straight of hammering the instance "" ""with bandwidth, we were confident. The rest is history. You can search the "" ""bug report for \""joe\"" to find my comments and actual tests."" msgstr """" ""パッチを当てた qemu と再現方法を携えて、我々は「あの問題」を最終的に解決した"" ""かを確認する作業に着手した。インスタンスにネットワーク負荷をかけてから丸48時"" ""間後、我々は確信していた。その後のことは知っての通りだ。あなたは、joe へのバ"" ""グ報告を検索し、私のコメントと実際のテストを見つけることができる。"" msgid """" ""As a last resort, our network admin (Alvaro) and myself sat down with four "" ""terminal windows, a pencil, and a piece of paper. In one window, we ran "" ""ping. In the second window, we ran <placeholder-1/> on the cloud controller. "" ""In the third, <placeholder-2/> on the compute node. And the forth had "" ""<placeholder-3/> on the instance. For background, this cloud was a multi-"" ""node, non-multi-host setup."" msgstr """" ""結局、我々のネットワーク管理者（Alvao）と私自身は４つのターミナルウィンドウ、"" ""１本の鉛筆と紙切れを持って座った。１つのウインドウで我々は ping を実行した。"" ""２つ目のウインドウではクラウドコントローラー上の <placeholder-1/>、３つ目では"" ""コンピュートノード上の <placeholder-2/>、４つ目ではインスタンス上の "" ""<placeholder-3/> を実行した。前提として、このクラウドはマルチノード、非マルチ"" ""ホスト構成である。"" msgid ""As a scalable, reliable data store for virtual machine images"" msgstr ""スケーラブルで信頼性のある仮想マシンイメージデータストアとして利用する"" msgid """" ""As a specific example, compare a cloud that supports a managed web-hosting "" ""platform with one running integration tests for a development project that "" ""creates one VM per code commit. In the former, the heavy work of creating a "" ""VM happens only every few months, whereas the latter puts constant heavy "" ""load on the cloud controller. You must consider your average VM lifetime, as "" ""a larger number generally means less load on the cloud controller.<indexterm "" ""class=\""singular\""><primary>cloud controllers</"" ""primary><secondary>scalability and</secondary></indexterm>"" msgstr """" ""特定の例としては、マネージド Web ホスティングプラットフォームをサポートするク"" ""ラウドと、コードコミットごとに仮想マシンを１つ作成するような開発プロジェクト"" ""の統合テストを実行するクラウドを比較してみましょう。前者では、VMを作成する負"" ""荷の大きい処理は数か月に 一度しか発生しないのに対して、後者ではクラウドコント"" ""ローラに常に負荷の大きい処理が発生します。一般論として、VMの平均寿命が長いと"" ""いうことは、クラウドコントローラの負荷が軽いことを意味するため、平均的なVMの"" ""寿命を検討する必要があります。<indexterm class=\""singular\""><primary>クラウド"" ""コントローラー</primary><secondary>スケーラビリティ</secondary></indexterm>"" msgid """" ""As always, refer to the <xref linkend=\""openstack_glossary\""/> if you are "" ""unclear about any of the terminology mentioned in these architectures."" msgstr """" ""これらのアーキテクチャで言及されている用語が明確に理解できない場合には、通常"" ""通り <xref linkend=\""openstack_glossary\""/> を参照してください。"" msgid """" ""As an administrator, you have a few ways to discover what your OpenStack "" ""cloud looks like simply by using the OpenStack tools available. This section "" ""gives you an idea of how to get an overview of your cloud, its shape, size, "" ""and current state.<indexterm class=\""singular\""><primary>services</"" ""primary><secondary>obtaining overview of</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>servers</primary><secondary>obtaining overview "" ""of</secondary></indexterm><indexterm class=\""singular\""><primary>cloud "" ""computing</primary><secondary>cloud overview</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>servers and services</secondary></indexterm>"" msgstr """" ""管理者は、利用可能な OpenStack ツールを使用して、OpenStack クラウドが全体像を"" ""確認する方法がいくつかあります。本項では、クラウドの概要、形態、サイズ、現在"" ""の状態についての情報を取得する方法について説明します。<indexterm class="" ""\""singular\""><primary>サービス</primary><secondary>概観の取得</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>サーバー</primary><secondary"" ""概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>クラ"" ""ウドコンピューティング</primary><secondary>クラウドの全体像</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</"" ""primary><secondary>サーバーとサービス</secondary></indexterm>"" msgid """" ""As another example, if you choose to use single-host networking where the "" ""cloud controller is the network gateway for all instances, then the cloud "" ""controller must support the total amount of traffic that travels between "" ""your cloud and the public Internet."" msgstr """" ""他の例としては、クラウドコントローラーがすべてのインスタンスのゲートウェイと"" ""なるような単一ホスト・ネットワークモデルを使うことにした場合、クラウドコント"" ""ローラーは外部インターネットとあなたのクラウドの間でやりとりされるすべてのト"" ""ラフィックを支えられなければなりません。"" msgid """" ""As another example, you could use pairs of servers for a collective cloud "" ""controller—one active, one standby—for redundant nodes providing a given set "" ""of related services, such as:"" msgstr """" ""他の例として、コントローラーをクラスタとして構成し1つはアクティブ、もう一つは"" ""スタンバイとして冗長ノードが以下のような機能を提供できるように複数のサーバを"" ""使用する事ができます。"" msgid """" ""As discussed in previous chapters, there are several options for networking "" ""in OpenStack Compute. We recommend <emphasis>FlatDHCP</emphasis> and to use "" ""<emphasis>Multi-Host</emphasis> networking mode for high availability, "" ""running one <code>nova-network</code> daemon per OpenStack compute host. "" ""This provides a robust mechanism for ensuring network interruptions are "" ""isolated to individual compute hosts, and allows for the direct use of "" ""hardware network gateways."" msgstr """" ""前章で述べたように、OpenStack Compute のネットワークにはいくつかの選択肢があ"" ""りますが、高可用性には <emphasis>FlatDHCP</emphasis> で <emphasis>マルチホス"" ""ト</emphasis> ネットワークモードを使用して、OpenStack Compute ホスト毎に "" ""<code>nova-network</code> デーモンを 1 つ実行することを推奨します。これによ"" ""り、ネットワーク障害が確実に各コンピュートホスト内に隔離される堅牢性の高いメ"" ""カニズムが提供され、各ホストはハードウェアのネットワークゲートウェイと直接通"" ""信することが可能となります。""msgid """" ""As shown, end users can interact through the dashboard, CLIs, and APIs. All "" ""services authenticate through a common Identity Service, and individual "" ""services interact with each other through public APIs, except where "" ""privileged administrator commands are necessary. <xref linkend=\""openstack-"" ""diagram\""/> shows the most common, but not the only logical architecture for "" ""an OpenStack cloud."" msgstr """" ""下図に示したように、エンドユーザーはダッシュボード、CLI、および API を使用し"" ""て対話することができます。サービスはすべて、共通の Identity Service を介して"" ""認証を行い、またサービス相互間の対話は、特権のある管理者がコマンドを実行する"" ""必要がある場合を除いてパブリック API を使用して行われます。<xref linkend="" ""\""openstack-diagram\""/> には、OpenStack の最も一般的な論理アーキテクチャを示"" ""しています。ただし、これは唯一のアーキテクチャではありません。""msgid ""As soon as this setting was fixed, everything worked."" msgstr ""全力でこの問題を修正した結果、全てが正常に動作するようになった。""msgid ""As this would be the server's bonded NIC."" msgstr ""これはサーバーの冗長化された（bonded）NIC であるべきだからだ。""""As with databases and message queues, having more than one <glossterm>API "" ""server</glossterm> is a good thing. Traditional HTTP load-balancing "" ""techniques can be used to achieve a highly available <code>nova-api</code> "" ""service.<indexterm class=\""singular\""><primary>API (application programming "" ""interface)</primary><secondary>API server</secondary></indexterm>""""データベースやメッセージキューのように、１台以上の<glossterm>API サーバー</"" ""glossterm> を設置する事は良い案です。<code>nova-api</code> サービスを高可用"" ""にするために、伝統的な HTTP 負荷分散技術を利用することができます。""""As with most architecture choices, the right answer depends on your "" ""environment. If you are using existing hardware, you know the disk density "" ""of your servers and can determine some decisions based on the options above. "" ""If you are going through a procurement process, your user's requirements "" ""also help you determine hardware purchases. Here are some examples from a "" ""private cloud providing web developers custom environments at AT&amp;T. This "" ""example is from a specific deployment, so your existing hardware or "" ""procurement opportunity may vary from this. AT&amp;T uses three types of "" ""hardware in its deployment:"" msgstr """" ""多くのアーキテクチャの選択肢と同様に、環境により適切なソリューションは変わっ"" ""て来ます。既存のハードウェアを使用する場合、サーバーのディスク密度を把握し、"" ""上記のオプションをもとに意思決定していきます。調達プロセスを行っている場合、"" ""ユーザー要件などもハードウェア購入決定の一助となります。ここでは AT&amp;T の "" ""Web 開発者にカスタムの環境を提供するプライベートクラウドの例をあげています。"" ""この例は、特定のデプロイメントであるため、既存のハードウェアや調達機会はこれ"" ""と異なる可能性があります。AT&amp;T は、デプロイメントに 3 種類のハードウェア"" ""を使用しています。""""As your focus turns to stable operations, we recommend that you do skim the "" ""remainder of this book to get a sense of the content. Some of this content "" ""is useful to read in advance so that you can put best practices into effect "" ""to simplify your life in the long run. Other content is more useful as a "" ""reference that you might turn to when an unexpected event occurs (such as a "" ""power failure), or to troubleshoot a particular problem.""""焦点を安定運用に切り替えるために、この文書の残りの部分をざっくりと読み、感覚"" ""をつかむ事をお勧めします。長期運用に向けてのベストプラクティスを実施するため"" ""この文書のいくつかのコンテンツはあらかじめ読んでおくと役に立つでしょう。その"" ""他のコンテンツは(電源障害のような)予期しないイベントが発生した場合や特定の問"" ""題のトラブルシューティングをする際に役に立つリファレンスとして役に立つでしょ"" ""う。""""Aside from the creation and termination of VMs, you must consider the impact "" ""of users accessing the service—particularly on <literal>nova-api</literal> "" ""and its associated database. Listing instances garners a great deal of "" ""information and, given the frequency with which users run this operation, a "" ""cloud with a large number of users can increase the load significantly. This "" ""can occur even without their knowledge—leaving the OpenStack dashboard "" ""instances tab open in the browser refreshes the list of VMs every 30 seconds.""""仮想マシンの作成、停止以外に、特に <literal>nova-api</literal> や関連のデータ"" ""ベースといったサービスにアクセスする際の影響について考慮する必要があります。"" ""インスタンスを一覧表示することで膨大な量の情報を収集し、この操作の実行頻度を"" ""前提として、ユーザー数の多いクラウドで負荷を大幅に増加させることができます。"" ""これはユーザーには透過的に行われます。OpenStack のダッシュボードをブラウザで"" ""開いた状態にすると、仮想マシンの一覧が 30 秒毎に更新されます。"" msgid ""Assignee: &lt;yourself&gt;"" msgstr ""Assignee: &lt;あなた自身&gt;"" msgid ""Associating Security Groups"" msgstr ""セキュリティグループの割り当て"" msgid ""Associating Users with Projects"" msgstr ""プロジェクトへのユーザーの割り当て""""At that time, our control services were hosted by another team and we didn't "" ""have much debugging information to determine what was going on with the "" ""master, and couldn't reboot it. That team noted that it failed without "" ""alert, but managed to reboot it. After an hour, the cluster had returned to "" ""its normal state and we went home for the day."" msgstr """" ""この時、我々のコントロールサービスは別のチームによりホスティングされており、"" ""我々には現用系サーバー上で何が起こっているのかを調査するための大したデバッグ"" ""情報がなく、再起動もできなかった。このチームは警報なしで障害が起こったと連絡"" ""してきたが、そのサーバーの再起動を管理していた。１時間後、クラスタは通常状態"" ""に復帰し、我々はその日は帰宅した。""""At the data center, I was finishing up some tasks and remembered the lock-"" ""up. I logged into the new instance and ran <placeholder-1/> again. It "" ""worked. Phew. I decided to run it one more time. It locked up. WTF.""""データセンターで、私はいくつかの仕事を済ませると、ロックアップのことを思い出"" ""した。私は新しいインスタンスにログインし、再度 <placeholder-1/> を実行した。"" ""コマンドは機能した。ふぅ。私はもう一度試してみることにした。今度はロックアッ"" ""プした。何だこれは？""""At the end of 2012, Cybera (a nonprofit with a mandate to oversee the "" ""development of cyberinfrastructure in Alberta, Canada) deployed an updated "" ""OpenStack cloud for their <link title=\""DAIR project\"" href=\""http://www."" ""canarie.ca/en/dair-program/about\"">DAIR project</link> (http://www.canarie."" ""ca/en/dair-program/about). A few days into production, a compute node locks "" ""up. Upon rebooting the node, I checked to see what instances were hosted on "" ""that node so I could boot them on behalf of the customer. Luckily, only one "" ""instance.""""2012年の終わり、Cybera （カナダ アルバータ州にある、サイバーインフラのデプロ"" ""イを監督する権限を持つ非営利団体）が、彼らの <link title=\""DAIR project\"" "" ""href=\""http://www.canarie.ca/en/dair-program/about\"">DAIR プロジェクト</"" ""link> (http://www.canarie.ca/en/dair-program/about) 用に新しい OpenStack クラ"" ""ウドをデプロイした。サービスインから数日後、あるコンピュートノードがロック"" ""アップした。問題のノードの再起動にあたり、私は顧客の権限でインスタンスを起動"" ""するため、そのノード上で何のインスタンスがホスティングされていたかを確認し"" ""た。幸運にも、インスタンスは１つだけだった。""""At the end of August 2012, a post-secondary school in Alberta, Canada "" ""migrated its infrastructure to an OpenStack cloud. As luck would have it, "" ""within the first day or two of it running, one of their servers just "" ""disappeared from the network. Blip. Gone.""""2012年8月の終わり、カナダ アルバータ州のある大学はそのインフラを OpenStack ク"" ""ラウドに移行した。幸か不幸か、サービスインから1～2日間に、彼らのサーバーの1台"" ""がネットワークから消失した。ビッ。いなくなった。""""At the same time of finding the bug report, a co-worker was able to "" ""successfully reproduce The Issue! How? He used <placeholder-1/> to spew a "" ""ton of bandwidth at an instance. Within 30 minutes, the instance just "" ""disappeared from the network.""""バグ報告を発見すると同時に、同僚が「あの問題」を再現することに成功した！どう"" ""やって？彼は <placeholder-1/> を使用して、インスタンス上で膨大なネットワーク"" ""負荷をかけた。30分後、インスタンスはネットワークから姿を消した。""""At the very base of any operating system are the hard drives on which the "" ""operating system (OS) is installed.<indexterm class=\""singular"" ""\""><primary>RAID (redundant array of independent disks)</primary></"" ""indexterm><indexterm class=\""singular\""><primary>partitions</"" ""primary><secondary>disk partitioning</secondary></indexterm><indexterm class="" ""\""singular\""><primary>disk partitioning</primary></indexterm>""""オペレーティングシステムの基盤は、オペレーティングシステムがインストールされ"" ""るハードドライブです。<indexterm class=\""singular\""><primary>RAID (Redundant "" ""Array of Independent Disks)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>パーティション</primary><secondary>ディスクパーティショニング</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>ディスクパーティ"" ""ショニング</primary></indexterm>""msgid ""Attaching Block Storage"" msgstr ""ブロックストレージの接続"" msgid ""Aug 10, 2012"" msgstr ""2012年8月10日"" msgid ""Aug 8, 2013"" msgstr ""2013年8月8日"" msgid ""Austin"" msgstr ""Austin"" msgid ""Authentication and Authorization"" msgstr ""認証と認可"" msgid ""Authentication and authorization for identity management"" msgstr ""アイデンティティ管理のための認証と認可"" msgid ""Automated Configuration"" msgstr ""自動環境設定"" msgid ""Automated Deployment"" msgstr ""自動デプロイメント"" msgid ""Availability Zones and Host Aggregates"" msgstr ""アベイラビリティゾーンとホストアグリゲート"" msgid ""Availability zone"" msgstr ""アベイラビリティゾーン"" msgid ""Availability zones"" msgstr ""アベイラビリティゾーン""""Availability zones are implemented through and configured in a similar way "" ""to host aggregates.""""アベイラビリティゾーンは、ホストアグリゲートを利用して実装されており、ホスト"" ""アグリゲートと同様の方法で設定します。""msgid ""Available vCPUs"" msgstr ""利用可能な vCPU 数"" msgid ""Backing storage services"" msgstr ""バックエンドのストレージサービス"" msgid ""Backup and Recovery"" msgstr ""バックアップとリカバリー"" msgid ""Basic node deployment"" msgstr ""基本ノードデプロイメント""""Because OpenStack is highly configurable, with many different backends and "" ""network configuration options, it is difficult to write documentation that "" ""covers all possible OpenStack deployments. Therefore, this guide defines "" ""example architectures to simplify the task of documenting, as well as to "" ""provide the scope for this guide. Both of the offered architecture examples "" ""are currently running in production and serving users.""""OpenStack は、多数の異なるバックエンドおよびネットワーク設定オプションを利用"" ""して高度に設定することが可能です。可能な OpenStack デプロイメントをすべて網羅"" ""するドキュメントを執筆するのは難しいため、本ガイドではアーキテクチャの例を定"" ""義することによって文書化の作業を簡素化すると共に、本書のスコープを規定しま"" ""す。以下に紹介するアーキテクチャの例はいずれも本番環境で現在実行中であり、"" ""ユーザーにサービスを提供しています。""""Because Pacemaker is cluster software, the software itself handles its own "" ""availability, leveraging <literal>corosync</literal> and <literal>cman</"" ""literal> underneath.""""Pacemaker は、クラスタリングソフトウェアであるため、基盤となる "" ""<literal>corosync</literal> および <literal>cman</literal> を活用して、ソフト"" ""ウェア自体が自らの可用性を処理します。""""Because it is recommended to not use partitions on a swift disk, simply "" ""format the disk as a whole:""""Swift ディスクではパーティションを使用しないことが推奨されるので、単にディス"" ""ク全体をフォーマットします。""""Because the cloud controller handles so many different services, it must be "" ""able to handle the amount of traffic that hits it. For example, if you "" ""choose to host the OpenStack Imaging Service on the cloud controller, the "" ""cloud controller should be able to support the transferring of the images at "" ""an acceptable speed.<indexterm class=\""singular\""><primary>cloud "" ""controllers</primary><secondary>network traffic and</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>design considerations</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>design considerations</"" ""primary><secondary>networks</secondary></indexterm>""""クラウドコントローラーは非常に多くのサービスを取り扱うため、それらすべてのト"" ""ラフィックを処理できなければなりません。例えば、クラウドコントローラー上に "" ""OpenStack イメージ サービスを乗せることにした場合、そのクラウドコントローラー"" ""は許容可能な速度でイメージの転送できなければなりません。<indexterm class="" ""\""singular\""><primary>クラウドコントローラー</primary><secondary>ネットワーク"" ""トラフィック</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ネットワーク</primary><secondary>設計上の考慮事項</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>ネットワーク</secondary></indexterm>""""Because without sensible quotas a single tenant could use up all the "" ""available resources, default quotas are shipped with OpenStack. You should "" ""pay attention to which quota settings make sense for your hardware "" ""capabilities.""""妥当なクォータがないと、単一のテナントが利用可能なリソースをすべて使用してし"" ""まう可能性があるため、デフォルトのクォータが OpenStack には含まれています。お"" ""使いのハードウェア機能には、どのクォータ設定が適切か注意してください。""msgid ""Before you begin"" msgstr ""始める前に""""Betsy Hagemeier, a Fanatical Executive Assistant, took care of a room "" ""reshuffle and helped us settle in for the week.""""熱狂的なエグゼクティブアシスタントの Betsy Hagemeier は、部屋の改造の面倒を見"" ""てくれて、1週間で解決する手助けをしてくれました。"" msgid ""Between the proxies and your users"" msgstr ""proxy server と 利用者の間"" msgid ""Between those servers and the proxies"" msgstr ""object/container/account server と proxy server の間"" msgid ""Bexar"" msgstr ""Bexar"" msgid ""Block"" msgstr ""ブロックストレージ"" msgid ""Block Storage"" msgstr ""ブロックストレージ""""Block Storage (cinder) is installed natively on external storage nodes and "" ""uses the <emphasis>LVM/iSCSI plug-in</emphasis>. Most Block Storage Service "" ""plug-ins are tied to particular vendor products and implementations limiting "" ""their use to consumers of those hardware platforms, but LVM/iSCSI is robust "" ""and stable on commodity hardware.""""Block Storage (cinder) は、外部ストレージノードにネイティブでインストールさ"" ""れ、<emphasis>LVM/iSCSI plug-in</emphasis> を使用します。大半の Block "" ""Storage Service プラグインは、特定のベンダーの製品や実装と関連付けられてお"" ""り、使用はそれらのハードウェアプラットフォームのユーザーに制限されています"" ""が、LVM/iSCSI はコモディティハードウェア上で堅牢性および安定性があります。""msgid ""Block Storage Creation Failures"" msgstr ""ブロックストレージの作成エラー"" msgid ""Block Storage Service (cinder) backend"" msgstr ""Block Storage Service (cinder) バックエンド"" msgid ""Block storage"" msgstr ""ブロックストレージ""""Block storage (sometimes referred to as volume storage) provides users with "" ""access to block-storage devices. Users interact with block storage by "" ""attaching volumes to their running VM instances.<indexterm class=\""singular"" ""\""><primary>volume storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>block storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>storage</primary><secondary>block storage</secondary></indexterm>""""Block storage (ボリュームストレージと呼ばれる場合もある) は、ユーザーがブロッ"" ""クストレージデバイスにアクセスできるようにします。ユーザーは、実行中の仮想マ"" ""シンインスタンスにボリュームを接続することで、ブロックストレージと対話しま"" ""す。<indexterm class=\""singular\""><primary>ボリュームストレージ</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ブロックストレージ</"" ""primary></indexterm><indexterm class=\""singular\""><primary>ストレージ</"" ""primary><secondary>ブロックストレージ</secondary></indexterm>""""Both <literal>nova-network</literal> and neutron services provide similar "" ""capabilities, such as VLAN between VMs. You also can provide multiple NICs "" ""on VMs with either service. Further discussion follows.""""<literal>nova-network</literal>とneutronサービスはVM間でのVLANといった似通っ"" ""た可用性を提供します。また、それぞれのサービスで複数のNICを付与したVMも提供す"" ""る事ができます。""""Both Ubuntu and Red Hat Enterprise Linux include mechanisms for configuring "" ""the operating system, including preseed and kickstart, that you can use "" ""after a network boot. Typically, these are used to bootstrap an automated "" ""configuration system. Alternatively, you can use an image-based approach for "" ""deploying the operating system, such as systemimager. You can use both "" ""approaches with a virtualized infrastructure, such as when you run VMs to "" ""separate your control services and physical infrastructure.""""Ubuntu と Red Hat Enterprise Linux にはいずれも、ネットワークブート後に使用可"" ""能なpreseed や kickstart といった、オペレーティングシステムを設定するための仕"" ""組みがあります。これらは、典型的には自動環境設定システムのブートストラップに"" ""使用されます。他の方法としては、systemimager のようなイメージベースのオペレー"" ""ティングシステムのデプロイメント手法を使うこともできます。これらの手法はどち"" ""らも、物理インフラストラクチャーと制御サービスを分離するために仮想マシンを実"" ""行する場合など、仮想化基盤と合わせて使用できます。"" msgid ""Bug Fixing"" msgstr ""バグ修正"" msgid ""Burn-in Testing"" msgstr ""エージング試験"" msgid """" ""By mistake, I configured OpenStack to attach all tenant VLANs to vlan20 "" ""instead of bond0 thereby stacking one VLAN on top of another which then "" ""added an extra 4 bytes to each packet which cause a packet of 1504 bytes to "" ""be sent out which would cause problems when it arrived at an interface that "" ""only accepted 1500!"" msgstr """" ""ミスにより、私は全てのテナント VLAN を bond0 の代わりに vlan20 にアタッチする"" ""よう OpenStack を設定した。それによって１つの VLAN が別の VLAN の上に積み重な"" ""り、各パケットに余分に４バイトが追加され、送信されるパケットサイズが 1504 バ"" ""イトになる原因となった。これがパケットサイズ 1500 のみ許容するインターフェー"" ""スに到達した際、問題の原因となったのだった！"" msgid """" ""By running this command periodically and keeping a record of the result, you "" ""can create a trending report over time that shows whether your <code>nova-"" ""api</code> usage is increasing, decreasing, or keeping steady."" msgstr """" ""このコマンドを定期的に実行し結果を記録することで、トレンドレポートを作ること"" ""ができます。これにより<code>/var/log/nova/nova-api.log</code>の使用量が増えて"" ""いるのか、減っているのか、安定しているのか、を知ることができます。"" msgid ""CERN"" msgstr ""CERN"" msgid """" ""CONF.node_availability_zone has been renamed to CONF."" ""default_availability_zone and is used only by the <literal>nova-api</"" ""literal> and <literal>nova-scheduler</literal> services."" msgstr """" ""CONF.node_availability_zone は、CONF.default_availability_zone に名前が変更さ"" ""れ、<literal>nova-api</literal> および <literal>nova-scheduler</literal> サー"" ""ビスのみで使用されます。"" msgid ""CONF.node_availability_zone still works but is deprecated."" msgstr ""CONF.node_availability_zone は今も機能しますが、非推奨扱いです。""msgid ""CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgstr ""CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz""msgid ""CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgstr ""CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz""msgid ""CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz"" msgstr ""CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz""msgid ""Cactus"" msgstr ""Cactus"" msgid ""Can objects be stored and deleted?"" msgstr ""オブジェクトの保存と削除は可能か?"" msgid ""Can users be created?"" msgstr ""ユーザの作成は可能か?"" msgid ""Can volumes be created and destroyed?"" msgstr ""ボリュームの作成と削除は可能か?"" msgid ""Capacity Planning"" msgstr ""キャパシティプランニング"" msgid ""Cells"" msgstr ""セル"" msgid ""Cells and Regions"" msgstr ""セルとリージョン""""Cells and regions, which segregate an entire cloud and result in running "" ""separate Compute deployments.""""セルおよびリージョン。クラウド全体を分離し、個別にコンピュートデプロイメント"" ""を稼働します。"" msgid ""Centrally Managing Logs"" msgstr ""ログの集中管理"" msgid ""Ceph"" msgstr ""Ceph""""Ceph was designed to expose different types of storage interfaces to the end "" ""user: it supports object storage, block storage, and file-system interfaces, "" ""although the file-system interface is not yet considered production-ready. "" ""Ceph supports the same API as swift for object storage and can be used as a "" ""backend for cinder block storage as well as backend storage for glance "" ""images. Ceph supports \""thin provisioning,\"" implemented using copy-on-write.""""Ceph は、異なる種類のストレージインターフェースをエンドユーザーに公開するよう"" ""に設計されました。Ceph は、オブジェクトストレージ、ブロックストレージ、ファイ"" ""ルシステムインターフェースをサポートしていますが、ファイルシステムインター"" ""フェースは、実稼動環境での使用にはまだ適していません。Ceph は、オブジェクトス"" ""トレージでは swift と同じ API をサポートしており、cinder ブロックストレージの"" ""バックエンド、glance イメージのバックエンドストレージとして使用することができ"" ""ます。Ceph は、copy-on-write を使用して実装されたシンプロビジョニングをサポー"" ""トします。""""Ceph's advantages are that it gives the administrator more fine-grained "" ""control over data distribution and replication strategies, enables you to "" ""consolidate your object and block storage, enables very fast provisioning of "" ""boot-from-volume instances using thin provisioning, and supports a "" ""distributed file-system interface, though this interface is <link href="" ""\""http://ceph.com/docs/master/cephfs/\"" title=\""OpenStack wiki\"">not yet "" ""recommended</link> for use in production deployment by the Ceph project.""""Ceph の利点は、管理者がより細かくデータの分散やレプリカのストラテジーを管理で"" ""きるようになり、オブジェクトとブロックストレージを統合し、シンプロビジョニン"" ""グでボリュームから起動するインスタンスを非常に早くプロビジョニングできるだけ"" ""でなく、分散ファイルシステムのインターフェースもサポートしている点です。ただ"" ""し、このインターフェースは、Ceph プロジェクトによる実稼動デプロイメントでの使"" ""用には、 <link href=\""http://ceph.com/docs/master/cephfs/\"" title="" ""\""OpenStack wiki\"">推奨されていません</link>。""msgid ""Ceph<indexterm class=\""singular\""><primary>Ceph</primary></indexterm>"" msgstr ""Ceph<indexterm class=\""singular\""><primary>Ceph</primary></indexterm>"" msgid ""Check cloud usage: <placeholder-1/>"" msgstr ""クラウドの使用量を確認します: <placeholder-1/>"" msgid ""Check for instances in a failed or weird state and investigate why."" msgstr ""故障または異常になっているインスタンスを確認し、理由を調査します。"" msgid ""Check for operator accounts that should be removed."" msgstr ""削除すべきオペレーターアカウントを確認します。"" msgid ""Check for security patches and apply them as needed."" msgstr ""セキュリティパッチを確認し、必要に応じて適用します。"" msgid ""Check for user accounts that should be removed."" msgstr ""削除すべきユーザーアカウントを確認します。"" msgid ""Check usage and trends over the past month."" msgstr ""この 1 か月における使用量および傾向を確認します。"" msgid ""Check your monitoring system for alerts and act on them."" msgstr ""監視システムのアラートを確認し、それらに対処します。"" msgid ""Check your ticket queue for new tickets."" msgstr ""チケットキューの新しいチケットを確認します。"" msgid ""Choice of File System"" msgstr ""ファイルシステムの選択"" msgid ""Choosing Storage Backends"" msgstr ""ストレージバックエンドの選択"" msgid ""Choosing a CPU"" msgstr ""CPU の選択"" msgid ""Choosing a Hypervisor"" msgstr ""ハイパーバイザーの選択"" msgid ""Click the <guibutton>Create Project</guibutton> button."" msgstr ""<guibutton>プロジェクトの作成</guibutton> ボタンをクリックします。"" msgid ""Cloud Controller and Storage Proxy Failures and Maintenance"" msgstr ""クラウドコントローラーとストレージプロキシの故障とメンテナンス"" msgid ""Cloud controller hardware sizing considerations"" msgstr ""クラウドコントローラーのハードウェアサイジングに関する考慮事項"" msgid ""Cloud controller receives the renewal request and sends a response."" msgstr ""クラウドコントローラーは更新リクエストを受信し、レスポンスを返す。"" msgid ""Cloud controller receives the second request and sends a new response."" msgstr """" ""クラウドコントローラーは２度めのリクエストを受信し、新しいレスポンスを返す。"" msgid ""Column"" msgstr ""項目"" msgid ""Command prompts"" msgstr ""コマンドプロンプト"" msgid ""Command-Line Tools"" msgstr ""コマンドラインツール"" msgid ""Command-line interface (CLI)"" msgstr ""コマンドラインインターフェース (CLI)""""Commands prefixed with the <literal>$</literal> prompt can be executed by "" ""any user, including <literal>root</literal>.""""<literal>$</literal> プロンプトから始まるコマンドは、<literal>root</literal> "" ""を含む、すべてのユーザーにより実行できます。""""Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, "" ""and <literal>auth_protocol</literal> options because the "" ""<literal>identity_uri</literal> option replaces them.""""<literal>identity_uri</literal> オプションにより置き換えられるので、"" ""<literal>auth_host</literal>、<literal>auth_port</literal>、"" ""<literal>auth_protocol</literal> オプションをコメントアウトします。""msgid ""Commodity Storage Backend Technologies"" msgstr ""商用ストレージバックエンドのテクノロジー"" msgid ""Component"" msgstr ""コンポーネント"" msgid ""Components"" msgstr ""コンポーネント"" msgid ""Compute"" msgstr ""コンピュート"" msgid ""Compute Node Failures and Maintenance"" msgstr ""コンピュートノードの故障とメンテナンス"" msgid ""Compute Nodes"" msgstr ""コンピュートノード"" msgid ""Compute and storage communications"" msgstr ""コンピュートとストレージの通信"" msgid ""Compute node"" msgstr ""コンピュートノード"" msgid ""Compute nodes"" msgstr ""コンピュートノード""msgid """" ""Compute nodes are where the computing resources are held, and in our example "" ""architecture, they run the hypervisor (KVM), libvirt (the driver for the "" ""hypervisor, which enables live migration from node to node), <code>nova-"" ""compute</code>, <code>nova-api-metadata</code> (generally only used when "" ""running in multi-host mode, it retrieves instance-specific metadata), "" ""<code>nova-vncproxy</code>, and <code>nova-network</code>."" msgstr """" ""コンピュートノードには、コンピューティングリソースが保持されます。このアーキ"" ""テクチャ例では、コンピュートノードで、ハイパーバイザー (KVM)、libvirt (ノード"" ""間でのライブマイグレーションを可能にするハイパーバイザー用ドライバー)、"" ""<code>nova-compute</code>、 <code>nova-api-metadata</code> (通常はマルチホス"" ""トモードの場合のみ使用され、インスタンス固有のメタデータを取得する)、nova-"" ""vncproxy、<code>nova-network</code> を実行します。""""Compute nodes have 24 to 48 cores, with at least 4 GB of RAM per core and "" ""approximately 40 GB of ephemeral storage per core.""""コンピュートノードは 24～48コアがあり、１コアあたり 4GB 以上の RAM があり、１"" ""コアあたり約 40GB 以上の一時ストレージがあります。""msgid ""Compute nodes run the virtual machine instances in OpenStack. They:"" msgstr """" ""コンピュートノードは、OpenStack 内の仮想マシンインスタンスを実行します。コン"" ""ピュートノードは、以下のような役割を果たします。""""Compute nodes typically need IP addresses accessible by external networks.""""コンピュートノードは概して外部ネットワークからアクセス可能なIPアドレスが必要"" ""です。"" msgid ""Compute service"" msgstr ""Compute サービス""""Compute's compute and conductor services, which run on the compute nodes, "" ""are only needed to run services on that node, so availability of those "" ""services is coupled tightly to the nodes that are available. As long as a "" ""compute node is up, it will have the needed services running on top of it.""""コンピュートノード上で実行される Compute のコンピュートサービスおよびコンダク"" ""ターサービスは、そのノード上でのみサービスを実行する必要があるので、これらの"" ""サービスの可用性はそのノードの稼働状態と密接に連結しています。コンピュート"" ""ノードが稼働している限りは、そのノード上で必要なサービスが実行されます。"" msgid ""Conclusion"" msgstr ""まとめ"" msgid ""Conductor Services"" msgstr ""コンダクターサービス"" msgid ""Conductor services"" msgstr ""コンダクターサービス"" msgid ""Configuration Management"" msgstr ""構成管理"" msgid ""Configuration changes to <filename>nova.conf</filename>."" msgstr ""<filename>nova.conf</filename> の設定を変更""""Configure DHCP agents and routing agents. Network Address Translation (NAT) "" ""performed outside of compute nodes, typically on one or more network nodes.""""DHCPエージェントとルーティングエージェントを構成します。Network Address "" ""Translation (NAT) によってコンピュートノードと外部を接続します。一般的に1つ以"" ""上のネットワークノードで成り立ちます。""""Configure a single bridge as the integration bridge (br-int) and connect it "" ""to a physical network interface with the Modular Layer 2 (ML2) plug-in, "" ""which uses Open vSwitch by default.""""インテグレーションブリッジ(br-int)として1つのブリッジを構成し、Open vSwitchを"" ""デフォルトとして使うModuler Layer2(ML2)プラグインでbr-intと物理ネットワークイ"" ""ンターフェースを接続します。""""Configure neutron with multiple DHCP and layer-3 agents. Network nodes are "" ""not able to failover to each other, so the controller runs networking "" ""services, such as DHCP. Compute nodes run the ML2 plug-in with support for "" ""agents such as Open vSwitch or Linux Bridge.""""複数のDHCPおよびレイヤ-3エージェントを持つようなneutronの構成では、ネットワー"" ""クノードは互いにフェールオーバできませんのでコントローラはDHCPといったネット"" ""ワークサービスを実行します。コンピュートノードはOpen vSwitchまたはLinux "" ""BridgeといったエージェントをサポートするML2プラグインを実行します。""""Configured <literal>nova-consoleauth</literal> to use Memcached for session "" ""management (so that it can have multiple copies and run in a load balancer).""""<literal>nova-consoleauth</literal> がセッション管理に Memcached を使用するよ"" ""うに設定 (複数のコピーが存在可能で、ロードバランサーで実行できる)。""""Configured to use Qpid, <phrase role=\""keep-together"" ""\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together"" ""\""><literal>10</literal>,</phrase></phrase><phrase role=\""keep-together\""> "" ""configured to use</phrase> Memcached for caching, configured to use <phrase "" ""role=\""keep-together\""><literal>libvirt</literal>,</phrase> configured to "" ""use <phrase role=\""keep-together\""><literal>neutron</literal>.</phrase>""""Qpid を使用するように設定、<phrase role=\""keep-together"" ""\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together"" ""\""><literal>10</literal>、</phrase></phrase><phrase role=\""keep-together\""> "" ""</phrase> Memcached をキャッシュに使用するように設定、 <phrase role=\""keep-"" ""together\""><literal>libvirt</literal> を使用するように設定、</phrase> "" ""<phrase role=\""keep-together\""><literal>neutron</literal> を使用するように設"" ""定</phrase>""msgid ""Connectivity for maximum performance"" msgstr ""パフォーマンスを最大化するための接続性""""Consider creating other private networks for communication between internal "" ""components of OpenStack, such as the message queue and OpenStack Compute. "" ""Using a virtual local area network (VLAN) works well for these scenarios "" ""because it provides a method for creating multiple virtual networks on a "" ""physical network.""""メッセージキューや OpenStack コンピュート といった OpenStack 内部のコンポーネ"" ""ント間の通信用に別のプライベートネットワークの作成を検討して下さい。Virtual "" ""Local Area Network(VLAN) は1つの物理ネットワークに複数の仮想ネットワークを作"" ""成できるのでこのシナリオに非常に適しています。"" msgid ""Consider the following example:"" msgstr ""次のような例を考えてみましょう。""""Consider the scenario where an entire server fails and 24 TB of data needs "" ""to be transferred \""immediately\"" to remain at three copies—this can put "" ""significant load on the network.""""サーバー全体が停止し、24 TB 分のデータを即時に 3 つのコピーに残るように移行す"" ""るというシナリオを思い浮かべてください。これは、ネットワークに大きな負荷がか"" ""かる可能性があります。""msgid ""Consideration"" msgstr ""考慮事項"" msgid ""Considered experimental."" msgstr ""試験として使用""""Continuing the diagnosis the next morning was kick started by another "" ""identical failure. We quickly got the message queue running again, and tried "" ""to work out why Rabbit was suffering from so much network traffic. Enabling "" ""debug logging on <systemitem class=\""service\"">nova-api</systemitem> quickly "" ""brought understanding. A <placeholder-1/> was scrolling by faster than we'd "" ""ever seen before. CTRL+C on that and we could plainly see the contents of a "" ""system log spewing failures over and over again - a system log from one of "" ""our users' instances.""""翌朝の継続調査は別の同様の障害でいきなり始まった。我々は急いで RabbitMQ サー"" ""バーを再起動し、何故 RabbitMQ がそのような過剰なネットワーク負荷に直面してい"" ""るのかを調べようとした。<systemitem class=\""service\"">nova-api</systemitem> "" ""のデバッグログを出力することにより、理由はすぐに判明した。<placeholder-1/> は"" ""我々が見たこともない速さでスクロールしていた。CTRL+C でコマンドを止め、障害を"" ""吐き出していたシステムログの内容をはっきり目にすることが出来た。－我々のユー"" ""ザの１人のインスタンスからのシステムログだった。""msgid ""Control services public interfaces"" msgstr ""コントロールサービス用パブリックインターフェース"" msgid ""Controller"" msgstr ""コントローラー"" msgid ""Controller node"" msgstr ""コントローラーノード""""Controller nodes are responsible for running the management software "" ""services needed for the OpenStack environment to function. These nodes:""""コントローラーノードは、 OpenStack 環境が機能するために必要な管理ソフトウェア"" ""サービスを実行します。これらのノードは、以下のような役割を果たします。"" msgid ""Copyright details are filled in by the template."" msgstr ""Copyright details are filled in by the template."" msgid ""Core developers also prioritize the bug, based on its impact:"" msgstr ""にセットして下さい。"" msgid ""Create a backup of configuration files and databases."" msgstr ""設定ファイルとデータベースのバックアップを作成します。"" msgid ""Creating New Users"" msgstr ""新規ユーザーの作成"" msgid ""Current stable release, security-supported"" msgstr ""現在の安定版リリース、セキュリティアップデート対象"" msgid ""Customizing Authorization"" msgstr ""権限のカスタマイズ"" msgid ""DAIR"" msgstr ""DAIR"" msgid ""DHCP traffic can be isolated within an individual host."" msgstr ""DHCP トラフィックは個々のホスト内に閉じ込めることができる。"" msgid ""DNS"" msgstr ""DNS"" msgid ""Daemon"" msgstr ""デーモン"" msgid ""Daily"" msgstr ""日次"" msgid ""Dashboard"" msgstr ""ダッシュボード"" msgid ""Dashboard node"" msgstr ""ダッシュボードサービス"" msgid ""Dashboard's Create Project form"" msgstr ""Dashboard のプロジェクトの作成フォーム"" msgid ""Database"" msgstr ""データベース"" msgid ""Database Backups"" msgstr ""データベースのバックアップ"" msgid ""Database Connectivity"" msgstr ""データベース接続性"" msgid ""Database and message queue server (such as MySQL, RabbitMQ)"" msgstr ""データベースとメッセージキューサーバ（例:MySQL、RabbitMQ）"" msgid ""Databases"" msgstr ""データベース"" msgid ""Date"" msgstr ""リリース日"" msgid ""Debugging DNS Issues"" msgstr ""DNS の問題をデバッグする"" msgid ""Dec 13, 2012"" msgstr ""2012年12月13日"" msgid ""Dec 16, 2013"" msgstr ""2013年12月16日"" msgid """" ""Dedicate entire disks to certain partitions. For example, you could allocate "" ""disk one and two entirely to the boot, root, and swap partitions under a "" ""RAID 1 mirror. Then, allocate disk three and four entirely to the LVM "" ""partition, also under a RAID 1 mirror. Disk I/O should be better because I/O "" ""is focused on dedicated tasks. However, the LVM partition is much smaller."" msgstr """" ""全ディスク領域を特定のパーティションに割り当てます。例えば、ディスク 1 と 2 "" ""すべてを RAID 1 ミラーとして boot、root、swapパーティションに割り当てます。そ"" ""して、ディスク 3 と 4 すべてを、同様に RAID 1 ミラーとしてLVMパーティションに"" ""割り当てます。I/O は専用タスクにフォーカスするため、ディスクの I/O は良くなる"" ""はずです。しかし、LVM パーティションははるかに小さくなります。"" msgid """" ""Default CPU overcommit ratio (<code>cpu_allocation_ratio</code> in nova."" ""conf) of 16:1."" msgstr """" ""デフォルトの CPU オーバーコミット比率 (<code>cpu_allocation_ratio</code> in "" ""nova.conf) は 16:1 とします。"" msgid ""Deleted by user"" msgstr ""ユーザーが削除するまで"" msgid ""Deleting Images"" msgstr ""イメージの削除"" msgid """" ""Depending on design, heavy I/O usage from some instances can affect "" ""unrelated instances."" msgstr """" ""設計次第では、一部のインスタンスの I/O が非常に多い場合に、無関係のインスタン"" ""スに影響が出る場合があります。"" msgid ""Deployment"" msgstr ""デプロイ"" msgid ""Deployment scenarios"" msgstr ""構成シナリオ"" msgid ""Deprecated"" msgstr ""非推奨"" msgid ""Description"" msgstr ""説明"" msgid """" ""Designing an OpenStack cloud is a great achievement. It requires a robust "" ""understanding of the requirements and needs of the cloud's users to "" ""determine the best possible configuration to meet them. OpenStack provides a "" ""great deal of flexibility to achieve your needs, and this part of the book "" ""aims to shine light on many of the decisions you need to make during the "" ""process."" msgstr """" ""OpenStack クラウドの設計は重要な作業です。クラウドのユーザーの要件とニーズを"" ""確実に理解して、それらに対応するために可能な限り最良の構成を決定する必要があ"" ""ります。OpenStack は、ユーザーのニーズを満たすための優れた柔軟性を提供しま"" ""す。本セクションでは、このようなプロセスで行う必要のある数多くの決定事項を明"" ""確に説明することを目的としています。"" msgid """" ""Designing for Cloud Controllers and <phrase role=\""keep-together\"">Cloud "" ""Management</phrase>"" msgstr """" ""クラウドコントローラーのデザインと<phrase role=\""keep-together\"">クラウド管理"" ""</phrase>"" msgid ""Detailed Description"" msgstr ""詳細な説明"" msgid ""Details"" msgstr ""詳細"" msgid """" ""Determining the scalability of your cloud and how to improve it is an "" ""exercise with many variables to balance. No one solution meets everyone's "" ""scalability goals. However, it is helpful to track a number of metrics. "" ""Since you can define virtual hardware templates, called \""flavors\"" in "" ""OpenStack, you can start to make scaling decisions based on the flavors "" ""you'll provide. These templates define sizes for memory in RAM, root disk "" ""size, amount of ephemeral data disk space available, and number of cores for "" ""starters.<indexterm class=\""singular\""><primary>virtual machine (VM)</"" ""primary></indexterm><indexterm class=\""singular\""><primary>hardware</"" ""primary><secondary>virtual hardware</secondary></indexterm><indexterm class="" ""\""singular\""><primary>flavor</primary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>metrics for</secondary></indexterm>"" msgstr """" ""多くのアイテムでバランスを取りながら、クラウドのスケーラビリティや改善方法を"" ""決定していきます。ソリューション 1 つだけでは、スケーラビリティの目的を達成す"" ""ることはできません。しかし、複数のメトリクスをトラッキングすると役に立ちま"" ""す。仮想ハードウェアのテンプレート (OpenStack ではフレーバーと呼ばれる) を定"" ""義できるため、用意するフレーバーをもとにスケーリングの意思決定を行うことがで"" ""きます。これらのテンプレートは、メモリーのサイズ (RAM)、root ディスクのサイ"" ""ズ、一時データディスクの空き容量、スターターのコア数を定義します。<indexterm "" ""class=\""singular\""><primary>仮想マシン</primary></indexterm><indexterm class="" ""\""singular\""><primary>ハードウェア</primary><secondary>仮想ハードウェア</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>フレーバー</"" ""primary></indexterm><indexterm class=\""singular\""><primary>スケーリング</"" ""primary><secondary>メトリクス</secondary></indexterm>"" msgid ""Diablo"" msgstr ""Diablo"" msgid ""Diagnose Your Compute Nodes"" msgstr ""コンピュートノードの診断"" msgid ""Direct I/O access can increase performance."" msgstr ""I/O アクセスが直接行われるので、性能向上が図れます。"" msgid ""Disappearing Images"" msgstr ""イメージの消失"" msgid """" ""Discrete regions with separate API endpoints and no coordination between "" ""regions."" msgstr """" ""リージョンごとに別々のAPIエンドポイントが必要で、リージョン間で協調する必要が"" ""ない場合"" msgid ""Disk"" msgstr ""ディスク"" msgid ""Disk Partitioning and RAID"" msgstr ""ディスクのパーティショニングと RAID"" msgid ""Disk Size: minimum 5 GB"" msgstr ""ディスクサイズ: 最低 5 GB"" msgid ""Disk partioning and disk array setup for scalability"" msgstr """" ""スケーラビリティ確保に向けたディスクのパーティショニングおよびディスク配列設"" ""定"" msgid ""Disk space"" msgstr ""ディスク領域"" msgid ""Disk space is cheap these days. Data recovery is not."" msgstr ""今日、ディスクスペースは安価である。データの復元はそうではない。"" msgid ""Disk: two 300 GB 10000 RPM SAS Disks"" msgstr ""ディスク: 300 GB 10000 RPM SAS ディスク x 2"" msgid ""Disk: two 500 GB 7200 RPM SAS Disks"" msgstr ""ディスク: 500 GB 7200 RPM SAS ディスク x 2"" msgid """" ""Disk: two 500 GB 7200 RPM SAS Disks and twenty-four 600 GB 10000 RPM SAS "" ""Disks"" msgstr """" ""ディスク: 500 GB 7200 RPM SAS ディスク x 2 および 600 GB 10000 RPM SAS ディス"" ""ク x 24"" msgid ""Disk: two 600 GB 10000 RPM SAS Disks"" msgstr ""ディスク: 600 GB 10000 RPM SAS ディスク x 2"" msgid ""Do I need to support live migration?"" msgstr ""管理者がライブマイグレーションを必要とするか？"" msgid ""Do more spindles result in better I/O despite network access?"" msgstr """" ""ネットワークアクセスがあったとしても、ディスク数が多い方が良い I/O 性能が得ら"" ""れるか？"" msgid ""Do my users need block storage?"" msgstr ""ユーザがブロックストレージを必要とするか？"" msgid ""Do my users need object storage?"" msgstr ""ユーザがオブジェクトストレージを必要とするか？"" msgid ""Docker"" msgstr ""Docker"" msgid ""Does your authentication system also verify externally?"" msgstr ""認証システムは外部に確認を行いますか？"" msgid ""Double VLAN"" msgstr ""ダブル VLAN"" msgid ""Down the Rabbit Hole"" msgstr ""ウサギの穴に落ちて""msgid ""Each cell has a full nova installation except nova-api."" msgstr ""各セルには nova-api 以外の全 nova 設定が含まれています。"" ""Each method provides different functionality and can be best divided into "" ""two groups:""""メソッド毎に異なる機能を提供しますが、このメソッドは 2 つのグループに分類する"" ""と良いでしょう。""msgid ""Each region has a full nova installation."" msgstr ""各リージョンにフルセットのNovaサービスが必要"" msgid ""Each tenant is isolated to its own VLANs."" msgstr ""それぞれのテナントは自身のVLANによって独立しています。"" msgid ""Edit the <filename>/etc/nova/nova.conf</filename> file:"" msgstr ""<filename>/etc/nova/nova.conf</filename> ファイルを編集します。"" msgid ""Email address"" msgstr ""電子メールアドレス""""Emma Richards of Rackspace Guest Relations took excellent care of our lunch "" ""orders and even set aside a pile of sticky notes that had fallen off the "" ""walls.""""Rackspace ゲストリレーションズの Emma Richards は、私たちのランチの注文を素晴"" ""らしく面倒を見てくれて、更に壁から剥がれ落ちた付箋紙の山を脇においてくれまし"" ""た。""""Enables users to submit API calls to OpenStack services through commands."" ""<indexterm class=\""singular\""><primary>Command-line interface (CLI)</""""ユーザーはコマンドを使用して API コールを OpenStack サービスに送信できます。"" ""<indexterm class=\""singular\""><primary>コマンドラインインターフェース (CLI)</"" msgid ""Ensure that the operating system has recognized the new disk:""""オペレーティングシステムが新しいディスクを認識していることを確認します。""""Ensure that your messaging queue handles requests successfully and size "" ""accordingly.""""メッセージキューが正しくリクエストを処理することを保証し、適切にサイジングし"" ""てください。"" msgid ""Ephemeral"" msgstr ""エフェメラル"" msgid ""Ephemeral Storage"" msgstr ""一時ストレージ"" msgid ""Ephemeral storage"" msgstr ""エフェメラルストレージ"" msgid ""Essex"" msgstr ""Essex""""Ever have one of those days where all of the sudden you get the Google "" ""results you were looking for? Well, that's what happened here. I was looking "" ""for information on dhclient and why it dies when it can't renew its lease "" ""and all of the sudden I found a bunch of OpenStack and dnsmasq discussions "" ""that were identical to the problem we were seeing!""""探し続けてきた Google の検索結果が突然得られたという事態をお分かりだろうか？"" ""えっと、それがここで起こったことだ。私は dhclient の情報と、何故 dhclient が"" ""そのリースを更新できない場合に死ぬのかを探していて、我々が遭遇したのと同じ問"" ""題についての OpenStack と dnsmasq の議論の束を突然発見した。""msgid ""Example"" msgstr ""例"" msgid ""Example Architectures"" msgstr ""アーキテクチャの例"" msgid ""Example Architecture—Legacy Networking (nova)"" msgstr ""アーキテクチャ例: レガシーネットワーク (nova)"" msgid ""Example Architecture—OpenStack Networking"" msgstr ""アーキテクチャの例: OpenStack Networking"" msgid ""Example Component Configuration"" msgstr ""コンポーネントの設定例"" msgid ""Example hardware"" msgstr ""ハードウェアの例"" msgid ""Example of Complexity"" msgstr ""複雑な例"" msgid ""Example of typical usage…"" msgstr ""典型的な利用例"" msgid ""Experimental"" msgstr ""テスト用"" msgid ""Extensions"" msgstr ""API 拡張""""External systems such as LDAP or <glossterm>Active Directory</glossterm> "" ""require network connectivity between the cloud controller and an external "" ""authentication system. Also ensure that the cloud controller has the CPU "" ""power to keep up with requests.""""LDAPや<glossterm>Active Directory</glossterm>のような外部認証システムを利用す"" ""る場合クラウドコントローラと外部認証システムとの間のネットワーク接続性が良好"" ""である必要があります。また、クラウドコントローラがそれらのリクエストを処理す"" ""るための十分のCPUパワーが必要です。"" msgid ""Extremely simple topology."" msgstr ""極めて単純なトポロジー。""""Feature requests typically start their life in Etherpad, a collaborative "" ""editing tool, which is used to take coordinating notes at a design summit "" ""session specific to the feature. This then leads to the creation of a "" ""blueprint on the Launchpad site for the particular project, which is used to "" ""describe the feature more formally. Blueprints are then approved by project "" ""team members, and development can begin.""""機能追加リクエストは、通常 Etherpad で始まります。Etherpad は共同編集ツール"" ""で、デザインサミットのその機能に関するセッションで議論を整理するのに使われま"" ""す。続けて、プロジェクトの Launchpad サイトに blueprint が作成され、"" ""blueprint を使ってよりきちんとした形で機能が規定されていきます。 この後、"" ""blueprint はプロジェクトメンバーによって承認され、開発が始まります。"" msgid ""Feb 3, 2011"" msgstr ""2011年2月3日"" msgid ""File System Backups"" msgstr ""ファイルシステムバックアップ"" msgid ""File system"" msgstr ""ファイルシステム""""File system to store files and directories, where all the data lives, "" ""including the root partition that starts and runs the system""""ファイルやディレクトリを格納するファイルシステム。システムを起動、実行する "" ""root パーティションなど、全データが設置される場所。"" msgid ""File-level Storage (for Live Migration)"" msgstr ""ファイルレベルのストレージ (ライブマイグレーション用)"" msgid ""File-level<placeholder-1/>"" msgstr ""ファイルレベル<placeholder-1/>""""Finally, Alvaro noticed something. When a packet from the outside hits the "" ""cloud controller, it should not be configured with a VLAN. We verified this "" ""as true. When the packet went from the cloud controller to the compute node, "" ""it should only have a VLAN if it was destined for an instance. This was "" ""still true. When the ping reply was sent from the instance, it should be in "" ""a VLAN. True. When it came back to the cloud controller and on its way out "" ""to the public internet, it should no longer have a VLAN. False. Uh oh. It "" ""looked as though the VLAN part of the packet was not being removed.""""遂に、Alvaro が何かを掴んだ。外部からのパケットがクラウドコントローラーを叩い"" ""た際、パケットは VLAN で設定されるべきではない。我々はこれが正しいことを検証"" ""した。パケットがクラウドコントローラーからコンピュートノードに行く際、パケッ"" ""トはインスタンス宛の場合にのみ VLAN を持つべきである。これもまた正しかった。"" ""ping のレスポンスがインスタンスから送られる際、パケットは VLAN 中にいるべきで"" ""ある。ＯＫ。クラウドコントローラーからパブリックインターネットにパケットが戻"" ""る際、パケットには VLAN を持つべきではない。ＮＧ。うぉっ。まるで パケットの "" ""VLAN 部分が削除されていないように見える。""msgid ""Finally, mount the disk:"" msgstr ""最後に、ディスクをマウントします。""msgid ""Finding Additional Information"" msgstr ""さらに情報を見つける"" msgid ""Finding a Failure in the Path"" msgstr ""経路上の障害を見つける"" msgid ""First, find the UUID of the instance in question:"" msgstr ""まず、インスタンスのUUIDを確認します。"" msgid ""First, unmount the disk:"" msgstr ""まず、ディスクをアンマウントします。""msgid ""Fixed IPs"" msgstr ""固定 IP""msgid ""Flat"" msgstr ""Flat""msgid ""FlatDHCP"" msgstr ""FlatDHCP""msgid ""FlatDHCP Multi-host with high availability (HA)"" msgstr ""高可用性(HA)のためのフラットDHCPマルチホスト構成""msgid ""Flavor parameters"" msgstr ""フレーバーのパラメーター""msgid ""Flavors"" msgstr ""フレーバー""msgid ""Floating IPs"" msgstr ""Floating IP""msgid ""Folsom"" msgstr ""Folsom""""For a discussion of metric tracking, including how to extract metrics from "" ""your cloud, see <xref linkend=\""logging_monitoring\""/>.""""クラウドからメトリクスを抽出する方法など、メトリクスの追跡については、<xref "" ""linkend=\""logging_monitoring\""/> を参照してください。""""For example, a cloud administrator might be able to list all instances in "" ""the cloud, whereas a user can see only those in his current group. Resources "" ""quotas, such as the number of cores that can be used, disk space, and so on, "" ""are associated with a project.""""例えば、クラウドのユーザは自分の現在のグループに属するインスタンスのみが見え"" ""るのに対して、クラウドの管理者はそのクラウドのすべてのインスタンスの一覧をと"" ""ることができるでしょう。利用可能なコア数、ディスク容量等のリソースのクォータ"" ""はプロジェクトに対して関連づけられています。""""For example, if a physical node has 48 GB of RAM, the scheduler allocates "" ""instances to that node until the sum of the RAM associated with the "" ""instances reaches 72 GB (such as nine instances, in the case where each "" ""instance has 8 GB of RAM).""""例えば、物理ノードに 48GB の RAM がある場合、そのノード上のインスタンスに割り"" ""当てられた RAM の合計が 72GB に達するまでは、スケジューラーはそのノードにイン"" ""スタンスを割り振ることになります (例えば、各インスタンスのメモリが 8GB であれ"" ""ば、9 インスタンス割り当てられます)。""msgid ""For example, run the following command:"" msgstr ""例えば、以下のコマンドを実行します。""""For example, take a deployment that has both OpenStack Compute and Object "" ""Storage, with private ranges 172.22.42.0/24 and 172.22.87.0/26 available. "" ""One way to segregate the space might be as follows:""""例えば、OpenStack コンピュート と オブジェクトストレージ の両方を使用し、プラ"" ""イベートアドレス範囲として 172.22.42.0/24 と 172.22.87.0/26 が利用できる場面"" ""を考えます。一例として、アドレス空間を以下のように分割することができます。""""For example, the EC2 API refers to instances using IDs that contain "" ""hexadecimal, whereas the OpenStack API uses names and digits. Similarly, the "" ""EC2 API tends to rely on DNS aliases for contacting virtual machines, as "" ""opposed to OpenStack, which typically lists IP addresses.<indexterm class="" ""\""singular\""><primary>DNS (Domain Name Server, Service or System)</"" ""primary><secondary>DNS aliases</secondary></indexterm><indexterm class="" ""\""singular\""><primary>troubleshooting</primary><secondary>DNS issues</""""例えば、EC2 API では、16 進数を含む ID を使ってインスタンスを参照するのに対し"" ""て、OpenStack API では名前と数値を使います。同様に、EC2 API は仮想マシンに接"" ""続するのに DNS エイリアスに頼る傾向がありますが、OpenStack では典型的には IP "" ""アドレスを使います。<indexterm class=\""singular\""><primary>DNS (Domain Name "" ""Server, Service or System)</primary><secondary>DNS エイリアス</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>トラブルシューティング</"" ""primary><secondary>DNS 問題</secondary></indexterm>""""For example, to monitor disk capacity on a compute node with Nagios, add the "" ""following to your Nagios configuration:""""例として、コンピュートノード上のディスク容量をNagiosを使って監視する場合、次"" ""のようなNagios設定を追加します。""msgid ""For example, to restrict a project's image storage to 5 GB, do this:""""たとえば、プロジェクトのイメージストレージを 5GB に制限するには、以下を実行し""""For example, you must plan the number of IP addresses that you need for both "" ""your guest instances as well as management infrastructure. Additionally, you "" ""must research and discuss cloud network connectivity through proxy servers "" ""and firewalls.""""例えば、管理インフラだけでなくゲストインスタンス用のIPアドレスの数も計画しな"" ""ければなりません。加えて、プロキシサーバーやファイアウォールを経由してのクラ"" ""ウドネットワークの接続性を調査・議論する必要があります。""msgid ""For example:"" msgstr ""例えば""msgid ""For example: <placeholder-1/><placeholder-2/>"" msgstr ""例えば、<placeholder-1/><placeholder-2/>""""For the storage proxy, ensure that the Object Storage service has resumed:""""ストレージプロキシの場合、Object Storage サービスが再開していることを確認しま"" ""す。"" msgid """" ""Form the only ingress and egress point for instances running on top of "" ""OpenStack."" msgstr """" ""OpenStack 上で実行されているインスタンス用の唯一の送受信ポイントを形成しま"" ""す。"" msgid """" ""From here, click the <guiicon>+</guiicon> icon to add users to the project. "" ""Click the <guiicon>-</guiicon> to remove them."" msgstr """" ""ここから、プロジェクトにユーザーを追加するには <guiicon>+</guiicon> アイコン"" ""をクリックします。削除するには <guiicon>-</guiicon> をクリックします。""msgid """" ""Further days go by and we catch The Issue in action more and more. We find "" ""that dhclient is not running after The Issue happens. Now we're back to "" ""thinking it's a DHCP issue. Running <filename>/etc/init.d/networking</"" ""filename> restart brings everything back up and running."" msgstr """" ""それから何日か過ぎ、我々は「あの問題」に度々遭遇した。我々は「あの問題」の発"" ""生後、dhclient が実行されていないことを発見した。今、我々は、それが DHCP の問"" ""題であるという考えに立ち戻った。<filename>/etc/init.d/networking</filename> "" ""restart を実行すると、全ては元通りに実行されるようになった。""""Further troubleshooting showed that libvirt was not running at all. This "" ""made more sense. If libvirt wasn't running, then no instance could be "" ""virtualized through KVM. Upon trying to start libvirt, it would silently die "" ""immediately. The libvirt logs did not explain why.""""さらなるトラブルシューティングにより、libvirt がまったく動作していないことが"" ""わかりました。これは大きな手がかりです。libvirt が動作していないと、KVM によ"" ""るインスタンスの仮想化ができません。libvirt を開始させようとしても、libvirt "" ""は何も表示せずすぐに停止しました。libvirt のログでは理由がわかりませんでし"" ""た。"" msgid ""Getting Credentials"" msgstr ""認証情報の取得方法"" msgid ""Getting Help"" msgstr ""助けを得る"" msgid ""Gluster"" msgstr ""Gluster"" msgid """" ""Gluster<indexterm class=\""singular\""><primary>GlusterFS</primary></indexterm>"" msgstr """" ""Gluster<indexterm class=\""singular\""><primary>GlusterFS</primary></indexterm>"" msgid ""GlusterFS"" msgstr ""GlusterFS"" msgid """" ""GlusterFS offers scalable storage. As your environment grows, you can "" ""continue to add more storage nodes (instead of being restricted, for "" ""example, by an expensive storage array)."" msgstr """" ""GlusterFS は拡張可能なストレージを提供します。環境の拡大に応じて、 (高額なス"" ""トレージアレイなどによる制約を受けずに) ストレージノードを継続的に追加するこ"" ""とが可能です。"" msgid ""Grizzly"" msgstr ""Grizzly"" msgid ""HDWMY"" msgstr ""HDWMY"" msgid ""HTTP"" msgstr ""HTTP"" msgid ""Handling a Complete Failure"" msgstr ""完全な故障の対処""msgid ""Hardware Procurement"" msgstr ""ハードウェア調達"" ""Hardware does not have to be consistent, but it should at least have the "" ""same type of CPU to support instance migration.""""ハードウェアに一貫性を持たせる必要はありませんが、インスタンスのマイグレー"" ""ションをサポートできるように、最低限、CPU の種類は同じにする必要があります。"" msgid """" ""Hardware for compute nodes. Typically 256 or 144 GB memory, two processors, "" ""24 cores. 4–6 TB direct attached storage, typically in a RAID 5 "" ""configuration."" msgstr """" ""コンピュートノードのハードウェア。通常、メモリー 256 GB または 144 GB、プロ"" ""セッサー 2 個、コア 24 個、通常 RAID 5 設定のダイレクトアタッチストレージ "" ""(DAS)。"" msgid """" ""Hardware for controller nodes, used for all stateless OpenStack API "" ""services. About 32–64 GB memory, small attached disk, one processor, varied "" ""number of cores, such as 6–12."" msgstr """" ""コントローラーノードのハードウェア。ステートレスの OpenStack API サービスすべ"" ""てに使用します。メモリー約 32-64GB、接続された容量の小さいディスク、プロセッ"" ""サー 1 つ、6-12 個程度のコア。"" msgid """" ""Hardware for storage nodes. Typically for these, the disk space is optimized "" ""for the lowest cost per GB of storage while maintaining rack-space "" ""efficiency."" msgstr """" ""ストレージノードのハードウェア。通常、ラックスペース効率を確保しつつも、ディ"" ""スク容量のコストが GB ベースで最も低く最適化されています。"" msgid ""Havana"" msgstr ""Havana"" msgid """" ""He re-enabled the switch ports and the two compute nodes immediately came "" ""back to life."" msgstr """" ""彼はスイッチポートを再度有効にしたところ、２つのコンピュートノードは即時に復"" ""活した。"" msgid """" ""Heavy I/O usage on one compute node does not affect instances on other "" ""compute nodes."" msgstr """" ""あるコンピュートノード上での I/O が非常に多い場合でも、他のコンピュートノード"" ""のインスタンスに影響がありません。"" msgid """" ""Here are snippets of the default nova <filename>policy.json</filename> file:"" msgstr """" ""これは標準の nova <filename>policy.json</filename> ファイルの抜粋です。"" msgid """" ""Here we can see that the request was denied because the remote IP address "" ""wasn't in the set of allowed IPs."" msgstr """" ""ここで、リモートIPアドレスが、許可されたIPアドレスの中になかったため、リクエ"" ""ストが拒否されていることがわかります。"" msgid """" ""Here, two floating IPs are available. The first has been allocated to a "" ""project, while the other is unallocated."" msgstr """" ""この場合は、2 つの Floating IP アドレスが利用可能です。最初の IP アドレスはプ"" ""ロジェクトに確保されていますが、もう一方は確保されていません。"" msgid """" ""Herein lies a selection of tales from OpenStack cloud operators. Read, and "" ""learn from their wisdom."" msgstr """" ""ここにあるのは、OpenStack クラウドオペレータ達の苦闘の抜粋である。これを読"" ""み、彼らの叡智を学ぶが良い。"" msgid ""High Availability"" msgstr ""高可用性"" msgid ""Host aggregates"" msgstr ""ホスト・アグリゲート"" msgid ""Host aggregates zone"" msgstr ""ホストアグリゲートゾーン"" msgid ""Host operating system"" msgstr ""ホストのオペレーティングシステム"" msgid ""Hourly"" msgstr ""毎時"" msgid ""How This Book Is Organized"" msgstr ""この本の構成"" msgid ""How do I manage the storage operationally?"" msgstr ""ストレージの運用管理をどうするか？"" msgid ""How do you manage the storage operationally?"" msgstr ""運用上ストレージをどのように管理したいのか？"" msgid ""How long does a single instance run?"" msgstr ""１つのインスタンスがどのくらい実行され続けますか？"" msgid """" ""How many <code>nova-api</code> services do you run at once for your cloud?"" msgstr """" ""あなたのクラウドで、何個の<code>nova-api</code>サービスを同時に実行しますか？"" msgid ""How many backups to keep?"" msgstr ""いくつのバックアップを持つべきか?"" msgid ""How many compute nodes will run at once?"" msgstr ""同時にコンピュートノードが何ノード実行されますか？"" msgid ""How many instances will run at once?"" msgstr ""同時に何インスタンス実行されますか？"" msgid """" ""How many users will access the <glossterm>dashboard</glossterm> versus the "" ""REST API directly?"" msgstr """" ""REST APIに直接アクセスに対してどのくらい多くのユーザが <glossterm>ダッシュ"" ""ボード</glossterm>にアクセスしますか？"" msgid ""How many users will access the API?"" msgstr ""どのくらいの数のユーザがAPIにアクセスしますか？"" msgid ""How much storage is required <code>(flavor disk size </code>"" msgstr ""必要とされるストレージ容量<code>(flavor disk size </code>"" msgid ""How often should backups be tested?"" msgstr ""どの程度の頻度でバックアップをテストすべきか?"" msgid """" ""How redundant and distributed is the storage? What happens if a storage node "" ""fails? To what extent can it mitigate my data-loss disaster scenarios?"" msgstr """" ""ストレージの冗長性と分散をどうするか？ストレージノード障害でどうなるか？災害"" ""時、自分のデータ消失をどの程度軽減できるのか？"" msgid ""How to Contribute to This Book"" msgstr ""この本の作成に参加するには"" msgid ""How to Contribute to the Documentation"" msgstr ""ドキュメント作成への貢献の仕方"" msgid """" ""However, if you are more restricted in the number of physical hosts you have "" ""available for creating your cloud and you want to be able to dedicate as "" ""many of your hosts as possible to running instances, it makes sense to run "" ""compute and storage on the same machines."" msgstr """" ""一方、クラウドの構築に使用できる物理ホスト数に制限があり、できるだけ多くのホ"" ""ストをインスタンスの実行に使えるようにしたい場合は、同じマシンでコンピュート"" ""ホストとストレージホストを動作させるのは理にかなっています。"" msgid ""However, this option has several downsides:"" msgstr ""しかし、この方法にはいくつかマイナス点があります。"" msgid """" ""However, you need more than the core count alone to estimate the load that "" ""the API services, database servers, and queue servers are likely to "" ""encounter. You must also consider the usage patterns of your cloud."" msgstr """" ""しかし、APIサービスやデータベースサーバー、MQサーバーがおそらく遭遇する負荷を"" ""見積もるためには、コア数以外の検討も行う必要があります。クラウドの利用パター"" ""ンも考慮しなければなりません。"" msgid ""However, you use them for different reasons."" msgstr """" ""しかし、アベイラビリティゾーンとホストアグリゲートは別の用途で使用します。"" msgid """" ""Hyper-Threading is Intel's proprietary simultaneous multithreading "" ""implementation used to improve parallelization on their CPUs. You might "" ""consider enabling Hyper-Threading to improve the performance of "" ""multithreaded applications."" msgstr """" ""ハイパースレッディングは、Intel 専用の同時マルチスレッド実装で、CPU の並列化"" ""向上に使用されます。マルチスレッドアプリケーションのパフォーマンスを改善する"" ""には、ハイパースレッディングを有効にすることを検討してください。"" msgid ""Hyper-V"" msgstr ""Hyper-V"" msgid ""Hypervisor"" msgstr ""ハイパーバイザー"" msgid """" ""I logged into the cloud controller and was able to both <placeholder-1/> and "" ""SSH into the problematic compute node which seemed very odd. Usually if I "" ""receive this type of alert, the compute node has totally locked up and would "" ""be inaccessible."" msgstr """" ""実に奇妙なことだが、私はクラウドコントローラーにログインし、問題のコンピュー"" ""トノードに <placeholder-1/> と SSH の両方を実行できた。通常、この種の警告を受"" ""け取ると、コンピュートノードは完全にロックしていてアクセス不可になる。"" msgid """" ""I looked at the status of both NICs in the bonded pair and saw that neither "" ""was able to communicate with the switch port. Seeing as how each NIC in the "" ""bond is connected to a separate switch, I thought that the chance of a "" ""switch port dying on each switch at the same time was quite improbable. I "" ""concluded that the 10gb dual port NIC had died and needed replaced. I "" ""created a ticket for the hardware support department at the data center "" ""where the node was hosted. I felt lucky that this was a new node and no one "" ""else was hosted on it yet."" msgstr """" ""私は bonding ペアの両方の NIC の状態を確認し、両方ともスイッチポートへの通信"" ""ができないことを知った。bond 中の各 NIC が異なるスイッチに接続されていること"" ""を知り、私は、各スイッチのスイッチポートが同時に死ぬ可能性はまずないと思っ"" ""た。私は 10Gb デュアルポート NIC が死んで、交換が必要だと結論づけた。私は、そ"" ""のノードがホスティングされているデータセンターのハードウェアサポート部門に宛"" ""てたチケットを作成した。私は、それが新しいノードで、他のインスタンスがまだそ"" ""のノード上でホスティングされていないことを幸運に思った。"" msgid """" ""I reviewed the <code>nova</code> database and saw the instance's entry in "" ""the <code>nova.instances</code> table. The image that the instance was using "" ""matched what virsh was reporting, so no inconsistency there."" msgstr """" ""私は <code>nova</code> データベースを見直し、<code>nova.instances</code> テー"" ""ブル中の当該インスタンスのレコードを見た。インスタンスが使用しているイメージ"" ""は virsh が報告したものと一致した。よって、ここでは矛盾は発見されなかった。"" msgid """" ""I was on-site in Kelowna, British Columbia, Canada setting up a new "" ""OpenStack cloud. The deployment was fully automated: Cobbler deployed the OS "" ""on the bare metal, bootstrapped it, and Puppet took over from there. I had "" ""run the deployment scenario so many times in practice and took for granted "" ""that everything was working."" msgstr """" ""私は、新しい OpenStack クラウドのセットアップをするため、カナダのブリティッ"" ""シュコロンビア州ケロウナの現地にいた。デプロイ作業は完全に自動化されていた。"" ""Cobbler が物理マシンに OS をデプロイし、それを起動し、その後は Puppet が引き"" ""継いだ。私は練習で幾度もデプロイシナリオを実行してきたし、もちろん全て正常で"" ""あった。"" msgid """" ""I was totally confused at this point, so I texted our network admin to see "" ""if he was available to help. He logged in to both switches and immediately "" ""saw the problem: the switches detected spanning tree packets coming from the "" ""two compute nodes and immediately shut the ports down to prevent spanning "" ""tree loops: <placeholder-1/>"" msgstr """" ""私はこの時点で完全に混乱した。よって、私はネットワーク管理者に対して、私を助"" ""けられるか聞いてみるためメールした。彼は両方のスイッチにログインし、すぐに問"" ""題を発見した。そのスイッチは２つのコンピュートノードから来たスパニングツリー"" ""パケットを検出し、スパニングツリーループを回避するため、即時にそれらのポート"" ""をダウンさせたのだ。<placeholder-1/>"" msgid ""IBM (Storwize family/SVC, XIV)"" msgstr ""IBM (Storwize family/SVC, XIV)"" msgid ""ID"" msgstr ""ID"" msgid ""IP Address Planning"" msgstr ""IP アドレス計画"" msgid """" ""IP addresses for public-facing interfaces on the controller nodes (which end "" ""users will access the OpenStack services)"" msgstr """" ""コントローラーノード上のパブリックインターフェースの IP アドレス (エンドユー"" ""ザーが OpenStack サービスにアクセスするのに使用)"" msgid ""Icehouse"" msgstr ""Icehouse"" msgid ""Identity"" msgstr ""認証"" msgid ""Identity Service (keystone) driver"" msgstr ""Identity Service (keystone) のドライバー"" msgid ""Identity service"" msgstr ""Identity"" msgid """" ""If OpenStack is not set up in the right way, it is simple to have scenarios "" ""in which users are unable to contact their instances due to having only an "" ""incorrect DNS alias. Despite this, EC2 compatibility can assist users "" ""migrating to your cloud."" msgstr """" ""もしOpenStakcが正しく構成されていない場合、正しくないDNSエイリアスしな無いた"" ""め、ユーザはインスタンスへアクセスできないというシンプルな事態が生じます。そ"" ""れにもかかわらず、EC2互換はユーザをあなたのクラウドへ移行することをアシストし"" ""ます。"" msgid ""If a compute node fails, instances are usually easily recoverable."" msgstr """" ""コンピュートホストが故障した場合、通常インスタンスは簡単に復旧できます。"" msgid ""If a compute node fails, the instances running on that node are lost."" msgstr """" ""コンピュートノードが故障すると、そのノードで実行中のインスタンスが失われてし"" ""まいます。"" msgid """" ""If a dedicated remote access controller chip is included in servers, often "" ""these are on a separate network."" msgstr """" ""専用のリモートアクセスコントローラーチップがサーバーに搭載されている場合、多"" ""くの場合、これらは独立したネットワーク上に置かれます。"" msgid ""If additional storage is required, this option does not scale."" msgstr ""追加ストレージが必要な場合、このオプションはスケールしません。"" msgid """" ""If an instance does not boot, meaning <code>virsh list</code> never shows "" ""the instance as even attempting to boot, do the following on the compute "" ""node:"" msgstr """" ""インスタンスがブートしなければ、つまりブートしようとしても <code>virsh list</"" ""code> がインスタンスを表示しなければ、コンピュートノードにおいて以下のとおり"" ""実行します。"" msgid """" ""If ephemeral or block storage is external to the compute node, this network "" ""is used."" msgstr """" ""一時ディスクまたはブロックストレージがコンピュートノード以外にある場合、この"" ""ネットワークが使用されます。"" msgid """" ""If many users will make multiple requests, make sure that the CPU load for "" ""the cloud controller can handle it."" msgstr """" ""もし多数のユーザが複数のリクエストを発行するのであれば、クラウドコントロー"" ""ラーがそれらを扱えるよう、CPU負荷を確認してください。"" msgid """" ""If the instance fails to resolve the hostname, you have a DNS problem. For "" ""example:"" msgstr """" ""もしインスタンスがホスト名の解決に失敗するのであれば、DNSに問題があります。例"" ""えば、"" msgid """" ""If the networking performance of the basic layout is not enough, you can "" ""move to <xref linkend=\""fig1-2\""/>, which provides 2 10G network links to "" ""all instances in the environment as well as providing more network bandwidth "" ""to the storage layer. bandwidth obtaining maximum performance"" msgstr """" ""基本レイアウトのネットワークパフォーマンスが十分でない場合には、<xref "" ""linkend=\""fig1-2\""/> に移行することができます。このレイアウトでは、環境内の全"" ""インスタンスに 10G のネットワークリンクを2 つ提供するだけでなく、ストレージ層"" ""にさらなるネットワーク帯域幅を提供し、パフォーマンスを最大化します。"" msgid """" ""If this is the first time you are deploying a cloud infrastructure in your "" ""organization, after reading this section, your first conversations should be "" ""with your networking team. Network usage in a running cloud is vastly "" ""different from traditional network deployments and has the potential to be "" ""disruptive at both a connectivity and a policy level.<indexterm class="" ""\""singular\""><primary>cloud computing</primary><secondary>vs. traditional "" ""deployments</secondary></indexterm>"" msgstr """" ""これがあなたの組織で初めてのクラウド基盤構築であれば、この章を読んだ後、最初"" ""にあなたの（組織の）ネットワーク管理チームと相談すべきです。クラウド運用にお"" ""けるネットワークの使用は伝統的なネットワーク構築とはかなり異なり、接続性とポ"" ""リシーレベルの両面で破壊的な結果をもたらす可能性があります。<indexterm class="" ""\""singular\""><primary>クラウドコンピューティング</primary><secondary>VS. 伝統"" ""的実装</secondary></indexterm>"" msgid """" ""If you are not using shared storage, you can use the <code>--block-migrate</"" ""code> option:"" msgstr """" ""共有ストレージを使用していない場合、<code>--block-migrate</code> オプションを"" ""使用できます。"" msgid """" ""If you are using <literal>nova-network</literal> and multi-host networking "" ""in your cloud environment, <literal>nova-compute</literal> still requires "" ""direct access to the database.<indexterm class=\""singular\""><primary>multi-"" ""host networking</primary></indexterm>"" msgstr """" ""あなたのクラウド環境で、<literal>nova-network</literal>とマルチホストネット"" ""ワークを使用している場合、 <literal>nova-compute</literal>は現在もデータベー"" ""スへの直接アクセスを必要とします。<indexterm class=\""singular\""><primary>マル"" ""チホストネットワーク</primary></indexterm>"" msgid """" ""If you are using cinder, run the following command to see a similar listing:"" msgstr """" ""cinder を使用している場合は、次のコマンドを実行して同様の一覧を表示します。"" msgid """" ""If you can't ping the IP address of the compute node, the problem is between "" ""the instance and the compute node. This includes the bridge connecting the "" ""compute node's main NIC with the vnet NIC of the instance."" msgstr """" ""もしコンピュートノードのIPアドレスにpingできないのであれば、問題はインスタン"" ""スとコンピュートノード間にあります。これはコンピュートノードの物理NICとインス"" ""タンス vnet NIC間のブリッジ接続を含みます。"" msgid """" ""If you can't, try pinging the IP address of the compute node where the "" ""instance is hosted. If you can ping this IP, then the problem is somewhere "" ""between the compute node and that compute node's gateway."" msgstr """" ""もしそれができないのであれば、インスタンスがホストされているコンピュートノー"" ""ドのIPアドレスへpingを試行してください。もしそのIPにpingできるのであれば、そ"" ""のコンピュートノードと、ゲートウェイ間のどこかに問題があります。"" msgid """" ""If you deploy only the OpenStack Compute Service (nova), your users do not "" ""have access to any form of persistent storage by default. The disks "" ""associated with VMs are \""ephemeral,\"" meaning that (from the user's point "" ""of view) they effectively disappear when a virtual machine is terminated."" ""<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>ephemeral</secondary></indexterm>"" msgstr """" ""OpenStack Compute Service (nova) のみをデプロイする場合、デフォルトでは、どの"" ""ような形式の永続ストレージにもアクセスできません。仮想マシンに関連付けされて"" ""いるディスクは一時的です。つまり、(ユーザー視点から) 仮想マシンが終了されると"" ""このストレージは効率的に表示がなくなります。<indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>一時</secondary></indexterm>"" msgid """" ""If you have an OpenStack Object Storage service, we recommend using this as "" ""a scalable place to store your images. You can also use a file system with "" ""sufficient performance or Amazon S3—unless you do not need the ability to "" ""upload new images through OpenStack."" msgstr """" ""OpenStack Storageサービスがある場合は、イメージを保存するためにスケーラブルな"" ""場所を利用する事を推奨します。また、OpenStackをとおして新しいイメージをアップ"" ""ロードする必要がない場合を除いて、十分な性能を備えたファイルシステムかAmazon "" ""S3を使用する事もできます。"" msgid """" ""If you need even newer versions of the clients, pip can install directly "" ""from the upstream git repository using the <code>-e</code> flag. You must "" ""specify a name for the Python egg that is installed. For example:"" msgstr """" ""もし新しいバージョンのクライアントが必要な場合、<code>-e</code>フラグを指定す"" ""ることで、アップストリームのgitリポジトリから直接導入できます。その際は、"" ""Python egg名を指定しなければいけません。例えば、"" msgid ""If you only want to backup a single database, you can instead run:"" msgstr """" ""もし、単一のデータベースのみバックアップする場合は次のように実行します。"" msgid """" ""If you run FlatDHCPManager, one bridge is on the compute node. If you run "" ""VlanManager, one bridge exists for each VLAN."" msgstr """" ""もしFlatDHCPManagerを使っているのであれば、ブリッジはコンピュートノード上に一"" ""つです。VlanManagerであれば、VLANごとにブリッジが存在します。"" msgid """" ""If you support the EC2 API on your cloud, you should also install the "" ""euca2ools package or some other EC2 API tool so that you can get the same "" ""view your users have. Using EC2 API-based tools is mostly out of the scope "" ""of this guide, though we discuss getting credentials for use with it."" msgstr """" ""クラウド上で EC2 API をサポートする場合には、ユーザーと同じビューを表示できる"" ""ように、euca2ools パッケージまたはその他の EC2 API ツールもインストールする必"" ""要があります。EC2 API ベースのツールの使用に関する内容の大半は本ガイドの対象"" ""範囲外となりますが、このツールで使用する認証情報の取得方法についての説明は記"" ""載しています。"" msgid """" ""If you use separate compute and storage hosts, you can treat your compute "" ""hosts as \""stateless.\"" As long as you don't have any instances currently "" ""running on a compute host, you can take it offline or wipe it completely "" ""without having any effect on the rest of your cloud. This simplifies "" ""maintenance for the compute hosts."" msgstr """" ""コンピュートホストとストレージホストを分離して使用すると、コンピュートホスト"" ""を「ステートレス」として処理できます。コンピュートホストで実行中のインスタン"" ""スがなければ、クラウドの他のアイテムに影響を与えることなく、ノードをオフライ"" ""ンにしたり、完全に消去したりすることができます。これにより、コンピュートホス"" ""トのメンテナンスが簡素化されます。"" msgid """" ""If you use the GlusterFS native client, no virtual IP is needed, since the "" ""client knows all about nodes after initial connection and automatically "" ""routes around failures on the client side."" msgstr """" ""GlusterFS ネイティブクライアントを使用する場合には、そのクライアントは初回接"" ""続後にノードに関する全情報を認識し、クライアント側の障害を迂回するように自動"" ""的にルーティングするため、仮想 IP は必要ありません。"" msgid """" ""If you use the NFS or SMB adaptor, you will need a virtual IP on which to "" ""mount the GlusterFS volumes."" msgstr """" ""NFS または SMB のアダプターを使用する場合には、GlusterFS ボリュームをマウント"" ""する仮想 IP が必要となります。"" msgid """" ""If you want to manage your object and block storage within a single system, "" ""or if you want to support fast boot-from-volume, you should consider Ceph."" msgstr """" ""単一システムでオブジェクトストレージとブロックストレージを管理する場合、また"" ""はボリュームから素早く起動するサポートが必要な場合、Ceph の使用を検討してくだ"" ""さい。"" msgid """" ""If you want to support shared-storage live migration, you need to configure "" ""a distributed file system.<indexterm class=\""singular\""><primary>compute "" ""nodes</primary><secondary>file system choice</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>file systems</"" ""primary><secondary>choice of</secondary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>file system choice</"" ""secondary></indexterm>"" msgstr """" ""共有ストレージのライブマイグレーションをサポートする場合、分散ファイルシステ"" ""ムを設定する必要があります。<indexterm class=\""singular\""><primary>コンピュー"" ""トノード</primary><secondary>ファイルシステムの選択</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ファイルシステム</"" ""primary><secondary>選択</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>ファイルシステムの選択</"" ""secondary></indexterm>"" msgid """" ""If you're encountering any sort of networking difficulty, one good initial "" ""sanity check is to make sure that your interfaces are up. For example:"" msgstr """" ""もしあなたがネットワークの問題に直面した場合、まず最初にするとよいのは、イン"" ""ターフェイスがUPになっているかを確認することです。例えば、"" msgid ""Image Catalog and Delivery"" msgstr ""イメージカタログと配布"" msgid ""Image service"" msgstr ""Image サービス"" msgid ""Image usage"" msgstr ""イメージ使用量"" msgid ""Image-management services"" msgstr ""イメージ管理サービス"" msgid ""Image: Ubuntu 12.04 LTS"" msgstr ""イメージ: Ubuntu 12.04 LTS"" msgid ""Images"" msgstr ""イメージ"" msgid ""Importance: &lt;Bug impact&gt;"" msgstr ""Importance: &lt;バグ影響度&gt;"" msgid """" ""In <filename>nova.conf</filename>, <code>vlan_interface</code> specifies "" ""what interface OpenStack should attach all VLANs to. The correct setting "" ""should have been: <placeholder-1/>."" msgstr """" ""<filename>nova.conf</filename> 中で、<code>vlan_interface</code> は "" ""OpenStack が全ての VLAN をアタッチすべきインターフェースがどれかを指定する。"" ""正しい設定はこうだった: <placeholder-1/>"" msgid """" ""In OpenStack user interfaces and documentation, a group of users is referred "" ""to as a <glossterm>project</glossterm> or <glossterm>tenant</glossterm>. "" ""These terms are interchangeable.<indexterm class=\""singular\""><primary>user "" ""management</primary><secondary>terminology for</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>tenant</"" ""primary><secondary>definition of</secondary></indexterm><indexterm class="" ""\""singular\""><primary>projects</primary><secondary>definition of</"" ""secondary></indexterm>"" msgstr """" ""OpenStack ユーザーインターフェースとドキュメントでは、ユーザーのグループは "" ""<glossterm>プロジェクト</glossterm> または <glossterm>テナント</glossterm> と"" ""呼ばれます。これらの用語は同義です。<indexterm class=\""singular\""><primary>"" ""ユーザー管理</primary><secondary>用語</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>テナント</primary><secondary>定義</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>プロジェクト</"" ""primary><secondary>定義</secondary></indexterm>"" msgid """" ""In a default OpenStack deployment, there is a single <code>nova-network</"" ""code> service that runs within the cloud (usually on the cloud controller) "" ""that provides services such as network address translation (NAT), DHCP, and "" ""DNS to the guest instances. If the single node that runs the <code>nova-"" ""network</code> service goes down, you cannot access your instances, and the "" ""instances cannot access the Internet. The single node that runs the "" ""<literal>nova-network</literal> service can become a bottleneck if excessive "" ""network traffic comes in and goes out of the cloud.<indexterm class="" ""\""singular\""><primary>networks</primary><secondary>multi-host</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>multi-host networking</"" ""primary></indexterm><indexterm class=\""singular\""><primary>legacy networking "" ""(nova)</primary><secondary>benefits of multi-host networking</secondary></"" ""indexterm>"" msgstr """" ""デフォルトの OpenStack デプロイメントでは、単一の <code>nova-network</code> "" ""サービスがクラウド内 (通常はクラウドコントローラー) で実行され、ネットワーク"" ""アドレス変換 (NAT)、DHCP、DNS などのサービスをゲストインスタンスにd提供しま"" ""す。<code>nova-network</code> サービスを実行する単一のノードが停止した場合に"" ""は、インスタンスにアクセスできなくなり、またインスタンスはインターネットにア"" ""クセスできません。クラウドでネットワークトラフィックが過剰に送受信されると、"" ""<literal>nova-network</literal> サービスを実行する単一ノードがボトルネックと"" ""なる可能性があります。<indexterm class=\""singular\""><primary>ネットワーク</"" ""primary><secondary>マルチホスト</secondary></indexterm><indexterm class="" ""\""singular\""><primary>マルチホストネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>レガシーネットワーク(nova)</"" ""primary><secondary>マルチホストネットワークの利点</secondary></indexterm>"" msgid """" ""In addition to the open source technologies, there are a number of "" ""proprietary solutions that are officially supported by OpenStack Block "" ""Storage.<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>storage driver support</secondary></indexterm> They are "" ""offered by the following vendors:"" msgstr """" ""オープンソースのテクノロジーに加え、OpenStack Block Storage で正式にサポート"" ""される専用ソリューションが多数存在します。<indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>ストレージドライバーのサポート</"" ""secondary></indexterm>以下のベンダーによりサポートされています。"" msgid """" ""In addition, consider remote power control as well. While IPMI usually "" ""controls the server's power state, having remote access to the PDU that the "" ""server is plugged into can really be useful for situations when everything "" ""seems wedged."" msgstr """" ""さらに、リモート電源管理装置も検討してください。通常、IPMI はサーバーの電源状"" ""態を制御しますが、サーバーが接続されている PDU にリモートアクセスできれば、す"" ""べてが手詰まりに見えるような状況で非常に役に立ちます。"" msgid """" ""In general, the questions you should ask when selecting storage are as "" ""follows:"" msgstr ""一般的に、ストレージを選択する際に以下の点を考慮する必要があります。"" msgid """" ""In our experience, most operators don't sit right next to the servers "" ""running the cloud, and many don't necessarily enjoy visiting the data "" ""center. OpenStack should be entirely remotely configurable, but sometimes "" ""not everything goes according to plan.<indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>remote management</"" ""secondary></indexterm>"" msgstr """" ""経験上、多くのオペレーターはクラウドを動かすサーバのそばにいるわけではありま"" ""せんし、多くの人が必ずしも楽しんでデータセンターに訪問してるわけではありませ"" ""ん。OpenStackは、完全にリモート設定できるはずですが、計画通りにいかないことも"" ""あります。<indexterm class=\""singular\""><primary>プロビジョニング/デプロイメ"" ""ント</primary><secondary>遠隔管理</secondary></indexterm>"" msgid """" ""In some cases, some operations should be restricted to administrators only. "" ""Therefore, as a further example, let us consider how this sample policy file "" ""could be modified in a scenario where we enable users to create their own "" ""flavors:"" msgstr """" ""いくつかの場合では、いくつかの操作を管理者のみに制限すべきです。そこで、次の"" ""例では、ユーザーが自分のフレーバーを作成できるようにするシナリオの場合に、こ"" ""のサンプルのポリシーファイルをどのように変更すればよいかを示します。"" msgid """" ""In the <literal>[token]</literal> section, configure the UUID token provider "" ""and SQL driver:"" msgstr """" ""<literal>[token]</literal> セクションに、UUID トークンプロバイダーと SQL ドラ"" ""イバーを設定します。"" msgid """" ""In the previous version of OpenStack, all <literal>nova-compute</literal> "" ""services required direct access to the database hosted on the cloud "" ""controller. This was problematic for two reasons: security and performance. "" ""With regard to security, if a compute node is compromised, the attacker "" ""inherently has access to the database. With regard to performance, "" ""<literal>nova-compute</literal> calls to the database are single-threaded "" ""and blocking. This creates a performance bottleneck because database "" ""requests are fulfilled serially rather than in parallel.<indexterm class="" ""\""singular\""><primary>conductors</primary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>conductor "" ""services</secondary></indexterm>"" msgstr """" ""以前のバージョンのOpenStackではすべての<literal>nova-compute</literal>サービ"" ""スはクラウドコントローラーに搭載されたデータベースに直接アクセスする必要があ"" ""りました。これはセキュリティとパフォーマンスという2つの問題を抱えていました。"" ""セキュリティに関してはもしコンピュートノードに侵入された場合、アタッカーは"" ""データベースにアクセスできてしまいます。パフォーマンスに関しては、"" ""<literal>nova-compute</literal>はデータベースの呼び出しをシングルスレッドで行"" ""い、他の呼び出しをブロックする点です。データベースリクエストはシリアルリクエ"" ""ストよりパラレルリクエストの方が効率がいいのでこの点はパフォーマンスのボトル"" ""ネックになります。<indexterm class=\""singular\""><primary>コンダクター</"" ""primary></indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>コンダクターサービス</secondary></indexterm>"" msgid """" ""In the remainder of this guide, we assume that you have successfully "" ""deployed an OpenStack cloud and are able to perform basic operations such as "" ""adding images, booting instances, and attaching volumes."" msgstr """" ""このガイドの残りの部分では、OpenStackクラウドの構成が無事に成功し、イメージの"" ""追加、インスタンスの起動、ボリュームの追加が行えるようになったとします。"" msgid """" ""In this chapter, we discuss some of the choices you need to consider when "" ""building out your compute nodes. Compute nodes form the resource core of the "" ""OpenStack Compute cloud, providing the processing, memory, network and "" ""storage resources to run instances."" msgstr """" ""本章では、コンピュートノードの構築時に考慮する必要のある選択肢について説明し"" ""ます。コンピュートノードは、OpenStack Compute クラウドのリソースコアを構成"" ""し、プロセッシング、メモリー、ネットワーク、ストレージの各リソースを提供して"" ""インスタンスを実行します。"" msgid """" ""In this chapter, we'll give some examples of network implementations to "" ""consider and provide information about some of the network layouts that "" ""OpenStack uses. Finally, we have some brief notes on the networking services "" ""that are essential for stable operation."" msgstr """" ""この章では、いくつかのネットワーク構成の例を挙げながら、OpenStackを使用した"" ""ネットワークレイアウトについての情報を提供します。最後に、安定稼働のたの重要"" ""な音とトワークサービスに関する注意事項を記載します。"" msgid ""In this example, these locations have the following IP addresses:"" msgstr ""例では、この環境には以下のIPアドレスが存在します"" msgid """" ""In this instance, having an out-of-band access into nodes running OpenStack "" ""components is a boon. The IPMI protocol is the de facto standard here, and "" ""acquiring hardware that supports it is highly recommended to achieve that "" ""lights-out data center aim."" msgstr """" ""この場合、OpenStack が動くノードに対して外側からアクセスできるようにすること"" ""が重要です。ここでは、IPMIプロトコルが事実上標準となっています。完全自動の"" ""データセンタを実現するために、IPMIをサポートしたハードウェアを入手することを"" ""強く推奨します。"" msgid """" ""In this option, each compute node is specified with a significant amount of "" ""disk space, but a distributed file system ties the disks from each compute "" ""node into a single mount."" msgstr """" ""このオプションでは、各コンピュートノードに、多くのディスク容量が指定されてい"" ""ますが、分散ファイルシステムにより、それぞれのコンピュートノードからのディス"" ""クが 1 つのマウントとしてまとめられます。"" msgid """" ""In this option, each compute node is specified with enough disks to store "" ""the instances it hosts.<indexterm class=\""singular\""><primary>file systems</"" ""primary><secondary>nonshared</secondary></indexterm>"" msgstr """" ""このオプションでは、ホストするインスタンスを格納するのに十分なディスク容量が"" ""各コンピュートノードに指定されます。<indexterm class=\""singular\""><primary>"" ""ファイルシステム</primary><secondary>非共有</secondary></indexterm>"" msgid """" ""In this option, the disks storing the running instances are hosted in "" ""servers outside of the compute nodes.<indexterm class=\""singular"" ""\""><primary>shared storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>file systems</primary><secondary>shared</secondary></indexterm>"" msgstr """" ""このオプションでは、実行中のインスタンスを格納するディスクはコンピュートノー"" ""ド外のサーバーでホストされます。<indexterm class=\""singular\""><primary>共有ス"" ""トレージ</primary></indexterm><indexterm class=\""singular\""><primary>ファイル"" ""システム</primary><secondary>共有</secondary></indexterm>"" msgid ""In-band remote management"" msgstr ""帯域内リモート管理"" msgid ""In-memory key-value Store (a simplified internal storage structure)"" msgstr ""メモリ内のキーバリュー型ストア（シンプルな内部ストレージ構造）"" msgid """" ""Indicates which resources to use first; for example, spreading out where "" ""instances are launched based on an algorithm"" msgstr """" ""どのリソースを最初に使用するかを示します。例えば、インスタンスをどこで起動す"" ""るかをアルゴリズムに乗っ取って展開します。"" msgid """" ""Indicates which users can do what actions on certain cloud resources; quota "" ""management is spread out among services, however<indexterm class=\""singular"" ""\""><primary>authentication</primary></indexterm>"" msgstr """" ""ある特定のクラウドリソースで誰が何をしようとしているか示します。しかし、ク"" ""オータ管理は全体のサービスに展開されます。<indexterm class=\""singular"" ""\""><primary>認証</primary></indexterm>"" msgid ""Initial deployment"" msgstr ""初期デプロイメント"" msgid """" ""Initially, the connection setup should revolve around keeping the "" ""connectivity simple and straightforward in order to minimize deployment "" ""complexity and time to deploy. The deployment shown in <xref linkend="" ""\""fig1-1\""/> aims to have 1 10G connectivity available to all compute nodes, "" ""while still leveraging bonding on appropriate nodes for maximum performance."" msgstr """" ""デプロイメントの複雑度と所要時間を最小限に抑えるためには、初めに、接続性を単"" ""純かつ簡潔に保つことを中心に接続の設定を展開する必要があります。<xref "" ""linkend=\""fig1-1\""/> に示したデプロイメントでは、全コンピュートノードに 10G "" ""の接続を 1 つずつ提供する一方で、適切なノードにはボンディングを活用してパ"" ""フォーマンスを最大化することを目的としています。"" msgid ""Injected file content bytes"" msgstr ""注入ファイルのコンテンツ (バイト)"" msgid ""Injected file path bytes"" msgstr ""注入ファイルのパス (バイト)"" msgid ""Injected files"" msgstr ""注入ファイル"" msgid ""Inspecting API Calls"" msgstr ""API コールの検査"" msgid ""Inspecting and Recovering Data from Failed Instances"" msgstr ""故障したインスタンスからの検査とデータ復旧"" msgid ""Installing the Tools"" msgstr ""ツールの導入"" msgid """" ""Installs a virtual environment and runs tests.<indexterm class=\""singular"" ""\""><primary>script modules</primary></indexterm>"" msgstr """" ""仮想環境をインストールし、テストを実行します。<indexterm class=\""singular"" ""\""><primary>スクリプトモジュール</primary></indexterm>"" msgid ""Instance \""ignores\"" the response and re-sends the renewal request."" msgstr ""インスタンスはそのレスポンスを「無視」して、更新リクエストを再送する。"" msgid ""Instance Boot Failures"" msgstr ""インスタンスの起動失敗"" msgid ""Instance Storage Solutions"" msgstr ""インスタンスストレージのソリューション"" msgid """" ""Instance begins sending a renewal request to <code>255.255.255.255</code> "" ""since it hasn't heard back from the cloud controller."" msgstr """" ""インスタンスはクラウドコントローラーからのレスポンスを受信しなかったため、更"" ""新リクエストを<code>255.255.255.255</code>に送信し始める。"" msgid ""Instance snapshots"" msgstr ""インスタンスのスナップショット"" msgid ""Instance tries to renew IP."" msgstr ""インスタンスはIPアドレスを更新しようとする。"" msgid ""Instances"" msgstr ""インスタンス"" msgid ""Instances in the Database"" msgstr ""データベースにあるインスタンス"" msgid ""Intelligent Alerting"" msgstr ""インテリジェントなアラート"" msgid ""Internal network connectivity"" msgstr ""内部ネットワーク接続性"" msgid ""Introduction to OpenStack"" msgstr ""OpenStack の概要"" msgid ""Is_Public"" msgstr ""Is_Public"" msgid """" ""Isolated tenant networks implement some form of isolation of layer 2 traffic "" ""between distinct networks. VLAN tagging is key concept, where traffic is "" ""“tagged” with an ordinal identifier for the VLAN. Isolated network "" ""implementations may or may not include additional services like DHCP, NAT, "" ""and routing."" msgstr """" ""独立テナントネットワークは個々のネットワーク間のレイヤー2トラフィックをいくつ"" ""かの方法で分離する事で実装します。タグVLANはキーコンセプトでトラフィックをど"" ""こに流すかを”タグ”で決定します。独立テナントネットワークにはDHCPやNAT、ルー"" ""ティングと言った追加のサービスが含まれるかもしれませんし、含まれないかもしれ"" ""ません。"" msgid ""Issues with Live Migration"" msgstr ""ライブマイグレーションに関する問題"" msgid """" ""It is also possible to add project members and adjust the project quotas. "" ""We'll discuss those actions later, but in practice, it can be quite "" ""convenient to deal with all these operations at one time."" msgstr """" ""プロジェクトメンバーの追加やプロジェクトのクォータの調節も可能です。このよう"" ""なアクションについては後ほど説明しますが、実際にこれらの操作を扱うと非常に便"" ""利です。"" msgid """" ""It is also possible to run multiple hypervisors in a single deployment using "" ""host aggregates or cells. However, an individual compute node can run only a "" ""single hypervisor at a time.<indexterm class=\""singular"" ""\""><primary>hypervisors</primary><secondary>running multiple</secondary></"" ""indexterm>"" msgstr """" ""ホストアグリゲートやセルを使用すると、1 つのデプロイメントで複数のハイパーバ"" ""イザーを実行することも可能です。しかし、個別のコンピュートノードでは 1 度につ"" ""き 1 つのハイパーバイザーしか実行することができません。<indexterm class="" ""\""singular\""><primary>hypervisors</primary><secondary>複数実行</secondary></"" ""indexterm>"" msgid """" ""It is important to note that powering off an instance does not terminate it "" ""in the OpenStack sense."" msgstr """" ""注意すべき大事な点は、インスタンスの電源オフは、OpenStack 的な意味でのインス"" ""タンスの終了ではないということです。"" msgid ""It is possible to define other roles, but doing so is uncommon."" msgstr ""他の役割を定義できますが、一般的にはそうしません。"" msgid ""It may be possible to share the external storage for other purposes."" msgstr ""外部ストレージを他の用途と共有できる可能性があります。"" msgid """" ""It turns out the reason that this compute node locked up was a hardware "" ""issue. We removed it from the DAIR cloud and called Dell to have it "" ""serviced. Dell arrived and began working. Somehow or another (or a fat "" ""finger), a different compute node was bumped and rebooted. Great."" msgstr """" ""コンピュートノードがロックアップした原因はハードウェアの問題だったことが判明"" ""した。我々はそのハードウェアを DAIR クラウドから取り外し、修理するよう Dell "" ""に依頼した。Dell が到着して作業を開始した。何とかかんとか（あるいはタイプミ"" ""ス）で、異なるコンピュートノードを落としてしまい、再起動した。素晴らしい。"" msgid """" ""It was funny to read the report. It was full of people who had some strange "" ""network problem but didn't quite explain it in the same way."" msgstr """" ""レポートを読むのは楽しかった。同じ奇妙なネットワーク問題にあった人々であふれ"" ""ていたが、全く同じ説明はなかった。""""Items to monitor for RabbitMQ include the number of items in each of the "" ""queues and the processing time statistics for the server.""""RabbitMQで監視すべき項目としては、各キューでのアイテムの数と、サーバーでの処"" ""理時間の統計情報があります。""msgid ""Jan 19, 2012"" msgstr ""2012年1月19日""msgid ""Jan 31, 2013"" msgstr ""2013年1月31日""msgid ""Join the OpenStack Community"" msgstr ""OpenStack コミュニティに参加する""msgid ""Jun 22, 2012"" msgstr ""2012年6月22日"" msgid ""Jun 6, 2013"" msgstr ""2013年6月6日"" msgid ""Juno"" msgstr ""Juno""""Just as important as a backup policy is a recovery policy (or at least "" ""recovery testing).""""バックアップポリシーと同じくらい大事なことは、リカバリーポリシーです (少なく"" ""ともリカバリーのテストは必要です)。""msgid ""KVM"" msgstr ""KVM""""KVM is the supported hypervisor of choice for Red Hat Enterprise Linux (and "" ""included in distribution). It is feature complete and free from licensing "" ""charges and restrictions.""""KVM は、Red Hat Enterprise Linux に最適なサポート対象ハイパーバイザーです (ま"" ""た、ディストリビューションにも含まれます)。機能が完成されており、ライセンスの"" ""料金や制限は課せられません。""msgid ""Key pairs"" msgstr ""キーペア"" msgid ""Keystone"" msgstr ""Keystone"" msgid ""Keystone services"" msgstr ""Keystone サービス"" msgid ""Kilo"" msgstr ""Kilo"" msgid ""LDAP (such as OpenLDAP or Microsoft's Active Directory)"" msgstr ""LDAP (OpenLDAP や Microsoft の Active Directory)"" msgid ""LVM"" msgstr ""LVM""""LVM does <emphasis>not</emphasis> provide any replication. Typically, "" ""administrators configure RAID on nodes that use LVM as block storage to "" ""protect against failures of individual hard drives. However, RAID does not "" ""protect against a failure of the entire host.""""LVMはレプリケーションを<emphasis>提供しません</emphasis>。通常、管理者はブ"" ""ロックストレージとしてLVMを利用するホスト上にRAIDを構成し、ここのハードディス"" ""ク障害からブロックストレージを保護します。しかしRAIDではホストそのものの障害"" ""には対応できません。""msgid ""LVM/iSCSI"" msgstr ""LVM/iSCSI""""LVM<indexterm class=\""singular\""><primary>LVM (Logical Volume Manager)</"" ""primary></indexterm>""""LVM<indexterm class=\""singular\""><primary>LVM (Logical Volume Manager)</"" ""primary></indexterm>""msgid ""LXC"" msgstr ""LXC"" msgid ""Large instances"" msgstr ""大きなインスタンス"" msgid ""Lay of the Land"" msgstr ""環境の把握"" msgid ""Liberty"" msgstr ""Liberty"" msgid ""List all default quotas for all tenants, as follows:"" msgstr """" ""全テナントに対するクォータのデフォルト値を全て表示するには、以下のようにしま"" ""す。"" msgid ""List the currently set quota values for a tenant, as follows:"" msgstr ""テナントの現在のクォータ値を一覧表示します。""""Live migration can also be done with nonshared storage, using a feature "" ""known as <emphasis>KVM live block migration</emphasis>. While an earlier "" ""implementation of block-based migration in KVM and QEMU was considered "" ""unreliable, there is a newer, more reliable implementation of block-based "" ""live migration as of QEMU 1.4 and libvirt 1.0.2 that is also compatible with "" ""OpenStack. However, none of the authors of this guide have first-hand "" ""experience using live block migration.<indexterm class=\""singular"" ""\""><primary>block migration</primary></indexterm>""""ライブマイグレーションは、<emphasis>KVM ライブブロックマイグレーション</"" ""emphasis> という機能を使用して、非共有ストレージでも行うことができます。KVM "" ""や QEMU でのブロックベースのマイグレーションは当初、信頼できませんでしたが、"" ""OpenStack との互換性もある QEMU 1.4 および libvirt 1.0.2 では、より新しく、信"" ""頼性の高いブロックベースのライブマイグレーション実装ができるようになっていま"" ""す。ただし、本書の執筆者は、ライブブロックマイグレーションを実際に使用してい"" ""ません。<indexterm class=\""singular\""><primary>ブロックマイグレーション</"" ""primary></indexterm>"" msgid ""Log in as an administrative user."" msgstr ""管理ユーザーとしてログインします。"" msgid ""Logging"" msgstr ""ロギング"" msgid ""Logging and Monitoring"" msgstr ""ロギングと監視""""Logging is detailed more fully in <xref linkend=\""logging_monitoring\""/>. "" ""However, it is an important design consideration to take into account before "" ""commencing operations of your cloud.<indexterm class=\""singular"" ""\""><primary>logging/monitoring</primary><secondary>compute nodes and</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>compute nodes</"" ""primary><secondary>logging</secondary></indexterm>""""ロギングの詳細は、<xref linkend=\""logging_monitoring\""/> で包括的に記載してい"" ""ます。ただし、クラウドの運用を開始する前に、重要な設計に関する事項について考"" ""慮していく必要があります。<indexterm class=\""singular\""><primary>logging/"" ""monitoring</primary><secondary>コンピュートノードおよび</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>ロギング</secondary></indexterm>""""Logical separation within your nova deployment for physical isolation or "" ""redundancy.""""物理的な隔離や冗長性のために、Nova デプロイメントの中で論理的な分離が必要な場"" ""合"" msgid ""Look at your OpenStack service <glossterm>catalog</glossterm>:"" msgstr """" ""それではOpenStack サービス<glossterm>カタログ</glossterm>を見てみましょう。""msgid ""Lustre"" msgstr ""Lustre"" msgid ""MIT CSAIL"" msgstr ""MIT CSAIL"" msgid ""Maintenance, Failures, and Debugging"" msgstr ""メンテナンス、故障およびデバッグ"" msgid ""Managed by…"" msgstr ""管理元"" msgid ""Management Network"" msgstr ""管理ネットワーク"" msgid ""Managing Projects"" msgstr ""プロジェクトの管理"" msgid ""Managing Projects and Users"" msgstr ""プロジェクトとユーザーの管理"" msgid """" ""Many deployments use the SQL database; however, LDAP is also a popular "" ""choice for those with existing authentication infrastructure that needs to "" ""be integrated."" msgstr """" ""多くのデプロイメントで SQL データベースが使われていますが、既存の認証インフラ"" ""とインテグレーションする必要のある環境では、LDAP もポピュラーな選択肢です。"" msgid """" ""Many operators use separate compute and storage hosts. Compute services and "" ""storage services have different requirements, and compute hosts typically "" ""require more CPU and RAM than storage hosts. Therefore, for a fixed budget, "" ""it makes sense to have different configurations for your compute nodes and "" ""your storage nodes. Compute nodes will be invested in CPU and RAM, and "" ""storage nodes will be invested in block storage."" msgstr """" ""多くの運用者はコンピュートホストとストレージホストを分離して使用しています。"" ""コンピュートサービスとストレージサービスには異なる要件があり、コンピュートホ"" ""ストでは通常はストレージホストよりも多くの CPU と RAM が必要です。そのため、"" ""一定の予算の中では、コンピュートホストとストレージホストの構成が異なることは"" ""理にかなっています。コンピュートホストでは、CPU や RAM を、ストレージノードで"" ""はブロックストレージを多く使用します。"" msgid ""May 9, 2013"" msgstr ""2013年5月9日"" msgid ""Memory"" msgstr ""メモリ"" msgid ""Memory: 128 GB"" msgstr ""メモリー: 128 GB"" msgid ""Memory: 32 GB"" msgstr ""メモリー: 32 GB"" msgid ""Memory: 64 GB"" msgstr ""メモリー: 64 GB"" msgid ""Memory_MB"" msgstr ""Memory_MB"" msgid ""Message queue"" msgstr ""メッセージキュー"" msgid ""Message queue services"" msgstr ""メッセージキューサービス"" msgid ""Metadata items"" msgstr ""メタデータ項目"" msgid """" ""Migrations of instances from one node to another are more complicated and "" ""rely on features that may not continue to be developed."" msgstr """" ""ノード間のインスタンスのマイグレーションがより複雑になり、今後開発が継続され"" ""ない可能性のある機能に依存することになります。"" msgid ""Milestone: Milestone the bug was fixed in"" msgstr ""Milestone: このバグの修正が入ったマイルストーン"" msgid ""Model: Dell R620"" msgstr ""モデル: Dell R620"" msgid ""Model: Dell R720xd"" msgstr ""モデル: Dell R720xd"" msgid ""Monitoring"" msgstr ""監視"" msgid ""Monthly"" msgstr ""月次"" msgid ""MooseFS"" msgstr ""MooseFS"" msgid ""More complex to set up."" msgstr ""少し複雑な構成。"" msgid ""More proxies means more bandwidth, if your storage can keep up."" msgstr """" ""ストレージ側の性能が十分であれば、proxy server の増加は帯域の増加になります。"" msgid """" ""Most instances are size m1.medium (two virtual cores, 50 GB of storage)."" msgstr """" ""ほとんどのインスタンスのサイズは m1.medium (仮想コア数2、ストレージ50GB) とし"" ""ます。"" msgid ""Mount the qemu-nbd device."" msgstr ""qemu-nbd デバイスをマウントします。"" msgid ""Multi-Host and Single-Host Networking"" msgstr ""マルチホストあるいはシングルホストネットワーキング"" msgid ""Multi-NIC Provisioning"" msgstr ""マルチNICプロビジョニング"" msgid ""Multithread Considerations"" msgstr ""マルチスレッドの課題"" msgid ""MySQL"" msgstr ""MySQL""""MySQL is used as the database backend for all databases in the OpenStack "" ""environment. MySQL is the supported database of choice for Red Hat "" ""Enterprise Linux (and included in distribution); the database is open "" ""source, scalable, and handles memory well.""""MySQL は、OpenStack 環境の全データベースのデータベースバックエンドとして使用"" ""されます。MySQL は、Red Hat Enterprise Linux に最適なサポート対象データベース"" ""です (また、ディストリビューションにも同梱されています)。このデータベースは、"" ""オープンソースで、拡張が可能な上、メモリーの処理を効率的に行います。"" msgid ""MySQL*"" msgstr ""MySQL*"" msgid ""NFS"" msgstr ""NFS"" msgid ""NFS (default for Linux)"" msgstr ""NFS (Linux でのデフォルト)"" msgid ""NOVA_PASS"" msgstr ""NOVA_PASS"" msgid ""NTP"" msgstr ""NTP"" msgid ""Name"" msgstr ""名前"" msgid ""NeCTAR"" msgstr ""NeCTAR"" msgid ""NetApp"" msgstr ""NetApp"" msgid ""Network"" msgstr ""ネットワーク"" msgid ""Network Configuration"" msgstr ""ネットワーク設定"" msgid ""Network Considerations"" msgstr ""ネットワークの考慮事項"" msgid ""Network Design"" msgstr ""ネットワーク設計"" msgid ""Network Inspection"" msgstr ""ネットワークの検査"" msgid ""Network Topology"" msgstr ""ネットワークトポロジー"" msgid ""Network Troubleshooting"" msgstr ""ネットワークのトラブルシューティング"" msgid """" ""Network configuration is a very large topic that spans multiple areas of "" ""this book. For now, make sure that your servers can PXE boot and "" ""successfully communicate with the deployment server.<indexterm class="" ""\""singular\""><primary>networks</primary><secondary>configuration of</"" ""secondary></indexterm>"" msgstr """" ""ネットワーク設定は、本書でも複数の箇所で取り上げられている大きいトピックで"" ""す。ここでは、お使いのサーバが PXEブートでき、デプロイメントサーバと正常に通"" ""信できることを確認しておいてください。.<indexterm class=\""singular"" ""\""><primary>ネットワーク</primary><secondary>設定</secondary></indexterm>"" msgid ""Network deployment model"" msgstr ""ネットワーク構成モデル"" msgid ""Network manager"" msgstr ""ネットワークマネージャー"" msgid ""Network node"" msgstr ""ネットワークノード"" msgid """" ""Network nodes are responsible for doing all the virtual networking needed "" ""for people to create public or private networks and uplink their virtual "" ""machines into external networks. Network nodes:"" msgstr """" ""ネットワークノードは、ユーザーがパブリックまたはプライベートネットワークを作"" ""成し、仮想マシンを外部ネットワークにアップリンクするために必要なすべての仮想"" ""ネットワーキングを実行する役割を果たします。ネットワークノードは以下のような"" ""操作を実行します。"" msgid ""Network traffic is distributed to the compute nodes."" msgstr ""ネットワークトラフィックをコンピュートノード全体に分散できる。"" msgid ""Network usage (bandwidth and IP usage)"" msgstr ""ネットワーク使用量 (帯域および IP 使用量)"" msgid ""Network: five 10G network ports"" msgstr ""ネットワーク: 10G ネットワークポート x 5"" msgid ""Network: four 10G network ports (For future proofing expansion)"" msgstr ""ネットワーク: 10G ネットワークポート x 4 (将来を保証する拡張性のため)"" msgid ""Network: two 10G network ports"" msgstr ""ネットワーク: 10G のネットワークポート x 2"" msgid ""Networking"" msgstr ""ネットワーク"" msgid ""Networking configuration just for PXE booting"" msgstr ""PXE ブート用のネットワーク設定"" msgid ""Networking deployment options"" msgstr ""ネットワーク構成オプション"" msgid """" ""Networking failure is isolated to the VMs running on the affected hypervisor."" msgstr ""ネットワーク障害は影響を受けるハイパーバイザーのVMに限定されます。"" msgid """" ""Networking in OpenStack is a complex, multifaceted challenge. See <xref "" ""linkend=\""network_design\""/>.<indexterm class=\""singular\""><primary>compute "" ""nodes</primary><secondary>networking</secondary></indexterm>"" msgstr """" ""OpenStack でのネットワークは複雑で、多くの課題があります。<xref linkend="" ""\""network_design\""/>を参照してください。<indexterm class=\""singular"" ""\""><primary>コンピュートノード</primary><secondary>ネットワーキング</"" ""secondary></indexterm>"" msgid ""Networking layout"" msgstr ""ネットワークのレイアウト"" msgid ""Networking service"" msgstr ""ネットワークサービス"" msgid ""Neutron equivalent"" msgstr ""Neutronでの実装"" msgid ""NewValue"" msgstr ""NewValue"" msgid ""Nexenta"" msgstr ""Nexenta"" msgid ""Next, migrate them one by one:"" msgstr ""次に、それらを一つずつマイグレーションします。"" msgid """" ""Next, physically remove the disk from the server and replace it with a "" ""working disk."" msgstr """" ""次に、ディスクを物理的にサーバーから取り外し、正常なディスクと入れ替えます。"" msgid ""Next, redistribute the ring files to the other nodes:"" msgstr ""次に、ring ファイルを他のノードに再配布します。"" msgid """" ""Next, the <code>nova</code> database contains three tables that store usage "" ""information."" msgstr """" ""次に <code>nova</code> データベースは 利用情報に関して3つのテーブルを持ってい"" ""ます。"" msgid ""No DHCP overhead."" msgstr ""DHCPによるオーバーヘッドがありません。"" msgid ""Node connectivity"" msgstr ""ノードの接続性"" msgid ""Node diagrams"" msgstr ""ノードの図"" msgid ""Node types"" msgstr ""ノードのタイプ"" msgid """" ""Not all packets have a size of 1500. Running the <placeholder-1/> command "" ""over SSH might only create a single packets less than 1500 bytes. However, "" ""running a command with heavy output, such as <placeholder-2/> requires "" ""several packets of 1500 bytes."" msgstr """" ""すべてのパケットサイズが 1500 に収まるわけではない。SSH 経由の "" ""<placeholder-1/> コマンド実行は 1500 バイト未満のサイズのパケット１つで収まる"" ""かもしれない。しかし、 <placeholder-2/> のように多大な出力を行うコマンドを実"" ""行する場合、1500 バイトのパケットが複数必要とある。"" msgid ""Nov 29, 2012"" msgstr ""2012年11月29日"" msgid """" ""Now that you see the myriad designs for controlling your cloud, read more "" ""about the further considerations to help with your design decisions."" msgstr """" ""クラウドコントローラの設計は無数にあります、クラウドコントローラの設計の助け"" ""として更なる考慮事項をお読みください。"" msgid """" ""Now you can refer to your token on the command line as <literal>$TOKEN</"" ""literal>."" msgstr """" ""これで、コマンドラインでトークンを <literal>$TOKEN</literal> として参照できる"" ""ようになりました。"" msgid ""Number of Block Storage snapshots allowed per tenant."" msgstr ""テナントごとのブロックストレージスナップショット数"" msgid ""Number of bytes allowed per injected file path."" msgstr ""injected file のパス長の最大バイト数"" msgid ""Number of content bytes allowed per injected file."" msgstr ""injected file あたりの最大バイト数"" msgid """" ""Number of fixed IP addresses allowed per tenant. This number must be equal "" ""to or greater than the number of allowed instances."" msgstr """" ""テナント毎の固定 IP アドレスの最大数。この数はテナント毎の最大インスタンス数"" ""以上にしなければなりません。"" msgid ""Number of floating IP addresses allowed per tenant."" msgstr ""テナントごとの最大 Floating IP 数"" msgid ""Number of injected files allowed per tenant."" msgstr ""injected file の最大数"" msgid ""Number of instance cores allowed per tenant."" msgstr ""テナントごとのインスタンスのコア数"" msgid ""Number of instances allowed per tenant."" msgstr ""テナントごとの最大インスタンス数"" msgid ""Number of key pairs allowed per user."" msgstr ""ユーザーごとの最大キーペア数"" msgid ""Number of metadata items allowed per instance."" msgstr ""インスタンスごとのメタデータ項目数"" msgid ""Number of physical cores"" msgstr ""物理コア数"" msgid ""Number of rules per security group."" msgstr ""セキュリティグループごとのセキュリティルール数"" msgid ""Number of security groups per tenant."" msgstr ""テナントごとのセキュリティグループ数"" msgid ""Number of virtual CPUs presented to the instance."" msgstr ""インスタンスに存在する仮想 CPU 数。"" msgid ""Number of virtual cores per instance"" msgstr ""インスタンスごとの仮想コア数"" msgid """" ""OK, so where is the MTU issue coming from? Why haven't we seen this in any "" ""other deployment? What's new in this situation? Well, new data center, new "" ""uplink, new switches, new model of switches, new servers, first time using "" ""this model of servers… so, basically everything was new. Wonderful. We toyed "" ""around with raising the MTU at various areas: the switches, the NICs on the "" ""compute nodes, the virtual NICs in the instances, we even had the data "" ""center raise the MTU for our uplink interface. Some changes worked, some "" ""didn't. This line of troubleshooting didn't feel right, though. We shouldn't "" ""have to be changing the MTU in these areas."" msgstr """" ""OK。では MTU の問題はどこから来るのか？なぜ我々は他のデプロイでこの問題に遭遇"" ""しなかったのか？この状況は何が新しいのか？えっと、新しいデータセンター、新し"" ""い上位リンク、新しいスイッチ、スイッチの新機種、新しいサーバー、サーバーの新"" ""機種…つまり、基本的に全てが新しいものだった。素晴らしい。我々は様々な領域で "" ""MTU の増加を試してみた。スイッチ、コンピュータのNIC、インスタンスの仮想NIC、"" ""データセンターの上位リンク用のインターフェースのMTUまでいじってみた。いくつか"" ""の変更ではうまくいったが、他はダメだった。やはり、この線の障害対策はうまく"" ""いってないようだった。我々はこれらの領域のMTUは変更すべきではないようだ。"" msgid ""OR"" msgstr ""OR"" msgid ""Object"" msgstr ""オブジェクトストレージ"" msgid ""Object Storage"" msgstr ""オブジェクトストレージ"" msgid ""Object Storage cluster internal communications"" msgstr ""Object Storage クラスタ内の通信"" msgid """" ""Object Storage is very \""chatty\"" among servers hosting data—even a small "" ""cluster does megabytes/second of traffic, which is predominantly, “Do you "" ""have the object?”/“Yes I have the object!” Of course, if the answer to the "" ""aforementioned question is negative or the request times out, replication of "" ""the object begins."" msgstr """" ""オブジェクトストレージは、データをホストするサーバーの中で非常に呼び出しが多"" ""く、小さいクラスターでも一秒に MB 単位のトラフィックがあります。「オブジェク"" ""トがありますか？はい、あります。」当然、この質問に対する答えがNoの場合、また"" ""は要求がタイムアウトした場合、オブジェクトの複製が開始されます。"" msgid """" ""Object Storage's network patterns might seem unfamiliar at first. Consider "" ""these main traffic flows: <indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>storage decisions and</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>containers</primary><secondary>storage decisions "" ""and</secondary></indexterm><indexterm class=\""singular\""><primary>account "" ""server</primary></indexterm><placeholder-1/>"" msgstr """" ""オブジェクトストレージのネットワークパターンは、最初は見慣れないかもしれませ"" ""ん。これらのメイントラフィックの流れを見てみましょう。 <indexterm class="" ""\""singular\""><primary>objects</primary><secondary>ストレージの決定</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>コンテナー</"" ""primary><secondary>ストレージの決定</secondary></indexterm><indexterm class="" ""\""singular\""><primary>アカウントサーバー</primary></indexterm><placeholder-1/"" "">"" msgid ""Object storage"" msgstr ""オブジェクトストレージ"" msgid ""Obtain the tenant ID, as follows:"" msgstr ""テナント ID を取得します。"" msgid ""Oct 12, 2012"" msgstr ""2012年10月12日"" msgid ""Oct 17, 2013"" msgstr ""2013年10月17日"" msgid ""Oct 21, 2010"" msgstr ""2010年10月21日"" msgid ""Off Compute Node Storage—Shared File System"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）"" msgid ""Off compute node storage—shared file system"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）"" msgid """" ""Offers each service's REST API access, where the API endpoint catalog is "" ""managed by the Identity Service"" msgstr """" ""それぞれのサービス用のAPIアクセスを提供します。APIエンドポイントカタログの場"" ""所はIIdentity サービスが管理しています。"" msgid """" ""Often, an extra (such as 1 GB) interface on compute or storage nodes is used "" ""for system administrators or monitoring tools to access the host instead of "" ""going through the public interface."" msgstr """" ""システム管理者や監視ツールがパブリックインターフェース経由の代わりにコン"" ""ピュートノードやストレージノードのアクセスに使用するための追加インターフェー"" ""ス(1GBなど)"" msgid """" ""Oisin Feeley read it, made some edits, and provided emailed feedback right "" ""when we asked."" msgstr """" ""Oisin Feeley は、このマニュアルを読んで、いくつかの編集をし、私たちが問い合わ"" ""せをした際には、E-mailでのフィードバックをくれました。"" msgid ""On Compute Node Storage—Nonshared File System"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）"" msgid ""On Compute Node Storage—Shared File System"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）"" msgid """" ""On Wednesday night we had a fun happy hour with the Austin OpenStack Meetup "" ""group and Racker Katie Schmidt took great care of our group."" msgstr """" ""水曜日の夜、オースチン OpenStack ミートアップグループと楽しく幸せな時間を過ご"" ""し、Racker Katie Schmidt は私たちのグループを素晴らしい世話をしてくれました。"" msgid ""On compute node storage—nonshared file system"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）"" msgid ""On compute node storage—shared file system"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）"" msgid """" ""On each host that will house block storage, an administrator must initially "" ""create a volume group dedicated to Block Storage volumes. Blocks are created "" ""from LVM logical volumes."" msgstr """" ""ブロックストレージを収容する各ホストでは、管理者は事前にブロックストレージ専"" ""用のボリュームグループを作成しておく必要があります。ブロックストレージはLVM論"" ""理ボリュームから作られます。"" msgid """" ""On my last day in Kelowna, I was in a conference call from my hotel. In the "" ""background, I was fooling around on the new cloud. I launched an instance "" ""and logged in. Everything looked fine. Out of boredom, I ran <placeholder-1/"" ""> and all of the sudden the instance locked up."" msgstr """" ""ケロウナの最終日、私はホテルから電話会議に参加していた。その裏で、私は新しい"" ""クラウドをいじっていた。私はインスタンスを１つ起動し、ログインした。全ては正"" ""常に思えた。退屈しのぎに、私は <placeholder-1/> を実行したところ、突然そのイ"" ""ンスタンスがロックアップしてしまった。"" msgid ""On the compute node, add the following to your NRPE configuration:"" msgstr ""コンピュートノード上では、次のようなNRPE設定を追加します。"" msgid ""On the external server:"" msgstr ""外部サーバー上"" msgid ""Once the files are restored, start everything back up:"" msgstr ""ファイルをリストア後、サービスを起動します。"" msgid """" ""One choice that always comes up is whether to virtualize. Some services, "" ""such as <code>nova-compute</code>, <code>swift-proxy</code> and <code>swift-"" ""object</code> servers, should not be virtualized. However, control servers "" ""can often be happily virtualized—the performance penalty can usually be "" ""offset by simply running more of the service."" msgstr """" ""仮想化するかどうかについてはいつも問題になります。 <code>nova-compute</"" ""code>、<code>swift-proxy</code> 、 <code>swift-object</code> といったいくつか"" ""のサーバーは仮想化にすべきではありません。しかし、制御系のサーバについては仮"" ""想化にすると幸せになります。それによる性能のペナルティは単純により多くのサー"" ""ビスを動かす事で相殺する事ができます。"" msgid """" ""One cloud controller acted as a gateway to all compute nodes. VlanManager "" ""was used for the network config. This means that the cloud controller and "" ""all compute nodes had a different VLAN for each OpenStack project. We used "" ""the -s option of <placeholder-1/> to change the packet size. We watched as "" ""sometimes packets would fully return, sometimes they'd only make it out and "" ""never back in, and sometimes the packets would stop at a random point. We "" ""changed <placeholder-2/> to start displaying the hex dump of the packet. We "" ""pinged between every combination of outside, controller, compute, and "" ""instance."" msgstr """" ""１つのクラウドコントローラーが全コンピュートノードのゲートウェイの役割を果た"" ""していた。ネットワーク設定には VlanManager が使われていた。これは、クラウドコ"" ""ントローラーと全コンピュートノードで、各 OpenStack プロジェクトが異なる VLAN "" ""を持つことを意味する。パケットサイズ変更のため、<placeholder-1/> の -s オプ"" ""ションを使用していた。パケットが全て戻ってくる時もあれば、パケットが出ていっ"" ""たきり全く戻って来ない時もあれば、パケットはランダムな場所で止まってしまう時"" ""もある、という状況だった。<placeholder-2/> を変更し、パケットの16進ダンプを表"" ""示するようにした。外部、コントローラー、コンピュート、インスタンスのあらゆる"" ""組み合わせの間で ping を実行した。"" msgid """" ""One of the most complex aspects of an OpenStack cloud is the networking "" ""configuration. You should be familiar with concepts such as DHCP, Linux "" ""bridges, VLANs, and iptables. You must also have access to a network "" ""hardware expert who can configure the switches and routers required in your "" ""OpenStack cloud."" msgstr """" ""OpenStack クラウドの最も複雑な点の一つにネットワーク設定があります。DHCP、"" ""Linux ブリッジ、VLAN、iptables といった考え方をよく理解していなければなりませ"" ""ん。OpenStack クラウドで必要となるスイッチやルータを設定できるネットワーク"" ""ハードウェアの専門家と話をする必要もあります。"" msgid ""OpenStack"" msgstr ""OpenStack"" msgid ""OpenStack API Quick Start"" msgstr ""OpenStack API クイックスタート"" msgid ""OpenStack Admin User Guide"" msgstr ""OpenStack 管理ユーザーガイド"" msgid ""OpenStack Block Storage"" msgstr ""OpenStack Block Storage"" msgid ""OpenStack Block Storage (cinder)"" msgstr ""OpenStack Block Storage (cinder)"" msgid ""OpenStack Cloud Administrator Guide"" msgstr ""OpenStack クラウド管理者ガイド"" msgid ""OpenStack Compute"" msgstr ""OpenStack Compute"" msgid ""OpenStack Compute (nova)"" msgstr ""OpenStack Compute (nova)"" msgid """" ""OpenStack Compute cells are designed to allow running the cloud in a "" ""distributed fashion without having to use more complicated technologies, or "" ""be invasive to existing nova installations. Hosts in a cloud are partitioned "" ""into groups called <emphasis>cells</emphasis>. Cells are configured in a "" ""tree. The top-level cell (\""API cell\"") has a host that runs the <code>nova-"" ""api</code> service, but no <code>nova-compute</code> services. Each child "" ""cell runs all of the other typical <code>nova-*</code> services found in a "" ""regular installation, except for the <code>nova-api</code> service. Each "" ""cell has its own message queue and database service and also runs <code>nova-"" ""cells</code>, which manages the communication between the API cell and child "" ""cells.<indexterm class=\""singular\""><primary>scaling</"" ""primary><secondary>cells and regions</secondary></indexterm><indexterm class="" ""\""singular\""><primary>cells</primary><secondary>cloud segregation</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>region</"" ""primary></indexterm>"" msgstr """" ""OpenStack Compute のセルによって、より複雑な技術を持ち込むことなしに、また既"" ""存のNovaシステムに悪影響を与えることなしに、クラウドを分散された環境で運用す"" ""ることができます。１つのクラウドの中のホストは、<emphasis>セル</emphasis> と"" ""呼ばれるグループに分割されます。セルは、木構造に構成されてます。最上位のセル "" ""(「API セル」) は<code>nova-api</code>サービスを実行するホストを持ちますが、"" ""<code>nova-compute</code> サービスを実行するホストは持ちません。それぞれの子"" ""セルは、<code>nova-api</code>サービス以外の、普通のNovaシステムに見られる他の"" ""すべての典型的な <code>nova-*</code> サービスを実行します。それぞれのセルは自"" ""分のメッセージキューとデータベースサービスを持ち、またAPIセルと子セルの間の通"" ""信を制御する <code>nova-cells</code> サービスを実行します。<indexterm class="" ""\""singular\""><primary>スケーリング</primary><secondary>セルとリージョン</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>セル</"" ""primary><secondary>クラウド分割</secondary></indexterm><indexterm class="" ""\""singular\""><primary>リージョン</primary></indexterm>"" msgid """" ""OpenStack Compute uses a SQL database to store and retrieve stateful "" ""information. MySQL is the popular database choice in the OpenStack community."" ""<indexterm class=\""singular\""><primary>databases</primary><secondary>design "" ""considerations</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>design considerations</primary><secondary>database choice</"" ""secondary></indexterm>"" msgstr """" ""OpenStackコンピュートはステートフルな情報を保存、取得するためにSQLデータベー"" ""スを使用します。MySQLはOpenStackコミュニティでポピュラーな選択です。"" ""<indexterm class=\""singular\""><primary>データベース</primary><secondary>設計"" ""上の考慮事項</secondary></indexterm><indexterm class=\""singular\""><primary>設"" ""計上の考慮事項</primary><secondary>データベースの選択</secondary></indexterm>"" msgid """" ""OpenStack Compute with <literal>nova-network</literal> provides predefined "" ""network deployment models, each with its own strengths and weaknesses. The "" ""selection of a network manager changes your network topology, so the choice "" ""should be made carefully. You also have a choice between the tried-and-true "" ""legacy <literal>nova-network</literal> settings or the <phrase role=\""keep-"" ""together\"">neutron</phrase> project for OpenStack Networking. Both offer "" ""networking for launched instances with different implementations and "" ""requirements.<indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>deployment options</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>networks</primary><secondary>network managers</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>network topology</secondary><tertiary>deployment options</"" ""tertiary></indexterm>"" msgstr """" "" <literal>nova-network</literal>を使用したOpenStackコンピュートはいくつかのあ"" ""らかじめ定義されたネットワークの実装モデルを提供しますが、それぞれ強みと弱み"" ""があります。ネットワークマネージャの選択はあなたのネットワークトポロジーを変"" ""更するので、慎重に選択するべきです。また、実証済みでレガシーな<literal>nova-"" ""network</literal>による設定か、OpenStackネットワーキングのための<phrase role="" ""\""keep-together\"">neutron</phrase>プロジェクトを採用するか決定する必要があり"" ""ます。インスタンスのネットワークの実装方法それぞれに異なる実装と要件がありま"" ""す。<indexterm class=\""singular\""><primary>ネットワーク</primary><secondary>"" ""開発オプション</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ネットワーク</primary><secondary>絵ネットワークマネージャ</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワークデザイン</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>deployment "" ""options</tertiary></indexterm>"" msgid ""OpenStack Configuration Reference"" msgstr ""OpenStack 設定レファレンス"" msgid ""OpenStack End User Guide"" msgstr ""OpenStack エンドユーザーガイド"" msgid ""OpenStack Foundation"" msgstr ""OpenStack Foundation"" msgid ""OpenStack Guides"" msgstr ""OpenStack の各種ガイド"" msgid ""OpenStack High Availability Guide"" msgstr ""OpenStack 高可用性ガイド"" msgid ""OpenStack Identity"" msgstr ""OpenStack Identity"" msgid ""OpenStack Installation Guides"" msgstr ""OpenStack インストールガイド"" msgid """" ""OpenStack Logical Architecture (<link href=\""http://docs.openstack.org/"" ""openstack-ops/content/figures/2/figures/osog_0001.png\""/>)"" msgstr """" ""OpenStack の論理アーキテクチャ (<link href=\""http://docs.openstack.org/"" ""openstack-ops/content/figures/2/figures/osog_0001.png\""/>)"" msgid ""OpenStack Networking"" msgstr ""OpenStack Networking"" msgid """" ""OpenStack Networking offers sophisticated networking functionality, "" ""including Layer 2 (L2) network segregation and provider networks."" msgstr """" ""OpenStack Networking は、レイヤー 2 (L2) ネットワークの分離やプロバイダーネッ"" ""トワークを含む高度なネットワーク機能を提供します。"" msgid """" ""OpenStack Networking's <literal>ovs-agent</literal>, <literal>l3-agent</"" ""literal>, <literal>dhcp-agent</literal>, and <literal>metadata-agent</"" ""literal> services run on the network nodes, as <literal>lsb</literal> "" ""resources inside of Pacemaker. This means that in the case of network node "" ""failure, services are kept running on another node. Finally, the "" ""<literal>ovs-agent</literal> service is also run on all compute nodes, and "" ""in case of compute node failure, the other nodes will continue to function "" ""using the copy of the service running on them."" msgstr """" ""OpenStack Networking の <literal>ovs-agent</literal>、<literal>l3-agent</"" ""literal>、<literal>dhcp-agent</literal>、および <literal>metadata-agent</"" ""literal> のサービスは、ネットワークノード上で Pacemaker 内の <literal>lsb</"" ""literal> リソースとして稼働します。これは、ネットワークノードに障害が発生した"" ""場合にサービスが別のノードで稼働し続けることを意味します。最後に "" ""<literal>ovs-agent</literal> サービスも全コンピュートノードで稼働し、コン"" ""ピュートノードに障害が発生した場合に、その他のノードが、そこで実行されている"" ""サービスのコピーを使用して機能し続けます。"" msgid ""OpenStack Object Storage"" msgstr ""OpenStack オブジェクトストレージ"" msgid ""OpenStack Object Storage (swift)"" msgstr ""OpenStack Object Storage (swift)"" msgid """" ""OpenStack Object Storage provides a highly scalable, highly available "" ""storage solution by relaxing some of the constraints of traditional file "" ""systems. In designing and procuring for such a cluster, it is important to "" ""understand some key concepts about its operation. Essentially, this type of "" ""storage is built on the idea that all storage hardware fails, at every "" ""level, at some point. Infrequently encountered failures that would hamstring "" ""other storage systems, such as issues taking down RAID cards or entire "" ""servers, are handled gracefully with OpenStack Object Storage.<indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>Object Storage and</"" ""secondary></indexterm>"" msgstr """" ""OpenStack Object Storage は、従来のファイルシステムの制約の一部を緩和すること"" ""で、高可用性かつ高拡張性のストレージソリューションを提供します。このようなク"" ""ラスターの設計、調達には、操作に関する主なコンセプトを理解することが重要で"" ""す。基本的に、このタイプのストレージハードウェアはすべて、どこかの段階で、ど"" ""のレベルであっても故障するというコンセプトをベースに、この種類のストレージは"" ""構築されています。 RAID カードやサーバー全体での問題など、他のストレージシス"" ""テムに影響を与える障害に遭遇することがまれにあります。このような場合、"" ""OpenStack Object Storageでは滞りなく処理されます。<indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>オブジェクトストレージ</"" ""secondary></indexterm>"" msgid ""OpenStack Operations Guide"" msgstr ""OpenStack 運用ガイド"" msgid ""OpenStack Ops Guide"" msgstr ""OpenStack 運用ガイド"" msgid ""OpenStack Security Guide"" msgstr ""OpenStack セキュリティガイド"" msgid ""OpenStack Storage Concepts"" msgstr ""ストレージのコンセプト"" msgid ""OpenStack Telemetry"" msgstr ""OpenStack Telemetry"" msgid """" ""OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows "" ""you to increase the number of instances you can have running on your cloud, "" ""at the cost of reducing the performance of the instances.<indexterm class="" ""\""singular\""><primary>RAM overcommit</primary></indexterm><indexterm class="" ""\""singular\""><primary>CPUs (central processing units)</"" ""primary><secondary>overcommitting</secondary></indexterm><indexterm class="" ""\""singular\""><primary>overcommitting</primary></indexterm><indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>overcommitting</"" ""secondary></indexterm> OpenStack Compute uses the following ratios by "" ""default:"" msgstr """" ""OpenStack は、コンピュートノードで CPU および RAM をオーバーコミットすること"" ""ができます。これにより、インスタンスのパフォーマンスを落とすことでクラウドで"" ""実行可能なインスタンス数を増やすことができます。<indexterm class=\""singular"" ""\""><primary>RAM オーバーコミット</primary></indexterm><indexterm class="" ""\""singular\""><primary>CPU (central processing unit)</"" ""primary><secondary>overcommitting</secondary></indexterm><indexterm class="" ""\""singular\""><primary>オーバーコミット</primary></indexterm><indexterm class="" ""\""singular\""><primary>コンピュートノード</primary><secondary>オーバーコミット"" ""</secondary></indexterm> OpenStack Compute はデフォルトで以下の比率を使用しま"" ""す。"" msgid """" ""OpenStack can be deployed on any hardware supported by an OpenStack-"" ""compatible Linux distribution."" msgstr """" ""OpenStack は、OpenStack と互換性のある Linux ディストリビューションによりサ"" ""ポートされているハードウェアにデプロイすることができます。"" msgid """" ""OpenStack clouds do not present file-level storage to end users. However, it "" ""is important to consider file-level storage for storing instances under "" ""<code>/var/lib/nova/instances</code> when designing your cloud, since you "" ""must have a shared file system if you want to support live migration."" msgstr """" ""OpenStack クラウドは、ファイルレベルのストレージはエンドユーザーには見えませ"" ""んが、クラウドの設計時に <code>/var/lib/nova/instances</code> の配下にインス"" ""タンスを格納する、ファイルレベルのストレージを検討してください。これは、ライ"" ""ブマイグレーションのサポートには、共有ファイルシステムが必要であるためです。"" msgid ""OpenStack default flavors"" msgstr ""OpenStack デフォルトのフレーバー"" msgid """" ""OpenStack does not currently provide DNS services, aside from the dnsmasq "" ""daemon, which resides on <code>nova-network</code> hosts. You could consider "" ""providing a dynamic DNS service to allow instances to update a DNS entry "" ""with new IP addresses. You can also consider making a generic forward and "" ""reverse DNS mapping for instances' IP addresses, such as vm-203-0-113-123."" ""example.com.<indexterm class=\""singular\""><primary>DNS (Domain Name Server, "" ""Service or System)</primary><secondary>DNS service choices</secondary></"" ""indexterm>"" msgstr """" ""OpenStackは現在のところ <code>nova-network</code>ホストに起動しているdnsmasq"" ""デーモンに則したDNSサービスの提供はしていません。インスタンスの新IPアドレスに"" ""対するDNSレコードの更新のためにダイナミックDNSの構成を検討する事ができます。"" ""また、インスタンスのIPアドレスに対応するvm-203-0-113-123.example.comというよ"" ""うな一般的な逆引きDNSサービスの構成も検討する事ができます。<indexterm class="" ""\""singular\""><primary>DNS (Domain Name Serverサービス、システム)</"" ""primary><secondary>DNS サービスの選択</secondary></indexterm>"" msgid ""OpenStack internal network"" msgstr ""OpenStack 内部ネットワーク"" msgid """" ""OpenStack is an open source platform that lets you build an Infrastructure "" ""as a Service (IaaS) cloud that runs on commodity hardware."" msgstr """" ""OpenStack はオープンソースプラットフォームで、OpenStack を使うと、コモディ"" ""ティハードウェア上で動作する Infrastructure as a Service (IaaS) クラウドを自"" ""分で構築できます。"" msgid """" ""OpenStack is designed to be massively horizontally scalable, which allows "" ""all services to be distributed widely. However, to simplify this guide, we "" ""have decided to discuss services of a more central nature, using the concept "" ""of a <emphasis>cloud controller</emphasis>. A cloud controller is just a "" ""conceptual simplification. In the real world, you design an architecture for "" ""your cloud controller that enables high availability so that if any node "" ""fails, another can take over the required tasks. In reality, cloud "" ""controller tasks are spread out across more than a single node.<indexterm "" ""class=\""singular\""><primary>design considerations</primary><secondary>cloud "" ""controller services</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>cloud controllers</primary><secondary>concept of</secondary></"" ""indexterm>"" msgstr """" ""OpenStackはすべてのサービスが広く分散できるよう水平方向に大規模にスケーリング"" ""できるように設計されています。しかし、このガイドではシンプルに<emphasis>クラ"" ""ウドコントローラー</emphasis>の利用についてより中心的な性質を持つサービスにつ"" ""いて議論する事にしました。クラウドコントローラーという言葉はその概念をシンプ"" ""ルに表現した物に過ぎません。実際にはあなたはクラウドコントローラーは冗長構成"" ""としてどのノードが障害となっても他のノードで運用ができるような設計にデザイン"" ""します。実際にはクラウドコントローラーのタスクは1つ以上のノードにまたがって展"" ""開されます。<indexterm class=\""singular\""><primary>設計上の考慮点</"" ""primary><secondary>クラウドコントローラーサービス</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>クラウドコントローラー</"" ""primary><secondary>コンセプト</secondary></indexterm>"" msgid ""OpenStack modules are one of the following types:"" msgstr ""OpenStack のモジュールは、以下の種別のいずれかです。"" msgid ""OpenStack package repository"" msgstr ""OpenStack パッケージリポジトリ"" msgid """" ""OpenStack produces a great deal of useful logging information, however; but "" ""for the information to be useful for operations purposes, you should "" ""consider having a central logging server to send logs to, and a log parsing/"" ""analysis system (such as <phrase role=\""keep-together\"">logstash</phrase>)."" msgstr """" ""OpenStack は、便利なロギング情報を多く生成しますが、運用目的でその情報を有効"" ""活用するには、ログの送信先となる中央ロギングサーバーや、ログの解析/分析システ"" ""ム (<phrase role=\""keep-together\"">logstash</phrase> など) の導入を検討する必"" ""要があります。"" msgid """" ""OpenStack provides a rich networking environment, and this chapter details "" ""the requirements and options to deliberate when designing your cloud."" ""<indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>first steps</secondary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>network "" ""design</secondary></indexterm>"" msgstr """" ""OpenStackは様々なネットワーク環境を提供します。この章ではクラウドを設計する際"" ""に必要な事項と慎重に決定すべきオプションの詳細を説明します。<indexterm class="" ""\""singular\""><primary>ネットワーク設計</primary><secondary>第1段階</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項"" ""</primary><secondary>ネットワーク設計</secondary></indexterm>"" msgid ""OpenStack release"" msgstr ""OpenStack リリース"" msgid ""OpenStack segregation methods"" msgstr ""OpenStack 分離の手法"" msgid ""OpenStack storage"" msgstr ""OpenStack ストレージ"" msgid """" ""OpenStack, like any network application, has a number of standard "" ""considerations to apply, such as NTP and DNS.<indexterm class=\""singular"" ""\""><primary>network design</primary><secondary>services for networking</"" ""secondary></indexterm>"" msgstr """" ""多くのネットワークアプリケーションがそうであるようにOpenStackでもNTPやDNS と"" ""言った適用するための数多くの検討事項があります。<indexterm class=\""singular"" ""\""><primary>ネットワークデザイン</primary><secondary>ネットワークサービス</"" ""secondary></indexterm>"" msgid ""Operations"" msgstr ""運用"" msgid ""Option 1"" msgstr ""オプション 1"" msgid ""Option 2"" msgstr ""オプション 2"" msgid ""Option 3"" msgstr ""オプション 3"" msgid ""Optional Extensions"" msgstr ""さらなる拡張"" msgid ""Optional swap space allocation for the instance."" msgstr ""インスタンスに割り当てられるスワップ空間。これはオプションです。"" msgid """" ""Options must be carefully configured for live migration to work with "" ""networking services."" msgstr """" ""ネットワークサービスが正しく動くようにライブマイグレーションを設定するために"" ""は注意してオプションを構成する必要があります。"" msgid ""Other CLI Options"" msgstr ""他の CLI オプション"" msgid ""Other backup considerations include:"" msgstr ""さらにバックアップの考慮点として以下があげられます。"" msgid ""Out-of-band remote management"" msgstr ""帯域外管理リモート管理"" msgid ""Overcommitting"" msgstr ""オーバーコミット"" msgid ""Overhead"" msgstr ""オーバーヘッド"" msgid ""Overview"" msgstr ""概要"" msgid ""PAM (Pluggable Authentication Module)"" msgstr ""PAM (Pluggable Authentication Module)"" msgid ""PC"" msgstr ""PC"" msgid """" ""Pacemaker is the clustering software used to ensure the availability of "" ""services running on the controller and network nodes: <placeholder-1/>"" msgstr """" ""Pacemaker とは、コントローラーノードおよびネットワークノードで実行されている"" ""サービスの可用性を確保するために使用するクラスタリングソフトウェアです: "" ""<placeholder-1/>"" msgid """" ""Packets leaving the subnet go via this address, which could be a dedicated "" ""router or a <literal>nova-network</literal> service."" msgstr """" ""パケットが出て行く際に通るIPアドレスで、これは専用のルータか<literal>nova-"" ""network</literal> サービスです。"" msgid ""Parting Thoughts for Provisioning and Deploying OpenStack"" msgstr ""OpenStack のプロビジョニングおよびデプロイメントの概念"" msgid ""Parting Thoughts on Architectures"" msgstr ""アーキテクチャについての章の結び"" msgid """" ""Partition all drives in the same way in a horizontal fashion, as shown in "" ""<xref linkend=\""disk_partition_figure\""/>."" msgstr """" ""<xref linkend=\""disk_partition_figure\""/> にあるように、すべてのドライブを同"" ""じように並列してパーティショニングにします。"" msgid ""Partition setup of drives"" msgstr ""ドライブのパーティション設定"" msgid """" ""Partitioning, which provides greater flexibility for layout of operating "" ""system and swap space, as described below."" msgstr """" ""パーティショニング。以下に説明されている通り、オペレーティングシステムと "" ""Swap 領域のレイアウトにおける柔軟性がはるかに高くになります。"" msgid ""Password"" msgstr ""パスワード"" msgid ""Perform the day-to-day tasks required to administer a cloud."" msgstr ""クラウドを管理する上で必要となる日々のタスクの実行。"" msgid ""Performance and Optimizing"" msgstr ""パフォーマンスと最適化"" msgid ""Performance node deployment"" msgstr ""パフォーマンスノードのデプロイメント"" msgid ""Persistent Storage"" msgstr ""永続ストレージ"" msgid ""Persistent file-based storage support"" msgstr ""永続ファイルベースのストレージサポート"" msgid """" ""Persistent storage means that the storage resource outlives any other "" ""resource and is always available, regardless of the state of a running "" ""instance."" msgstr """" ""永続ストレージとは、実行中のインスタンスの状態が何であっても、ストレージリ"" ""ソースが他のリソースよりも長く存在して、常に利用できる状態のストレージを指し"" ""ます。"" msgid ""Persists until…"" msgstr ""データの残存期間"" msgid """" ""Pick a service endpoint from your service catalog, such as compute. Try a "" ""request, for example, listing instances (servers):"" msgstr """" ""サービスカタログから、サービスエンドポイント (例: コンピュート) を選択しま"" ""す。要求を試します。例えば、インスタンス (サーバー) の一覧表示を行います。"" msgid ""Place the tenant ID in a useable variable, as follows:"" msgstr ""テナント ID を変数に格納しておきます。"" msgid ""Planned Maintenance"" msgstr ""計画メンテナンス"" msgid ""Possible options include:"" msgstr ""次のような選択肢があります。"" msgid ""Preface"" msgstr ""はじめに"" msgid ""Prepare any quarterly reports on usage and statistics."" msgstr ""使用量と統計に関する四半期レポートを準備します。"" msgid ""Press Enter to run it."" msgstr ""Enter キーを押し、実行します。"" msgid ""Press Up Arrow to bring up the last command."" msgstr ""上矢印キーを押し、最後のコマンドを表示させます。"" msgid """" ""Previously, all services had an availability zone. Currently, only the "" ""<literal>nova-compute</literal> service has its own availability zone. "" ""Services such as <literal>nova-scheduler</literal>, <literal>nova-network</"" ""literal>, and <literal>nova-conductor</literal> have always spanned all "" ""availability zones."" msgstr """" ""以前のバージョンでは、全サービスにアベイラビリティゾーンがありました。現在"" ""は、<literal>nova-compute</literal> サービスには独自のアベイラビリティゾーン"" ""があります。 <literal>nova-scheduler</literal>、 <literal>nova-network</"" ""literal>、<literal>nova-conductor</literal> などのサービスは、常にすべてのア"" ""ベイラビリティゾーンに対応します。"" msgid ""Primary project"" msgstr ""主プロジェクト"" msgid """" ""Probably the most important factor in your choice of hypervisor is your "" ""current usage or experience. Aside from that, there are practical concerns "" ""to do with feature parity, documentation, and the level of community "" ""experience."" msgstr """" ""おそらく、ハイパーバイザーの選択で最も重要な要素は、現在の使用法やこれまでの"" ""経験でしょう。それ以外では、同等の機能の実用上の懸念、ドキュメント、コミュニ"" ""ティでの経験量などあると思います。"" msgid ""Process Monitoring"" msgstr ""プロセス監視"" msgid ""Projects or Tenants?"" msgstr ""プロジェクトかテナントか?"" msgid ""Property name"" msgstr ""プロパティ名"" msgid """" ""Provide the front door that people access as well as the API services that "" ""all other components in the environment talk to."" msgstr """" ""ユーザーがアクセスするフロントドアに加えて、環境内その他すべてのコンポーネン"" ""トが通信する API サービスを提供します。"" msgid """" ""Provide what is known as \""persistent storage\"" through services run on the "" ""host as well. This persistent storage is backed onto the storage nodes for "" ""reliability."" msgstr """" ""ホストでも実行されるサービスを介して、いわゆる「永続ストレージ」を提供しま"" ""す。この永続ストレージは、信頼性のためにストレージノードにバッキングされま"" ""す。"" msgid """" ""Provides a web-based frontend for users to consume OpenStack cloud services"" msgstr """" ""利用ユーザ用のOpenStackクラウドサービスのウェブインターフェースを提供します。"" msgid ""Provisioning and Deployment"" msgstr ""プロビジョニングとデプロイメント"" msgid ""Proxy requests to a database"" msgstr ""データベースリクエストのプロクシ"" msgid ""Public Addressing Options"" msgstr ""パブリックアドレスの選択肢"" msgid ""Public Network"" msgstr ""パブリックネットワーク"" msgid """" ""Public access to <code>swift-proxy</code>, <code>nova-api</code>, "" ""<code>glance-api</code>, and horizon come to these addresses, which could be "" ""on one side of a load balancer or pointing at individual machines."" msgstr """" ""<code>swift-proxy</code>, <code>nova-api</code>, <code>glance-api</code>, "" ""horizon へのパブリックアクセスはこれらのアドレス宛にアクセスしてきます。これ"" ""らのアドレスはロードバランサの片側か、個々の機器を指しています。"" msgid ""Python"" msgstr ""Python"" msgid ""QEMU"" msgstr ""QEMU"" msgid ""Qpid"" msgstr ""Qpid"" msgid ""Quarterly"" msgstr ""四半期ごと"" msgid ""Quota"" msgstr ""クォータ"" msgid ""Quotas"" msgstr ""クォータ"" msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" msgid """" ""RAID is not used in this simplistic one-drive setup because generally for "" ""production clouds, you want to ensure that if one disk fails, another can "" ""take its place. Instead, for production, use more than one disk. The number "" ""of disks determine what types of RAID arrays to build."" msgstr """" ""通常、本番環境のクラウドでは、1 つのディスクに問題が発生した場合、別のディス"" ""クが必ず稼働するようにするため、RAID は、このシンプルな、ドライブ 1 つの設定"" ""では使用されません。本番環境では、ディスクを 1 つ以上使用します。ディスク数に"" ""より、どのようなタイプの RAID 配列を構築するか決定します。"" msgid ""RAM"" msgstr ""メモリー"" msgid ""RAM allocation ratio: 1.5:1"" msgstr ""RAM 割当比: 1.5:1"" msgid ""RDO"" msgstr ""RDO"" msgid ""RXTX_Factor"" msgstr ""RXTX_Factor"" msgid ""RabbitMQ Web Management Interface or rabbitmqctl"" msgstr ""RabbitMQ Web管理インターフェイス および rabbitmqctl"" msgid ""RabbitMQ for Ubuntu; Qpid for Red Hat Enterprise Linux and derivatives"" msgstr """" ""Ubuntu には RabbitMQ、Red Hat Enterprise Linux には Qpid、 および派生物"" msgid ""Raid Controller: PERC H710P Integrated RAID Controller, 1 GB NV Cache"" msgstr """" ""RAID コントローラー: PERC H710P Integrated RAID Controller、1 GB NV キャッ"" ""シュ"" msgid ""Ramification"" msgstr ""派生問題"" msgid ""Rationale"" msgstr ""設定指針"" msgid ""Read the release notes and documentation."" msgstr ""リリースノートとドキュメントを読みます。"" msgid """" ""Read through the JSON response to get a feel for how the catalog is laid out."" msgstr ""JSONレスポンスを読むことで、カタログを把握することができます。"" msgid ""Rebooting a Storage Node"" msgstr ""ストレージノードの再起動"" msgid """" ""Recall that a cloud controller node runs several different services. You can "" ""install services that communicate only using the message queue internally—"" ""<code>nova-scheduler</code> and <code>nova-console</code>—on a new server "" ""for expansion. However, other integral parts require more care."" msgstr """" ""クラウドコントローラは、異なるサービスを複数実行することを思い出してくださ"" ""い。拡張のための新しいサーバには、<code>nova-scheduler</code> や <code>nova-"" ""console</code> のようなメッセージキューのみを使用して内部通信を行うサービスを"" ""インストールすることができます。しかし、その他の不可欠な部分はさらに細心の注"" ""意が必要です。"" msgid ""Recovering Backups"" msgstr ""バックアップのリカバリー"" msgid ""Recovery of instances is complicated by depending on multiple hosts."" msgstr ""複数の物理ホストが関係するため、インスタンスの復旧が複雑になります。"" msgid ""Red Hat Distributed OpenStack (RDO)"" msgstr ""Red Hat Distributed OpenStack (RDO)"" msgid ""Red Hat Enterprise Linux"" msgstr ""Red Hat Enterprise Linux"" msgid ""Red Hat Enterprise Linux 6.5"" msgstr ""Red Hat Enterprise Linux 6.5"" msgid ""Regions"" msgstr ""リージョン"" msgid ""Relatively simple to deploy."" msgstr ""比較的シンプルな構成"" msgid ""Releases"" msgstr ""リリース番号"" msgid ""Remote Management"" msgstr ""リモート管理"" msgid """" ""Replace <replaceable>NEUTRON_DBPASS</replaceable> with the password you "" ""chose for the database."" msgstr """" ""<replaceable>NEUTRON_PASS</replaceable> をデータベース用に選んだパスワードで"" ""置き換えます。"" msgid """" ""Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose "" ""for the <literal>guest</literal> account in <application>RabbitMQ</"" ""application>."" msgstr """" ""<replaceable>RABBIT_PASS</replaceable> を <application>RabbitMQ</"" ""application> の <literal>guest</literal> アカウント用に選んだパスワードで置き"" ""換えます。"" msgid ""Replacing Components"" msgstr ""コンポーネントの交換"" msgid ""Replacing a Swift Disk"" msgstr ""Swift ディスクの交換"" msgid ""Reporting Bugs"" msgstr ""バグ報告"" msgid """" ""Requires file injection into the instance to configure network interfaces."" msgstr """" ""ネットワークインターフェースの設定にはインスタンスへのファイルの注入が必須で"" ""す。"" msgid ""Requires its own DHCP broadcast domain."" msgstr ""専用の DHCP ブロードキャストドメインが必要。"" msgid ""Requires many VLANs to be trunked onto a single port."" msgstr ""一つのポートに多数の VLAN をトランクが必要。"" msgid ""Resource Alerting"" msgstr ""リソースのアラート"" msgid ""Resources"" msgstr ""情報源"" msgid ""Restart Compute services:"" msgstr ""Compute サービスを再起動します。"" msgid ""Restart Networking services:"" msgstr ""Networking サービスを再起動します。"" msgid ""Restart the services."" msgstr ""サービスを再起動します。"" msgid ""Review and plan any major OpenStack upgrades."" msgstr ""OpenStack のメジャーアップグレードの内容を確認し、その計画を立てます。"" msgid ""Review and plan any necessary cloud additions."" msgstr ""クラウドの追加の必要性を検討し、計画を立てます。"" msgid ""Review usage and trends over the past quarter."" msgstr ""この四半期における使用量および傾向を確認します。"" msgid ""Role"" msgstr ""役割"" msgid ""Routers for private networks created within OpenStack."" msgstr ""OpenStack 内に作成されるプライベートネットワーク用のルーター"" msgid """" ""Run <code>glance-*</code> servers on the <code>swift-proxy</code> server."" msgstr ""<code>swift-proxy</code> サーバで<code>glance-*</code>サーバを稼働する"" msgid ""Run a central dedicated database server."" msgstr ""中央データベースサーバを構成する"" msgid """" ""Run a number of services in a highly available fashion, utilizing Pacemaker "" ""and HAProxy to provide a virtual IP and load-balancing functions so all "" ""controller nodes are being used."" msgstr """" ""全コントローラーノードが使用されるように Pacemaker と HAProxy を利用して仮想 "" ""IP および負荷分散機能を提供して、多数のサービスを高可用性で実行します。"" msgid """" ""Run all of the environment's networking services, with the exception of the "" ""networking API service (which runs on the controller node)."" msgstr """" ""環境の全ネットワークサービスを実行します。ただし、ネットワーク API サービス "" ""(コントローラーノードで実行される) を除きます。"" msgid ""Run one VM per service."" msgstr ""1サービスにつき1つのVMを稼働させる"" msgid ""Run operating system and scratch space"" msgstr ""OS を起動し、空き領域に記録する"" msgid ""Run the bare minimum of services needed to facilitate these instances."" msgstr """" ""それらのインスタンスを円滑に稼働するために必要な最低限のサービスを実行しま"" ""す。"" msgid ""Run the following command to view the current iptables configuration:"" msgstr ""iptablesの現在の構成を見るには、以下のコマンドを実行します。"" msgid ""Run the following command to view the properties of existing images:"" msgstr """" ""既存のイメージのプロパティを表示するために、以下のコマンドを実行します。"" msgid ""Run this on the command line of the following areas:"" msgstr ""このコマンドは以下の場所で実行します。"" msgid ""Running Daemons on the CLI"" msgstr ""コマンドラインでのデーモンの実行"" msgid ""Running Instances"" msgstr ""稼働中のインスタンス"" msgid ""Running a dedicated storage system can be operationally simpler."" msgstr ""専用のストレージシステムを動作させることで、運用がシンプルになります。"" msgid """" ""Running a distributed file system can make you lose your data locality "" ""compared with nonshared storage."" msgstr """" ""分散ファイルシステムを実行すると、非共有ストレージに比べデータの局所性が失わ"" ""れる可能性があります。"" msgid """" ""Running a shared file system on a storage system apart from the computes "" ""nodes is ideal for clouds where reliability and scalability are the most "" ""important factors. Running a shared file system on the compute nodes "" ""themselves may be best in a scenario where you have to deploy to preexisting "" ""servers for which you have little to no control over their specifications. "" ""Running a nonshared file system on the compute nodes themselves is a good "" ""option for clouds with high I/O requirements and low concern for reliability."" ""<indexterm class=\""singular\""><primary>scaling</primary><secondary>file "" ""system choice</secondary></indexterm>"" msgstr """" ""信頼性と拡張性が最も重要な要因とするクラウドでは、コンピュートノードと分離し"" ""てストレージシステムで共有ファイルシステムを実行することが理想的です。仕様の"" ""コントロールをほぼできない、または全くできない既存のサーバーにデプロイシなけ"" ""ればならない場合などは、コンピュートノード自体で共有ファイルシステムを実行す"" ""るとベストです。また、I/O 要件が高く、信頼性にあまり配慮しなくてもいいクラウ"" ""ドには、コンピュートノード上で非共有ファイルシステムを実行すると良いでしょ"" ""う。<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>"" ""ファイルシステムの選択</secondary></indexterm>"" msgid ""Running programs have written their contents to disk"" msgstr ""実行中のプログラムがコンテンツをディスクに書き込んだこと"" msgid """" ""Runs as a background process. On Linux platforms, a daemon is usually "" ""installed as a service.<indexterm class=\""singular\""><primary>daemons</"" ""primary><secondary>basics of</secondary></indexterm>"" msgstr """" ""バックグラウンドプロセスとして実行されます。Linux プラットフォームでは、デー"" ""モンは通常サービスとしてインストールされます。<indexterm class=\""singular"" ""\""><primary>デーモン</primary><secondary>基本</secondary></indexterm>"" msgid ""S3"" msgstr ""S3"" msgid ""SERVICE_TENANT_ID"" msgstr ""SERVICE_TENANT_ID"" msgid ""SQL"" msgstr ""SQL"" msgid ""SQL database (such as MySQL or PostgreSQL)"" msgstr ""SQL データベース (MySQL や PostgreSQL など)"" msgid ""Scalable Hardware"" msgstr ""スケーラブルハードウェア"" msgid ""Scaling"" msgstr ""スケーリング"" msgid ""Scenario"" msgstr ""シナリオ"" msgid ""Scheduling"" msgstr ""スケジューリング"" msgid ""Scheduling services"" msgstr ""スケジュールサービス"" msgid ""Scheduling to hosts with trusted hardware support."" msgstr """" ""トラステッドコンピューティング機能に対応したホスト群に対してスケジューリング"" ""したい場合"" msgid ""Script"" msgstr ""スクリプト"" msgid """" ""Secondly, DAIR's shared <filename>/var/lib/nova/instances</filename> "" ""directory contributed to the problem. Since all compute nodes have access to "" ""this directory, all compute nodes periodically review the _base directory. "" ""If there is only one instance using an image, and the node that the instance "" ""is on is down for a few minutes, it won't be able to mark the image as still "" ""in use. Therefore, the image seems like it's not in use and is deleted. When "" ""the compute node comes back online, the instance hosted on that node is "" ""unable to start."" msgstr """" ""次に、DAIR の共有された <filename>/var/lib/nova/instances</filename> が問題を"" ""助長した。全コンピュートノードがこのディレクトリにアクセスするため、全てのコ"" ""ンピュートノードは定期的に _base ディレクトリを見直していた。あるイメージを使"" ""用しているインスタンスが１つだけあり、そのインスタンスが存在するノードが数分"" ""間ダウンした場合、そのイメージが使用中であるという印を付けられなくなる。それ"" ""ゆえ、イメージは使用中に見えず、削除されてしまったのだ。そのコンピュートノー"" ""ドが復帰した際、そのノード上でホスティングされていたインスタンスは起動できな"" ""い。"" msgid ""Security Groups"" msgstr ""セキュリティグループ"" msgid ""Security Information"" msgstr ""セキュリティ情報"" msgid ""Security group rules"" msgstr ""セキュリティグループルール"" msgid ""Security groups"" msgstr ""セキュリティグループ"" msgid ""See <xref linkend=\""node_compute-diagram\""/>."" msgstr ""<xref linkend=\""node_compute-diagram\""/> を参照してください。"" msgid ""See <xref linkend=\""node_controller-diagram\""/>."" msgstr ""<xref linkend=\""node_controller-diagram\""/> を参照してください。"" msgid ""See <xref linkend=\""node_network-diagram\""/>."" msgstr ""<xref linkend=\""node_network-diagram\""/> を参照してください。"" msgid ""See <xref linkend=\""node_storage-diagram\""/>."" msgstr ""<xref linkend=\""node_storage-diagram\""/> を参照してください。"" msgid ""Segregating Your Cloud"" msgstr ""クラウドの分離"" msgid ""Select the <guilabel>Admin</guilabel> tab in the left navigation bar."" msgstr """" ""左側にあるナビゲーションバーの <guilabel>管理</guilabel> タブを選択します。"" msgid ""Sep 22, 2011"" msgstr ""2011年9月22日"" msgid ""Sep 27, 2012"" msgstr ""2012年9月27日"" msgid ""Separation of Services"" msgstr ""サービスの分離"" msgid ""Series"" msgstr ""シリーズ"" msgid ""Seriously, Google."" msgstr ""マジ？Google。"" msgid ""Servers and Services"" msgstr ""サーバーとサービス"" msgid ""Service"" msgstr ""サービス"" msgid ""Services"" msgstr ""サービス"" msgid ""Services for Networking"" msgstr ""ネットワーク関係のサービス"" msgid ""Set Compute Service Quotas"" msgstr ""コンピュートサービスのクォータの設定"" msgid ""Set Image Quotas"" msgstr ""イメージクォータの設定"" msgid """" ""Several options are available for MySQL load balancing, and the supported "" ""AMQP brokers have built-in clustering support. Information on how to "" ""configure these and many of the other services can be found in <xref linkend="" ""\""operations\"" xrefstyle=\""part-num-title\""/>.<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgstr """" ""MySQL の負荷分散には複数のオプションがあり、サポートされている AMQP ブロー"" ""カーにはクラスタリングサポートが含まれています。これらの設定方法やその他多く"" ""のサービスに関する情報は、 <xref linkend=\""operations\"" xrefstyle=\""part-num-"" ""title\""/> を参照してください。<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgid ""Shared services"" msgstr ""共有サービス"" msgid ""Shared storage using NFS*"" msgstr ""NFS を使用する共有ストレージ* "" msgid ""Sheepdog"" msgstr ""Sheepdog"" msgid ""Should backups be kept off-site?"" msgstr ""オフサイトにバックアップを置くべきか?"" msgid """" ""Should my persistent storage drives be contained in my compute nodes, or "" ""should I use external storage?"" msgstr """" ""永続的ストレージをコンピュートノード内に持つべきか？それとも外部ストレージに"" ""持つべきか？"" msgid ""Shutting Down a Storage Node"" msgstr ""ストレージノードのシャットダウン"" msgid """" ""Similarly, the default RAM allocation ratio of 1.5:1 means that the "" ""scheduler allocates instances to a physical node as long as the total amount "" ""of RAM associated with the instances is less than 1.5 times the amount of "" ""RAM available on the physical node."" msgstr """" ""同様に、RAM 割当比のデフォルト1.5:1 は、インスタンスに関連づけられた RAM の総"" ""量が物理ノードで利用できるメモリ量の1.5倍未満であれば、スケジューラーがその物"" ""理ノードにインスタンスを割り当てることを意味します。"" msgid ""Single <literal>nova-network</literal> or multi-host?"" msgstr ""単一の <literal>nova-network</literal> またはマルチホスト?"" msgid """" ""Size your database server accordingly, and scale out beyond one cloud "" ""controller if many instances will report status at the same time and "" ""scheduling where a new instance starts up needs computing power."" msgstr """" ""データベースサーバーを負荷に応じてサイジングしてください。もし、多数のインス"" ""タンスが同時に状態を報告したり、CPU能力が必要な新規インスタンス起動のスケ"" ""ジューリングを行う場合は、１台のクラウドコントローラーを超えてスケールアウト"" ""してください。"" msgid ""Sizing determined by…"" msgstr ""容量の指定"" msgid ""So it was a qemu/kvm bug."" msgstr ""つまり、これは qemu/kvm のバグである。"" msgid ""SolidFire"" msgstr ""SolidFire"" msgid ""Some of the resources that you want to monitor include:"" msgstr ""監視項目に含む幾つかのリソースをあげます。"" msgid ""Some other examples for Intelligent Alerting include:"" msgstr ""インテリジェントなアラートのその他の例としては以下があります。"" msgid """" ""Sometimes a compute node either crashes unexpectedly or requires a reboot "" ""for maintenance reasons."" msgstr """" ""コンピュートノードは、予期せずクラッシュしたり、メンテナンスのために再起動が"" ""必要になったりすることがときどきあります。"" msgid """" ""Sometimes a user and a group have a one-to-one mapping. This happens for "" ""standard system accounts, such as cinder, glance, nova, and swift, or when "" ""only one user is part of a group."" msgstr """" ""ユーザーとグループは、一対一でマッピングされる場合があります。このようなマッ"" ""ピングは cinder、glance、nova、swift などの標準システムアカウントや、グループ"" ""にユーザーが 1 人しかいない場合に発生します。"" msgid ""Spare space for future growth"" msgstr ""将来のための余剰"" msgid """" ""Specifies the size of a secondary ephemeral data disk. This is an empty, "" ""unformatted disk and exists only for the life of the instance."" msgstr """" ""二次的な一時データディスクの容量を指定します。これは空の、フォーマットされて"" ""いないディスクです。インスタンスの生存期間だけ存在します。"" msgid ""StackTach"" msgstr ""StackTach"" msgid ""Standard VLAN number limitation."" msgstr ""標準的な VLAN 数の上限。"" msgid ""Standard networking."" msgstr ""標準的なネットワーク。"" msgid ""Start the services:"" msgstr ""サービスを起動します。"" msgid ""Starting Instances"" msgstr ""インスタンスの起動"" msgid """" ""Starting instances and deleting instances is demanding on the compute node "" ""but also demanding on the controller node because of all the API queries and "" ""scheduling needs."" msgstr """" ""インスタンスの起動と停止は コンピュートノードに負荷をかけますが、それだけで"" ""なく、すべてのAPI処理とスケジューリングの必要性のために、コントローラーノード"" ""にも負荷をかけます。"" msgid ""Status"" msgstr ""状態"" msgid ""Status: <emphasis>Confirmed</emphasis>"" msgstr ""Status: <emphasis>Confirmed</emphasis>"" msgid ""Status: <emphasis>Incomplete</emphasis>"" msgstr ""Status: <emphasis>Incomplete</emphasis>"" msgid ""Status: <emphasis>New</emphasis>"" msgstr ""Status: <emphasis>New</emphasis>"" msgid ""Storage"" msgstr ""ストレージ"" msgid ""Storage Decisions"" msgstr ""ストレージ選定"" msgid ""Storage Driver Support"" msgstr ""ストレージドライバーズサポート"" msgid ""Storage Node Failures and Maintenance"" msgstr ""ストレージノードの故障とメンテナンス"" msgid """" ""Storage is found in many parts of the OpenStack stack, and the differing "" ""types can cause confusion to even experienced cloud engineers. This section "" ""focuses on persistent storage options you can configure with your cloud. "" ""It's important to understand the distinction between <glossterm baseform="" ""\""ephemeral volume\""> ephemeral</glossterm> storage and <glossterm baseform="" ""\""persistent volume\""> persistent</glossterm> storage."" msgstr """" ""ストレージは、OpenStack のスタックの多くの箇所で使用されており、ストレージの"" ""種別が異なると、経験豊かなエンジニアでも混乱する可能性があります。本章は、お"" ""使いのクラウドで設定可能な永続ストレージオプションにフォーカスします。"" ""<glossterm baseform=\""ephemeral volume\""> 一時</glossterm> ストレージと "" ""<glossterm baseform=\""persistent volume\""> 永続</glossterm> ストレージの相違"" ""点を理解することが重要です。"" msgid ""Storage node"" msgstr ""ストレージノード"" msgid ""Storage nodes"" msgstr ""ストレージノード"" msgid ""Store data, including VM images"" msgstr ""データを保存する（VMイメージも含む）"" msgid """" ""Stores and serves images with metadata on each, for launching in the cloud"" msgstr """" ""クラウド内で起動するための各メタデータが付属したイメージデータを蓄え、提供し"" ""ます"" msgid ""Strengths"" msgstr ""長所"" msgid ""Subnet router"" msgstr ""サブネットルーター"" msgid ""Summary"" msgstr ""概要"" msgid """" ""Supply highly available \""infrastructure\"" services, such as MySQL and Qpid, "" ""that underpin all the services."" msgstr """" ""高可用性の「インフラストラクチャ」サービス (全サービスの基盤となる MySQL や "" ""Qpid など) を提供します。 "" msgid """" ""Sure enough, the user had been periodically refreshing the console log page "" ""on the dashboard and the 5G file was traversing the rabbit cluster to get to "" ""the dashboard."" msgstr """" ""思った通り、ユーザはダッシュボード上のコンソールログページを定期的に更新して"" ""おり、ダッシュボードに向けて5GB のファイルが RabbitMQ クラスタを通過してい"" ""た。"" msgid ""Swap"" msgstr ""スワップ"" msgid """" ""Swap space to free up memory for processes, as an independent area of the "" ""physical disk used only for swapping and nothing else"" msgstr """" ""プロセス用にメモリーを空ける Swap 領域。物理ディスクから独立した、スワップの"" ""みに使用される領域。"" msgid ""Swift"" msgstr ""Swift"" msgid """" ""Swift should notice the new disk and that no data exists. It then begins "" ""replicating the data to the disk from the other existing replicas."" msgstr """" ""Swift は新しいディスクを認識します。また、データが存在しないことを認識しま"" ""す。そうすると、他の既存の複製からディスクにデータを複製しはじめます。"" msgid ""Switches must support 802.1q VLAN tagging."" msgstr ""802.1q VLAN タギングに対応したスイッチが必要。"" msgid """" ""Sébastien Han has written excellent blogs and generously gave his permission "" ""for re-use."" msgstr """" ""Sébastien Han は素晴らしいブログを書いてくれて、寛大にも再利用の許可を与えて"" ""くれました。"" msgid ""Tailing Logs"" msgstr ""最新ログの確認"" msgid ""Taking Snapshots"" msgstr ""スナップショットの取得"" msgid ""Tales From the Cryp^H^H^H^H Cloud"" msgstr ""ハリウッド^H^H^H^H^Hクラウドナイトメア"" msgid ""Tenant Network Separation"" msgstr ""テナントネットワークの分離"" msgid ""Terminal 1:"" msgstr ""端末 1:"" msgid ""Terminal 2:"" msgstr ""端末 2:"" msgid ""That made no sense."" msgstr ""これでは意味が無かった。"" msgid ""The 1gb NIC was still alive and active"" msgstr ""1Gb NICはまだ生きていて、有効だった。"" msgid """" ""The <code>-s flag</code> used in the cURL commands above are used to prevent "" ""the progress meter from being shown. If you are having trouble running cURL "" ""commands, you'll want to remove it. Likewise, to help you troubleshoot cURL "" ""commands, you can include the <code>-v</code> flag to show you the verbose "" ""output. There are many more extremely useful features in cURL; refer to the "" ""man page for all the options."" msgstr """" ""上記の cURL コマンドで使用している <code>-s flag</code> は、進行状況メーター"" ""が表示されないようにするために使用します。cURL コマンドの実行で問題が生じた場"" ""合には、このオプションを削除してください。また、cURL コマンドのトラブルシュー"" ""ティングを行う場合には、<code>-v</code> フラグを指定してより詳細な出力を表示"" ""すると役立ちます。cURL には他にも多数の役立つ機能があります。全オプションは、"" ""man ページで参照してください。"" msgid """" ""The <code>glance-api</code> part is an abstraction layer that allows a "" ""choice of backend. Currently, it supports:"" msgstr """" ""<code>glance-api</code>部はバックエンドを選択する事ができる抽象的なレイヤーで"" ""す。現在、以下をサポートしています："" msgid """" ""The <code>nova flavor-create</code> command allows authorized users to "" ""create new flavors. Additional flavor manipulation commands can be shown "" ""with the command: <placeholder-1/>"" msgstr """" ""<code>nova flavor-create</code> コマンドにより、権限のあるユーザーが新しいフ"" ""レーバーを作成できます。さらなるフレーバーの操作コマンドは次のコマンドを用い"" ""て表示できます: <placeholder-1/>"" msgid """" ""The <code>nova.quota_usages</code> table keeps track of how many resources "" ""the tenant currently has in use:"" msgstr """" ""<code>nova.quota_usages</code>テーブルはどのくらいリソースをテナントが利用し"" ""ているかを記録しています。"" msgid """" ""The <literal>-H</literal> flag is required when running the daemons with "" ""sudo because some daemons will write files relative to the user's home "" ""directory, and this write may fail if <literal>-H</literal> is left off."" msgstr """" ""sudo を用いてデーモンを実行するとき、<literal>-H</literal> フラグが必要です。"" ""いくつかのデーモンは、ユーザーのホームディレクトリーからの相対パスのファイル"" ""に書き込みを行うため、<literal>-H</literal> がないと、この書き込みが失敗して"" ""しまいます。"" msgid """" ""The <literal>nova-conductor</literal> service is horizontally scalable. To "" ""make <literal>nova-conductor</literal> highly available and fault tolerant, "" ""just launch more instances of the <code>nova-conductor</code> process, "" ""either on the same server or across multiple servers."" msgstr """" ""<literal>nova-conductor</literal>サービスは水平方向にスケーラブルです。"" ""<literal>nova-conductor</literal>を冗長構成になるためには、<code>nova-"" ""conductor</code> プロセスを同一サーバまたは複数のサーバに渡って複数起動するだ"" ""けです。"" msgid """" ""The <literal>nova-manage</literal> tool can provide some additional details:"" msgstr """" ""<literal>nova-manage</literal> ツールは、追加の情報を提供することが可能です:"" msgid """" ""The <literal>nova-network</literal> service has the ability to operate in a "" ""multi-host or single-host mode. Multi-host is when each compute node runs a "" ""copy of <literal>nova-network</literal> and the instances on that compute "" ""node use the compute node as a gateway to the Internet. The compute nodes "" ""also host the floating IPs and security groups for instances on that node. "" ""Single-host is when a central server—for example, the cloud controller—runs "" ""the <code>nova-network</code> service. All compute nodes forward traffic "" ""from the instances to the cloud controller. The cloud controller then "" ""forwards traffic to the Internet. The cloud controller hosts the floating "" ""IPs and security groups for all instances on all compute nodes in the cloud."" ""<indexterm class=\""singular\""><primary>single-host networking</primary></"" ""indexterm><indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>multi-host</secondary></indexterm><indexterm class="" ""\""singular\""><primary>multi-host networking</primary></indexterm><indexterm "" ""class=\""singular\""><primary>network design</primary><secondary>network "" ""topology</secondary><tertiary>multi- vs. single-host networking</tertiary></"" ""indexterm>"" msgstr """" ""<literal>nova-network</literal>はマルチホストまたはシングルホストモードで運用"" ""する事ができます。マルチホスト構成はそれぞれのコンピュートノードで"" ""<literal>nova-network</literal> の複製とそのコンピュートノードのインスタンス"" ""が稼働している時、コンピュートノードをインターネットへのゲートウェイとして利"" ""用します。また、そのコンピュートノードはそこで稼働しているインスタンスのフ"" ""ローティングIPアドレスとセキュリティグループを受け持ちます。シングルホスト構"" ""成はクラウドコントローラと言った中央サーバが<code>nova-network</code> サービ"" ""スを受け持ちます。すべてのコンピュートノードはインターネットへのトラフィック"" ""をコントローラに転送します。クラウドコントローラがすべてのコントローラ上のす"" ""べてのインスタンスのフローティングIPアドレスとセキュリティグループを受け持ち"" ""ます。<indexterm class=\""singular\""><primary>シングルホストネットワーク</"" ""primary></indexterm><indexterm class=\""singular\""><primary>ネットワーク</"" ""primary><secondary>マルチホスト</secondary></indexterm><indexterm class="" ""\""singular\""><primary>マルチホストネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワークデザイン</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>マルチvsシング"" ""ルホストネットワーク</tertiary></indexterm>"" msgid """" ""The <placeholder-1/> command wasn't working, so I used <placeholder-2/>, but "" ""it immediately came back with an error saying it was unable to find the "" ""backing disk. In this case, the backing disk is the Glance image that is "" ""copied to <filename>/var/lib/nova/instances/_base</filename> when the image "" ""is used for the first time. Why couldn't it find it? I checked the directory "" ""and sure enough it was gone."" msgstr """" ""<placeholder-1/> コマンドは機能しなかったので、<placeholder-2/> を使用した"" ""が、すぐに仮想ディスクが見つからないとのエラーが返ってきた。この場合、仮想"" ""ディスクは Glance イメージで、イメージが最初に使用する際に <filename>/var/"" ""lib/nova/instances/_base</filename> にコピーされていた。何故イメージが見つか"" ""らないのか？私はそのディレクトリをチェックし、イメージがないことを知った。"" msgid """" ""The <placeholder-1/> looked very, very weird. In short, it looked as though "" ""network communication stopped before the instance tried to renew its IP. "" ""Since there is so much DHCP chatter from a one minute lease, it's very hard "" ""to confirm it, but even with only milliseconds difference between packets, "" ""if one packet arrives first, it arrived first, and if that packet reported "" ""network issues, then it had to have happened before DHCP."" msgstr """" ""<placeholder-1/> の結果は非常に奇妙だった。一言で言えば、インスタンスが IP ア"" ""ドレスを更新しようとする前に、まるでネットワーク通信が停止しているように見え"" ""た。１分間のリース期間で大量の DHCP ネゴシエーションがあるため、確認作業は困"" ""難を極めた。しかし、パケット間のたった数ミリ秒の違いであれ、あるパケットが最"" ""初に到着する際、そのパケットが最初に到着し、そのパケットがネットワーク障害を"" ""報告した場合、DHCP より前にネットワーク障害が発生していることになる。"" msgid ""The I/O statistics of your storage services"" msgstr ""ストレージサービスの I/O の統計"" msgid """" ""The Identity Service supports different plug-ins for authentication "" ""decisions and identity storage. Examples of these plug-ins include:"" msgstr """" ""Identity サービスは、バックエンド認証と情報保持のために種々のプラグインをサ"" ""ポートしています。これらの選択肢は、現在は以下の物が含まれています。"" msgid """" ""The Logical Volume Manager is a Linux-based system that provides an "" ""abstraction layer on top of physical disks to expose logical volumes to the "" ""operating system. The LVM backend implements block storage as LVM logical "" ""partitions."" msgstr """" ""論理ボリュームマネージャー (LVM) は Linux ベースのシステムで、物理ディスク上"" ""に抽象層を提供して論理ボリュームをオペレーティングシステムに公開します。LVM "" ""バックエンドは、LVM 論理パーティションとしてブロックストレージを実装します。"" msgid """" ""The OpenStack Compute API is extensible. An extension adds capabilities to "" ""an API beyond those defined in the core. The introduction of new features, "" ""MIME types, actions, states, headers, parameters, and resources can all be "" ""accomplished by means of extensions to the core API. This allows the "" ""introduction of new features in the API without requiring a version change "" ""and allows the introduction of vendor-specific niche functionality."" msgstr """" ""OpenStack Compute API は拡張可能です。ある拡張は、ある API にコア定義を超えた"" ""ケイパビリティを追加します。新機能、新しい MIME タイプ、アクション、状態、"" ""ヘッダ、パラメータ、そしてリソースの導入は、コア API の拡張によって達成するこ"" ""とができます。これにより、API に対してバージョンを変更することなく新機能を導"" ""入することができ、ベンダー固有の特定の機能を導入することもできます。"" msgid """" ""The OpenStack Identity Service (keystone) is the point that provides the "" ""authentication decisions and user attribute information, which is then used "" ""by the other OpenStack services to perform authorization. Policy is set in "" ""the <filename>policy.json</filename> file. For <phrase role=\""keep-together"" ""\"">information</phrase> on how to configure these, see <xref linkend="" ""\""projects_users\""/>.<indexterm class=\""singular\""><primary>Identity "" ""Service</primary><secondary>authentication decisions</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>plug-in support</secondary></indexterm>"" msgstr """" ""OpenStack Identity Service (Keystone) は、認証の判定とユーザの属性情報を提供"" ""する場となり、他の OpenStack サービスから認証のために使用されます。ポリシー"" ""は <filename>policy.json</filename> で記述されます。これらを設定するための"" ""<phrase role=\""keep-together\"">情報</phrase>については、<xref linkend="" ""\""projects_users\""/> を参照してください。<indexterm class=\""singular"" ""\""><primary>Identity サービス</primary><secondary>認証の判定</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Identity サービス</"" ""primary><secondary>プラグインサポート</secondary></indexterm>"" msgid """" ""The OpenStack Networking service is run on all controller nodes, ensuring at "" ""least one instance will be available in case of node failure. It also sits "" ""behind HAProxy, which detects if the software fails and routes requests "" ""around the failing instance."" msgstr """" ""OpenStack Networking Service は、全コントローラーノード上で実行され、ノードの"" ""障害が発生した場合に少なくとも 1 インスタンスが利用可能となるようにします。"" ""また、このサービスは、ソフトウェアの障害を検出して、障害の発生したインスタン"" ""スを迂回するように要求をルーティングする HAProxy の背後に配置されます。"" msgid """" ""The OpenStack dashboard (horizon) provides a web-based user interface to the "" ""various OpenStack components. The dashboard includes an end-user area for "" ""users to manage their virtual infrastructure and an admin area for cloud "" ""operators to manage the OpenStack environment as a whole.<indexterm class="" ""\""singular\""><primary>dashboard</primary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>dashboard</"" ""secondary></indexterm>"" msgstr """" ""OpenStackダッシュボード(horizon)は様々なOpenStackコンポーネントのウェブベース"" ""ユーザーインターフェースを提供します。ダッシュボードにはエンドユーザの仮想イ"" ""ンフラを管理するための領域と、OpenStack環境全体を管理するためのクラウド管理者"" ""のための管理者領域が含まれます。<indexterm class=\""singular\""><primary>ダッ"" ""シュボード</primary></indexterm><indexterm class=\""singular\""><primary>設計上"" ""の考慮事項</primary><secondary>ダッシュボード</secondary></indexterm>"" msgid """" ""The OpenStack service's policy engine matches a policy directly. A rule "" ""indicates evaluation of the elements of such policies. For instance, in a "" ""<code>compute:create: [[\""rule:admin_or_owner\""]]</code> statement, the "" ""policy is <code>compute:create</code>, and the rule is <code>admin_or_owner</"" ""code>."" msgstr """" ""OpenStack サービスのポリシーエンジンがポリシーと直接照合を行います。ルールは"" ""そのようなポリシーの要素の評価を意味します。たとえば、<code>compute:create: "" ""[[\""rule:admin_or_owner\""]]</code> 文において、ポリシーは <code>compute:"" ""create</code> で、ルールは <code>admin_or_owner</code> です。"" msgid ""The REST API"" msgstr ""REST API"" msgid """" ""The Real Estate team at Rackspace in Austin, also known as \""The Victors,\"" "" ""were super responsive."" msgstr """" ""「The Victors」としても知られている、オースチンの Rackspace の不動産チーム"" ""は、素晴らしい応答をしてくれました。"" msgid """" ""The Red Hat Distributed OpenStack package offers an easy way to download the "" ""most current OpenStack release that is built for the Red Hat Enterprise "" ""Linux platform."" msgstr """" ""Red Hat Distributed OpenStack パッケージは、Red Hat Enterprise Linux プラット"" ""フォーム用に構築された最新の OpenStack リリースを容易にダウンロードする方法を"" ""提供します。"" msgid """" ""The Solaris iSCSI driver for OpenStack Block Storage implements blocks as "" ""ZFS entities. ZFS is a file system that also has the functionality of a "" ""volume manager. This is unlike on a Linux system, where there is a "" ""separation of volume manager (LVM) and file system (such as, ext3, ext4, "" ""xfs, and btrfs). ZFS has a number of advantages over ext4, including "" ""improved data-integrity checking."" msgstr """" ""OpenStack Block Storage 用の Solaris iSCSI ドライバーは、ZFS エンティティーと"" ""してブロックを実装します。ZFS は、ボリュームManagerの機能が備わっているファイ"" ""ルシステムです。これは、ボリュームマネージャー (LVM) およびファイルシステム "" ""(ext3、ext4、xfs、btrfs など) が分離している Linux システムとは違います。ZFS "" ""は、向上されたデータ整合性チェックなど、ext4 よりも多数利点があります。"" msgid ""The Starting Point"" msgstr ""出発点"" msgid ""The Valentine's Day Compute Node Massacre"" msgstr ""バレンタインデーのコンピュートノード大虐殺"" msgid """" ""The ZFS backend for OpenStack Block Storage supports only Solaris-based "" ""systems, such as Illumos. While there is a Linux port of ZFS, it is not "" ""included in any of the standard Linux distributions, and it has not been "" ""tested with OpenStack Block Storage. As with LVM, ZFS does not provide "" ""replication across hosts on its own; you need to add a replication solution "" ""on top of ZFS if your cloud needs to be able to handle storage-node failures."" msgstr """" ""OpenStack Block Storage の ZFS バックエンドは、Illumos などの Solaris ベース"" ""のシステムのみをサポートします。ZFS の Linux ポートは存在するものの、標準の "" ""Linux ディストリビューションには含まれておらず、OpenStack Block Storage では"" ""テストされていません。LVM では、ZFS はこれだけではホスト間の複製ができませ"" ""ん。つまり、お使いのクラウドでストレージノードの問題を処理する機能が必要な場"" ""合、ZFS に複製ソリューションを追加する必要があります。"" msgid ""The bonded 10gb network device (bond0) was in a DOWN state"" msgstr ""冗長化された 10Gb ネットワークデバイス(bond0）は DOWN 状態だった。"" msgid ""The bug impacts are categorized as follows:"" msgstr ""バグ影響度は以下のカテゴリに分かれています。"" msgid """" ""The chassis size of the compute node can limit the number of spindles able "" ""to be used in a compute node."" msgstr """" ""コンピュートノードの筐体サイズによって、コンピュートノードに搭載できるディス"" ""ク数が制限されます。"" msgid """" ""The choice of <emphasis>RabbitMQ</emphasis> over other AMQP compatible "" ""options that are gaining support in OpenStack, such as ZeroMQ and Qpid, is "" ""due to its ease of use and significant testing in production. It also is the "" ""only option that supports features such as Compute cells. We recommend "" ""clustering with RabbitMQ, as it is an integral component of the system and "" ""fairly simple to implement due to its inbuilt nature.<indexterm class="" ""\""singular\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></"" ""indexterm>"" msgstr """" ""OpenStack では AMQP 互換の選択肢として ZeroMQ や Qpid などのサポートが進んで"" ""いますが、<emphasis>RabbitMQ</emphasis> を選んだのは、その使いやすさと本番環"" ""境で十分にテストされているのが理由です。また、RabbitMQ は Compute Cell といっ"" ""た機能でサポートされている唯一の選択肢です。メッセージキューは OpenStack シス"" ""テムで不可欠のコンポーネントで、RabbitMQ 自体で元々サポートされているため、極"" ""めて簡単に実装できます。このため、RabbitMQ は クラスター構成にすることを推奨"" ""します。<indexterm class=\""singular\""><primary>Advanced Message Queuing "" ""Protocol (AMQP)</primary></indexterm>"" msgid """" ""The cloud controller and storage proxy are very similar to each other when "" ""it comes to expected and unexpected downtime. One of each server type "" ""typically runs in the cloud, which makes them very noticeable when they are "" ""not running."" msgstr """" ""想定内の場合も想定外の場合も停止時間が発生した場合の挙動が、クラウドコント"" ""ローラーとストレージプロキシは互いに似ています。クラウドコントローラーとスト"" ""レージプロキシはそれぞれクラウドで一つ実行されるので、動作していない場合、非"" ""常に目立ちます。"" msgid """" ""The cloud controller manages the following services for the cloud:<indexterm "" ""class=\""singular\""><primary>cloud controllers</primary><secondary>services "" ""managed by</secondary></indexterm>"" msgstr """" ""クラウドコントローラーはクラウドの次のサービスを管理します:<indexterm class="" ""\""singular\""><primary>クラウドコントローラー</primary><secondary>管理対象サー"" ""ビス</secondary></indexterm>"" msgid """" ""The cloud controller provides the central management system for OpenStack "" ""deployments. Typically, the cloud controller manages authentication and "" ""sends messaging to all the systems through a message queue."" msgstr """" ""クラウドコントローラは、複数ノードで構成されるOpenStack構成に対する集中管理機"" ""能を提供します。典型的には、クラウドコントローラは認証および、メッセージ"" ""キューを通じたメッセージのやりとりを管理します。"" msgid """" ""The cloud controller receives the <code>255.255.255.255</code> request and "" ""sends a third response."" msgstr """" ""クラウドコントローラーは <code>255.255.255.255</code> 宛のリクエストを受信"" ""し、３番めのレスポンスを返す。"" msgid """" ""The cloud controller runs the dashboard, the API services, the database "" ""(MySQL), a message queue server (RabbitMQ), the scheduler for choosing "" ""compute resources (<literal>nova-scheduler</literal>), Identity services "" ""(keystone, <code>nova-consoleauth</code>), Image services (<code>glance-api</"" ""code>, <code>glance-registry</code>), services for console access of guests, "" ""and Block Storage services, including the scheduler for storage resources "" ""(<code>cinder-api</code> and <code>cinder-scheduler</code>).<indexterm class="" ""\""singular\""><primary>cloud controllers</primary><secondary>duties of</"" ""secondary></indexterm>"" msgstr """" ""クラウドコントローラーは、ダッシュボード、API サービス、データベース "" ""(MySQL)、メッセージキューサーバー (RabbitMQ)、コンピュートリソースを選択する"" ""スケジューラー (<literal>nova-scheduler</literal>)、Identity Service "" ""(keystone、<code>nova-consoleauth</code>)、Image Service (<code>glance-api</"" ""code>、 <code>glance-registry</code>)、ゲストのコンソールアクセスのためのサー"" ""ビス、ストレージリソースのスケジューラーを含む Block Storage Service "" ""(<code>cinder-api</code> および <code>cinder-scheduler</code>) を実行します。"" ""<indexterm class=\""singular\""><primary>クラウドコントローラー</"" ""primary><secondary>役割</secondary></indexterm>"" msgid """" ""The command-line tools can be made to show the OpenStack API calls they make "" ""by passing the <code>--debug</code> flag to them.<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</primary><secondary>API "" ""calls, inspecting</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>command-line tools</primary><secondary>inspecting API calls</"" ""secondary></indexterm> For example:"" msgstr """" ""コマンドラインツールに <code>--debug</code> フラグを渡すことにより、実行す"" ""る OpenStack API コールを表示することができます。<indexterm class="" ""\""singular\""><primary>API (Application Programming Interface)</"" ""primary><secondary>API コール、検査</secondary></indexterm><indexterm class="" ""\""singular\""><primary>コマンドラインツール</primary><secondary>API コールの検"" ""査</secondary></indexterm> 例えば、以下のようになります。"" msgid """" ""The concepts supporting OpenStack's authentication and authorization are "" ""derived from well-understood and widely used systems of a similar nature. "" ""Users have credentials they can use to authenticate, and they can be a "" ""member of one or more groups (known as projects or tenants, interchangeably)."" ""<indexterm class=\""singular\""><primary>credentials</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authorization</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authentication</primary></"" ""indexterm><indexterm class=\""singular\""><primary>design considerations</"" ""primary><secondary>authentication/authorization</secondary></indexterm>"" msgstr """" ""OpenStackの認証と承認は良く知られ、幅広いシステムで良く利用されている物から来"" ""ています。ユーザは認証のためにクレデンシャルを持ち、1つ以上のグループ(プロ"" ""ジェクトまたはテナントと呼ばれます)のメンバーとなる事ができます。<indexterm "" ""class=\""singular\""><primary>クレデンシャル</primary></indexterm><indexterm "" ""class=\""singular\""><primary>認証</primary></indexterm><indexterm class="" ""\""singular\""><primary>承認</primary></indexterm><indexterm class=\""singular"" ""\""><primary>設計上の考慮事項</primary><secondary>認証/承認</secondary></"" ""indexterm>""msgid ""The connection strings take this format:"" msgstr ""connection 文字列は以下の形式をとります。"" ""The dashboard is implemented as a Python web application that normally runs "" ""in <glossterm>Apache</glossterm><code>httpd</code>. Therefore, you may treat "" ""it the same as any other web application, provided it can reach the API "" ""servers (including their admin endpoints) over the <phrase role=\""keep-"" ""together\"">network</phrase>.<indexterm class=\""singular\""><primary>Apache</"" ""primary></indexterm>""""ダッシュボードはPythonのウェブアプリケーションとして実装され、通常は"" ""<glossterm>Apache</glossterm><code>httpd</code>サーバ上で稼働します。したがっ"" ""て、そこから <phrase role=\""keep-together\"">ネットワーク</phrase>経由で (管理"" ""者 エンドポイントを含む) API サーバーにアクセスできるという条件の下、他の任意"" ""の Web アプリケーションと同じように取り扱うことができます。<indexterm class="" ""\""singular\""><primary>Apache</primary></indexterm>""""The dashboard makes many requests, even more than the API access, so add "" ""even more CPU if your dashboard is the main interface for your users.""""ダッシュボードは、APIアクセスよりもさらに多くのリクエストを発行します。そのた"" ""め、もしユーザに対するインタフェースがダッシュボードなのであれば、より多くの"" ""CPUを追加してください。""""The decisions you make with respect to provisioning and deployment will "" ""affect your day-to-day, week-to-week, and month-to-month maintenance of the "" ""cloud. Your configuration management will be able to evolve over time. "" ""However, more thought and design need to be done for upfront choices about "" ""deployment, disk partitioning, and network configuration.""""プロビジョニングやデプロイメントでの意思決定は、クラウドの日次、週次、月次の"" ""メンテナンスに影響を与えます。設定管理は時が経つにつれ進化することができま"" ""す。しかし、デプロイメント、ディスクのパーティショニング、ネットワーク設定を"" ""事前に選択するには、さらに検討、設計が必要になります。""""The default CPU allocation ratio of 16:1 means that the scheduler allocates "" ""up to 16 virtual cores per physical core. For example, if a physical node "" ""has 12 cores, the scheduler sees 192 available virtual cores. With typical "" ""flavor definitions of 4 virtual cores per instance, this ratio would provide "" ""48 instances on a physical node.""""デフォルトの CPU 割当比は 16:1 で、これは、物理コア 1 つにつき仮想コアが最大 "" ""16 個までスケジューラーにより割り当てることができることを意味します。例えば、"" ""物理ノードにコアが 12 個ある場合、スケジューラーには、使用可能な仮想コアが "" ""192 個あることになります。インスタンス 1 個に仮想コア 4 個という通常のフレー"" ""バーの定義では、この比率をもとにすると、1 つの物理にインスタンスが 48 個割り"" ""当てらることになります。""""The default OpenStack flavors are shown in <xref linkend=\""os-flavors-table"" ""\""/>."" msgstr """" ""デフォルトの OpenStack フレーバーは <xref linkend=\""os-flavors-table\""/> に表"" ""示されています。"" msgid """" ""The existence of the <code>*-manage</code> tools is a legacy issue. It is a "" ""goal of the OpenStack project to eventually migrate all of the remaining "" ""functionality in the <code>*-manage</code> tools into the API-based tools. "" ""Until that day, you need to SSH into the <glossterm>cloud controller node</"" ""glossterm> to perform some maintenance operations that require one of the "" ""<phrase role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> "" ""tools</phrase>.<indexterm class=\""singular\""><primary>cloud controller "" ""nodes</primary><secondary>command-line tools and</secondary></indexterm>"" msgstr """" ""<code>*-manage</code> ツールの存在は、レガシーの問題です。OpenStack プロジェ"" ""クトでは、最終的には <code>*-manage</code> ツールの残りの機能をすべて API "" ""ベースのツールに移行することを目標としています。移行が完了するまで、<phrase "" ""role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> ツール</"" ""phrase> を必要とするメンテナンス操作は、<glossterm>クラウドコントローラーノー"" ""ド</glossterm> に SSH 接続して実行する必要があります。<indexterm class="" ""\""singular\""><primary>クラウドコントローラーノード</primary><secondary>コマン"" ""ドラインツール</secondary></indexterm>"" msgid """" ""The file system does not have any \""dirty\"" buffers: where programs have "" ""issued the command to write to disk, but the operating system has not yet "" ""done the write"" msgstr """" ""ファイルシステムが「ダーティー」バッファーを持たないこと: 「ダーティー」バッ"" ""ファーがあるとは、プログラムがディスクに書き込むためにコマンドを発行しました"" ""が、オペレーティングシステムがまだ書き込みを完了していないことです。"" msgid """" ""The first step is setting the aggregate metadata keys "" ""<parameter>cpu_allocation_ratio</parameter> and "" ""<parameter>ram_allocation_ratio</parameter> to a floating-point value. The "" ""filter schedulers <parameter>AggregateCoreFilter</parameter> and "" ""<parameter>AggregateRamFilter</parameter> will use those values rather than "" ""the global defaults in <filename>nova.conf</filename> when scheduling to "" ""hosts in the aggregate. It is important to be cautious when using this "" ""feature, since each host can be in multiple aggregates but should have only "" ""one allocation ratio for each resources. It is up to you to avoid putting a "" ""host in multiple aggregates that define different values for the same "" ""<phrase role=\""keep-together\"">resource</phrase>."" msgstr """" ""最初のステップは、<parameter>cpu_allocation_ratio</parameter> と "" ""<parameter>ram_allocation_ratio</parameter> のアグリゲートメタデータキーを浮"" ""動小数点の値に設定します。<parameter>AggregateCoreFilter</parameter> と "" ""<parameter>AggregateRamFilter</parameter> のフィルタースケジューラーは、アグ"" ""リゲートのホストにスケジューリングしている場合、<filename>nova.conf</"" ""filename> のグローバルの初期値を仕様するのではなく、この値を使用します。各ホ"" ""ストは複数のアグリゲートに含まれていますがリソースごとに 1 つの割当比率しか指"" ""定されていないため、この機能の使用時は、注意が必要です。同じ <phrase role="" ""\""keep-together\"">リソース</phrase> に対して別の値が定義されている複数のアグ"" ""リゲートにホストを設置しないように注意してください。"" msgid """" ""The first thing you must do is authenticate with the cloud using your "" ""credentials to get an <glossterm>authentication token</glossterm>."" msgstr """" ""まずはじめに、クラウドの認証が必要です。あなたの認証情報を用いて<glossterm>認"" ""証トークン</glossterm>を入手してください。"" msgid """" ""The following command requires you to have your shell environment configured "" ""with the proper administrative variables:"" msgstr """" ""以下のコマンドを実行するには、管理系の変数を正しく設定したシェル環境が必要で"" ""す。"" msgid """" ""The following diagrams (<xref linkend=\""node_controller-diagram\""/> through "" ""<xref linkend=\""node_storage-diagram\""/>) include logical information about "" ""the different types of nodes, indicating what services will be running on "" ""top of them and how they interact with each other. The diagrams also "" ""illustrate how the availability and scalability of services are achieved."" msgstr """" ""以下の図 (<xref linkend=\""node_controller-diagram\""/> through <xref linkend="" ""\""node_storage-diagram\""/>) には、異なるタイプのノードについての論理的情報が"" ""含まれます。この図には、実行されるサービスやそれらがどのように相互に対話する"" ""かが示されています。また、サービスの可用性とスケーラビリティがどのように実現"" ""されるかについても図示しています。"" msgid """" ""The following features of OpenStack are supported by the example "" ""architecture documented in this guide, but are optional:<placeholder-1/>"" msgstr """" ""以下にあげる OpenStack の機能は、本ガイドに記載のアーキテクチャではサポートさ"" ""れていますが、必須項目ではありません。<placeholder-1/>"" msgid """" ""The following section details how the nodes are connected to the different "" ""networks (see <xref linkend=\""networking_layout\""/>) and what other "" ""considerations need to take place (for example, bonding) when connecting "" ""nodes to the networks."" msgstr """" ""以下のセクションでは、ノードを異なるネットワークに接続する方法 ( <xref "" ""linkend=\""networking_layout\""/> を参照) と、ノードをネットワークに接続する際"" ""に他に考慮すべき点 (例: ボンディング) について説明します。"" msgid """" ""The formula for the number of virtual instances on a compute node is "" ""<emphasis>(OR*PC)/VC</emphasis>, where:"" msgstr """" ""コンピュートノード上の仮想インスタンス数の公式は、 <emphasis>(OR*PC)/VC</"" ""emphasis> です。それぞれ以下を意味します。"" msgid """" ""The general case for this is setting key-value pairs in the aggregate "" ""metadata and matching key-value pairs in flavor's <parameter>extra_specs</"" ""parameter> metadata. The <parameter>AggregateInstanceExtraSpecsFilter</"" ""parameter> in the filter scheduler will enforce that instances be scheduled "" ""only on hosts in aggregates that define the same key to the same value."" msgstr """" ""この一般的なケースは、アグリゲートメタデータで key-value ペアを設定して、フ"" ""レーバーの <parameter>extra_specs</parameter> メタデータで key-value ペアを一"" ""致させます。フィルタースケジューラーの "" ""<parameter>AggregateInstanceExtraSpecsFilter</parameter> は、強制的にインスタ"" ""ンスが、同じ値に同じキーが定義されているアグリゲートのホストに対してのみスケ"" ""ジューリングするようにします。"" msgid ""The generated file looks something like this:"" msgstr ""出力は以下のようになります。"" msgid """" ""The initial implementation of the OpenStack Compute Service (nova) had its "" ""own authentication system and used the term <literal>project</literal>. When "" ""authentication moved into the OpenStack Identity Service (keystone) project, "" ""it used the term <literal>tenant</literal> to refer to a group of users. "" ""Because of this legacy, some of the OpenStack tools refer to projects and "" ""some refer to tenants."" msgstr """" ""OpenStack Compute サービス (Nova) の初期実装は独自の認証システムを持ち、"" ""<literal>プロジェクト</literal>という用語を使用していました。認証が "" ""OpenStack Identity サービス (Keystone) プロジェクトに移行したとき、ユーザーの"" ""グループを意味する用語として<literal>テナント</literal>という用語が使用されま"" ""した。このような経緯のため、いくつかの OpenStack ツールはプロジェクトを使用"" ""し、いくつかはテナントを使用します。"" msgid ""The instance finally gives up."" msgstr ""最終的に、インスタンスはIPアドレス取得を諦める。"" msgid ""The load shot up to 8 right before I received the alert"" msgstr ""私が警告を受け取る直前、負荷率は８に急増した。"" msgid """" ""The main advantage of this option is that it scales to external storage when "" ""you require additional storage."" msgstr """" ""このオプションの主な利点は、追加ストレージが必要な場合、外部ストレージにス"" ""ケールアウトできる点です。"" msgid ""The main downsides to this approach are:"" msgstr ""この方法の主なマイナス面は以下の点です。"" msgid """" ""The main reason to use GFO rather than regular swift is if you also want to "" ""support a distributed file system, either to support shared storage live "" ""migration or to provide it as a separate service to your end users. If you "" ""want to manage your object and file storage within a single system, you "" ""should consider GFO."" msgstr """" ""通常の swift ではなく GFO を使用するのは、主に、分散ファイルシステムのサポー"" ""トや、共有ストレージのライブマイグレーションのサポートを提供したり、エンド"" ""ユーザーに個別サービスとして提供したりするためです。単一システムでオブジェク"" ""トとファイルストレージを管理する場合は、GFO の使用を検討してください。"" msgid """" ""The network consists of two switches, one for the management or private "" ""traffic, and one that covers public access, including floating IPs. To "" ""support this, the cloud controller and the compute nodes have two network "" ""cards. The OpenStack Block Storage and NFS storage servers only need to "" ""access the private network and therefore only need one network card, but "" ""multiple cards run in a bonded configuration are recommended if possible. "" ""Floating IP access is direct to the Internet, whereas Flat IP access goes "" ""through a NAT. To envision the network traffic, use this diagram:"" msgstr """" ""ネットワークは、2 つのスイッチで構成され、1 つは管理/プライベートトラフィック"" ""用、もう 1 つは Floating IP を含むパブリックアクセスが対象です。この構成に対"" ""応するために、クラウドコントローラーおよびコンピュートノードで NIC を 2 枚を"" ""装備します。OpenStack Block Storage および NFS ストレージサーバーは、プライ"" ""ベートネットワークにのみアクセスする必要があるので、必要な NIC は 1 枚です"" ""が、可能な場合には複数の NIC をボンディング構成で動作させることを推奨します。"" ""Floating IP のアクセスは、インターネットに直結ですが、Flat IP のアクセスは "" ""NAT 経由となります。ネットワークトラフィックの構想には、以下の図を利用してく"" ""ださい。"" msgid """" ""The network contains all the management devices for all hardware in the "" ""environment (for example, by including Dell iDrac7 devices for the hardware "" ""nodes, and management interfaces for network switches). The network is "" ""accessed by internal staff only when diagnosing or recovering a hardware "" ""issue."" msgstr """" ""ネットワークには、環境内の全ハードウェア用の管理デバイスがすべて含まれます "" ""(例: ハードウェアノード用の Dell iDrac7 デバイスやネットワークスイッチ用の管"" ""理インターフェースの追加による) 。ネットワークは、ハードウェア問題の診断また"" ""はリカバリを実行する場合にのみ内部スタッフがアクセスします。"" msgid """" ""The nova API, scheduler, objectstore, cert, consoleauth, conductor, and "" ""vncproxy services are run on all controller nodes, ensuring at least one "" ""instance will be available in case of node failure. Compute is also behind "" ""HAProxy, which detects when the software fails and routes requests around "" ""the failing instance."" msgstr """" ""nova API、scheduler、objectstore、cert、consoleauth、conductor、および "" ""vncproxy のサービスは、全コントローラーノードで実行され、ノードに障害が発生し"" ""た場合には少なくとも 1 インスタンスが利用可能となるようにします。Compute "" ""は、ソフトウェアの障害を検出して、障害の発生したインスタンスを迂回するように"" ""要求をルーティングする HAProxy の背後に配置されます。"" msgid ""The number of Object Storage requests each hour"" msgstr ""1時間あたりの Object Storage リクエスト数"" msgid """" ""The number of cores that the CPU has also affects the decision. It's common "" ""for current CPUs to have up to 12 cores. Additionally, if an Intel CPU "" ""supports hyperthreading, those 12 cores are doubled to 24 cores. If you "" ""purchase a server that supports multiple CPUs, the number of cores is "" ""further multiplied.<indexterm class=\""singular\""><primary>cores</primary></"" ""indexterm><indexterm class=\""singular\""><primary>hyperthreading</primary></"" ""indexterm><indexterm class=\""singular\""><primary>multithreading</primary></"" ""indexterm>"" msgstr """" ""CPU のコア数も選択に影響します。現在の CPU では最大 12 コアあるのが一般的で"" ""す。さらに、Intel CPU がハイパースレッディングをサポートしている場合、12 コア"" ""は 2 倍の 24 コアになります。複数の CPU をサポートするサーバーを購入する場"" ""合、コア数はさらに倍になっていきます。<indexterm class=\""singular\""><primary>"" ""コア</primary></indexterm><indexterm class=\""singular\""><primary>ハイパース"" ""レッディング</primary></indexterm><indexterm class=\""singular\""><primary>マル"" ""チスレッド</primary></indexterm>"" msgid ""The number of instances on each compute node"" msgstr ""各コンピュートノード上のインスタンス数"" msgid """" ""The number of virtual machines (VMs) you expect to run, <code>((overcommit "" ""fraction </code>"" msgstr ""実行する必要のある仮想マシン数。<code>((overcommit fraction </code>"" msgid ""The number of volumes in use"" msgstr ""使用中のボリューム数"" msgid """" ""The official OpenStack Object Store implementation. It is a mature "" ""technology that has been used for several years in production by Rackspace "" ""as the technology behind Rackspace Cloud Files. As it is highly scalable, it "" ""is well-suited to managing petabytes of storage. OpenStack Object Storage's "" ""advantages are better <phrase role=\""keep-together\"">integration</phrase> "" ""with OpenStack (integrates with OpenStack Identity, works with the OpenStack "" ""dashboard interface) and better support for multiple data center deployment "" ""through support of asynchronous eventual consistency replication."" msgstr """" ""公式の OpenStack Object Store 実装。Rackspace Cloud Filesのベースとなる技術と"" ""して、RackSpace により実稼動環境で数年間使用された成熟テクノロジーです。拡張"" ""性が高いため、ペタバイトレベルのストレージを管理するのに非常に適しています。"" ""OpenStack Object Storage の利点は OpenStack (OpenStack Identity と統合し、"" ""OpenStack Dashboard インターフェースと連携) と<phrase role=\""keep-together\"">"" ""統合でき</phrase>、非同期のイベントを一貫性を保ちながら複製できるため、複数の"" ""データセンターのデプロイメントへのサポートも向上されています。"" msgid """" ""The other directories are titled <code>instance-xxxxxxxx</code>. These "" ""directories correspond to instances running on that compute node. The files "" ""inside are related to one of the files in the <code>_base</code> directory. "" ""They're essentially differential-based files containing only the changes "" ""made from the original <code>_base</code> directory."" msgstr """" ""もう一つのディレクトリは <code>instance-xxxxxxxx</code> という名前です。これ"" ""らのディレクトリはコンピュートノードにおいて実行中のインスタンスと対応しま"" ""す。中にあるファイルは <code>_base</code> ディレクトリにあるファイルのどれか"" ""と関連があります。これらは基本的に、元々の <code>_base</code> ディレクトリか"" ""らの変更点のみ含む、差分ベースのファイルです。"" msgid ""The output looks like the following:"" msgstr ""出力は以下のようになります。"" msgid """" ""The output shows that there are five compute nodes and one cloud controller. "" ""You see a smiley face, such as <code>:-)</code>, which indicates that the "" ""services are up and running. If a service is no longer available, the "" ""<code>:-)</code> symbol changes to <code>XXX</code>. This is an indication "" ""that you should troubleshoot why the service is down."" msgstr """" ""出力には、5 つのコンピュートノードと 1 つのクラウドコントローラーが表示されて"" ""います。スマイリーフェイス <code>:-)</code> が見えます。これはサービスが稼働"" ""中であることを示しています。サービスが利用できなくなると、<code>:-)</code> の"" ""シンボルが <code>XXX</code> に変わります。これは、サービスが停止している理由"" ""をトラブルシューティングする必要があることを示しています。"" msgid """" ""The pip utility is used to manage package installation from the PyPI archive "" ""and is available in the python-pip package in most Linux distributions. Each "" ""OpenStack project has its own client, so depending on which services your "" ""site runs, install some or all of the following<indexterm class=\""singular"" ""\""><primary>neutron</primary><secondary>python-neutronclient</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>swift</"" ""primary><secondary>python-swiftclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>cinder</primary></indexterm><indexterm class="" ""\""singular\""><primary>keystone</primary></indexterm><indexterm class="" ""\""singular\""><primary>glance</primary><secondary>python-glanceclient</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>nova</"" ""primary><secondary>python-novaclient</secondary></indexterm> packages:"" msgstr """" ""pip ユーティリティは、PyPI アーカイブからのパッケージインストールの管理に使"" ""用するツールで、大半の Linux ディストリビューションの python-pip パッケージに"" ""含まれています。各 OpenStack プロジェクトにはそれぞれ独自のクライアントがあり"" ""ます。サイトで実行するサービスに応じて、以下のパッケージの一部またはすべてを"" ""インストールしてください。<indexterm class=\""singular\""><primary>neutron</"" ""primary><secondary>python-neutronclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>swift</primary><secondary>python-swiftclient</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>cinder</"" ""primary></indexterm><indexterm class=\""singular\""><primary>keystone</"" ""primary></indexterm><indexterm class=\""singular\""><primary>glance</"" ""primary><secondary>python-glanceclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>nova</primary><secondary>python-novaclient</""""The preceding output has been truncated to show only two services. You will "" ""see one service block for each service that your cloud provides. Note how "" ""the endpoint domain can be different depending on the endpoint type. "" ""Different endpoint domains per type are not required, but this can be done "" ""for different reasons, such as endpoint privacy or network traffic "" ""segregation.""""上記の出力は、2 つのサービスのみを表示するようにカットされています。クラウド"" ""が提供するサービスごとにサービスブロックが 1 つ表示されているのがわかります。"" ""エンドポイントタイプによってエンドポイントドメインが異なる場合がある点に注意"" ""してください。タイプによってエンドポイントドメインを別にする必要はありません"" ""が、エンドポイントのプライバシーやネットワークトラフィックの分離などの異なる"" ""理由で分けることができます。""""The purpose of automatic configuration management is to establish and "" ""maintain the consistency of a system without using human intervention. You "" ""want to maintain consistency in your deployments so that you can have the "" ""same cloud every time, repeatably. Proper use of automatic configuration-"" ""management tools ensures that components of the cloud systems are in "" ""particular states, in addition to simplifying deployment, and configuration "" ""change propagation.<indexterm class=\""singular\""><primary>automated "" ""configuration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>automated "" ""configuration</secondary></indexterm>""""自動環境設定管理の目的は、人間の介在なしにシステムの一貫性を確保、維持するこ"" ""とにあります。毎回、同じクラウド環境を繰り返し作るために、デプロイメントにお"" ""ける一貫性を確保します。自動環境設定管理ツールを正しく利用することによって、"" ""デプロイメントと環境設定の変更を伝搬する作業を簡素化するだけでなく、クラウド"" ""システムのコンポーネントが必ず特定の状態にあるようにすることができます。"" ""<indexterm class=\""singular\""><primary>自動設定</primary></"" ""indexterm><indexterm class=\""singular\""><primary>プロビジョニング/デプロイメ"" ""ント</primary><secondary>自動設定</secondary></indexterm>""""The reference architecture consists of multiple compute nodes, a cloud "" ""controller, an external NFS storage server for instance storage, and an "" ""OpenStack Block Storage server for <glossterm>volume</glossterm> storage."" ""<indexterm class=\""singular\""><primary>legacy networking (nova)</"" ""primary><secondary>detailed description</secondary></indexterm> A network "" ""time service (Network Time Protocol, or NTP) synchronizes time on all the "" ""nodes. FlatDHCPManager in multi-host mode is used for the networking. A "" ""logical diagram for this example architecture shows which services are "" ""running on each node:""""この参照アーキテクチャは、複数のコンピュートノード、クラウドコントローラー 1 "" ""台、インスタンスストレージ用の外部 NFS ストレージサーバー 1 台、"" ""<glossterm>volume</glossterm> ストレージ用の OpenStack Block Storage サー"" ""バー 1 台で構成されます。<indexterm class=\""singular\""><primary>レガシーネッ"" ""トワーク (nova)</primary><secondary>詳しい説明</secondary></indexterm> ネット"" ""ワークタイムサービス (Network Time Protocol / NTP) は全ノードの時刻を同期しま"" ""す。ネットワークには、マルチホストモードの FlatDHCPManager を使用しています。"" ""このアーキテクチャ例の論理図には、各ノードで実行されているサービスが示されて"" ""います。""msgid """" ""The remaining point on bandwidth is the public-facing portion. The "" ""<literal>swift-proxy</literal> service is stateless, which means that you "" ""can easily add more and use HTTP load-balancing methods to share bandwidth "" ""and availability between them."" msgstr """" ""帯域幅に関する残りのポイントは、パブリック側の部分です。<literal>swift-"" ""proxy</literal> サービスは、ステートレスです。ステートレスとは、HTTP 負荷分散"" ""メソッドを簡単に追加、使用して帯域幅や可用性を共有できるという意味です。""""The simplest architecture you can build upon for Compute has a single cloud "" ""controller and multiple compute nodes. The simplest architecture for Object "" ""Storage has five nodes: one for identifying users and proxying requests to "" ""the API, then four for storage itself to provide enough replication for "" ""eventual consistency. This example architecture does not dictate a "" ""particular number of nodes, but shows the thinking <phrase role=\""keep-"" ""together\"">and considerations</phrase> that went into choosing this "" ""architecture including the features <phrase role=\""keep-together\"">offered</"" ""phrase>.<indexterm class=\""singular\""><primary>CentOS</primary></"" ""indexterm><indexterm class=\""singular\""><primary>RDO (Red Hat Distributed "" ""OpenStack)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Ubuntu</primary></indexterm><indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>component overview</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>example "" ""architectures</primary><see>legacy networking; OpenStack networking</see></"" ""indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>simplest architecture for</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Compute</"" ""primary><secondary>simplest architecture for</secondary></indexterm>"" msgstr """" ""Compute 用の基盤となる最もシンプルなアーキテクチャは、単一のクラウドコント"" ""ローラーと複数のコンピュートノードで構成されます。Object Storage 用の最もシン"" ""プルなアーキテクチャは、ユーザーを識別して API への要求をプロキシするノード "" ""1 つと、最終的な一貫性を確保するのに十分なレプリケーションを提供する、スト"" ""レージ自体のためのノード 4つを合わせた 5 つのノードで構成されます。このアーキ"" ""テクチャの例では、特定のノード数は決まっていませんが、このアーキテクチャを選"" ""択するにあたって考慮 <phrase role=\""keep-together\"">および検討した点</"" ""phrase> (どのような機能を<phrase role=\""keep-together\"">提供するか</phrase>な"" ""ど) をお分かりいただけます。<indexterm class=\""singular\""><primary>CentOS</"" ""primary></indexterm><indexterm class=\""singular\""><primary>RDO (Red Hat "" ""Distributed OpenStack)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Ubuntu</primary></indexterm><indexterm class=\""singular"" ""\""><primary>レガシーネットワーク (nova)</primary><secondary>コンポーネントの"" ""概要</secondary></indexterm><indexterm class=\""singular\""><primary>アーキテク"" ""チャ例</primary><see>レガシーネットワーク; OpenStack Networking</see></"" ""indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>最もシンプルなアーキテクチャ</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Compute</primary><secondary>"" ""最もシンプルなアーキテクチャ</secondary></indexterm>"" msgid """" ""The simplest option to get started is to use one hard drive with two "" ""partitions:"" msgstr """" ""最もシンプルに使用を開始できるオプションは、１台のハードディスクを２つのパー"" ""ティションに分割することです。"" msgid """" ""The starting point for most is the core count of your cloud. By applying "" ""some ratios, you can gather information about: <placeholder-1/> You can use "" ""these ratios to determine how much additional infrastructure you need to "" ""support your cloud."" msgstr """" ""多くの場合、クラウドのコア数から始めます。比率を適用することで、 "" ""<placeholder-1/> に関する情報を取得できます。これらの比率を使用して、クラウド"" ""のサポートに必要なインフラストラクチャーがどの程度必要か判断することができま"" ""す。"" msgid ""The team includes:"" msgstr ""以下が執筆チームのメンバーです。"" msgid """" ""The type of CPU in your compute node is a very important choice. First, "" ""ensure that the CPU supports virtualization by way of <emphasis>VT-x</"" ""emphasis> for Intel chips and <emphasis>AMD-v</emphasis> for AMD chips."" ""<indexterm class=\""singular\""><primary>CPUs (central processing units)</"" ""primary><secondary>choosing</secondary></indexterm><indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>CPU choice</"" ""secondary></indexterm>"" msgstr """" ""コンピュートノードの CPU タイプを選択することは非常に重要です。まず、Intel "" ""チップには <emphasis>VT-x</emphasis>、AMD チップには <emphasis>AMD-v</"" ""emphasis> という風に、CPU が仮想化をサポートするようにします。<indexterm "" ""class=\""singular\""><primary>CPU (central processing unit)</"" ""primary><secondary>選択</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>コンピュートノード</primary><secondary>CPU の選択</secondary></"" ""indexterm>"" msgid ""The types of flavors in use"" msgstr ""使用中のフレーバー"" msgid """" ""The typical hardware recommended for use with OpenStack is the standard "" ""value-for-money offerings that most hardware vendors stock. It should be "" ""straightforward to divide your procurement into building blocks such as "" ""\""compute,\"" \""object storage,\"" and \""cloud controller,\"" and request as "" ""many of these as you need. Alternatively, should you be unable to spend "" ""more, if you have existing servers—provided they meet your performance "" ""requirements and virtualization technology—they are quite likely to be able "" ""to support OpenStack."" msgstr """" ""OpenStack での使用に推奨しているハードウェアは一般的に、多くのハードウェアベ"" ""ンダーが提供している、コストパフォーマンスの高い標準オファリングです。調達す"" ""べきものをコンピュート、オブジェクトストレージ、クラウドコントローラなどのビ"" ""ルディングブロックに分類し、必要に応じ依頼していくと分かりやすいでしょう。ま"" ""た、投資額をこれ以上かけられない場合、既存サーバーがありパフォーマンス要件や"" ""仮想化技術に対応しているのであれば、高い確率で OpenStack をサポートしているは"" ""ずです。"" msgid """" ""The typical way is to trace the UUID associated with an instance across the "" ""service logs."" msgstr """" ""一般的な方法はインスタンスのUUIDをキーにして、各サービスのログを追跡すること"" ""です。"" msgid ""The upgrade process generally follows these steps:"" msgstr ""一般的に、アップグレード作業は以下の手順で行います。"" msgid ""Then it all made sense… <placeholder-1/>"" msgstr ""やっと事の全容が判明した… <placeholder-1/>"" msgid """" ""Then on the actual compute node, create the following NRPE configuration:"" msgstr """" ""そして、対象のコンピュートノードにおいて、次のようなNRPE設定を作成します。"" msgid ""Then start the <code>nova-compute</code> service:"" msgstr ""そして <code>nova-compute</code> サービスを起動します。"" msgid """" ""There are also several <literal>*-manage</literal> command-line tools. These "" ""are installed with the project's services on the cloud controller and do not "" ""need to be installed<indexterm class=\""singular\""><primary>*-manage command-"" ""line tools</primary></indexterm><indexterm class=\""singular"" ""\""><primary>command-line tools</primary><secondary>administrative</"" ""secondary></indexterm> separately:"" msgstr """" ""<literal>*-manage</literal> のコマンドラインツールも複数あります。これらは、"" ""プロジェクトのサービスとともにクラウドコントローラーにインストールされるの"" ""で、別途インストールする必要はありません。 <indexterm class=\""singular"" ""\""><primary>*-manage コマンドラインツール</primary></indexterm><indexterm "" ""class=\""singular\""><primary>コマンドラインツール</primary><secondary>管理系</"" ""secondary></indexterm>"" msgid """" ""There are benefits to both modes. Single-node has the downside of a single "" ""point of failure. If the cloud controller is not available, instances cannot "" ""communicate on the network. This is not true with multi-host, but multi-host "" ""requires that each compute node has a public IP address to communicate on "" ""the Internet. If you are not able to obtain a significant block of public IP "" ""addresses, multi-host might not be an option."" msgstr """" ""どちらのモードにもメリットがあります。シングルホストモードには、単一障害点と"" ""いうマイナス面があります。クラウドコントローラーが利用できなくなると、インス"" ""タンスはネットワークと通信できなくなります。マルチホストモードでは、この状況"" ""にはなりませんが、各コンピュートノードはインターネットと通信するためのパブ"" ""リックIPアドレスが必要となります。十分な大きさのパブリックIPアドレスブロック"" ""を取得できない場合には、マルチホストモードは選択肢にならないかもしれません。"" msgid """"msgid ""There are several advantages to this approach:"" msgstr ""このアプローチには複数の利点があります。""msgid ""There are two main reasons why this is a good idea:"" msgstr ""このアイデアが良いとされる理由は主に 2 点挙げられます。""""There are two main types of IP addresses for guest virtual machines: fixed "" ""IPs and floating IPs. Fixed IPs are assigned to instances on boot, whereas "" ""floating IP addresses can change their association between instances by "" ""action of the user. Both types of IP addresses can be either public or "" ""private, depending on your use case.<indexterm class=\""singular"" ""\""><primary>IP addresses</primary><secondary>public addressing options</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>public addressing options</secondary></indexterm>""""ゲストの仮想マシン用に主に2つのタイプのIPアドレス（固定IPアドレスとフローティ"" ""ングIPアドレス）があります。固定IPアドレスはインスタンス起動時に割り当てら"" ""れ、フローティングIPアドレスは、ユーザ操作によって割当が変更できます。どちら"" ""のタイプのIPアドレスも用途に合わせてパブリックまたはプライベートにする事がで"" ""きます。<indexterm class=\""singular\""><primary>IPアドレス</"" ""primary><secondary>パブリックアドレスオプション</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワーク設計</"" ""primary><secondary>パブリックアドレスオプション</secondary></indexterm>""""There are two ways to ensure stability with this directory. The first is to "" ""make sure this directory is run on a RAID array. If a disk fails, the "" ""directory is available. The second way is to use a tool such as rsync to "" ""replicate the images to another server:""""このディレクトリの永続性を保証するために二つの方法があります。一つ目はRAIDア"" ""レイ上にこのディレクトリを置くことで、ディスク障害時にもこのディレクトリが利"" ""用できます。二つ目の方法はrsyncのようなツールを用いてイメージを他のサーバーに"" ""複製することです。""""Therefore, if you eventually plan on distributing your storage cluster "" ""across multiple data centers, if you need unified accounts for your users "" ""for both compute and object storage, or if you want to control your object "" ""storage with the OpenStack dashboard, you should consider OpenStack Object "" ""Storage. More detail can be found about OpenStack Object Storage in the "" ""section below.<indexterm class=\""singular\""><primary>accounts</primary></"" ""indexterm>""""そのため、最終的に、複数のデータセンターにまたがってストレージクラスターを分"" ""散するように計画した場合、Compute およびオブジェクトストレージ用に統合アカウ"" ""ントが必要な場合、または OpenStack Dashboard でオブジェクトストレージを制御す"" ""る場合、OpenStack Object Storage を考慮してみてください。以下のセクションで "" ""OpenStack Object Storage iについて詳しく記載されています。<indexterm class="" ""\""singular\""><primary>アカウント</primary></indexterm>""""These actions effectively take the storage node out of the storage cluster."" msgstr """" ""これらの操作はストレージノードをストレージクラスターから効率的に外せます。"" msgid """" ""These drivers work a little differently than a traditional \""block\"" storage "" ""driver. On an NFS or GlusterFS file system, a single file is created and "" ""then mapped as a \""virtual\"" volume into the instance. This mapping/"" ""translation is similar to how OpenStack utilizes QEMU's file-based virtual "" ""machines stored in <code>/var/lib/nova/instances</code>."" msgstr """" ""これらのドライバーは従来のブロックストレージドライバとは少々異なる動作をしま"" ""す。NFSやGlusterFSでは1つのファイルが作成され、インスタンスに対して「仮想」ボ"" ""リュームとしてマッピングされます。このマッピング/変換は<code>/var/lib/nova/"" ""instances</code> 下に保存される、QEMUのファイルベースの仮想マシンの、"" ""OpenStackによる扱い方と同様です。"" msgid """" ""These nodes run services such as provisioning, configuration management, "" ""monitoring, or GlusterFS management software. They are not required to "" ""scale, although these machines are usually backed up."" msgstr """" ""これらのノードは、プロビジョニング、設定管理、モニタリング、GlusterFS 管理ソ"" ""フトウェアなどのサービスを実行します。拡張の必要はありませんが、これらのマシ"" ""ンは通常バックアップされます。"" msgid """" ""These volumes are persistent: they can be detached from one instance and re-"" ""attached to another, and the data remains intact. Block storage is "" ""implemented in OpenStack by the OpenStack Block Storage (cinder) project, "" ""which supports multiple backends in the form of drivers. Your choice of a "" ""storage backend must be supported by a Block Storage driver."" msgstr """" ""これらのボリュームは永続的であるため、インスタンスから切り離して、データをそ"" ""のまま維持しつつ、別のインスタンスに再接続することができます。ブロックスト"" ""レージは、ドライバー形式で複数のバックエンドをサポートする、OpenStack Block "" ""Storage (Cinder) プロジェクトで OpenStack に実装されています。お使いのスト"" ""レージバックエンドは、Block Storage ドライバーでサポートされている必要があり"" ""ます。"" msgid ""They are:"" msgstr ""次の3つの方法があります。"" msgid """" ""Thinking it was just a one-off issue, I terminated the instance and launched "" ""a new one. By then, the conference call ended and I was off to the data "" ""center."" msgstr """" ""これは単なる１回限りの問題と思ったので、私はインスタンスを削除して、新しいイ"" ""ンスタンスを起動した。その後電話会議は終了し、私はデータセンターを離れた。"" msgid """" ""This allows for a single API server being used to control access to multiple "" ""cloud installations. Introducing a second level of scheduling (the cell "" ""selection), in addition to the regular <code>nova-scheduler</code> selection "" ""of hosts, provides greater flexibility to control where virtual machines are "" ""run."" msgstr """" ""これによって、複数のクラウドシステムに対するアクセスを、１つのAPIサーバで制御"" ""することができます。通常の<code>nova-scheduler</code>によるホストの選択に加え"" ""て、第二段階のスケジューリング(セルの選択)を導入することにより、仮想マシンを"" ""実行する場所の制御の柔軟性が大きく向上します。"" msgid """" ""This architecture's components have been selected for the following reasons:"" msgstr """" ""このアーキテクチャコンポーネントは、以下のような理由で選択されています。"" msgid """" ""This book provides information about designing and operating OpenStack "" ""clouds."" msgstr ""本書は OpenStack クラウドの設計および運用に関する情報を提供します。"" msgid """" ""This can be useful when booting from volume because a new volume can be "" ""provisioned very quickly. Ceph also supports keystone-based authentication "" ""(as of version 0.56), so it can be a seamless swap in for the default "" ""OpenStack swift implementation."" msgstr """" ""新規ボリュームは非常に早くプロビジョニングされるため、ボリュームからの起動に"" ""便利です。また、Ceph は keystone ベースの認証 (バージョン 0.56 以降) もサポー"" ""トするため、デフォルトの OpenStack swift 実装とシームレスに切り替えることがで"" ""きます。"" msgid """" ""This chapter helps you set up your working environment and use it to take a "" ""look around your cloud."" msgstr """" ""本章では、作業環境を設定し、クラウドの全体像を概観するのに役立つ内容を記載し"" ""ます。"" msgid """" ""This chapter provides an example architecture using OpenStack Networking, "" ""also known as the Neutron project, in a highly available environment."" msgstr """" ""本章には、OpenStack Networking (別称: Neutron プロジェクト) を高可用性環境で"" ""使用するアーキテクチャの例を記載します。"" msgid """" ""This command creates a project named \""demo.\"" Optionally, you can add a "" ""description string by appending <code>--description <replaceable>tenant-"" ""description</replaceable></code>, which can be very useful. You can also "" ""create a group in a disabled state by appending <code>--enabled false</code> "" ""to the command. By default, projects are created in an enabled state."" msgstr """" ""このコマンドは、demo という名前のプロジェクトを作成します。オプションで、"" ""<code>--description <replaceable>tenant-description</replaceable></code> を追"" ""加することで、説明の文字列を追加することができ、非常に便利です。また、コマン"" ""ドに <code>--enabled false</code> を追加して、グループを無効な状態で作成する"" ""こともできます。デフォルトでは、有効化された状態でプロジェクトが作成されま"" ""す。"" msgid """" ""This deployment felt that the spare I/O on the Object Storage proxy server "" ""was sufficient and that the Image Delivery portion of glance benefited from "" ""being on physical hardware and having good connectivity to the Object "" ""Storage backend it was using."" msgstr """" ""この構成ではオブジェクトストレージプロクシサーバのI/Oの空きが十分にあり、"" ""glance のイメージ配信部分は物理ハードウェアとオブジェクトストレージのバック"" ""エンドに使用している良好なネットワーク接続性の恩恵を十分に受ける事ができると"" ""感じた。"" msgid """" ""This deployment had an expensive hardware load balancer in its organization. "" ""It ran multiple <code>nova-api</code> and <code>swift-proxy</code> servers "" ""on different physical servers and used the load balancer to switch between "" ""them."" msgstr """" ""この構成は、組織内に高価なハードウェアロードバランサーを持っていました。彼ら"" ""は複数の <code>nova-api</code> と<code>swift-proxy</code> サーバーを異なる物"" ""理サーバーで動作させ、その振り分けにロードバランサーを利用し増した。"" msgid """" ""This deployment ran central services on a set of servers running KVM. A "" ""dedicated VM was created for each service (<literal>nova-scheduler</"" ""literal>, rabbitmq, database, etc). This assisted the deployment with "" ""scaling because administrators could tune the resources given to each "" ""virtual machine based on the load it received (something that was not well "" ""understood during installation)."" msgstr """" ""この構成では中央サーバをKVM上のサーバで実行しました。専用のVMをそれぞれのサー"" ""ビスで用意しました(<literal>nova-scheduler</literal>, RabbitMQ, データベース"" ""など)。この構成はクラウド管理者が(インストール時によく推測できないので)それぞ"" ""れのサービスへの負荷のかかり具合によって各バーチャルマシンへのリソース割当を"" ""変更する事ができる構成でした。"" msgid """" ""This deployment used a central dedicated server to provide the databases for "" ""all services. This approach simplified operations by isolating database "" ""server updates and allowed for the simple creation of slave database servers "" ""for failover."" msgstr """" ""この構成では、すべてのサービスに対するデータベースサービスを提供する専用サー"" ""バを設置しました。これにより、データベースサーバーのアップデートを分離でき、"" ""運用がシンプルになりました。また、フェイルオーバーのためのスレーブデータベー"" ""スサーバーの設置が単純になりました。"" msgid """" ""This does not save your password in plain text, which is a good thing. But "" ""when you source or run the script, it prompts you for your password and then "" ""stores your response in the environment variable <code>OS_PASSWORD</code>. "" ""It is important to note that this does require interactivity. It is possible "" ""to store a value directly in the script if you require a noninteractive "" ""operation, but you then need to be extremely cautious with the security and "" ""permissions of this file.<indexterm class=\""singular\""><primary>passwords</"" ""primary></indexterm><indexterm class=\""singular\""><primary>security issues</"" ""primary><secondary>passwords</secondary></indexterm>"" msgstr """" ""この場合には、パスワードがプレーンテキスト形式で保存されないのがこの方法の利"" ""点となりますが、このスクリプトを元データとして使用したり、実行したりする際に"" ""は、パスワードが要求され、その回答は環境変数 <code>OS_PASSWORD</code> に保存"" ""されます。この操作は対話的に実行される必要がある点は、注意すべき重要なポイン"" ""トです。 操作を非対話的に行う必要がある場合には、値をスクリプトに直接に保存す"" ""ることも可能ですが、その場合にはこのファイルのセキュリティとアクセス権を極め"" ""て慎重に管理する必要があります。, <indexterm class=\""singular\""><primary>パス"" ""ワード</primary></indexterm><indexterm class=\""singular\""><primary>セキュリ"" ""ティ上の問題</primary><secondary>パスワード</secondary></indexterm>"" msgid """" ""This enables you to arrange OpenStack compute hosts into logical groups and "" ""provides a form of physical isolation and redundancy from other availability "" ""zones, such as by using a separate power supply or network equipment."" ""<indexterm class=\""singular\""><primary>availability zone</primary></"" ""indexterm>"" msgstr """" ""アベイラビリティゾーンにより、OpenStack Compute ホストを論理グループにまとめ"" ""て、（独立した電源系統やネットワーク装置を使うことなどで）他のアベイラビリ"" ""ティゾーンとの物理的な分離や冗長性を実現できます。<indexterm class=\""singular"" ""\""><primary>アベイラビリティゾーン</primary></indexterm>"" msgid """" ""This enables you to partition OpenStack Compute deployments into logical "" ""groups for load balancing and instance distribution. You can use host "" ""aggregates to further partition an availability zone. For example, you might "" ""use host aggregates to partition an availability zone into groups of hosts "" ""that either share common resources, such as storage and network, or have a "" ""special property, such as trusted computing hardware.<indexterm class="" ""\""singular\""><primary>scaling</primary><secondary>host aggregate</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>host aggregate</""""これにより、OpenStack コンピュートデプロイメントを負荷分散やインスタンスディ"" ""ストリビューション用の論理グループに分割することができます。ホストアグリゲー"" ""トをシヨ空いて、アベイラビリティゾーンをさらに分割することができます。例え"" ""ば、ホストアグリゲートを使用してアベイラビリティゾーンをストレージやネット"" ""ワークなどの共通のリソースを共有するか、信頼済みのコンピューティングハード"" ""ウェアなどの特別なプロパティを持つホストグループに分割することができます。"" ""<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>ホス"" ""トアグリゲート</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ホストアグリゲート</primary></indexterm>""""This example architecture does not use the OpenStack Network Service "" ""(neutron), because it does not yet support multi-host networking and our "" ""organizations (university, government) have access to a large range of "" ""publicly-accessible IPv4 addresses.<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>vs. OpenStack "" ""Network Service (neutron)</secondary></indexterm>""""このアーキテクチャ例では、OpenStack Networking Service (neutron) は使用して"" ""いません。neutron はマルチホストネットワークをまだサポートしておらず、また対"" ""象となる組織 (大学/政府機関) ではパブリックでアクセス可能な IPv4 アドレスを広"" ""範囲で利用できるのが理由です。<indexterm class=\""singular\""><primary>レガシー"" ""ネットワーク (nova)</primary><secondary>vs. OpenStack Network Service "" ""(neutron)</secondary></indexterm>"" msgid """" ""This example architecture has been selected based on the current default "" ""feature set of OpenStack <glossterm>Havana</glossterm>, with an emphasis on "" ""stability. We believe that many clouds that currently run OpenStack in "" ""production have made similar choices.<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>rationale for "" ""choice of</secondary></indexterm>"" msgstr """" ""このアーキテクチャの例は、OpenStack <glossterm>Havana</glossterm> の現在のデ"" ""フォルト機能セットをベースに、安定性に重点を置いて選択しています。現在 "" ""OpenStack を本番環境で実行しているクラウドの多くは、同様の選択をしているもの"" ""と推定されます。<indexterm class=\""singular\""><primary>レガシーネットワーク "" ""(nova)</primary><secondary>選択の理由</secondary></indexterm>"" msgid """" ""This example architecture has been selected based on the current default "" ""feature set of OpenStack Havana, with an emphasis on high availability. This "" ""architecture is currently being deployed in an internal Red Hat OpenStack "" ""cloud and used to run hosted and shared services, which by their nature must "" ""be highly available.<indexterm class=\""singular\""><primary>OpenStack "" ""Networking (neutron)</primary><secondary>rationale for choice of</"" ""secondary></indexterm>"" msgstr """" ""このアーキテクチャ例は、OpenStack Havana の現在のデフォルト機能セットをベース"" ""に、高可用性に重点を置いて選択しています。このアーキテクチャは、現在 Red Hat "" ""の 企業内 OpenStack クラウドでデプロイされており、ホステッド共有サービスの運"" ""用に使用されています。ホステッド共有サービスは、その性質上、高可用性が要求さ"" ""れます。<indexterm class=\""singular\""><primary>OpenStack Networking (neutron)"" ""</primary><secondary>設定指針</secondary></indexterm>"" msgid ""This example assumes that <code>/dev/sdb</code> has failed."" msgstr ""この例では、<code>/dev/sdb</code> が故障したと仮定します。"" msgid """" ""This example shows the HTTP requests from the client and the responses from "" ""the endpoints, which can be helpful in creating custom tools written to the "" ""OpenStack API."" msgstr """" ""この例は、クライアントからのHTTPリクエストとエンドポイントからのレスポンスを"" ""表示しています。これはOpenStack APIを使ったカスタムツールを作る際に役立ちま"" ""す。"" msgid """" ""This guide uses the term <literal>project</literal>, unless an example shows "" ""interaction with a tool that uses the term <literal>tenant</literal>."" msgstr """" ""このガイドは<literal>プロジェクト</literal>という用語を使用します。<literal>"" ""テナント</literal>という用語を使用するツールとやりとりする例もあります。"" msgid ""This has several downsides:"" msgstr ""この方法には次のようなマイナス点があります。"" msgid """" ""This infrastructure includes systems to automatically install the operating "" ""system's initial configuration and later coordinate the configuration of all "" ""services automatically and centrally, which reduces both manual effort and "" ""the chance for error. Examples include Ansible, Chef, Puppet, and Salt. You "" ""can even use OpenStack to deploy OpenStack, fondly named TripleO, for "" ""OpenStack On OpenStack.<indexterm class=\""singular\""><primary>Puppet</"" ""primary></indexterm><indexterm class=\""singular\""><primary>Chef</primary></"" ""indexterm>"" msgstr """" ""このインフラストラクチャーには、オペレーティングシステムの初期設定を自動にイ"" ""ンストールするシステムや、全サーバーを自動的かつ一元的に連携、設定するシステ"" ""ムが含まれており、手作業やエラーの発生する可能性を減らします。例えば、"" ""Ansible、Chef、Puppet、Salt などのシステムです。OpenStack を使用して、"" ""OpenStack をデプロイすることも可能です。これは、TripleO (OpenStack 上の "" ""OpenStack) という愛称で呼ばれています。<indexterm class=\""singular"" ""\""><primary>Puppet</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Chef</primary></indexterm>"" msgid """" ""This is a closed network that is not publicly routable and is simply used as "" ""a private, internal network for traffic between virtual machines in "" ""OpenStack, and between the virtual machines and the network nodes that "" ""provide l3 routes out to the public network (and floating IPs for "" ""connections back in to the VMs). Because this is a closed network, we are "" ""using a different address space to the others to clearly define the "" ""separation. Only Compute and OpenStack Networking nodes need to be connected "" ""to this network."" msgstr """" ""これは、パブリックにはルーティングできない閉じたネットワークで、単に "" ""OpenStack 内の仮想マシン間のトラフィックや、パブリックネットワークへの外向き"" ""の L3 ルート (および仮想マシンに戻る接続のための Floating IP) を提供するネッ"" ""トワークノードと仮想マシンと間 のトラフィックのためのプライベートの内部ネット"" ""ワークに使用されます。このネットワークは閉じているため、他とは異なるアドレス"" ""空間を使用して、その区別を明確に定義しています。このネットワークに接続する必"" ""要があるのは、Compute ノードと OpenStack Networking ノードのみです。"" msgid """" ""This is the first half of the equation. To get flavor types that are "" ""guaranteed a particular ratio, you must set the <parameter>extra_specs</"" ""parameter> in the flavor type to the key-value pair you want to match in the "" ""aggregate. For example, if you define <parameter>extra_specs</"" ""parameter><parameter>cpu_allocation_ratio</parameter> to \""1.0\"", then "" ""instances of that type will run in aggregates only where the metadata key "" ""<parameter>cpu_allocation_ratio</parameter> is also defined as \""1.0.\"" In "" ""practice, it is better to define an additional key-value pair in the "" ""aggregate metadata to match on rather than match directly on "" ""<parameter>cpu_allocation_ratio</parameter> or "" ""<parameter>core_allocation_ratio</parameter>. This allows better "" ""abstraction. For example, by defining a key <parameter>overcommit</"" ""parameter> and setting a value of \""high,\"" \""medium,\"" or \""low,\"" you "" ""could then tune the numeric allocation ratios in the aggregates without also "" ""needing to change all flavor types relating to them."" msgstr """" ""これは前半部分です。特定の比率を保証するフレーバー種別を取得するには、フレー"" ""バー種別の <parameter>extra_specs</parameter> をアグリゲートでマッチする key-"" ""value ペアに設定する必要があります。たとえば、<parameter>extra_specs</"" ""parameter><parameter>cpu_allocation_ratio</parameter> を 1.0 に定義すると、そ"" ""の種別のインスタンスは、メタデータキー <parameter>cpu_allocation_ratio</"" ""parameter> も 1.0 と定義されているアグリゲートのみで実行されます。実際は、 "" ""<parameter>cpu_allocation_ratio</parameter> または "" ""<parameter>core_allocation_ratio</parameter> で直接マッチさせるのではなく、"" ""マッチするアグリゲートメタデータに追加の key-value ペアを定義すると良いでしょ"" ""う。これにより抽象化が改善されます。たとえば、<parameter>overcommit</"" ""parameter> キーを定義して、高、中、低の値を設定することで、関連するフレーバー"" ""種別をすべて変更する必要なしに、アグリゲートの割合比を調節することができま"" ""す。"" msgid """" ""This list of open source file-level shared storage solutions is not "" ""exhaustive; other open source solutions exist (MooseFS). Your organization "" ""may already have deployed a file-level shared storage solution that you can "" ""use."" msgstr """" ""オープンソースのファイルレベルの共有ストレージソリューションに関する一覧は完"" ""全ではありません。その他のオープンソースソリューションも存在します "" ""(MooseFS)。ユーザーの所属組織では、すでにユーザーが使用できるように、ファイル"" ""レベルの共有ストレージソリューションがデプロイされている可能性があります。"" msgid ""This might print the error and cause of the problem.<placeholder-1/>"" msgstr """" ""これにより、エラーと問題の原因が表示されるかもしれません。 <placeholder-1/>"" msgid ""This network is a combination of: <placeholder-1/>"" msgstr ""このネットワークは、以下の要素の組み合わせです: <placeholder-1/>"" msgid """" ""This network is connected to the controller nodes so users can access the "" ""OpenStack interfaces, and connected to the network nodes to provide VMs with "" ""publicly routable traffic functionality. The network is also connected to "" ""the utility machines so that any utility services that need to be made "" ""public (such as system monitoring) can be accessed."" msgstr """" ""このネットワークは、ユーザーが OpenStack インターフェースにアクセスできるよう"" ""するためにコントローラーノードに接続され、パブリックでルーティング可能なトラ"" ""フィックの機能を仮想マシンに提供するためにネットワークノードに接続されます。"" ""また、このネットワークは、公開する必要のある任意のユーティリティサービス (シ"" ""ステムの監視など) にアクセスできるようにするために、ユーティリティマシンにも"" ""接続されます。"" msgid """" ""This network is used for OpenStack management functions and traffic, "" ""including services needed for the provisioning of physical nodes "" ""(<literal>pxe</literal>, <literal>tftp</literal>, <literal>kickstart</"" ""literal>), traffic between various OpenStack node types using OpenStack APIs "" ""and messages (for example, <literal>nova-compute</literal> talking to "" ""<literal>keystone</literal> or <literal>cinder-volume</literal> talking to "" ""<literal>nova-api</literal>), and all traffic for storage data to the "" ""storage layer underneath by the Gluster protocol. All physical nodes have at "" ""least one network interface (typically <literal>eth0</literal>) in this "" ""network. This network is only accessible from other VLANs on port 22 (for "" ""<literal>ssh</literal> access to manage machines)."" msgstr """" ""このネットワークは、OpenStack の管理機能およびトラフィックに使用されます。こ"" ""れには、物理ノードのプロビジョニングに必要なサービス (<literal>pxe</"" ""literal>、<literal>tftp</literal>、<literal>kickstart</literal>)、OpenStack "" ""API およびメッセージを使用する様々な OpenStack ノードタイプの間のトラフィッ"" ""ク (例: <literal>nova-compute</literal> から <literal>keystone</literal> への"" ""通信や <literal>cinder-volume</literal> から <literal>nova-api</literal> へ"" ""の通信など)、 Gluster プロトコルによる配下のストレージ層へのストレージデータ"" ""の全トラフィックなどが含まれます。全物理ノードで、少なくとも 1 つのネットワー"" ""クインターフェース (通常は <literal>eth0</literal>) がこのネットワークに設定"" ""されます。他の VLAN からのこのネットワークへのアクセスは、ポート 22 でのみで"" ""可能です (マシンを管理するための <literal>ssh</literal> アクセス)。"" msgid """" ""This output shows that an instance named <placeholder-1/> was created from "" ""an Ubuntu 12.04 image using a flavor of <literal>m1.small</literal> and is "" ""hosted on the compute node <literal>c02.example.com</literal>."" msgstr """" ""この出力は、<placeholder-1/> という名前のインスタンスが Ubuntu 12.04 イメージ"" ""から <literal>m1.small</literal> のフレーバーで作成され、コンピュートノード "" ""<literal>c02.example.com</literal> でホストされていることを示しています。"" msgid """" ""This output shows that two networks are configured, each network containing "" ""255 IPs (a /24 subnet). The first network has been assigned to a certain "" ""project, while the second network is still open for assignment. You can "" ""assign this network manually; otherwise, it is automatically assigned when a "" ""project launches its first instance."" msgstr """" ""この出力は、2 つのネットワークが設定されており、各ネットワークには 255 の IP "" ""アドレス (/24 サブネットが 1 つ) が含まれていることを示しています。1 番目の"" ""ネットワークは、特定のプロジェクトに割り当て済みですが、2 番目のネットワーク"" ""はまだ割り当てができる状態です。このネットワークは手動で割り当てることができ"" ""ます。手動での割り当てを行わなかった場合には、プロジェクトで最初のインスタン"" ""スが起動されたときに自動で割り当てられます。"" msgid """" ""This particular example architecture has been upgraded from Grizzly to "" ""Havana and tested in production environments where many public IP addresses "" ""are available for assignment to multiple instances. You can find a second "" ""example architecture that uses OpenStack Networking (neutron) after this "" ""section. Each example offers high availability, meaning that if a particular "" ""node goes down, another node with the same configuration can take over the "" ""tasks so that service continues to be available.<indexterm class=\""singular"" ""\""><primary>Havana</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Grizzly</primary></indexterm>"" msgstr """" ""この特定のアーキテクチャ例は、Grizzly から Havana にアップグレードされてお"" ""り、複数のインスタンスに割り当てるためのパブリック IP アドレスが多数利用可能"" ""な本番環境でテスト済みです。このセクションの次には、OpenStack Networking "" ""(neutron) を使用する第 2 のアーキテクチャ例を紹介しています。各例では高可用性"" ""を提供しています。これは、特定のノードが停止した場合には同じ設定の別のノード"" ""がタスクを引き継いでサービスを引き続き提供できることを意味します。<indexterm "" ""class=\""singular\""><primary>Havana</primary></indexterm><indexterm class="" ""\""singular\""><primary>Grizzly</primary></indexterm>"" msgid """" ""This script is specific to a certain OpenStack installation and must be "" ""modified to fit your environment. However, the logic should easily be "" ""transferable."" msgstr """" ""このスクリプトは特定のOpenStackインストール環境向けなので、自身の環境に適用す"" ""る際には変更しなくてはいけませんが、ロジックは簡単に変更できるでしょう。"" msgid """" ""This section covers specific examples of configuration options you might "" ""consider tuning. It is by no means an exhaustive list."" msgstr """" ""この節では、調整を検討した方がよい設定オプションの個別の具体例を扱います。決"" ""して完全なリストではありません。"" msgid """" ""This section gives you a breakdown of the different nodes that make up the "" ""OpenStack environment. A node is a physical machine that is provisioned with "" ""an operating system, and running a defined software stack on top of it. "" ""<xref linkend=\""node-types-table\""/> provides node descriptions and "" ""specifications.<indexterm class=\""singular\""><primary>OpenStack Networking "" ""(neutron)</primary><secondary>detailed description of</secondary></indexterm>"" msgstr """" ""本セクションでは、OpenStack 環境を構成する異なるノードの内訳を記載します。 "" ""ノードとは、オペレーティングシステムがプロビジョニングされた物理マシンで、そ"" ""の上に定義済みソフトウェアスタックを実行します。 <xref linkend=\""node-types-"" ""table\""/> には、ノードの説明と仕様を記載しています。<indexterm class="" ""\""singular\""><primary>OpenStack Networking (neutron)</primary><secondary>詳細"" ""</secondary></indexterm>"" msgid """" ""This section provides a high-level overview of the differences among the "" ""different commodity storage backend technologies. Depending on your cloud "" ""user's needs, you can implement one or many of these technologies in "" ""different combinations:<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>commodity storage</secondary></indexterm>"" msgstr """" ""このセクションでは、さまざまな商用ストレージバックエンドテクノロジーにおける"" ""相違点をカンタンにまとめます。クラウドユーザーのニーズに合わせて、1 つまたは"" ""多数のテクノロジーを組み合わせて実装することができます。<indexterm class="" ""\""singular\""><primary>storage</primary><secondary>commodity storage</"" ""secondary></indexterm>"" msgid """" ""This stage is about checking that a bug is real and assessing its impact. "" ""Some of these steps require bug supervisor rights (usually limited to core "" ""teams). If the bug lacks information to properly reproduce or assess the "" ""importance of the bug, the bug is set to:"" msgstr """" ""このステップでは、バグが実際に起こるかのチェックやその重要度の判定が行われま"" ""す。これらのステップを行うには、バグ管理者権限が必要なものがあります (通常、"" ""バグ管理者権限はコア開発者チームだけが持っています)。バグ報告に、バグを再現し"" ""たり、バグの重要度を判定したりするのに必要な情報が不足している場合、バグは"" msgid ""This user was the only user on the node (new node)"" msgstr ""このユーザはそのノード（新しいノード）上の唯一のユーザだった。"" msgid """" ""Tim Bell from CERN gave us feedback on the outline before we started and "" ""reviewed it mid-week."" msgstr """" ""CERNの Tim Bell は、私たちが作業を開始する前に、その概要についてフィードバッ"" ""クを与えてくれて、週の半ばにはレビューをしてくれました。"" msgid """" ""Time synchronization is a critical element to ensure continued operation of "" ""OpenStack components. Correct time is necessary to avoid errors in instance "" ""scheduling, replication of objects in the object store, and even matching "" ""log timestamps for debugging.<indexterm class=\""singular"" ""\""><primary>networks</primary><secondary>Network Time Protocol (NTP)</"" ""secondary></indexterm>"" msgstr """" ""時刻同期はOpenStackコンポーネントを継続運用する上で非常に重要な要素です。正確"" ""な時間はインスタンスのスケジューリング、ボブジェクトストア内のオブジェクトの"" ""レプリケーションのエラーの回避や、さらにはデバッグのためにログのタイムスタン"" ""プの一致という意味合いで必要です。<indexterm class=\""singular\""><primary>ネッ"" ""トワーク</primary><secondary>ネットワークタイムプロトコル (NTP)</secondary></""msgid ""To add a DEBUG logging statement, you would do:"" msgstr ""DEBUGログステートメントを追加するには次のようにします。""""To add a project through the command line, you must use the keystone "" ""utility, which uses <literal>tenant</literal> in place of <literal>project</"" ""literal>:""""コマンドラインでプロジェクトを追加するには、<literal>project</literal> の代わ"" ""りに <literal>tenant</literal> を使用する keystone ユーティリティを使用する必"" ""要があります。""msgid ""To create a project through the OpenStack dashboard:"" msgstr ""OpenStack Dashboard でプロジェクトを作成します。""msgid ""To create a user, you need the following information:"" msgstr ""ユーザーを作成するには、以下の情報が必要です。"" msgid ""To create the middleware and plug it in through Paste configuration:"" msgstr ""ミドルウェアを作成して Paste の環境設定を通して組み込むためには："" msgid ""To create the scheduler and plug it in through configuration:"" msgstr ""スケジューラーを作成して、設定を通して組み込むためには："" msgid """" ""To deal with the \""dirty\"" buffer issue, we recommend using the sync command "" ""before snapshotting:"" msgstr """" ""「ダーティー」バッファーの問題を解決するために、スナップショットの前に sync "" ""コマンドを使用することを推奨します。"" msgid """" ""To deploy your storage by using only commodity hardware, you can use a "" ""number of open-source packages, as shown in <xref linkend=\""storage_solutions"" ""\""/>."" msgstr """" ""<xref linkend=\""storage_solutions\""/>で記載されているように、コモディティハー"" ""ドウェアを使用してストレージをデプロイする場合、オープンソースのパッケージを"" ""使用することができます。"" msgid """" ""To design, deploy, and configure OpenStack, administrators must understand "" ""the logical architecture. A diagram can help you envision all the integrated "" ""services within OpenStack and how they interact with each other.<indexterm "" ""class=\""singular\""><primary>modules, types of</primary></"" ""indexterm><indexterm class=\""singular\""><primary>OpenStack</"" ""primary><secondary>module types in</secondary></indexterm>"" msgstr """" ""OpenStack の設計、デプロイ、および構成を行うにあたって、管理者は論理アーキテ"" ""クチャを理解するが必要があります。OpenStack 内で統合される全サービスおよびそ"" ""れらがどのように相互作用するかについての構想を立てるには、図が役立ちます。"" ""<indexterm class=\""singular\""><primary>モジュール、タイプ</primary></"" ""indexterm><indexterm class=\""singular\""><primary>OpenStack</"" ""primary><secondary>モジュールタイプ</secondary></indexterm>"" msgid """" ""To discover how API requests should be structured, read the <link href="" ""\""http://developer.openstack.org/api-ref.html\"">OpenStack API Reference</"" ""link>. To chew through the responses using jq, see the <link href=\""http://"" ""stedolan.github.io/jq/manual/\"">jq Manual</link>."" msgstr """" ""API 要求の構成方法については、<link href=\""http://developer.openstack.org/"" ""api-ref.html\"">OpenStack API Reference</link> を参照してください。jq を使用し"" ""た応答についての詳しい説明は <link href=\""http://stedolan.github.io/jq/"" ""manual/\"">jq Manual</link> を参照してください。"" msgid """" ""To do this, generate a list of instance UUIDs that are hosted on the failed "" ""node by running the following query on the nova database:"" msgstr """" ""これを実行するために、nova データベースにおいて以下のクエリーを実行することに"" ""より、故障したノードにおいてホストされているインスタンスの UUID の一覧を生成"" ""します。"" msgid """" ""To enable this feature, edit the <filename>/etc/glance/glance-api.conf</"" ""filename> file, and under the [DEFAULT] section, add:"" msgstr """" ""この機能を有効にするには、<filename>/etc/glance/glance-api.conf</filename> "" ""ファイルを編集して [DEFAULT] セクションに以下を追加します。"" msgid ""To find out whether any floating IPs are available in your cloud, run:"" msgstr """" ""クラウドに利用可能な Floating IP アドレスがあるかどうかを確認するには、以下の"" ""コマンドを実行します。"" msgid """" ""To install (or upgrade) a package from the PyPI archive with pip, <indexterm "" ""class=\""singular\""><primary>command-line tools</"" ""primary><secondary>installing</secondary></indexterm>as root:"" msgstr """" ""pip を使用して PyPI アーカイブからパッケージをインストール (またはアップグ"" ""レード) するには、<indexterm class=\""singular\""><primary>コマンドラインツール"" ""</primary><secondary>インストール</secondary></indexterm>root として以下のコ"" ""マンドを実行します。"" msgid """" ""To make working with subsequent requests easier, store the token in an "" ""environment variable:"" msgstr ""次の要求での作業をより簡単に行うには、環境変数にトークンを保管します。"" msgid ""To perform this action from command line, run the following command:"" msgstr """" ""このアクションをコマンドラインから実行するには、以下のコマンドを実行します"" msgid """" ""To prevent system capacities from being exhausted without notification, you "" ""can set up <glossterm baseform=\""quota\"">quotas</glossterm>. Quotas are "" ""operational limits. For example, the number of gigabytes allowed per tenant "" ""can be controlled to ensure that a single tenant cannot consume all of the "" ""disk space. Quotas are currently enforced at the tenant (or project) level, "" ""rather than the user level.<indexterm class=\""startofrange\"" xml:id="" ""\""quotas9\""><primary>quotas</primary></indexterm><indexterm class=\""singular"" ""\""><primary>user management</primary><secondary>quotas</secondary></"" ""indexterm>"" msgstr """" ""システムの容量が通知なしに完全に消費されないように、<glossterm baseform="" ""\""quota\"">クォータ</glossterm> を設定することができます。クォータとは、運用上"" ""の制限値です。たとえば、各テナントに許容される容量 (GB) を制御して、単一のテ"" ""ナントで全ディスク容量すべてが消費されないようにします。現在、ユーザーレベル"" ""ではなく、テナント (またはプロジェクト) レベルで、クォータを有効にすることが"" ""できます。<indexterm class=\""startofrange\"" xml:id=\""quotas9\""><primary>"" ""クォータ</primary></indexterm><indexterm class=\""singular\""><primary>ユーザー"" ""管理</primary><secondary>クォータ</secondary></indexterm>"" msgid ""To provide users with a persistent storage mechanism"" msgstr ""ユーザに永続的ストレージの仕組みを提供する"" msgid """" ""To put the EC2 credentials into your environment, source the <code>ec2rc.sh</"" ""code> file."" msgstr """" ""EC2 認証情報を環境に適用するには、<code>ec2rc.sh</code> ファイルを元データと"" ""します。"" msgid ""To remove the package:"" msgstr ""パッケージを削除するには、"" msgid ""To schedule a group of hosts with common features."" msgstr ""共通の機能を持ったホストのグループに対してスケジューリングしたい場合"" msgid """" ""To see a list of projects that have been added to the cloud,<indexterm class="" ""\""singular\""><primary>projects</primary><secondary>obtaining list of "" ""current</secondary></indexterm><indexterm class=\""singular\""><primary>user "" ""management</primary><secondary>listing users</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>working environment</"" ""primary><secondary>users and projects</secondary></indexterm> run:"" msgstr """" ""クラウドに追加されたプロジェクトの一覧を確認するには、<indexterm class="" ""\""singular\""><primary>プロジェクト</primary><secondary>現在の一覧の取得</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>ユーザー管理</"" ""primary><secondary>ユーザーの一覧表示</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>作業環境</primary><secondary>users and projects</"" ""secondary></indexterm>以下のコマンドを実行します:"" msgid """" ""To see a list of running instances,<indexterm class=\""singular"" ""\""><primary>instances</primary><secondary>list of running</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>working environment</"" ""primary><secondary>running instances</secondary></indexterm> run:"" msgstr """" ""実行中のインスタンスを確認するには、<indexterm class=\""singular"" ""\""><primary>instances</primary><secondary>実行中の一覧</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>作業環境</"" ""primary><secondary>実行中のインスタンス</secondary></indexterm>以下のコマンド"" ""を実行します:"" msgid ""To see a list of users, run:"" msgstr ""ユーザーのリストを見るためには、"" msgid """" ""To see which bridge the packet will use, run the command: <placeholder-1/>"" msgstr """" ""下記コマンドを実行することで、パケットがどのブリッジを使うか確認できます。"" ""<placeholder-1/>"" msgid """" ""To see which fixed IP networks are configured in your cloud, you can use the "" ""<literal>nova</literal> command-line client to get the IP ranges:<indexterm "" ""class=\""singular\""><primary>networks</primary><secondary>inspection of</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>working "" ""environment</primary><secondary>network inspection</secondary></"" ""indexterm><placeholder-1/>"" msgstr """" ""クラウドでどの Fixed IP ネットワークが設定されているかを確認するには、 "" ""<literal>nova</literal> コマンドラインクライアントを使用して IP アドレスの範"" ""囲を取得することができます:<indexterm class=\""singular\""><primary>ネットワー"" ""ク</primary><secondary>検査</secondary></indexterm><indexterm class="" ""\""singular\""><primary>作業環境</primary><secondary>ネットワークの検査</"" ""secondary></indexterm><placeholder-1/>"" msgid """" ""To suit the cloud paradigm, OpenStack itself is designed to be horizontally "" ""scalable. Rather than switching to larger servers, you procure more servers "" ""and simply install identically configured services. Ideally, you scale out "" ""and load balance among groups of functionally identical services (for "" ""example, compute nodes or <literal>nova-api</literal> nodes), that "" ""communicate on a message bus."" msgstr """" ""クラウドのパラダイムに合わせるため、OpenStack は水平的にスケーリングできるよ"" ""うに設計されています。容量の大きいサーバーに切り替えるのではなく、サーバーを"" ""多く調達して同じように設定したサービスをインストールするだけです。理想として"" ""は、メッセージバスを通信する、機能的に同じサービス (例: コンピュートノードや "" ""<literal>nova-api</literal> ノード) グループでスケールアウト、負荷分散しま"" ""す。"" msgid """" ""To this day, <link href=\""https://bugs.launchpad.net/nova/+bug/832507\"">the "" ""issue</link> (https://bugs.launchpad.net/nova/+bug/832507) doesn't have a "" ""permanent resolution, but we look forward to the discussion at the next "" ""summit."" msgstr """" ""今日に至るまで、<link href=\""https://bugs.launchpad.net/nova/+bug/832507\"">こ"" ""の問題</link> (https://bugs.launchpad.net/nova/+bug/832507) には完全な解決策"" ""がないが、我々は次回のサミットの議論に期待している。"" msgid """" ""To understand the possibilities OpenStack offers, it's best to start with "" ""basic architectures that are tried-and-true and have been tested in "" ""production environments. We offer two such examples with basic pivots on the "" ""base operating system (Ubuntu and Red Hat Enterprise Linux) and the "" ""networking architectures. There are other differences between these two "" ""examples, but you should find the considerations made for the choices in "" ""each as well as a rationale for why it worked well in a given environment."" msgstr """" ""OpenStack が提供する可能性を理解するには、確実に信頼できる、本番環境での検証"" ""済みの基本アーキテクチャから開始するのが最善の方法です。本ガイドでは、ベース"" ""オペレーティングシステム (Ubuntu および Red Hat Enterprise Linux) 上に基本ピ"" ""ボットとネットワークアーキテクチャを備えた基本アーキテクチャの例を 2 つ紹介し"" ""ています。これらの 2 つの例では、他にも相違点がありますが、各例で選択にあたっ"" ""て考慮した点と、それらのアーキテクチャが特定の環境で適切に機能するための設定"" ""指針をご理解いただけるはずです。"" msgid """" ""To update a default value for a new tenant, update the property in the "" ""<filename>/etc/cinder/cinder.conf</filename> file."" msgstr """" ""新規テナントのクォータのデフォルト値を更新するには、<filename>/etc/cinder/"" ""cinder.conf</filename> ファイルの対応する項目を更新します。"" msgid ""To update quota values for a tenant (project)"" msgstr ""テナント (プロジェクト) のクォータ値の更新"" msgid ""To view all tenants, run: <placeholder-1/>"" msgstr """" ""全てのテナントを表示するには、以下のコマンドを実行します。<placeholder-1/>"" msgid ""To view and update default Block Storage quota values"" msgstr ""Block Storage のデフォルトのクォータ値の表示と更新"" msgid ""To view and update default quota values"" msgstr ""デフォルトのクォータ値の表示と更新"" msgid ""To view quota values for a tenant (project)"" msgstr ""テナント (プロジェクト) のクォータ値の表示"" msgid ""To view the details of the \""open\"" security group:"" msgstr ""「open」セキュリティグループの詳細を表示する方法:"" msgid """" ""Today, OpenStack clouds explicitly support two types of persistent storage: "" ""<emphasis>object storage</emphasis> and <emphasis>block storage</emphasis>."" ""<indexterm class=\""singular\""><primary>swift</primary><secondary>Object "" ""Storage API</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>persistent storage</primary></indexterm><indexterm class="" ""\""singular\""><primary>objects</primary><secondary>persistent storage of</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>Object Storage API</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>object storage</"" ""secondary></indexterm>"" msgstr """" ""現在、OpenStack クラウドは、<emphasis>オブジェクトストレージ</emphasis> およ"" ""び<emphasis>ブロックストレージ</emphasis> の 2 種類の永続ストレージを明示的に"" ""サポートしています。<indexterm class=\""singular\""><primary>swift</"" ""primary><secondary>Object Storage API</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>永続ストレージ</primary></indexterm><indexterm "" ""class=\""singular\""><primary>オブジェクト</primary><secondary>永続ストレージ</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>オブジェクトスト"" ""レージ</primary><secondary>Object Storage API</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>storage</primary><secondary>"" ""オブジェクトストレージ</secondary></indexterm>"" msgid ""Total Cloud Controller Failure"" msgstr ""全体的なクラウドコントローラーの故障"" msgid ""Total Compute Node Failure"" msgstr ""コンピュートノード全体の故障"" msgid ""Tracing Instance Requests"" msgstr ""インスタンスリクエストの追跡"" msgid """" ""Tracks current information about users and instances, for example, in a "" ""database, typically one database instance managed per service"" msgstr """" ""ユーザとインスタンスの現在の状態をトラッキングします。例えば、一般的なデータ"" ""ベースでは1つのデータベースインスタンスはサービス毎に管理されます。"" msgid """" ""Traffic among object/account/container servers and between these and the "" ""proxy server's internal interface uses this private network.<indexterm class="" ""\""singular\""><primary>containers</primary><secondary>container servers</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>object servers</secondary></indexterm><indexterm class="" ""\""singular\""><primary>account server</primary></indexterm>"" msgstr """" ""オブジェクト/アカウント/コンテナサービスの間とこれらとプロクシサーバーのイン"" ""ターフェイス間のトラフィックはこのプライベートネットワークを利用します。"" ""<indexterm class=\""singular\""><primary>コンテナ</primary><secondary>コンテナ"" ""サーバー</secondary></indexterm><indexterm class=\""singular\""><primary>オブ"" ""ジェクト</primary><secondary>オブジェクトサーバー</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>アカウントサーバー</"" ""primary></indexterm>"" msgid ""Trending"" msgstr ""トレンド"" msgid """" ""Try executing the <code>nova reboot</code> command again. You should see an "" ""error message about why the instance was not able to boot"" msgstr """" ""再び <code>nova reboot</code> コマンドを実行してみてください。インスタンスが"" ""なぜブートできないかについて、エラーメッセージを確認すべきです。"" msgid ""Type"" msgstr ""種別"" msgid """" ""Typically, default values are changed because a tenant requires more than "" ""the OpenStack default of 10 volumes per tenant, or more than the OpenStack "" ""default of 1 TB of disk space on a compute node."" msgstr """" ""テナントには、10 個を超える Block Storage ボリュームまたはコンピュートノード"" ""で 1 TB 以上が必要であるため、通常クラウドのオペレーターはデフォルト値を変更"" ""します。"" msgid """" ""Ubuntu 12.04 LTS or Red Hat Enterprise Linux 6.5, including derivatives such "" ""as CentOS and Scientific Linux"" msgstr """" ""Ubuntu 12.04 LTS または Red Hat Enterprise Linux 6.5 (CentOS および "" ""Scientific Linux などの派生物を含む)""msgid ""Under Identity Panel, click <guilabel>Projects</guilabel>."" msgstr ""認証パネルの <guilabel>プロジェクト</guilabel> をクリックします。"" ""Underlying the use of the command-line tools is the OpenStack API, which is "" ""a RESTful API that runs over HTTP. There may be cases where you want to "" ""interact with the API directly or need to use it because of a suspected bug "" ""in one of the CLI tools. The best way to do this is to use a combination "" ""of <link href=\""http://curl.haxx.se/\"">cURL</link> and another tool, such "" ""as <link href=\""http://stedolan.github.io/jq/\"">jq</link>, to parse the JSON "" ""from the responses.<indexterm class=\""singular\""><primary>authentication "" ""tokens</primary></indexterm><indexterm class=\""singular\""><primary>cURL</"" ""primary></indexterm>""""コマンドラインツールの使用の根底にあるのは、HTTP を介して実行する RESTful "" ""API である OpenStack API です。API と直接対話を行いたい場合や、CLI ツールにバ"" ""グがあることが疑われるために使用する必要がある場合があります。この場合の最善"" ""の対処方法は、 <link href=\""http://curl.haxx.se/\"">cURL</link> と <link href="" ""\""http://stedolan.github.io/jq/\"">jq</link> などの他のツールを組み合わせて使"" ""用し、その応答から JSON を解析することです。<indexterm class=\""singular"" ""\""><primary>認証トークン</primary></indexterm><indexterm class=\""singular"" ""\""><primary>cURL</primary></indexterm>""msgid """" ""Unfortunately, this command does not tell you various details about the "" ""running <phrase role=\""keep-together\"">instances</phrase>, such as what "" ""compute node the instance is running on, what flavor the instance is, and so "" ""on. You can use the following command to view details about individual "" ""instances:<indexterm class=\""singular\""><primary>config drive</primary></"" ""indexterm>"" msgstr """" ""残念ながら、このコマンドは、インスタンスを実行しているコンピュートノードやイ"" ""ンスタンスのフレーバーなどのような、実行中の<phrase role=\""keep-together\"">イ"" ""ンスタンス</phrase>についての多様な情報は提供しません。個別のインスタンスにつ"" ""いての詳しい情報を確認するには以下のコマンドを使用してください:<indexterm "" ""class=\""singular\""><primary>コンフィグドライブ</primary></indexterm>""msgid """" ""Unfortunately, this story has an open ending... we're still looking into why "" ""the CentOS image was sending out spanning tree packets. Further, we're "" ""researching a proper way on how to mitigate this from happening. It's a "" ""bigger issue than one might think. While it's extremely important for "" ""switches to prevent spanning tree loops, it's very problematic to have an "" ""entire compute node be cut from the network when this happens. If a compute "" ""node is hosting 100 instances and one of them sends a spanning tree packet, "" ""that instance has effectively DDOS'd the other 99 instances."" msgstr """" ""不幸にも、この話にはエンディングがない…我々は、なぜ CentOS イメージがスパニン"" ""グツリーパケットを送信し始める原因をいまだ探している。更に、我々は障害時にス"" ""パニングツリーを軽減する正しい方法を調査している。これは誰かが思うより大きな"" ""問題だ。スパニングツリーループを防ぐことはスイッチにとって非常に重要である"" ""が、スパニングツリーが起こった際に、コンピュートノード全体がネットワークから"" ""切り離されることも大きな問題である。コンピュートノードが 100 インスタンスをホ"" ""スティングしていて、そのうち１つがスパニングツリーパケットを送信した場合、そ"" ""のインスタンスは事実上他の 99 インスタンスを DDoS（サービス不能攻撃）したこと"" ""になる。""msgid ""Uninstalling"" msgstr ""アンインストール""msgid """" ""Unlike the CLI tools mentioned above, the <code>*-manage</code> tools must "" ""be run from the cloud controller, as root, because they need read access to "" ""the config files such as <code>/etc/nova/nova.conf</code> and to make "" ""queries directly against the database rather than against the OpenStack "" ""<glossterm baseform=\""API endpoint\"">API endpoints</glossterm>.<indexterm "" ""class=\""singular\""><primary>API (application programming interface)</"" ""primary><secondary>API endpoint</secondary></indexterm><indexterm class="" ""\""singular\""><primary>endpoints</primary><secondary>API endpoint</"" ""secondary></indexterm>"" msgstr """" ""前述の CLI ツールとは異なり、<code>*-manage</code> ツールは、<code>/etc/nova/"" ""nova.conf</code> などの設定ファイルへの読み取りアクセスが必要で、かつ "" ""OpenStack に対してではなくデータベースに対して直接クエリーを実行しなければな"" ""らないため、クラウドコントローラーから root として実行する必要があります。"" ""<glossterm baseform=\""API endpoint\"">API エンドポイント</glossterm>."" ""<indexterm class=\""singular\""><primary>API (Application Programming "" ""Interface)</primary><secondary>API エンドポイント</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>エンドポイント</"" ""primary><secondary>API エンドポイント</secondary></indexterm>""msgid ""Update a default value for a new tenant, as follows:"" msgstr """" ""新規テナントに対するクォータのデフォルト値を更新するには、以下のようにしま"" ""す。""msgid ""Update a particular quota value, as follows:"" msgstr ""指定したクォータ値を更新します。""msgid ""Update the configuration files according to the release notes."" msgstr ""リリースノートに従って設定ファイルを更新します。""msgid ""Upgrade OpenStack Block Storage (cinder)."" msgstr ""OpenStack Block Storage (cinder) をアップグレードする。"" msgid ""Upgrade OpenStack Compute (nova), including networking components."" msgstr """" ""OpenStack Compute (nova) とネットワークコンポーネントをアップグレードする。"" msgid ""Upgrade OpenStack."" msgstr ""OpenStack をアップグレードします。"" msgid ""Upgrade the OpenStack Image service (glance)."" msgstr ""OpenStack Image サービス (glance) をアップグレードします。"" msgid ""Upgrades"" msgstr ""アップグレード"" msgid ""Upstream OpenStack"" msgstr ""OpenStack コミュニティ"" msgid ""Use Cases"" msgstr ""事例"" msgid ""Use an external load balancer."" msgstr ""外部ロードバランサーの使用"" msgid """" ""Use local storage on the node for the virtual machines so that no VM "" ""migration or instance recovery at node failure is possible."" msgstr """" ""ノードの障害発生時に仮想マシンの移行やインスタンスのリカバリができないよう"" ""に、仮想マシンにノード上のローカルストレージを使用します。"" msgid ""Use of the network can decrease performance."" msgstr ""ネットワークを使用するため、性能低下が起こる可能性があります。"" msgid ""Use when you need"" msgstr ""用途"" msgid ""Used to…"" msgstr ""使用目的"" msgid ""User Management"" msgstr ""ユーザー管理"" msgid ""User dashboard"" msgstr ""ユーザーダッシュボード"" msgid ""User quotas"" msgstr ""ユーザークォータ"" msgid ""User specification in initial request"" msgstr ""初回要求のユーザー仕様"" msgid ""User virtual machines"" msgstr ""ユーザーの仮想マシン"" msgid ""Username"" msgstr ""ユーザー名"" msgid ""Users and Projects"" msgstr ""ユーザーとプロジェクト"" msgid """" ""Users must be associated with at least one project, though they may belong "" ""to many. Therefore, you should add at least one project before adding users."" ""<indexterm class=\""singular\""><primary>user management</"" ""primary><secondary>adding projects</secondary></indexterm>"" msgstr """" ""ユーザーは、多数のプロジェクトに所属することは可能ですが、最低でも 1 つのプロ"" ""ジェクトと関連付ける必要があります。そのため、ユーザー追加の前にプロジェクト"" ""を 1 つ追加しておく必要があります。<indexterm class=\""singular\""><primary>"" ""ユーザー管理</primary><secondary>プロジェクトの追加</secondary></indexterm>"" msgid """" ""Users will indicate different needs for their cloud use cases. Some may need "" ""fast access to many objects that do not change often, or want to set a time-"" ""to-live (TTL) value on a file. Others may access only storage that is "" ""mounted with the file system itself, but want it to be replicated instantly "" ""when starting a new instance. For other systems, ephemeral storage—storage "" ""that is released when a VM attached to it is shut down— is the preferred "" ""way. When you select <glossterm>storage backend</glossterm>s, <indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>choosing backends</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>storage "" ""backend</primary></indexterm><indexterm class=\""singular\""><primary>backend "" ""interactions</primary><secondary>store</secondary></indexterm>ask the "" ""following questions on behalf of your users:"" msgstr """" ""クラウドのユースケースごとにニーズが異なります。頻繁に変更が発生しない多数の"" ""オブジェクトに素早くアクセスする必要がある場合、ファイルに Time-to-Live "" ""(TTL) の値を設定する場合、ファイルシステムのみにマウントされているストレージ"" ""のみにアクセスするが、新しいインスタンスの起動時には即時にそのストレージを複"" ""製する場合などがあります。他のシステムの場合は、一時ストレージ (ストレージに"" ""接続された仮想マシンがシャットダウンされている場合に開放されるストレージ) が"" ""より良い方法です。<glossterm>ストレージのバックエンド</glossterm>の選択時は、"" ""<indexterm class=\""singular\""><primary>ストレージ</primary><secondary>バック"" ""エンドの選択</secondary></indexterm><indexterm class=\""singular\""><primary>ス"" ""トレージバックエンド</primary></indexterm><indexterm class=\""singular"" ""\""><primary>バックエンドの対話</primary><secondary>store</secondary></"" ""indexterm>ユーザーの代わりに以下の質問を確認してください。"" msgid ""Uses any traditional file system to store the images as files."" msgstr """" ""イメージをファイルとして格納するために一般的なファイルシステムを使用します。"" msgid ""Using \""ip a\"" to Check Interface States"" msgstr ""「ip a」を使ってインタフェース状態をチェックする"" msgid """" ""Using a virtual local area network offers broadcast control, security, and "" ""physical layer transparency. If needed, use VXLAN to extend your address "" ""space."" msgstr """" ""仮想ローカルエリアネットワークを使用してブロードキャスト制御、セキュリティ、"" ""物理レイヤーの透過性を提供します。必要な場合には、VXLAN を使用してアドレス空"" ""間を拡張します。"" msgid ""Using cURL for further inspection"" msgstr ""cURL を使用したさらなる検査"" msgid ""Using the OpenStack Dashboard for Administration"" msgstr ""管理目的での OpenStack Dashboard の使用"" msgid """" ""Using the command-line interface, you can manage quotas for the OpenStack "" ""Compute Service and the Block Storage Service."" msgstr """" ""コマンドラインインターフェースを使って、OpenStack Compute サービスと Block "" ""Storage サービスのクォータを管理できます。"" msgid ""Utility"" msgstr ""ユーティリティ"" msgid """" ""Utility nodes are used by internal administration staff only to provide a "" ""number of basic system administration functions needed to get the "" ""environment up and running and to maintain the hardware, OS, and software on "" ""which it runs."" msgstr """" ""ユーティリティノードは、環境を稼働させ、その環境を実行しているハードウェア/"" ""OS/ソフトウェアを維持管理するのに必要な多数の基本的なシステム管理機能を提供す"" ""るために、内部管理スタッフのみが使用します。"" msgid ""VC"" msgstr ""VC"" msgid ""VCPUs"" msgstr ""仮想 CPU"" msgid ""VLAN"" msgstr ""VLAN"" msgid ""VLAN Configuration Within OpenStack VMs"" msgstr ""OpenStack VM内のVLAN設定"" msgid """" ""VLAN configuration can be as simple or as complicated as desired. The use of "" ""VLANs has the benefit of allowing each project its own subnet and broadcast "" ""segregation from other projects. To allow OpenStack to efficiently use "" ""VLANs, you must allocate a VLAN range (one for each project) and turn each "" ""compute node switch port into a trunk port.<indexterm class=\""singular"" ""\""><primary>networks</primary><secondary>VLAN</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>VLAN network</primary></"" ""indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>network topology</secondary><tertiary>VLAN with OpenStack "" ""VMs</tertiary></indexterm>"" msgstr """" ""VLAN設定は要求によっては複雑であったり単純であったりする事ができます。VLANを"" ""使用すると互いのプロジェクトに専用のサブネットを提供でき、ブロードキャストド"" ""メインを分割するという利点が得られます。効果的にVLANを使用できるようにするに"" ""は、VLANの範囲を(それぞれのプロジェクトに1つずつ)割り当て、各コンピュートノー"" ""ドのポートをトランクポートに変更する必要があります。<indexterm class="" ""\""singular\""><primary>ネットワーク</primary><secondary>VLAN</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>VLANネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワーク設計</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>OpenStack VMと"" ""VLAN</tertiary></indexterm>"" msgid ""VM is terminated"" msgstr ""VM終了まで"" msgid ""VM traffic network"" msgstr ""仮想マシントラフィックネットワーク"" msgid ""Value"" msgstr ""値"" msgid ""Verify your alert mechanisms are still working."" msgstr ""アラート機能が動作していることを確認します。"" msgid ""View and update Block Storage quotas for a tenant (project)"" msgstr """" ""Block Storage サービスのテナント (プロジェクト) の クォータの表示と更新"" msgid ""View and update compute quotas for a tenant (project)"" msgstr ""テナント (プロジェクト) のコンピュートクォータの表示/更新"" msgid ""View quotas for the tenant, as follows:"" msgstr ""特定のテナントのクォータを表示するには以下のようにします。"" msgid ""Virtual Machine Image Guide"" msgstr ""仮想マシンイメージガイド"" msgid ""Virtual cores"" msgstr ""仮想コア数"" msgid ""Virtual machine memory in megabytes."" msgstr ""メガバイト単位の仮想マシンメモリー。"" msgid """" ""Virtual root disk size in gigabytes. This is an ephemeral disk the base "" ""image is copied into. You don't use it when you boot from a persistent "" ""volume. The \""0\"" size is a special case that uses the native base image "" ""size as the size of the ephemeral root volume."" msgstr """" ""ギガバイト単位の仮想ルートディスク容量。これはベースイメージがコピーされる一"" ""時ディスクです。永続的なボリュームからブートするとき、これは使用されません。"" ""「0」という容量は特別な値で、一時ルートボリュームの容量としてベースイメージの"" ""ネイティブ容量をそのまま使用することを意味します。"" msgid ""Virtualization"" msgstr ""仮想化"" msgid ""VlanManager"" msgstr ""VlanManager"" msgid ""Volume snapshots"" msgstr ""ボリュームのスナップショット"" msgid ""Volumes"" msgstr ""ボリューム"" msgid ""Vulnerability management"" msgstr ""脆弱性管理"" msgid ""We also had some excellent input from outside of the room:"" msgstr ""私たちは部屋の外から、いくつかの素晴らしいインプットを得ました。"" msgid """" ""We called them and asked them to stop for a while, and they were happy to "" ""abandon the horribly broken VM. After that, we started monitoring the size "" ""of console logs."" msgstr """" ""我々はユーザを呼び、しばらくダッシュボードの更新を止めるよう申し入れた。する"" ""と、恐ろしい VM の破壊は止み、彼らは大いに喜んだ。その後、我々はコンソールロ"" ""グのサイズを監視するようになった。"" msgid """" ""We consider live migration an integral part of the operations of the cloud. "" ""This feature provides the ability to seamlessly move instances from one "" ""physical host to another, a necessity for performing upgrades that require "" ""reboots of the compute hosts, but only works well with shared storage."" ""<indexterm class=\""singular\""><primary>storage</primary><secondary>live "" ""migration</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>migration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>live migration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>compute nodes</primary><secondary>live migration</secondary></"" ""indexterm>"" msgstr """" ""ライブマイグレーションは、クラウドの運用に不可欠であると考えられます。この機"" ""能により、物理ホストから別の物理ホストに、インスタンスをシームレスに移動し、"" ""コンピュートホストの再起動を必要とするアップグレードができるようになります。"" ""しかし、ライブマイグレーションは共有ストレージのみで正常に機能します。"" ""<indexterm class=\""singular\""><primary>ストレージ</primary><secondary>ライブ"" ""マイグレーション</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>マイグレーション</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ライブマイグレーション</primary></indexterm><indexterm class="" ""\""singular\""><primary>コンピュートノード</primary><secondary>ライブマイグレー"" ""ション</secondary></indexterm>"" msgid """" ""We couldn't have pulled it off without so much supportive help and "" ""encouragement."" msgstr """" ""私たちは、これらの多大な協力的な援助と励まし無しには、これを成し遂げることは"" ""できなかったでしょう。"" msgid """" ""We decided to have <placeholder-1/> run on this instance and see if we could "" ""catch it in action again. Sure enough, we did."" msgstr """" ""我々は、このインスタンス上で <placeholder-1/> を実行して、操作で再びこの現象"" ""に遭遇するか見てみることにした。実際、我々はやってみた。"" msgid """" ""We don't recommend ZFS unless you have previous experience with deploying "" ""it, since the ZFS backend for Block Storage requires a Solaris-based "" ""operating system, and we assume that your experience is primarily with Linux-"" ""based systems."" msgstr """" ""本書は、Linux ベースシステムを主に使用するユーザーを想定しており、Block "" ""Storage の ZFS バックエンドには Solaris ベースのオペレーティングシステムが必"" ""要であるため、ZFS でのデプロイ経験がない場合は、ZFS は推奨していません。"" msgid """" ""We hope that you now have some considerations in mind and questions to ask "" ""your future cloud users about their storage use cases. As you can see, your "" ""storage decisions will also influence your network design for performance "" ""and security needs. Continue with us to make more informed decisions about "" ""your OpenStack cloud <phrase role=\""keep-together\"">design</phrase>."" msgstr """" ""今後のクラウドユーザーにストレージのユースケースに関する質問事項および、懸念"" ""点など理解いただけたかと思います。ストレージの決定はパフォーマンスやセキュリ"" ""ティのニーズにあったネットワーク設計をする際に影響を与えます。OpenStack クラ"" ""ウド <phrase role=\""keep-together\"">設計</phrase> について理解したうえで意思"" ""決定が行えるように、本書を読み進めてください。"" msgid """" ""We reached out for help. A networking engineer suggested it was an MTU "" ""issue. Great! MTU! Something to go on! What's MTU and why would it cause a "" ""problem?"" msgstr """" ""我々は助けを求めた。ネットワークエンジニアは、これは MTU の問題ではないかとい"" ""うのだ。素晴らしい！MTU! 事態は動き始めた! MTU とは何で、何故それが問題になる"" ""のだろうか？"" msgid """" ""We recommend that you choose one of the following multiple disk options:"" msgstr ""以下に挙げる複数のディスクの選択肢から選ぶことを推奨します。"" msgid """" ""We recommend that you do not use the default Ubuntu OpenStack install "" ""packages and instead use the <link href=\""https://wiki.ubuntu.com/ServerTeam/"" ""CloudArchive\"">Ubuntu Cloud Archive</link>. The Cloud Archive is a package "" ""repository supported by Canonical that allows you to upgrade to future "" ""OpenStack releases while remaining on Ubuntu 12.04."" msgstr """" ""デフォルトの Ubuntu OpenStack インストールパッケージは使用せずに、<link href="" ""\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud Archive</"" ""link> を使用することをお勧めします。Cloud Archive は、Canonical がサポートす"" ""るパッケージリポジトリです。これにより、Ubuntu 12.04 を維持した状態で将来の "" ""OpenStack リリースにアップグレードすることができます。"" msgid """" ""We recommend that you use the same hardware for new compute and block "" ""storage nodes. At the very least, ensure that the CPUs are similar in the "" ""compute nodes to not break live migration."" msgstr """" ""新しいコンピュートノードとブロックストレージノードには、同じハードウェアを使"" ""用することを推奨します。最低限、ライブマイグレーションが失敗しないように、コ"" ""ンピュートノードでは CPU は同様のものにしてください。"" msgid """" ""We recommend using a combination of the OpenStack command-line interface "" ""(CLI) tools and the OpenStack dashboard for administration. Some users with "" ""a background in other cloud technologies may be using the EC2 Compatibility "" ""API, which uses naming conventions somewhat different from the native API. "" ""We highlight those differences.<indexterm class=\""singular"" ""\""><primary>working environment</primary><secondary>command-line tools</"" ""secondary></indexterm>"" msgstr """" ""管理には、OpenStack コマンドラインインターフェース (CLI) ツールと OpenStack "" ""Dashboard を組み合わせて使用することをお勧めします。他のクラウドテクノロジー"" ""の使用経験のある一部のユーザーは、EC2 互換 API を使用している可能性がありま"" ""す。この API は、ネイティブの API とは若干異なる命名規則を採用しています。こ"" ""の相違点について以下に説明します。<indexterm class=\""singular\""><primary>作業"" ""環境</primary><secondary>コマンドラインツール</secondary></indexterm>"" msgid """" ""We reviewed both sets of logs. The one thing that stood out the most was "" ""DHCP. At the time, OpenStack, by default, set DHCP leases for one minute "" ""(it's now two minutes). This means that every instance contacts the cloud "" ""controller (DHCP server) to renew its fixed IP. For some reason, this "" ""instance could not renew its IP. We correlated the instance's logs with the "" ""logs on the cloud controller and put together a conversation:"" msgstr """" ""我々はログのセットを両方見直した。頻発したログの１つは DHCP だった。当時、"" ""OpenStack はデフォルトでは DHCP リース期間を 1分に設定していた (現在は 2分)。"" ""これは、各インスタンスが固定 IP アドレスを更新するためにクラウドコントロー"" ""ラー（DHCP サーバー）に接続することを意味する。幾つかの理由で、このインスタン"" ""スはその IP アドレスを更新できなかった。インスタンスのログとクラウドコント"" ""ローラー上のログを突き合わせ、並べてやりとりにしてみた。"" msgid """" ""We strongly suggest that you install the command-line clients from the <link "" ""href=\""https://pypi.python.org/pypi\"">Python Package Index</link> (PyPI) "" ""instead of from the distribution packages. The clients are under heavy "" ""development, and it is very likely at any given time that the version of the "" ""packages distributed by your operating-system vendor are out of date."" ""<indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>Python Package Index (PyPI)</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>pip utility</primary></"" ""indexterm><indexterm class=\""singular\""><primary>Python Package Index (PyPI)"" ""</primary></indexterm>"" msgstr """" ""コマンドラインクライアントは、ディストリビューションのパッケージからではな"" ""く、<link href=\""https://pypi.python.org/pypi\"">Python Package Index</link> "" ""(PyPI) からインストールすることを強く推奨します。これは、クライアントの開発"" ""が活発に行われており、オペレーティングシステムのベンダーにより配布されたパッ"" ""ケージのバージョンが任意の時点で無効になってしまう可能性が高いためです。"" ""<indexterm class=\""singular\""><primary>コマンドラインツール</"" ""primary><secondary>Python Package Index (PyPI)</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>pip ユーティリティ</"" ""primary></indexterm><indexterm class=\""singular\""><primary>Python Package "" ""Index (PyPI)</primary></indexterm>"" msgid """" ""We want to acknowledge our excellent host Rackers at Rackspace in Austin:"" msgstr """" ""私たちは、オースチンの Rackspace での素晴らしいホスト Rackersに感謝したい:"" msgid """" ""We wrote furiously from our own experiences and bounced ideas between each "" ""other. At regular intervals we reviewed the shape and organization of the "" ""book and further molded it, leading to what you see today."" msgstr """" ""私たちは一心不乱に自分たちの経験に基づき執筆を行い、互いに意見をぶつけ合いま"" ""した。一定の間隔で、本の現在の状況や構成をレビューし、本を作り上げていき、今"" ""皆さんが見ているものができあがりました。"" msgid ""We wrote this book to help you:<placeholder-1/>"" msgstr """" ""次のような場面であなたの助けとなるように、この本を書きました。<placeholder-1/"" "">"" msgid """" ""We'll discuss the three main approaches to instance storage in the next few "" ""sections."" msgstr ""以降の数セクションでは、 3 つの主要アプローチについて説明します。"" msgid """" ""We've seen deployments with all, and recommend that you choose the one you "" ""are most familiar with operating. If you are not familiar with any of these, "" ""choose NFS, as it is the easiest to set up and there is extensive community "" ""knowledge about it."" msgstr """" ""すべてのファイルシステムを使用したデプロイメントに触れ、運用になれているもの"" ""を選択するように推奨しました。いずれのファイルシステムにも馴染みがない場合"" ""は、設定が簡単で、コミュニティのナレッジベースが幅広く存在するため、NFS を選"" ""択するようにしてください。"" msgid ""Weaknesses"" msgstr ""短所"" msgid ""Weekly"" msgstr ""週次"" msgid """" ""What is the platter count I can achieve? Do more spindles result in better I/"" ""O despite network access?"" msgstr """" ""実現可能な容量は？ネットワークアクセスでも、より多くのディスクがより良い I/O "" ""性能に繋がるか？"" msgid ""What is the platter count you can achieve?"" msgstr ""実現したいプラッター数（ディスク容量）はどれくらいか？"" msgid """" ""When designing your cluster, you must consider durability and availability. "" ""Understand that the predominant source of these is the spread and placement "" ""of your data, rather than the reliability of the hardware. Consider the "" ""default value of the number of replicas, which is three. This means that "" ""before an object is marked as having been written, at least two copies exist—"" ""in case a single server fails to write, the third copy may or may not yet "" ""exist when the write operation initially returns. Altering this number "" ""increases the robustness of your data, but reduces the amount of storage you "" ""have available. Next, look at the placement of your servers. Consider "" ""spreading them widely throughout your data center's network and power-"" ""failure zones. Is a zone a rack, a server, or a disk?"" msgstr """" ""クラスターの設計時には、耐久性と可用性を考慮する必要があります。耐久性や可用"" ""性は主に、ハードウェアの信頼性に頼るのではなく、データを分散して設置すること"" ""で確保されることを理解してください。レプリカの数のデフォルト値は 3 である点も"" ""考慮します。つまり、オブジェクトが書き込みされたとマークされる前でも、少なく"" ""ともコピーが 2 つ存在します。1 つのサーバーが書き込みに失敗しても、書き込み操"" ""作が最初に返された時点で、3 番めのコピーが存在する可能性があります。この数字"" ""を変更することで、データの堅牢性を高めることができますが、利用可能なストレー"" ""ジ数が減少します。次に、サーバーの設置について見ていきます。データセンターの"" ""ネットワークや停電ゾーン全体に設定するようにします。ゾーンには、ラック、サー"" ""バー、ディスクのいずれを使用していますか？"" msgid """" ""When the fix makes it into a milestone or release branch, it automatically "" ""moves to:"" msgstr """" ""修正がマイルストーンやリリースブランチに取り込まれると、バグの状態は自動的に"" ""以下のようになります。"" msgid """" ""When the snapshot is done, you can thaw the file system with the following "" ""command, as root, inside of the instance:"" msgstr """" ""スナップショットの作成が終わったら、インスタンスの中で root として以下のコマ"" ""ンドを用いて、ファイルシステムをフリーズ解除できます。"" msgid """" ""When this node fully booted, I ran through the same scenario of seeing what "" ""instances were running so I could turn them back on. There were a total of "" ""four. Three booted and one gave an error. It was the same error as before: "" ""unable to find the backing disk. Seriously, what?"" msgstr """" ""そのノードが完全に起動した際、インスタンスが起動した時に何が起こるのかを見る"" ""ため、私は同じシナリオを実行して、インスタンスを復旧した。インスタンスは全部"" ""で４つあった。３つは起動し、１つはエラーになった。このエラーは以前のエラーと"" ""同じだった。「unable to find the backing disk.」マジ、何で？"" msgid """" ""When users provision resources, they can specify from which availability "" ""zone they want their instance to be built. This allows cloud consumers to "" ""ensure that their application resources are spread across disparate machines "" ""to achieve high availability in the event of hardware failure."" msgstr """" ""リソースのプロビジョニングの際には、インスタンスを作成するアベイラビリティ"" ""ゾーンを指定することができます。これによって、クラウドの利用者は、アプリケー"" ""ションのリソースが異なるマシンに分散して配置され、ハードウェア故障が発生した"" ""場合でも高可用性を達成することができます。"" msgid """" ""When you create a deployment plan, focus on a few vital areas because they "" ""are very hard to modify post deployment. The next two sections talk about "" ""configurations for:"" msgstr """" ""デプロイメントプランを作成する場合、デプロイメント後の修正は困難であるため、"" ""いくつかの重要な分野にフォーカスを当ててください。次の 2 章で以下の設定内容に"" ""ついて説明していきます。"" msgid ""When you do this, the bug is created with:"" msgstr ""バグ報告をすると、バグは次のステータスで作成されます。"" msgid """" ""When you run any of the following operations, the services appear in their "" ""own internal availability zone (CONF.internal_service_availability_zone): "" ""<placeholder-1/>The internal availability zone is hidden in euca-describe-"" ""availability_zones (nonverbose)."" msgstr """" ""以下の操作のいずれかを実行する場合、サービスは独自の内部アベイラビリティゾー"" ""ン(CONF.internal_service_availability_zone) に表示されます。<placeholder-1/>"" ""内部のアベイラビリティゾーンは、euca-describe-availability_zones "" ""(nonverbose) に隠し設定されています。"" msgid """" ""When you want to offer users different regions to provide legal "" ""considerations for data storage, redundancy across earthquake fault lines, "" ""or for low-latency API calls, you segregate your cloud. Use one of the "" ""following OpenStack methods to segregate your cloud: <emphasis>cells</"" ""emphasis>, <emphasis>regions</emphasis>, <emphasis>availability zones</"" ""emphasis>, or <emphasis>host aggregates</emphasis>.<indexterm class="" ""\""singular\""><primary>segregation methods</primary></indexterm><indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>cloud segregation</"" ""secondary></indexterm>"" msgstr """" ""法的に考慮したデータストレージ、耐震ラインでの冗長性、低遅延の API コールを提"" ""供する様々なリージョンを提供するには、クラウドを分割します。<emphasis>セル</"" ""emphasis>、<emphasis>リージョン</emphasis>、<emphasis>アベイラビリティゾーン"" ""</emphasis>、<emphasis>ホストアグリゲート</emphasis> のいずれかの OpenStack "" ""メソッドを使用して、クラウドを分割します。<indexterm class=\""singular"" ""\""><primary>分割メソッド</primary></indexterm><indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>クラウド分割</secondary></"" ""indexterm>"" msgid ""Where Are the Logs?"" msgstr ""ログはどこにあるのか？"" msgid """" ""Whereas traditional applications required larger hardware to scale "" ""(\""vertical scaling\""), cloud-based applications typically request more, "" ""discrete hardware (\""horizontal scaling\""). If your cloud is successful, "" ""eventually you must add resources to meet the increasing demand.<indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>vertical vs. "" ""horizontal</secondary></indexterm>"" msgstr """" ""従来のアプリケーションでは、スケーリングするには、より大きいハードウェアが必"" ""要でした (垂直スケーリング) が、クラウドベースのアプリケーションは通常、別の"" ""ハードウェアを必要とします(水平スケーリング)。クラウドを正常に設定できた場"" ""合、需要が増すとそれに合うようにリソースを追加する必要がでてきます。"" ""<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>垂直 "" ""vs 水平</secondary></indexterm>"" msgid """" ""Whether you should enable Hyper-Threading on your CPUs depends upon your use "" ""case. For example, disabling Hyper-Threading can be beneficial in intense "" ""computing environments. We recommend that you do performance testing with "" ""your local workload with both Hyper-Threading on and off to determine what "" ""is more appropriate in your case.<indexterm class=\""singular\""><primary>CPUs "" ""(central processing units)</primary><secondary>enabling hyperthreading on</"" ""secondary></indexterm>"" msgstr """" ""CPU のハイパースレッディングを有効にするかどうかは、それぞれのユースケースに"" ""より変わってきます。例えば、ハイパースレッディングを無効にすると、負荷の高い"" ""コンピューティング環境で有用です。ハイパースレッディングがオン、オフの両方の"" ""状態でローカルのワークロードを使用してパフォーマンスのテストを実施し、各ケー"" ""スでいずれが適しているか決定するように推奨しています。<indexterm class="" ""\""singular\""><primary>CPU (central processing unit)</primary><secondary>ハイ"" ""パースレッディングをオンにする</secondary></indexterm>"" msgid ""Which one results in the best cost-performance scenario I'm aiming for?"" msgstr ""どちらが自分の意図した最高のコストパフォーマンスシナリオを実現するか？"" msgid """" ""Which one results in the best cost-performance scenario you're aiming for?"" msgstr ""何があなたが目指すコストパフォーマンスのシナリオはどれか？"" msgid """" ""While bouncing this idea around in our heads, I was randomly typing commands "" ""on the compute node: <placeholder-1/>"" msgstr """" ""このアイデアが我々の頭を駆け巡る間、私はコンピュートノード上でコマンドをラン"" ""ダムに叩いていた。 <placeholder-1/>"" msgid """" ""While it is important for an operator to be familiar with the steps involved "" ""in deploying OpenStack, we also strongly encourage you to evaluate "" ""configuration-management tools, such as <glossterm>Puppet</glossterm> or "" ""<glossterm>Chef</glossterm>, which can help automate this deployment process."" ""<indexterm class=\""singular\""><primary>Chef</primary></indexterm><indexterm "" ""class=\""singular\""><primary>Puppet</primary></indexterm>"" msgstr """" ""オペレータはOpenStackのデプロイに必要な手順に精通している事は重要ですが、一方"" ""で、 <glossterm>Puppet</glossterm> や <glossterm>Chef</glossterm>と言った構成"" ""管理ツールの検証評価をする事を強くお勧めします。それらは自動構成をする手助け"" ""となります。<indexterm class=\""singular\""><primary>Chef</primary></"" ""indexterm><indexterm class=\""singular\""><primary>Puppet</primary></indexterm>"" msgid """" ""While our example contains all central services in a single location, it is "" ""possible and indeed often a good idea to separate services onto different "" ""physical servers. <xref linkend=\""sep-services-table\""/> is a list of "" ""deployment scenarios we've seen and their justifications.<indexterm class="" ""\""singular\""><primary>provisioning/deployment</primary><secondary>deployment "" ""scenarios</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>services</primary><secondary>separation of</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>separation of services</"" ""primary></indexterm><indexterm class=\""singular\""><primary>design "" ""considerations</primary><secondary>separation of services</secondary></"" ""indexterm>"" msgstr """" ""この例ではすべての中心的なサービスが1つの場所にありますが、サービスを分割して"" ""それぞれ別の物理サーバに配置する事は可能であり、本当に良いアイデアです。"" ""<xref linkend=\""sep-services-table\""/> は構築のシナリオと設計の理由です。"" ""<indexterm class=\""singular\""><primary>プロビジョニング/構築</"" ""primary><secondary>構築シナリオ</secondary></indexterm><indexterm class="" ""\""singular\""><primary>サービス</primary><secondary>分離</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>サービスの分離</primary></"" ""indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>サービスの分離</secondary></indexterm>"" msgid """" ""While several resources already exist to help with deploying and installing "" ""OpenStack, it's very important to make sure that you have your deployment "" ""planned out ahead of time. This guide presumes that you have at least set "" ""aside a rack for the OpenStack cloud but also offers suggestions for when "" ""and what to scale."" msgstr """" ""OpenStack のデプロイやインストールの助けとなるリソースがすでに複数存在してい"" ""る場合でも、時間に余裕を持ってデプロイメントの系っ買うを立てることは非常に重"" ""要です。本書は、OpenStack クラウド用のラックを少なくとも 1 つ用意しているとの"" ""前提で、何を度のタイミングでスケールするかの提案をしていきます。"" msgid """" ""While the cloud can be run without the <emphasis>OpenStack Dashboard</"" ""emphasis>, we consider it to be indispensable, not just for user interaction "" ""with the cloud, but also as a tool for operators. Additionally, the "" ""dashboard's use of Django makes it a flexible framework for <phrase role="" ""\""keep-together\"">extension</phrase>."" msgstr """" ""クラウドは <emphasis>OpenStack Dashboard</emphasis> がなくても稼働させること"" ""は可能ですが、クラウドとの対話だけでなく運用担当者のツールとしても不可欠な要"" ""素と判断しました。また、ダッシュボードに採用されている Django により、"" ""<phrase role=\""keep-together\"">拡張機能</phrase> のための柔軟なフレームワーク"" ""となります。"" msgid """" ""While version 3 of the Identity API is available, the client tools do not "" ""yet implement those calls, and most OpenStack clouds are still implementing "" ""Identity API v2.0.<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>Identity Service API</secondary></indexterm>"" msgstr """" ""Identity API バージョン 3 が利用できますが、クライアントツールにはこれらの呼"" ""び出しがまだ実装されておらず、多くの OpenStack クラウドは Identity API v2.0 "" ""を実装しています。<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>Identity Service API</secondary></indexterm>"" msgid """" ""While you might end up with unused partitions, such as partition 1 in disk "" ""three and four of this example, this option allows for maximum utilization "" ""of disk space. I/O performance might be an issue as a result of all disks "" ""being used for all tasks."" msgstr """" ""この例では、ディスク 3 と 4 のパーティション 1 のように未使用のパーティション"" ""が残る可能性もありますが、このオプションにより、ディスク領域の使用状況を最大"" ""化することができます。すべてのディスクがすべてのタスクで利用されるため、I/O "" ""のパフォーマンスが問題になる可能性があります。"" msgid ""Who This Book Is For"" msgstr ""この本の対象読者"" msgid ""Why and How We Wrote This Book"" msgstr ""この本をなぜ書いたか？どうやって書いたか？"" msgid ""Why not use the OpenStack Network Service (neutron)?"" msgstr ""OpenStack Network Service (neutron) を使用しない理由"" msgid ""Why use multi-host networking?"" msgstr ""マルチホストネットワークを使用する理由"" msgid """" ""With file-level storage, users access stored data using the operating "" ""system's file system interface. Most users, if they have used a network "" ""storage solution before, have encountered this form of networked storage. In "" ""the Unix world, the most common form of this is NFS. In the Windows world, "" ""the most common form is called CIFS (previously, SMB).<indexterm class="" ""\""singular\""><primary>migration</primary></indexterm><indexterm class="" ""\""singular\""><primary>live migration</primary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>file-level</secondary></"" ""indexterm>"" msgstr """" ""ファイルレベルのストレージでは、ユーザーは、オペレーティングシステムのファイ"" ""ルシステムインターフェースを使用して保存したデータにアクセスします。ネット"" ""ワークストレージソリューションの使用経験のあるユーザーの多くは、この形式の"" ""ネットワークストレージを使用したことがあります。Unix の分野では、ネットワーク"" ""ストレージで最も一般的なものが NFS で、Windows では CIFS (旧称 SMB) です。"" ""<indexterm class=\""singular\""><primary>migration</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ライブマイグレーション</"" ""primary></indexterm><indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>ファイルレベル</secondary></indexterm>"" msgid """" ""With object storage, users access binary objects through a REST API. You may "" ""be familiar with Amazon S3, which is a well-known example of an object "" ""storage system. Object storage is implemented in OpenStack by the OpenStack "" ""Object Storage (swift) project. If your intended users need to archive or "" ""manage large datasets, you want to provide them with object storage. In "" ""addition, OpenStack can store your virtual <phrase role=\""keep-together"" ""\"">machine</phrase> (VM) images inside of an object storage system, as an "" ""alternative to storing the images on a file system.<indexterm class="" ""\""singular\""><primary>binary</primary><secondary>binary objects</secondary></"" ""indexterm>"" msgstr """" ""オブジェクトストレージでは、REST API を使用してバイナリオブジェクトにアクセス"" ""します。オブジェクトストレージで有名な例として、Amazon S3 は知られています。"" ""オブジェクトストレージは、OpenStack Object Storage (swift) プロジェクトによ"" ""り、OpenStack に実装されています。ユーザーが、大規模なデータセットをアーカイ"" ""ブまたは管理する場合オブジェクトストレージを提供します。さらに OpenStack で"" ""は、ファイルシステムにイメージを格納する代わりに、仮想<phrase role=\""keep-"" ""together\"">マシン</phrase> (VM) のイメージを、オブジェクトストレージシステム"" ""の中に格納できます。<indexterm class=\""singular\""><primary>バイナリ</"" ""primary><secondary>バイナリオブジェクト</secondary></indexterm>"" msgid """" ""With so many considerations and options available, our hope is to provide a "" ""few clearly-marked and tested paths for your OpenStack exploration. If "" ""you're looking for additional ideas, check out <xref linkend=\""use-cases\""/"" "">, the <link href=\""http://docs.openstack.org/\"">OpenStack Installation "" ""Guides</link>, or the <link href=\""http://www.openstack.org/user-stories/"" ""\"">OpenStack User Stories page</link>."" msgstr """" ""数多くの考慮事項およびオプションがあるため、本セクションでは、OpenStack をお"" ""試しいただくための明確に記載した検証済みの方法を提供するように構成していま"" ""す。本セクションに記載した以外の情報をお探しの場合には、<xref linkend=\""use-"" ""cases\""/>、<link href=\""http://docs.openstack.org/\"">OpenStack Installation "" ""Guides</link>、または <link href=\""http://www.openstack.org/user-stories/"" ""\"">OpenStack User Stories page</link> をご確認ください。"" msgid """" ""With these two tables, you now have a good overview of what servers and "" ""services make up your cloud."" msgstr """" ""これら2つの表で、どのサーバーとサービスがあなたのクラウドを構成しているのか、"" ""概要を知ることができました。"" msgid """" ""With this information in hand, we were sure that the problem had to do with "" ""DHCP. We thought that for some reason, the instance wasn't getting a new IP "" ""address and with no IP, it shut itself off from the network."" msgstr """" ""この情報により、我々は問題が DHCP 実行に起因するものと確信した。何らかの理由"" ""でインスタンスが新しいIPアドレスを取得できず、その結果IPアドレスがなくなり、"" ""インスタンスは自分自身をネットワークから切り離した、と考えた。"" msgid """" ""With this option, you can assign different partitions to different RAID "" ""arrays. You can allocate partition 1 of disk one and two to the <code>/boot</"" ""code> partition mirror. You can make partition 2 of all disks the root "" ""partition mirror. You can use partition 3 of all disks for a <code>cinder-"" ""volumes</code> LVM partition running on a RAID 10 array."" msgstr """" ""このオプションでは、パーティションごとに異なる RAID アレイにおくことができま"" ""す。例えば、ディスク 1 とディスク 2 のパーティション 1 を <code>/boot</code> "" ""パーティションのミラーとして、すべてのディスクのパーティション 2 をルートパー"" ""ティションのミラーとして、すべてのディスクのパーティション 3 を RAID10 アレイ"" ""の上の <code>cinder-volumes</code> の LVM パーティションとして割り当てること"" ""ができます。"" msgid ""Within a VM"" msgstr ""VM内"" msgid ""Working with Hardware"" msgstr ""ハードウェアの取り扱い"" msgid ""Works with all guest operating systems."" msgstr ""どんなゲストOSでも動きます。"" msgid ""Xen"" msgstr ""Xen"" msgid """" ""You are prompted for a project name and an optional, but recommended, "" ""description. Select the checkbox at the bottom of the form to enable this "" ""project. By default, it is enabled, as shown in <xref linkend=\""horizon-add-"" ""project\""/>."" msgstr """" ""プロジェクト名および任意の説明 (推奨) が要求されます。フォームの一番下の"" ""チェックボックスを選択してこのプロジェクトを有効にします。<xref linkend="" ""\""horizon-add-project\""/>のように、デフォルトでは、有効になっています。"" msgid """" ""You can also use the Identity Service (keystone) to see what services are "" ""available in your cloud as well as what endpoints have been configured for "" ""the services.<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>displaying services and endpoints with</secondary></"" ""indexterm>"" msgstr """" ""また、Identity Service (keystone) を使用してクラウドで利用可能なサービスと、"" ""サービス用に設定済みのエンドポイントを確認することもできます。<indexterm "" ""class=\""singular\""><primary>Identity Service</primary><secondary>サービスおよ"" ""びエンドポイントの表示</secondary></indexterm>"" msgid """" ""You can configure some services, such as <code>nova-api</code> and "" ""<code>glance-api</code>, to use multiple processes by changing a flag in "" ""their configuration file—allowing them to share work between multiple cores "" ""on the one machine."" msgstr """" ""<code>nova-api</code> や <code>glance-api</code> などのサービスは、環境設定"" ""ファイルのフラグを変更することによって複数プロセスで処理させるように設定でき"" ""ます。これによって 1 台のサーバー上にある複数のコアの間で処理を共有できるよう"" ""になります。""""You can easily automate this process by creating a cron job that runs the "" ""following script once per day:""""以下のようなcronジョブを一日に一度実行することで、簡単に自動化することも出来""""You can extend this reference architecture as<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>optional "" ""extensions</secondary></indexterm> follows:""""この参照アーキテクチャは、<indexterm class=\""singular\""><primary>レガシーネッ"" ""トワーク (nova)</primary><secondary>オプションの拡張機能</secondary></"" ""indexterm>以下のように拡張することが可能です:""""You can facilitate the horizontal expansion of your cloud by adding nodes. "" ""Adding compute nodes is straightforward—they are easily picked up by the "" ""existing installation. However, you must consider some important points when "" ""you design your cluster to be highly available.<indexterm class=\""singular"" ""\""><primary>compute nodes</primary><secondary>adding</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>high availability</"" ""primary></indexterm><indexterm class=\""singular\""><primary>configuration "" ""options</primary><secondary>high availability</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>cloud controller nodes</"" ""primary><secondary>adding</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>adding cloud controller nodes</"" ""secondary></indexterm>""""ノードを追加することで、垂直に拡張するのが容易になります。コンピュートノード"" ""の追加は単純で、既存のインストール環境から簡単にピックアップすることができま"" ""す。しかし、高可用性のクラスターを設計するには、重要なポイントを考慮する必要"" ""があります。<indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>追加</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>高可用性</primary></indexterm><indexterm class=\""singular"" ""\""><primary>設定オプション</primary><secondary>高可用性</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>クラウドコントローラーノード"" ""</primary><secondary>追加</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>クラウドコントローラーノードの追"" ""加</secondary></indexterm>""msgid """" ""You can find a matrix of the functionality provided by all of the supported "" ""Block Storage drivers on the <link href=\""https://wiki.openstack.org/wiki/"" ""CinderSupportMatrix\"" title=\""OpenStack wiki\"">OpenStack wiki</link>."" msgstr """" ""<link href=\""https://wiki.openstack.org/wiki/CinderSupportMatrix\"" title="" ""\""OpenStack wiki\"">OpenStack wiki</link> で、サポートされている全ブロックスト"" ""レージドライバーが提供する機能一覧を確認いただけます。"" msgid """" ""You can find the version of the Compute installation by using the "" ""<literal>nova-manage</literal><phrase role=\""keep-together\"">command</"" ""phrase>: <placeholder-1/>"" msgstr """" ""インストールされている Compute のバージョンを確認するには、<literal>nova-"" ""manage</literal><phrase role=\""keep-together\"">command</phrase> を使用するこ"" ""とができます: <placeholder-1/>"" msgid """" ""You can now optionally migrate the instances back to their original compute "" ""node."" msgstr """" ""インスタンスを元のコンピュートノードにマイグレーションすることもできます。"" msgid """" ""You can obtain extra information about virtual machines that are running—"" ""their CPU usage, the memory, the disk I/O or network I/O—per instance, by "" ""running the <literal>nova diagnostics</literal> command with<indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>diagnosing</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>command-line "" ""tools</primary><secondary>compute node diagnostics</secondary></indexterm> a "" ""server ID:"" msgstr """" ""実行中の仮想マシンの CPU 使用状況、メモリー、ディスク I/O、ネットワーク I/O "" ""などの追加情報を取得するには、<literal>nova diagnostics</literal> コマンドに"" ""<indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>診断</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>コマンドラインツール</primary><secondary>コンピュートノードの診断"" ""</secondary></indexterm>サーバー ID を指定して実行します:"" msgid """" ""You can obtain further statistics by looking for the number of successful "" ""requests:"" msgstr ""成功したリクエストを検索することで、更なる情報を取得できます。"" msgid """" ""You can save resources by looking at the best fit for the hardware you have "" ""in place already. You might have some high-density storage hardware "" ""available. You could format and repurpose those servers for OpenStack Object "" ""Storage. All of these considerations and input from users help you build "" ""your use case and your deployment plan."" msgstr """" ""すでに設置済みのハードウェアに最適な方法で使用されていることをチェックするこ"" ""とで、リソースを節約することができます。高濃度のストレージハードウェアがある"" ""とします。このハードウェアをフォーマットして、OpenStack Object Storage 用に"" ""サーバーの用途を変更することができます。ユーザーからのこのような検討やイン"" ""プットすべてをベースにすることで、ユースケースやデプロイメントプランの作成が"" ""容易になります。"" msgid """" ""You can save time by understanding the use cases for the cloud you want to "" ""create. Use cases for OpenStack are varied. Some include object storage "" ""only; others require preconfigured compute resources to speed development-"" ""environment set up; and others need fast provisioning of compute resources "" ""that are already secured per tenant with private networks. Your users may "" ""have need for highly redundant servers to make sure their legacy "" ""applications continue to run. Perhaps a goal would be to architect these "" ""legacy applications so that they run on multiple instances in a cloudy, "" ""fault-tolerant way, but not make it a goal to add to those clusters over "" ""time. Your users may indicate that they need scaling considerations because "" ""of heavy Windows server use.<indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>tips for</"" ""secondary></indexterm>"" msgstr """" ""作成するクラウドのユースケースを理解することで時間を節約することあできます。"" ""OpenStack のユースケースはさまざまで、オブジェクトストレージのみのもの、開発"" ""環境設定を加速するために事前設定されたコンピュートリソースが必要なもの、プラ"" ""イベートネットワークでテナントごとにセキュリティが確保されたコンピュートリ"" ""ソースの迅速にプロビジョニングするものもあります。ユーザーは、レガシーアプリ"" ""ケーションが継続して実行されるように、非常に冗長化されたサーバーが必要な場合"" ""もあります。おそらく、時間をかけてこれらのクラスターを追加するのが目的ではな"" ""く、クラウドの耐障害性を確保したかたちで、複数のインスタンス上で実行するため"" ""に、レガシーのアプリケーションを構築するのが目的の場合もあります。ユーザーに"" ""よっては、負荷の高い Windows サーバーを使用するため、スケーリングを考慮する必"" ""要があると指定する場合もあるでしょう。<indexterm class=\""singular\""><primary>"" ""プロビジョニング/デプロイメント</primary><secondary>tips for</secondary></"" ""indexterm>"" msgid ""You can scale to any number of spindles."" msgstr ""スピンドル数を何個にでもスケールすることができます。"" msgid """" ""You can use availability zones, host aggregates, or both to partition a nova "" ""deployment.<indexterm class=\""singular\""><primary>scaling</"" ""primary><secondary>availability zones</secondary></indexterm>"" msgstr """" ""アベイラビリティゾーン、ホストアグリゲート、または両方を使用して、nova デプロ"" ""イメントを分割することができます。<indexterm class=\""singular\""><primary>ス"" ""ケーリング</primary><secondary>アベイラビリティゾーン</secondary></indexterm>"" msgid """" ""You define the availability zone in which a specified compute host resides "" ""locally on each server. An availability zone is commonly used to identify a "" ""set of servers that have a common attribute. For instance, if some of the "" ""racks in your data center are on a separate power source, you can put "" ""servers in those racks in their own availability zone. Availability zones "" ""can also help separate different classes of hardware."" msgstr """" ""指定したコンピュートホストがローカルでサーバー毎に所属するアベイラビリティ"" ""ゾーンを定義します。アベイラビリティゾーンは一般的に、共通の属性を持つサー"" ""バーを識別するために使用されます。例えば、データセンターのラックの一部が別の"" ""電源を仕様している場合、このラックのサーバーを独自のアベイラビリティゾーンに"" ""入れることができます。アベイラビリティゾーンは、異なるハードウェアクラスを分"" ""割することもできます。"" msgid """" ""You may find that you can automate the partitioning itself. For example, MIT "" ""uses <link href=\""http://fai-project.org/\"">Fully Automatic Installation "" ""(FAI)</link> to do the initial PXE-based partition and then install using a "" ""combination of min/max and percentage-based partitioning.<indexterm class="" ""\""singular\""><primary>Fully Automatic Installation (FAI)</primary></"" ""indexterm>"" msgstr """" ""パーティショニング自体を自動化可能であることが分かります。例えば、MIT は "" ""<link href=\""http://fai-project.org/\"">Fully Automatic Installation (FAI)</"" ""link> を使用して、初期の PXE ベースのパーティション分割を行い、min/max および"" ""パーセントベースのパーティショニングを組み合わせてインストールしていきます。"" ""<indexterm class=\""singular\""><primary>Fully Automatic Installation (FAI)</"" ""primary></indexterm>"" msgid """" ""You must also consider key hardware specifications for the performance of "" ""user VMs, as well as budget and performance needs, including storage "" ""performance (spindles/core), memory availability (RAM/core), network "" ""bandwidth<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>hardware specifications and</secondary></indexterm> (Gbps/"" ""core), and overall CPU performance (CPU/core)."" msgstr """" ""また、仮想マシンのパフォーマンス、ストレージの性能 (スピンドル/コア)、メモ"" ""リーの空き容量 (RAM/コア)、ネットワークの帯域幅など、予算や性能のニーズに関し"" ""て、主なハードウェアの仕様を考慮する必要もあります。<indexterm class="" ""\""singular\""><primary>帯域幅</primary><secondary>ハードウェアの仕様</"" ""secondary></indexterm> (Gbps/コア)、全体的な CPU のパフォーマンス (CPU/コア)"" msgid """" ""You must choose an operating system that can run on all of the physical "" ""nodes. This example architecture is based on Red Hat Enterprise Linux, which "" ""offers reliability, long-term support, certified testing, and is hardened. "" ""Enterprise customers, now moving into OpenStack usage, typically require "" ""these advantages."" msgstr """" ""全物理ノードで実行可能なオペレーティングシステムを選択する必要があります。こ"" ""のアーキテクチャ例は、信頼性、長期的なサポート、認定テストが提供され、セキュ"" ""リティ強化されている Red Hat Enterprise Linux をベースにしています。現在、"" ""OpenStack の採用に向けて移行中の企業顧客には、通常このような利点が要求されま"" ""す。"" msgid """" ""You must choose whether you want to support the Amazon EC2 compatibility "" ""APIs, or just the OpenStack APIs. One issue you might encounter when running "" ""both APIs is an inconsistent experience when referring to images and "" ""instances."" msgstr """" ""Amazon EC2 互換 API をサポートしたいか、OpenStack API だけなのか、選択しなけ"" ""ればなりません。両方の API を運用する場合、イメージとインスタンスを参照する際"" ""の見え方が違うことが一つの論点になります。"" msgid """" ""You must complete the following configurations on the server's hard drives:"" msgstr """" ""サーバーのハードディスクに対して、以下の環境設定を完了させなければなりませ"" ""ん。"" msgid """" ""You must first choose the operating system that runs on all of the physical "" ""nodes. While OpenStack is supported on several distributions of Linux, we "" ""used <emphasis>Ubuntu 12.04 LTS (Long Term Support)</emphasis>, which is "" ""used by the majority of the development community, has feature completeness "" ""compared with other distributions and has clear future support plans."" msgstr """" ""まず最初に、物理ノード上で実行するオペレーティングシステムを選択する必要があ"" ""ります。OpenStack は複数の Linux ディストリビューションでサポートされています"" ""が、開発コミュニティの大半で使用されている <emphasis>Ubuntu 12.04 LTS (Long "" ""Term Support)</emphasis> を使用しました。このディストリビューションは、他の"" ""ディストリビューションと比較した場合、機能の完全性が高く、将来のサポートプラ"" ""ンが明確に立てられています。"" msgid """" ""You must have the appropriate credentials if you want to use the command-"" ""line tools to make queries against your OpenStack cloud. By far, the easiest "" ""way to obtain <glossterm>authentication</glossterm> credentials to use with "" ""command-line clients is to use the OpenStack dashboard. From the top-right "" ""navigation row, select <guimenuitem>Project</guimenuitem>, then "" ""<guimenuitem>Access &amp; Security</guimenuitem>, then <guimenuitem>API "" ""Access</guimenuitem> to access the user settings page where you can set your "" ""language and timezone preferences for the dashboard view. This action "" ""displays two buttons, <guilabel>Download OpenStack RC File</guilabel> and "" ""<guilabel>Download EC2 Credentials</guilabel>, which let you generate files "" ""that you can source in your shell to populate the environment variables the "" ""command-line tools require to know where your service endpoints and your "" ""authentication information are. The user you logged in to the dashboard "" ""dictates the filename for the openrc file, such as <filename>demo-openrc.sh</"" ""filename>. When logged in as admin, the file is named <filename>admin-openrc."" ""sh</filename>.<indexterm class=\""singular\""><primary>credentials</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authentication</primary></"" ""indexterm><indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>getting credentials</secondary></indexterm>"" msgstr """" ""コマンドラインツールを使用して OpenStack クラウドに対してクエリーを実行するに"" ""は、適切な認証情報が必要です。コマンドラインクライアントで使用する<glossterm>"" ""認証</glossterm>のクレデンシャルを取得する最も簡単な方法は、OpenStack ダッ"" ""シュボードを使用する方法です。画面右上のナビレーションバーから <guimenuitem>"" ""プロジェクト</guimenuitem> を選択し、<guimenuitem>アクセスとセキュリティ</"" ""guimenuitem> をクリックしてから, <guimenuitem>API アクセス</guimenuitem> のタ"" ""ブを開き、ユーザー設定のページにアクセスします。このページでは、ダッシュボー"" ""ドで表示される言語とタイムゾーンを設定することができます。この操作では、"" ""<guilabel>OpenStack RC ファイルのダウンロード</guilabel> と <guilabel>EC2 認"" ""証情報のダウンロード</guilabel> の 2 つのボタンが表示されます。これらのボタン"" ""により、コマンドラインツールがサービスエンドポイントと認証情報の場所を知るの"" ""に必要な環境変数を読み込むために、シェルで元データとして使用することのできる"" ""ファイルを生成することができます。ダッシュボードにログインしたユーザーによっ"" ""て、openrc ファイルのファイル名が決定します (例: <filename>demo-openrc.sh</"" ""filename>)。admin としてログインした場合には、ファイル名は <filename>admin-"" ""openrc.sh</filename> となります。<indexterm class=\""singular\""><primary>認証"" ""情報</primary></indexterm><indexterm class=\""singular\""><primary>認証</"" ""primary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツー"" ""ル</primary><secondary>認証情報の取得</secondary></indexterm>"" msgid """" ""You must have the matching private key to access instances associated with "" ""this key."" msgstr """" ""この鍵と関連付けられたインスタンスにアクセスするために、対応する秘密鍵を持つ"" ""必要があります。""""You must select the appropriate CPU and RAM allocation ratio for your "" ""particular use case.""""あなた自身のユースケースに合わせて、適切な CPU と RAM の割当比を選択しなけれ"" ""ばなりません。"" msgid ""You need to size the controller with a core per service."" msgstr """" ""サービスごとに１コア割り当ててコントローラーをサイジングする必要があります。"" msgid """" ""Your credentials are a combination of username, password, and tenant "" ""(project). You can extract these values from the <code>openrc.sh</code> "" ""discussed above. The token allows you to interact with your other service "" ""endpoints without needing to reauthenticate for every request. Tokens are "" ""typically good for 24 hours, and when the token expires, you are alerted "" ""with a 401 (Unauthorized) response and you can request another <phrase role="" ""\""keep-together\"">token</phrase>.<indexterm class=\""singular"" ""\""><primary>catalog</primary></indexterm>"" msgstr """" ""認証情報はユーザー名、パスワード、テナント (プロジェクト) の組み合わせです。"" ""これらの値は、前述の <code>openrc.sh</code> から抽出することができます。トー"" ""クンにより、要求ごとに再認証する必要なく他のエンドポイントとの対話を行うこと"" ""ができます。トークンは通常 24 時間有効です。期限が切れると、401 "" ""(Unauthorized) の応答で警告され、<phrase role=\""keep-together\"">トークン</"" ""phrase> をもう 1 つ要求することができます。<indexterm class=\""singular"" ""\""><primary>カタログ</primary></indexterm>"" msgid ""ZFS"" msgstr ""ZFS"" msgid ""ZFS<indexterm class=\""singular\""><primary>ZFS</primary></indexterm>"" msgstr ""ZFS<indexterm class=\""singular\""><primary>ZFS</primary></indexterm>"" msgid ""admin"" msgstr ""admin"" msgid ""bandwidth_poll_interval"" msgstr ""bandwidth_poll_interval"" msgid ""base_image_ref"" msgstr ""base_image_ref"" msgid ""cinder-*"" msgstr ""cinder-*"" msgid ""cinder-manage"" msgstr ""cinder-manage"" msgid ""cinder-scheduler"" msgstr ""cinder-scheduler"" msgid ""controller"" msgstr ""controller"" msgid ""cores"" msgstr ""cores"" msgid ""created_at"" msgstr ""created_at"" msgid ""delete-on-terminate"" msgstr ""delete-on-terminate"" msgid ""deleted_at"" msgstr ""deleted_at"" msgid ""dev-name"" msgstr ""dev-name"" msgid ""euca-describe-availability-zones verbose"" msgstr ""euca-describe-availability-zones verbose"" msgid ""extra_specs"" msgstr ""extra_specs"" msgid ""file"" msgstr ""file"" msgid ""fixed-ips"" msgstr ""fixed-ips"" msgid ""fixed_ips"" msgstr ""fixed_ips"" msgid ""floating-ips"" msgstr ""floating-ips"" msgid ""gigabytes"" msgstr ""gigabytes"" msgid ""glance-*"" msgstr ""glance-*"" msgid ""glance-manage"" msgstr ""glance-manage"" msgid ""heal_instance_info_cache_interval"" msgstr ""heal_instance_info_cache_interval"" msgid ""horizon"" msgstr ""horizon"" msgid ""host_state_interval"" msgstr ""host_state_interval"" msgid ""hosts_up"" msgstr ""hosts_up"" msgid ""id"" msgstr ""id"" msgid ""image_cache_manager_interval"" msgstr ""image_cache_manager_interval"" msgid ""image_location"" msgstr ""image_location"" msgid ""image_properties"" msgstr ""image_properties"" msgid ""image_type"" msgstr ""image_type"" msgid ""images"" msgstr ""images"" msgid ""injected-file-content-bytes"" msgstr ""injected-file-content-bytes"" msgid ""injected-file-path-bytes"" msgstr ""injected-file-path-bytes"" msgid ""injected-files"" msgstr ""injected-files"" msgid ""instance_delete_interval"" msgstr ""instance_delete_interval"" msgid ""instance_uuid"" msgstr ""instance_uuid"" msgid ""instances"" msgstr ""instances"" msgid ""iptables"" msgstr ""iptables"" msgid ""key"" msgstr ""key"" msgid ""key-pairs"" msgstr ""key-pairs"" msgid ""keystone-manage"" msgstr ""keystone-manage"" msgid ""launched_at"" msgstr ""launched_at"" msgid ""libvirt"" msgstr ""libvirt"" msgid ""m1.large"" msgstr ""m1.large"" msgid ""m1.medium"" msgstr ""m1.medium"" msgid ""m1.small"" msgstr ""m1.small"" msgid ""m1.tiny"" msgstr ""m1.tiny"" msgid ""m1.xlarge"" msgstr ""m1.xlarge"" msgid ""metadata-items"" msgstr ""metadata-items"" msgid ""multi-host*"" msgstr ""マルチホスト*"" msgid ""nova host-list (os-hosts)"" msgstr ""nova host-list (os-hosts)"" msgid ""nova-*"" msgstr ""nova-*"" msgid ""nova-api"" msgstr ""nova-api"" msgid ""nova-manage"" msgstr ""nova-manage"" msgid ""nova-network"" msgstr ""nova-network"" msgid ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" msgstr ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" msgid ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" msgstr ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" msgid ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" msgstr ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" msgid ""python-neutronclient (<glossterm>neutron</glossterm> CLI)"" msgstr ""python-neutronclient (<glossterm>neutron</glossterm> CLI)"" msgid ""python-novaclient (<glossterm>nova</glossterm> CLI)"" msgstr ""python-novaclient (<glossterm>nova</glossterm> CLI)"" msgid ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" msgstr ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" msgid ""quotaName"" msgstr ""quotaName"" msgid ""quotaValue"" msgstr ""quotaValue"" msgid ""ram"" msgstr ""ram"" msgid ""reclaim_instance_interval"" msgstr ""reclaim_instance_interval"" msgid ""rsyslog Client Configuration"" msgstr ""rsyslog クライアント設定"" msgid ""rsyslog Server Configuration"" msgstr ""rsyslog サーバー設定"" msgid ""scheduled_at"" msgstr ""scheduled_at"" msgid ""security-group-rules"" msgstr ""security-group-rules"" msgid ""security-groups"" msgstr ""security-groups"" msgid ""shelved_offload_time"" msgstr ""shelved_offload_time"" msgid ""shelved_poll_interval"" msgstr ""shelved_poll_interval"" msgid ""size (GB)"" msgstr ""size (GB)"" msgid ""snapshot"" msgstr ""スナップショット"" msgid ""snapshots"" msgstr ""snapshots"" msgid ""sync_power_state_interval"" msgstr ""sync_power_state_interval"" msgid ""tcpdump"" msgstr ""tcpdump"" msgid ""tenantID"" msgstr ""tenantID"" msgid ""tenantName"" msgstr ""tenantName"" msgid ""terminated_at"" msgstr ""terminated_at"" msgid ""type"" msgstr ""type"" msgid ""update_service_capabilities"" msgstr ""update_service_capabilities"" msgid ""updated_at"" msgstr ""updated_at"" msgid ""username"" msgstr ""ユーザー名"" msgid ""value"" msgstr ""value"" msgid """" ""vlan20 is the VLAN that the data center gave us for outgoing public internet "" ""access. It's a correct VLAN and is also attached to bond0."" msgstr """" ""vlan20 はデータセンターが外向けのパブリックなインターネットアクセス用に我々に"" ""付与した VLAN である。これは正しい VLAN で bond0 にアタッチされている。"" msgid ""volume_usage_poll_interval"" msgstr ""volume_usage_poll_interval"" msgid ""volumes"" msgstr ""volumes"" msgid ""where <code>nova</code> is the database you want to back up."" msgstr ""ここで <code>nova</code> はバックアップ対象のデータベースです。"" msgid "" "" msgstr "" "" msgid """" ""“The Cloud” has been described as a volatile environment where servers can "" ""be created and terminated at will. While this may be true, it does not mean "" ""that your servers must be volatile. Ensuring that your cloud’s hardware is "" ""stable and configured correctly means that your cloud environment remains up "" ""and running. Basically, put effort into creating a stable hardware "" ""environment so that you can host a cloud that users may treat as unstable "" ""and volatile.<indexterm class=\""singular\""><primary>servers</"" ""primary><secondary>avoiding volatility in</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>hardware</primary><secondary>scalability "" ""planning</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>hardware procurement</secondary></"" ""indexterm>"" msgstr """" ""「クラウド」とは、サーバーを自由に作成、終了でき、不安定な環境と説明されてき"" ""ました。これは真実ですが、サーバー自体が不安定なわけではありません。クラウド"" ""のハードウェアは、安定して正しく設定されているようにすることで、クラウド環境"" ""は稼動状態を保ちます。基本的に、安定したハードウェア環境を構築するように努め"" ""ることで、ユーザーが不安定かつ変化しやすいものとして処理を行う可能性のあるク"" ""ラウドをホストすることができます。<indexterm class=\""singular"" ""\""><primary>servers</primary><secondary>不安定性の回避</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ハードウェア</"" ""primary><secondary>拡張性プランニング</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>スケーリング</primary><secondary>ハードウェア調達"" ""</secondary></indexterm>""","""POT-Creation-Date: 2015-05-09 07:30+0000\n"" ""PO-Revision-Date: 2015-05-12 08:26+0000\n""#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST""msgid ""Series"" msgstr ""シリーズ""msgid ""Status"" msgstr ""状態""msgid ""Releases"" msgstr ""リリース番号""msgid ""Date"" msgstr ""リリース日""msgid ""Liberty"" msgstr ""Liberty""msgid ""Kilo"" msgstr ""Kilo""msgid ""Current stable release, security-supported"" msgstr ""現在の安定版リリース、セキュリティアップデート対象""msgid ""Juno"" msgstr ""Juno""msgid ""Icehouse"" msgstr ""Icehouse""msgid ""Havana"" msgstr ""Havana""msgid ""2013.2"" msgstr ""2013.2""msgid ""Apr 4, 2013"" msgstr ""2013年4月4日""msgid ""2013.2.1"" msgstr ""2013.2.1""msgid ""Dec 16, 2013"" msgstr ""2013年12月16日""msgid ""Grizzly"" msgstr ""Grizzly""msgid ""May 9, 2013"" msgstr ""2013年5月9日"" msgid ""Jun 6, 2013"" msgstr ""2013年6月6日"" msgid ""Aug 8, 2013"" msgstr ""2013年8月8日"" msgid ""Oct 17, 2013"" msgstr ""2013年10月17日""msgid ""Folsom"" msgstr ""Folsom"" msgid ""2012.2"" msgstr ""2012.2"" msgid ""Sep 27, 2012"" msgstr ""2012年9月27日"" msgid ""2012.2.1"" msgstr ""2012.2.1"" msgid ""Nov 29, 2012"" msgstr ""2012年11月29日"" msgid ""2012.2.2"" msgstr ""2012.2.2"" msgid ""Dec 13, 2012"" msgstr ""2012年12月13日"" msgid ""2012.2.3"" msgstr ""2012.2.3"" msgid ""Jan 31, 2013"" msgstr ""2013年1月31日"" msgid ""2012.2.4"" msgstr ""2012.2.4"" msgid ""Apr 11, 2013"" msgstr ""2013年4月11日"" msgid ""Essex"" msgstr ""Essex"" msgid ""2012.1"" msgstr ""2012.1"" msgid ""Apr 5, 2012"" msgstr ""2012年4月5日"" msgid ""2012.1.1"" msgstr ""2012.1.1"" msgid ""Jun 22, 2012"" msgstr ""2012年6月22日"" msgid ""2012.1.2"" msgstr ""2012.1.2"" msgid ""Aug 10, 2012"" msgstr ""2012年8月10日"" msgid ""2012.1.3"" msgstr ""2012.1.3"" msgid ""Oct 12, 2012"" msgstr ""2012年10月12日"" msgid ""Diablo"" msgstr ""Diablo"" msgid ""Deprecated"" msgstr ""非推奨"" msgid ""2011.3"" msgstr ""2011.3"" msgid ""Sep 22, 2011"" msgstr ""2011年9月22日"" msgid ""2011.3.1"" msgstr ""2011.3.1"" msgid ""Jan 19, 2012"" msgstr ""2012年1月19日"" msgid ""Cactus"" msgstr ""Cactus"" msgid ""2011.2"" msgstr ""2011.2"" msgid ""Apr 15, 2011"" msgstr ""2011年4月15日"" msgid ""Bexar"" msgstr ""Bexar"" msgid ""2011.1"" msgstr ""2011.1"" msgid ""Feb 3, 2011"" msgstr ""2011年2月3日"" msgid ""Austin"" msgstr ""Austin"" msgid ""2010.1"" msgstr ""2010.1"" msgid ""Oct 21, 2010"" msgstr ""2010年10月21日"" msgid """" ""Feature requests typically start their life in Etherpad, a collaborative "" ""editing tool, which is used to take coordinating notes at a design summit "" ""session specific to the feature. This then leads to the creation of a "" ""blueprint on the Launchpad site for the particular project, which is used to "" ""describe the feature more formally. Blueprints are then approved by project "" ""team members, and development can begin."" msgstr """" ""機能追加リクエストは、通常 Etherpad で始まります。Etherpad は共同編集ツール"" ""で、デザインサミットのその機能に関するセッションで議論を整理するのに使われま"" ""す。続けて、プロジェクトの Launchpad サイトに blueprint が作成され、"" ""blueprint を使ってよりきちんとした形で機能が規定されていきます。 この後、"" ""blueprint はプロジェクトメンバーによって承認され、開発が始まります。"" msgid ""OpenStack Operations Guide"" msgstr ""OpenStack 運用ガイド"" msgid ""OpenStack Ops Guide"" msgstr ""OpenStack 運用ガイド"" msgid ""OpenStack Foundation"" msgstr ""OpenStack Foundation""msgid ""OpenStack"" msgstr ""OpenStack""msgid ""Copyright details are filled in by the template."" msgstr ""Copyright details are filled in by the template.""msgid """" ""This book provides information about designing and operating OpenStack "" ""clouds."" msgstr ""本書は OpenStack クラウドの設計および運用に関する情報を提供します。""msgid ""Operations"" msgstr ""運用""msgid """" ""While it is important for an operator to be familiar with the steps involved "" ""in deploying OpenStack, we also strongly encourage you to evaluate "" ""configuration-management tools, such as <glossterm>Puppet</glossterm> or "" ""<glossterm>Chef</glossterm>, which can help automate this deployment process."" ""<indexterm class=\""singular\""><primary>Chef</primary></indexterm><indexterm "" ""class=\""singular\""><primary>Puppet</primary></indexterm>"" msgstr """" ""オペレータはOpenStackのデプロイに必要な手順に精通している事は重要ですが、一方"" ""で、 <glossterm>Puppet</glossterm> や <glossterm>Chef</glossterm>と言った構成"" ""管理ツールの検証評価をする事を強くお勧めします。それらは自動構成をする手助け"" ""となります。<indexterm class=\""singular\""><primary>Chef</primary></"" ""indexterm><indexterm class=\""singular\""><primary>Puppet</primary></indexterm>""msgid """" ""In the remainder of this guide, we assume that you have successfully "" ""deployed an OpenStack cloud and are able to perform basic operations such as "" ""adding images, booting instances, and attaching volumes."" msgstr """" ""このガイドの残りの部分では、OpenStackクラウドの構成が無事に成功し、イメージの"" ""追加、インスタンスの起動、ボリュームの追加が行えるようになったとします。""msgid """" ""As your focus turns to stable operations, we recommend that you do skim the "" ""remainder of this book to get a sense of the content. Some of this content "" ""is useful to read in advance so that you can put best practices into effect "" ""to simplify your life in the long run. Other content is more useful as a "" ""reference that you might turn to when an unexpected event occurs (such as a "" ""power failure), or to troubleshoot a particular problem."" msgstr """" ""焦点を安定運用に切り替えるために、この文書の残りの部分をざっくりと読み、感覚"" ""をつかむ事をお勧めします。長期運用に向けてのベストプラクティスを実施するため"" ""この文書のいくつかのコンテンツはあらかじめ読んでおくと役に立つでしょう。その"" ""他のコンテンツは(電源障害のような)予期しないイベントが発生した場合や特定の問"" ""題のトラブルシューティングをする際に役に立つリファレンスとして役に立つでしょ"" ""う。""msgid ""Network Troubleshooting"" msgstr ""ネットワークのトラブルシューティング""msgid ""Using \""ip a\"" to Check Interface States"" msgstr ""「ip a」を使ってインタフェース状態をチェックする""msgid """" ""If you're encountering any sort of networking difficulty, one good initial "" ""sanity check is to make sure that your interfaces are up. For example:"" msgstr """" ""もしあなたがネットワークの問題に直面した場合、まず最初にするとよいのは、イン"" ""ターフェイスがUPになっているかを確認することです。例えば、""msgid """" ""If you run FlatDHCPManager, one bridge is on the compute node. If you run "" ""VlanManager, one bridge exists for each VLAN."" msgstr """" ""もしFlatDHCPManagerを使っているのであれば、ブリッジはコンピュートノード上に一"" ""つです。VlanManagerであれば、VLANごとにブリッジが存在します。""msgid """" ""To see which bridge the packet will use, run the command: <placeholder-1/>"" msgstr """" ""下記コマンドを実行することで、パケットがどのブリッジを使うか確認できます。"" ""<placeholder-1/>""msgid """" ""After the packet is on this NIC, it transfers to the compute node's default "" ""gateway. The packet is now most likely out of your control at this point. "" ""The diagram depicts an external gateway. However, in the default "" ""configuration with multi-host, the compute host is the gateway."" msgstr """" ""パケットはこのNICに送られた後、コンピュートノードのデフォルトゲートウェイに転"" ""送されます。パケットはこの時点で、おそらくあなたの管理範囲外でしょう。図には"" ""外部ゲートウェイを描いていますが、マルチホストのデフォルト構成では、コン"" ""ピュートホストがゲートウェイです。""msgid ""Finding a Failure in the Path"" msgstr ""経路上の障害を見つける""msgid """" ""If you can't, try pinging the IP address of the compute node where the "" ""instance is hosted. If you can ping this IP, then the problem is somewhere "" ""between the compute node and that compute node's gateway.""""もしそれができないのであれば、インスタンスがホストされているコンピュートノー"" ""ドのIPアドレスへpingを試行してください。もしそのIPにpingできるのであれば、そ"" ""のコンピュートノードと、ゲートウェイ間のどこかに問題があります。""""If you can't ping the IP address of the compute node, the problem is between "" ""the instance and the compute node. This includes the bridge connecting the "" ""compute node's main NIC with the vnet NIC of the instance.""""もしコンピュートノードのIPアドレスにpingできないのであれば、問題はインスタン"" ""スとコンピュートノード間にあります。これはコンピュートノードの物理NICとインス"" ""タンス vnet NIC間のブリッジ接続を含みます。"" msgid ""tcpdump"" msgstr ""tcpdump"" msgid ""For example, run the following command:"" msgstr ""例えば、以下のコマンドを実行します。"" msgid ""Run this on the command line of the following areas:"" msgstr ""このコマンドは以下の場所で実行します。"" msgid ""In this example, these locations have the following IP addresses:"" msgstr ""例では、この環境には以下のIPアドレスが存在します"" msgid ""On the external server:"" msgstr ""外部サーバー上"" msgid ""iptables"" msgstr ""iptables"" msgid ""Run the following command to view the current iptables configuration:"" msgstr ""iptablesの現在の構成を見るには、以下のコマンドを実行します。"" msgid ""fixed_ips"" msgstr ""fixed_ips"" msgid ""instances"" msgstr ""instances"" msgid ""First, find the UUID of the instance in question:"" msgstr ""まず、インスタンスのUUIDを確認します。""""After you establish that the instance booted properly, the task is to figure "" ""out where the failure is.""""インスタンスが正しく起動した後、この手順でどこが問題かを切り分けることができ"" ""ます。"" msgid ""Debugging DNS Issues"" msgstr ""DNS の問題をデバッグする""""If the instance fails to resolve the hostname, you have a DNS problem. For "" ""example:""""もしインスタンスがホスト名の解決に失敗するのであれば、DNSに問題があります。例"" ""えば、"" msgid ""Summary"" msgstr ""概要""msgid ""Tales From the Cryp^H^H^H^H Cloud"" msgstr ""ハリウッド^H^H^H^H^Hクラウドナイトメア""""Herein lies a selection of tales from OpenStack cloud operators. Read, and "" ""learn from their wisdom.""""ここにあるのは、OpenStack クラウドオペレータ達の苦闘の抜粋である。これを読"" ""み、彼らの叡智を学ぶが良い。"" msgid ""Double VLAN"" msgstr ""ダブル VLAN""""I was on-site in Kelowna, British Columbia, Canada setting up a new "" ""OpenStack cloud. The deployment was fully automated: Cobbler deployed the OS "" ""on the bare metal, bootstrapped it, and Puppet took over from there. I had "" ""run the deployment scenario so many times in practice and took for granted "" ""that everything was working.""""私は、新しい OpenStack クラウドのセットアップをするため、カナダのブリティッ"" ""シュコロンビア州ケロウナの現地にいた。デプロイ作業は完全に自動化されていた。"" ""Cobbler が物理マシンに OS をデプロイし、それを起動し、その後は Puppet が引き"" ""継いだ。私は練習で幾度もデプロイシナリオを実行してきたし、もちろん全て正常で"" ""あった。""""On my last day in Kelowna, I was in a conference call from my hotel. In the "" ""background, I was fooling around on the new cloud. I launched an instance "" ""and logged in. Everything looked fine. Out of boredom, I ran <placeholder-1/"" ""> and all of the sudden the instance locked up.""""ケロウナの最終日、私はホテルから電話会議に参加していた。その裏で、私は新しい"" ""クラウドをいじっていた。私はインスタンスを１つ起動し、ログインした。全ては正"" ""常に思えた。退屈しのぎに、私は <placeholder-1/> を実行したところ、突然そのイ"" ""ンスタンスがロックアップしてしまった。"" msgid """" ""Thinking it was just a one-off issue, I terminated the instance and launched "" ""a new one. By then, the conference call ended and I was off to the data "" ""center."" msgstr """" ""これは単なる１回限りの問題と思ったので、私はインスタンスを削除して、新しいイ"" ""ンスタンスを起動した。その後電話会議は終了し、私はデータセンターを離れた。"" msgid """" ""At the data center, I was finishing up some tasks and remembered the lock-"" ""up. I logged into the new instance and ran <placeholder-1/> again. It "" ""worked. Phew. I decided to run it one more time. It locked up. WTF."" msgstr """" ""データセンターで、私はいくつかの仕事を済ませると、ロックアップのことを思い出"" ""した。私は新しいインスタンスにログインし、再度 <placeholder-1/> を実行した。"" ""コマンドは機能した。ふぅ。私はもう一度試してみることにした。今度はロックアッ"" ""プした。何だこれは？"" msgid """" ""After reproducing the problem several times, I came to the unfortunate "" ""conclusion that this cloud did indeed have a problem. Even worse, my time "" ""was up in Kelowna and I had to return back to Calgary."" msgstr """" ""何度か問題が再現した後、私はこのクラウドが実は問題を抱えているという不幸な結"" ""論に至った。更に悪いことに、私がケロウナから出発する時間になっており、カルガ"" ""リーに戻らなければならなかった。"" msgid """" ""We reached out for help. A networking engineer suggested it was an MTU "" ""issue. Great! MTU! Something to go on! What's MTU and why would it cause a "" ""problem?"" msgstr """" ""我々は助けを求めた。ネットワークエンジニアは、これは MTU の問題ではないかとい"" ""うのだ。素晴らしい！MTU! 事態は動き始めた! MTU とは何で、何故それが問題になる"" ""のだろうか？"" msgid """" ""Not all packets have a size of 1500. Running the <placeholder-1/> command "" ""over SSH might only create a single packets less than 1500 bytes. However, "" ""running a command with heavy output, such as <placeholder-2/> requires "" ""several packets of 1500 bytes."" msgstr """" ""すべてのパケットサイズが 1500 に収まるわけではない。SSH 経由の "" ""<placeholder-1/> コマンド実行は 1500 バイト未満のサイズのパケット１つで収まる"" ""かもしれない。しかし、 <placeholder-2/> のように多大な出力を行うコマンドを実"" ""行する場合、1500 バイトのパケットが複数必要とある。"" msgid """" ""OK, so where is the MTU issue coming from? Why haven't we seen this in any "" ""other deployment? What's new in this situation? Well, new data center, new "" ""uplink, new switches, new model of switches, new servers, first time using "" ""this model of servers… so, basically everything was new. Wonderful. We toyed "" ""around with raising the MTU at various areas: the switches, the NICs on the "" ""compute nodes, the virtual NICs in the instances, we even had the data "" ""center raise the MTU for our uplink interface. Some changes worked, some "" ""didn't. This line of troubleshooting didn't feel right, though. We shouldn't "" ""have to be changing the MTU in these areas."" msgstr """" ""OK。では MTU の問題はどこから来るのか？なぜ我々は他のデプロイでこの問題に遭遇"" ""しなかったのか？この状況は何が新しいのか？えっと、新しいデータセンター、新し"" ""い上位リンク、新しいスイッチ、スイッチの新機種、新しいサーバー、サーバーの新"" ""機種…つまり、基本的に全てが新しいものだった。素晴らしい。我々は様々な領域で "" ""MTU の増加を試してみた。スイッチ、コンピュータのNIC、インスタンスの仮想NIC、"" ""データセンターの上位リンク用のインターフェースのMTUまでいじってみた。いくつか"" ""の変更ではうまくいったが、他はダメだった。やはり、この線の障害対策はうまく"" ""いってないようだった。我々はこれらの領域のMTUは変更すべきではないようだ。"" msgid """" ""As a last resort, our network admin (Alvaro) and myself sat down with four "" ""terminal windows, a pencil, and a piece of paper. In one window, we ran "" ""ping. In the second window, we ran <placeholder-1/> on the cloud controller. "" ""In the third, <placeholder-2/> on the compute node. And the forth had "" ""<placeholder-3/> on the instance. For background, this cloud was a multi-"" ""node, non-multi-host setup."" msgstr """" ""結局、我々のネットワーク管理者（Alvao）と私自身は４つのターミナルウィンドウ、"" ""１本の鉛筆と紙切れを持って座った。１つのウインドウで我々は ping を実行した。"" ""２つ目のウインドウではクラウドコントローラー上の <placeholder-1/>、３つ目では"" ""コンピュートノード上の <placeholder-2/>、４つ目ではインスタンス上の "" ""<placeholder-3/> を実行した。前提として、このクラウドはマルチノード、非マルチ"" ""ホスト構成である。"" msgid """" ""One cloud controller acted as a gateway to all compute nodes. VlanManager "" ""was used for the network config. This means that the cloud controller and "" ""all compute nodes had a different VLAN for each OpenStack project. We used "" ""the -s option of <placeholder-1/> to change the packet size. We watched as "" ""sometimes packets would fully return, sometimes they'd only make it out and "" ""never back in, and sometimes the packets would stop at a random point. We "" ""changed <placeholder-2/> to start displaying the hex dump of the packet. We "" ""pinged between every combination of outside, controller, compute, and "" ""instance."" msgstr """" ""１つのクラウドコントローラーが全コンピュートノードのゲートウェイの役割を果た"" ""していた。ネットワーク設定には VlanManager が使われていた。これは、クラウドコ"" ""ントローラーと全コンピュートノードで、各 OpenStack プロジェクトが異なる VLAN "" ""を持つことを意味する。パケットサイズ変更のため、<placeholder-1/> の -s オプ"" ""ションを使用していた。パケットが全て戻ってくる時もあれば、パケットが出ていっ"" ""たきり全く戻って来ない時もあれば、パケットはランダムな場所で止まってしまう時"" ""もある、という状況だった。<placeholder-2/> を変更し、パケットの16進ダンプを表"" ""示するようにした。外部、コントローラー、コンピュート、インスタンスのあらゆる"" ""組み合わせの間で ping を実行した。"" msgid """" ""Finally, Alvaro noticed something. When a packet from the outside hits the "" ""cloud controller, it should not be configured with a VLAN. We verified this "" ""as true. When the packet went from the cloud controller to the compute node, "" ""it should only have a VLAN if it was destined for an instance. This was "" ""still true. When the ping reply was sent from the instance, it should be in "" ""a VLAN. True. When it came back to the cloud controller and on its way out "" ""to the public internet, it should no longer have a VLAN. False. Uh oh. It "" ""looked as though the VLAN part of the packet was not being removed."" msgstr """" ""遂に、Alvaro が何かを掴んだ。外部からのパケットがクラウドコントローラーを叩い"" ""た際、パケットは VLAN で設定されるべきではない。我々はこれが正しいことを検証"" ""した。パケットがクラウドコントローラーからコンピュートノードに行く際、パケッ"" ""トはインスタンス宛の場合にのみ VLAN を持つべきである。これもまた正しかった。"" ""ping のレスポンスがインスタンスから送られる際、パケットは VLAN 中にいるべきで"" ""ある。ＯＫ。クラウドコントローラーからパブリックインターネットにパケットが戻"" ""る際、パケットには VLAN を持つべきではない。ＮＧ。うぉっ。まるで パケットの "" ""VLAN 部分が削除されていないように見える。"" msgid ""That made no sense."" msgstr ""これでは意味が無かった。"" msgid """" ""While bouncing this idea around in our heads, I was randomly typing commands "" ""on the compute node: <placeholder-1/>"" msgstr """" ""このアイデアが我々の頭を駆け巡る間、私はコンピュートノード上でコマンドをラン"" ""ダムに叩いていた。 <placeholder-1/>"" msgid ""\""Hey Alvaro, can you run a VLAN on top of a VLAN?\"""" msgstr ""「Alvaro、VLAN 上に VLAN って作れるのかい？」"" msgid ""Then it all made sense… <placeholder-1/>"" msgstr ""やっと事の全容が判明した… <placeholder-1/>"" msgid """" ""In <filename>nova.conf</filename>, <code>vlan_interface</code> specifies "" ""what interface OpenStack should attach all VLANs to. The correct setting "" ""should have been: <placeholder-1/>."" msgstr """" ""<filename>nova.conf</filename> 中で、<code>vlan_interface</code> は "" ""OpenStack が全ての VLAN をアタッチすべきインターフェースがどれかを指定する。"" ""正しい設定はこうだった: <placeholder-1/>"" msgid ""As this would be the server's bonded NIC."" msgstr ""これはサーバーの冗長化された（bonded）NIC であるべきだからだ。"" msgid """" ""vlan20 is the VLAN that the data center gave us for outgoing public internet "" ""access. It's a correct VLAN and is also attached to bond0."" msgstr """" ""vlan20 はデータセンターが外向けのパブリックなインターネットアクセス用に我々に"" ""付与した VLAN である。これは正しい VLAN で bond0 にアタッチされている。"" msgid """" ""By mistake, I configured OpenStack to attach all tenant VLANs to vlan20 "" ""instead of bond0 thereby stacking one VLAN on top of another which then "" ""added an extra 4 bytes to each packet which cause a packet of 1504 bytes to "" ""be sent out which would cause problems when it arrived at an interface that "" ""only accepted 1500!"" msgstr """" ""ミスにより、私は全てのテナント VLAN を bond0 の代わりに vlan20 にアタッチする"" ""よう OpenStack を設定した。それによって１つの VLAN が別の VLAN の上に積み重な"" ""り、各パケットに余分に４バイトが追加され、送信されるパケットサイズが 1504 バ"" ""イトになる原因となった。これがパケットサイズ 1500 のみ許容するインターフェー"" ""スに到達した際、問題の原因となったのだった！"" msgid ""As soon as this setting was fixed, everything worked."" msgstr ""全力でこの問題を修正した結果、全てが正常に動作するようになった。"" msgid ""\""The Issue\"""" msgstr ""「あの問題」"" msgid """" ""At the end of August 2012, a post-secondary school in Alberta, Canada "" ""migrated its infrastructure to an OpenStack cloud. As luck would have it, "" ""within the first day or two of it running, one of their servers just "" ""disappeared from the network. Blip. Gone."" msgstr """" ""2012年8月の終わり、カナダ アルバータ州のある大学はそのインフラを OpenStack ク"" ""ラウドに移行した。幸か不幸か、サービスインから1～2日間に、彼らのサーバーの1台"" ""がネットワークから消失した。ビッ。いなくなった。"" msgid """" ""After restarting the instance, everything was back up and running. We "" ""reviewed the logs and saw that at some point, network communication stopped "" ""and then everything went idle. We chalked this up to a random occurrence."" msgstr """" ""インスタンスの再起動後、全ては元通りに動くようになった。我々はログを見直し、"" ""問題の箇所（ネットワーク通信が止まり、全ては待機状態になった）を見た。我々は"" ""ランダムな事象の原因はこのインスタンスだと判断した。"" msgid ""A few nights later, it happened again."" msgstr ""数日後、それは再び起こった。"" msgid """" ""We reviewed both sets of logs. The one thing that stood out the most was "" ""DHCP. At the time, OpenStack, by default, set DHCP leases for one minute "" ""(it's now two minutes). This means that every instance contacts the cloud "" ""controller (DHCP server) to renew its fixed IP. For some reason, this "" ""instance could not renew its IP. We correlated the instance's logs with the "" ""logs on the cloud controller and put together a conversation:"" msgstr """" ""我々はログのセットを両方見直した。頻発したログの１つは DHCP だった。当時、"" ""OpenStack はデフォルトでは DHCP リース期間を 1分に設定していた (現在は 2分)。"" ""これは、各インスタンスが固定 IP アドレスを更新するためにクラウドコントロー"" ""ラー（DHCP サーバー）に接続することを意味する。幾つかの理由で、このインスタン"" ""スはその IP アドレスを更新できなかった。インスタンスのログとクラウドコント"" ""ローラー上のログを突き合わせ、並べてやりとりにしてみた。"" msgid ""Instance tries to renew IP."" msgstr ""インスタンスはIPアドレスを更新しようとする。"" msgid ""Cloud controller receives the renewal request and sends a response."" msgstr ""クラウドコントローラーは更新リクエストを受信し、レスポンスを返す。"" msgid ""Instance \""ignores\"" the response and re-sends the renewal request."" msgstr ""インスタンスはそのレスポンスを「無視」して、更新リクエストを再送する。"" msgid ""Cloud controller receives the second request and sends a new response."" msgstr """" ""クラウドコントローラーは２度めのリクエストを受信し、新しいレスポンスを返す。"" msgid """" ""Instance begins sending a renewal request to <code>255.255.255.255</code> "" ""since it hasn't heard back from the cloud controller."" msgstr """" ""インスタンスはクラウドコントローラーからのレスポンスを受信しなかったため、更"" ""新リクエストを<code>255.255.255.255</code>に送信し始める。"" msgid """" ""The cloud controller receives the <code>255.255.255.255</code> request and "" ""sends a third response."" msgstr """" ""クラウドコントローラーは <code>255.255.255.255</code> 宛のリクエストを受信"" ""し、３番めのレスポンスを返す。"" msgid ""The instance finally gives up."" msgstr ""最終的に、インスタンスはIPアドレス取得を諦める。"" msgid """" ""With this information in hand, we were sure that the problem had to do with "" ""DHCP. We thought that for some reason, the instance wasn't getting a new IP "" ""address and with no IP, it shut itself off from the network."" msgstr """" ""この情報により、我々は問題が DHCP 実行に起因するものと確信した。何らかの理由"" ""でインスタンスが新しいIPアドレスを取得できず、その結果IPアドレスがなくなり、"" ""インスタンスは自分自身をネットワークから切り離した、と考えた。"" msgid """" ""An initial idea was to just increase the lease time. If the instance only "" ""renewed once every week, the chances of this problem happening would be "" ""tremendously smaller than every minute. This didn't solve the problem, "" ""though. It was just covering the problem up."" msgstr """" ""最初のアイデアは、単にリース時間を増やすことだった。もしインスタンスが毎週１"" ""回だけIPアドレスを更新するのであれば、毎分更新する場合よりこの問題が起こる可"" ""能性は極端に低くなるだろう。これはこの問題を解決しないが、問題を単に取り繕う"" ""ことはできる。"" msgid """" ""We decided to have <placeholder-1/> run on this instance and see if we could "" ""catch it in action again. Sure enough, we did."" msgstr """" ""我々は、このインスタンス上で <placeholder-1/> を実行して、操作で再びこの現象"" ""に遭遇するか見てみることにした。実際、我々はやってみた。"" msgid """" ""The <placeholder-1/> looked very, very weird. In short, it looked as though "" ""network communication stopped before the instance tried to renew its IP. "" ""Since there is so much DHCP chatter from a one minute lease, it's very hard "" ""to confirm it, but even with only milliseconds difference between packets, "" ""if one packet arrives first, it arrived first, and if that packet reported "" ""network issues, then it had to have happened before DHCP."" msgstr """" ""<placeholder-1/> の結果は非常に奇妙だった。一言で言えば、インスタンスが IP ア"" ""ドレスを更新しようとする前に、まるでネットワーク通信が停止しているように見え"" ""た。１分間のリース期間で大量の DHCP ネゴシエーションがあるため、確認作業は困"" ""難を極めた。しかし、パケット間のたった数ミリ秒の違いであれ、あるパケットが最"" ""初に到着する際、そのパケットが最初に到着し、そのパケットがネットワーク障害を"" ""報告した場合、DHCP より前にネットワーク障害が発生していることになる。"" msgid """" ""Additionally, this instance in question was responsible for a very, very "" ""large backup job each night. While \""The Issue\"" (as we were now calling it) "" ""didn't happen exactly when the backup happened, it was close enough (a few "" ""hours) that we couldn't ignore it."" msgstr """" ""加えて、問題のインスタンスは毎晩非常に長いバックアップジョブを担っていた。"" ""「あの問題」（今では我々はこの障害をこう呼んでいる）はバックアップが行われて"" ""いる最中には起こらなかったが、（数時間たっていて）「あの問題」が起こるまであ"" ""と少しのところだった。"" msgid """" ""Further days go by and we catch The Issue in action more and more. We find "" ""that dhclient is not running after The Issue happens. Now we're back to "" ""thinking it's a DHCP issue. Running <filename>/etc/init.d/networking</"" ""filename> restart brings everything back up and running."" msgstr """" ""それから何日か過ぎ、我々は「あの問題」に度々遭遇した。我々は「あの問題」の発"" ""生後、dhclient が実行されていないことを発見した。今、我々は、それが DHCP の問"" ""題であるという考えに立ち戻った。<filename>/etc/init.d/networking</filename> "" ""restart を実行すると、全ては元通りに実行されるようになった。"" msgid """" ""Ever have one of those days where all of the sudden you get the Google "" ""results you were looking for? Well, that's what happened here. I was looking "" ""for information on dhclient and why it dies when it can't renew its lease "" ""and all of the sudden I found a bunch of OpenStack and dnsmasq discussions "" ""that were identical to the problem we were seeing!"" msgstr """" ""探し続けてきた Google の検索結果が突然得られたという事態をお分かりだろうか？"" ""えっと、それがここで起こったことだ。私は dhclient の情報と、何故 dhclient が"" ""そのリースを更新できない場合に死ぬのかを探していて、我々が遭遇したのと同じ問"" ""題についての OpenStack と dnsmasq の議論の束を突然発見した。"" msgid """" ""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""operators/18197\"">Problem with Heavy Network IO and Dnsmasq</link> (http://"" ""www.gossamer-threads.com/lists/openstack/operators/18197)"" msgstr """" ""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""operators/18197\"">高負荷ネットワークIOとdnsmasqの問題</link> (http://www."" ""gossamer-threads.com/lists/openstack/operators/18197)"" msgid """" ""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""dev/14696\"">instances losing IP address while running, due to No DHCPOFFER</"" ""link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)"" msgstr """" ""<link href=\""http://www.gossamer-threads.com/lists/openstack/"" ""dev/14696\"">DHCPOFFERが送信されない事による、起動中のインスタンスのIPアドレス"" ""の消失</link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)"" msgid ""Seriously, Google."" msgstr ""マジ？Google。"" msgid """" ""It was funny to read the report. It was full of people who had some strange "" ""network problem but didn't quite explain it in the same way."" msgstr """" ""レポートを読むのは楽しかった。同じ奇妙なネットワーク問題にあった人々であふれ"" ""ていたが、全く同じ説明はなかった。"" msgid ""So it was a qemu/kvm bug."" msgstr ""つまり、これは qemu/kvm のバグである。"" msgid """" ""At the same time of finding the bug report, a co-worker was able to "" ""successfully reproduce The Issue! How? He used <placeholder-1/> to spew a "" ""ton of bandwidth at an instance. Within 30 minutes, the instance just "" ""disappeared from the network."" msgstr """" ""バグ報告を発見すると同時に、同僚が「あの問題」を再現することに成功した！どう"" ""やって？彼は <placeholder-1/> を使用して、インスタンス上で膨大なネットワーク"" ""負荷をかけた。30分後、インスタンスはネットワークから姿を消した。"" msgid """" ""Armed with a patched qemu and a way to reproduce, we set out to see if we've "" ""finally solved The Issue. After 48 hours straight of hammering the instance "" ""with bandwidth, we were confident. The rest is history. You can search the "" ""bug report for \""joe\"" to find my comments and actual tests."" msgstr """" ""パッチを当てた qemu と再現方法を携えて、我々は「あの問題」を最終的に解決した"" ""かを確認する作業に着手した。インスタンスにネットワーク負荷をかけてから丸48時"" ""間後、我々は確信していた。その後のことは知っての通りだ。あなたは、joe へのバ"" ""グ報告を検索し、私のコメントと実際のテストを見つけることができる。"" msgid ""Disappearing Images"" msgstr ""イメージの消失"" msgid """" ""At the end of 2012, Cybera (a nonprofit with a mandate to oversee the "" ""development of cyberinfrastructure in Alberta, Canada) deployed an updated "" ""OpenStack cloud for their <link title=\""DAIR project\"" href=\""http://www."" ""canarie.ca/en/dair-program/about\"">DAIR project</link> (http://www.canarie."" ""ca/en/dair-program/about). A few days into production, a compute node locks "" ""up. Upon rebooting the node, I checked to see what instances were hosted on "" ""that node so I could boot them on behalf of the customer. Luckily, only one "" ""instance."" msgstr """" ""2012年の終わり、Cybera （カナダ アルバータ州にある、サイバーインフラのデプロ"" ""イを監督する権限を持つ非営利団体）が、彼らの <link title=\""DAIR project\"" "" ""href=\""http://www.canarie.ca/en/dair-program/about\"">DAIR プロジェクト</"" ""link> (http://www.canarie.ca/en/dair-program/about) 用に新しい OpenStack クラ"" ""ウドをデプロイした。サービスインから数日後、あるコンピュートノードがロック"" ""アップした。問題のノードの再起動にあたり、私は顧客の権限でインスタンスを起動"" ""するため、そのノード上で何のインスタンスがホスティングされていたかを確認し"" ""た。幸運にも、インスタンスは１つだけだった。"" msgid """" ""The <placeholder-1/> command wasn't working, so I used <placeholder-2/>, but "" ""it immediately came back with an error saying it was unable to find the "" ""backing disk. In this case, the backing disk is the Glance image that is "" ""copied to <filename>/var/lib/nova/instances/_base</filename> when the image "" ""is used for the first time. Why couldn't it find it? I checked the directory "" ""and sure enough it was gone."" msgstr """" ""<placeholder-1/> コマンドは機能しなかったので、<placeholder-2/> を使用した"" ""が、すぐに仮想ディスクが見つからないとのエラーが返ってきた。この場合、仮想"" ""ディスクは Glance イメージで、イメージが最初に使用する際に <filename>/var/"" ""lib/nova/instances/_base</filename> にコピーされていた。何故イメージが見つか"" ""らないのか？私はそのディレクトリをチェックし、イメージがないことを知った。"" msgid """" ""I reviewed the <code>nova</code> database and saw the instance's entry in "" ""the <code>nova.instances</code> table. The image that the instance was using "" ""matched what virsh was reporting, so no inconsistency there."" msgstr """" ""私は <code>nova</code> データベースを見直し、<code>nova.instances</code> テー"" ""ブル中の当該インスタンスのレコードを見た。インスタンスが使用しているイメージ"" ""は virsh が報告したものと一致した。よって、ここでは矛盾は発見されなかった。"" msgid """" ""It turns out the reason that this compute node locked up was a hardware "" ""issue. We removed it from the DAIR cloud and called Dell to have it "" ""serviced. Dell arrived and began working. Somehow or another (or a fat "" ""finger), a different compute node was bumped and rebooted. Great."" msgstr """" ""コンピュートノードがロックアップした原因はハードウェアの問題だったことが判明"" ""した。我々はそのハードウェアを DAIR クラウドから取り外し、修理するよう Dell "" ""に依頼した。Dell が到着して作業を開始した。何とかかんとか（あるいはタイプミ"" ""ス）で、異なるコンピュートノードを落としてしまい、再起動した。素晴らしい。"" msgid """" ""When this node fully booted, I ran through the same scenario of seeing what "" ""instances were running so I could turn them back on. There were a total of "" ""four. Three booted and one gave an error. It was the same error as before: "" ""unable to find the backing disk. Seriously, what?"" msgstr """" ""そのノードが完全に起動した際、インスタンスが起動した時に何が起こるのかを見る"" ""ため、私は同じシナリオを実行して、インスタンスを復旧した。インスタンスは全部"" ""で４つあった。３つは起動し、１つはエラーになった。このエラーは以前のエラーと"" ""同じだった。「unable to find the backing disk.」マジ、何で？"" msgid """" ""Again, it turns out that the image was a snapshot. The three other instances "" ""that successfully started were standard cloud images. Was it a problem with "" ""snapshots? That didn't make sense."" msgstr """" ""再度、イメージがスナップショットであることが判明した。無事に起動した他の３イ"" ""ンスタンスは標準のクラウドイメージであった。これはスナップショットの問題か？"" ""それは意味が無かった。"" msgid """" ""A note about DAIR's architecture: <filename>/var/lib/nova/instances</"" ""filename> is a shared NFS mount. This means that all compute nodes have "" ""access to it, which includes the <code>_base</code> directory. Another "" ""centralized area is <filename>/var/log/rsyslog</filename> on the cloud "" ""controller. This directory collects all OpenStack logs from all compute "" ""nodes. I wondered if there were any entries for the file that <placeholder-1/"" ""> is reporting: <placeholder-2/>"" msgstr """" ""DAIR のアーキテクチャは <filename>/var/lib/nova/instances</filename> が共有 "" ""NFS マウントであることに注意したい。これは、全てのコンピュートノードがその"" ""ディレクトリにアクセスし、その中に <code>_base</code> ディレクトリが含まれる"" ""ことを意味していた。その他の集約化エリアはクラウドコントローラーの "" ""<filename>/var/log/rsyslog</filename> だ。このディレクトリは全コンピュート"" ""ノードの全ての OpenStack ログが収集されていた。私は、<placeholder-1/> が報告"" ""したファイルに関するエントリがあるのだろうかと思った。 <placeholder-2/>"" msgid ""Ah-hah! So OpenStack was deleting it. But why?"" msgstr ""あっはっは！じゃぁ、OpenStack が削除したのか。でも何故？"" msgid ""Actions which delete things should not be enabled by default."" msgstr ""何かを削除する操作はデフォルトで有効化されるべきではない。"" msgid ""Disk space is cheap these days. Data recovery is not."" msgstr ""今日、ディスクスペースは安価である。データの復元はそうではない。"" msgid """" ""Secondly, DAIR's shared <filename>/var/lib/nova/instances</filename> "" ""directory contributed to the problem. Since all compute nodes have access to "" ""this directory, all compute nodes periodically review the _base directory. "" ""If there is only one instance using an image, and the node that the instance "" ""is on is down for a few minutes, it won't be able to mark the image as still "" ""in use. Therefore, the image seems like it's not in use and is deleted. When "" ""the compute node comes back online, the instance hosted on that node is "" ""unable to start."" msgstr """" ""次に、DAIR の共有された <filename>/var/lib/nova/instances</filename> が問題を"" ""助長した。全コンピュートノードがこのディレクトリにアクセスするため、全てのコ"" ""ンピュートノードは定期的に _base ディレクトリを見直していた。あるイメージを使"" ""用しているインスタンスが１つだけあり、そのインスタンスが存在するノードが数分"" ""間ダウンした場合、そのイメージが使用中であるという印を付けられなくなる。それ"" ""ゆえ、イメージは使用中に見えず、削除されてしまったのだ。そのコンピュートノー"" ""ドが復帰した際、そのノード上でホスティングされていたインスタンスは起動できな"" ""い。"" msgid ""The Valentine's Day Compute Node Massacre"" msgstr ""バレンタインデーのコンピュートノード大虐殺"" msgid """" ""Although the title of this story is much more dramatic than the actual "" ""event, I don't think, or hope, that I'll have the opportunity to use "" ""\""Valentine's Day Massacre\"" again in a title."" msgstr """" ""この物語のタイトルは実際の事件よりかなりドラマティックだが、私はタイトル中に"" ""「バレンタインデーの大虐殺」を使用する機会が再びあるとは思わない（し望まな"" ""い）。"" msgid """" ""I logged into the cloud controller and was able to both <placeholder-1/> and "" ""SSH into the problematic compute node which seemed very odd. Usually if I "" ""receive this type of alert, the compute node has totally locked up and would "" ""be inaccessible."" msgstr """" ""実に奇妙なことだが、私はクラウドコントローラーにログインし、問題のコンピュー"" ""トノードに <placeholder-1/> と SSH の両方を実行できた。通常、この種の警告を受"" ""け取ると、コンピュートノードは完全にロックしていてアクセス不可になる。"" msgid ""After a few minutes of troubleshooting, I saw the following details:"" msgstr ""数分間のトラブル調査の後、以下の詳細が判明した。"" msgid ""A user recently tried launching a CentOS instance on that node"" msgstr """" ""最近、あるユーザがそのノード上で CentOS のインスタンスを起動しようとした。"" msgid ""This user was the only user on the node (new node)"" msgstr ""このユーザはそのノード（新しいノード）上の唯一のユーザだった。"" msgid ""The load shot up to 8 right before I received the alert"" msgstr ""私が警告を受け取る直前、負荷率は８に急増した。"" msgid ""The bonded 10gb network device (bond0) was in a DOWN state"" msgstr ""冗長化された 10Gb ネットワークデバイス(bond0）は DOWN 状態だった。"" msgid ""The 1gb NIC was still alive and active"" msgstr ""1Gb NICはまだ生きていて、有効だった。"" msgid """" ""I looked at the status of both NICs in the bonded pair and saw that neither "" ""was able to communicate with the switch port. Seeing as how each NIC in the "" ""bond is connected to a separate switch, I thought that the chance of a "" ""switch port dying on each switch at the same time was quite improbable. I "" ""concluded that the 10gb dual port NIC had died and needed replaced. I "" ""created a ticket for the hardware support department at the data center "" ""where the node was hosted. I felt lucky that this was a new node and no one "" ""else was hosted on it yet."" msgstr """" ""私は bonding ペアの両方の NIC の状態を確認し、両方ともスイッチポートへの通信"" ""ができないことを知った。bond 中の各 NIC が異なるスイッチに接続されていること"" ""を知り、私は、各スイッチのスイッチポートが同時に死ぬ可能性はまずないと思っ"" ""た。私は 10Gb デュアルポート NIC が死んで、交換が必要だと結論づけた。私は、そ"" ""のノードがホスティングされているデータセンターのハードウェアサポート部門に宛"" ""てたチケットを作成した。私は、それが新しいノードで、他のインスタンスがまだそ"" ""のノード上でホスティングされていないことを幸運に思った。"" msgid """" ""An hour later I received the same alert, but for another compute node. Crap. "" ""OK, now there's definitely a problem going on. Just like the original node, "" ""I was able to log in by SSH. The bond0 NIC was DOWN but the 1gb NIC was "" ""active."" msgstr """" ""１時間後、私は同じ警告を受信したが、別のコンピュートノードだった。拍手。OK、"" ""問題は間違いなく現在進行中だ。元のノードと全く同様に、私は SSH でログインする"" ""ことが出来た。bond0 NIC は DOWN だったが、1Gb NIC は有効だった。"" msgid """" ""And the best part: the same user had just tried creating a CentOS instance. "" ""What?"" msgstr """" ""そして、最も重要なこと。同じユーザが CentOS インスタンスを作成しようとしたば"" ""かりだった。何だと？"" msgid """" ""I was totally confused at this point, so I texted our network admin to see "" ""if he was available to help. He logged in to both switches and immediately "" ""saw the problem: the switches detected spanning tree packets coming from the "" ""two compute nodes and immediately shut the ports down to prevent spanning "" ""tree loops: <placeholder-1/>"" msgstr """" ""私はこの時点で完全に混乱した。よって、私はネットワーク管理者に対して、私を助"" ""けられるか聞いてみるためメールした。彼は両方のスイッチにログインし、すぐに問"" ""題を発見した。そのスイッチは２つのコンピュートノードから来たスパニングツリー"" ""パケットを検出し、スパニングツリーループを回避するため、即時にそれらのポート"" ""をダウンさせたのだ。<placeholder-1/>"" msgid """" ""He re-enabled the switch ports and the two compute nodes immediately came "" ""back to life."" msgstr """" ""彼はスイッチポートを再度有効にしたところ、２つのコンピュートノードは即時に復"" ""活した。"" msgid """" ""Unfortunately, this story has an open ending... we're still looking into why "" ""the CentOS image was sending out spanning tree packets. Further, we're "" ""researching a proper way on how to mitigate this from happening. It's a "" ""bigger issue than one might think. While it's extremely important for "" ""switches to prevent spanning tree loops, it's very problematic to have an "" ""entire compute node be cut from the network when this happens. If a compute "" ""node is hosting 100 instances and one of them sends a spanning tree packet, "" ""that instance has effectively DDOS'd the other 99 instances."" msgstr """" ""不幸にも、この話にはエンディングがない…我々は、なぜ CentOS イメージがスパニン"" ""グツリーパケットを送信し始める原因をいまだ探している。更に、我々は障害時にス"" ""パニングツリーを軽減する正しい方法を調査している。これは誰かが思うより大きな"" ""問題だ。スパニングツリーループを防ぐことはスイッチにとって非常に重要である"" ""が、スパニングツリーが起こった際に、コンピュートノード全体がネットワークから"" ""切り離されることも大きな問題である。コンピュートノードが 100 インスタンスをホ"" ""スティングしていて、そのうち１つがスパニングツリーパケットを送信した場合、そ"" ""のインスタンスは事実上他の 99 インスタンスを DDoS（サービス不能攻撃）したこと"" ""になる。"" msgid ""Down the Rabbit Hole"" msgstr ""ウサギの穴に落ちて"" msgid """" ""At that time, our control services were hosted by another team and we didn't "" ""have much debugging information to determine what was going on with the "" ""master, and couldn't reboot it. That team noted that it failed without "" ""alert, but managed to reboot it. After an hour, the cluster had returned to "" ""its normal state and we went home for the day."" msgstr """" ""この時、我々のコントロールサービスは別のチームによりホスティングされており、"" ""我々には現用系サーバー上で何が起こっているのかを調査するための大したデバッグ"" ""情報がなく、再起動もできなかった。このチームは警報なしで障害が起こったと連絡"" ""してきたが、そのサーバーの再起動を管理していた。１時間後、クラスタは通常状態"" ""に復帰し、我々はその日は帰宅した。"" msgid """" ""Continuing the diagnosis the next morning was kick started by another "" ""identical failure. We quickly got the message queue running again, and tried "" ""to work out why Rabbit was suffering from so much network traffic. Enabling "" ""debug logging on <systemitem class=\""service\"">nova-api</systemitem> quickly "" ""brought understanding. A <placeholder-1/> was scrolling by faster than we'd "" ""ever seen before. CTRL+C on that and we could plainly see the contents of a "" ""system log spewing failures over and over again - a system log from one of "" ""our users' instances."" msgstr """" ""翌朝の継続調査は別の同様の障害でいきなり始まった。我々は急いで RabbitMQ サー"" ""バーを再起動し、何故 RabbitMQ がそのような過剰なネットワーク負荷に直面してい"" ""るのかを調べようとした。<systemitem class=\""service\"">nova-api</systemitem> "" ""のデバッグログを出力することにより、理由はすぐに判明した。<placeholder-1/> は"" ""我々が見たこともない速さでスクロールしていた。CTRL+C でコマンドを止め、障害を"" ""吐き出していたシステムログの内容をはっきり目にすることが出来た。－我々のユー"" ""ザの１人のインスタンスからのシステムログだった。"" msgid """" ""After finding the instance ID we headed over to <filename>/var/lib/nova/"" ""instances</filename> to find the <filename>console.log</filename>: "" ""<placeholder-1/>"" msgstr """" ""インスタンスIDの発見後、<filename>console.log</filename> を探すため "" ""<filename>/var/lib/nova/instances</filename> にアクセスした。<placeholder-1/>"" msgid """" ""Sure enough, the user had been periodically refreshing the console log page "" ""on the dashboard and the 5G file was traversing the rabbit cluster to get to "" ""the dashboard."" msgstr """" ""思った通り、ユーザはダッシュボード上のコンソールログページを定期的に更新して"" ""おり、ダッシュボードに向けて5GB のファイルが RabbitMQ クラスタを通過してい"" ""た。"" msgid """" ""We called them and asked them to stop for a while, and they were happy to "" ""abandon the horribly broken VM. After that, we started monitoring the size "" ""of console logs."" msgstr """" ""我々はユーザを呼び、しばらくダッシュボードの更新を止めるよう申し入れた。する"" ""と、恐ろしい VM の破壊は止み、彼らは大いに喜んだ。その後、我々はコンソールロ"" ""グのサイズを監視するようになった。"" msgid """" ""To this day, <link href=\""https://bugs.launchpad.net/nova/+bug/832507\"">the "" ""issue</link> (https://bugs.launchpad.net/nova/+bug/832507) doesn't have a "" ""permanent resolution, but we look forward to the discussion at the next "" ""summit."" msgstr """" ""今日に至るまで、<link href=\""https://bugs.launchpad.net/nova/+bug/832507\"">こ"" ""の問題</link> (https://bugs.launchpad.net/nova/+bug/832507) には完全な解決策"" ""がないが、我々は次回のサミットの議論に期待している。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"" msgid ""Example Architecture—Legacy Networking (nova)"" msgstr ""アーキテクチャ例: レガシーネットワーク (nova)"" msgid """" ""This particular example architecture has been upgraded from Grizzly to "" ""Havana and tested in production environments where many public IP addresses "" ""are available for assignment to multiple instances. You can find a second "" ""example architecture that uses OpenStack Networking (neutron) after this "" ""section. Each example offers high availability, meaning that if a particular "" ""node goes down, another node with the same configuration can take over the "" ""tasks so that service continues to be available.<indexterm class=\""singular"" ""\""><primary>Havana</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Grizzly</primary></indexterm>"" msgstr """" ""この特定のアーキテクチャ例は、Grizzly から Havana にアップグレードされてお"" ""り、複数のインスタンスに割り当てるためのパブリック IP アドレスが多数利用可能"" ""な本番環境でテスト済みです。このセクションの次には、OpenStack Networking "" ""(neutron) を使用する第 2 のアーキテクチャ例を紹介しています。各例では高可用性"" ""を提供しています。これは、特定のノードが停止した場合には同じ設定の別のノード"" ""がタスクを引き継いでサービスを引き続き提供できることを意味します。<indexterm "" ""class=\""singular\""><primary>Havana</primary></indexterm><indexterm class="" ""\""singular\""><primary>Grizzly</primary></indexterm>"" msgid ""Overview"" msgstr ""概要"" msgid """" ""The simplest architecture you can build upon for Compute has a single cloud "" ""controller and multiple compute nodes. The simplest architecture for Object "" ""Storage has five nodes: one for identifying users and proxying requests to "" ""the API, then four for storage itself to provide enough replication for "" ""eventual consistency. This example architecture does not dictate a "" ""particular number of nodes, but shows the thinking <phrase role=\""keep-"" ""together\"">and considerations</phrase> that went into choosing this "" ""architecture including the features <phrase role=\""keep-together\"">offered</"" ""phrase>.<indexterm class=\""singular\""><primary>CentOS</primary></"" ""indexterm><indexterm class=\""singular\""><primary>RDO (Red Hat Distributed "" ""OpenStack)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Ubuntu</primary></indexterm><indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>component overview</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>example "" ""architectures</primary><see>legacy networking; OpenStack networking</see></"" ""indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>simplest architecture for</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Compute</"" ""primary><secondary>simplest architecture for</secondary></indexterm>"" msgstr """" ""Compute 用の基盤となる最もシンプルなアーキテクチャは、単一のクラウドコント"" ""ローラーと複数のコンピュートノードで構成されます。Object Storage 用の最もシン"" ""プルなアーキテクチャは、ユーザーを識別して API への要求をプロキシするノード "" ""1 つと、最終的な一貫性を確保するのに十分なレプリケーションを提供する、スト"" ""レージ自体のためのノード 4つを合わせた 5 つのノードで構成されます。このアーキ"" ""テクチャの例では、特定のノード数は決まっていませんが、このアーキテクチャを選"" ""択するにあたって考慮 <phrase role=\""keep-together\"">および検討した点</"" ""phrase> (どのような機能を<phrase role=\""keep-together\"">提供するか</phrase>な"" ""ど) をお分かりいただけます。<indexterm class=\""singular\""><primary>CentOS</"" ""primary></indexterm><indexterm class=\""singular\""><primary>RDO (Red Hat "" ""Distributed OpenStack)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Ubuntu</primary></indexterm><indexterm class=\""singular"" ""\""><primary>レガシーネットワーク (nova)</primary><secondary>コンポーネントの"" ""概要</secondary></indexterm><indexterm class=\""singular\""><primary>アーキテク"" ""チャ例</primary><see>レガシーネットワーク; OpenStack Networking</see></"" ""indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>最もシンプルなアーキテクチャ</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Compute</primary><secondary>"" ""最もシンプルなアーキテクチャ</secondary></indexterm>"" msgid ""Components"" msgstr ""コンポーネント"" msgid ""Component"" msgstr ""コンポーネント"" msgid ""Details"" msgstr ""詳細"" msgid ""OpenStack release"" msgstr ""OpenStack リリース"" msgid ""Host operating system"" msgstr ""ホストのオペレーティングシステム"" msgid """" ""Ubuntu 12.04 LTS or Red Hat Enterprise Linux 6.5, including derivatives such "" ""as CentOS and Scientific Linux"" msgstr """" ""Ubuntu 12.04 LTS または Red Hat Enterprise Linux 6.5 (CentOS および "" ""Scientific Linux などの派生物を含む)"" msgid ""OpenStack package repository"" msgstr ""OpenStack パッケージリポジトリ"" msgid """" ""<link href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> or <link href=\""http://openstack.redhat.com/"" ""Frequently_Asked_Questions\"">RDO</link>*"" msgstr """" ""<link href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> または <link href=\""http://openstack.redhat.com/"" ""Frequently_Asked_Questions\"">RDO</link>*"" msgid ""Hypervisor"" msgstr ""ハイパーバイザー"" msgid ""KVM"" msgstr ""KVM"" msgid ""Database"" msgstr ""データベース"" msgid ""MySQL*"" msgstr ""MySQL*"" msgid ""Message queue"" msgstr ""メッセージキュー"" msgid ""RabbitMQ for Ubuntu; Qpid for Red Hat Enterprise Linux and derivatives"" msgstr """" ""Ubuntu には RabbitMQ、Red Hat Enterprise Linux には Qpid、 および派生物"" msgid ""Networking service"" msgstr ""ネットワークサービス"" msgid ""nova-network"" msgstr ""nova-network"" msgid ""Network manager"" msgstr ""ネットワークマネージャー"" msgid ""FlatDHCP"" msgstr ""FlatDHCP"" msgid ""Single <literal>nova-network</literal> or multi-host?"" msgstr ""単一の <literal>nova-network</literal> またはマルチホスト?"" msgid ""multi-host*"" msgstr ""マルチホスト*"" msgid ""file"" msgstr ""file"" msgid ""Identity Service (keystone) driver"" msgstr ""Identity Service (keystone) のドライバー"" msgid ""SQL"" msgstr ""SQL"" msgid ""LVM/iSCSI"" msgstr ""LVM/iSCSI"" msgid ""Shared storage using NFS*"" msgstr ""NFS を使用する共有ストレージ* "" msgid ""Object storage"" msgstr ""オブジェクトストレージ"" msgid ""OpenStack Object Storage (swift)"" msgstr ""OpenStack Object Storage (swift)"" msgid """" ""An asterisk (*) indicates when the example architecture deviates from the "" ""settings of a default installation. We'll offer explanations for those "" ""deviations next.<indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>object storage</secondary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>object storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>migration</"" ""primary></indexterm><indexterm class=\""singular\""><primary>live migration</"" ""primary></indexterm><indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>floating</secondary></indexterm><indexterm class="" ""\""singular\""><primary>floating IP address</primary></indexterm><indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>block storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>block storage</"" ""primary></indexterm><indexterm class=\""singular\""><primary>dashboard</"" ""primary></indexterm><indexterm class=\""singular\""><primary>legacy networking "" ""(nova)</primary><secondary>features supported by</secondary></indexterm>"" msgstr """" ""アスタリスク (*) は、アーキテクチャの例がデフォルトインストールの設定から逸脱"" ""している箇所を示しています。この逸脱については、次のセクションで説明します。"" ""<indexterm class=\""singular\""><primary>オブジェクト</"" ""primary><secondary>Object Storage</secondary></indexterm><indexterm class="" ""\""singular\""><primary>ストレージ</primary><secondary>Object Storage</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>マイグレーション"" ""</primary></indexterm><indexterm class=\""singular\""><primary>ライブマイグレー"" ""ション</primary></indexterm><indexterm class=\""singular\""><primary>IP アドレ"" ""ス</primary><secondary>floating</secondary></indexterm><indexterm class="" ""\""singular\""><primary>floating IP address</primary></indexterm><indexterm "" ""class=\""singular\""><primary>ストレージ</primary><secondary>ブロックストレージ"" ""</secondary></indexterm><indexterm class=\""singular\""><primary>ブロックスト"" ""レージ</primary></indexterm><indexterm class=\""singular\""><primary>ダッシュ"" ""ボード</primary></indexterm><indexterm class=\""singular\""><primary>レガシー"" ""ネットワーク (nova)</primary><secondary>サポート対象機能</secondary></"" ""indexterm>"" msgid """" ""<glossterm>Dashboard</glossterm>: You probably want to offer a dashboard, "" ""but your users may be more interested in API access only."" msgstr """" ""<glossterm>ダッシュボード</glossterm>: ダッシュボードの提供を考慮されているか"" ""もしれませんが、ユーザーは API アクセスのみの方に対する関心の方が高い可能性が"" ""あります。""""The following features of OpenStack are supported by the example "" ""architecture documented in this guide, but are optional:<placeholder-1/>"" msgstr """" ""以下にあげる OpenStack の機能は、本ガイドに記載のアーキテクチャではサポートさ"" ""れていますが、必須項目ではありません。<placeholder-1/>"" msgid ""Rationale"" msgstr ""設定指針"" msgid """" ""This example architecture has been selected based on the current default "" ""feature set of OpenStack <glossterm>Havana</glossterm>, with an emphasis on "" ""stability. We believe that many clouds that currently run OpenStack in "" ""production have made similar choices.<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>rationale for "" ""choice of</secondary></indexterm>"" msgstr """" ""このアーキテクチャの例は、OpenStack <glossterm>Havana</glossterm> の現在のデ"" ""フォルト機能セットをベースに、安定性に重点を置いて選択しています。現在 "" ""OpenStack を本番環境で実行しているクラウドの多くは、同様の選択をしているもの"" ""と推定されます。<indexterm class=\""singular\""><primary>レガシーネットワーク "" ""(nova)</primary><secondary>選択の理由</secondary></indexterm>"" msgid """" ""You must first choose the operating system that runs on all of the physical "" ""nodes. While OpenStack is supported on several distributions of Linux, we "" ""used <emphasis>Ubuntu 12.04 LTS (Long Term Support)</emphasis>, which is "" ""used by the majority of the development community, has feature completeness "" ""compared with other distributions and has clear future support plans."" msgstr """" ""まず最初に、物理ノード上で実行するオペレーティングシステムを選択する必要があ"" ""ります。OpenStack は複数の Linux ディストリビューションでサポートされています"" ""が、開発コミュニティの大半で使用されている <emphasis>Ubuntu 12.04 LTS (Long "" ""Term Support)</emphasis> を使用しました。このディストリビューションは、他の"" ""ディストリビューションと比較した場合、機能の完全性が高く、将来のサポートプラ"" ""ンが明確に立てられています。"" msgid """" ""We recommend that you do not use the default Ubuntu OpenStack install "" ""packages and instead use the <link href=\""https://wiki.ubuntu.com/ServerTeam/"" ""CloudArchive\"">Ubuntu Cloud Archive</link>. The Cloud Archive is a package "" ""repository supported by Canonical that allows you to upgrade to future "" ""OpenStack releases while remaining on Ubuntu 12.04."" msgstr """" ""デフォルトの Ubuntu OpenStack インストールパッケージは使用せずに、<link href="" ""\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud Archive</"" ""link> を使用することをお勧めします。Cloud Archive は、Canonical がサポートす"" ""るパッケージリポジトリです。これにより、Ubuntu 12.04 を維持した状態で将来の "" ""OpenStack リリースにアップグレードすることができます。"" msgid """" ""<emphasis>KVM</emphasis> as a <glossterm>hypervisor</glossterm> complements "" ""the choice of Ubuntu—being a matched pair in terms of support, and also "" ""because of the significant degree of attention it garners from the OpenStack "" ""development community (including the authors, who mostly use KVM). It is "" ""also feature complete, free from licensing charges and restrictions."" ""<indexterm class=\""singular\""><primary>kernel-based VM (KVM) hypervisor</"" ""primary></indexterm><indexterm class=\""singular\""><primary>hypervisors</"" ""primary><secondary>KVM</secondary></indexterm>"" msgstr """" ""<emphasis>KVM</emphasis> は <glossterm>ハイパーバイザー</glossterm> として "" ""Ubuntu の選択を補完します。これらはサポート面で対応する一対であり、OpenStack "" ""開発コミュニティ (主に KVM を使用する作成者) から集まる注目度が高いのも理由で"" ""す。また、機能が完全で、ライセンスの料金や制限がありません。<indexterm class="" ""\""singular\""><primary>kernel-based VM (KVM) ハイパーバイザー</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ハイパーバイザー</"" ""primary><secondary>KVM</secondary></indexterm>"" msgid """" ""<emphasis>MySQL</emphasis> follows a similar trend. Despite its recent "" ""change of ownership, this database is the most tested for use with OpenStack "" ""and is heavily documented. We deviate from the default database, "" ""<emphasis>SQLite</emphasis>, because SQLite is not an appropriate database "" ""for production usage."" msgstr """" ""<emphasis>MySQL</emphasis> も同様の傾向に沿っています。最近所有権が移転したに"" ""も関わらず、このデータベースは OpenStack での使用では最も検証されており、十分"" ""に文書化されています。<emphasis>SQLite</emphasis> は本番環境での使用には適し"" ""てないため、デフォルトのデータベースでは対象外とします。"" msgid """" ""The choice of <emphasis>RabbitMQ</emphasis> over other AMQP compatible "" ""options that are gaining support in OpenStack, such as ZeroMQ and Qpid, is "" ""due to its ease of use and significant testing in production. It also is the "" ""only option that supports features such as Compute cells. We recommend "" ""clustering with RabbitMQ, as it is an integral component of the system and "" ""fairly simple to implement due to its inbuilt nature.<indexterm class="" ""\""singular\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></"" ""indexterm>"" msgstr """" ""OpenStack では AMQP 互換の選択肢として ZeroMQ や Qpid などのサポートが進んで"" ""いますが、<emphasis>RabbitMQ</emphasis> を選んだのは、その使いやすさと本番環"" ""境で十分にテストされているのが理由です。また、RabbitMQ は Compute Cell といっ"" ""た機能でサポートされている唯一の選択肢です。メッセージキューは OpenStack シス"" ""テムで不可欠のコンポーネントで、RabbitMQ 自体で元々サポートされているため、極"" ""めて簡単に実装できます。このため、RabbitMQ は クラスター構成にすることを推奨"" ""します。<indexterm class=\""singular\""><primary>Advanced Message Queuing "" ""Protocol (AMQP)</primary></indexterm>"" msgid """" ""As discussed in previous chapters, there are several options for networking "" ""in OpenStack Compute. We recommend <emphasis>FlatDHCP</emphasis> and to use "" ""<emphasis>Multi-Host</emphasis> networking mode for high availability, "" ""running one <code>nova-network</code> daemon per OpenStack compute host. "" ""This provides a robust mechanism for ensuring network interruptions are "" ""isolated to individual compute hosts, and allows for the direct use of "" ""hardware network gateways."" msgstr """" ""前章で述べたように、OpenStack Compute のネットワークにはいくつかの選択肢があ"" ""りますが、高可用性には <emphasis>FlatDHCP</emphasis> で <emphasis>マルチホス"" ""ト</emphasis> ネットワークモードを使用して、OpenStack Compute ホスト毎に "" ""<code>nova-network</code> デーモンを 1 つ実行することを推奨します。これによ"" ""り、ネットワーク障害が確実に各コンピュートホスト内に隔離される堅牢性の高いメ"" ""カニズムが提供され、各ホストはハードウェアのネットワークゲートウェイと直接通"" ""信することが可能となります。"" msgid """" ""<emphasis>Live Migration</emphasis> is supported by way of shared storage, "" ""with <emphasis>NFS</emphasis> as the distributed file system."" msgstr """" ""<emphasis>ライブマイグレーション</emphasis> は、共有ストレージを使用すること"" ""によってサポートされます。分散ファイルシステムには <emphasis>NFS</emphasis> "" ""を使用します。"" msgid """" ""Block Storage (cinder) is installed natively on external storage nodes and "" ""uses the <emphasis>LVM/iSCSI plug-in</emphasis>. Most Block Storage Service "" ""plug-ins are tied to particular vendor products and implementations limiting "" ""their use to consumers of those hardware platforms, but LVM/iSCSI is robust "" ""and stable on commodity hardware."" msgstr """" ""Block Storage (cinder) は、外部ストレージノードにネイティブでインストールさ"" ""れ、<emphasis>LVM/iSCSI plug-in</emphasis> を使用します。大半の Block "" ""Storage Service プラグインは、特定のベンダーの製品や実装と関連付けられてお"" ""り、使用はそれらのハードウェアプラットフォームのユーザーに制限されています"" ""が、LVM/iSCSI はコモディティハードウェア上で堅牢性および安定性があります。"" msgid """" ""While the cloud can be run without the <emphasis>OpenStack Dashboard</"" ""emphasis>, we consider it to be indispensable, not just for user interaction "" ""with the cloud, but also as a tool for operators. Additionally, the "" ""dashboard's use of Django makes it a flexible framework for <phrase role="" ""\""keep-together\"">extension</phrase>."" msgstr """" ""クラウドは <emphasis>OpenStack Dashboard</emphasis> がなくても稼働させること"" ""は可能ですが、クラウドとの対話だけでなく運用担当者のツールとしても不可欠な要"" ""素と判断しました。また、ダッシュボードに採用されている Django により、"" ""<phrase role=\""keep-together\"">拡張機能</phrase> のための柔軟なフレームワーク"" ""となります。"" msgid ""Why not use the OpenStack Network Service (neutron)?"" msgstr ""OpenStack Network Service (neutron) を使用しない理由"" msgid """" ""This example architecture does not use the OpenStack Network Service "" ""(neutron), because it does not yet support multi-host networking and our "" ""organizations (university, government) have access to a large range of "" ""publicly-accessible IPv4 addresses.<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>vs. OpenStack "" ""Network Service (neutron)</secondary></indexterm>"" msgstr """" ""このアーキテクチャ例では、OpenStack Networking Service (neutron) は使用して"" ""いません。neutron はマルチホストネットワークをまだサポートしておらず、また対"" ""象となる組織 (大学/政府機関) ではパブリックでアクセス可能な IPv4 アドレスを広"" ""範囲で利用できるのが理由です。<indexterm class=\""singular\""><primary>レガシー"" ""ネットワーク (nova)</primary><secondary>vs. OpenStack Network Service "" ""(neutron)</secondary></indexterm>"" msgid ""Why use multi-host networking?"" msgstr ""マルチホストネットワークを使用する理由"" msgid """" ""In a default OpenStack deployment, there is a single <code>nova-network</"" ""code> service that runs within the cloud (usually on the cloud controller) "" ""that provides services such as network address translation (NAT), DHCP, and "" ""DNS to the guest instances. If the single node that runs the <code>nova-"" ""network</code> service goes down, you cannot access your instances, and the "" ""instances cannot access the Internet. The single node that runs the "" ""<literal>nova-network</literal> service can become a bottleneck if excessive "" ""network traffic comes in and goes out of the cloud.<indexterm class="" ""\""singular\""><primary>networks</primary><secondary>multi-host</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>multi-host networking</"" ""primary></indexterm><indexterm class=\""singular\""><primary>legacy networking "" ""(nova)</primary><secondary>benefits of multi-host networking</secondary></"" ""indexterm>"" msgstr """" ""デフォルトの OpenStack デプロイメントでは、単一の <code>nova-network</code> "" ""サービスがクラウド内 (通常はクラウドコントローラー) で実行され、ネットワーク"" ""アドレス変換 (NAT)、DHCP、DNS などのサービスをゲストインスタンスにd提供しま"" ""す。<code>nova-network</code> サービスを実行する単一のノードが停止した場合に"" ""は、インスタンスにアクセスできなくなり、またインスタンスはインターネットにア"" ""クセスできません。クラウドでネットワークトラフィックが過剰に送受信されると、"" ""<literal>nova-network</literal> サービスを実行する単一ノードがボトルネックと"" ""なる可能性があります。<indexterm class=\""singular\""><primary>ネットワーク</"" ""primary><secondary>マルチホスト</secondary></indexterm><indexterm class="" ""\""singular\""><primary>マルチホストネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>レガシーネットワーク(nova)</"" ""primary><secondary>マルチホストネットワークの利点</secondary></indexterm>"" msgid """"msgid ""Detailed Description"" msgstr ""詳細な説明"" ""The reference architecture consists of multiple compute nodes, a cloud "" ""controller, an external NFS storage server for instance storage, and an "" ""OpenStack Block Storage server for <glossterm>volume</glossterm> storage."" ""<indexterm class=\""singular\""><primary>legacy networking (nova)</"" ""primary><secondary>detailed description</secondary></indexterm> A network "" ""time service (Network Time Protocol, or NTP) synchronizes time on all the "" ""nodes. FlatDHCPManager in multi-host mode is used for the networking. A "" ""logical diagram for this example architecture shows which services are "" ""running on each node:""""この参照アーキテクチャは、複数のコンピュートノード、クラウドコントローラー 1 "" ""台、インスタンスストレージ用の外部 NFS ストレージサーバー 1 台、"" ""<glossterm>volume</glossterm> ストレージ用の OpenStack Block Storage サー"" ""バー 1 台で構成されます。<indexterm class=\""singular\""><primary>レガシーネッ"" ""トワーク (nova)</primary><secondary>詳しい説明</secondary></indexterm> ネット"" ""ワークタイムサービス (Network Time Protocol / NTP) は全ノードの時刻を同期しま"" ""す。ネットワークには、マルチホストモードの FlatDHCPManager を使用しています。"" ""このアーキテクチャ例の論理図には、各ノードで実行されているサービスが示されて"" ""います。""""The cloud controller runs the dashboard, the API services, the database "" ""(MySQL), a message queue server (RabbitMQ), the scheduler for choosing "" ""compute resources (<literal>nova-scheduler</literal>), Identity services "" ""(keystone, <code>nova-consoleauth</code>), Image services (<code>glance-api</"" ""code>, <code>glance-registry</code>), services for console access of guests, "" ""and Block Storage services, including the scheduler for storage resources "" ""(<code>cinder-api</code> and <code>cinder-scheduler</code>).<indexterm class="" ""\""singular\""><primary>cloud controllers</primary><secondary>duties of</""""クラウドコントローラーは、ダッシュボード、API サービス、データベース "" ""(MySQL)、メッセージキューサーバー (RabbitMQ)、コンピュートリソースを選択する"" ""スケジューラー (<literal>nova-scheduler</literal>)、Identity Service "" ""(keystone、<code>nova-consoleauth</code>)、Image Service (<code>glance-api</"" ""code>、 <code>glance-registry</code>)、ゲストのコンソールアクセスのためのサー"" ""ビス、ストレージリソースのスケジューラーを含む Block Storage Service "" ""(<code>cinder-api</code> および <code>cinder-scheduler</code>) を実行します。"" ""<indexterm class=\""singular\""><primary>クラウドコントローラー</"" ""primary><secondary>役割</secondary></indexterm>""""Compute nodes are where the computing resources are held, and in our example "" ""architecture, they run the hypervisor (KVM), libvirt (the driver for the "" ""hypervisor, which enables live migration from node to node), <code>nova-"" ""compute</code>, <code>nova-api-metadata</code> (generally only used when "" ""running in multi-host mode, it retrieves instance-specific metadata), "" ""<code>nova-vncproxy</code>, and <code>nova-network</code>.""""コンピュートノードには、コンピューティングリソースが保持されます。このアーキ"" ""テクチャ例では、コンピュートノードで、ハイパーバイザー (KVM)、libvirt (ノード"" ""間でのライブマイグレーションを可能にするハイパーバイザー用ドライバー)、"" ""<code>nova-compute</code>、 <code>nova-api-metadata</code> (通常はマルチホス"" ""トモードの場合のみ使用され、インスタンス固有のメタデータを取得する)、nova-"" ""vncproxy、<code>nova-network</code> を実行します。""""The network consists of two switches, one for the management or private "" ""traffic, and one that covers public access, including floating IPs. To "" ""support this, the cloud controller and the compute nodes have two network "" ""cards. The OpenStack Block Storage and NFS storage servers only need to "" ""access the private network and therefore only need one network card, but "" ""multiple cards run in a bonded configuration are recommended if possible. "" ""Floating IP access is direct to the Internet, whereas Flat IP access goes "" ""through a NAT. To envision the network traffic, use this diagram:""""ネットワークは、2 つのスイッチで構成され、1 つは管理/プライベートトラフィック"" ""用、もう 1 つは Floating IP を含むパブリックアクセスが対象です。この構成に対"" ""応するために、クラウドコントローラーおよびコンピュートノードで NIC を 2 枚を"" ""装備します。OpenStack Block Storage および NFS ストレージサーバーは、プライ"" ""ベートネットワークにのみアクセスする必要があるので、必要な NIC は 1 枚です"" ""が、可能な場合には複数の NIC をボンディング構成で動作させることを推奨します。"" ""Floating IP のアクセスは、インターネットに直結ですが、Flat IP のアクセスは "" ""NAT 経由となります。ネットワークトラフィックの構想には、以下の図を利用してく"" ""ださい。"" msgid ""Optional Extensions"" msgstr ""さらなる拡張"" msgid """" ""You can extend this reference architecture as<indexterm class=\""singular"" ""\""><primary>legacy networking (nova)</primary><secondary>optional "" ""extensions</secondary></indexterm> follows:"" msgstr """" ""この参照アーキテクチャは、<indexterm class=\""singular\""><primary>レガシーネッ"" ""トワーク (nova)</primary><secondary>オプションの拡張機能</secondary></"" ""indexterm>以下のように拡張することが可能です:"" msgid ""Add additional cloud controllers (see <xref linkend=\""maintenance\""/>)."" msgstr """" ""追加でクラウドコントローラーを増やす (<xref linkend=\""maintenance\""/> を参"" ""照)。"" msgid """" ""Add an OpenStack Storage service (see the Object Storage chapter in the "" ""<emphasis>OpenStack Installation Guide</emphasis> for your distribution)."" msgstr """" ""OpenStack Storage Service を追加する (お使いのディストリビューション向けの "" ""<emphasis>OpenStack インストールガイド</emphasis> で Object Storage の章を参"" ""照してください)"" msgid """" ""Add additional OpenStack Block Storage hosts (see <xref linkend=\""maintenance"" ""\""/>)."" msgstr """" ""追加で OpenStack Block Storage ホストを増やす (see <xref linkend="" ""\""maintenance\""/> 参照)。""msgid ""Example Architecture—OpenStack Networking"" msgstr ""アーキテクチャの例: OpenStack Networking""""This chapter provides an example architecture using OpenStack Networking, "" ""also known as the Neutron project, in a highly available environment.""""本章には、OpenStack Networking (別称: Neutron プロジェクト) を高可用性環境で"" ""使用するアーキテクチャの例を記載します。""msgid ""Red Hat Enterprise Linux 6.5"" msgstr ""Red Hat Enterprise Linux 6.5"" msgid ""Red Hat Distributed OpenStack (RDO)"" msgstr ""Red Hat Distributed OpenStack (RDO)"" msgid ""MySQL"" msgstr ""MySQL"" msgid ""Qpid"" msgstr ""Qpid"" msgid ""OpenStack Networking"" msgstr ""OpenStack Networking"" msgid ""Tenant Network Separation"" msgstr ""テナントネットワークの分離"" msgid ""VLAN"" msgstr ""VLAN"" msgid ""GlusterFS"" msgstr ""GlusterFS"" msgid ""Block Storage Service (cinder) backend"" msgstr ""Block Storage Service (cinder) バックエンド"" msgid """" ""This example architecture has been selected based on the current default "" ""feature set of OpenStack Havana, with an emphasis on high availability. This "" ""architecture is currently being deployed in an internal Red Hat OpenStack "" ""cloud and used to run hosted and shared services, which by their nature must "" ""be highly available.<indexterm class=\""singular\""><primary>OpenStack "" ""Networking (neutron)</primary><secondary>rationale for choice of</"" ""secondary></indexterm>"" msgstr """" ""このアーキテクチャ例は、OpenStack Havana の現在のデフォルト機能セットをベース"" ""に、高可用性に重点を置いて選択しています。このアーキテクチャは、現在 Red Hat "" ""の 企業内 OpenStack クラウドでデプロイされており、ホステッド共有サービスの運"" ""用に使用されています。ホステッド共有サービスは、その性質上、高可用性が要求さ"" ""れます。<indexterm class=\""singular\""><primary>OpenStack Networking (neutron)"" ""</primary><secondary>設定指針</secondary></indexterm>"" msgid """" ""This architecture's components have been selected for the following reasons:"" msgstr """" ""このアーキテクチャコンポーネントは、以下のような理由で選択されています。"" msgid ""Red Hat Enterprise Linux"" msgstr ""Red Hat Enterprise Linux"" msgid """" ""You must choose an operating system that can run on all of the physical "" ""nodes. This example architecture is based on Red Hat Enterprise Linux, which "" ""offers reliability, long-term support, certified testing, and is hardened. "" ""Enterprise customers, now moving into OpenStack usage, typically require "" ""these advantages."" msgstr """" ""全物理ノードで実行可能なオペレーティングシステムを選択する必要があります。こ"" ""のアーキテクチャ例は、信頼性、長期的なサポート、認定テストが提供され、セキュ"" ""リティ強化されている Red Hat Enterprise Linux をベースにしています。現在、"" ""OpenStack の採用に向けて移行中の企業顧客には、通常このような利点が要求されま"" ""す。"" msgid ""RDO"" msgstr ""RDO"" msgid """" ""The Red Hat Distributed OpenStack package offers an easy way to download the "" ""most current OpenStack release that is built for the Red Hat Enterprise "" ""Linux platform."" msgstr """" ""Red Hat Distributed OpenStack パッケージは、Red Hat Enterprise Linux プラット"" ""フォーム用に構築された最新の OpenStack リリースを容易にダウンロードする方法を"" ""提供します。"" msgid """" ""KVM is the supported hypervisor of choice for Red Hat Enterprise Linux (and "" ""included in distribution). It is feature complete and free from licensing "" ""charges and restrictions."" msgstr """" ""KVM は、Red Hat Enterprise Linux に最適なサポート対象ハイパーバイザーです (ま"" ""た、ディストリビューションにも含まれます)。機能が完成されており、ライセンスの"" ""料金や制限は課せられません。"" msgid """" ""MySQL is used as the database backend for all databases in the OpenStack "" ""environment. MySQL is the supported database of choice for Red Hat "" ""Enterprise Linux (and included in distribution); the database is open "" ""source, scalable, and handles memory well."" msgstr """" ""MySQL は、OpenStack 環境の全データベースのデータベースバックエンドとして使用"" ""されます。MySQL は、Red Hat Enterprise Linux に最適なサポート対象データベース"" ""です (また、ディストリビューションにも同梱されています)。このデータベースは、"" ""オープンソースで、拡張が可能な上、メモリーの処理を効率的に行います。"" msgid """" ""Apache Qpid offers 100 percent compatibility with the Advanced Message "" ""Queuing Protocol Standard, and its broker is available for both C++ and Java."" msgstr """" ""Apache Qpid は、Advanced Message Queuing Protocol の標準との 100% の互換性を"" ""提供し、ブローカーは C++ と Java の両方で利用可能です。"" msgid """" ""OpenStack Networking offers sophisticated networking functionality, "" ""including Layer 2 (L2) network segregation and provider networks."" msgstr """" ""OpenStack Networking は、レイヤー 2 (L2) ネットワークの分離やプロバイダーネッ"" ""トワークを含む高度なネットワーク機能を提供します。"" msgid """" ""Using a virtual local area network offers broadcast control, security, and "" ""physical layer transparency. If needed, use VXLAN to extend your address "" ""space."" msgstr """" ""仮想ローカルエリアネットワークを使用してブロードキャスト制御、セキュリティ、"" ""物理レイヤーの透過性を提供します。必要な場合には、VXLAN を使用してアドレス空"" ""間を拡張します。"" msgid """" ""GlusterFS offers scalable storage. As your environment grows, you can "" ""continue to add more storage nodes (instead of being restricted, for "" ""example, by an expensive storage array)."" msgstr """" ""GlusterFS は拡張可能なストレージを提供します。環境の拡大に応じて、 (高額なス"" ""トレージアレイなどによる制約を受けずに) ストレージノードを継続的に追加するこ"" ""とが可能です。"" msgid ""Node types"" msgstr ""ノードのタイプ"" msgid """" ""This section gives you a breakdown of the different nodes that make up the "" ""OpenStack environment. A node is a physical machine that is provisioned with "" ""an operating system, and running a defined software stack on top of it. "" ""<xref linkend=\""node-types-table\""/> provides node descriptions and "" ""specifications.<indexterm class=\""singular\""><primary>OpenStack Networking "" ""(neutron)</primary><secondary>detailed description of</secondary></indexterm>"" msgstr """" ""本セクションでは、OpenStack 環境を構成する異なるノードの内訳を記載します。 "" ""ノードとは、オペレーティングシステムがプロビジョニングされた物理マシンで、そ"" ""の上に定義済みソフトウェアスタックを実行します。 <xref linkend=\""node-types-"" ""table\""/> には、ノードの説明と仕様を記載しています。<indexterm class="" ""\""singular\""><primary>OpenStack Networking (neutron)</primary><secondary>詳細"" ""</secondary></indexterm>"" msgid ""Type"" msgstr ""種別"" msgid ""Description"" msgstr ""説明"" msgid ""Example hardware"" msgstr ""ハードウェアの例"" msgid ""Controller"" msgstr ""コントローラー"" msgid """" ""Controller nodes are responsible for running the management software "" ""services needed for the OpenStack environment to function. These nodes:"" msgstr """" ""コントローラーノードは、 OpenStack 環境が機能するために必要な管理ソフトウェア"" ""サービスを実行します。これらのノードは、以下のような役割を果たします。"" msgid """" ""Provide the front door that people access as well as the API services that "" ""all other components in the environment talk to."" msgstr """" ""ユーザーがアクセスするフロントドアに加えて、環境内その他すべてのコンポーネン"" ""トが通信する API サービスを提供します。"" msgid """" ""Run a number of services in a highly available fashion, utilizing Pacemaker "" ""and HAProxy to provide a virtual IP and load-balancing functions so all "" ""controller nodes are being used."" msgstr """" ""全コントローラーノードが使用されるように Pacemaker と HAProxy を利用して仮想 "" ""IP および負荷分散機能を提供して、多数のサービスを高可用性で実行します。"" msgid """" ""Supply highly available \""infrastructure\"" services, such as MySQL and Qpid, "" ""that underpin all the services."" msgstr """" ""高可用性の「インフラストラクチャ」サービス (全サービスの基盤となる MySQL や "" ""Qpid など) を提供します。 "" msgid """" ""Provide what is known as \""persistent storage\"" through services run on the "" ""host as well. This persistent storage is backed onto the storage nodes for "" ""reliability."" msgstr """" ""ホストでも実行されるサービスを介して、いわゆる「永続ストレージ」を提供しま"" ""す。この永続ストレージは、信頼性のためにストレージノードにバッキングされま"" ""す。"" msgid ""See <xref linkend=\""node_controller-diagram\""/>."" msgstr ""<xref linkend=\""node_controller-diagram\""/> を参照してください。"" msgid ""Model: Dell R620"" msgstr ""モデル: Dell R620"" msgid ""CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgstr ""CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgid ""Memory: 32 GB"" msgstr ""メモリー: 32 GB"" msgid ""Disk: two 300 GB 10000 RPM SAS Disks"" msgstr ""ディスク: 300 GB 10000 RPM SAS ディスク x 2"" msgid ""Network: two 10G network ports"" msgstr ""ネットワーク: 10G のネットワークポート x 2"" msgid ""Compute"" msgstr ""コンピュート"" msgid ""Compute nodes run the virtual machine instances in OpenStack. They:"" msgstr """" ""コンピュートノードは、OpenStack 内の仮想マシンインスタンスを実行します。コン"" ""ピュートノードは、以下のような役割を果たします。"" msgid ""Run the bare minimum of services needed to facilitate these instances."" msgstr """" ""それらのインスタンスを円滑に稼働するために必要な最低限のサービスを実行しま"" ""す。"" msgid """" ""Use local storage on the node for the virtual machines so that no VM "" ""migration or instance recovery at node failure is possible."" msgstr """" ""ノードの障害発生時に仮想マシンの移行やインスタンスのリカバリができないよう"" ""に、仮想マシンにノード上のローカルストレージを使用します。"" msgid ""See <xref linkend=\""node_compute-diagram\""/>."" msgstr ""<xref linkend=\""node_compute-diagram\""/> を参照してください。"" msgid ""CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz"" msgstr ""CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz"" msgid ""Memory: 128 GB"" msgstr ""メモリー: 128 GB"" msgid ""Disk: two 600 GB 10000 RPM SAS Disks"" msgstr ""ディスク: 600 GB 10000 RPM SAS ディスク x 2"" msgid ""Network: four 10G network ports (For future proofing expansion)"" msgstr ""ネットワーク: 10G ネットワークポート x 4 (将来を保証する拡張性のため)"" msgid ""Storage"" msgstr ""ストレージ"" msgid ""See <xref linkend=\""node_storage-diagram\""/>."" msgstr ""<xref linkend=\""node_storage-diagram\""/> を参照してください。"" msgid ""Model: Dell R720xd"" msgstr ""モデル: Dell R720xd"" msgid ""Memory: 64 GB"" msgstr ""メモリー: 64 GB"" msgid """" ""Disk: two 500 GB 7200 RPM SAS Disks and twenty-four 600 GB 10000 RPM SAS "" ""Disks"" msgstr """" ""ディスク: 500 GB 7200 RPM SAS ディスク x 2 および 600 GB 10000 RPM SAS ディス"" ""ク x 24"" msgid ""Raid Controller: PERC H710P Integrated RAID Controller, 1 GB NV Cache"" msgstr """" ""RAID コントローラー: PERC H710P Integrated RAID Controller、1 GB NV キャッ"" ""シュ"" msgid ""Network"" msgstr ""ネットワーク"" msgid """" ""Network nodes are responsible for doing all the virtual networking needed "" ""for people to create public or private networks and uplink their virtual "" ""machines into external networks. Network nodes:"" msgstr """" ""ネットワークノードは、ユーザーがパブリックまたはプライベートネットワークを作"" ""成し、仮想マシンを外部ネットワークにアップリンクするために必要なすべての仮想"" ""ネットワーキングを実行する役割を果たします。ネットワークノードは以下のような"" ""操作を実行します。"" msgid """" ""Form the only ingress and egress point for instances running on top of "" ""OpenStack."" msgstr """" ""OpenStack 上で実行されているインスタンス用の唯一の送受信ポイントを形成しま"" ""す。"" msgid """" ""Run all of the environment's networking services, with the exception of the "" ""networking API service (which runs on the controller node)."" msgstr """" ""環境の全ネットワークサービスを実行します。ただし、ネットワーク API サービス "" ""(コントローラーノードで実行される) を除きます。"" msgid ""See <xref linkend=\""node_network-diagram\""/>."" msgstr ""<xref linkend=\""node_network-diagram\""/> を参照してください。"" msgid ""CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgstr ""CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"" msgid ""Network: five 10G network ports"" msgstr ""ネットワーク: 10G ネットワークポート x 5"" msgid ""Utility"" msgstr ""ユーティリティ"" msgid """" ""Utility nodes are used by internal administration staff only to provide a "" ""number of basic system administration functions needed to get the "" ""environment up and running and to maintain the hardware, OS, and software on "" ""which it runs."" msgstr """" ""ユーティリティノードは、環境を稼働させ、その環境を実行しているハードウェア/"" ""OS/ソフトウェアを維持管理するのに必要な多数の基本的なシステム管理機能を提供す"" ""るために、内部管理スタッフのみが使用します。"" msgid """" ""These nodes run services such as provisioning, configuration management, "" ""monitoring, or GlusterFS management software. They are not required to "" ""scale, although these machines are usually backed up."" msgstr """" ""これらのノードは、プロビジョニング、設定管理、モニタリング、GlusterFS 管理ソ"" ""フトウェアなどのサービスを実行します。拡張の必要はありませんが、これらのマシ"" ""ンは通常バックアップされます。"" msgid ""Disk: two 500 GB 7200 RPM SAS Disks"" msgstr ""ディスク: 500 GB 7200 RPM SAS ディスク x 2"" msgid ""Networking layout"" msgstr ""ネットワークのレイアウト"" msgid """" ""The network contains all the management devices for all hardware in the "" ""environment (for example, by including Dell iDrac7 devices for the hardware "" ""nodes, and management interfaces for network switches). The network is "" ""accessed by internal staff only when diagnosing or recovering a hardware "" ""issue."" msgstr """" ""ネットワークには、環境内の全ハードウェア用の管理デバイスがすべて含まれます "" ""(例: ハードウェアノード用の Dell iDrac7 デバイスやネットワークスイッチ用の管"" ""理インターフェースの追加による) 。ネットワークは、ハードウェア問題の診断また"" ""はリカバリを実行する場合にのみ内部スタッフがアクセスします。"" msgid ""OpenStack internal network"" msgstr ""OpenStack 内部ネットワーク"" msgid """" ""This network is used for OpenStack management functions and traffic, "" ""including services needed for the provisioning of physical nodes "" ""(<literal>pxe</literal>, <literal>tftp</literal>, <literal>kickstart</"" ""literal>), traffic between various OpenStack node types using OpenStack APIs "" ""and messages (for example, <literal>nova-compute</literal> talking to "" ""<literal>keystone</literal> or <literal>cinder-volume</literal> talking to "" ""<literal>nova-api</literal>), and all traffic for storage data to the "" ""storage layer underneath by the Gluster protocol. All physical nodes have at "" ""least one network interface (typically <literal>eth0</literal>) in this "" ""network. This network is only accessible from other VLANs on port 22 (for "" ""<literal>ssh</literal> access to manage machines)."" msgstr """" ""このネットワークは、OpenStack の管理機能およびトラフィックに使用されます。こ"" ""れには、物理ノードのプロビジョニングに必要なサービス (<literal>pxe</"" ""literal>、<literal>tftp</literal>、<literal>kickstart</literal>)、OpenStack "" ""API およびメッセージを使用する様々な OpenStack ノードタイプの間のトラフィッ"" ""ク (例: <literal>nova-compute</literal> から <literal>keystone</literal> への"" ""通信や <literal>cinder-volume</literal> から <literal>nova-api</literal> へ"" ""の通信など)、 Gluster プロトコルによる配下のストレージ層へのストレージデータ"" ""の全トラフィックなどが含まれます。全物理ノードで、少なくとも 1 つのネットワー"" ""クインターフェース (通常は <literal>eth0</literal>) がこのネットワークに設定"" ""されます。他の VLAN からのこのネットワークへのアクセスは、ポート 22 でのみで"" ""可能です (マシンを管理するための <literal>ssh</literal> アクセス)。"" msgid ""Public Network"" msgstr ""パブリックネットワーク"" msgid """" ""IP addresses for public-facing interfaces on the controller nodes (which end "" ""users will access the OpenStack services)"" msgstr """" ""コントローラーノード上のパブリックインターフェースの IP アドレス (エンドユー"" ""ザーが OpenStack サービスにアクセスするのに使用)"" msgid """" ""A range of publicly routable, IPv4 network addresses to be used by OpenStack "" ""Networking for floating IPs. You may be restricted in your access to IPv4 "" ""addresses; a large range of IPv4 addresses is not necessary."" msgstr """" ""OpenStack Networking が Floating IP に使用する、パブリックにルーティング可能"" ""な IPv4 ネットワークアドレスの範囲。IPv4 アドレスへのアクセスは制限される可能"" ""性があります。IPv4 アドレスの範囲を大きくする必要はありません。"" msgid ""Routers for private networks created within OpenStack."" msgstr ""OpenStack 内に作成されるプライベートネットワーク用のルーター"" msgid ""This network is a combination of: <placeholder-1/>"" msgstr ""このネットワークは、以下の要素の組み合わせです: <placeholder-1/>"" msgid """" ""This network is connected to the controller nodes so users can access the "" ""OpenStack interfaces, and connected to the network nodes to provide VMs with "" ""publicly routable traffic functionality. The network is also connected to "" ""the utility machines so that any utility services that need to be made "" ""public (such as system monitoring) can be accessed."" msgstr """" ""このネットワークは、ユーザーが OpenStack インターフェースにアクセスできるよう"" ""するためにコントローラーノードに接続され、パブリックでルーティング可能なトラ"" ""フィックの機能を仮想マシンに提供するためにネットワークノードに接続されます。"" ""また、このネットワークは、公開する必要のある任意のユーティリティサービス (シ"" ""ステムの監視など) にアクセスできるようにするために、ユーティリティマシンにも"" ""接続されます。"" msgid ""VM traffic network"" msgstr ""仮想マシントラフィックネットワーク"" msgid """" ""This is a closed network that is not publicly routable and is simply used as "" ""a private, internal network for traffic between virtual machines in "" ""OpenStack, and between the virtual machines and the network nodes that "" ""provide l3 routes out to the public network (and floating IPs for "" ""connections back in to the VMs). Because this is a closed network, we are "" ""using a different address space to the others to clearly define the "" ""separation. Only Compute and OpenStack Networking nodes need to be connected "" ""to this network."" msgstr """" ""これは、パブリックにはルーティングできない閉じたネットワークで、単に "" ""OpenStack 内の仮想マシン間のトラフィックや、パブリックネットワークへの外向き"" ""の L3 ルート (および仮想マシンに戻る接続のための Floating IP) を提供するネッ"" ""トワークノードと仮想マシンと間 のトラフィックのためのプライベートの内部ネット"" ""ワークに使用されます。このネットワークは閉じているため、他とは異なるアドレス"" ""空間を使用して、その区別を明確に定義しています。このネットワークに接続する必"" ""要があるのは、Compute ノードと OpenStack Networking ノードのみです。"" msgid ""Node connectivity"" msgstr ""ノードの接続性"" msgid """" ""The following section details how the nodes are connected to the different "" ""networks (see <xref linkend=\""networking_layout\""/>) and what other "" ""considerations need to take place (for example, bonding) when connecting "" ""nodes to the networks."" msgstr """" ""以下のセクションでは、ノードを異なるネットワークに接続する方法 ( <xref "" ""linkend=\""networking_layout\""/> を参照) と、ノードをネットワークに接続する際"" ""に他に考慮すべき点 (例: ボンディング) について説明します。"" msgid ""Initial deployment"" msgstr ""初期デプロイメント"" msgid """" ""Initially, the connection setup should revolve around keeping the "" ""connectivity simple and straightforward in order to minimize deployment "" ""complexity and time to deploy. The deployment shown in <xref linkend="" ""\""fig1-1\""/> aims to have 1 10G connectivity available to all compute nodes, "" ""while still leveraging bonding on appropriate nodes for maximum performance."" msgstr """" ""デプロイメントの複雑度と所要時間を最小限に抑えるためには、初めに、接続性を単"" ""純かつ簡潔に保つことを中心に接続の設定を展開する必要があります。<xref "" ""linkend=\""fig1-1\""/> に示したデプロイメントでは、全コンピュートノードに 10G "" ""の接続を 1 つずつ提供する一方で、適切なノードにはボンディングを活用してパ"" ""フォーマンスを最大化することを目的としています。"" msgid ""Basic node deployment"" msgstr ""基本ノードデプロイメント"" msgid ""Connectivity for maximum performance"" msgstr ""パフォーマンスを最大化するための接続性"" msgid """" ""If the networking performance of the basic layout is not enough, you can "" ""move to <xref linkend=\""fig1-2\""/>, which provides 2 10G network links to "" ""all instances in the environment as well as providing more network bandwidth "" ""to the storage layer. bandwidth obtaining maximum performance"" msgstr """" ""基本レイアウトのネットワークパフォーマンスが十分でない場合には、<xref "" ""linkend=\""fig1-2\""/> に移行することができます。このレイアウトでは、環境内の全"" ""インスタンスに 10G のネットワークリンクを2 つ提供するだけでなく、ストレージ層"" ""にさらなるネットワーク帯域幅を提供し、パフォーマンスを最大化します。"" msgid ""Performance node deployment"" msgstr ""パフォーマンスノードのデプロイメント"" msgid ""Node diagrams"" msgstr ""ノードの図"" msgid """" ""The following diagrams (<xref linkend=\""node_controller-diagram\""/> through "" ""<xref linkend=\""node_storage-diagram\""/>) include logical information about "" ""the different types of nodes, indicating what services will be running on "" ""top of them and how they interact with each other. The diagrams also "" ""illustrate how the availability and scalability of services are achieved."" msgstr """" ""以下の図 (<xref linkend=\""node_controller-diagram\""/> through <xref linkend="" ""\""node_storage-diagram\""/>) には、異なるタイプのノードについての論理的情報が"" ""含まれます。この図には、実行されるサービスやそれらがどのように相互に対話する"" ""かが示されています。また、サービスの可用性とスケーラビリティがどのように実現"" ""されるかについても図示しています。"" msgid ""Controller node"" msgstr ""コントローラーノード"" msgid ""Compute node"" msgstr ""コンピュートノード"" msgid ""Network node"" msgstr ""ネットワークノード"" msgid ""Storage node"" msgstr ""ストレージノード"" msgid ""Example Component Configuration"" msgstr ""コンポーネントの設定例"" msgid """" ""Because Pacemaker is cluster software, the software itself handles its own "" ""availability, leveraging <literal>corosync</literal> and <literal>cman</"" ""literal> underneath."" msgstr """" ""Pacemaker は、クラスタリングソフトウェアであるため、基盤となる "" ""<literal>corosync</literal> および <literal>cman</literal> を活用して、ソフト"" ""ウェア自体が自らの可用性を処理します。"" msgid """" ""If you use the GlusterFS native client, no virtual IP is needed, since the "" ""client knows all about nodes after initial connection and automatically "" ""routes around failures on the client side."" msgstr """" ""GlusterFS ネイティブクライアントを使用する場合には、そのクライアントは初回接"" ""続後にノードに関する全情報を認識し、クライアント側の障害を迂回するように自動"" ""的にルーティングするため、仮想 IP は必要ありません。"" msgid """" ""If you use the NFS or SMB adaptor, you will need a virtual IP on which to "" ""mount the GlusterFS volumes."" msgstr """" ""NFS または SMB のアダプターを使用する場合には、GlusterFS ボリュームをマウント"" ""する仮想 IP が必要となります。"" msgid """" ""Pacemaker is the clustering software used to ensure the availability of "" ""services running on the controller and network nodes: <placeholder-1/>"" msgstr """" ""Pacemaker とは、コントローラーノードおよびネットワークノードで実行されている"" ""サービスの可用性を確保するために使用するクラスタリングソフトウェアです: "" ""<placeholder-1/>"" msgid """" ""Configured to use Qpid, <phrase role=\""keep-together"" ""\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together"" ""\""><literal>10</literal>,</phrase></phrase><phrase role=\""keep-together\""> "" ""configured to use</phrase> Memcached for caching, configured to use <phrase "" ""role=\""keep-together\""><literal>libvirt</literal>,</phrase> configured to "" ""use <phrase role=\""keep-together\""><literal>neutron</literal>.</phrase>"" msgstr """" ""Qpid を使用するように設定、<phrase role=\""keep-together"" ""\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together"" ""\""><literal>10</literal>、</phrase></phrase><phrase role=\""keep-together\""> "" ""</phrase> Memcached をキャッシュに使用するように設定、 <phrase role=\""keep-"" ""together\""><literal>libvirt</literal> を使用するように設定、</phrase> "" ""<phrase role=\""keep-together\""><literal>neutron</literal> を使用するように設"" ""定</phrase>"" msgid """" ""Configured <literal>nova-consoleauth</literal> to use Memcached for session "" ""management (so that it can have multiple copies and run in a load balancer)."" msgstr """" ""<literal>nova-consoleauth</literal> がセッション管理に Memcached を使用するよ"" ""うに設定 (複数のコピーが存在可能で、ロードバランサーで実行できる)。"" msgid """" ""The nova API, scheduler, objectstore, cert, consoleauth, conductor, and "" ""vncproxy services are run on all controller nodes, ensuring at least one "" ""instance will be available in case of node failure. Compute is also behind "" ""HAProxy, which detects when the software fails and routes requests around "" ""the failing instance."" msgstr """" ""nova API、scheduler、objectstore、cert、consoleauth、conductor、および "" ""vncproxy のサービスは、全コントローラーノードで実行され、ノードに障害が発生し"" ""た場合には少なくとも 1 インスタンスが利用可能となるようにします。Compute "" ""は、ソフトウェアの障害を検出して、障害の発生したインスタンスを迂回するように"" ""要求をルーティングする HAProxy の背後に配置されます。"" msgid """" ""Compute's compute and conductor services, which run on the compute nodes, "" ""are only needed to run services on that node, so availability of those "" ""services is coupled tightly to the nodes that are available. As long as a "" ""compute node is up, it will have the needed services running on top of it."" msgstr """" ""コンピュートノード上で実行される Compute のコンピュートサービスおよびコンダク"" ""ターサービスは、そのノード上でのみサービスを実行する必要があるので、これらの"" ""サービスの可用性はそのノードの稼働状態と密接に連結しています。コンピュート"" ""ノードが稼働している限りは、そのノード上で必要なサービスが実行されます。"" msgid """" ""The OpenStack Networking service is run on all controller nodes, ensuring at "" ""least one instance will be available in case of node failure. It also sits "" ""behind HAProxy, which detects if the software fails and routes requests "" ""around the failing instance."" msgstr """" ""OpenStack Networking Service は、全コントローラーノード上で実行され、ノードの"" ""障害が発生した場合に少なくとも 1 インスタンスが利用可能となるようにします。"" ""また、このサービスは、ソフトウェアの障害を検出して、障害の発生したインスタン"" ""スを迂回するように要求をルーティングする HAProxy の背後に配置されます。"" msgid """" ""OpenStack Networking's <literal>ovs-agent</literal>, <literal>l3-agent</"" ""literal>, <literal>dhcp-agent</literal>, and <literal>metadata-agent</"" ""literal> services run on the network nodes, as <literal>lsb</literal> "" ""resources inside of Pacemaker. This means that in the case of network node "" ""failure, services are kept running on another node. Finally, the "" ""<literal>ovs-agent</literal> service is also run on all compute nodes, and "" ""in case of compute node failure, the other nodes will continue to function "" ""using the copy of the service running on them."" msgstr """" ""OpenStack Networking の <literal>ovs-agent</literal>、<literal>l3-agent</"" ""literal>、<literal>dhcp-agent</literal>、および <literal>metadata-agent</"" ""literal> のサービスは、ネットワークノード上で Pacemaker 内の <literal>lsb</"" ""literal> リソースとして稼働します。これは、ネットワークノードに障害が発生した"" ""場合にサービスが別のノードで稼働し続けることを意味します。最後に "" ""<literal>ovs-agent</literal> サービスも全コンピュートノードで稼働し、コン"" ""ピュートノードに障害が発生した場合に、その他のノードが、そこで実行されている"" ""サービスのコピーを使用して機能し続けます。"" msgid ""Use Cases"" msgstr ""事例"" msgid ""NeCTAR"" msgstr ""NeCTAR"" msgid ""Deployment"" msgstr ""デプロイ"" msgid """" ""Compute nodes have 24 to 48 cores, with at least 4 GB of RAM per core and "" ""approximately 40 GB of ephemeral storage per core."" msgstr """" ""コンピュートノードは 24～48コアがあり、１コアあたり 4GB 以上の RAM があり、１"" ""コアあたり約 40GB 以上の一時ストレージがあります。"" msgid ""Resources"" msgstr ""情報源"" msgid ""MIT CSAIL"" msgstr ""MIT CSAIL"" msgid ""DAIR"" msgstr ""DAIR"" msgid ""CERN"" msgstr ""CERN"" msgid ""Image: Ubuntu 12.04 LTS"" msgstr ""イメージ: Ubuntu 12.04 LTS"" msgid ""Disk Size: minimum 5 GB"" msgstr ""ディスクサイズ: 最低 5 GB"" msgid ""username"" msgstr ""ユーザー名"" msgid ""horizon"" msgstr ""horizon"" msgid ""To create the middleware and plug it in through Paste configuration:"" msgstr ""ミドルウェアを作成して Paste の環境設定を通して組み込むためには："" msgid ""Press Up Arrow to bring up the last command."" msgstr ""上矢印キーを押し、最後のコマンドを表示させます。"" msgid ""Press Enter to run it."" msgstr ""Enter キーを押し、実行します。"" msgid """" ""Here we can see that the request was denied because the remote IP address "" ""wasn't in the set of allowed IPs."" msgstr """" ""ここで、リモートIPアドレスが、許可されたIPアドレスの中になかったため、リクエ"" ""ストが拒否されていることがわかります。"" msgid ""update_service_capabilities"" msgstr ""update_service_capabilities"" msgid ""hosts_up"" msgstr ""hosts_up"" msgid ""* <code>schedule_run_instance</code>"" msgstr ""* <code>schedule_run_instance</code>"" msgid ""key"" msgstr ""key"" msgid ""To create the scheduler and plug it in through configuration:"" msgstr ""スケジューラーを作成して、設定を通して組み込むためには："" msgid ""Conclusion"" msgstr ""まとめ"" msgid ""Upstream OpenStack"" msgstr ""OpenStack コミュニティ"" msgid ""Getting Help"" msgstr ""助けを得る"" msgid ""Reporting Bugs"" msgstr ""バグ報告"" msgid ""When you do this, the bug is created with:"" msgstr ""バグ報告をすると、バグは次のステータスで作成されます。"" msgid ""Status: <emphasis>New</emphasis>"" msgstr ""Status: <emphasis>New</emphasis>"" msgid """" ""This stage is about checking that a bug is real and assessing its impact. "" ""Some of these steps require bug supervisor rights (usually limited to core "" ""teams). If the bug lacks information to properly reproduce or assess the "" ""importance of the bug, the bug is set to:"" msgstr """" ""このステップでは、バグが実際に起こるかのチェックやその重要度の判定が行われま"" ""す。これらのステップを行うには、バグ管理者権限が必要なものがあります (通常、"" ""バグ管理者権限はコア開発者チームだけが持っています)。バグ報告に、バグを再現し"" ""たり、バグの重要度を判定したりするのに必要な情報が不足している場合、バグは"" msgid ""Status: <emphasis>Incomplete</emphasis>"" msgstr ""Status: <emphasis>Incomplete</emphasis>"" msgid ""Status: <emphasis>Confirmed</emphasis>"" msgstr ""Status: <emphasis>Confirmed</emphasis>"" msgid ""Core developers also prioritize the bug, based on its impact:"" msgstr ""にセットして下さい。"" msgid ""Importance: &lt;Bug impact&gt;"" msgstr ""Importance: &lt;バグ影響度&gt;"" msgid ""The bug impacts are categorized as follows:"" msgstr ""バグ影響度は以下のカテゴリに分かれています。"" msgid """" ""<emphasis>High</emphasis> if the bug prevents a key feature from working "" ""properly for some users (or with a workaround)"" msgstr """" ""<emphasis>High</emphasis> このバグにより、目玉となる機能が何人かユーザで正常"" ""に動作しない場合 (または簡単なワークアラウンドで動作する場合)"" msgid """" ""<emphasis>Medium</emphasis> if the bug prevents a secondary feature from "" ""working properly"" msgstr """" ""<emphasis>Medium</emphasis> このバグにより、ある程度重要な機能が正常に動作し"" ""ない場合"" msgid ""<emphasis>Low</emphasis> if the bug is mostly cosmetic"" msgstr ""<emphasis>Low</emphasis> このバグが多くの場合で軽微な場合"" msgid ""Bug Fixing"" msgstr ""バグ修正"" msgid ""Assignee: &lt;yourself&gt;"" msgstr ""Assignee: &lt;あなた自身&gt;"" msgid """" ""After the change is reviewed, accepted, and lands in master, it "" ""automatically moves to:"" msgstr """" ""変更がレビューされ、受理されて、マスターブランチにマージされると、バグの状態"" ""は自動的に以下のようになります。"" msgid """" ""When the fix makes it into a milestone or release branch, it automatically "" ""moves to:"" msgstr """" ""修正がマイルストーンやリリースブランチに取り込まれると、バグの状態は自動的に"" ""以下のようになります。"" msgid ""Milestone: Milestone the bug was fixed in"" msgstr ""Milestone: このバグの修正が入ったマイルストーン"" msgid ""Join the OpenStack Community"" msgstr ""OpenStack コミュニティに参加する"" msgid ""How to Contribute to the Documentation"" msgstr ""ドキュメント作成への貢献の仕方"" msgid ""Security Information"" msgstr ""セキュリティ情報"" msgid ""Vulnerability management"" msgstr ""脆弱性管理"" msgid ""Finding Additional Information"" msgstr ""さらに情報を見つける"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST"" msgid ""Architecture"" msgstr ""アーキテクチャ"" msgid """" ""Designing an OpenStack cloud is a great achievement. It requires a robust "" ""understanding of the requirements and needs of the cloud's users to "" ""determine the best possible configuration to meet them. OpenStack provides a "" ""great deal of flexibility to achieve your needs, and this part of the book "" ""aims to shine light on many of the decisions you need to make during the "" ""process."" msgstr """" ""OpenStack クラウドの設計は重要な作業です。クラウドのユーザーの要件とニーズを"" ""確実に理解して、それらに対応するために可能な限り最良の構成を決定する必要があ"" ""ります。OpenStack は、ユーザーのニーズを満たすための優れた柔軟性を提供しま"" ""す。本セクションでは、このようなプロセスで行う必要のある数多くの決定事項を明"" ""確に説明することを目的としています。"" msgid """" ""To design, deploy, and configure OpenStack, administrators must understand "" ""the logical architecture. A diagram can help you envision all the integrated "" ""services within OpenStack and how they interact with each other.<indexterm "" ""class=\""singular\""><primary>modules, types of</primary></"" ""indexterm><indexterm class=\""singular\""><primary>OpenStack</"" ""primary><secondary>module types in</secondary></indexterm>"" msgstr """" ""OpenStack の設計、デプロイ、および構成を行うにあたって、管理者は論理アーキテ"" ""クチャを理解するが必要があります。OpenStack 内で統合される全サービスおよびそ"" ""れらがどのように相互作用するかについての構想を立てるには、図が役立ちます。"" ""<indexterm class=\""singular\""><primary>モジュール、タイプ</primary></"" ""indexterm><indexterm class=\""singular\""><primary>OpenStack</"" ""primary><secondary>モジュールタイプ</secondary></indexterm>"" msgid ""OpenStack modules are one of the following types:"" msgstr ""OpenStack のモジュールは、以下の種別のいずれかです。"" msgid ""Daemon"" msgstr ""デーモン"" msgid """" ""Runs as a background process. On Linux platforms, a daemon is usually "" ""installed as a service.<indexterm class=\""singular\""><primary>daemons</"" ""primary><secondary>basics of</secondary></indexterm>"" msgstr """" ""バックグラウンドプロセスとして実行されます。Linux プラットフォームでは、デー"" ""モンは通常サービスとしてインストールされます。<indexterm class=\""singular"" ""\""><primary>デーモン</primary><secondary>基本</secondary></indexterm>"" msgid ""Script"" msgstr ""スクリプト"" msgid """" ""Installs a virtual environment and runs tests.<indexterm class=\""singular"" ""\""><primary>script modules</primary></indexterm>"" msgstr """" ""仮想環境をインストールし、テストを実行します。<indexterm class=\""singular"" ""\""><primary>スクリプトモジュール</primary></indexterm>"" msgid ""Command-line interface (CLI)"" msgstr ""コマンドラインインターフェース (CLI)"" msgid """" ""Enables users to submit API calls to OpenStack services through commands."" ""<indexterm class=\""singular\""><primary>Command-line interface (CLI)</"" ""primary></indexterm>"" msgstr """" ""ユーザーはコマンドを使用して API コールを OpenStack サービスに送信できます。"" ""<indexterm class=\""singular\""><primary>コマンドラインインターフェース (CLI)</"" ""primary></indexterm>"" msgid """" ""As shown, end users can interact through the dashboard, CLIs, and APIs. All "" ""services authenticate through a common Identity Service, and individual "" ""services interact with each other through public APIs, except where "" ""privileged administrator commands are necessary. <xref linkend=\""openstack-"" ""diagram\""/> shows the most common, but not the only logical architecture for "" ""an OpenStack cloud."" msgstr """" ""下図に示したように、エンドユーザーはダッシュボード、CLI、および API を使用し"" ""て対話することができます。サービスはすべて、共通の Identity Service を介して"" ""認証を行い、またサービス相互間の対話は、特権のある管理者がコマンドを実行する"" ""必要がある場合を除いてパブリック API を使用して行われます。<xref linkend="" ""\""openstack-diagram\""/> には、OpenStack の最も一般的な論理アーキテクチャを示"" ""しています。ただし、これは唯一のアーキテクチャではありません。"" msgid """" ""OpenStack Logical Architecture (<link href=\""http://docs.openstack.org/"" ""openstack-ops/content/figures/2/figures/osog_0001.png\""/>)"" msgstr """" ""OpenStack の論理アーキテクチャ (<link href=\""http://docs.openstack.org/"" ""openstack-ops/content/figures/2/figures/osog_0001.png\""/>)"" msgid ""OpenStack Cloud Administrator Guide"" msgstr ""OpenStack クラウド管理者ガイド"" msgid ""Python"" msgstr ""Python"" msgid ""Networking"" msgstr ""ネットワーク"" msgid ""Virtualization"" msgstr ""仮想化"" msgid ""Configuration Management"" msgstr ""構成管理"" msgid ""Example Architectures"" msgstr ""アーキテクチャの例"" msgid """" ""To understand the possibilities OpenStack offers, it's best to start with "" ""basic architectures that are tried-and-true and have been tested in "" ""production environments. We offer two such examples with basic pivots on the "" ""base operating system (Ubuntu and Red Hat Enterprise Linux) and the "" ""networking architectures. There are other differences between these two "" ""examples, but you should find the considerations made for the choices in "" ""each as well as a rationale for why it worked well in a given environment."" msgstr """" ""OpenStack が提供する可能性を理解するには、確実に信頼できる、本番環境での検証"" ""済みの基本アーキテクチャから開始するのが最善の方法です。本ガイドでは、ベース"" ""オペレーティングシステム (Ubuntu および Red Hat Enterprise Linux) 上に基本ピ"" ""ボットとネットワークアーキテクチャを備えた基本アーキテクチャの例を 2 つ紹介し"" ""ています。これらの 2 つの例では、他にも相違点がありますが、各例で選択にあたっ"" ""て考慮した点と、それらのアーキテクチャが特定の環境で適切に機能するための設定"" ""指針をご理解いただけるはずです。"" msgid """" ""Because OpenStack is highly configurable, with many different backends and "" ""network configuration options, it is difficult to write documentation that "" ""covers all possible OpenStack deployments. Therefore, this guide defines "" ""example architectures to simplify the task of documenting, as well as to "" ""provide the scope for this guide. Both of the offered architecture examples "" ""are currently running in production and serving users."" msgstr """" ""OpenStack は、多数の異なるバックエンドおよびネットワーク設定オプションを利用"" ""して高度に設定することが可能です。可能な OpenStack デプロイメントをすべて網羅"" ""するドキュメントを執筆するのは難しいため、本ガイドではアーキテクチャの例を定"" ""義することによって文書化の作業を簡素化すると共に、本書のスコープを規定しま"" ""す。以下に紹介するアーキテクチャの例はいずれも本番環境で現在実行中であり、"" ""ユーザーにサービスを提供しています。"" msgid """" ""As always, refer to the <xref linkend=\""openstack_glossary\""/> if you are "" ""unclear about any of the terminology mentioned in these architectures."" msgstr """" ""これらのアーキテクチャで言及されている用語が明確に理解できない場合には、通常"" ""通り <xref linkend=\""openstack_glossary\""/> を参照してください。"" msgid ""Parting Thoughts on Architectures"" msgstr ""アーキテクチャについての章の結び"" msgid """" ""With so many considerations and options available, our hope is to provide a "" ""few clearly-marked and tested paths for your OpenStack exploration. If "" ""you're looking for additional ideas, check out <xref linkend=\""use-cases\""/"" "">, the <link href=\""http://docs.openstack.org/\"">OpenStack Installation "" ""Guides</link>, or the <link href=\""http://www.openstack.org/user-stories/"" ""\"">OpenStack User Stories page</link>."" msgstr """" ""数多くの考慮事項およびオプションがあるため、本セクションでは、OpenStack をお"" ""試しいただくための明確に記載した検証済みの方法を提供するように構成していま"" ""す。本セクションに記載した以外の情報をお探しの場合には、<xref linkend=\""use-"" ""cases\""/>、<link href=\""http://docs.openstack.org/\"">OpenStack Installation "" ""Guides</link>、または <link href=\""http://www.openstack.org/user-stories/"" ""\"">OpenStack User Stories page</link> をご確認ください。"" msgid ""Images"" msgstr ""イメージ"" msgid ""Adding Images"" msgstr ""イメージの追加"" msgid ""Run the following command to view the properties of existing images:"" msgstr """" ""既存のイメージのプロパティを表示するために、以下のコマンドを実行します。"" msgid ""For example:"" msgstr ""例えば"" msgid ""Deleting Images"" msgstr ""イメージの削除"" msgid ""Other CLI Options"" msgstr ""他の CLI オプション"" msgid ""images"" msgstr ""images"" msgid ""image_properties"" msgstr ""image_properties"" msgid ""Another example is displaying all properties for a certain image:"" msgstr """" ""もう一つの例は、特定のイメージに関するすべてのプロパティを表示することです。"" msgid ""Flavors"" msgstr ""フレーバー"" msgid """" ""The <code>nova flavor-create</code> command allows authorized users to "" ""create new flavors. Additional flavor manipulation commands can be shown "" ""with the command: <placeholder-1/>"" msgstr """" ""<code>nova flavor-create</code> コマンドにより、権限のあるユーザーが新しいフ"" ""レーバーを作成できます。さらなるフレーバーの操作コマンドは次のコマンドを用い"" ""て表示できます: <placeholder-1/>"" msgid ""Flavor parameters"" msgstr ""フレーバーのパラメーター"" msgid ""Column"" msgstr ""項目"" msgid ""ID"" msgstr ""ID"" msgid ""Name"" msgstr ""名前"" msgid ""Memory_MB"" msgstr ""Memory_MB"" msgid ""Virtual machine memory in megabytes."" msgstr ""メガバイト単位の仮想マシンメモリー。"" msgid ""Disk"" msgstr ""ディスク"" msgid """" ""Virtual root disk size in gigabytes. This is an ephemeral disk the base "" ""image is copied into. You don't use it when you boot from a persistent "" ""volume. The \""0\"" size is a special case that uses the native base image "" ""size as the size of the ephemeral root volume."" msgstr """" ""ギガバイト単位の仮想ルートディスク容量。これはベースイメージがコピーされる一"" ""時ディスクです。永続的なボリュームからブートするとき、これは使用されません。"" ""「0」という容量は特別な値で、一時ルートボリュームの容量としてベースイメージの"" ""ネイティブ容量をそのまま使用することを意味します。"" msgid ""Ephemeral"" msgstr ""エフェメラル"" msgid """" ""Specifies the size of a secondary ephemeral data disk. This is an empty, "" ""unformatted disk and exists only for the life of the instance."" msgstr """" ""二次的な一時データディスクの容量を指定します。これは空の、フォーマットされて"" ""いないディスクです。インスタンスの生存期間だけ存在します。"" msgid ""Swap"" msgstr ""スワップ"" msgid ""Optional swap space allocation for the instance."" msgstr ""インスタンスに割り当てられるスワップ空間。これはオプションです。"" msgid ""VCPUs"" msgstr ""仮想 CPU"" msgid ""Number of virtual CPUs presented to the instance."" msgstr ""インスタンスに存在する仮想 CPU 数。"" msgid ""RXTX_Factor"" msgstr ""RXTX_Factor"" msgid ""Is_Public"" msgstr ""Is_Public"" msgid ""extra_specs"" msgstr ""extra_specs"" msgid ""Security Groups"" msgstr ""セキュリティグループ"" msgid ""To view the details of the \""open\"" security group:"" msgstr ""「open」セキュリティグループの詳細を表示する方法:"" msgid ""Block Storage"" msgstr ""ブロックストレージ"" msgid ""Block Storage Creation Failures"" msgstr ""ブロックストレージの作成エラー"" msgid ""Instances"" msgstr ""インスタンス"" msgid ""Starting Instances"" msgstr ""インスタンスの起動"" msgid """" ""It is important to note that powering off an instance does not terminate it "" ""in the OpenStack sense."" msgstr """" ""注意すべき大事な点は、インスタンスの電源オフは、OpenStack 的な意味でのインス"" ""タンスの終了ではないということです。"" msgid ""Instance Boot Failures"" msgstr ""インスタンスの起動失敗"" msgid """" ""You must have the matching private key to access instances associated with "" ""this key."" msgstr """" ""この鍵と関連付けられたインスタンスにアクセスするために、対応する秘密鍵を持つ"" ""必要があります。"" msgid ""Associating Security Groups"" msgstr ""セキュリティグループの割り当て"" msgid ""Floating IPs"" msgstr ""Floating IP"" msgid ""Attaching Block Storage"" msgstr ""ブロックストレージの接続"" msgid ""To perform this action from command line, run the following command:"" msgstr """" ""このアクションをコマンドラインから実行するには、以下のコマンドを実行します"" msgid ""dev-name"" msgstr ""dev-name"" msgid ""id"" msgstr ""id"" msgid ""type"" msgstr ""type"" msgid ""size (GB)"" msgstr ""size (GB)"" msgid ""delete-on-terminate"" msgstr ""delete-on-terminate"" msgid """" ""A boolean to indicate whether the volume should be deleted when the instance "" ""is terminated. True can be specified as <literal>True</literal> or "" ""<literal>1</literal>. False can be specified as <literal>False</literal> or "" ""<literal>0</literal>."" msgstr """" ""インスタンスが終了したときに、ボリュームが削除されるかどうかを指示する論理値"" ""です。真は <literal>True</literal> または <literal>1</literal> として指定でき"" ""ます。偽は <literal>False</literal> または <literal>0</literal> として指定で"" ""きます。"" msgid ""Taking Snapshots"" msgstr ""スナップショットの取得"" msgid ""Instance snapshots"" msgstr ""インスタンスのスナップショット"" msgid ""Volume snapshots"" msgstr ""ボリュームのスナップショット"" msgid ""Value"" msgstr ""値"" msgid ""image_type"" msgstr ""image_type"" msgid ""snapshot"" msgstr ""スナップショット"" msgid ""instance_uuid"" msgstr ""instance_uuid"" msgid ""&lt;uuid of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの UUID&gt;"" msgid ""base_image_ref"" msgstr ""base_image_ref"" msgid ""&lt;uuid of original image of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの元イメージの UUID&gt;"" msgid ""image_location"" msgstr ""image_location"" msgid """" ""A snapshot captures the state of the file system, but not the state of the "" ""memory. Therefore, to ensure your snapshot contains the data that you want, "" ""before your snapshot you need to ensure that:"" msgstr """" ""スナップショットは、ファイルシステムの状態をキャプチャーしますが、メモリーの"" ""状態をキャプチャーしません。そのため、スナップショットに期待するデータが含ま"" ""れることを確実にするために、次のことを確実にする必要があります。"" msgid ""Running programs have written their contents to disk"" msgstr ""実行中のプログラムがコンテンツをディスクに書き込んだこと"" msgid """" ""The file system does not have any \""dirty\"" buffers: where programs have "" ""issued the command to write to disk, but the operating system has not yet "" ""done the write"" msgstr """" ""ファイルシステムが「ダーティー」バッファーを持たないこと: 「ダーティー」バッ"" ""ファーがあるとは、プログラムがディスクに書き込むためにコマンドを発行しました"" ""が、オペレーティングシステムがまだ書き込みを完了していないことです。"" msgid """" ""To deal with the \""dirty\"" buffer issue, we recommend using the sync command "" ""before snapshotting:"" msgstr """" ""「ダーティー」バッファーの問題を解決するために、スナップショットの前に sync "" ""コマンドを使用することを推奨します。"" msgid """" ""When the snapshot is done, you can thaw the file system with the following "" ""command, as root, inside of the instance:"" msgstr """" ""スナップショットの作成が終わったら、インスタンスの中で root として以下のコマ"" ""ンドを用いて、ファイルシステムをフリーズ解除できます。"" msgid ""Instances in the Database"" msgstr ""データベースにあるインスタンス"" msgid ""created_at"" msgstr ""created_at"" msgid ""updated_at"" msgstr ""updated_at"" msgid ""deleted_at"" msgstr ""deleted_at"" msgid ""scheduled_at"" msgstr ""scheduled_at"" msgid ""launched_at"" msgstr ""launched_at"" msgid ""terminated_at"" msgstr ""terminated_at"" msgid ""Upgrades"" msgstr ""アップグレード"" msgid ""The upgrade process generally follows these steps:"" msgstr ""一般的に、アップグレード作業は以下の手順で行います。"" msgid ""Read the release notes and documentation."" msgstr ""リリースノートとドキュメントを読みます。"" msgid ""Upgrade the OpenStack Image service (glance)."" msgstr ""OpenStack Image サービス (glance) をアップグレードします。"" msgid ""Upgrade OpenStack Compute (nova), including networking components."" msgstr """" ""OpenStack Compute (nova) とネットワークコンポーネントをアップグレードする。"" msgid ""Upgrade OpenStack Block Storage (cinder)."" msgstr ""OpenStack Block Storage (cinder) をアップグレードする。"" msgid ""Create a backup of configuration files and databases."" msgstr ""設定ファイルとデータベースのバックアップを作成します。"" msgid ""Update the configuration files according to the release notes."" msgstr ""リリースノートに従って設定ファイルを更新します。"" msgid ""OpenStack Identity"" msgstr ""OpenStack Identity"" msgid ""OpenStack Compute"" msgstr ""OpenStack Compute"" msgid ""OpenStack Block Storage"" msgstr ""OpenStack Block Storage"" msgid ""controller"" msgstr ""controller"" msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" msgid """" ""Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose "" ""for the <literal>guest</literal> account in <application>RabbitMQ</"" ""application>."" msgstr """" ""<replaceable>RABBIT_PASS</replaceable> を <application>RabbitMQ</"" ""application> の <literal>guest</literal> アカウント用に選んだパスワードで置き"" ""換えます。"" msgid ""Start the services:"" msgstr ""サービスを起動します。"" msgid """" ""Replace <replaceable>NEUTRON_DBPASS</replaceable> with the password you "" ""chose for the database."" msgstr """" ""<replaceable>NEUTRON_PASS</replaceable> をデータベース用に選んだパスワードで"" ""置き換えます。"" msgid ""SERVICE_TENANT_ID"" msgstr ""SERVICE_TENANT_ID"" msgid ""NOVA_PASS"" msgstr ""NOVA_PASS"" msgid ""Restart Networking services:"" msgstr ""Networking サービスを再起動します。"" msgid ""Restart Compute services:"" msgstr ""Compute サービスを再起動します。"" msgid ""Before you begin"" msgstr ""始める前に"" msgid """" ""Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, "" ""and <literal>auth_protocol</literal> options because the "" ""<literal>identity_uri</literal> option replaces them."" msgstr """" ""<literal>identity_uri</literal> オプションにより置き換えられるので、"" ""<literal>auth_host</literal>、<literal>auth_port</literal>、"" ""<literal>auth_protocol</literal> オプションをコメントアウトします。"" msgid ""Identity service"" msgstr ""Identity"" msgid """" ""In the <literal>[token]</literal> section, configure the UUID token provider "" ""and SQL driver:"" msgstr """" ""<literal>[token]</literal> セクションに、UUID トークンプロバイダーと SQL ドラ"" ""イバーを設定します。"" msgid ""Image service"" msgstr ""Image サービス"" msgid ""Compute service"" msgstr ""Compute サービス"" msgid ""Edit the <filename>/etc/nova/nova.conf</filename> file:"" msgstr ""<filename>/etc/nova/nova.conf</filename> ファイルを編集します。"" msgid ""Dashboard"" msgstr ""ダッシュボード"" msgid ""Restart the services."" msgstr ""サービスを再起動します。"" msgid ""Compute nodes"" msgstr ""コンピュートノード"" msgid ""Storage nodes"" msgstr ""ストレージノード"" msgid ""Preface"" msgstr ""はじめに"" msgid """" ""OpenStack is an open source platform that lets you build an Infrastructure "" ""as a Service (IaaS) cloud that runs on commodity hardware."" msgstr """" ""OpenStack はオープンソースプラットフォームで、OpenStack を使うと、コモディ"" ""ティハードウェア上で動作する Infrastructure as a Service (IaaS) クラウドを自"" ""分で構築できます。"" msgid ""Introduction to OpenStack"" msgstr ""OpenStack の概要"" msgid ""Who This Book Is For"" msgstr ""この本の対象読者"" msgid """" ""One of the most complex aspects of an OpenStack cloud is the networking "" ""configuration. You should be familiar with concepts such as DHCP, Linux "" ""bridges, VLANs, and iptables. You must also have access to a network "" ""hardware expert who can configure the switches and routers required in your "" ""OpenStack cloud."" msgstr """" ""OpenStack クラウドの最も複雑な点の一つにネットワーク設定があります。DHCP、"" ""Linux ブリッジ、VLAN、iptables といった考え方をよく理解していなければなりませ"" ""ん。OpenStack クラウドで必要となるスイッチやルータを設定できるネットワーク"" ""ハードウェアの専門家と話をする必要もあります。"" msgid ""OpenStack Guides"" msgstr ""OpenStack の各種ガイド"" msgid ""OpenStack Installation Guides"" msgstr ""OpenStack インストールガイド"" msgid ""OpenStack Configuration Reference"" msgstr ""OpenStack 設定レファレンス"" msgid ""OpenStack High Availability Guide"" msgstr ""OpenStack 高可用性ガイド"" msgid ""OpenStack Security Guide"" msgstr ""OpenStack セキュリティガイド"" msgid ""Virtual Machine Image Guide"" msgstr ""仮想マシンイメージガイド"" msgid ""OpenStack End User Guide"" msgstr ""OpenStack エンドユーザーガイド"" msgid ""OpenStack Admin User Guide"" msgstr ""OpenStack 管理ユーザーガイド"" msgid ""OpenStack API Quick Start"" msgstr ""OpenStack API クイックスタート"" msgid ""How This Book Is Organized"" msgstr ""この本の構成"" msgid ""Why and How We Wrote This Book"" msgstr ""この本をなぜ書いたか？どうやって書いたか？"" msgid ""Perform the day-to-day tasks required to administer a cloud."" msgstr ""クラウドを管理する上で必要となる日々のタスクの実行。"" msgid ""We wrote this book to help you:<placeholder-1/>"" msgstr """" ""次のような場面であなたの助けとなるように、この本を書きました。<placeholder-1/"" "">"" msgid """" ""We wrote furiously from our own experiences and bounced ideas between each "" ""other. At regular intervals we reviewed the shape and organization of the "" ""book and further molded it, leading to what you see today."" msgstr """" ""私たちは一心不乱に自分たちの経験に基づき執筆を行い、互いに意見をぶつけ合いま"" ""した。一定の間隔で、本の現在の状況や構成をレビューし、本を作り上げていき、今"" ""皆さんが見ているものができあがりました。"" msgid ""The team includes:"" msgstr ""以下が執筆チームのメンバーです。"" msgid ""Adam Hyde"" msgstr ""Adam Hyde"" msgid ""How to Contribute to This Book"" msgstr ""この本の作成に参加するには"" msgid ""Command prompts"" msgstr ""コマンドプロンプト"" msgid """" ""Commands prefixed with the <literal>$</literal> prompt can be executed by "" ""any user, including <literal>root</literal>."" msgstr """" ""<literal>$</literal> プロンプトから始まるコマンドは、<literal>root</literal> "" ""を含む、すべてのユーザーにより実行できます。"" msgid ""Scaling"" msgstr ""スケーリング"" msgid """" ""Whereas traditional applications required larger hardware to scale "" ""(\""vertical scaling\""), cloud-based applications typically request more, "" ""discrete hardware (\""horizontal scaling\""). If your cloud is successful, "" ""eventually you must add resources to meet the increasing demand.<indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>vertical vs. "" ""horizontal</secondary></indexterm>"" msgstr """" ""従来のアプリケーションでは、スケーリングするには、より大きいハードウェアが必"" ""要でした (垂直スケーリング) が、クラウドベースのアプリケーションは通常、別の"" ""ハードウェアを必要とします(水平スケーリング)。クラウドを正常に設定できた場"" ""合、需要が増すとそれに合うようにリソースを追加する必要がでてきます。"" ""<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>垂直 "" ""vs 水平</secondary></indexterm>"" msgid """" ""To suit the cloud paradigm, OpenStack itself is designed to be horizontally "" ""scalable. Rather than switching to larger servers, you procure more servers "" ""and simply install identically configured services. Ideally, you scale out "" ""and load balance among groups of functionally identical services (for "" ""example, compute nodes or <literal>nova-api</literal> nodes), that "" ""communicate on a message bus."" msgstr """" ""クラウドのパラダイムに合わせるため、OpenStack は水平的にスケーリングできるよ"" ""うに設計されています。容量の大きいサーバーに切り替えるのではなく、サーバーを"" ""多く調達して同じように設定したサービスをインストールするだけです。理想として"" ""は、メッセージバスを通信する、機能的に同じサービス (例: コンピュートノードや "" ""<literal>nova-api</literal> ノード) グループでスケールアウト、負荷分散しま"" ""す。"" msgid ""The Starting Point"" msgstr ""出発点"" msgid """" ""Determining the scalability of your cloud and how to improve it is an "" ""exercise with many variables to balance. No one solution meets everyone's "" ""scalability goals. However, it is helpful to track a number of metrics. "" ""Since you can define virtual hardware templates, called \""flavors\"" in "" ""OpenStack, you can start to make scaling decisions based on the flavors "" ""you'll provide. These templates define sizes for memory in RAM, root disk "" ""size, amount of ephemeral data disk space available, and number of cores for "" ""starters.<indexterm class=\""singular\""><primary>virtual machine (VM)</"" ""primary></indexterm><indexterm class=\""singular\""><primary>hardware</"" ""primary><secondary>virtual hardware</secondary></indexterm><indexterm class="" ""\""singular\""><primary>flavor</primary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>metrics for</secondary></indexterm>"" msgstr """" ""多くのアイテムでバランスを取りながら、クラウドのスケーラビリティや改善方法を"" ""決定していきます。ソリューション 1 つだけでは、スケーラビリティの目的を達成す"" ""ることはできません。しかし、複数のメトリクスをトラッキングすると役に立ちま"" ""す。仮想ハードウェアのテンプレート (OpenStack ではフレーバーと呼ばれる) を定"" ""義できるため、用意するフレーバーをもとにスケーリングの意思決定を行うことがで"" ""きます。これらのテンプレートは、メモリーのサイズ (RAM)、root ディスクのサイ"" ""ズ、一時データディスクの空き容量、スターターのコア数を定義します。<indexterm "" ""class=\""singular\""><primary>仮想マシン</primary></indexterm><indexterm class="" ""\""singular\""><primary>ハードウェア</primary><secondary>仮想ハードウェア</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>フレーバー</"" ""primary></indexterm><indexterm class=\""singular\""><primary>スケーリング</"" ""primary><secondary>メトリクス</secondary></indexterm>"" msgid """" ""The default OpenStack flavors are shown in <xref linkend=\""os-flavors-table"" ""\""/>."" msgstr """" ""デフォルトの OpenStack フレーバーは <xref linkend=\""os-flavors-table\""/> に表"" ""示されています。"" msgid ""OpenStack default flavors"" msgstr ""OpenStack デフォルトのフレーバー"" msgid ""Virtual cores"" msgstr ""仮想コア数"" msgid ""Memory"" msgstr ""メモリ"" msgid ""m1.tiny"" msgstr ""m1.tiny"" msgid ""1"" msgstr ""1"" msgid ""512 MB"" msgstr ""512 MB"" msgid ""1 GB"" msgstr ""1 GB"" msgid ""0 GB"" msgstr ""0 GB"" msgid ""m1.small"" msgstr ""m1.small"" msgid ""2 GB"" msgstr ""2 GB"" msgid ""10 GB"" msgstr ""10 GB"" msgid ""20 GB"" msgstr ""20 GB"" msgid ""m1.medium"" msgstr ""m1.medium"" msgid ""2"" msgstr ""2"" msgid ""4 GB"" msgstr ""4 GB"" msgid ""40 GB"" msgstr ""40 GB"" msgid ""m1.large"" msgstr ""m1.large"" msgid ""4"" msgstr ""4"" msgid ""8 GB"" msgstr ""8 GB"" msgid ""80 GB"" msgstr ""80 GB"" msgid ""m1.xlarge"" msgstr ""m1.xlarge"" msgid ""8"" msgstr ""8"" msgid ""16 GB"" msgstr ""16 GB"" msgid ""160 GB"" msgstr ""160 GB"" msgid """" ""The number of virtual machines (VMs) you expect to run, <code>((overcommit "" ""fraction </code>"" msgstr ""実行する必要のある仮想マシン数。<code>((overcommit fraction </code>"" msgid ""How much storage is required <code>(flavor disk size </code>"" msgstr ""必要とされるストレージ容量<code>(flavor disk size </code>"" msgid """" ""The starting point for most is the core count of your cloud. By applying "" ""some ratios, you can gather information about: <placeholder-1/> You can use "" ""these ratios to determine how much additional infrastructure you need to "" ""support your cloud."" msgstr """" ""多くの場合、クラウドのコア数から始めます。比率を適用することで、 "" ""<placeholder-1/> に関する情報を取得できます。これらの比率を使用して、クラウド"" ""のサポートに必要なインフラストラクチャーがどの程度必要か判断することができま"" ""す。"" msgid ""200 physical cores."" msgstr ""物理コア 200 個"" msgid """" ""Most instances are size m1.medium (two virtual cores, 50 GB of storage)."" msgstr """" ""ほとんどのインスタンスのサイズは m1.medium (仮想コア数2、ストレージ50GB) とし"" ""ます。"" msgid """" ""Default CPU overcommit ratio (<code>cpu_allocation_ratio</code> in nova."" ""conf) of 16:1."" msgstr """" ""デフォルトの CPU オーバーコミット比率 (<code>cpu_allocation_ratio</code> in "" ""nova.conf) は 16:1 とします。"" msgid """" ""However, you need more than the core count alone to estimate the load that "" ""the API services, database servers, and queue servers are likely to "" ""encounter. You must also consider the usage patterns of your cloud."" msgstr """" ""しかし、APIサービスやデータベースサーバー、MQサーバーがおそらく遭遇する負荷を"" ""見積もるためには、コア数以外の検討も行う必要があります。クラウドの利用パター"" ""ンも考慮しなければなりません。"" msgid """" ""As a specific example, compare a cloud that supports a managed web-hosting "" ""platform with one running integration tests for a development project that "" ""creates one VM per code commit. In the former, the heavy work of creating a "" ""VM happens only every few months, whereas the latter puts constant heavy "" ""load on the cloud controller. You must consider your average VM lifetime, as "" ""a larger number generally means less load on the cloud controller.<indexterm "" ""class=\""singular\""><primary>cloud controllers</"" ""primary><secondary>scalability and</secondary></indexterm>"" msgstr """" ""特定の例としては、マネージド Web ホスティングプラットフォームをサポートするク"" ""ラウドと、コードコミットごとに仮想マシンを１つ作成するような開発プロジェクト"" ""の統合テストを実行するクラウドを比較してみましょう。前者では、VMを作成する負"" ""荷の大きい処理は数か月に 一度しか発生しないのに対して、後者ではクラウドコント"" ""ローラに常に負荷の大きい処理が発生します。一般論として、VMの平均寿命が長いと"" ""いうことは、クラウドコントローラの負荷が軽いことを意味するため、平均的なVMの"" ""寿命を検討する必要があります。<indexterm class=\""singular\""><primary>クラウド"" ""コントローラー</primary><secondary>スケーラビリティ</secondary></indexterm>"" msgid """" ""Aside from the creation and termination of VMs, you must consider the impact "" ""of users accessing the service—particularly on <literal>nova-api</literal> "" ""and its associated database. Listing instances garners a great deal of "" ""information and, given the frequency with which users run this operation, a "" ""cloud with a large number of users can increase the load significantly. This "" ""can occur even without their knowledge—leaving the OpenStack dashboard "" ""instances tab open in the browser refreshes the list of VMs every 30 seconds."" msgstr """" ""仮想マシンの作成、停止以外に、特に <literal>nova-api</literal> や関連のデータ"" ""ベースといったサービスにアクセスする際の影響について考慮する必要があります。"" ""インスタンスを一覧表示することで膨大な量の情報を収集し、この操作の実行頻度を"" ""前提として、ユーザー数の多いクラウドで負荷を大幅に増加させることができます。"" ""これはユーザーには透過的に行われます。OpenStack のダッシュボードをブラウザで"" ""開いた状態にすると、仮想マシンの一覧が 30 秒毎に更新されます。"" msgid """" ""After you consider these factors, you can determine how many cloud "" ""controller cores you require. A typical eight core, 8 GB of RAM server is "" ""sufficient for up to a rack of compute nodes — given the above caveats."" msgstr """" ""これらの要素を検討した後、クラウドコントローラにどのくらいのコア数が必要なの"" ""か決定することができます。上記で説明した留意事項の下、典型的には、ラック 1 本"" ""分のコンピュートノードに対して8 コア、メモリ 8GB のサーバで充分です。"" msgid """" ""You must also consider key hardware specifications for the performance of "" ""user VMs, as well as budget and performance needs, including storage "" ""performance (spindles/core), memory availability (RAM/core), network "" ""bandwidth<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>hardware specifications and</secondary></indexterm> (Gbps/"" ""core), and overall CPU performance (CPU/core)."" msgstr """" ""また、仮想マシンのパフォーマンス、ストレージの性能 (スピンドル/コア)、メモ"" ""リーの空き容量 (RAM/コア)、ネットワークの帯域幅など、予算や性能のニーズに関し"" ""て、主なハードウェアの仕様を考慮する必要もあります。<indexterm class="" ""\""singular\""><primary>帯域幅</primary><secondary>ハードウェアの仕様</"" ""secondary></indexterm> (Gbps/コア)、全体的な CPU のパフォーマンス (CPU/コア)"" msgid """" ""For a discussion of metric tracking, including how to extract metrics from "" ""your cloud, see <xref linkend=\""logging_monitoring\""/>."" msgstr """" ""クラウドからメトリクスを抽出する方法など、メトリクスの追跡については、<xref "" ""linkend=\""logging_monitoring\""/> を参照してください。"" msgid ""Adding Cloud Controller Nodes"" msgstr ""クラウドコントローラーノードの追加"" msgid """" ""You can facilitate the horizontal expansion of your cloud by adding nodes. "" ""Adding compute nodes is straightforward—they are easily picked up by the "" ""existing installation. However, you must consider some important points when "" ""you design your cluster to be highly available.<indexterm class=\""singular"" ""\""><primary>compute nodes</primary><secondary>adding</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>high availability</"" ""primary></indexterm><indexterm class=\""singular\""><primary>configuration "" ""options</primary><secondary>high availability</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>cloud controller nodes</"" ""primary><secondary>adding</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>adding cloud controller nodes</"" ""secondary></indexterm>"" msgstr """" ""ノードを追加することで、垂直に拡張するのが容易になります。コンピュートノード"" ""の追加は単純で、既存のインストール環境から簡単にピックアップすることができま"" ""す。しかし、高可用性のクラスターを設計するには、重要なポイントを考慮する必要"" ""があります。<indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>追加</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>高可用性</primary></indexterm><indexterm class=\""singular"" ""\""><primary>設定オプション</primary><secondary>高可用性</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>クラウドコントローラーノード"" ""</primary><secondary>追加</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>クラウドコントローラーノードの追"" ""加</secondary></indexterm>"" msgid """" ""Recall that a cloud controller node runs several different services. You can "" ""install services that communicate only using the message queue internally—"" ""<code>nova-scheduler</code> and <code>nova-console</code>—on a new server "" ""for expansion. However, other integral parts require more care."" msgstr """" ""クラウドコントローラは、異なるサービスを複数実行することを思い出してくださ"" ""い。拡張のための新しいサーバには、<code>nova-scheduler</code> や <code>nova-"" ""console</code> のようなメッセージキューのみを使用して内部通信を行うサービスを"" ""インストールすることができます。しかし、その他の不可欠な部分はさらに細心の注"" ""意が必要です。"" msgid """" ""You can configure some services, such as <code>nova-api</code> and "" ""<code>glance-api</code>, to use multiple processes by changing a flag in "" ""their configuration file—allowing them to share work between multiple cores "" ""on the one machine."" msgstr """" ""<code>nova-api</code> や <code>glance-api</code> などのサービスは、環境設定"" ""ファイルのフラグを変更することによって複数プロセスで処理させるように設定でき"" ""ます。これによって 1 台のサーバー上にある複数のコアの間で処理を共有できるよう"" ""になります。"" msgid """" ""Several options are available for MySQL load balancing, and the supported "" ""AMQP brokers have built-in clustering support. Information on how to "" ""configure these and many of the other services can be found in <xref linkend="" ""\""operations\"" xrefstyle=\""part-num-title\""/>.<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgstr """" ""MySQL の負荷分散には複数のオプションがあり、サポートされている AMQP ブロー"" ""カーにはクラスタリングサポートが含まれています。これらの設定方法やその他多く"" ""のサービスに関する情報は、 <xref linkend=\""operations\"" xrefstyle=\""part-num-"" ""title\""/> を参照してください。<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgid ""Segregating Your Cloud"" msgstr ""クラウドの分離"" msgid """" ""When you want to offer users different regions to provide legal "" ""considerations for data storage, redundancy across earthquake fault lines, "" ""or for low-latency API calls, you segregate your cloud. Use one of the "" ""following OpenStack methods to segregate your cloud: <emphasis>cells</"" ""emphasis>, <emphasis>regions</emphasis>, <emphasis>availability zones</"" ""emphasis>, or <emphasis>host aggregates</emphasis>.<indexterm class="" ""\""singular\""><primary>segregation methods</primary></indexterm><indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>cloud segregation</"" ""secondary></indexterm>"" msgstr """" ""法的に考慮したデータストレージ、耐震ラインでの冗長性、低遅延の API コールを提"" ""供する様々なリージョンを提供するには、クラウドを分割します。<emphasis>セル</"" ""emphasis>、<emphasis>リージョン</emphasis>、<emphasis>アベイラビリティゾーン"" ""</emphasis>、<emphasis>ホストアグリゲート</emphasis> のいずれかの OpenStack "" ""メソッドを使用して、クラウドを分割します。<indexterm class=\""singular"" ""\""><primary>分割メソッド</primary></indexterm><indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>クラウド分割</secondary></"" ""indexterm>"" msgid """" ""Each method provides different functionality and can be best divided into "" ""two groups:"" msgstr """" ""メソッド毎に異なる機能を提供しますが、このメソッドは 2 つのグループに分類する"" ""と良いでしょう。"" msgid """" ""Cells and regions, which segregate an entire cloud and result in running "" ""separate Compute deployments."" msgstr """" ""セルおよびリージョン。クラウド全体を分離し、個別にコンピュートデプロイメント"" ""を稼働します。"" msgid """" ""<glossterm baseform=\""Availability zone\"">Availability zones</glossterm> and "" ""host aggregates, which merely divide a single Compute deployment."" msgstr """" ""<glossterm baseform=\""Availability zone\"">アベイラビリティゾーン</glossterm> "" ""およびホストアグリゲート。コンピュートのデプロイメントの分割のみを行います。"" msgid """" ""<xref linkend=\""segragation_methods\""/> provides a comparison view of each "" ""segregation method currently provided by OpenStack Compute.<indexterm class="" ""\""singular\""><primary>endpoints</primary><secondary>API endpoint</"" ""secondary></indexterm>"" msgstr """" ""<xref linkend=\""segragation_methods\""/> では、OpenStack Compute が現在提供し"" ""ている各分割メソッドの比較ビューを提供しています。<indexterm class=\""singular"" ""\""><primary>エンドポイント</primary><secondary>API エンドポイント</"" ""secondary></indexterm>"" msgid ""OpenStack segregation methods"" msgstr ""OpenStack 分離の手法"" msgid ""Cells"" msgstr ""セル"" msgid ""Regions"" msgstr ""リージョン"" msgid ""Availability zones"" msgstr ""アベイラビリティゾーン"" msgid ""Host aggregates"" msgstr ""ホスト・アグリゲート"" msgid ""Use when you need"" msgstr ""用途"" msgid """" ""A single <glossterm>API endpoint</glossterm> for compute, or you require a "" ""second level of scheduling."" msgstr """" ""コンピュート資源に対する単一の <glossterm>API エンドポイント</glossterm>、も"" ""しくは２段階スケジューリングが必要な場合"" msgid """" ""Discrete regions with separate API endpoints and no coordination between "" ""regions."" msgstr """" ""リージョンごとに別々のAPIエンドポイントが必要で、リージョン間で協調する必要が"" ""ない場合"" msgid """" ""Logical separation within your nova deployment for physical isolation or "" ""redundancy."" msgstr """" ""物理的な隔離や冗長性のために、Nova デプロイメントの中で論理的な分離が必要な場"" ""合"" msgid ""To schedule a group of hosts with common features."" msgstr ""共通の機能を持ったホストのグループに対してスケジューリングしたい場合"" msgid ""Example"" msgstr ""例"" msgid """" ""A cloud with multiple sites where you can schedule VMs \""anywhere\"" or on a "" ""particular site."" msgstr """" ""複数サイトで構成されるクラウドで、仮想マシンを「任意のサイト」または特定のサ"" ""イトにスケジューリングしたい場合"" msgid """" ""A cloud with multiple sites, where you schedule VMs to a particular site and "" ""you want a shared infrastructure."" msgstr """" ""複数サイトで構成されるクラウドで、仮想マシンを特定のサイトに対してスケジュー"" ""リングでき、かつ共有インフラを利用したい場合"" msgid ""A single-site cloud with equipment fed by separate power supplies."" msgstr ""分離された電源供給ラインを持つ設備で構成される、単一サイトのクラウド。"" msgid ""Scheduling to hosts with trusted hardware support."" msgstr """" ""トラステッドコンピューティング機能に対応したホスト群に対してスケジューリング"" ""したい場合"" msgid ""Overhead"" msgstr ""オーバーヘッド"" msgid ""Considered experimental."" msgstr ""試験として使用"" msgid ""A new service, nova-cells."" msgstr ""新規サービス、nova-cells"" msgid ""Each cell has a full nova installation except nova-api."" msgstr ""各セルには nova-api 以外の全 nova 設定が含まれています。"" msgid ""A different API endpoint for every region."" msgstr ""リージョン毎に別々のAPIエンドポイントが必要"" msgid ""Each region has a full nova installation."" msgstr ""各リージョンにフルセットのNovaサービスが必要"" msgid ""Configuration changes to <filename>nova.conf</filename>."" msgstr ""<filename>nova.conf</filename> の設定を変更"" msgid ""Shared services"" msgstr ""共有サービス"" msgid ""Keystone"" msgstr ""Keystone"" msgid ""nova-api"" msgstr ""nova-api"" msgid ""All nova services"" msgstr ""すべての Nova サービス"" msgid ""Cells and Regions"" msgstr ""セルとリージョン"" msgid """" ""OpenStack Compute cells are designed to allow running the cloud in a "" ""distributed fashion without having to use more complicated technologies, or "" ""be invasive to existing nova installations. Hosts in a cloud are partitioned "" ""into groups called <emphasis>cells</emphasis>. Cells are configured in a "" ""tree. The top-level cell (\""API cell\"") has a host that runs the <code>nova-"" ""api</code> service, but no <code>nova-compute</code> services. Each child "" ""cell runs all of the other typical <code>nova-*</code> services found in a "" ""regular installation, except for the <code>nova-api</code> service. Each "" ""cell has its own message queue and database service and also runs <code>nova-"" ""cells</code>, which manages the communication between the API cell and child "" ""cells.<indexterm class=\""singular\""><primary>scaling</"" ""primary><secondary>cells and regions</secondary></indexterm><indexterm class="" ""\""singular\""><primary>cells</primary><secondary>cloud segregation</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>region</"" ""primary></indexterm>"" msgstr """" ""OpenStack Compute のセルによって、より複雑な技術を持ち込むことなしに、また既"" ""存のNovaシステムに悪影響を与えることなしに、クラウドを分散された環境で運用す"" ""ることができます。１つのクラウドの中のホストは、<emphasis>セル</emphasis> と"" ""呼ばれるグループに分割されます。セルは、木構造に構成されてます。最上位のセル "" ""(「API セル」) は<code>nova-api</code>サービスを実行するホストを持ちますが、"" ""<code>nova-compute</code> サービスを実行するホストは持ちません。それぞれの子"" ""セルは、<code>nova-api</code>サービス以外の、普通のNovaシステムに見られる他の"" ""すべての典型的な <code>nova-*</code> サービスを実行します。それぞれのセルは自"" ""分のメッセージキューとデータベースサービスを持ち、またAPIセルと子セルの間の通"" ""信を制御する <code>nova-cells</code> サービスを実行します。<indexterm class="" ""\""singular\""><primary>スケーリング</primary><secondary>セルとリージョン</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>セル</"" ""primary><secondary>クラウド分割</secondary></indexterm><indexterm class="" ""\""singular\""><primary>リージョン</primary></indexterm>"" msgid """" ""This allows for a single API server being used to control access to multiple "" ""cloud installations. Introducing a second level of scheduling (the cell "" ""selection), in addition to the regular <code>nova-scheduler</code> selection "" ""of hosts, provides greater flexibility to control where virtual machines are "" ""run."" msgstr """" ""これによって、複数のクラウドシステムに対するアクセスを、１つのAPIサーバで制御"" ""することができます。通常の<code>nova-scheduler</code>によるホストの選択に加え"" ""て、第二段階のスケジューリング(セルの選択)を導入することにより、仮想マシンを"" ""実行する場所の制御の柔軟性が大きく向上します。"" msgid ""Availability Zones and Host Aggregates"" msgstr ""アベイラビリティゾーンとホストアグリゲート"" msgid """" ""You can use availability zones, host aggregates, or both to partition a nova "" ""deployment.<indexterm class=\""singular\""><primary>scaling</"" ""primary><secondary>availability zones</secondary></indexterm>"" msgstr """" ""アベイラビリティゾーン、ホストアグリゲート、または両方を使用して、nova デプロ"" ""イメントを分割することができます。<indexterm class=\""singular\""><primary>ス"" ""ケーリング</primary><secondary>アベイラビリティゾーン</secondary></indexterm>"" msgid """" ""Availability zones are implemented through and configured in a similar way "" ""to host aggregates."" msgstr """" ""アベイラビリティゾーンは、ホストアグリゲートを利用して実装されており、ホスト"" ""アグリゲートと同様の方法で設定します。"" msgid ""However, you use them for different reasons."" msgstr """" ""しかし、アベイラビリティゾーンとホストアグリゲートは別の用途で使用します。"" msgid ""Availability zone"" msgstr ""アベイラビリティゾーン"" msgid """" ""This enables you to arrange OpenStack compute hosts into logical groups and "" ""provides a form of physical isolation and redundancy from other availability "" ""zones, such as by using a separate power supply or network equipment."" ""<indexterm class=\""singular\""><primary>availability zone</primary></"" ""indexterm>"" msgstr """" ""アベイラビリティゾーンにより、OpenStack Compute ホストを論理グループにまとめ"" ""て、（独立した電源系統やネットワーク装置を使うことなどで）他のアベイラビリ"" ""ティゾーンとの物理的な分離や冗長性を実現できます。<indexterm class=\""singular"" ""\""><primary>アベイラビリティゾーン</primary></indexterm>"" msgid """" ""You define the availability zone in which a specified compute host resides "" ""locally on each server. An availability zone is commonly used to identify a "" ""set of servers that have a common attribute. For instance, if some of the "" ""racks in your data center are on a separate power source, you can put "" ""servers in those racks in their own availability zone. Availability zones "" ""can also help separate different classes of hardware."" msgstr """" ""指定したコンピュートホストがローカルでサーバー毎に所属するアベイラビリティ"" ""ゾーンを定義します。アベイラビリティゾーンは一般的に、共通の属性を持つサー"" ""バーを識別するために使用されます。例えば、データセンターのラックの一部が別の"" ""電源を仕様している場合、このラックのサーバーを独自のアベイラビリティゾーンに"" ""入れることができます。アベイラビリティゾーンは、異なるハードウェアクラスを分"" ""割することもできます。"" msgid """" ""When users provision resources, they can specify from which availability "" ""zone they want their instance to be built. This allows cloud consumers to "" ""ensure that their application resources are spread across disparate machines "" ""to achieve high availability in the event of hardware failure."" msgstr """" ""リソースのプロビジョニングの際には、インスタンスを作成するアベイラビリティ"" ""ゾーンを指定することができます。これによって、クラウドの利用者は、アプリケー"" ""ションのリソースが異なるマシンに分散して配置され、ハードウェア故障が発生した"" ""場合でも高可用性を達成することができます。"" msgid ""Host aggregates zone"" msgstr ""ホストアグリゲートゾーン"" msgid """" ""This enables you to partition OpenStack Compute deployments into logical "" ""groups for load balancing and instance distribution. You can use host "" ""aggregates to further partition an availability zone. For example, you might "" ""use host aggregates to partition an availability zone into groups of hosts "" ""that either share common resources, such as storage and network, or have a "" ""special property, such as trusted computing hardware.<indexterm class="" ""\""singular\""><primary>scaling</primary><secondary>host aggregate</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>host aggregate</"" ""primary></indexterm>"" msgstr """" ""これにより、OpenStack コンピュートデプロイメントを負荷分散やインスタンスディ"" ""ストリビューション用の論理グループに分割することができます。ホストアグリゲー"" ""トをシヨ空いて、アベイラビリティゾーンをさらに分割することができます。例え"" ""ば、ホストアグリゲートを使用してアベイラビリティゾーンをストレージやネット"" ""ワークなどの共通のリソースを共有するか、信頼済みのコンピューティングハード"" ""ウェアなどの特別なプロパティを持つホストグループに分割することができます。"" ""<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>ホス"" ""トアグリゲート</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ホストアグリゲート</primary></indexterm>"" msgid """" ""A common use of host aggregates is to provide information for use with the "" ""<literal>nova-scheduler</literal>. For example, you might use a host "" ""aggregate to group a set of hosts that share specific flavors or images."" msgstr """" ""ホストアグリゲートの一般的な用途は <literal>nova-scheduler</literal> で使用す"" ""る情報を提供することです。例えば、ホストアグリゲートを使って、特定のフレー"" ""バーやイメージを共有するホストの集合を作成することができます。"" msgid """" ""The general case for this is setting key-value pairs in the aggregate "" ""metadata and matching key-value pairs in flavor's <parameter>extra_specs</"" ""parameter> metadata. The <parameter>AggregateInstanceExtraSpecsFilter</"" ""parameter> in the filter scheduler will enforce that instances be scheduled "" ""only on hosts in aggregates that define the same key to the same value."" msgstr """" ""この一般的なケースは、アグリゲートメタデータで key-value ペアを設定して、フ"" ""レーバーの <parameter>extra_specs</parameter> メタデータで key-value ペアを一"" ""致させます。フィルタースケジューラーの "" ""<parameter>AggregateInstanceExtraSpecsFilter</parameter> は、強制的にインスタ"" ""ンスが、同じ値に同じキーが定義されているアグリゲートのホストに対してのみスケ"" ""ジューリングするようにします。"" msgid """" ""An advanced use of this general concept allows different flavor types to run "" ""with different CPU and RAM allocation ratios so that high-intensity "" ""computing loads and low-intensity development and testing systems can share "" ""the same cloud without either starving the high-use systems or wasting "" ""resources on low-utilization systems. This works by setting "" ""<parameter>metadata</parameter> in your host aggregates and matching "" ""<parameter>extra_specs</parameter> in your flavor types."" msgstr """" ""この一般的なコンセプトを高度なレベルで使用すると、集中度の高いコンピュート"" ""ロードや負荷の低い開発やテストシステムが使用量の多いシステムのリソースが不足"" ""したり、使用量の低いシステムでリソースを無駄にしたりしないで、同じクラウドを"" ""共有できるように、異なるフレーバーの種別が、異なる CPU および RAM 割当の比率"" ""で実行できるようになります。 これは、ホストアグリゲートに "" ""<parameter>metadata</parameter> を設定して、フレーバー種別の"" ""<parameter>extra_specs</parameter> と一致させると機能します。"" msgid """" ""The first step is setting the aggregate metadata keys "" ""<parameter>cpu_allocation_ratio</parameter> and "" ""<parameter>ram_allocation_ratio</parameter> to a floating-point value. The "" ""filter schedulers <parameter>AggregateCoreFilter</parameter> and "" ""<parameter>AggregateRamFilter</parameter> will use those values rather than "" ""the global defaults in <filename>nova.conf</filename> when scheduling to "" ""hosts in the aggregate. It is important to be cautious when using this "" ""feature, since each host can be in multiple aggregates but should have only "" ""one allocation ratio for each resources. It is up to you to avoid putting a "" ""host in multiple aggregates that define different values for the same "" ""<phrase role=\""keep-together\"">resource</phrase>."" msgstr """" ""最初のステップは、<parameter>cpu_allocation_ratio</parameter> と "" ""<parameter>ram_allocation_ratio</parameter> のアグリゲートメタデータキーを浮"" ""動小数点の値に設定します。<parameter>AggregateCoreFilter</parameter> と "" ""<parameter>AggregateRamFilter</parameter> のフィルタースケジューラーは、アグ"" ""リゲートのホストにスケジューリングしている場合、<filename>nova.conf</"" ""filename> のグローバルの初期値を仕様するのではなく、この値を使用します。各ホ"" ""ストは複数のアグリゲートに含まれていますがリソースごとに 1 つの割当比率しか指"" ""定されていないため、この機能の使用時は、注意が必要です。同じ <phrase role="" ""\""keep-together\"">リソース</phrase> に対して別の値が定義されている複数のアグ"" ""リゲートにホストを設置しないように注意してください。"" msgid """" ""This is the first half of the equation. To get flavor types that are "" ""guaranteed a particular ratio, you must set the <parameter>extra_specs</"" ""parameter> in the flavor type to the key-value pair you want to match in the "" ""aggregate. For example, if you define <parameter>extra_specs</"" ""parameter><parameter>cpu_allocation_ratio</parameter> to \""1.0\"", then "" ""instances of that type will run in aggregates only where the metadata key "" ""<parameter>cpu_allocation_ratio</parameter> is also defined as \""1.0.\"" In "" ""practice, it is better to define an additional key-value pair in the "" ""aggregate metadata to match on rather than match directly on "" ""<parameter>cpu_allocation_ratio</parameter> or "" ""<parameter>core_allocation_ratio</parameter>. This allows better "" ""abstraction. For example, by defining a key <parameter>overcommit</"" ""parameter> and setting a value of \""high,\"" \""medium,\"" or \""low,\"" you "" ""could then tune the numeric allocation ratios in the aggregates without also "" ""needing to change all flavor types relating to them."" msgstr """" ""これは前半部分です。特定の比率を保証するフレーバー種別を取得するには、フレー"" ""バー種別の <parameter>extra_specs</parameter> をアグリゲートでマッチする key-"" ""value ペアに設定する必要があります。たとえば、<parameter>extra_specs</"" ""parameter><parameter>cpu_allocation_ratio</parameter> を 1.0 に定義すると、そ"" ""の種別のインスタンスは、メタデータキー <parameter>cpu_allocation_ratio</"" ""parameter> も 1.0 と定義されているアグリゲートのみで実行されます。実際は、 "" ""<parameter>cpu_allocation_ratio</parameter> または "" ""<parameter>core_allocation_ratio</parameter> で直接マッチさせるのではなく、"" ""マッチするアグリゲートメタデータに追加の key-value ペアを定義すると良いでしょ"" ""う。これにより抽象化が改善されます。たとえば、<parameter>overcommit</"" ""parameter> キーを定義して、高、中、低の値を設定することで、関連するフレーバー"" ""種別をすべて変更する必要なしに、アグリゲートの割合比を調節することができま"" ""す。"" msgid """" ""Previously, all services had an availability zone. Currently, only the "" ""<literal>nova-compute</literal> service has its own availability zone. "" ""Services such as <literal>nova-scheduler</literal>, <literal>nova-network</"" ""literal>, and <literal>nova-conductor</literal> have always spanned all "" ""availability zones."" msgstr """" ""以前のバージョンでは、全サービスにアベイラビリティゾーンがありました。現在"" ""は、<literal>nova-compute</literal> サービスには独自のアベイラビリティゾーン"" ""があります。 <literal>nova-scheduler</literal>、 <literal>nova-network</"" ""literal>、<literal>nova-conductor</literal> などのサービスは、常にすべてのア"" ""ベイラビリティゾーンに対応します。"" msgid ""nova host-list (os-hosts)"" msgstr ""nova host-list (os-hosts)"" msgid ""euca-describe-availability-zones verbose"" msgstr ""euca-describe-availability-zones verbose"" msgid ""<literal>nova-manage</literal> service list"" msgstr ""<literal>nova-manage</literal> サービス一覧"" msgid """" ""When you run any of the following operations, the services appear in their "" ""own internal availability zone (CONF.internal_service_availability_zone): "" ""<placeholder-1/>The internal availability zone is hidden in euca-describe-"" ""availability_zones (nonverbose)."" msgstr """" ""以下の操作のいずれかを実行する場合、サービスは独自の内部アベイラビリティゾー"" ""ン(CONF.internal_service_availability_zone) に表示されます。<placeholder-1/>"" ""内部のアベイラビリティゾーンは、euca-describe-availability_zones "" ""(nonverbose) に隠し設定されています。"" msgid """" ""CONF.node_availability_zone has been renamed to CONF."" ""default_availability_zone and is used only by the <literal>nova-api</"" ""literal> and <literal>nova-scheduler</literal> services."" msgstr """" ""CONF.node_availability_zone は、CONF.default_availability_zone に名前が変更さ"" ""れ、<literal>nova-api</literal> および <literal>nova-scheduler</literal> サー"" ""ビスのみで使用されます。"" msgid ""CONF.node_availability_zone still works but is deprecated."" msgstr ""CONF.node_availability_zone は今も機能しますが、非推奨扱いです。"" msgid ""Scalable Hardware"" msgstr ""スケーラブルハードウェア"" msgid """" ""While several resources already exist to help with deploying and installing "" ""OpenStack, it's very important to make sure that you have your deployment "" ""planned out ahead of time. This guide presumes that you have at least set "" ""aside a rack for the OpenStack cloud but also offers suggestions for when "" ""and what to scale."" msgstr """" ""OpenStack のデプロイやインストールの助けとなるリソースがすでに複数存在してい"" ""る場合でも、時間に余裕を持ってデプロイメントの系っ買うを立てることは非常に重"" ""要です。本書は、OpenStack クラウド用のラックを少なくとも 1 つ用意しているとの"" ""前提で、何を度のタイミングでスケールするかの提案をしていきます。"" msgid ""Hardware Procurement"" msgstr ""ハードウェア調達"" msgid """" ""“The Cloud” has been described as a volatile environment where servers can "" ""be created and terminated at will. While this may be true, it does not mean "" ""that your servers must be volatile. Ensuring that your cloud’s hardware is "" ""stable and configured correctly means that your cloud environment remains up "" ""and running. Basically, put effort into creating a stable hardware "" ""environment so that you can host a cloud that users may treat as unstable "" ""and volatile.<indexterm class=\""singular\""><primary>servers</"" ""primary><secondary>avoiding volatility in</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>hardware</primary><secondary>scalability "" ""planning</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>scaling</primary><secondary>hardware procurement</secondary></"" ""indexterm>"" msgstr """" ""「クラウド」とは、サーバーを自由に作成、終了でき、不安定な環境と説明されてき"" ""ました。これは真実ですが、サーバー自体が不安定なわけではありません。クラウド"" ""のハードウェアは、安定して正しく設定されているようにすることで、クラウド環境"" ""は稼動状態を保ちます。基本的に、安定したハードウェア環境を構築するように努め"" ""ることで、ユーザーが不安定かつ変化しやすいものとして処理を行う可能性のあるク"" ""ラウドをホストすることができます。<indexterm class=\""singular"" ""\""><primary>servers</primary><secondary>不安定性の回避</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ハードウェア</"" ""primary><secondary>拡張性プランニング</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>スケーリング</primary><secondary>ハードウェア調達"" ""</secondary></indexterm>"" msgid """" ""OpenStack can be deployed on any hardware supported by an OpenStack-"" ""compatible Linux distribution."" msgstr """" ""OpenStack は、OpenStack と互換性のある Linux ディストリビューションによりサ"" ""ポートされているハードウェアにデプロイすることができます。"" msgid """" ""Hardware does not have to be consistent, but it should at least have the "" ""same type of CPU to support instance migration."" msgstr """" ""ハードウェアに一貫性を持たせる必要はありませんが、インスタンスのマイグレー"" ""ションをサポートできるように、最低限、CPU の種類は同じにする必要があります。"" msgid """" ""The typical hardware recommended for use with OpenStack is the standard "" ""value-for-money offerings that most hardware vendors stock. It should be "" ""straightforward to divide your procurement into building blocks such as "" ""\""compute,\"" \""object storage,\"" and \""cloud controller,\"" and request as "" ""many of these as you need. Alternatively, should you be unable to spend "" ""more, if you have existing servers—provided they meet your performance "" ""requirements and virtualization technology—they are quite likely to be able "" ""to support OpenStack."" msgstr """" ""OpenStack での使用に推奨しているハードウェアは一般的に、多くのハードウェアベ"" ""ンダーが提供している、コストパフォーマンスの高い標準オファリングです。調達す"" ""べきものをコンピュート、オブジェクトストレージ、クラウドコントローラなどのビ"" ""ルディングブロックに分類し、必要に応じ依頼していくと分かりやすいでしょう。ま"" ""た、投資額をこれ以上かけられない場合、既存サーバーがありパフォーマンス要件や"" ""仮想化技術に対応しているのであれば、高い確率で OpenStack をサポートしているは"" ""ずです。"" msgid ""Capacity Planning"" msgstr ""キャパシティプランニング"" msgid ""Burn-in Testing"" msgstr ""エージング試験"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST"" msgid ""Storage Decisions"" msgstr ""ストレージ選定"" msgid """" ""Storage is found in many parts of the OpenStack stack, and the differing "" ""types can cause confusion to even experienced cloud engineers. This section "" ""focuses on persistent storage options you can configure with your cloud. "" ""It's important to understand the distinction between <glossterm baseform="" ""\""ephemeral volume\""> ephemeral</glossterm> storage and <glossterm baseform="" ""\""persistent volume\""> persistent</glossterm> storage."" msgstr """" ""ストレージは、OpenStack のスタックの多くの箇所で使用されており、ストレージの"" ""種別が異なると、経験豊かなエンジニアでも混乱する可能性があります。本章は、お"" ""使いのクラウドで設定可能な永続ストレージオプションにフォーカスします。"" ""<glossterm baseform=\""ephemeral volume\""> 一時</glossterm> ストレージと "" ""<glossterm baseform=\""persistent volume\""> 永続</glossterm> ストレージの相違"" ""点を理解することが重要です。"" msgid ""Ephemeral Storage"" msgstr ""一時ストレージ"" msgid """" ""If you deploy only the OpenStack Compute Service (nova), your users do not "" ""have access to any form of persistent storage by default. The disks "" ""associated with VMs are \""ephemeral,\"" meaning that (from the user's point "" ""of view) they effectively disappear when a virtual machine is terminated."" ""<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>ephemeral</secondary></indexterm>"" msgstr """" ""OpenStack Compute Service (nova) のみをデプロイする場合、デフォルトでは、どの"" ""ような形式の永続ストレージにもアクセスできません。仮想マシンに関連付けされて"" ""いるディスクは一時的です。つまり、(ユーザー視点から) 仮想マシンが終了されると"" ""このストレージは効率的に表示がなくなります。<indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>一時</secondary></indexterm>"" msgid ""Persistent Storage"" msgstr ""永続ストレージ"" msgid """" ""Persistent storage means that the storage resource outlives any other "" ""resource and is always available, regardless of the state of a running "" ""instance."" msgstr """" ""永続ストレージとは、実行中のインスタンスの状態が何であっても、ストレージリ"" ""ソースが他のリソースよりも長く存在して、常に利用できる状態のストレージを指し"" ""ます。"" msgid """" ""Today, OpenStack clouds explicitly support two types of persistent storage: "" ""<emphasis>object storage</emphasis> and <emphasis>block storage</emphasis>."" ""<indexterm class=\""singular\""><primary>swift</primary><secondary>Object "" ""Storage API</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>persistent storage</primary></indexterm><indexterm class="" ""\""singular\""><primary>objects</primary><secondary>persistent storage of</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>Object Storage</"" ""primary><secondary>Object Storage API</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>object storage</"" ""secondary></indexterm>"" msgstr """" ""現在、OpenStack クラウドは、<emphasis>オブジェクトストレージ</emphasis> およ"" ""び<emphasis>ブロックストレージ</emphasis> の 2 種類の永続ストレージを明示的に"" ""サポートしています。<indexterm class=\""singular\""><primary>swift</"" ""primary><secondary>Object Storage API</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>永続ストレージ</primary></indexterm><indexterm "" ""class=\""singular\""><primary>オブジェクト</primary><secondary>永続ストレージ</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>オブジェクトスト"" ""レージ</primary><secondary>Object Storage API</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>storage</primary><secondary>"" ""オブジェクトストレージ</secondary></indexterm>"" msgid ""Object Storage"" msgstr ""オブジェクトストレージ"" msgid """" ""With object storage, users access binary objects through a REST API. You may "" ""be familiar with Amazon S3, which is a well-known example of an object "" ""storage system. Object storage is implemented in OpenStack by the OpenStack "" ""Object Storage (swift) project. If your intended users need to archive or "" ""manage large datasets, you want to provide them with object storage. In "" ""addition, OpenStack can store your virtual <phrase role=\""keep-together"" ""\"">machine</phrase> (VM) images inside of an object storage system, as an "" ""alternative to storing the images on a file system.<indexterm class="" ""\""singular\""><primary>binary</primary><secondary>binary objects</secondary></"" ""indexterm>"" msgstr """" ""オブジェクトストレージでは、REST API を使用してバイナリオブジェクトにアクセス"" ""します。オブジェクトストレージで有名な例として、Amazon S3 は知られています。"" ""オブジェクトストレージは、OpenStack Object Storage (swift) プロジェクトによ"" ""り、OpenStack に実装されています。ユーザーが、大規模なデータセットをアーカイ"" ""ブまたは管理する場合オブジェクトストレージを提供します。さらに OpenStack で"" ""は、ファイルシステムにイメージを格納する代わりに、仮想<phrase role=\""keep-"" ""together\"">マシン</phrase> (VM) のイメージを、オブジェクトストレージシステム"" ""の中に格納できます。<indexterm class=\""singular\""><primary>バイナリ</"" ""primary><secondary>バイナリオブジェクト</secondary></indexterm>"" msgid """" ""OpenStack Object Storage provides a highly scalable, highly available "" ""storage solution by relaxing some of the constraints of traditional file "" ""systems. In designing and procuring for such a cluster, it is important to "" ""understand some key concepts about its operation. Essentially, this type of "" ""storage is built on the idea that all storage hardware fails, at every "" ""level, at some point. Infrequently encountered failures that would hamstring "" ""other storage systems, such as issues taking down RAID cards or entire "" ""servers, are handled gracefully with OpenStack Object Storage.<indexterm "" ""class=\""singular\""><primary>scaling</primary><secondary>Object Storage and</"" ""secondary></indexterm>"" msgstr """" ""OpenStack Object Storage は、従来のファイルシステムの制約の一部を緩和すること"" ""で、高可用性かつ高拡張性のストレージソリューションを提供します。このようなク"" ""ラスターの設計、調達には、操作に関する主なコンセプトを理解することが重要で"" ""す。基本的に、このタイプのストレージハードウェアはすべて、どこかの段階で、ど"" ""のレベルであっても故障するというコンセプトをベースに、この種類のストレージは"" ""構築されています。 RAID カードやサーバー全体での問題など、他のストレージシス"" ""テムに影響を与える障害に遭遇することがまれにあります。このような場合、"" ""OpenStack Object Storageでは滞りなく処理されます。<indexterm class=\""singular"" ""\""><primary>スケーリング</primary><secondary>オブジェクトストレージ</"" ""secondary></indexterm>"" msgid """" ""A good document describing the Object Storage architecture is found within "" ""<link href=\""http://docs.openstack.org/developer/swift/overview_architecture."" ""html\"" title=\""OpenStack wiki\"">the developer documentation</link>—read this "" ""first. Once you understand the architecture, you should know what a proxy "" ""server does and how zones work. However, some important points are often "" ""missed at first glance."" msgstr """" ""オブジェクトストレージのアーキテクチャーについて詳しく説明したドキュメントは "" ""<link href=\""http://docs.openstack.org/developer/swift/overview_architecture."" ""html\"" title=\""OpenStack wiki\"">the developer documentation</link>にありま"" ""す。これをまず参照してください。アーキテクチャーを理解したら、プロキシサー"" ""バーの役割やゾーンの機能について理解できるはずです。しかし、少し見ただけで"" ""は、頻繁に重要なポイントを逃してしまうことがあります。"" msgid """" ""When designing your cluster, you must consider durability and availability. "" ""Understand that the predominant source of these is the spread and placement "" ""of your data, rather than the reliability of the hardware. Consider the "" ""default value of the number of replicas, which is three. This means that "" ""before an object is marked as having been written, at least two copies exist—"" ""in case a single server fails to write, the third copy may or may not yet "" ""exist when the write operation initially returns. Altering this number "" ""increases the robustness of your data, but reduces the amount of storage you "" ""have available. Next, look at the placement of your servers. Consider "" ""spreading them widely throughout your data center's network and power-"" ""failure zones. Is a zone a rack, a server, or a disk?"" msgstr """" ""クラスターの設計時には、耐久性と可用性を考慮する必要があります。耐久性や可用"" ""性は主に、ハードウェアの信頼性に頼るのではなく、データを分散して設置すること"" ""で確保されることを理解してください。レプリカの数のデフォルト値は 3 である点も"" ""考慮します。つまり、オブジェクトが書き込みされたとマークされる前でも、少なく"" ""ともコピーが 2 つ存在します。1 つのサーバーが書き込みに失敗しても、書き込み操"" ""作が最初に返された時点で、3 番めのコピーが存在する可能性があります。この数字"" ""を変更することで、データの堅牢性を高めることができますが、利用可能なストレー"" ""ジ数が減少します。次に、サーバーの設置について見ていきます。データセンターの"" ""ネットワークや停電ゾーン全体に設定するようにします。ゾーンには、ラック、サー"" ""バー、ディスクのいずれを使用していますか？"" msgid """" ""Among <glossterm>object</glossterm>, <glossterm>container</glossterm>, and "" ""<glossterm>account server</glossterm>s"" msgstr """" ""<glossterm>object server</glossterm> 、 <glossterm>container server</"" ""glossterm> 、 <glossterm>account server</glossterm> 間"" msgid ""Between those servers and the proxies"" msgstr ""object/container/account server と proxy server の間"" msgid ""Between the proxies and your users"" msgstr ""proxy server と 利用者の間"" msgid """" ""Object Storage's network patterns might seem unfamiliar at first. Consider "" ""these main traffic flows: <indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>storage decisions and</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>containers</primary><secondary>storage decisions "" ""and</secondary></indexterm><indexterm class=\""singular\""><primary>account "" ""server</primary></indexterm><placeholder-1/>"" msgstr """" ""オブジェクトストレージのネットワークパターンは、最初は見慣れないかもしれませ"" ""ん。これらのメイントラフィックの流れを見てみましょう。 <indexterm class="" ""\""singular\""><primary>objects</primary><secondary>ストレージの決定</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>コンテナー</"" ""primary><secondary>ストレージの決定</secondary></indexterm><indexterm class="" ""\""singular\""><primary>アカウントサーバー</primary></indexterm><placeholder-1/"" "">"" msgid """" ""Object Storage is very \""chatty\"" among servers hosting data—even a small "" ""cluster does megabytes/second of traffic, which is predominantly, “Do you "" ""have the object?”/“Yes I have the object!” Of course, if the answer to the "" ""aforementioned question is negative or the request times out, replication of "" ""the object begins."" msgstr """" ""オブジェクトストレージは、データをホストするサーバーの中で非常に呼び出しが多"" ""く、小さいクラスターでも一秒に MB 単位のトラフィックがあります。「オブジェク"" ""トがありますか？はい、あります。」当然、この質問に対する答えがNoの場合、また"" ""は要求がタイムアウトした場合、オブジェクトの複製が開始されます。"" msgid """" ""Consider the scenario where an entire server fails and 24 TB of data needs "" ""to be transferred \""immediately\"" to remain at three copies—this can put "" ""significant load on the network."" msgstr """" ""サーバー全体が停止し、24 TB 分のデータを即時に 3 つのコピーに残るように移行す"" ""るというシナリオを思い浮かべてください。これは、ネットワークに大きな負荷がか"" ""かる可能性があります。"" msgid """" ""Another fact that's often forgotten is that when a new file is being "" ""uploaded, the proxy server must write out as many streams as there are "" ""replicas—giving a multiple of network traffic. For a three-replica cluster, "" ""10 Gbps in means 30 Gbps out. Combining this with the previous high "" ""bandwidth<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>private vs. public network recommendations</secondary></"" ""indexterm> demands of replication is what results in the recommendation that "" ""your private network be of significantly higher bandwidth than your public "" ""need be. Oh, and OpenStack Object Storage communicates internally with "" ""unencrypted, unauthenticated rsync for performance—you do want the private "" ""network to be private."" msgstr """" ""また、新規ファイルがアップロードされると、プロキシサーバーはレプリカの数だけ"" ""書き込みが行われ、複数のネットワークトラフィックが発生するという点も頻繁に忘"" ""れられています。 レプリカが３つのクラスターでは、受信トラフィックが 10 Gbps "" ""とすると、送信トラフィックは 30 Gbps ということになります。これを以前のレプリ"" ""カの帯域幅の需要が<indexterm class=\""singular\""><primary>bandwidth</"" ""primary><secondary>プライベート vs. パブリックネットワークの推奨事項</"" ""secondary></indexterm> 高いことと合わせて考えると、パブリックネットワークよ"" ""りもプライベートネットワークのほうがはるかに高い帯域幅が必要であることが分か"" ""ります。OpenStack Object Storage はパフォーマンスを保つために内部では、暗号化"" ""なし、認証なしの rsync と通信します (プライベートネットワークをプライベートに"" ""保つため)。"" msgid """" ""The remaining point on bandwidth is the public-facing portion. The "" ""<literal>swift-proxy</literal> service is stateless, which means that you "" ""can easily add more and use HTTP load-balancing methods to share bandwidth "" ""and availability between them."" msgstr """" ""帯域幅に関する残りのポイントは、パブリック側の部分です。<literal>swift-"" ""proxy</literal> サービスは、ステートレスです。ステートレスとは、HTTP 負荷分散"" ""メソッドを簡単に追加、使用して帯域幅や可用性を共有できるという意味です。"" msgid ""More proxies means more bandwidth, if your storage can keep up."" msgstr """" ""ストレージ側の性能が十分であれば、proxy server の増加は帯域の増加になります。"" msgid """" ""Block storage (sometimes referred to as volume storage) provides users with "" ""access to block-storage devices. Users interact with block storage by "" ""attaching volumes to their running VM instances.<indexterm class=\""singular"" ""\""><primary>volume storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>block storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>storage</primary><secondary>block storage</secondary></indexterm>"" msgstr """" ""Block storage (ボリュームストレージと呼ばれる場合もある) は、ユーザーがブロッ"" ""クストレージデバイスにアクセスできるようにします。ユーザーは、実行中の仮想マ"" ""シンインスタンスにボリュームを接続することで、ブロックストレージと対話しま"" ""す。<indexterm class=\""singular\""><primary>ボリュームストレージ</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ブロックストレージ</"" ""primary></indexterm><indexterm class=\""singular\""><primary>ストレージ</"" ""primary><secondary>ブロックストレージ</secondary></indexterm>"" msgid """" ""These volumes are persistent: they can be detached from one instance and re-"" ""attached to another, and the data remains intact. Block storage is "" ""implemented in OpenStack by the OpenStack Block Storage (cinder) project, "" ""which supports multiple backends in the form of drivers. Your choice of a "" ""storage backend must be supported by a Block Storage driver."" msgstr """" ""これらのボリュームは永続的であるため、インスタンスから切り離して、データをそ"" ""のまま維持しつつ、別のインスタンスに再接続することができます。ブロックスト"" ""レージは、ドライバー形式で複数のバックエンドをサポートする、OpenStack Block "" ""Storage (Cinder) プロジェクトで OpenStack に実装されています。お使いのスト"" ""レージバックエンドは、Block Storage ドライバーでサポートされている必要があり"" ""ます。"" msgid """" ""These drivers work a little differently than a traditional \""block\"" storage "" ""driver. On an NFS or GlusterFS file system, a single file is created and "" ""then mapped as a \""virtual\"" volume into the instance. This mapping/"" ""translation is similar to how OpenStack utilizes QEMU's file-based virtual "" ""machines stored in <code>/var/lib/nova/instances</code>."" msgstr """" ""これらのドライバーは従来のブロックストレージドライバとは少々異なる動作をしま"" ""す。NFSやGlusterFSでは1つのファイルが作成され、インスタンスに対して「仮想」ボ"" ""リュームとしてマッピングされます。このマッピング/変換は<code>/var/lib/nova/"" ""instances</code> 下に保存される、QEMUのファイルベースの仮想マシンの、"" ""OpenStackによる扱い方と同様です。"" msgid ""OpenStack Storage Concepts"" msgstr ""ストレージのコンセプト"" msgid """" ""<xref linkend=\""openstack_storage\""/> explains the different storage "" ""concepts provided by OpenStack.<indexterm class=\""singular\""><primary>block "" ""device</primary></indexterm><indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>overview of concepts</secondary></indexterm>"" msgstr """" ""<xref linkend=\""openstack_storage\""/> は、OpenStack で提供されているさまざま"" ""なストレージのコンセプトについて説明しています。<indexterm class=\""singular"" ""\""><primary>ブロックデバイス</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>oコンセプトの概要</secondary></"" ""indexterm>"" msgid ""OpenStack storage"" msgstr ""OpenStack ストレージ"" msgid ""Ephemeral storage"" msgstr ""エフェメラルストレージ"" msgid ""Block storage"" msgstr ""ブロックストレージ"" msgid ""Used to…"" msgstr ""使用目的"" msgid ""Run operating system and scratch space"" msgstr ""OS を起動し、空き領域に記録する"" msgid ""Add additional persistent storage to a virtual machine (VM)"" msgstr ""永続的なストレージを仮想マシン（VM）へ追加する"" msgid ""Store data, including VM images"" msgstr ""データを保存する（VMイメージも含む）"" msgid ""Accessed through…"" msgstr ""アクセス方法"" msgid ""A file system"" msgstr ""ファイルシステム"" msgid """" ""A <glossterm>block device</glossterm> that can be partitioned, formatted, "" ""and mounted (such as, /dev/vdc)"" msgstr """" ""パーティション分割、フォーマット、マウントが可能な <glossterm>ブロックデバイ"" ""ス</glossterm> (/dev/vdc など)"" msgid ""The REST API"" msgstr ""REST API"" msgid ""Accessible from…"" msgstr ""アクセス可能な場所"" msgid ""Within a VM"" msgstr ""VM内"" msgid ""Anywhere"" msgstr ""どこからでも"" msgid ""Managed by…"" msgstr ""管理元"" msgid ""OpenStack Compute (nova)"" msgstr ""OpenStack Compute (nova)"" msgid ""OpenStack Block Storage (cinder)"" msgstr ""OpenStack Block Storage (cinder)"" msgid ""Persists until…"" msgstr ""データの残存期間"" msgid ""VM is terminated"" msgstr ""VM終了まで"" msgid ""Deleted by user"" msgstr ""ユーザーが削除するまで"" msgid ""Sizing determined by…"" msgstr ""容量の指定"" msgid """" ""Administrator configuration of size settings, known as <emphasis>flavors</"" ""emphasis>"" msgstr ""<emphasis>フレーバー</emphasis> として知られる管理者のサイズ設定"" msgid ""User specification in initial request"" msgstr ""初回要求のユーザー仕様"" msgid ""Amount of available physical storage"" msgstr ""利用可能な物理ディスクの総量で決まる"" msgid ""Example of typical usage…"" msgstr ""典型的な利用例"" msgid ""10 GB first disk, 30 GB second disk"" msgstr ""1 番目のディスク 10 GB、2 番目のディスク 30 GB"" msgid ""1 TB disk"" msgstr ""1TBディスク"" msgid ""10s of TBs of dataset storage"" msgstr ""数十TBのデータセットストレージ"" msgid ""File-level Storage (for Live Migration)"" msgstr ""ファイルレベルのストレージ (ライブマイグレーション用)"" msgid """" ""With file-level storage, users access stored data using the operating "" ""system's file system interface. Most users, if they have used a network "" ""storage solution before, have encountered this form of networked storage. In "" ""the Unix world, the most common form of this is NFS. In the Windows world, "" ""the most common form is called CIFS (previously, SMB).<indexterm class="" ""\""singular\""><primary>migration</primary></indexterm><indexterm class="" ""\""singular\""><primary>live migration</primary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>file-level</secondary></"" ""indexterm>"" msgstr """" ""ファイルレベルのストレージでは、ユーザーは、オペレーティングシステムのファイ"" ""ルシステムインターフェースを使用して保存したデータにアクセスします。ネット"" ""ワークストレージソリューションの使用経験のあるユーザーの多くは、この形式の"" ""ネットワークストレージを使用したことがあります。Unix の分野では、ネットワーク"" ""ストレージで最も一般的なものが NFS で、Windows では CIFS (旧称 SMB) です。"" ""<indexterm class=\""singular\""><primary>migration</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ライブマイグレーション</"" ""primary></indexterm><indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>ファイルレベル</secondary></indexterm>"" msgid """" ""OpenStack clouds do not present file-level storage to end users. However, it "" ""is important to consider file-level storage for storing instances under "" ""<code>/var/lib/nova/instances</code> when designing your cloud, since you "" ""must have a shared file system if you want to support live migration."" msgstr """" ""OpenStack クラウドは、ファイルレベルのストレージはエンドユーザーには見えませ"" ""んが、クラウドの設計時に <code>/var/lib/nova/instances</code> の配下にインス"" ""タンスを格納する、ファイルレベルのストレージを検討してください。これは、ライ"" ""ブマイグレーションのサポートには、共有ファイルシステムが必要であるためです。"" msgid ""Choosing Storage Backends"" msgstr ""ストレージバックエンドの選択"" msgid """" ""Users will indicate different needs for their cloud use cases. Some may need "" ""fast access to many objects that do not change often, or want to set a time-"" ""to-live (TTL) value on a file. Others may access only storage that is "" ""mounted with the file system itself, but want it to be replicated instantly "" ""when starting a new instance. For other systems, ephemeral storage—storage "" ""that is released when a VM attached to it is shut down— is the preferred "" ""way. When you select <glossterm>storage backend</glossterm>s, <indexterm "" ""class=\""singular\""><primary>storage</primary><secondary>choosing backends</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>storage "" ""backend</primary></indexterm><indexterm class=\""singular\""><primary>backend "" ""interactions</primary><secondary>store</secondary></indexterm>ask the "" ""following questions on behalf of your users:"" msgstr """" ""クラウドのユースケースごとにニーズが異なります。頻繁に変更が発生しない多数の"" ""オブジェクトに素早くアクセスする必要がある場合、ファイルに Time-to-Live "" ""(TTL) の値を設定する場合、ファイルシステムのみにマウントされているストレージ"" ""のみにアクセスするが、新しいインスタンスの起動時には即時にそのストレージを複"" ""製する場合などがあります。他のシステムの場合は、一時ストレージ (ストレージに"" ""接続された仮想マシンがシャットダウンされている場合に開放されるストレージ) が"" ""より良い方法です。<glossterm>ストレージのバックエンド</glossterm>の選択時は、"" ""<indexterm class=\""singular\""><primary>ストレージ</primary><secondary>バック"" ""エンドの選択</secondary></indexterm><indexterm class=\""singular\""><primary>ス"" ""トレージバックエンド</primary></indexterm><indexterm class=\""singular"" ""\""><primary>バックエンドの対話</primary><secondary>store</secondary></"" ""indexterm>ユーザーの代わりに以下の質問を確認してください。"" msgid ""Do my users need block storage?"" msgstr ""ユーザがブロックストレージを必要とするか？"" msgid ""Do my users need object storage?"" msgstr ""ユーザがオブジェクトストレージを必要とするか？"" msgid ""Do I need to support live migration?"" msgstr ""管理者がライブマイグレーションを必要とするか？"" msgid """" ""Should my persistent storage drives be contained in my compute nodes, or "" ""should I use external storage?"" msgstr """" ""永続的ストレージをコンピュートノード内に持つべきか？それとも外部ストレージに"" ""持つべきか？"" msgid """" ""What is the platter count I can achieve? Do more spindles result in better I/"" ""O despite network access?"" msgstr """" ""実現可能な容量は？ネットワークアクセスでも、より多くのディスクがより良い I/O "" ""性能に繋がるか？"" msgid ""Which one results in the best cost-performance scenario I'm aiming for?"" msgstr ""どちらが自分の意図した最高のコストパフォーマンスシナリオを実現するか？"" msgid ""How do I manage the storage operationally?"" msgstr ""ストレージの運用管理をどうするか？"" msgid """" ""How redundant and distributed is the storage? What happens if a storage node "" ""fails? To what extent can it mitigate my data-loss disaster scenarios?"" msgstr """" ""ストレージの冗長性と分散をどうするか？ストレージノード障害でどうなるか？災害"" ""時、自分のデータ消失をどの程度軽減できるのか？"" msgid """" ""To deploy your storage by using only commodity hardware, you can use a "" ""number of open-source packages, as shown in <xref linkend=\""storage_solutions"" ""\""/>."" msgstr """" ""<xref linkend=\""storage_solutions\""/>で記載されているように、コモディティハー"" ""ドウェアを使用してストレージをデプロイする場合、オープンソースのパッケージを"" ""使用することができます。"" msgid ""Persistent file-based storage support"" msgstr ""永続ファイルベースのストレージサポート"" msgid "" "" msgstr "" "" msgid ""Object"" msgstr ""オブジェクトストレージ"" msgid ""Block"" msgstr ""ブロックストレージ"" msgid """" ""This list of open source file-level shared storage solutions is not "" ""exhaustive; other open source solutions exist (MooseFS). Your organization "" ""may already have deployed a file-level shared storage solution that you can "" ""use."" msgstr """" ""オープンソースのファイルレベルの共有ストレージソリューションに関する一覧は完"" ""全ではありません。その他のオープンソースソリューションも存在します "" ""(MooseFS)。ユーザーの所属組織では、すでにユーザーが使用できるように、ファイル"" ""レベルの共有ストレージソリューションがデプロイされている可能性があります。"" msgid ""File-level<placeholder-1/>"" msgstr ""ファイルレベル<placeholder-1/>"" msgid ""Swift"" msgstr ""Swift"" msgid ""LVM"" msgstr ""LVM"" msgid ""Ceph"" msgstr ""Ceph"" msgid ""Experimental"" msgstr ""テスト用"" msgid ""Gluster"" msgstr ""Gluster"" msgid ""NFS"" msgstr ""NFS"" msgid ""ZFS"" msgstr ""ZFS"" msgid ""Sheepdog"" msgstr ""Sheepdog"" msgid ""Storage Driver Support"" msgstr ""ストレージドライバーズサポート"" msgid """" ""In addition to the open source technologies, there are a number of "" ""proprietary solutions that are officially supported by OpenStack Block "" ""Storage.<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>storage driver support</secondary></indexterm> They are "" ""offered by the following vendors:"" msgstr """" ""オープンソースのテクノロジーに加え、OpenStack Block Storage で正式にサポート"" ""される専用ソリューションが多数存在します。<indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>ストレージドライバーのサポート</"" ""secondary></indexterm>以下のベンダーによりサポートされています。"" msgid ""IBM (Storwize family/SVC, XIV)"" msgstr ""IBM (Storwize family/SVC, XIV)"" msgid ""NetApp"" msgstr ""NetApp"" msgid ""Nexenta"" msgstr ""Nexenta"" msgid ""SolidFire"" msgstr ""SolidFire"" msgid """" ""You can find a matrix of the functionality provided by all of the supported "" ""Block Storage drivers on the <link href=\""https://wiki.openstack.org/wiki/"" ""CinderSupportMatrix\"" title=\""OpenStack wiki\"">OpenStack wiki</link>."" msgstr """" ""<link href=\""https://wiki.openstack.org/wiki/CinderSupportMatrix\"" title="" ""\""OpenStack wiki\"">OpenStack wiki</link> で、サポートされている全ブロックスト"" ""レージドライバーが提供する機能一覧を確認いただけます。"" msgid """" ""Also, you need to decide whether you want to support object storage in your "" ""cloud. The two common use cases for providing object storage in a compute "" ""cloud are:"" msgstr """" ""クラウド内でオブジェクトストレージの利用を検討する必要があります。コンピュー"" ""トクラウドで提供されるオブジェクトストレージの一般的な利用方法は以下の二つで"" ""す。"" msgid ""To provide users with a persistent storage mechanism"" msgstr ""ユーザに永続的ストレージの仕組みを提供する"" msgid ""As a scalable, reliable data store for virtual machine images"" msgstr ""スケーラブルで信頼性のある仮想マシンイメージデータストアとして利用する"" msgid ""Commodity Storage Backend Technologies"" msgstr ""商用ストレージバックエンドのテクノロジー"" msgid """" ""This section provides a high-level overview of the differences among the "" ""different commodity storage backend technologies. Depending on your cloud "" ""user's needs, you can implement one or many of these technologies in "" ""different combinations:<indexterm class=\""singular\""><primary>storage</"" ""primary><secondary>commodity storage</secondary></indexterm>"" msgstr """" ""このセクションでは、さまざまな商用ストレージバックエンドテクノロジーにおける"" ""相違点をカンタンにまとめます。クラウドユーザーのニーズに合わせて、1 つまたは"" ""多数のテクノロジーを組み合わせて実装することができます。<indexterm class="" ""\""singular\""><primary>storage</primary><secondary>commodity storage</"" ""secondary></indexterm>"" msgid """" ""The official OpenStack Object Store implementation. It is a mature "" ""technology that has been used for several years in production by Rackspace "" ""as the technology behind Rackspace Cloud Files. As it is highly scalable, it "" ""is well-suited to managing petabytes of storage. OpenStack Object Storage's "" ""advantages are better <phrase role=\""keep-together\"">integration</phrase> "" ""with OpenStack (integrates with OpenStack Identity, works with the OpenStack "" ""dashboard interface) and better support for multiple data center deployment "" ""through support of asynchronous eventual consistency replication."" msgstr """" ""公式の OpenStack Object Store 実装。Rackspace Cloud Filesのベースとなる技術と"" ""して、RackSpace により実稼動環境で数年間使用された成熟テクノロジーです。拡張"" ""性が高いため、ペタバイトレベルのストレージを管理するのに非常に適しています。"" ""OpenStack Object Storage の利点は OpenStack (OpenStack Identity と統合し、"" ""OpenStack Dashboard インターフェースと連携) と<phrase role=\""keep-together\"">"" ""統合でき</phrase>、非同期のイベントを一貫性を保ちながら複製できるため、複数の"" ""データセンターのデプロイメントへのサポートも向上されています。"" msgid """" ""Therefore, if you eventually plan on distributing your storage cluster "" ""across multiple data centers, if you need unified accounts for your users "" ""for both compute and object storage, or if you want to control your object "" ""storage with the OpenStack dashboard, you should consider OpenStack Object "" ""Storage. More detail can be found about OpenStack Object Storage in the "" ""section below.<indexterm class=\""singular\""><primary>accounts</primary></"" ""indexterm>"" msgstr """" ""そのため、最終的に、複数のデータセンターにまたがってストレージクラスターを分"" ""散するように計画した場合、Compute およびオブジェクトストレージ用に統合アカウ"" ""ントが必要な場合、または OpenStack Dashboard でオブジェクトストレージを制御す"" ""る場合、OpenStack Object Storage を考慮してみてください。以下のセクションで "" ""OpenStack Object Storage iについて詳しく記載されています。<indexterm class="" ""\""singular\""><primary>アカウント</primary></indexterm>"" msgid ""Ceph<indexterm class=\""singular\""><primary>Ceph</primary></indexterm>"" msgstr ""Ceph<indexterm class=\""singular\""><primary>Ceph</primary></indexterm>"" msgid """" ""A scalable storage solution that replicates data across commodity storage "" ""nodes. Ceph was originally developed by one of the founders of DreamHost and "" ""is currently used in production there."" msgstr """" ""商用ストレージノード全体でデータを複製する拡張性の高いストレージソリューショ"" ""ン。Ceph は、DreamHost の創設者により開発され、現在は実稼動環境で使用されてい"" ""ます。"" msgid """" ""Ceph was designed to expose different types of storage interfaces to the end "" ""user: it supports object storage, block storage, and file-system interfaces, "" ""although the file-system interface is not yet considered production-ready. "" ""Ceph supports the same API as swift for object storage and can be used as a "" ""backend for cinder block storage as well as backend storage for glance "" ""images. Ceph supports \""thin provisioning,\"" implemented using copy-on-write."" msgstr """" ""Ceph は、異なる種類のストレージインターフェースをエンドユーザーに公開するよう"" ""に設計されました。Ceph は、オブジェクトストレージ、ブロックストレージ、ファイ"" ""ルシステムインターフェースをサポートしていますが、ファイルシステムインター"" ""フェースは、実稼動環境での使用にはまだ適していません。Ceph は、オブジェクトス"" ""トレージでは swift と同じ API をサポートしており、cinder ブロックストレージの"" ""バックエンド、glance イメージのバックエンドストレージとして使用することができ"" ""ます。Ceph は、copy-on-write を使用して実装されたシンプロビジョニングをサポー"" ""トします。"" msgid """" ""This can be useful when booting from volume because a new volume can be "" ""provisioned very quickly. Ceph also supports keystone-based authentication "" ""(as of version 0.56), so it can be a seamless swap in for the default "" ""OpenStack swift implementation."" msgstr """" ""新規ボリュームは非常に早くプロビジョニングされるため、ボリュームからの起動に"" ""便利です。また、Ceph は keystone ベースの認証 (バージョン 0.56 以降) もサポー"" ""トするため、デフォルトの OpenStack swift 実装とシームレスに切り替えることがで"" ""きます。"" msgid """" ""Ceph's advantages are that it gives the administrator more fine-grained "" ""control over data distribution and replication strategies, enables you to "" ""consolidate your object and block storage, enables very fast provisioning of "" ""boot-from-volume instances using thin provisioning, and supports a "" ""distributed file-system interface, though this interface is <link href="" ""\""http://ceph.com/docs/master/cephfs/\"" title=\""OpenStack wiki\"">not yet "" ""recommended</link> for use in production deployment by the Ceph project."" msgstr """" ""Ceph の利点は、管理者がより細かくデータの分散やレプリカのストラテジーを管理で"" ""きるようになり、オブジェクトとブロックストレージを統合し、シンプロビジョニン"" ""グでボリュームから起動するインスタンスを非常に早くプロビジョニングできるだけ"" ""でなく、分散ファイルシステムのインターフェースもサポートしている点です。ただ"" ""し、このインターフェースは、Ceph プロジェクトによる実稼動デプロイメントでの使"" ""用には、 <link href=\""http://ceph.com/docs/master/cephfs/\"" title="" ""\""OpenStack wiki\"">推奨されていません</link>。"" msgid """" ""If you want to manage your object and block storage within a single system, "" ""or if you want to support fast boot-from-volume, you should consider Ceph."" msgstr """" ""単一システムでオブジェクトストレージとブロックストレージを管理する場合、また"" ""はボリュームから素早く起動するサポートが必要な場合、Ceph の使用を検討してくだ"" ""さい。"" msgid """" ""Gluster<indexterm class=\""singular\""><primary>GlusterFS</primary></indexterm>"" msgstr """" ""Gluster<indexterm class=\""singular\""><primary>GlusterFS</primary></indexterm>"" msgid """" ""A distributed, shared file system. As of Gluster version 3.3, you can use "" ""Gluster to consolidate your object storage and file storage into one unified "" ""file and object storage solution, which is called Gluster For OpenStack "" ""(GFO). GFO uses a customized version of swift that enables Gluster to be "" ""used as the backend storage."" msgstr """" ""分散型の共有ファイルシステム。Gluster バージョン 3.3 以降、Gluster を使用し"" ""て、オブジェクトストレージとファイルストレージを1 つの統合ファイルとオブジェ"" ""クトストレージソリューションにまとめることができるようになりました。これは"" ""Gluster For OpenStack (GFO) と呼ばれます。GFO は、swift のカスタマイズバー"" ""ジョンを使用しており、Gluster がバックエンドストレージを使用できるようになっ"" ""ています。"" msgid """" ""The main reason to use GFO rather than regular swift is if you also want to "" ""support a distributed file system, either to support shared storage live "" ""migration or to provide it as a separate service to your end users. If you "" ""want to manage your object and file storage within a single system, you "" ""should consider GFO."" msgstr """" ""通常の swift ではなく GFO を使用するのは、主に、分散ファイルシステムのサポー"" ""トや、共有ストレージのライブマイグレーションのサポートを提供したり、エンド"" ""ユーザーに個別サービスとして提供したりするためです。単一システムでオブジェク"" ""トとファイルストレージを管理する場合は、GFO の使用を検討してください。"" msgid """" ""LVM<indexterm class=\""singular\""><primary>LVM (Logical Volume Manager)</"" ""primary></indexterm>"" msgstr """" ""LVM<indexterm class=\""singular\""><primary>LVM (Logical Volume Manager)</"" ""primary></indexterm>"" msgid """" ""The Logical Volume Manager is a Linux-based system that provides an "" ""abstraction layer on top of physical disks to expose logical volumes to the "" ""operating system. The LVM backend implements block storage as LVM logical "" ""partitions."" msgstr """" ""論理ボリュームマネージャー (LVM) は Linux ベースのシステムで、物理ディスク上"" ""に抽象層を提供して論理ボリュームをオペレーティングシステムに公開します。LVM "" ""バックエンドは、LVM 論理パーティションとしてブロックストレージを実装します。"" msgid """" ""On each host that will house block storage, an administrator must initially "" ""create a volume group dedicated to Block Storage volumes. Blocks are created "" ""from LVM logical volumes."" msgstr """" ""ブロックストレージを収容する各ホストでは、管理者は事前にブロックストレージ専"" ""用のボリュームグループを作成しておく必要があります。ブロックストレージはLVM論"" ""理ボリュームから作られます。"" msgid """" ""LVM does <emphasis>not</emphasis> provide any replication. Typically, "" ""administrators configure RAID on nodes that use LVM as block storage to "" ""protect against failures of individual hard drives. However, RAID does not "" ""protect against a failure of the entire host."" msgstr """" ""LVMはレプリケーションを<emphasis>提供しません</emphasis>。通常、管理者はブ"" ""ロックストレージとしてLVMを利用するホスト上にRAIDを構成し、ここのハードディス"" ""ク障害からブロックストレージを保護します。しかしRAIDではホストそのものの障害"" ""には対応できません。"" msgid ""ZFS<indexterm class=\""singular\""><primary>ZFS</primary></indexterm>"" msgstr ""ZFS<indexterm class=\""singular\""><primary>ZFS</primary></indexterm>"" msgid """" ""The Solaris iSCSI driver for OpenStack Block Storage implements blocks as "" ""ZFS entities. ZFS is a file system that also has the functionality of a "" ""volume manager. This is unlike on a Linux system, where there is a "" ""separation of volume manager (LVM) and file system (such as, ext3, ext4, "" ""xfs, and btrfs). ZFS has a number of advantages over ext4, including "" ""improved data-integrity checking."" msgstr """" ""OpenStack Block Storage 用の Solaris iSCSI ドライバーは、ZFS エンティティーと"" ""してブロックを実装します。ZFS は、ボリュームManagerの機能が備わっているファイ"" ""ルシステムです。これは、ボリュームマネージャー (LVM) およびファイルシステム "" ""(ext3、ext4、xfs、btrfs など) が分離している Linux システムとは違います。ZFS "" ""は、向上されたデータ整合性チェックなど、ext4 よりも多数利点があります。"" msgid """" ""The ZFS backend for OpenStack Block Storage supports only Solaris-based "" ""systems, such as Illumos. While there is a Linux port of ZFS, it is not "" ""included in any of the standard Linux distributions, and it has not been "" ""tested with OpenStack Block Storage. As with LVM, ZFS does not provide "" ""replication across hosts on its own; you need to add a replication solution "" ""on top of ZFS if your cloud needs to be able to handle storage-node failures."" msgstr """" ""OpenStack Block Storage の ZFS バックエンドは、Illumos などの Solaris ベース"" ""のシステムのみをサポートします。ZFS の Linux ポートは存在するものの、標準の "" ""Linux ディストリビューションには含まれておらず、OpenStack Block Storage では"" ""テストされていません。LVM では、ZFS はこれだけではホスト間の複製ができませ"" ""ん。つまり、お使いのクラウドでストレージノードの問題を処理する機能が必要な場"" ""合、ZFS に複製ソリューションを追加する必要があります。"" msgid """" ""We don't recommend ZFS unless you have previous experience with deploying "" ""it, since the ZFS backend for Block Storage requires a Solaris-based "" ""operating system, and we assume that your experience is primarily with Linux-"" ""based systems."" msgstr """" ""本書は、Linux ベースシステムを主に使用するユーザーを想定しており、Block "" ""Storage の ZFS バックエンドには Solaris ベースのオペレーティングシステムが必"" ""要であるため、ZFS でのデプロイ経験がない場合は、ZFS は推奨していません。"" msgid """" ""We hope that you now have some considerations in mind and questions to ask "" ""your future cloud users about their storage use cases. As you can see, your "" ""storage decisions will also influence your network design for performance "" ""and security needs. Continue with us to make more informed decisions about "" ""your OpenStack cloud <phrase role=\""keep-together\"">design</phrase>."" msgstr """" ""今後のクラウドユーザーにストレージのユースケースに関する質問事項および、懸念"" ""点など理解いただけたかと思います。ストレージの決定はパフォーマンスやセキュリ"" ""ティのニーズにあったネットワーク設計をする際に影響を与えます。OpenStack クラ"" ""ウド <phrase role=\""keep-together\"">設計</phrase> について理解したうえで意思"" ""決定が行えるように、本書を読み進めてください。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"" msgstr """" ""@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/"" ""openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"" msgid ""Managing Projects and Users"" msgstr ""プロジェクトとユーザーの管理"" msgid """" ""An OpenStack cloud does not have much value without users. This chapter "" ""covers topics that relate to managing users, projects, and quotas. This "" ""chapter describes users and projects as described by version 2 of the "" ""OpenStack Identity API."" msgstr """" ""OpenStack クラウドは、ユーザーなしでは特に価値はありません。本章では、ユー"" ""ザー、プロジェクト、クォータの管理に関するトピックを記載します。また、"" ""OpenStack Identity API のバージョン 2 で説明されているように、ユーザーとプロ"" ""ジェクトについても説明します。"" msgid """" ""While version 3 of the Identity API is available, the client tools do not "" ""yet implement those calls, and most OpenStack clouds are still implementing "" ""Identity API v2.0.<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>Identity Service API</secondary></indexterm>"" msgstr """" ""Identity API バージョン 3 が利用できますが、クライアントツールにはこれらの呼"" ""び出しがまだ実装されておらず、多くの OpenStack クラウドは Identity API v2.0 "" ""を実装しています。<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>Identity Service API</secondary></indexterm>"" msgid ""Projects or Tenants?"" msgstr ""プロジェクトかテナントか?"" msgid """" ""In OpenStack user interfaces and documentation, a group of users is referred "" ""to as a <glossterm>project</glossterm> or <glossterm>tenant</glossterm>. "" ""These terms are interchangeable.<indexterm class=\""singular\""><primary>user "" ""management</primary><secondary>terminology for</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>tenant</"" ""primary><secondary>definition of</secondary></indexterm><indexterm class="" ""\""singular\""><primary>projects</primary><secondary>definition of</"" ""secondary></indexterm>"" msgstr """" ""OpenStack ユーザーインターフェースとドキュメントでは、ユーザーのグループは "" ""<glossterm>プロジェクト</glossterm> または <glossterm>テナント</glossterm> と"" ""呼ばれます。これらの用語は同義です。<indexterm class=\""singular\""><primary>"" ""ユーザー管理</primary><secondary>用語</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>テナント</primary><secondary>定義</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>プロジェクト</"" ""primary><secondary>定義</secondary></indexterm>"" msgid """" ""The initial implementation of the OpenStack Compute Service (nova) had its "" ""own authentication system and used the term <literal>project</literal>. When "" ""authentication moved into the OpenStack Identity Service (keystone) project, "" ""it used the term <literal>tenant</literal> to refer to a group of users. "" ""Because of this legacy, some of the OpenStack tools refer to projects and "" ""some refer to tenants."" msgstr """" ""OpenStack Compute サービス (Nova) の初期実装は独自の認証システムを持ち、"" ""<literal>プロジェクト</literal>という用語を使用していました。認証が "" ""OpenStack Identity サービス (Keystone) プロジェクトに移行したとき、ユーザーの"" ""グループを意味する用語として<literal>テナント</literal>という用語が使用されま"" ""した。このような経緯のため、いくつかの OpenStack ツールはプロジェクトを使用"" ""し、いくつかはテナントを使用します。"" msgid """" ""This guide uses the term <literal>project</literal>, unless an example shows "" ""interaction with a tool that uses the term <literal>tenant</literal>."" msgstr """" ""このガイドは<literal>プロジェクト</literal>という用語を使用します。<literal>"" ""テナント</literal>という用語を使用するツールとやりとりする例もあります。"" msgid ""Managing Projects"" msgstr ""プロジェクトの管理"" msgid """" ""Users must be associated with at least one project, though they may belong "" ""to many. Therefore, you should add at least one project before adding users."" ""<indexterm class=\""singular\""><primary>user management</"" ""primary><secondary>adding projects</secondary></indexterm>"" msgstr """" ""ユーザーは、多数のプロジェクトに所属することは可能ですが、最低でも 1 つのプロ"" ""ジェクトと関連付ける必要があります。そのため、ユーザー追加の前にプロジェクト"" ""を 1 つ追加しておく必要があります。<indexterm class=\""singular\""><primary>"" ""ユーザー管理</primary><secondary>プロジェクトの追加</secondary></indexterm>"" msgid ""Adding Projects"" msgstr ""プロジェクトの追加"" msgid ""To create a project through the OpenStack dashboard:"" msgstr ""OpenStack Dashboard でプロジェクトを作成します。"" msgid ""Log in as an administrative user."" msgstr ""管理ユーザーとしてログインします。"" msgid ""Select the <guilabel>Admin</guilabel> tab in the left navigation bar."" msgstr """" ""左側にあるナビゲーションバーの <guilabel>管理</guilabel> タブを選択します。"" msgid ""Under Identity Panel, click <guilabel>Projects</guilabel>."" msgstr ""認証パネルの <guilabel>プロジェクト</guilabel> をクリックします。"" msgid ""Click the <guibutton>Create Project</guibutton> button."" msgstr ""<guibutton>プロジェクトの作成</guibutton> ボタンをクリックします。"" msgid """" ""You are prompted for a project name and an optional, but recommended, "" ""description. Select the checkbox at the bottom of the form to enable this "" ""project. By default, it is enabled, as shown in <xref linkend=\""horizon-add-"" ""project\""/>."" msgstr """" ""プロジェクト名および任意の説明 (推奨) が要求されます。フォームの一番下の"" ""チェックボックスを選択してこのプロジェクトを有効にします。<xref linkend="" ""\""horizon-add-project\""/>のように、デフォルトでは、有効になっています。"" msgid ""Dashboard's Create Project form"" msgstr ""Dashboard のプロジェクトの作成フォーム"" msgid """" ""It is also possible to add project members and adjust the project quotas. "" ""We'll discuss those actions later, but in practice, it can be quite "" ""convenient to deal with all these operations at one time."" msgstr """" ""プロジェクトメンバーの追加やプロジェクトのクォータの調節も可能です。このよう"" ""なアクションについては後ほど説明しますが、実際にこれらの操作を扱うと非常に便"" ""利です。"" msgid """" ""To add a project through the command line, you must use the keystone "" ""utility, which uses <literal>tenant</literal> in place of <literal>project</"" ""literal>:"" msgstr """" ""コマンドラインでプロジェクトを追加するには、<literal>project</literal> の代わ"" ""りに <literal>tenant</literal> を使用する keystone ユーティリティを使用する必"" ""要があります。"" msgid """" ""This command creates a project named \""demo.\"" Optionally, you can add a "" ""description string by appending <code>--description <replaceable>tenant-"" ""description</replaceable></code>, which can be very useful. You can also "" ""create a group in a disabled state by appending <code>--enabled false</code> "" ""to the command. By default, projects are created in an enabled state."" msgstr """" ""このコマンドは、demo という名前のプロジェクトを作成します。オプションで、"" ""<code>--description <replaceable>tenant-description</replaceable></code> を追"" ""加することで、説明の文字列を追加することができ、非常に便利です。また、コマン"" ""ドに <code>--enabled false</code> を追加して、グループを無効な状態で作成する"" ""こともできます。デフォルトでは、有効化された状態でプロジェクトが作成されま"" ""す。"" msgid ""Quotas"" msgstr ""クォータ"" msgid """" ""To prevent system capacities from being exhausted without notification, you "" ""can set up <glossterm baseform=\""quota\"">quotas</glossterm>. Quotas are "" ""operational limits. For example, the number of gigabytes allowed per tenant "" ""can be controlled to ensure that a single tenant cannot consume all of the "" ""disk space. Quotas are currently enforced at the tenant (or project) level, "" ""rather than the user level.<indexterm class=\""startofrange\"" xml:id="" ""\""quotas9\""><primary>quotas</primary></indexterm><indexterm class=\""singular"" ""\""><primary>user management</primary><secondary>quotas</secondary></"" ""indexterm>"" msgstr """" ""システムの容量が通知なしに完全に消費されないように、<glossterm baseform="" ""\""quota\"">クォータ</glossterm> を設定することができます。クォータとは、運用上"" ""の制限値です。たとえば、各テナントに許容される容量 (GB) を制御して、単一のテ"" ""ナントで全ディスク容量すべてが消費されないようにします。現在、ユーザーレベル"" ""ではなく、テナント (またはプロジェクト) レベルで、クォータを有効にすることが"" ""できます。<indexterm class=\""startofrange\"" xml:id=\""quotas9\""><primary>"" ""クォータ</primary></indexterm><indexterm class=\""singular\""><primary>ユーザー"" ""管理</primary><secondary>クォータ</secondary></indexterm>"" msgid """" ""Because without sensible quotas a single tenant could use up all the "" ""available resources, default quotas are shipped with OpenStack. You should "" ""pay attention to which quota settings make sense for your hardware "" ""capabilities."" msgstr """" ""妥当なクォータがないと、単一のテナントが利用可能なリソースをすべて使用してし"" ""まう可能性があるため、デフォルトのクォータが OpenStack には含まれています。お"" ""使いのハードウェア機能には、どのクォータ設定が適切か注意してください。"" msgid """" ""Using the command-line interface, you can manage quotas for the OpenStack "" ""Compute Service and the Block Storage Service."" msgstr """" ""コマンドラインインターフェースを使って、OpenStack Compute サービスと Block "" ""Storage サービスのクォータを管理できます。"" msgid """" ""Typically, default values are changed because a tenant requires more than "" ""the OpenStack default of 10 volumes per tenant, or more than the OpenStack "" ""default of 1 TB of disk space on a compute node."" msgstr """" ""テナントには、10 個を超える Block Storage ボリュームまたはコンピュートノード"" ""で 1 TB 以上が必要であるため、通常クラウドのオペレーターはデフォルト値を変更"" ""します。"" msgid ""To view all tenants, run: <placeholder-1/>"" msgstr """" ""全てのテナントを表示するには、以下のコマンドを実行します。<placeholder-1/>"" msgid ""Set Image Quotas"" msgstr ""イメージクォータの設定"" msgid """" ""To enable this feature, edit the <filename>/etc/glance/glance-api.conf</"" ""filename> file, and under the [DEFAULT] section, add:"" msgstr """" ""この機能を有効にするには、<filename>/etc/glance/glance-api.conf</filename> "" ""ファイルを編集して [DEFAULT] セクションに以下を追加します。"" msgid ""For example, to restrict a project's image storage to 5 GB, do this:"" msgstr """" ""たとえば、プロジェクトのイメージストレージを 5GB に制限するには、以下を実行し"" ""ます。"" msgid ""Set Compute Service Quotas"" msgstr ""コンピュートサービスのクォータの設定"" msgid ""Quota"" msgstr ""クォータ"" msgid ""Property name"" msgstr ""プロパティ名"" msgid ""Fixed IPs"" msgstr ""固定 IP"" msgid """" ""Number of fixed IP addresses allowed per tenant. This number must be equal "" ""to or greater than the number of allowed instances."" msgstr """" ""テナント毎の固定 IP アドレスの最大数。この数はテナント毎の最大インスタンス数"" ""以上にしなければなりません。"" msgid ""fixed-ips"" msgstr ""fixed-ips"" msgid ""Number of floating IP addresses allowed per tenant."" msgstr ""テナントごとの最大 Floating IP 数"" msgid ""floating-ips"" msgstr ""floating-ips"" msgid ""Injected file content bytes"" msgstr ""注入ファイルのコンテンツ (バイト)"" msgid ""Number of content bytes allowed per injected file."" msgstr ""injected file あたりの最大バイト数"" msgid ""injected-file-content-bytes"" msgstr ""injected-file-content-bytes"" msgid ""Injected file path bytes"" msgstr ""注入ファイルのパス (バイト)"" msgid ""Number of bytes allowed per injected file path."" msgstr ""injected file のパス長の最大バイト数"" msgid ""injected-file-path-bytes"" msgstr ""injected-file-path-bytes"" msgid ""Injected files"" msgstr ""注入ファイル"" msgid ""Number of injected files allowed per tenant."" msgstr ""injected file の最大数"" msgid ""injected-files"" msgstr ""injected-files"" msgid ""Number of instances allowed per tenant."" msgstr ""テナントごとの最大インスタンス数"" msgid ""Key pairs"" msgstr ""キーペア"" msgid ""Number of key pairs allowed per user."" msgstr ""ユーザーごとの最大キーペア数"" msgid ""key-pairs"" msgstr ""key-pairs"" msgid ""Metadata items"" msgstr ""メタデータ項目"" msgid ""Number of metadata items allowed per instance."" msgstr ""インスタンスごとのメタデータ項目数"" msgid ""metadata-items"" msgstr ""metadata-items"" msgid ""RAM"" msgstr ""メモリー"" msgid ""ram"" msgstr ""ram"" msgid ""Security group rules"" msgstr ""セキュリティグループルール"" msgid ""Number of rules per security group."" msgstr ""セキュリティグループごとのセキュリティルール数"" msgid ""security-group-rules"" msgstr ""security-group-rules"" msgid ""Security groups"" msgstr ""セキュリティグループ"" msgid ""Number of security groups per tenant."" msgstr ""テナントごとのセキュリティグループ数"" msgid ""security-groups"" msgstr ""security-groups"" msgid ""Number of instance cores allowed per tenant."" msgstr ""テナントごとのインスタンスのコア数"" msgid ""cores"" msgstr ""cores"" msgid ""View and update compute quotas for a tenant (project)"" msgstr ""テナント (プロジェクト) のコンピュートクォータの表示/更新"" msgid ""To view and update default quota values"" msgstr ""デフォルトのクォータ値の表示と更新"" msgid ""List all default quotas for all tenants, as follows:"" msgstr """" ""全テナントに対するクォータのデフォルト値を全て表示するには、以下のようにしま"" ""す。"" msgid ""Update a default value for a new tenant, as follows:"" msgstr """" ""新規テナントに対するクォータのデフォルト値を更新するには、以下のようにしま"" ""す。"" msgid ""value"" msgstr ""value"" msgid ""To view quota values for a tenant (project)"" msgstr ""テナント (プロジェクト) のクォータ値の表示"" msgid ""Place the tenant ID in a useable variable, as follows:"" msgstr ""テナント ID を変数に格納しておきます。"" msgid ""tenantName"" msgstr ""tenantName"" msgid ""List the currently set quota values for a tenant, as follows:"" msgstr ""テナントの現在のクォータ値を一覧表示します。"" msgid ""To update quota values for a tenant (project)"" msgstr ""テナント (プロジェクト) のクォータ値の更新"" msgid ""Obtain the tenant ID, as follows:"" msgstr ""テナント ID を取得します。"" msgid ""Update a particular quota value, as follows:"" msgstr ""指定したクォータ値を更新します。"" msgid ""quotaName"" msgstr ""quotaName"" msgid ""quotaValue"" msgstr ""quotaValue"" msgid ""tenantID"" msgstr ""tenantID"" msgid ""gigabytes"" msgstr ""gigabytes"" msgid ""snapshots"" msgstr ""snapshots"" msgid ""Number of Block Storage snapshots allowed per tenant."" msgstr ""テナントごとのブロックストレージスナップショット数"" msgid ""volumes"" msgstr ""volumes"" msgid ""View and update Block Storage quotas for a tenant (project)"" msgstr """" ""Block Storage サービスのテナント (プロジェクト) の クォータの表示と更新"" msgid ""To view and update default Block Storage quota values"" msgstr ""Block Storage のデフォルトのクォータ値の表示と更新"" msgid """" ""To update a default value for a new tenant, update the property in the "" ""<filename>/etc/cinder/cinder.conf</filename> file."" msgstr """" ""新規テナントのクォータのデフォルト値を更新するには、<filename>/etc/cinder/"" ""cinder.conf</filename> ファイルの対応する項目を更新します。"" msgid ""View quotas for the tenant, as follows:"" msgstr ""特定のテナントのクォータを表示するには以下のようにします。"" msgid ""NewValue"" msgstr ""NewValue"" msgid ""User Management"" msgstr ""ユーザー管理"" msgid ""Creating New Users"" msgstr ""新規ユーザーの作成"" msgid ""To create a user, you need the following information:"" msgstr ""ユーザーを作成するには、以下の情報が必要です。"" msgid ""Username"" msgstr ""ユーザー名"" msgid ""Email address"" msgstr ""電子メールアドレス"" msgid ""Password"" msgstr ""パスワード"" msgid ""Primary project"" msgstr ""主プロジェクト"" msgid ""Role"" msgstr ""役割"" msgid ""admin"" msgstr ""admin"" msgid ""It is possible to define other roles, but doing so is uncommon."" msgstr ""他の役割を定義できますが、一般的にはそうしません。"" msgid ""Associating Users with Projects"" msgstr ""プロジェクトへのユーザーの割り当て"" msgid """" ""From here, click the <guiicon>+</guiicon> icon to add users to the project. "" ""Click the <guiicon>-</guiicon> to remove them."" msgstr """" ""ここから、プロジェクトにユーザーを追加するには <guiicon>+</guiicon> アイコン"" ""をクリックします。削除するには <guiicon>-</guiicon> をクリックします。"" msgid ""Customizing Authorization"" msgstr ""権限のカスタマイズ"" msgid """" ""The OpenStack service's policy engine matches a policy directly. A rule "" ""indicates evaluation of the elements of such policies. For instance, in a "" ""<code>compute:create: [[\""rule:admin_or_owner\""]]</code> statement, the "" ""policy is <code>compute:create</code>, and the rule is <code>admin_or_owner</"" ""code>."" msgstr """" ""OpenStack サービスのポリシーエンジンがポリシーと直接照合を行います。ルールは"" ""そのようなポリシーの要素の評価を意味します。たとえば、<code>compute:create: "" ""[[\""rule:admin_or_owner\""]]</code> 文において、ポリシーは <code>compute:"" ""create</code> で、ルールは <code>admin_or_owner</code> です。"" msgid """" ""Here are snippets of the default nova <filename>policy.json</filename> file:"" msgstr """" ""これは標準の nova <filename>policy.json</filename> ファイルの抜粋です。"" msgid """" ""In some cases, some operations should be restricted to administrators only. "" ""Therefore, as a further example, let us consider how this sample policy file "" ""could be modified in a scenario where we enable users to create their own "" ""flavors:"" msgstr """" ""いくつかの場合では、いくつかの操作を管理者のみに制限すべきです。そこで、次の"" ""例では、ユーザーが自分のフレーバーを作成できるようにするシナリオの場合に、こ"" ""のサンプルのポリシーファイルをどのように変更すればよいかを示します。"" msgid ""Compute Nodes"" msgstr ""コンピュートノード"" msgid """" ""In this chapter, we discuss some of the choices you need to consider when "" ""building out your compute nodes. Compute nodes form the resource core of the "" ""OpenStack Compute cloud, providing the processing, memory, network and "" ""storage resources to run instances."" msgstr """" ""本章では、コンピュートノードの構築時に考慮する必要のある選択肢について説明し"" ""ます。コンピュートノードは、OpenStack Compute クラウドのリソースコアを構成"" ""し、プロセッシング、メモリー、ネットワーク、ストレージの各リソースを提供して"" ""インスタンスを実行します。"" msgid ""Choosing a CPU"" msgstr ""CPU の選択"" msgid """" ""The type of CPU in your compute node is a very important choice. First, "" ""ensure that the CPU supports virtualization by way of <emphasis>VT-x</"" ""emphasis> for Intel chips and <emphasis>AMD-v</emphasis> for AMD chips."" ""<indexterm class=\""singular\""><primary>CPUs (central processing units)</"" ""primary><secondary>choosing</secondary></indexterm><indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>CPU choice</"" ""secondary></indexterm>"" msgstr """" ""コンピュートノードの CPU タイプを選択することは非常に重要です。まず、Intel "" ""チップには <emphasis>VT-x</emphasis>、AMD チップには <emphasis>AMD-v</"" ""emphasis> という風に、CPU が仮想化をサポートするようにします。<indexterm "" ""class=\""singular\""><primary>CPU (central processing unit)</"" ""primary><secondary>選択</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>コンピュートノード</primary><secondary>CPU の選択</secondary></"" ""indexterm>"" msgid """" ""The number of cores that the CPU has also affects the decision. It's common "" ""for current CPUs to have up to 12 cores. Additionally, if an Intel CPU "" ""supports hyperthreading, those 12 cores are doubled to 24 cores. If you "" ""purchase a server that supports multiple CPUs, the number of cores is "" ""further multiplied.<indexterm class=\""singular\""><primary>cores</primary></"" ""indexterm><indexterm class=\""singular\""><primary>hyperthreading</primary></"" ""indexterm><indexterm class=\""singular\""><primary>multithreading</primary></"" ""indexterm>"" msgstr """" ""CPU のコア数も選択に影響します。現在の CPU では最大 12 コアあるのが一般的で"" ""す。さらに、Intel CPU がハイパースレッディングをサポートしている場合、12 コア"" ""は 2 倍の 24 コアになります。複数の CPU をサポートするサーバーを購入する場"" ""合、コア数はさらに倍になっていきます。<indexterm class=\""singular\""><primary>"" ""コア</primary></indexterm><indexterm class=\""singular\""><primary>ハイパース"" ""レッディング</primary></indexterm><indexterm class=\""singular\""><primary>マル"" ""チスレッド</primary></indexterm>"" msgid ""Multithread Considerations"" msgstr ""マルチスレッドの課題"" msgid """" ""Hyper-Threading is Intel's proprietary simultaneous multithreading "" ""implementation used to improve parallelization on their CPUs. You might "" ""consider enabling Hyper-Threading to improve the performance of "" ""multithreaded applications."" msgstr """" ""ハイパースレッディングは、Intel 専用の同時マルチスレッド実装で、CPU の並列化"" ""向上に使用されます。マルチスレッドアプリケーションのパフォーマンスを改善する"" ""には、ハイパースレッディングを有効にすることを検討してください。"" msgid """" ""Whether you should enable Hyper-Threading on your CPUs depends upon your use "" ""case. For example, disabling Hyper-Threading can be beneficial in intense "" ""computing environments. We recommend that you do performance testing with "" ""your local workload with both Hyper-Threading on and off to determine what "" ""is more appropriate in your case.<indexterm class=\""singular\""><primary>CPUs "" ""(central processing units)</primary><secondary>enabling hyperthreading on</"" ""secondary></indexterm>"" msgstr """" ""CPU のハイパースレッディングを有効にするかどうかは、それぞれのユースケースに"" ""より変わってきます。例えば、ハイパースレッディングを無効にすると、負荷の高い"" ""コンピューティング環境で有用です。ハイパースレッディングがオン、オフの両方の"" ""状態でローカルのワークロードを使用してパフォーマンスのテストを実施し、各ケー"" ""スでいずれが適しているか決定するように推奨しています。<indexterm class="" ""\""singular\""><primary>CPU (central processing unit)</primary><secondary>ハイ"" ""パースレッディングをオンにする</secondary></indexterm>"" msgid ""Choosing a Hypervisor"" msgstr ""ハイパーバイザーの選択"" msgid ""LXC"" msgstr ""LXC"" msgid ""QEMU"" msgstr ""QEMU"" msgid ""Xen"" msgstr ""Xen"" msgid ""Hyper-V"" msgstr ""Hyper-V"" msgid ""Docker"" msgstr ""Docker"" msgid """" ""Probably the most important factor in your choice of hypervisor is your "" ""current usage or experience. Aside from that, there are practical concerns "" ""to do with feature parity, documentation, and the level of community "" ""experience."" msgstr """" ""おそらく、ハイパーバイザーの選択で最も重要な要素は、現在の使用法やこれまでの"" ""経験でしょう。それ以外では、同等の機能の実用上の懸念、ドキュメント、コミュニ"" ""ティでの経験量などあると思います。""""It is also possible to run multiple hypervisors in a single deployment using "" ""host aggregates or cells. However, an individual compute node can run only a "" ""single hypervisor at a time.<indexterm class=\""singular"" ""\""><primary>hypervisors</primary><secondary>running multiple</secondary></"" ""indexterm>""""ホストアグリゲートやセルを使用すると、1 つのデプロイメントで複数のハイパーバ"" ""イザーを実行することも可能です。しかし、個別のコンピュートノードでは 1 度につ"" ""き 1 つのハイパーバイザーしか実行することができません。<indexterm class="" ""\""singular\""><primary>hypervisors</primary><secondary>複数実行</secondary></""msgid ""Instance Storage Solutions"" msgstr ""インスタンスストレージのソリューション""msgid ""They are:"" msgstr ""次の3つの方法があります。""msgid ""Off compute node storage—shared file system"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）""msgid ""On compute node storage—shared file system"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）"" msgid ""On compute node storage—nonshared file system"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）""""In general, the questions you should ask when selecting storage are as "" ""follows:"" msgstr ""一般的に、ストレージを選択する際に以下の点を考慮する必要があります。"" msgid ""What is the platter count you can achieve?"" msgstr ""実現したいプラッター数（ディスク容量）はどれくらいか？"" msgid ""Do more spindles result in better I/O despite network access?""""ネットワークアクセスがあったとしても、ディスク数が多い方が良い I/O 性能が得ら"" ""れるか？""""Which one results in the best cost-performance scenario you're aiming for?"" msgstr ""何があなたが目指すコストパフォーマンスのシナリオはどれか？"" msgid ""How do you manage the storage operationally?"" msgstr ""運用上ストレージをどのように管理したいのか？""""Many operators use separate compute and storage hosts. Compute services and "" ""storage services have different requirements, and compute hosts typically "" ""require more CPU and RAM than storage hosts. Therefore, for a fixed budget, "" ""it makes sense to have different configurations for your compute nodes and "" ""your storage nodes. Compute nodes will be invested in CPU and RAM, and "" ""storage nodes will be invested in block storage.""""多くの運用者はコンピュートホストとストレージホストを分離して使用しています。"" ""コンピュートサービスとストレージサービスには異なる要件があり、コンピュートホ"" ""ストでは通常はストレージホストよりも多くの CPU と RAM が必要です。そのため、"" ""一定の予算の中では、コンピュートホストとストレージホストの構成が異なることは"" ""理にかなっています。コンピュートホストでは、CPU や RAM を、ストレージノードで"" ""はブロックストレージを多く使用します。""""However, if you are more restricted in the number of physical hosts you have "" ""available for creating your cloud and you want to be able to dedicate as "" ""many of your hosts as possible to running instances, it makes sense to run "" ""compute and storage on the same machines.""""一方、クラウドの構築に使用できる物理ホスト数に制限があり、できるだけ多くのホ"" ""ストをインスタンスの実行に使えるようにしたい場合は、同じマシンでコンピュート"" ""ホストとストレージホストを動作させるのは理にかなっています。""""We'll discuss the three main approaches to instance storage in the next few "" ""sections."" msgstr ""以降の数セクションでは、 3 つの主要アプローチについて説明します。"" msgid ""Off Compute Node Storage—Shared File System"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）""""In this option, the disks storing the running instances are hosted in "" ""servers outside of the compute nodes.<indexterm class=\""singular"" ""\""><primary>shared storage</primary></indexterm><indexterm class=\""singular"" ""\""><primary>file systems</primary><secondary>shared</secondary></indexterm>""""このオプションでは、実行中のインスタンスを格納するディスクはコンピュートノー"" ""ド外のサーバーでホストされます。<indexterm class=\""singular\""><primary>共有ス"" ""トレージ</primary></indexterm><indexterm class=\""singular\""><primary>ファイル"" ""システム</primary><secondary>共有</secondary></indexterm>""""If you use separate compute and storage hosts, you can treat your compute "" ""hosts as \""stateless.\"" As long as you don't have any instances currently "" ""running on a compute host, you can take it offline or wipe it completely "" ""without having any effect on the rest of your cloud. This simplifies "" ""maintenance for the compute hosts.""""コンピュートホストとストレージホストを分離して使用すると、コンピュートホスト"" ""を「ステートレス」として処理できます。コンピュートホストで実行中のインスタン"" ""スがなければ、クラウドの他のアイテムに影響を与えることなく、ノードをオフライ"" ""ンにしたり、完全に消去したりすることができます。これにより、コンピュートホス"" ""トのメンテナンスが簡素化されます。"" msgid ""There are several advantages to this approach:"" msgstr ""このアプローチには複数の利点があります。"" msgid ""If a compute node fails, instances are usually easily recoverable."" msgstr """" ""コンピュートホストが故障した場合、通常インスタンスは簡単に復旧できます。"" msgid ""Running a dedicated storage system can be operationally simpler."" msgstr ""専用のストレージシステムを動作させることで、運用がシンプルになります。"" msgid ""You can scale to any number of spindles."" msgstr ""スピンドル数を何個にでもスケールすることができます。"" msgid ""It may be possible to share the external storage for other purposes."" msgstr ""外部ストレージを他の用途と共有できる可能性があります。"" msgid ""The main downsides to this approach are:"" msgstr ""この方法の主なマイナス面は以下の点です。""""Depending on design, heavy I/O usage from some instances can affect "" ""unrelated instances.""""設計次第では、一部のインスタンスの I/O が非常に多い場合に、無関係のインスタン"" ""スに影響が出る場合があります。"" msgid ""Use of the network can decrease performance."" msgstr ""ネットワークを使用するため、性能低下が起こる可能性があります。"" msgid ""On Compute Node Storage—Shared File System"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）""""In this option, each compute node is specified with a significant amount of "" ""disk space, but a distributed file system ties the disks from each compute "" ""node into a single mount.""""このオプションでは、各コンピュートノードに、多くのディスク容量が指定されてい"" ""ますが、分散ファイルシステムにより、それぞれのコンピュートノードからのディス"" ""クが 1 つのマウントとしてまとめられます。""""The main advantage of this option is that it scales to external storage when "" ""you require additional storage.""""このオプションの主な利点は、追加ストレージが必要な場合、外部ストレージにス"" ""ケールアウトできる点です。""msgid ""However, this option has several downsides:"" msgstr ""しかし、この方法にはいくつかマイナス点があります。""""Running a distributed file system can make you lose your data locality "" ""compared with nonshared storage.""""分散ファイルシステムを実行すると、非共有ストレージに比べデータの局所性が失わ"" ""れる可能性があります。""msgid ""Recovery of instances is complicated by depending on multiple hosts."" msgstr ""複数の物理ホストが関係するため、インスタンスの復旧が複雑になります。""""The chassis size of the compute node can limit the number of spindles able "" ""to be used in a compute node.""""コンピュートノードの筐体サイズによって、コンピュートノードに搭載できるディス"" ""ク数が制限されます。"" msgid ""On Compute Node Storage—Nonshared File System"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）""""In this option, each compute node is specified with enough disks to store "" ""the instances it hosts.<indexterm class=\""singular\""><primary>file systems</"" ""primary><secondary>nonshared</secondary></indexterm>""""このオプションでは、ホストするインスタンスを格納するのに十分なディスク容量が"" ""各コンピュートノードに指定されます。<indexterm class=\""singular\""><primary>"" ""ファイルシステム</primary><secondary>非共有</secondary></indexterm>"" msgid ""There are two main reasons why this is a good idea:"" msgstr ""このアイデアが良いとされる理由は主に 2 点挙げられます。""""Heavy I/O usage on one compute node does not affect instances on other "" ""compute nodes.""""あるコンピュートノード上での I/O が非常に多い場合でも、他のコンピュートノード"" ""のインスタンスに影響がありません。"" msgid ""Direct I/O access can increase performance."" msgstr ""I/O アクセスが直接行われるので、性能向上が図れます。"" msgid ""This has several downsides:"" msgstr ""この方法には次のようなマイナス点があります。"" msgid ""If a compute node fails, the instances running on that node are lost."" msgstr """" ""コンピュートノードが故障すると、そのノードで実行中のインスタンスが失われてし"" ""まいます。""""Migrations of instances from one node to another are more complicated and "" ""rely on features that may not continue to be developed.""""ノード間のインスタンスのマイグレーションがより複雑になり、今後開発が継続され"" ""ない可能性のある機能に依存することになります。"" msgid ""If additional storage is required, this option does not scale."" msgstr ""追加ストレージが必要な場合、このオプションはスケールしません。""""Running a shared file system on a storage system apart from the computes "" ""nodes is ideal for clouds where reliability and scalability are the most "" ""important factors. Running a shared file system on the compute nodes "" ""themselves may be best in a scenario where you have to deploy to preexisting "" ""servers for which you have little to no control over their specifications. "" ""Running a nonshared file system on the compute nodes themselves is a good "" ""option for clouds with high I/O requirements and low concern for reliability."" ""<indexterm class=\""singular\""><primary>scaling</primary><secondary>file "" ""system choice</secondary></indexterm>""""信頼性と拡張性が最も重要な要因とするクラウドでは、コンピュートノードと分離し"" ""てストレージシステムで共有ファイルシステムを実行することが理想的です。仕様の"" ""コントロールをほぼできない、または全くできない既存のサーバーにデプロイシなけ"" ""ればならない場合などは、コンピュートノード自体で共有ファイルシステムを実行す"" ""るとベストです。また、I/O 要件が高く、信頼性にあまり配慮しなくてもいいクラウ"" ""ドには、コンピュートノード上で非共有ファイルシステムを実行すると良いでしょ"" ""う。<indexterm class=\""singular\""><primary>スケーリング</primary><secondary>"" ""ファイルシステムの選択</secondary></indexterm>""msgid ""Issues with Live Migration"" msgstr ""ライブマイグレーションに関する問題""""We consider live migration an integral part of the operations of the cloud. "" ""This feature provides the ability to seamlessly move instances from one "" ""physical host to another, a necessity for performing upgrades that require "" ""reboots of the compute hosts, but only works well with shared storage."" ""<indexterm class=\""singular\""><primary>storage</primary><secondary>live "" ""migration</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>migration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>live migration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>compute nodes</primary><secondary>live migration</secondary></"" ""indexterm>""""ライブマイグレーションは、クラウドの運用に不可欠であると考えられます。この機"" ""能により、物理ホストから別の物理ホストに、インスタンスをシームレスに移動し、"" ""コンピュートホストの再起動を必要とするアップグレードができるようになります。"" ""しかし、ライブマイグレーションは共有ストレージのみで正常に機能します。"" ""<indexterm class=\""singular\""><primary>ストレージ</primary><secondary>ライブ"" ""マイグレーション</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>マイグレーション</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ライブマイグレーション</primary></indexterm><indexterm class="" ""\""singular\""><primary>コンピュートノード</primary><secondary>ライブマイグレー"" ""ション</secondary></indexterm>""""Live migration can also be done with nonshared storage, using a feature "" ""known as <emphasis>KVM live block migration</emphasis>. While an earlier "" ""implementation of block-based migration in KVM and QEMU was considered "" ""unreliable, there is a newer, more reliable implementation of block-based "" ""live migration as of QEMU 1.4 and libvirt 1.0.2 that is also compatible with "" ""OpenStack. However, none of the authors of this guide have first-hand "" ""experience using live block migration.<indexterm class=\""singular"" ""\""><primary>block migration</primary></indexterm>""""ライブマイグレーションは、<emphasis>KVM ライブブロックマイグレーション</"" ""emphasis> という機能を使用して、非共有ストレージでも行うことができます。KVM "" ""や QEMU でのブロックベースのマイグレーションは当初、信頼できませんでしたが、"" ""OpenStack との互換性もある QEMU 1.4 および libvirt 1.0.2 では、より新しく、信"" ""頼性の高いブロックベースのライブマイグレーション実装ができるようになっていま"" ""す。ただし、本書の執筆者は、ライブブロックマイグレーションを実際に使用してい"" ""ません。<indexterm class=\""singular\""><primary>ブロックマイグレーション</"" ""primary></indexterm>""msgid ""Choice of File System"" msgstr ""ファイルシステムの選択""""If you want to support shared-storage live migration, you need to configure "" ""a distributed file system.<indexterm class=\""singular\""><primary>compute "" ""nodes</primary><secondary>file system choice</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>file systems</"" ""primary><secondary>choice of</secondary></indexterm><indexterm class="" ""\""singular\""><primary>storage</primary><secondary>file system choice</"" ""secondary></indexterm>""""共有ストレージのライブマイグレーションをサポートする場合、分散ファイルシステ"" ""ムを設定する必要があります。<indexterm class=\""singular\""><primary>コンピュー"" ""トノード</primary><secondary>ファイルシステムの選択</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ファイルシステム</"" ""primary><secondary>選択</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>ストレージ</primary><secondary>ファイルシステムの選択</"" ""secondary></indexterm>"" msgid ""Possible options include:"" msgstr ""次のような選択肢があります。"" msgid ""NFS (default for Linux)"" msgstr ""NFS (Linux でのデフォルト)"" msgid ""MooseFS"" msgstr ""MooseFS"" msgid ""Lustre"" msgstr ""Lustre""""We've seen deployments with all, and recommend that you choose the one you "" ""are most familiar with operating. If you are not familiar with any of these, "" ""choose NFS, as it is the easiest to set up and there is extensive community "" ""knowledge about it.""""すべてのファイルシステムを使用したデプロイメントに触れ、運用になれているもの"" ""を選択するように推奨しました。いずれのファイルシステムにも馴染みがない場合"" ""は、設定が簡単で、コミュニティのナレッジベースが幅広く存在するため、NFS を選"" ""択するようにしてください。"" msgid ""Overcommitting"" msgstr ""オーバーコミット""""OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows "" ""you to increase the number of instances you can have running on your cloud, "" ""at the cost of reducing the performance of the instances.<indexterm class="" ""\""singular\""><primary>RAM overcommit</primary></indexterm><indexterm class="" ""\""singular\""><primary>CPUs (central processing units)</"" ""primary><secondary>overcommitting</secondary></indexterm><indexterm class="" ""\""singular\""><primary>overcommitting</primary></indexterm><indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>overcommitting</"" ""secondary></indexterm> OpenStack Compute uses the following ratios by "" ""default:""""OpenStack は、コンピュートノードで CPU および RAM をオーバーコミットすること"" ""ができます。これにより、インスタンスのパフォーマンスを落とすことでクラウドで"" ""実行可能なインスタンス数を増やすことができます。<indexterm class=\""singular"" ""\""><primary>RAM オーバーコミット</primary></indexterm><indexterm class="" ""\""singular\""><primary>CPU (central processing unit)</"" ""primary><secondary>overcommitting</secondary></indexterm><indexterm class="" ""\""singular\""><primary>オーバーコミット</primary></indexterm><indexterm class="" ""\""singular\""><primary>コンピュートノード</primary><secondary>オーバーコミット"" ""</secondary></indexterm> OpenStack Compute はデフォルトで以下の比率を使用しま"" ""す。""msgid ""RAM allocation ratio: 1.5:1"" msgstr ""RAM 割当比: 1.5:1"" msgid """" ""The default CPU allocation ratio of 16:1 means that the scheduler allocates "" ""up to 16 virtual cores per physical core. For example, if a physical node "" ""has 12 cores, the scheduler sees 192 available virtual cores. With typical "" ""flavor definitions of 4 virtual cores per instance, this ratio would provide "" ""48 instances on a physical node."" msgstr """" ""デフォルトの CPU 割当比は 16:1 で、これは、物理コア 1 つにつき仮想コアが最大 "" ""16 個までスケジューラーにより割り当てることができることを意味します。例えば、"" ""物理ノードにコアが 12 個ある場合、スケジューラーには、使用可能な仮想コアが "" ""192 個あることになります。インスタンス 1 個に仮想コア 4 個という通常のフレー"" ""バーの定義では、この比率をもとにすると、1 つの物理にインスタンスが 48 個割り"" ""当てらることになります。"" msgid """" ""The formula for the number of virtual instances on a compute node is "" ""<emphasis>(OR*PC)/VC</emphasis>, where:"" msgstr """" ""コンピュートノード上の仮想インスタンス数の公式は、 <emphasis>(OR*PC)/VC</"" ""emphasis> です。それぞれ以下を意味します。"" msgid ""OR"" msgstr ""OR"" msgid ""PC"" msgstr ""PC""msgid ""Number of physical cores"" msgstr ""物理コア数""msgid ""VC"" msgstr ""VC""msgid ""Number of virtual cores per instance"" msgstr ""インスタンスごとの仮想コア数""""Similarly, the default RAM allocation ratio of 1.5:1 means that the "" ""scheduler allocates instances to a physical node as long as the total amount "" ""of RAM associated with the instances is less than 1.5 times the amount of "" ""RAM available on the physical node.""""同様に、RAM 割当比のデフォルト1.5:1 は、インスタンスに関連づけられた RAM の総"" ""量が物理ノードで利用できるメモリ量の1.5倍未満であれば、スケジューラーがその物"" ""理ノードにインスタンスを割り当てることを意味します。""""For example, if a physical node has 48 GB of RAM, the scheduler allocates "" ""instances to that node until the sum of the RAM associated with the "" ""instances reaches 72 GB (such as nine instances, in the case where each "" ""instance has 8 GB of RAM).""""例えば、物理ノードに 48GB の RAM がある場合、そのノード上のインスタンスに割り"" ""当てられた RAM の合計が 72GB に達するまでは、スケジューラーはそのノードにイン"" ""スタンスを割り振ることになります (例えば、各インスタンスのメモリが 8GB であれ"" ""ば、9 インスタンス割り当てられます)。""""You must select the appropriate CPU and RAM allocation ratio for your "" ""particular use case.""""あなた自身のユースケースに合わせて、適切な CPU と RAM の割当比を選択しなけれ"" ""ばなりません。""msgid ""Logging"" msgstr ""ロギング""""Logging is detailed more fully in <xref linkend=\""logging_monitoring\""/>. "" ""However, it is an important design consideration to take into account before "" ""commencing operations of your cloud.<indexterm class=\""singular"" ""\""><primary>logging/monitoring</primary><secondary>compute nodes and</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>compute nodes</"" ""primary><secondary>logging</secondary></indexterm>""""ロギングの詳細は、<xref linkend=\""logging_monitoring\""/> で包括的に記載してい"" ""ます。ただし、クラウドの運用を開始する前に、重要な設計に関する事項について考"" ""慮していく必要があります。<indexterm class=\""singular\""><primary>logging/"" ""monitoring</primary><secondary>コンピュートノードおよび</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>ロギング</secondary></indexterm>""""OpenStack produces a great deal of useful logging information, however; but "" ""for the information to be useful for operations purposes, you should "" ""consider having a central logging server to send logs to, and a log parsing/"" ""analysis system (such as <phrase role=\""keep-together\"">logstash</phrase>).""""OpenStack は、便利なロギング情報を多く生成しますが、運用目的でその情報を有効"" ""活用するには、ログの送信先となる中央ロギングサーバーや、ログの解析/分析システ"" ""ム (<phrase role=\""keep-together\"">logstash</phrase> など) の導入を検討する必"" ""要があります。""msgid """" ""Networking in OpenStack is a complex, multifaceted challenge. See <xref "" ""linkend=\""network_design\""/>.<indexterm class=\""singular\""><primary>compute "" ""nodes</primary><secondary>networking</secondary></indexterm>"" msgstr """" ""OpenStack でのネットワークは複雑で、多くの課題があります。<xref linkend="" ""\""network_design\""/>を参照してください。<indexterm class=\""singular"" ""\""><primary>コンピュートノード</primary><secondary>ネットワーキング</"" ""secondary></indexterm>""msgid ""Lay of the Land"" msgstr ""環境の把握""""This chapter helps you set up your working environment and use it to take a "" ""look around your cloud.""""本章では、作業環境を設定し、クラウドの全体像を概観するのに役立つ内容を記載し"" ""ます。""msgid ""Using the OpenStack Dashboard for Administration"" msgstr ""管理目的での OpenStack Dashboard の使用"" msgid ""Command-Line Tools"" msgstr ""コマンドラインツール""""We recommend using a combination of the OpenStack command-line interface "" ""(CLI) tools and the OpenStack dashboard for administration. Some users with "" ""a background in other cloud technologies may be using the EC2 Compatibility "" ""API, which uses naming conventions somewhat different from the native API. "" ""We highlight those differences.<indexterm class=\""singular"" ""\""><primary>working environment</primary><secondary>command-line tools</"" ""secondary></indexterm>""""管理には、OpenStack コマンドラインインターフェース (CLI) ツールと OpenStack "" ""Dashboard を組み合わせて使用することをお勧めします。他のクラウドテクノロジー"" ""の使用経験のある一部のユーザーは、EC2 互換 API を使用している可能性がありま"" ""す。この API は、ネイティブの API とは若干異なる命名規則を採用しています。こ"" ""の相違点について以下に説明します。<indexterm class=\""singular\""><primary>作業"" ""環境</primary><secondary>コマンドラインツール</secondary></indexterm>""""We strongly suggest that you install the command-line clients from the <link "" ""href=\""https://pypi.python.org/pypi\"">Python Package Index</link> (PyPI) "" ""instead of from the distribution packages. The clients are under heavy "" ""development, and it is very likely at any given time that the version of the "" ""packages distributed by your operating-system vendor are out of date."" ""<indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>Python Package Index (PyPI)</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>pip utility</primary></"" ""indexterm><indexterm class=\""singular\""><primary>Python Package Index (PyPI)"" ""</primary></indexterm>""""コマンドラインクライアントは、ディストリビューションのパッケージからではな"" ""く、<link href=\""https://pypi.python.org/pypi\"">Python Package Index</link> "" ""(PyPI) からインストールすることを強く推奨します。これは、クライアントの開発"" ""が活発に行われており、オペレーティングシステムのベンダーにより配布されたパッ"" ""ケージのバージョンが任意の時点で無効になってしまう可能性が高いためです。"" ""<indexterm class=\""singular\""><primary>コマンドラインツール</"" ""primary><secondary>Python Package Index (PyPI)</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>pip ユーティリティ</"" ""primary></indexterm><indexterm class=\""singular\""><primary>Python Package "" ""Index (PyPI)</primary></indexterm>""""The pip utility is used to manage package installation from the PyPI archive "" ""and is available in the python-pip package in most Linux distributions. Each "" ""OpenStack project has its own client, so depending on which services your "" ""site runs, install some or all of the following<indexterm class=\""singular"" ""\""><primary>neutron</primary><secondary>python-neutronclient</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>swift</"" ""primary><secondary>python-swiftclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>cinder</primary></indexterm><indexterm class="" ""\""singular\""><primary>keystone</primary></indexterm><indexterm class="" ""\""singular\""><primary>glance</primary><secondary>python-glanceclient</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>nova</"" ""primary><secondary>python-novaclient</secondary></indexterm> packages:""""pip ユーティリティは、PyPI アーカイブからのパッケージインストールの管理に使"" ""用するツールで、大半の Linux ディストリビューションの python-pip パッケージに"" ""含まれています。各 OpenStack プロジェクトにはそれぞれ独自のクライアントがあり"" ""ます。サイトで実行するサービスに応じて、以下のパッケージの一部またはすべてを"" ""インストールしてください。<indexterm class=\""singular\""><primary>neutron</"" ""primary><secondary>python-neutronclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>swift</primary><secondary>python-swiftclient</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>cinder</"" ""primary></indexterm><indexterm class=\""singular\""><primary>keystone</"" ""primary></indexterm><indexterm class=\""singular\""><primary>glance</"" ""primary><secondary>python-glanceclient</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>nova</primary><secondary>python-novaclient</"" ""secondary></indexterm>"" msgid ""python-novaclient (<glossterm>nova</glossterm> CLI)"" msgstr ""python-novaclient (<glossterm>nova</glossterm> CLI)"" msgid ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" msgstr ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" msgid ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" msgstr ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" msgid ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" msgstr ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" msgid ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" msgstr ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" msgid ""python-neutronclient (<glossterm>neutron</glossterm> CLI)"" msgstr ""python-neutronclient (<glossterm>neutron</glossterm> CLI)"" msgid ""Installing the Tools"" msgstr ""ツールの導入""""To install (or upgrade) a package from the PyPI archive with pip, <indexterm "" ""class=\""singular\""><primary>command-line tools</"" ""primary><secondary>installing</secondary></indexterm>as root:""""pip を使用して PyPI アーカイブからパッケージをインストール (またはアップグ"" ""レード) するには、<indexterm class=\""singular\""><primary>コマンドラインツール"" ""</primary><secondary>インストール</secondary></indexterm>root として以下のコ"" ""マンドを実行します。"" msgid ""To remove the package:"" msgstr ""パッケージを削除するには、""""If you need even newer versions of the clients, pip can install directly "" ""from the upstream git repository using the <code>-e</code> flag. You must "" ""specify a name for the Python egg that is installed. For example:""""もし新しいバージョンのクライアントが必要な場合、<code>-e</code>フラグを指定す"" ""ることで、アップストリームのgitリポジトリから直接導入できます。その際は、"" ""Python egg名を指定しなければいけません。例えば、""""If you support the EC2 API on your cloud, you should also install the "" ""euca2ools package or some other EC2 API tool so that you can get the same "" ""view your users have. Using EC2 API-based tools is mostly out of the scope "" ""of this guide, though we discuss getting credentials for use with it.""""クラウド上で EC2 API をサポートする場合には、ユーザーと同じビューを表示できる"" ""ように、euca2ools パッケージまたはその他の EC2 API ツールもインストールする必"" ""要があります。EC2 API ベースのツールの使用に関する内容の大半は本ガイドの対象"" ""範囲外となりますが、このツールで使用する認証情報の取得方法についての説明は記"" ""載しています。"" msgid ""Administrative Command-Line Tools"" msgstr ""管理系コマンドラインツール""""There are also several <literal>*-manage</literal> command-line tools. These "" ""are installed with the project's services on the cloud controller and do not "" ""need to be installed<indexterm class=\""singular\""><primary>*-manage command-"" ""line tools</primary></indexterm><indexterm class=\""singular"" ""\""><primary>command-line tools</primary><secondary>administrative</"" ""secondary></indexterm> separately:""""<literal>*-manage</literal> のコマンドラインツールも複数あります。これらは、"" ""プロジェクトのサービスとともにクラウドコントローラーにインストールされるの"" ""で、別途インストールする必要はありません。 <indexterm class=\""singular"" ""\""><primary>*-manage コマンドラインツール</primary></indexterm><indexterm "" ""class=\""singular\""><primary>コマンドラインツール</primary><secondary>管理系</"" ""secondary></indexterm>""msgid ""nova-manage"" msgstr ""nova-manage"" msgid ""glance-manage"" msgstr ""glance-manage"" msgid ""keystone-manage"" msgstr ""keystone-manage"" msgid ""cinder-manage"" msgstr ""cinder-manage""""Unlike the CLI tools mentioned above, the <code>*-manage</code> tools must "" ""be run from the cloud controller, as root, because they need read access to "" ""the config files such as <code>/etc/nova/nova.conf</code> and to make "" ""queries directly against the database rather than against the OpenStack "" ""<glossterm baseform=\""API endpoint\"">API endpoints</glossterm>.<indexterm "" ""class=\""singular\""><primary>API (application programming interface)</"" ""primary><secondary>API endpoint</secondary></indexterm><indexterm class="" ""\""singular\""><primary>endpoints</primary><secondary>API endpoint</"" ""secondary></indexterm>""""前述の CLI ツールとは異なり、<code>*-manage</code> ツールは、<code>/etc/nova/"" ""nova.conf</code> などの設定ファイルへの読み取りアクセスが必要で、かつ "" ""OpenStack に対してではなくデータベースに対して直接クエリーを実行しなければな"" ""らないため、クラウドコントローラーから root として実行する必要があります。"" ""<glossterm baseform=\""API endpoint\"">API エンドポイント</glossterm>."" ""<indexterm class=\""singular\""><primary>API (Application Programming "" ""Interface)</primary><secondary>API エンドポイント</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>エンドポイント</"" ""primary><secondary>API エンドポイント</secondary></indexterm>""""The existence of the <code>*-manage</code> tools is a legacy issue. It is a "" ""goal of the OpenStack project to eventually migrate all of the remaining "" ""functionality in the <code>*-manage</code> tools into the API-based tools. "" ""Until that day, you need to SSH into the <glossterm>cloud controller node</"" ""glossterm> to perform some maintenance operations that require one of the "" ""<phrase role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> "" ""tools</phrase>.<indexterm class=\""singular\""><primary>cloud controller "" ""nodes</primary><secondary>command-line tools and</secondary></indexterm>""""<code>*-manage</code> ツールの存在は、レガシーの問題です。OpenStack プロジェ"" ""クトでは、最終的には <code>*-manage</code> ツールの残りの機能をすべて API "" ""ベースのツールに移行することを目標としています。移行が完了するまで、<phrase "" ""role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> ツール</"" ""phrase> を必要とするメンテナンス操作は、<glossterm>クラウドコントローラーノー"" ""ド</glossterm> に SSH 接続して実行する必要があります。<indexterm class="" ""\""singular\""><primary>クラウドコントローラーノード</primary><secondary>コマン"" ""ドラインツール</secondary></indexterm>""msgid ""Getting Credentials"" msgstr ""認証情報の取得方法""""You must have the appropriate credentials if you want to use the command-"" ""line tools to make queries against your OpenStack cloud. By far, the easiest "" ""way to obtain <glossterm>authentication</glossterm> credentials to use with "" ""command-line clients is to use the OpenStack dashboard. From the top-right "" ""navigation row, select <guimenuitem>Project</guimenuitem>, then "" ""<guimenuitem>Access &amp; Security</guimenuitem>, then <guimenuitem>API "" ""Access</guimenuitem> to access the user settings page where you can set your "" ""language and timezone preferences for the dashboard view. This action "" ""displays two buttons, <guilabel>Download OpenStack RC File</guilabel> and "" ""<guilabel>Download EC2 Credentials</guilabel>, which let you generate files "" ""that you can source in your shell to populate the environment variables the "" ""command-line tools require to know where your service endpoints and your "" ""authentication information are. The user you logged in to the dashboard "" ""dictates the filename for the openrc file, such as <filename>demo-openrc.sh</"" ""filename>. When logged in as admin, the file is named <filename>admin-openrc."" ""sh</filename>.<indexterm class=\""singular\""><primary>credentials</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authentication</primary></"" ""indexterm><indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>getting credentials</secondary></indexterm>""""コマンドラインツールを使用して OpenStack クラウドに対してクエリーを実行するに"" ""は、適切な認証情報が必要です。コマンドラインクライアントで使用する<glossterm>"" ""認証</glossterm>のクレデンシャルを取得する最も簡単な方法は、OpenStack ダッ"" ""シュボードを使用する方法です。画面右上のナビレーションバーから <guimenuitem>"" ""プロジェクト</guimenuitem> を選択し、<guimenuitem>アクセスとセキュリティ</"" ""guimenuitem> をクリックしてから, <guimenuitem>API アクセス</guimenuitem> のタ"" ""ブを開き、ユーザー設定のページにアクセスします。このページでは、ダッシュボー"" ""ドで表示される言語とタイムゾーンを設定することができます。この操作では、"" ""<guilabel>OpenStack RC ファイルのダウンロード</guilabel> と <guilabel>EC2 認"" ""証情報のダウンロード</guilabel> の 2 つのボタンが表示されます。これらのボタン"" ""により、コマンドラインツールがサービスエンドポイントと認証情報の場所を知るの"" ""に必要な環境変数を読み込むために、シェルで元データとして使用することのできる"" ""ファイルを生成することができます。ダッシュボードにログインしたユーザーによっ"" ""て、openrc ファイルのファイル名が決定します (例: <filename>demo-openrc.sh</"" ""filename>)。admin としてログインした場合には、ファイル名は <filename>admin-"" ""openrc.sh</filename> となります。<indexterm class=\""singular\""><primary>認証"" ""情報</primary></indexterm><indexterm class=\""singular\""><primary>認証</"" ""primary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツー"" ""ル</primary><secondary>認証情報の取得</secondary></indexterm>""msgid ""The generated file looks something like this:"" msgstr ""出力は以下のようになります。""""This does not save your password in plain text, which is a good thing. But "" ""when you source or run the script, it prompts you for your password and then "" ""stores your response in the environment variable <code>OS_PASSWORD</code>. "" ""It is important to note that this does require interactivity. It is possible "" ""to store a value directly in the script if you require a noninteractive "" ""operation, but you then need to be extremely cautious with the security and "" ""permissions of this file.<indexterm class=\""singular\""><primary>passwords</"" ""primary></indexterm><indexterm class=\""singular\""><primary>security issues</"" ""primary><secondary>passwords</secondary></indexterm>""""この場合には、パスワードがプレーンテキスト形式で保存されないのがこの方法の利"" ""点となりますが、このスクリプトを元データとして使用したり、実行したりする際に"" ""は、パスワードが要求され、その回答は環境変数 <code>OS_PASSWORD</code> に保存"" ""されます。この操作は対話的に実行される必要がある点は、注意すべき重要なポイン"" ""トです。 操作を非対話的に行う必要がある場合には、値をスクリプトに直接に保存す"" ""ることも可能ですが、その場合にはこのファイルのセキュリティとアクセス権を極め"" ""て慎重に管理する必要があります。, <indexterm class=\""singular\""><primary>パス"" ""ワード</primary></indexterm><indexterm class=\""singular\""><primary>セキュリ"" ""ティ上の問題</primary><secondary>パスワード</secondary></indexterm>""""To put the EC2 credentials into your environment, source the <code>ec2rc.sh</"" ""code> file.""""EC2 認証情報を環境に適用するには、<code>ec2rc.sh</code> ファイルを元データと"" ""します。""msgid ""Inspecting API Calls"" msgstr ""API コールの検査""""The command-line tools can be made to show the OpenStack API calls they make "" ""by passing the <code>--debug</code> flag to them.<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</primary><secondary>API "" ""calls, inspecting</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>command-line tools</primary><secondary>inspecting API calls</"" ""secondary></indexterm> For example:""""コマンドラインツールに <code>--debug</code> フラグを渡すことにより、実行す"" ""る OpenStack API コールを表示することができます。<indexterm class="" ""\""singular\""><primary>API (Application Programming Interface)</"" ""primary><secondary>API コール、検査</secondary></indexterm><indexterm class="" ""\""singular\""><primary>コマンドラインツール</primary><secondary>API コールの検"" ""査</secondary></indexterm> 例えば、以下のようになります。""""This example shows the HTTP requests from the client and the responses from "" ""the endpoints, which can be helpful in creating custom tools written to the "" ""OpenStack API."" msgstr """" ""この例は、クライアントからのHTTPリクエストとエンドポイントからのレスポンスを"" ""表示しています。これはOpenStack APIを使ったカスタムツールを作る際に役立ちま"" ""す。"" msgid """" ""<link href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">Keyring "" ""Support</link> enables you to securely save your OpenStack password in an "" ""encrypted file.<indexterm class=\""singular\""><primary>Keyring Support</""""<link href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">キーリングのサ"" ""ポート</link>により、暗号化されたファイルに OpenStack のパスワードをセキュア"" ""に保存することができます。<indexterm class=\""singular\""><primary>キーリングの"" ""サポート</primary></indexterm>"" msgid """" ""This feature is disabled by default. To enable it, add the <code>--os-cache</"" ""code> flag or set the environment variable <code>OS_CACHE=1</code>."" msgstr """" ""この機能は、デフォルトでは無効になっています。有効にするには、<code>--os-"" ""cache</code> フラグを追加するか、環境変数 <code>OS_CACHE=1</code> を設定して"" ""ください。"" msgid """" ""Configuring <literal>OS_CACHE</literal> causes the command-line tool to "" ""authenticate on each and every interaction with the cloud. This can assist "" ""with working around this scenario. However, it increases the time taken to "" ""run commands and also the load on the server."" msgstr """" ""<literal>OS_CACHE</literal> を設定すると、クラウドと対話する度にコマンドライ"" ""ンツールが認証を行うようになります。この方法は、このシナリオの次善策として役"" ""立ちますが、コマンドの実行時間が長くなり、サーバーに対する負荷も増大します。"" msgid ""Using cURL for further inspection"" msgstr ""cURL を使用したさらなる検査"" msgid """" ""Underlying the use of the command-line tools is the OpenStack API, which is "" ""a RESTful API that runs over HTTP. There may be cases where you want to "" ""interact with the API directly or need to use it because of a suspected bug "" ""in one of the CLI tools. The best way to do this is to use a combination "" ""of <link href=\""http://curl.haxx.se/\"">cURL</link> and another tool, such "" ""as <link href=\""http://stedolan.github.io/jq/\"">jq</link>, to parse the JSON "" ""from the responses.<indexterm class=\""singular\""><primary>authentication "" ""tokens</primary></indexterm><indexterm class=\""singular\""><primary>cURL</""""コマンドラインツールの使用の根底にあるのは、HTTP を介して実行する RESTful "" ""API である OpenStack API です。API と直接対話を行いたい場合や、CLI ツールにバ"" ""グがあることが疑われるために使用する必要がある場合があります。この場合の最善"" ""の対処方法は、 <link href=\""http://curl.haxx.se/\"">cURL</link> と <link href="" ""\""http://stedolan.github.io/jq/\"">jq</link> などの他のツールを組み合わせて使"" ""用し、その応答から JSON を解析することです。<indexterm class=\""singular"" ""\""><primary>認証トークン</primary></indexterm><indexterm class=\""singular"" ""\""><primary>cURL</primary></indexterm>""""The first thing you must do is authenticate with the cloud using your "" ""credentials to get an <glossterm>authentication token</glossterm>.""""まずはじめに、クラウドの認証が必要です。あなたの認証情報を用いて<glossterm>認"" ""証トークン</glossterm>を入手してください。""""Your credentials are a combination of username, password, and tenant "" ""(project). You can extract these values from the <code>openrc.sh</code> "" ""discussed above. The token allows you to interact with your other service "" ""endpoints without needing to reauthenticate for every request. Tokens are "" ""typically good for 24 hours, and when the token expires, you are alerted "" ""with a 401 (Unauthorized) response and you can request another <phrase role="" ""\""keep-together\"">token</phrase>.<indexterm class=\""singular"" ""\""><primary>catalog</primary></indexterm>""""認証情報はユーザー名、パスワード、テナント (プロジェクト) の組み合わせです。"" ""これらの値は、前述の <code>openrc.sh</code> から抽出することができます。トー"" ""クンにより、要求ごとに再認証する必要なく他のエンドポイントとの対話を行うこと"" ""ができます。トークンは通常 24 時間有効です。期限が切れると、401 "" ""(Unauthorized) の応答で警告され、<phrase role=\""keep-together\"">トークン</"" ""phrase> をもう 1 つ要求することができます。<indexterm class=\""singular"" ""\""><primary>カタログ</primary></indexterm>""msgid ""Look at your OpenStack service <glossterm>catalog</glossterm>:"" msgstr """" ""それではOpenStack サービス<glossterm>カタログ</glossterm>を見てみましょう。""""Read through the JSON response to get a feel for how the catalog is laid out."" msgstr ""JSONレスポンスを読むことで、カタログを把握することができます。"" msgid """" ""To make working with subsequent requests easier, store the token in an "" ""environment variable:"" msgstr ""次の要求での作業をより簡単に行うには、環境変数にトークンを保管します。"" msgid """" ""Now you can refer to your token on the command line as <literal>$TOKEN</"" ""literal>.""""これで、コマンドラインでトークンを <literal>$TOKEN</literal> として参照できる"" ""ようになりました。""""Pick a service endpoint from your service catalog, such as compute. Try a "" ""request, for example, listing instances (servers):""""サービスカタログから、サービスエンドポイント (例: コンピュート) を選択しま"" ""す。要求を試します。例えば、インスタンス (サーバー) の一覧表示を行います。""""To discover how API requests should be structured, read the <link href="" ""\""http://developer.openstack.org/api-ref.html\"">OpenStack API Reference</"" ""link>. To chew through the responses using jq, see the <link href=\""http://"" ""stedolan.github.io/jq/manual/\"">jq Manual</link>.""""API 要求の構成方法については、<link href=\""http://developer.openstack.org/"" ""api-ref.html\"">OpenStack API Reference</link> を参照してください。jq を使用し"" ""た応答についての詳しい説明は <link href=\""http://stedolan.github.io/jq/"" ""manual/\"">jq Manual</link> を参照してください。""""The <code>-s flag</code> used in the cURL commands above are used to prevent "" ""the progress meter from being shown. If you are having trouble running cURL "" ""commands, you'll want to remove it. Likewise, to help you troubleshoot cURL "" ""commands, you can include the <code>-v</code> flag to show you the verbose "" ""output. There are many more extremely useful features in cURL; refer to the "" ""man page for all the options.""""上記の cURL コマンドで使用している <code>-s flag</code> は、進行状況メーター"" ""が表示されないようにするために使用します。cURL コマンドの実行で問題が生じた場"" ""合には、このオプションを削除してください。また、cURL コマンドのトラブルシュー"" ""ティングを行う場合には、<code>-v</code> フラグを指定してより詳細な出力を表示"" ""すると役立ちます。cURL には他にも多数の役立つ機能があります。全オプションは、"" ""man ページで参照してください。""msgid ""Servers and Services"" msgstr ""サーバーとサービス""msgid """" ""As an administrator, you have a few ways to discover what your OpenStack "" ""cloud looks like simply by using the OpenStack tools available. This section "" ""gives you an idea of how to get an overview of your cloud, its shape, size, "" ""and current state.<indexterm class=\""singular\""><primary>services</"" ""primary><secondary>obtaining overview of</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>servers</primary><secondary>obtaining overview "" ""of</secondary></indexterm><indexterm class=\""singular\""><primary>cloud "" ""computing</primary><secondary>cloud overview</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>command-line tools</"" ""primary><secondary>servers and services</secondary></indexterm>"" msgstr """" ""管理者は、利用可能な OpenStack ツールを使用して、OpenStack クラウドが全体像を"" ""確認する方法がいくつかあります。本項では、クラウドの概要、形態、サイズ、現在"" ""の状態についての情報を取得する方法について説明します。<indexterm class="" ""\""singular\""><primary>サービス</primary><secondary>概観の取得</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>サーバー</primary><secondary"" ""概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>クラ"" ""ウドコンピューティング</primary><secondary>クラウドの全体像</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</"" ""primary><secondary>サーバーとサービス</secondary></indexterm>""msgid ""The output looks like the following:"" msgstr ""出力は以下のようになります。"" msgid """" ""The output shows that there are five compute nodes and one cloud controller. "" ""You see a smiley face, such as <code>:-)</code>, which indicates that the "" ""services are up and running. If a service is no longer available, the "" ""<code>:-)</code> symbol changes to <code>XXX</code>. This is an indication "" ""that you should troubleshoot why the service is down."" msgstr """" ""出力には、5 つのコンピュートノードと 1 つのクラウドコントローラーが表示されて"" ""います。スマイリーフェイス <code>:-)</code> が見えます。これはサービスが稼働"" ""中であることを示しています。サービスが利用できなくなると、<code>:-)</code> の"" ""シンボルが <code>XXX</code> に変わります。これは、サービスが停止している理由"" ""をトラブルシューティングする必要があることを示しています。"" msgid """" ""If you are using cinder, run the following command to see a similar listing:"" msgstr """" ""cinder を使用している場合は、次のコマンドを実行して同様の一覧を表示します。"" msgid """" ""With these two tables, you now have a good overview of what servers and "" ""services make up your cloud."" msgstr """" ""これら2つの表で、どのサーバーとサービスがあなたのクラウドを構成しているのか、"" ""概要を知ることができました。"" msgid """" ""You can also use the Identity Service (keystone) to see what services are "" ""available in your cloud as well as what endpoints have been configured for "" ""the services.<indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>displaying services and endpoints with</secondary></"" ""indexterm>"" msgstr """" ""また、Identity Service (keystone) を使用してクラウドで利用可能なサービスと、"" ""サービス用に設定済みのエンドポイントを確認することもできます。<indexterm "" ""class=\""singular\""><primary>Identity Service</primary><secondary>サービスおよ"" ""びエンドポイントの表示</secondary></indexterm>"" msgid """" ""The following command requires you to have your shell environment configured "" ""with the proper administrative variables:"" msgstr """" ""以下のコマンドを実行するには、管理系の変数を正しく設定したシェル環境が必要で"" ""す。"" msgid """" ""The preceding output has been truncated to show only two services. You will "" ""see one service block for each service that your cloud provides. Note how "" ""the endpoint domain can be different depending on the endpoint type. "" ""Different endpoint domains per type are not required, but this can be done "" ""for different reasons, such as endpoint privacy or network traffic "" ""segregation."" msgstr """" ""上記の出力は、2 つのサービスのみを表示するようにカットされています。クラウド"" ""が提供するサービスごとにサービスブロックが 1 つ表示されているのがわかります。"" ""エンドポイントタイプによってエンドポイントドメインが異なる場合がある点に注意"" ""してください。タイプによってエンドポイントドメインを別にする必要はありません"" ""が、エンドポイントのプライバシーやネットワークトラフィックの分離などの異なる"" ""理由で分けることができます。"" msgid """" ""You can find the version of the Compute installation by using the "" ""<literal>nova-manage</literal><phrase role=\""keep-together\"">command</"" ""phrase>: <placeholder-1/>"" msgstr """" ""インストールされている Compute のバージョンを確認するには、<literal>nova-"" ""manage</literal><phrase role=\""keep-together\"">command</phrase> を使用するこ"" ""とができます: <placeholder-1/>"" msgid ""Diagnose Your Compute Nodes"" msgstr ""コンピュートノードの診断"" msgid """" ""You can obtain extra information about virtual machines that are running—"" ""their CPU usage, the memory, the disk I/O or network I/O—per instance, by "" ""running the <literal>nova diagnostics</literal> command with<indexterm class="" ""\""singular\""><primary>compute nodes</primary><secondary>diagnosing</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>command-line "" ""tools</primary><secondary>compute node diagnostics</secondary></indexterm> a "" ""server ID:"" msgstr """" ""実行中の仮想マシンの CPU 使用状況、メモリー、ディスク I/O、ネットワーク I/O "" ""などの追加情報を取得するには、<literal>nova diagnostics</literal> コマンドに"" ""<indexterm class=\""singular\""><primary>コンピュートノード</"" ""primary><secondary>診断</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>コマンドラインツール</primary><secondary>コンピュートノードの診断"" ""</secondary></indexterm>サーバー ID を指定して実行します:"" msgid ""Network Inspection"" msgstr ""ネットワークの検査"" msgid """" ""To see which fixed IP networks are configured in your cloud, you can use the "" ""<literal>nova</literal> command-line client to get the IP ranges:<indexterm "" ""class=\""singular\""><primary>networks</primary><secondary>inspection of</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>working "" ""environment</primary><secondary>network inspection</secondary></"" ""indexterm><placeholder-1/>"" msgstr """" ""クラウドでどの Fixed IP ネットワークが設定されているかを確認するには、 "" ""<literal>nova</literal> コマンドラインクライアントを使用して IP アドレスの範"" ""囲を取得することができます:<indexterm class=\""singular\""><primary>ネットワー"" ""ク</primary><secondary>検査</secondary></indexterm><indexterm class="" ""\""singular\""><primary>作業環境</primary><secondary>ネットワークの検査</"" ""secondary></indexterm><placeholder-1/>"" msgid """" ""The <literal>nova-manage</literal> tool can provide some additional details:"" msgstr """" ""<literal>nova-manage</literal> ツールは、追加の情報を提供することが可能です:"" msgid """" ""This output shows that two networks are configured, each network containing "" ""255 IPs (a /24 subnet). The first network has been assigned to a certain "" ""project, while the second network is still open for assignment. You can "" ""assign this network manually; otherwise, it is automatically assigned when a "" ""project launches its first instance."" msgstr """" ""この出力は、2 つのネットワークが設定されており、各ネットワークには 255 の IP "" ""アドレス (/24 サブネットが 1 つ) が含まれていることを示しています。1 番目の"" ""ネットワークは、特定のプロジェクトに割り当て済みですが、2 番目のネットワーク"" ""はまだ割り当てができる状態です。このネットワークは手動で割り当てることができ"" ""ます。手動での割り当てを行わなかった場合には、プロジェクトで最初のインスタン"" ""スが起動されたときに自動で割り当てられます。"" msgid ""To find out whether any floating IPs are available in your cloud, run:"" msgstr """" ""クラウドに利用可能な Floating IP アドレスがあるかどうかを確認するには、以下の"" ""コマンドを実行します。"" msgid """" ""Here, two floating IPs are available. The first has been allocated to a "" ""project, while the other is unallocated."" msgstr """" ""この場合は、2 つの Floating IP アドレスが利用可能です。最初の IP アドレスはプ"" ""ロジェクトに確保されていますが、もう一方は確保されていません。"" msgid ""Users and Projects"" msgstr ""ユーザーとプロジェクト"" msgid """" ""To see a list of projects that have been added to the cloud,<indexterm class="" ""\""singular\""><primary>projects</primary><secondary>obtaining list of "" ""current</secondary></indexterm><indexterm class=\""singular\""><primary>user "" ""management</primary><secondary>listing users</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>working environment</"" ""primary><secondary>users and projects</secondary></indexterm> run:"" msgstr """" ""クラウドに追加されたプロジェクトの一覧を確認するには、<indexterm class="" ""\""singular\""><primary>プロジェクト</primary><secondary>現在の一覧の取得</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>ユーザー管理</"" ""primary><secondary>ユーザーの一覧表示</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>作業環境</primary><secondary>users and projects</"" ""secondary></indexterm>以下のコマンドを実行します:"" msgid ""To see a list of users, run:"" msgstr ""ユーザーのリストを見るためには、"" msgid """" ""Sometimes a user and a group have a one-to-one mapping. This happens for "" ""standard system accounts, such as cinder, glance, nova, and swift, or when "" ""only one user is part of a group."" msgstr """" ""ユーザーとグループは、一対一でマッピングされる場合があります。このようなマッ"" ""ピングは cinder、glance、nova、swift などの標準システムアカウントや、グループ"" ""にユーザーが 1 人しかいない場合に発生します。"" msgid ""Running Instances"" msgstr ""稼働中のインスタンス"" msgid """" ""To see a list of running instances,<indexterm class=\""singular"" ""\""><primary>instances</primary><secondary>list of running</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>working environment</"" ""primary><secondary>running instances</secondary></indexterm> run:"" msgstr """" ""実行中のインスタンスを確認するには、<indexterm class=\""singular"" ""\""><primary>instances</primary><secondary>実行中の一覧</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>作業環境</"" ""primary><secondary>実行中のインスタンス</secondary></indexterm>以下のコマンド"" ""を実行します:"" msgid """" ""Unfortunately, this command does not tell you various details about the "" ""running <phrase role=\""keep-together\"">instances</phrase>, such as what "" ""compute node the instance is running on, what flavor the instance is, and so "" ""on. You can use the following command to view details about individual "" ""instances:<indexterm class=\""singular\""><primary>config drive</primary></"" ""indexterm>"" msgstr """" ""残念ながら、このコマンドは、インスタンスを実行しているコンピュートノードやイ"" ""ンスタンスのフレーバーなどのような、実行中の<phrase role=\""keep-together\"">イ"" ""ンスタンス</phrase>についての多様な情報は提供しません。個別のインスタンスにつ"" ""いての詳しい情報を確認するには以下のコマンドを使用してください:<indexterm "" ""class=\""singular\""><primary>コンフィグドライブ</primary></indexterm>"" msgid ""For example: <placeholder-1/><placeholder-2/>"" msgstr ""例えば、<placeholder-1/><placeholder-2/>"" msgid """" ""This output shows that an instance named <placeholder-1/> was created from "" ""an Ubuntu 12.04 image using a flavor of <literal>m1.small</literal> and is "" ""hosted on the compute node <literal>c02.example.com</literal>."" msgstr """" ""この出力は、<placeholder-1/> という名前のインスタンスが Ubuntu 12.04 イメージ"" ""から <literal>m1.small</literal> のフレーバーで作成され、コンピュートノード "" ""<literal>c02.example.com</literal> でホストされていることを示しています。"" msgid """" ""We hope you have enjoyed this quick tour of your working environment, "" ""including how to interact with your cloud and extract useful information. "" ""From here, you can use the <emphasis><link href=\""http://docs.openstack.org/"" ""user-guide-admin/content/\"">Admin User Guide</link></emphasis> as your "" ""reference for all of the command-line functionality in your cloud."" msgstr """" ""クラウドとの対話や有用な情報の抽出の方法など、作業環境の概観を確認する手順を"" ""簡単にご紹介しました。役立てていただければ幸いです。ここで説明した内容よりも"" ""さらに詳しい情報は、クラウドの全コマンドライン機能についての参考資料として"" ""<emphasis><link href=\""http://docs.openstack.org/user-guide-admin/content/\"">"" ""管理ユーザーガイド</link></emphasis>を参照してください。"" msgid ""Advanced Configuration"" msgstr ""高度な設定"" msgid ""bandwidth_poll_interval"" msgstr ""bandwidth_poll_interval"" msgid ""sync_power_state_interval"" msgstr ""sync_power_state_interval"" msgid ""heal_instance_info_cache_interval"" msgstr ""heal_instance_info_cache_interval"" msgid ""host_state_interval"" msgstr ""host_state_interval"" msgid ""image_cache_manager_interval"" msgstr ""image_cache_manager_interval"" msgid ""reclaim_instance_interval"" msgstr ""reclaim_instance_interval"" msgid ""volume_usage_poll_interval"" msgstr ""volume_usage_poll_interval"" msgid ""shelved_poll_interval"" msgstr ""shelved_poll_interval"" msgid ""shelved_offload_time"" msgstr ""shelved_offload_time"" msgid ""instance_delete_interval"" msgstr ""instance_delete_interval"" msgid """" ""This section covers specific examples of configuration options you might "" ""consider tuning. It is by no means an exhaustive list."" msgstr """" ""この節では、調整を検討した方がよい設定オプションの個別の具体例を扱います。決"" ""して完全なリストではありません。"" msgid ""High Availability"" msgstr ""高可用性"" msgid ""Network Design"" msgstr ""ネットワーク設計"" msgid """" ""OpenStack provides a rich networking environment, and this chapter details "" ""the requirements and options to deliberate when designing your cloud."" ""<indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>first steps</secondary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>network "" ""design</secondary></indexterm>"" msgstr """" ""OpenStackは様々なネットワーク環境を提供します。この章ではクラウドを設計する際"" ""に必要な事項と慎重に決定すべきオプションの詳細を説明します。<indexterm class="" ""\""singular\""><primary>ネットワーク設計</primary><secondary>第1段階</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項"" ""</primary><secondary>ネットワーク設計</secondary></indexterm>"" msgid """" ""If this is the first time you are deploying a cloud infrastructure in your "" ""organization, after reading this section, your first conversations should be "" ""with your networking team. Network usage in a running cloud is vastly "" ""different from traditional network deployments and has the potential to be "" ""disruptive at both a connectivity and a policy level.<indexterm class="" ""\""singular\""><primary>cloud computing</primary><secondary>vs. traditional "" ""deployments</secondary></indexterm>"" msgstr """" ""これがあなたの組織で初めてのクラウド基盤構築であれば、この章を読んだ後、最初"" ""にあなたの（組織の）ネットワーク管理チームと相談すべきです。クラウド運用にお"" ""けるネットワークの使用は伝統的なネットワーク構築とはかなり異なり、接続性とポ"" ""リシーレベルの両面で破壊的な結果をもたらす可能性があります。<indexterm class="" ""\""singular\""><primary>クラウドコンピューティング</primary><secondary>VS. 伝統"" ""的実装</secondary></indexterm>"" msgid """" ""For example, you must plan the number of IP addresses that you need for both "" ""your guest instances as well as management infrastructure. Additionally, you "" ""must research and discuss cloud network connectivity through proxy servers "" ""and firewalls."" msgstr """" ""例えば、管理インフラだけでなくゲストインスタンス用のIPアドレスの数も計画しな"" ""ければなりません。加えて、プロキシサーバーやファイアウォールを経由してのクラ"" ""ウドネットワークの接続性を調査・議論する必要があります。"" msgid """" ""In this chapter, we'll give some examples of network implementations to "" ""consider and provide information about some of the network layouts that "" ""OpenStack uses. Finally, we have some brief notes on the networking services "" ""that are essential for stable operation."" msgstr """" ""この章では、いくつかのネットワーク構成の例を挙げながら、OpenStackを使用した"" ""ネットワークレイアウトについての情報を提供します。最後に、安定稼働のたの重要"" ""な音とトワークサービスに関する注意事項を記載します。"" msgid ""Management Network"" msgstr ""管理ネットワーク"" msgid """" ""A <glossterm>management network</glossterm> (a separate network for use by "" ""your cloud operators) typically consists of a separate switch and separate "" ""NICs (network interface cards), and is a recommended option. This "" ""segregation prevents system administration and the monitoring of system "" ""access from being disrupted by traffic generated by guests.<indexterm class="" ""\""singular\""><primary>NICs (network interface cards)</primary></"" ""indexterm><indexterm class=\""singular\""><primary>management network</"" ""primary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>management network</secondary></indexterm>"" msgstr """" "" <glossterm>管理用ネットワーク</glossterm> (クラウド管理者用の別のネットワー"" ""ク) は一般的には別のスイッチ別のNIC(Network Interface Cards)で構成する事が推"" ""奨されます。この構成ではゲストのトラフィックによって監視と管理のためのアクセ"" ""スが妨げられることを防ぎます。<indexterm class=\""singular\""><primary>NIC "" ""(network interface cards)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>管理ネットワーク</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ネットワークデザイン</primary><secondary>管理ネットワーク</"" ""secondary></indexterm>"" msgid """" ""Consider creating other private networks for communication between internal "" ""components of OpenStack, such as the message queue and OpenStack Compute. "" ""Using a virtual local area network (VLAN) works well for these scenarios "" ""because it provides a method for creating multiple virtual networks on a "" ""physical network."" msgstr """" ""メッセージキューや OpenStack コンピュート といった OpenStack 内部のコンポーネ"" ""ント間の通信用に別のプライベートネットワークの作成を検討して下さい。Virtual "" ""Local Area Network(VLAN) は1つの物理ネットワークに複数の仮想ネットワークを作"" ""成できるのでこのシナリオに非常に適しています。"" msgid ""Public Addressing Options"" msgstr ""パブリックアドレスの選択肢"" msgid """" ""There are two main types of IP addresses for guest virtual machines: fixed "" ""IPs and floating IPs. Fixed IPs are assigned to instances on boot, whereas "" ""floating IP addresses can change their association between instances by "" ""action of the user. Both types of IP addresses can be either public or "" ""private, depending on your use case.<indexterm class=\""singular"" ""\""><primary>IP addresses</primary><secondary>public addressing options</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>public addressing options</secondary></indexterm>"" msgstr """" ""ゲストの仮想マシン用に主に2つのタイプのIPアドレス（固定IPアドレスとフローティ"" ""ングIPアドレス）があります。固定IPアドレスはインスタンス起動時に割り当てら"" ""れ、フローティングIPアドレスは、ユーザ操作によって割当が変更できます。どちら"" ""のタイプのIPアドレスも用途に合わせてパブリックまたはプライベートにする事がで"" ""きます。<indexterm class=\""singular\""><primary>IPアドレス</"" ""primary><secondary>パブリックアドレスオプション</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワーク設計</"" ""primary><secondary>パブリックアドレスオプション</secondary></indexterm>"" msgid ""IP Address Planning"" msgstr ""IP アドレス計画""msgid """" ""An OpenStack installation can potentially have many subnets (ranges of IP "" ""addresses) and different types of services in each. An IP address plan can "" ""assist with a shared understanding of network partition purposes and "" ""scalability. Control services can have public and private IP addresses, and "" ""as noted above, there are a couple of options for an instance's public "" ""addresses.<indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>address planning</secondary></indexterm><indexterm class="" ""\""singular\""><primary>network design</primary><secondary>IP address "" ""planning</secondary></indexterm>"" msgstr """" ""OpenStackのインストールでは潜在的に多くのサブネット(IPアドレスの範囲) とそれ"" ""ぞれに異なるタイプのサービスを持つ可能性があります。あるIPアドレスプランは、"" ""ネットワーク分割の目的とスケーラビリティの共有された理解を手助けします。コン"" ""トロールサービスはパブリックとプライベートIPアドレスを持つ事ができ、上記の通"" ""り、インスタンスのパブリックアドレスとして2種類のオプションが存在します。"" ""<indexterm class=\""singular\""><primary>IPアドレス</primary><secondary>アドレ"" ""ス計画</secondary></indexterm><indexterm class=\""singular\""><primary>ネット"" ""ワーク設計</primary><secondary>IPアドレス計画</secondary></indexterm>""msgid """" ""An IP address plan might be broken down into the following sections:"" ""<indexterm class=\""singular\""><primary>IP addresses</"" ""primary><secondary>sections of</secondary></indexterm>"" msgstr """" ""IPアドレス計画としては次のような用途で分類されるでしょう：<indexterm class="" ""\""singular\""><primary>IPアドレス</primary><secondary>分類</secondary></"" ""indexterm>""msgid ""Subnet router"" msgstr ""サブネットルーター""msgid """" ""Packets leaving the subnet go via this address, which could be a dedicated "" ""router or a <literal>nova-network</literal> service."" msgstr """" ""パケットが出て行く際に通るIPアドレスで、これは専用のルータか<literal>nova-"" ""network</literal> サービスです。""msgid ""Control services public interfaces"" msgstr ""コントロールサービス用パブリックインターフェース""msgid """" ""Public access to <code>swift-proxy</code>, <code>nova-api</code>, "" ""<code>glance-api</code>, and horizon come to these addresses, which could be "" ""on one side of a load balancer or pointing at individual machines."" msgstr """" ""<code>swift-proxy</code>, <code>nova-api</code>, <code>glance-api</code>, "" ""horizon へのパブリックアクセスはこれらのアドレス宛にアクセスしてきます。これ"" ""らのアドレスはロードバランサの片側か、個々の機器を指しています。""msgid ""Object Storage cluster internal communications"" msgstr ""Object Storage クラスタ内の通信"" msgid """" ""Traffic among object/account/container servers and between these and the "" ""proxy server's internal interface uses this private network.<indexterm class="" ""\""singular\""><primary>containers</primary><secondary>container servers</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>objects</"" ""primary><secondary>object servers</secondary></indexterm><indexterm class="" ""\""singular\""><primary>account server</primary></indexterm>"" msgstr """" ""オブジェクト/アカウント/コンテナサービスの間とこれらとプロクシサーバーのイン"" ""ターフェイス間のトラフィックはこのプライベートネットワークを利用します。"" ""<indexterm class=\""singular\""><primary>コンテナ</primary><secondary>コンテナ"" ""サーバー</secondary></indexterm><indexterm class=\""singular\""><primary>オブ"" ""ジェクト</primary><secondary>オブジェクトサーバー</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>アカウントサーバー</"" ""primary></indexterm>"" msgid ""Compute and storage communications"" msgstr ""コンピュートとストレージの通信"" msgid """" ""If ephemeral or block storage is external to the compute node, this network "" ""is used."" msgstr """" ""一時ディスクまたはブロックストレージがコンピュートノード以外にある場合、この"" ""ネットワークが使用されます。"" msgid ""Out-of-band remote management"" msgstr ""帯域外管理リモート管理"" msgid """" ""If a dedicated remote access controller chip is included in servers, often "" ""these are on a separate network."" msgstr """" ""専用のリモートアクセスコントローラーチップがサーバーに搭載されている場合、多"" ""くの場合、これらは独立したネットワーク上に置かれます。"" msgid ""In-band remote management"" msgstr ""帯域内リモート管理"" msgid """" ""Often, an extra (such as 1 GB) interface on compute or storage nodes is used "" ""for system administrators or monitoring tools to access the host instead of "" ""going through the public interface."" msgstr """" ""システム管理者や監視ツールがパブリックインターフェース経由の代わりにコン"" ""ピュートノードやストレージノードのアクセスに使用するための追加インターフェー"" ""ス(1GBなど)"" msgid ""Spare space for future growth"" msgstr ""将来のための余剰"" msgid """" ""Adding more public-facing control services or guest instance IPs should "" ""always be part of your plan."" msgstr """" ""パブリック側に置かれるコントローラーサービスやゲストインスタンスのIPの追加"" ""は、必ずアドレス計画の一部として入れておくべきです。"" msgid """" ""For example, take a deployment that has both OpenStack Compute and Object "" ""Storage, with private ranges 172.22.42.0/24 and 172.22.87.0/26 available. "" ""One way to segregate the space might be as follows:"" msgstr """" ""例えば、OpenStack コンピュート と オブジェクトストレージ の両方を使用し、プラ"" ""イベートアドレス範囲として 172.22.42.0/24 と 172.22.87.0/26 が利用できる場面"" ""を考えます。一例として、アドレス空間を以下のように分割することができます。"" msgid """" ""A similar approach can be taken with public IP addresses, taking note that "" ""large, flat ranges are preferred for use with guest instance IPs. Take into "" ""account that for some OpenStack networking options, a public IP address in "" ""the range of a guest instance public IP address is assigned to the "" ""<literal>nova-compute</literal> host."" msgstr """" ""パブリックIPアドレスの場合でも同様のアプローチが取れます。但し、ゲストインス"" ""タンス用のIPとして使用する場合には、大きなフラットなアドレスレンジの方が好ま"" ""れることに注意した方がよいでしょう。また、OpenStack のネットワーク方式によっ"" ""ては、ゲストインスタンス用のパブリックIPアドレスレンジのうち一つが "" ""<literal>nova-compute </literal>ホストに割り当てられることも考慮する必要があ"" ""ります。"" msgid ""Network Topology"" msgstr ""ネットワークトポロジー"" msgid """" ""OpenStack Compute with <literal>nova-network</literal> provides predefined "" ""network deployment models, each with its own strengths and weaknesses. The "" ""selection of a network manager changes your network topology, so the choice "" ""should be made carefully. You also have a choice between the tried-and-true "" ""legacy <literal>nova-network</literal> settings or the <phrase role=\""keep-"" ""together\"">neutron</phrase> project for OpenStack Networking. Both offer "" ""networking for launched instances with different implementations and "" ""requirements.<indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>deployment options</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>networks</primary><secondary>network managers</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>network topology</secondary><tertiary>deployment options</"" ""tertiary></indexterm>"" msgstr """" "" <literal>nova-network</literal>を使用したOpenStackコンピュートはいくつかのあ"" ""らかじめ定義されたネットワークの実装モデルを提供しますが、それぞれ強みと弱み"" ""があります。ネットワークマネージャの選択はあなたのネットワークトポロジーを変"" ""更するので、慎重に選択するべきです。また、実証済みでレガシーな<literal>nova-"" ""network</literal>による設定か、OpenStackネットワーキングのための<phrase role="" ""\""keep-together\"">neutron</phrase>プロジェクトを採用するか決定する必要があり"" ""ます。インスタンスのネットワークの実装方法それぞれに異なる実装と要件がありま"" ""す。<indexterm class=\""singular\""><primary>ネットワーク</primary><secondary>"" ""開発オプション</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ネットワーク</primary><secondary>絵ネットワークマネージャ</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワークデザイン</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>deployment "" ""options</tertiary></indexterm>""msgid ""Networking deployment options"" msgstr ""ネットワーク構成オプション"" msgid ""Network deployment model"" msgstr ""ネットワーク構成モデル"" msgid ""Strengths"" msgstr ""長所"" msgid ""Weaknesses"" msgstr ""短所"" msgid ""Neutron equivalent"" msgstr ""Neutronでの実装"" msgid ""Flat"" msgstr ""Flat"" msgid ""Extremely simple topology."" msgstr ""極めて単純なトポロジー。"" msgid ""No DHCP overhead."" msgstr ""DHCPによるオーバーヘッドがありません。"" ""Requires file injection into the instance to configure network interfaces.""""ネットワークインターフェースの設定にはインスタンスへのファイルの注入が必須で"" ""す。""""Configure a single bridge as the integration bridge (br-int) and connect it "" ""to a physical network interface with the Modular Layer 2 (ML2) plug-in, "" ""which uses Open vSwitch by default.""""インテグレーションブリッジ(br-int)として1つのブリッジを構成し、Open vSwitchを"" ""デフォルトとして使うModuler Layer2(ML2)プラグインでbr-intと物理ネットワークイ"" ""ンターフェースを接続します。"" msgid ""Relatively simple to deploy."" msgstr ""比較的シンプルな構成"" msgid ""Standard networking."" msgstr ""標準的なネットワーク。"" msgid ""Works with all guest operating systems."" msgstr ""どんなゲストOSでも動きます。"" msgid ""Requires its own DHCP broadcast domain."" msgstr ""専用の DHCP ブロードキャストドメインが必要。""""Configure DHCP agents and routing agents. Network Address Translation (NAT) "" ""performed outside of compute nodes, typically on one or more network nodes.""""DHCPエージェントとルーティングエージェントを構成します。Network Address "" ""Translation (NAT) によってコンピュートノードと外部を接続します。一般的に1つ以"" ""上のネットワークノードで成り立ちます。"" msgid ""VlanManager"" msgstr ""VlanManager"" msgid ""Each tenant is isolated to its own VLANs."" msgstr ""それぞれのテナントは自身のVLANによって独立しています。"" msgid ""More complex to set up."" msgstr ""少し複雑な構成。"" msgid ""Requires many VLANs to be trunked onto a single port."" msgstr ""一つのポートに多数の VLAN をトランクが必要。"" msgid ""Standard VLAN number limitation."" msgstr ""標準的な VLAN 数の上限。"" msgid ""Switches must support 802.1q VLAN tagging."" msgstr ""802.1q VLAN タギングに対応したスイッチが必要。"" msgid """" ""Isolated tenant networks implement some form of isolation of layer 2 traffic "" ""between distinct networks. VLAN tagging is key concept, where traffic is "" ""“tagged” with an ordinal identifier for the VLAN. Isolated network "" ""implementations may or may not include additional services like DHCP, NAT, "" ""and routing."" msgstr """" ""独立テナントネットワークは個々のネットワーク間のレイヤー2トラフィックをいくつ"" ""かの方法で分離する事で実装します。タグVLANはキーコンセプトでトラフィックをど"" ""こに流すかを”タグ”で決定します。独立テナントネットワークにはDHCPやNAT、ルー"" ""ティングと言った追加のサービスが含まれるかもしれませんし、含まれないかもしれ"" ""ません。"" msgid ""FlatDHCP Multi-host with high availability (HA)"" msgstr ""高可用性(HA)のためのフラットDHCPマルチホスト構成"" msgid """" ""Networking failure is isolated to the VMs running on the affected hypervisor."" msgstr ""ネットワーク障害は影響を受けるハイパーバイザーのVMに限定されます。"" msgid ""DHCP traffic can be isolated within an individual host."" msgstr ""DHCP トラフィックは個々のホスト内に閉じ込めることができる。"" msgid ""Network traffic is distributed to the compute nodes."" msgstr ""ネットワークトラフィックをコンピュートノード全体に分散できる。"" msgid """" ""Compute nodes typically need IP addresses accessible by external networks."" msgstr """" ""コンピュートノードは概して外部ネットワークからアクセス可能なIPアドレスが必要"" ""です。"" msgid """" ""Options must be carefully configured for live migration to work with "" ""networking services."" msgstr """" ""ネットワークサービスが正しく動くようにライブマイグレーションを設定するために"" ""は注意してオプションを構成する必要があります。"" msgid """" ""Configure neutron with multiple DHCP and layer-3 agents. Network nodes are "" ""not able to failover to each other, so the controller runs networking "" ""services, such as DHCP. Compute nodes run the ML2 plug-in with support for "" ""agents such as Open vSwitch or Linux Bridge."" msgstr """" ""複数のDHCPおよびレイヤ-3エージェントを持つようなneutronの構成では、ネットワー"" ""クノードは互いにフェールオーバできませんのでコントローラはDHCPといったネット"" ""ワークサービスを実行します。コンピュートノードはOpen vSwitchまたはLinux "" ""BridgeといったエージェントをサポートするML2プラグインを実行します。"" msgid """" ""Both <literal>nova-network</literal> and neutron services provide similar "" ""capabilities, such as VLAN between VMs. You also can provide multiple NICs "" ""on VMs with either service. Further discussion follows."" msgstr """" ""<literal>nova-network</literal>とneutronサービスはVM間でのVLANといった似通っ"" ""た可用性を提供します。また、それぞれのサービスで複数のNICを付与したVMも提供す"" ""る事ができます。"" msgid ""VLAN Configuration Within OpenStack VMs"" msgstr ""OpenStack VM内のVLAN設定"" msgid """" ""VLAN configuration can be as simple or as complicated as desired. The use of "" ""VLANs has the benefit of allowing each project its own subnet and broadcast "" ""segregation from other projects. To allow OpenStack to efficiently use "" ""VLANs, you must allocate a VLAN range (one for each project) and turn each "" ""compute node switch port into a trunk port.<indexterm class=\""singular"" ""\""><primary>networks</primary><secondary>VLAN</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>VLAN network</primary></"" ""indexterm><indexterm class=\""singular\""><primary>network design</"" ""primary><secondary>network topology</secondary><tertiary>VLAN with OpenStack "" ""VMs</tertiary></indexterm>"" msgstr """" ""VLAN設定は要求によっては複雑であったり単純であったりする事ができます。VLANを"" ""使用すると互いのプロジェクトに専用のサブネットを提供でき、ブロードキャストド"" ""メインを分割するという利点が得られます。効果的にVLANを使用できるようにするに"" ""は、VLANの範囲を(それぞれのプロジェクトに1つずつ)割り当て、各コンピュートノー"" ""ドのポートをトランクポートに変更する必要があります。<indexterm class="" ""\""singular\""><primary>ネットワーク</primary><secondary>VLAN</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>VLANネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワーク設計</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>OpenStack VMと"" ""VLAN</tertiary></indexterm>""msgid ""Multi-NIC Provisioning"" msgstr ""マルチNICプロビジョニング"" msgid ""Multi-Host and Single-Host Networking"" msgstr ""マルチホストあるいはシングルホストネットワーキング""""The <literal>nova-network</literal> service has the ability to operate in a "" ""multi-host or single-host mode. Multi-host is when each compute node runs a "" ""copy of <literal>nova-network</literal> and the instances on that compute "" ""node use the compute node as a gateway to the Internet. The compute nodes "" ""also host the floating IPs and security groups for instances on that node. "" ""Single-host is when a central server—for example, the cloud controller—runs "" ""the <code>nova-network</code> service. All compute nodes forward traffic "" ""from the instances to the cloud controller. The cloud controller then "" ""forwards traffic to the Internet. The cloud controller hosts the floating "" ""IPs and security groups for all instances on all compute nodes in the cloud."" ""<indexterm class=\""singular\""><primary>single-host networking</primary></"" ""indexterm><indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>multi-host</secondary></indexterm><indexterm class="" ""\""singular\""><primary>multi-host networking</primary></indexterm><indexterm "" ""class=\""singular\""><primary>network design</primary><secondary>network "" ""topology</secondary><tertiary>multi- vs. single-host networking</tertiary></"" ""indexterm>""""<literal>nova-network</literal>はマルチホストまたはシングルホストモードで運用"" ""する事ができます。マルチホスト構成はそれぞれのコンピュートノードで"" ""<literal>nova-network</literal> の複製とそのコンピュートノードのインスタンス"" ""が稼働している時、コンピュートノードをインターネットへのゲートウェイとして利"" ""用します。また、そのコンピュートノードはそこで稼働しているインスタンスのフ"" ""ローティングIPアドレスとセキュリティグループを受け持ちます。シングルホスト構"" ""成はクラウドコントローラと言った中央サーバが<code>nova-network</code> サービ"" ""スを受け持ちます。すべてのコンピュートノードはインターネットへのトラフィック"" ""をコントローラに転送します。クラウドコントローラがすべてのコントローラ上のす"" ""べてのインスタンスのフローティングIPアドレスとセキュリティグループを受け持ち"" ""ます。<indexterm class=\""singular\""><primary>シングルホストネットワーク</"" ""primary></indexterm><indexterm class=\""singular\""><primary>ネットワーク</"" ""primary><secondary>マルチホスト</secondary></indexterm><indexterm class="" ""\""singular\""><primary>マルチホストネットワーク</primary></"" ""indexterm><indexterm class=\""singular\""><primary>ネットワークデザイン</"" ""primary><secondary>ネットワークトポロジー</secondary><tertiary>マルチvsシング"" ""ルホストネットワーク</tertiary></indexterm>""""There are benefits to both modes. Single-node has the downside of a single "" ""point of failure. If the cloud controller is not available, instances cannot "" ""communicate on the network. This is not true with multi-host, but multi-host "" ""requires that each compute node has a public IP address to communicate on "" ""the Internet. If you are not able to obtain a significant block of public IP "" ""addresses, multi-host might not be an option."" msgstr """" ""どちらのモードにもメリットがあります。シングルホストモードには、単一障害点と"" ""いうマイナス面があります。クラウドコントローラーが利用できなくなると、インス"" ""タンスはネットワークと通信できなくなります。マルチホストモードでは、この状況"" ""にはなりませんが、各コンピュートノードはインターネットと通信するためのパブ"" ""リックIPアドレスが必要となります。十分な大きさのパブリックIPアドレスブロック"" ""を取得できない場合には、マルチホストモードは選択肢にならないかもしれません。"" msgid ""Services for Networking"" msgstr ""ネットワーク関係のサービス"" msgid """" ""OpenStack, like any network application, has a number of standard "" ""considerations to apply, such as NTP and DNS.<indexterm class=\""singular"" ""\""><primary>network design</primary><secondary>services for networking</""""多くのネットワークアプリケーションがそうであるようにOpenStackでもNTPやDNS と"" ""言った適用するための数多くの検討事項があります。<indexterm class=\""singular"" ""\""><primary>ネットワークデザイン</primary><secondary>ネットワークサービス</"" ""secondary></indexterm>"" msgid ""NTP"" msgstr ""NTP""""Time synchronization is a critical element to ensure continued operation of "" ""OpenStack components. Correct time is necessary to avoid errors in instance "" ""scheduling, replication of objects in the object store, and even matching "" ""log timestamps for debugging.<indexterm class=\""singular"" ""\""><primary>networks</primary><secondary>Network Time Protocol (NTP)</"" ""secondary></indexterm>""""時刻同期はOpenStackコンポーネントを継続運用する上で非常に重要な要素です。正確"" ""な時間はインスタンスのスケジューリング、ボブジェクトストア内のオブジェクトの"" ""レプリケーションのエラーの回避や、さらにはデバッグのためにログのタイムスタン"" ""プの一致という意味合いで必要です。<indexterm class=\""singular\""><primary>ネッ"" ""トワーク</primary><secondary>ネットワークタイムプロトコル (NTP)</secondary></"" ""indexterm>""msgid """" ""All servers running OpenStack components should be able to access an "" ""appropriate NTP server. You may decide to set up one locally or use the "" ""public pools available from the <link href=\""http://www.pool.ntp.org/en/\""> "" ""Network Time Protocol project</link>.""""OpenStack コンポーネントが稼働しているすべてのサーバは適切なNTPサーバにアクセ"" ""ス可能であるべきです。<link href=\""http://www.pool.ntp.org/en/\""> Network "" ""Time Protocol project</link>が提供しているパブリックサーバかローカルにNTPサー"" ""バを構築するか決定する必要があるでしょう。"" msgid ""DNS"" msgstr ""DNS"" msgid """" ""OpenStack does not currently provide DNS services, aside from the dnsmasq "" ""daemon, which resides on <code>nova-network</code> hosts. You could consider "" ""providing a dynamic DNS service to allow instances to update a DNS entry "" ""with new IP addresses. You can also consider making a generic forward and "" ""reverse DNS mapping for instances' IP addresses, such as vm-203-0-113-123."" ""example.com.<indexterm class=\""singular\""><primary>DNS (Domain Name Server, "" ""Service or System)</primary><secondary>DNS service choices</secondary></"" ""indexterm>"" msgstr """" ""OpenStackは現在のところ <code>nova-network</code>ホストに起動しているdnsmasq"" ""デーモンに則したDNSサービスの提供はしていません。インスタンスの新IPアドレスに"" ""対するDNSレコードの更新のためにダイナミックDNSの構成を検討する事ができます。"" ""また、インスタンスのIPアドレスに対応するvm-203-0-113-123.example.comというよ"" ""うな一般的な逆引きDNSサービスの構成も検討する事ができます。<indexterm class="" ""\""singular\""><primary>DNS (Domain Name Serverサービス、システム)</"" ""primary><secondary>DNS サービスの選択</secondary></indexterm>"" msgid ""Backup and Recovery"" msgstr ""バックアップとリカバリー"" msgid ""Other backup considerations include:"" msgstr ""さらにバックアップの考慮点として以下があげられます。"" msgid ""How many backups to keep?"" msgstr ""いくつのバックアップを持つべきか?"" msgid ""Should backups be kept off-site?"" msgstr ""オフサイトにバックアップを置くべきか?"" msgid ""How often should backups be tested?"" msgstr ""どの程度の頻度でバックアップをテストすべきか?"" msgid """" ""Just as important as a backup policy is a recovery policy (or at least "" ""recovery testing)."" msgstr """" ""バックアップポリシーと同じくらい大事なことは、リカバリーポリシーです (少なく"" ""ともリカバリーのテストは必要です)。"" msgid ""Database Backups"" msgstr ""データベースのバックアップ"" msgid ""If you only want to backup a single database, you can instead run:"" msgstr """" ""もし、単一のデータベースのみバックアップする場合は次のように実行します。"" msgid ""where <code>nova</code> is the database you want to back up."" msgstr ""ここで <code>nova</code> はバックアップ対象のデータベースです。"" msgid """" ""You can easily automate this process by creating a cron job that runs the "" ""following script once per day:"" msgstr """" ""以下のようなcronジョブを一日に一度実行することで、簡単に自動化することも出来""msgid ""File System Backups"" msgstr ""ファイルシステムバックアップ"" msgid ""Image Catalog and Delivery"" msgstr ""イメージカタログと配布"" ""There are two ways to ensure stability with this directory. The first is to "" ""make sure this directory is run on a RAID array. If a disk fails, the "" ""directory is available. The second way is to use a tool such as rsync to "" ""replicate the images to another server:""""このディレクトリの永続性を保証するために二つの方法があります。一つ目はRAIDア"" ""レイ上にこのディレクトリを置くことで、ディスク障害時にもこのディレクトリが利"" ""用できます。二つ目の方法はrsyncのようなツールを用いてイメージを他のサーバーに"" ""複製することです。"" msgid ""Identity"" msgstr ""認証"" msgid ""<code>/var/lib/cinder</code> should also be backed up."" msgstr ""<code>/var/lib/cinder</code>もまたバックアップされるべきです。"" msgid ""Recovering Backups"" msgstr ""バックアップのリカバリー"" msgid ""Once the files are restored, start everything back up:"" msgstr ""ファイルをリストア後、サービスを起動します。"" msgid ""Maintenance, Failures, and Debugging"" msgstr ""メンテナンス、故障およびデバッグ"" msgid ""Cloud Controller and Storage Proxy Failures and Maintenance"" msgstr ""クラウドコントローラーとストレージプロキシの故障とメンテナンス"" msgid """" ""The cloud controller and storage proxy are very similar to each other when "" ""it comes to expected and unexpected downtime. One of each server type "" ""typically runs in the cloud, which makes them very noticeable when they are "" ""not running."" msgstr """" ""想定内の場合も想定外の場合も停止時間が発生した場合の挙動が、クラウドコント"" ""ローラーとストレージプロキシは互いに似ています。クラウドコントローラーとスト"" ""レージプロキシはそれぞれクラウドで一つ実行されるので、動作していない場合、非"" ""常に目立ちます。"" msgid ""Planned Maintenance"" msgstr ""計画メンテナンス"" msgid ""After a Cloud Controller or Storage Proxy Reboots"" msgstr ""クラウドコントローラーまたはストレージプロキシの再起動後"" msgid """" ""For the storage proxy, ensure that the Object Storage service has resumed:"" msgstr """" ""ストレージプロキシの場合、Object Storage サービスが再開していることを確認しま"" ""す。"" msgid ""Also check that it is functioning:"" msgstr ""また、正しく機能していることを確認します。"" msgid ""Total Cloud Controller Failure"" msgstr ""全体的なクラウドコントローラーの故障"" msgid ""Compute Node Failures and Maintenance"" msgstr ""コンピュートノードの故障とメンテナンス"" msgid """" ""Sometimes a compute node either crashes unexpectedly or requires a reboot "" ""for maintenance reasons."" msgstr """" ""コンピュートノードは、予期せずクラッシュしたり、メンテナンスのために再起動が"" ""必要になったりすることがときどきあります。"" msgid ""Next, migrate them one by one:"" msgstr ""次に、それらを一つずつマイグレーションします。"" msgid """" ""If you are not using shared storage, you can use the <code>--block-migrate</"" ""code> option:"" msgstr """" ""共有ストレージを使用していない場合、<code>--block-migrate</code> オプションを"" ""使用できます。"" msgid ""Then start the <code>nova-compute</code> service:"" msgstr ""そして <code>nova-compute</code> サービスを起動します。"" msgid """" ""You can now optionally migrate the instances back to their original compute "" ""node."" msgstr """" ""インスタンスを元のコンピュートノードにマイグレーションすることもできます。"" msgid ""After a Compute Node Reboots"" msgstr ""コンピュートノードの再起動後"" msgid ""Also ensure that it has successfully connected to the AMQP server:"" msgstr ""AMQP サーバーに正常に接続できることも確認します。"" msgid """" ""After you have the list, you can use the nova command to start each instance:"" msgstr """" ""一覧を取得した後、各インスタンスを起動するために nova コマンドを使用できま"" ""す。"" msgid """" ""If an instance does not boot, meaning <code>virsh list</code> never shows "" ""the instance as even attempting to boot, do the following on the compute "" ""node:"" msgstr """" ""インスタンスがブートしなければ、つまりブートしようとしても <code>virsh list</"" ""code> がインスタンスを表示しなければ、コンピュートノードにおいて以下のとおり"" ""実行します。"" msgid """" ""Try executing the <code>nova reboot</code> command again. You should see an "" ""error message about why the instance was not able to boot"" msgstr """" ""再び <code>nova reboot</code> コマンドを実行してみてください。インスタンスが"" ""なぜブートできないかについて、エラーメッセージを確認すべきです。"" msgid ""Inspecting and Recovering Data from Failed Instances"" msgstr ""故障したインスタンスからの検査とデータ復旧"" msgid ""Mount the qemu-nbd device."" msgstr ""qemu-nbd デバイスをマウントします。"" msgid ""Volumes"" msgstr ""ボリューム"" msgid ""Total Compute Node Failure"" msgstr ""コンピュートノード全体の故障"" msgid """" ""To do this, generate a list of instance UUIDs that are hosted on the failed "" ""node by running the following query on the nova database:"" msgstr """" ""これを実行するために、nova データベースにおいて以下のクエリーを実行することに"" ""より、故障したノードにおいてホストされているインスタンスの UUID の一覧を生成"" ""します。"" msgid ""/var/lib/nova/instances"" msgstr ""/var/lib/nova/instances"" msgid ""<code>/var/lib/nova/instances</code> contains two types of directories."" msgstr """" ""<code>/var/lib/nova/instances</code> には 2 種類のディレクトリがあります。"" msgid """" ""The other directories are titled <code>instance-xxxxxxxx</code>. These "" ""directories correspond to instances running on that compute node. The files "" ""inside are related to one of the files in the <code>_base</code> directory. "" ""They're essentially differential-based files containing only the changes "" ""made from the original <code>_base</code> directory."" msgstr """" ""もう一つのディレクトリは <code>instance-xxxxxxxx</code> という名前です。これ"" ""らのディレクトリはコンピュートノードにおいて実行中のインスタンスと対応しま"" ""す。中にあるファイルは <code>_base</code> ディレクトリにあるファイルのどれか"" ""と関連があります。これらは基本的に、元々の <code>_base</code> ディレクトリか"" ""らの変更点のみ含む、差分ベースのファイルです。"" msgid """" ""Although this method is not documented or supported, you can use it when "" ""your compute node is permanently offline but you have instances locally "" ""stored on it."" msgstr """" ""この方法はドキュメントに書かれておらず、サポートされていない方法ですが、コン"" ""ピュートノードが完全にオフラインになってしまったが、インスタンスがローカルに"" ""保存されているときに、この方法を使用できます。"" msgid ""Storage Node Failures and Maintenance"" msgstr ""ストレージノードの故障とメンテナンス"" msgid ""Rebooting a Storage Node"" msgstr ""ストレージノードの再起動"" msgid ""Shutting Down a Storage Node"" msgstr ""ストレージノードのシャットダウン"" msgid ""Next, redistribute the ring files to the other nodes:"" msgstr ""次に、ring ファイルを他のノードに再配布します。"" msgid """" ""These actions effectively take the storage node out of the storage cluster."" msgstr """" ""これらの操作はストレージノードをストレージクラスターから効率的に外せます。"" msgid ""Replacing a Swift Disk"" msgstr ""Swift ディスクの交換"" msgid ""This example assumes that <code>/dev/sdb</code> has failed."" msgstr ""この例では、<code>/dev/sdb</code> が故障したと仮定します。"" msgid ""First, unmount the disk:"" msgstr ""まず、ディスクをアンマウントします。"" msgid """" ""Next, physically remove the disk from the server and replace it with a "" ""working disk."" msgstr """" ""次に、ディスクを物理的にサーバーから取り外し、正常なディスクと入れ替えます。"" msgid ""Ensure that the operating system has recognized the new disk:"" msgstr """" ""オペレーティングシステムが新しいディスクを認識していることを確認します。"" msgid """" ""Because it is recommended to not use partitions on a swift disk, simply "" ""format the disk as a whole:"" msgstr """" ""Swift ディスクではパーティションを使用しないことが推奨されるので、単にディス"" ""ク全体をフォーマットします。"" msgid ""Finally, mount the disk:"" msgstr ""最後に、ディスクをマウントします。"" msgid """" ""Swift should notice the new disk and that no data exists. It then begins "" ""replicating the data to the disk from the other existing replicas."" msgstr """" ""Swift は新しいディスクを認識します。また、データが存在しないことを認識しま"" ""す。そうすると、他の既存の複製からディスクにデータを複製しはじめます。"" msgid ""Handling a Complete Failure"" msgstr ""完全な故障の対処"" msgid ""Services"" msgstr ""サービス"" msgid ""Internal network connectivity"" msgstr ""内部ネットワーク接続性"" msgid ""Backing storage services"" msgstr ""バックエンドのストレージサービス"" msgid ""3"" msgstr ""3"" msgid ""5"" msgstr ""5"" msgid ""User virtual machines"" msgstr ""ユーザーの仮想マシン"" msgid ""10"" msgstr ""10"" msgid ""15"" msgstr ""15"" msgid ""Keystone services"" msgstr ""Keystone サービス"" msgid ""20"" msgstr ""20"" msgid ""cinder-scheduler"" msgstr ""cinder-scheduler"" msgid ""21"" msgstr ""21"" msgid ""22"" msgstr ""22"" msgid ""98"" msgstr ""98"" msgid ""99"" msgstr ""99"" msgid ""100"" msgstr ""100"" msgid ""Dashboard node"" msgstr ""ダッシュボードサービス"" msgid ""Working with Hardware"" msgstr ""ハードウェアの取り扱い"" msgid ""Adding a Compute Node"" msgstr ""コンピュートノードの追加"" msgid """" ""We recommend that you use the same hardware for new compute and block "" ""storage nodes. At the very least, ensure that the CPUs are similar in the "" ""compute nodes to not break live migration."" msgstr """" ""新しいコンピュートノードとブロックストレージノードには、同じハードウェアを使"" ""用することを推奨します。最低限、ライブマイグレーションが失敗しないように、コ"" ""ンピュートノードでは CPU は同様のものにしてください。"" msgid ""Adding an Object Storage Node"" msgstr ""オブジェクトストレージノードの追加"" msgid ""Replacing Components"" msgstr ""コンポーネントの交換"" msgid ""Databases"" msgstr ""データベース"" msgid ""Database Connectivity"" msgstr ""データベース接続性"" msgid ""The connection strings take this format:"" msgstr ""connection 文字列は以下の形式をとります。"" msgid ""Performance and Optimizing"" msgstr ""パフォーマンスと最適化"" msgid ""HDWMY"" msgstr ""HDWMY"" msgid ""Hourly"" msgstr ""毎時"" msgid ""Check your monitoring system for alerts and act on them."" msgstr ""監視システムのアラートを確認し、それらに対処します。"" msgid ""Check your ticket queue for new tickets."" msgstr ""チケットキューの新しいチケットを確認します。"" msgid ""Daily"" msgstr ""日次"" msgid ""Check for instances in a failed or weird state and investigate why."" msgstr ""故障または異常になっているインスタンスを確認し、理由を調査します。"" msgid ""Check for security patches and apply them as needed."" msgstr ""セキュリティパッチを確認し、必要に応じて適用します。"" msgid ""Weekly"" msgstr ""週次"" msgid ""User quotas"" msgstr ""ユーザークォータ"" msgid ""Disk space"" msgstr ""ディスク領域"" msgid ""Image usage"" msgstr ""イメージ使用量"" msgid ""Large instances"" msgstr ""大きなインスタンス"" msgid ""Network usage (bandwidth and IP usage)"" msgstr ""ネットワーク使用量 (帯域および IP 使用量)"" msgid ""Check cloud usage: <placeholder-1/>"" msgstr ""クラウドの使用量を確認します: <placeholder-1/>"" msgid ""Verify your alert mechanisms are still working."" msgstr ""アラート機能が動作していることを確認します。"" msgid ""Monthly"" msgstr ""月次"" msgid ""Check usage and trends over the past month."" msgstr ""この 1 か月における使用量および傾向を確認します。"" msgid ""Check for user accounts that should be removed."" msgstr ""削除すべきユーザーアカウントを確認します。"" msgid ""Check for operator accounts that should be removed."" msgstr ""削除すべきオペレーターアカウントを確認します。"" msgid ""Quarterly"" msgstr ""四半期ごと"" msgid ""Review usage and trends over the past quarter."" msgstr ""この四半期における使用量および傾向を確認します。"" msgid ""Prepare any quarterly reports on usage and statistics."" msgstr ""使用量と統計に関する四半期レポートを準備します。"" msgid ""Review and plan any necessary cloud additions."" msgstr ""クラウドの追加の必要性を検討し、計画を立てます。"" msgid ""Review and plan any major OpenStack upgrades."" msgstr ""OpenStack のメジャーアップグレードの内容を確認し、その計画を立てます。"" msgid ""Upgrade OpenStack."" msgstr ""OpenStack をアップグレードします。"" msgid ""Tailing Logs"" msgstr ""最新ログの確認"" msgid ""Terminal 1:"" msgstr ""端末 1:"" msgid ""Terminal 2:"" msgstr ""端末 2:"" msgid ""Running Daemons on the CLI"" msgstr ""コマンドラインでのデーモンの実行"" msgid """" ""The <literal>-H</literal> flag is required when running the daemons with "" ""sudo because some daemons will write files relative to the user's home "" ""directory, and this write may fail if <literal>-H</literal> is left off."" msgstr """" ""sudo を用いてデーモンを実行するとき、<literal>-H</literal> フラグが必要です。"" ""いくつかのデーモンは、ユーザーのホームディレクトリーからの相対パスのファイル"" ""に書き込みを行うため、<literal>-H</literal> がないと、この書き込みが失敗して"" ""しまいます。"" msgid ""This might print the error and cause of the problem.<placeholder-1/>"" msgstr """" ""これにより、エラーと問題の原因が表示されるかもしれません。 <placeholder-1/>"" msgid ""Example of Complexity"" msgstr ""複雑な例"" msgid """" ""Further troubleshooting showed that libvirt was not running at all. This "" ""made more sense. If libvirt wasn't running, then no instance could be "" ""virtualized through KVM. Upon trying to start libvirt, it would silently die "" ""immediately. The libvirt logs did not explain why."" msgstr """" ""さらなるトラブルシューティングにより、libvirt がまったく動作していないことが"" ""わかりました。これは大きな手がかりです。libvirt が動作していないと、KVM によ"" ""るインスタンスの仮想化ができません。libvirt を開始させようとしても、libvirt "" ""は何も表示せずすぐに停止しました。libvirt のログでは理由がわかりませんでし"" ""た。"" msgid ""Uninstalling"" msgstr ""アンインストール"" msgid ""Acknowledgments"" msgstr ""謝辞"" msgid """" ""We want to acknowledge our excellent host Rackers at Rackspace in Austin:"" msgstr """" ""私たちは、オースチンの Rackspace での素晴らしいホスト Rackersに感謝したい:"" msgid """" ""Emma Richards of Rackspace Guest Relations took excellent care of our lunch "" ""orders and even set aside a pile of sticky notes that had fallen off the "" ""walls."" msgstr """" ""Rackspace ゲストリレーションズの Emma Richards は、私たちのランチの注文を素晴"" ""らしく面倒を見てくれて、更に壁から剥がれ落ちた付箋紙の山を脇においてくれまし"" ""た。"" msgid """" ""Betsy Hagemeier, a Fanatical Executive Assistant, took care of a room "" ""reshuffle and helped us settle in for the week."" msgstr """" ""熱狂的なエグゼクティブアシスタントの Betsy Hagemeier は、部屋の改造の面倒を見"" ""てくれて、1週間で解決する手助けをしてくれました。"" msgid """" ""The Real Estate team at Rackspace in Austin, also known as \""The Victors,\"" "" ""were super responsive."" msgstr """" ""「The Victors」としても知られている、オースチンの Rackspace の不動産チーム"" ""は、素晴らしい応答をしてくれました。"" msgid """" ""Adam Powell in Racker IT supplied us with bandwidth each day and second "" ""monitors for those of us needing more screens."" msgstr """" ""Rackspace IT部門 の Adam Powell は、私たちに毎日のネットワーク帯域を提供して"" ""くれました。また、より多くのスクリーンが必要となったため、セカンドモニタを提"" ""供してくれました。"" msgid """" ""On Wednesday night we had a fun happy hour with the Austin OpenStack Meetup "" ""group and Racker Katie Schmidt took great care of our group."" msgstr """" ""水曜日の夜、オースチン OpenStack ミートアップグループと楽しく幸せな時間を過ご"" ""し、Racker Katie Schmidt は私たちのグループを素晴らしい世話をしてくれました。"" msgid ""We also had some excellent input from outside of the room:"" msgstr ""私たちは部屋の外から、いくつかの素晴らしいインプットを得ました。"" msgid """" ""Tim Bell from CERN gave us feedback on the outline before we started and "" ""reviewed it mid-week."" msgstr """" ""CERNの Tim Bell は、私たちが作業を開始する前に、その概要についてフィードバッ"" ""クを与えてくれて、週の半ばにはレビューをしてくれました。"" msgid """" ""Sébastien Han has written excellent blogs and generously gave his permission "" ""for re-use."" msgstr """" ""Sébastien Han は素晴らしいブログを書いてくれて、寛大にも再利用の許可を与えて"" ""くれました。"" msgid """" ""Oisin Feeley read it, made some edits, and provided emailed feedback right "" ""when we asked."" msgstr """" ""Oisin Feeley は、このマニュアルを読んで、いくつかの編集をし、私たちが問い合わ"" ""せをした際には、E-mailでのフィードバックをくれました。"" msgid """" ""We couldn't have pulled it off without so much supportive help and "" ""encouragement."" msgstr """" ""私たちは、これらの多大な協力的な援助と励まし無しには、これを成し遂げることは"" ""できなかったでしょう。"" msgid ""Provisioning and Deployment"" msgstr ""プロビジョニングとデプロイメント"" msgid """" ""A critical part of a cloud's scalability is the amount of effort that it "" ""takes to run your cloud. To minimize the operational cost of running your "" ""cloud, set up and use an automated deployment and configuration "" ""infrastructure with a configuration management system, such as Puppet or "" ""Chef. Combined, these systems greatly reduce manual effort and the chance "" ""for operator error.<indexterm class=\""singular\""><primary>cloud computing</"" ""primary><secondary>minimizing costs of</secondary></indexterm>"" msgstr """" ""クラウドのスケーラビリティにおける重要な部分の一つは、クラウドを運用するのに"" ""必要な労力にあります。クラウドの運用コストを最小化するために、Puppet や Chef "" ""などの設定管理システムを使用して、自動化されたデプロイメントおよび設定インフ"" ""ラストラクチャーを設定、使用してください。これらのシステムを統合すると、工数"" ""やオペレーターのミスを大幅に減らすことができます。<indexterm class=\""singular"" ""\""><primary>クラウドコンピューティング</primary><secondary>コストの最小化</"" ""secondary></indexterm>"" msgid """" ""This infrastructure includes systems to automatically install the operating "" ""system's initial configuration and later coordinate the configuration of all "" ""services automatically and centrally, which reduces both manual effort and "" ""the chance for error. Examples include Ansible, Chef, Puppet, and Salt. You "" ""can even use OpenStack to deploy OpenStack, fondly named TripleO, for "" ""OpenStack On OpenStack.<indexterm class=\""singular\""><primary>Puppet</"" ""primary></indexterm><indexterm class=\""singular\""><primary>Chef</primary></"" ""indexterm>"" msgstr """" ""このインフラストラクチャーには、オペレーティングシステムの初期設定を自動にイ"" ""ンストールするシステムや、全サーバーを自動的かつ一元的に連携、設定するシステ"" ""ムが含まれており、手作業やエラーの発生する可能性を減らします。例えば、"" ""Ansible、Chef、Puppet、Salt などのシステムです。OpenStack を使用して、"" ""OpenStack をデプロイすることも可能です。これは、TripleO (OpenStack 上の "" ""OpenStack) という愛称で呼ばれています。<indexterm class=\""singular"" ""\""><primary>Puppet</primary></indexterm><indexterm class=\""singular"" ""\""><primary>Chef</primary></indexterm>"" msgid ""Automated Deployment"" msgstr ""自動デプロイメント"" msgid """" ""An automated deployment system installs and configures operating systems on "" ""new servers, without intervention, after the absolute minimum amount of "" ""manual work, including physical racking, MAC-to-IP assignment, and power "" ""configuration. Typically, solutions rely on wrappers around PXE boot and "" ""TFTP servers for the basic operating system install and then hand off to an "" ""automated configuration management system.<indexterm class=\""singular"" ""\""><primary>deployment</primary><see>provisioning/deployment</see></"" ""indexterm><indexterm class=\""singular\""><primary>provisioning/deployment</"" ""primary><secondary>automated deployment</secondary></indexterm>"" msgstr """" ""自動のデプロイメントシステムは、物理ラッキング、MAC から IP アドレスの割当、"" ""電源設定など、必要最小限の手作業のみで、介入なしに新規サーバー上にオペレー"" ""ティングシステムのインストールと設定を行います。ソリューションは通常、PXE "" ""ブートや TFTP サーバー関連のラッパーに依存して基本のオペレーティングシステム"" ""をインストールして、次に自動設定管理システムに委譲されます。<indexterm class="" ""\""singular\""><primary>デプロイメント</primary><see>プロビジョニング/デプロイ"" ""メント</see></indexterm><indexterm class=\""singular\""><primary>プロビジョニン"" ""グ/デプロイメント</primary><secondary>自動デプロイメント</secondary></"" ""indexterm>"" msgid """" ""Both Ubuntu and Red Hat Enterprise Linux include mechanisms for configuring "" ""the operating system, including preseed and kickstart, that you can use "" ""after a network boot. Typically, these are used to bootstrap an automated "" ""configuration system. Alternatively, you can use an image-based approach for "" ""deploying the operating system, such as systemimager. You can use both "" ""approaches with a virtualized infrastructure, such as when you run VMs to "" ""separate your control services and physical infrastructure."" msgstr """" ""Ubuntu と Red Hat Enterprise Linux にはいずれも、ネットワークブート後に使用可"" ""能なpreseed や kickstart といった、オペレーティングシステムを設定するための仕"" ""組みがあります。これらは、典型的には自動環境設定システムのブートストラップに"" ""使用されます。他の方法としては、systemimager のようなイメージベースのオペレー"" ""ティングシステムのデプロイメント手法を使うこともできます。これらの手法はどち"" ""らも、物理インフラストラクチャーと制御サービスを分離するために仮想マシンを実"" ""行する場合など、仮想化基盤と合わせて使用できます。"" msgid """" ""When you create a deployment plan, focus on a few vital areas because they "" ""are very hard to modify post deployment. The next two sections talk about "" ""configurations for:"" msgstr """" ""デプロイメントプランを作成する場合、デプロイメント後の修正は困難であるため、"" ""いくつかの重要な分野にフォーカスを当ててください。次の 2 章で以下の設定内容に"" ""ついて説明していきます。"" msgid ""Disk partioning and disk array setup for scalability"" msgstr """" ""スケーラビリティ確保に向けたディスクのパーティショニングおよびディスク配列設"" ""定"" msgid ""Networking configuration just for PXE booting"" msgstr ""PXE ブート用のネットワーク設定"" msgid ""Disk Partitioning and RAID"" msgstr ""ディスクのパーティショニングと RAID"" msgid """" ""At the very base of any operating system are the hard drives on which the "" ""operating system (OS) is installed.<indexterm class=\""singular"" ""\""><primary>RAID (redundant array of independent disks)</primary></"" ""indexterm><indexterm class=\""singular\""><primary>partitions</"" ""primary><secondary>disk partitioning</secondary></indexterm><indexterm class="" ""\""singular\""><primary>disk partitioning</primary></indexterm>"" msgstr """" ""オペレーティングシステムの基盤は、オペレーティングシステムがインストールされ"" ""るハードドライブです。<indexterm class=\""singular\""><primary>RAID (Redundant "" ""Array of Independent Disks)</primary></indexterm><indexterm class=\""singular"" ""\""><primary>パーティション</primary><secondary>ディスクパーティショニング</"" ""secondary></indexterm><indexterm class=\""singular\""><primary>ディスクパーティ"" ""ショニング</primary></indexterm>"" msgid """" ""You must complete the following configurations on the server's hard drives:"" msgstr """" ""サーバーのハードディスクに対して、以下の環境設定を完了させなければなりませ"" ""ん。"" msgid """" ""Partitioning, which provides greater flexibility for layout of operating "" ""system and swap space, as described below."" msgstr """" ""パーティショニング。以下に説明されている通り、オペレーティングシステムと "" ""Swap 領域のレイアウトにおける柔軟性がはるかに高くになります。"" msgid """" ""Adding to a RAID array (RAID stands for redundant array of independent "" ""disks), based on the number of disks you have available, so that you can add "" ""capacity as your cloud grows. Some options are described in more detail "" ""below."" msgstr """" ""使用可能なディスクの数をもとに、RAID 配列 (RAID は Redundant Array of "" ""Independent Disks の略) に追加します。 こうすることで、クラウドが大きくなった"" ""場合も容量を追加できます。オプションは、以下で詳しく説明しています。"" msgid """" ""The simplest option to get started is to use one hard drive with two "" ""partitions:"" msgstr """" ""最もシンプルに使用を開始できるオプションは、１台のハードディスクを２つのパー"" ""ティションに分割することです。"" msgid """" ""File system to store files and directories, where all the data lives, "" ""including the root partition that starts and runs the system"" msgstr """" ""ファイルやディレクトリを格納するファイルシステム。システムを起動、実行する "" ""root パーティションなど、全データが設置される場所。"" msgid """" ""Swap space to free up memory for processes, as an independent area of the "" ""physical disk used only for swapping and nothing else"" msgstr """" ""プロセス用にメモリーを空ける Swap 領域。物理ディスクから独立した、スワップの"" ""みに使用される領域。"" msgid """" ""RAID is not used in this simplistic one-drive setup because generally for "" ""production clouds, you want to ensure that if one disk fails, another can "" ""take its place. Instead, for production, use more than one disk. The number "" ""of disks determine what types of RAID arrays to build."" msgstr """" ""通常、本番環境のクラウドでは、1 つのディスクに問題が発生した場合、別のディス"" ""クが必ず稼働するようにするため、RAID は、このシンプルな、ドライブ 1 つの設定"" ""では使用されません。本番環境では、ディスクを 1 つ以上使用します。ディスク数に"" ""より、どのようなタイプの RAID 配列を構築するか決定します。"" msgid """" ""We recommend that you choose one of the following multiple disk options:"" msgstr ""以下に挙げる複数のディスクの選択肢から選ぶことを推奨します。"" msgid ""Option 1"" msgstr ""オプション 1"" msgid """" ""Partition all drives in the same way in a horizontal fashion, as shown in "" ""<xref linkend=\""disk_partition_figure\""/>."" msgstr """" ""<xref linkend=\""disk_partition_figure\""/> にあるように、すべてのドライブを同"" ""じように並列してパーティショニングにします。"" msgid """" ""With this option, you can assign different partitions to different RAID "" ""arrays. You can allocate partition 1 of disk one and two to the <code>/boot</"" ""code> partition mirror. You can make partition 2 of all disks the root "" ""partition mirror. You can use partition 3 of all disks for a <code>cinder-"" ""volumes</code> LVM partition running on a RAID 10 array."" msgstr """" ""このオプションでは、パーティションごとに異なる RAID アレイにおくことができま"" ""す。例えば、ディスク 1 とディスク 2 のパーティション 1 を <code>/boot</code> "" ""パーティションのミラーとして、すべてのディスクのパーティション 2 をルートパー"" ""ティションのミラーとして、すべてのディスクのパーティション 3 を RAID10 アレイ"" ""の上の <code>cinder-volumes</code> の LVM パーティションとして割り当てること"" ""ができます。"" msgid ""Partition setup of drives"" msgstr ""ドライブのパーティション設定"" msgid """" ""While you might end up with unused partitions, such as partition 1 in disk "" ""three and four of this example, this option allows for maximum utilization "" ""of disk space. I/O performance might be an issue as a result of all disks "" ""being used for all tasks."" msgstr """" ""この例では、ディスク 3 と 4 のパーティション 1 のように未使用のパーティション"" ""が残る可能性もありますが、このオプションにより、ディスク領域の使用状況を最大"" ""化することができます。すべてのディスクがすべてのタスクで利用されるため、I/O "" ""のパフォーマンスが問題になる可能性があります。"" msgid ""Option 2"" msgstr ""オプション 2"" msgid """" ""Add all raw disks to one large RAID array, either hardware or software "" ""based. You can partition this large array with the boot, root, swap, and LVM "" ""areas. This option is simple to implement and uses all partitions. However, "" ""disk I/O might suffer."" msgstr """" ""すべてのローディスクを 1 つの大きな RAID 配列に追加します。ここでは、ソフト"" ""ウェアベースでもハードウェアベースでも構いません。この大きなRAID 配列を "" ""boot、root、swap、LVM 領域に分割します。この選択肢はシンプルですべてのパー"" ""ティションを利用することができますが、I/O性能に悪影響がでる可能性があります。"" msgid ""Option 3"" msgstr ""オプション 3"" msgid """" ""Dedicate entire disks to certain partitions. For example, you could allocate "" ""disk one and two entirely to the boot, root, and swap partitions under a "" ""RAID 1 mirror. Then, allocate disk three and four entirely to the LVM "" ""partition, also under a RAID 1 mirror. Disk I/O should be better because I/O "" ""is focused on dedicated tasks. However, the LVM partition is much smaller."" msgstr """" ""全ディスク領域を特定のパーティションに割り当てます。例えば、ディスク 1 と 2 "" ""すべてを RAID 1 ミラーとして boot、root、swapパーティションに割り当てます。そ"" ""して、ディスク 3 と 4 すべてを、同様に RAID 1 ミラーとしてLVMパーティションに"" ""割り当てます。I/O は専用タスクにフォーカスするため、ディスクの I/O は良くなる"" ""はずです。しかし、LVM パーティションははるかに小さくなります。"" msgid """" ""You may find that you can automate the partitioning itself. For example, MIT "" ""uses <link href=\""http://fai-project.org/\"">Fully Automatic Installation "" ""(FAI)</link> to do the initial PXE-based partition and then install using a "" ""combination of min/max and percentage-based partitioning.<indexterm class="" ""\""singular\""><primary>Fully Automatic Installation (FAI)</primary></"" ""indexterm>"" msgstr """" ""パーティショニング自体を自動化可能であることが分かります。例えば、MIT は "" ""<link href=\""http://fai-project.org/\"">Fully Automatic Installation (FAI)</"" ""link> を使用して、初期の PXE ベースのパーティション分割を行い、min/max および"" ""パーセントベースのパーティショニングを組み合わせてインストールしていきます。"" ""<indexterm class=\""singular\""><primary>Fully Automatic Installation (FAI)</"" ""primary></indexterm>"" msgid """" ""As with most architecture choices, the right answer depends on your "" ""environment. If you are using existing hardware, you know the disk density "" ""of your servers and can determine some decisions based on the options above. "" ""If you are going through a procurement process, your user's requirements "" ""also help you determine hardware purchases. Here are some examples from a "" ""private cloud providing web developers custom environments at AT&amp;T. This "" ""example is from a specific deployment, so your existing hardware or "" ""procurement opportunity may vary from this. AT&amp;T uses three types of "" ""hardware in its deployment:"" msgstr """" ""多くのアーキテクチャの選択肢と同様に、環境により適切なソリューションは変わっ"" ""て来ます。既存のハードウェアを使用する場合、サーバーのディスク密度を把握し、"" ""上記のオプションをもとに意思決定していきます。調達プロセスを行っている場合、"" ""ユーザー要件などもハードウェア購入決定の一助となります。ここでは AT&amp;T の "" ""Web 開発者にカスタムの環境を提供するプライベートクラウドの例をあげています。"" ""この例は、特定のデプロイメントであるため、既存のハードウェアや調達機会はこれ"" ""と異なる可能性があります。AT&amp;T は、デプロイメントに 3 種類のハードウェア"" ""を使用しています。"" msgid """" ""Hardware for controller nodes, used for all stateless OpenStack API "" ""services. About 32–64 GB memory, small attached disk, one processor, varied "" ""number of cores, such as 6–12."" msgstr """" ""コントローラーノードのハードウェア。ステートレスの OpenStack API サービスすべ"" ""てに使用します。メモリー約 32-64GB、接続された容量の小さいディスク、プロセッ"" ""サー 1 つ、6-12 個程度のコア。"" msgid """" ""Hardware for compute nodes. Typically 256 or 144 GB memory, two processors, "" ""24 cores. 4–6 TB direct attached storage, typically in a RAID 5 "" ""configuration."" msgstr """" ""コンピュートノードのハードウェア。通常、メモリー 256 GB または 144 GB、プロ"" ""セッサー 2 個、コア 24 個、通常 RAID 5 設定のダイレクトアタッチストレージ "" ""(DAS)。"" msgid """" ""Hardware for storage nodes. Typically for these, the disk space is optimized "" ""for the lowest cost per GB of storage while maintaining rack-space "" ""efficiency."" msgstr """" ""ストレージノードのハードウェア。通常、ラックスペース効率を確保しつつも、ディ"" ""スク容量のコストが GB ベースで最も低く最適化されています。"" msgid """" ""Again, the right answer depends on your environment. You have to make your "" ""decision based on the trade-offs between space utilization, simplicity, and "" ""I/O performance."" msgstr """" ""ここでも、環境によって適したソリューションが変わります。スペース使用状況、シ"" ""ンプルさ、I/O パフォーマンスの長所、短所をベースに意思決定していく必要があり"" ""ます。"" msgid ""Network Configuration"" msgstr ""ネットワーク設定"" msgid """" ""Network configuration is a very large topic that spans multiple areas of "" ""this book. For now, make sure that your servers can PXE boot and "" ""successfully communicate with the deployment server.<indexterm class="" ""\""singular\""><primary>networks</primary><secondary>configuration of</"" ""secondary></indexterm>"" msgstr """" ""ネットワーク設定は、本書でも複数の箇所で取り上げられている大きいトピックで"" ""す。ここでは、お使いのサーバが PXEブートでき、デプロイメントサーバと正常に通"" ""信できることを確認しておいてください。.<indexterm class=\""singular"" ""\""><primary>ネットワーク</primary><secondary>設定</secondary></indexterm>""msgid ""Automated Configuration"" msgstr ""自動環境設定""msgid """" ""The purpose of automatic configuration management is to establish and "" ""maintain the consistency of a system without using human intervention. You "" ""want to maintain consistency in your deployments so that you can have the "" ""same cloud every time, repeatably. Proper use of automatic configuration-"" ""management tools ensures that components of the cloud systems are in "" ""particular states, in addition to simplifying deployment, and configuration "" ""change propagation.<indexterm class=\""singular\""><primary>automated "" ""configuration</primary></indexterm><indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>automated "" ""configuration</secondary></indexterm>"" msgstr """" ""自動環境設定管理の目的は、人間の介在なしにシステムの一貫性を確保、維持するこ"" ""とにあります。毎回、同じクラウド環境を繰り返し作るために、デプロイメントにお"" ""ける一貫性を確保します。自動環境設定管理ツールを正しく利用することによって、"" ""デプロイメントと環境設定の変更を伝搬する作業を簡素化するだけでなく、クラウド"" ""システムのコンポーネントが必ず特定の状態にあるようにすることができます。"" ""<indexterm class=\""singular\""><primary>自動設定</primary></"" ""indexterm><indexterm class=\""singular\""><primary>プロビジョニング/デプロイメ"" ""ント</primary><secondary>自動設定</secondary></indexterm>"" msgid """" ""An integral part of a configuration-management system is the items that it "" ""controls. You should carefully consider all of the items that you want, or "" ""do not want, to be automatically managed. For example, you may not want to "" ""automatically format hard drives with user data."" msgstr """" ""設定管理システムの不可欠な部分は、このシステムが制御する項目です。自動管理を"" ""する項目、しない項目をすべて慎重に検討していく必要があります。例えば、ユー"" ""ザーデータが含まれるハードドライブは自動フォーマットは必要ありません。"" msgid ""Remote Management"" msgstr ""リモート管理"" msgid """" ""In our experience, most operators don't sit right next to the servers "" ""running the cloud, and many don't necessarily enjoy visiting the data "" ""center. OpenStack should be entirely remotely configurable, but sometimes "" ""not everything goes according to plan.<indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>remote management</"" ""secondary></indexterm>"" msgstr """" ""経験上、多くのオペレーターはクラウドを動かすサーバのそばにいるわけではありま"" ""せんし、多くの人が必ずしも楽しんでデータセンターに訪問してるわけではありませ"" ""ん。OpenStackは、完全にリモート設定できるはずですが、計画通りにいかないことも"" ""あります。<indexterm class=\""singular\""><primary>プロビジョニング/デプロイメ"" ""ント</primary><secondary>遠隔管理</secondary></indexterm>"" msgid """" ""In this instance, having an out-of-band access into nodes running OpenStack "" ""components is a boon. The IPMI protocol is the de facto standard here, and "" ""acquiring hardware that supports it is highly recommended to achieve that "" ""lights-out data center aim."" msgstr """" ""この場合、OpenStack が動くノードに対して外側からアクセスできるようにすること"" ""が重要です。ここでは、IPMIプロトコルが事実上標準となっています。完全自動の"" ""データセンタを実現するために、IPMIをサポートしたハードウェアを入手することを"" ""強く推奨します。"" msgid """" ""In addition, consider remote power control as well. While IPMI usually "" ""controls the server's power state, having remote access to the PDU that the "" ""server is plugged into can really be useful for situations when everything "" ""seems wedged."" msgstr """" ""さらに、リモート電源管理装置も検討してください。通常、IPMI はサーバーの電源状"" ""態を制御しますが、サーバーが接続されている PDU にリモートアクセスできれば、す"" ""べてが手詰まりに見えるような状況で非常に役に立ちます。"" msgid ""Parting Thoughts for Provisioning and Deploying OpenStack"" msgstr ""OpenStack のプロビジョニングおよびデプロイメントの概念"" msgid """" ""You can save time by understanding the use cases for the cloud you want to "" ""create. Use cases for OpenStack are varied. Some include object storage "" ""only; others require preconfigured compute resources to speed development-"" ""environment set up; and others need fast provisioning of compute resources "" ""that are already secured per tenant with private networks. Your users may "" ""have need for highly redundant servers to make sure their legacy "" ""applications continue to run. Perhaps a goal would be to architect these "" ""legacy applications so that they run on multiple instances in a cloudy, "" ""fault-tolerant way, but not make it a goal to add to those clusters over "" ""time. Your users may indicate that they need scaling considerations because "" ""of heavy Windows server use.<indexterm class=\""singular"" ""\""><primary>provisioning/deployment</primary><secondary>tips for</"" ""secondary></indexterm>"" msgstr """" ""作成するクラウドのユースケースを理解することで時間を節約することあできます。"" ""OpenStack のユースケースはさまざまで、オブジェクトストレージのみのもの、開発"" ""環境設定を加速するために事前設定されたコンピュートリソースが必要なもの、プラ"" ""イベートネットワークでテナントごとにセキュリティが確保されたコンピュートリ"" ""ソースの迅速にプロビジョニングするものもあります。ユーザーは、レガシーアプリ"" ""ケーションが継続して実行されるように、非常に冗長化されたサーバーが必要な場合"" ""もあります。おそらく、時間をかけてこれらのクラスターを追加するのが目的ではな"" ""く、クラウドの耐障害性を確保したかたちで、複数のインスタンス上で実行するため"" ""に、レガシーのアプリケーションを構築するのが目的の場合もあります。ユーザーに"" ""よっては、負荷の高い Windows サーバーを使用するため、スケーリングを考慮する必"" ""要があると指定する場合もあるでしょう。<indexterm class=\""singular\""><primary>"" ""プロビジョニング/デプロイメント</primary><secondary>tips for</secondary></"" ""indexterm>"" msgid """" ""You can save resources by looking at the best fit for the hardware you have "" ""in place already. You might have some high-density storage hardware "" ""available. You could format and repurpose those servers for OpenStack Object "" ""Storage. All of these considerations and input from users help you build "" ""your use case and your deployment plan."" msgstr """" ""すでに設置済みのハードウェアに最適な方法で使用されていることをチェックするこ"" ""とで、リソースを節約することができます。高濃度のストレージハードウェアがある"" ""とします。このハードウェアをフォーマットして、OpenStack Object Storage 用に"" ""サーバーの用途を変更することができます。ユーザーからのこのような検討やイン"" ""プットすべてをベースにすることで、ユースケースやデプロイメントプランの作成が"" ""容易になります。"" msgid """" ""The decisions you make with respect to provisioning and deployment will "" ""affect your day-to-day, week-to-week, and month-to-month maintenance of the "" ""cloud. Your configuration management will be able to evolve over time. "" ""However, more thought and design need to be done for upfront choices about "" ""deployment, disk partitioning, and network configuration."" msgstr """" ""プロビジョニングやデプロイメントでの意思決定は、クラウドの日次、週次、月次の"" ""メンテナンスに影響を与えます。設定管理は時が経つにつれ進化することができま"" ""す。しかし、デプロイメント、ディスクのパーティショニング、ネットワーク設定を"" ""事前に選択するには、さらに検討、設計が必要になります。"" msgid """" ""Designing for Cloud Controllers and <phrase role=\""keep-together\"">Cloud "" ""Management</phrase>"" msgstr """" ""クラウドコントローラーのデザインと<phrase role=\""keep-together\"">クラウド管理"" ""</phrase>"" msgid """" ""OpenStack is designed to be massively horizontally scalable, which allows "" ""all services to be distributed widely. However, to simplify this guide, we "" ""have decided to discuss services of a more central nature, using the concept "" ""of a <emphasis>cloud controller</emphasis>. A cloud controller is just a "" ""conceptual simplification. In the real world, you design an architecture for "" ""your cloud controller that enables high availability so that if any node "" ""fails, another can take over the required tasks. In reality, cloud "" ""controller tasks are spread out across more than a single node.<indexterm "" ""class=\""singular\""><primary>design considerations</primary><secondary>cloud "" ""controller services</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>cloud controllers</primary><secondary>concept of</secondary></"" ""indexterm>"" msgstr """" ""OpenStackはすべてのサービスが広く分散できるよう水平方向に大規模にスケーリング"" ""できるように設計されています。しかし、このガイドではシンプルに<emphasis>クラ"" ""ウドコントローラー</emphasis>の利用についてより中心的な性質を持つサービスにつ"" ""いて議論する事にしました。クラウドコントローラーという言葉はその概念をシンプ"" ""ルに表現した物に過ぎません。実際にはあなたはクラウドコントローラーは冗長構成"" ""としてどのノードが障害となっても他のノードで運用ができるような設計にデザイン"" ""します。実際にはクラウドコントローラーのタスクは1つ以上のノードにまたがって展"" ""開されます。<indexterm class=\""singular\""><primary>設計上の考慮点</"" ""primary><secondary>クラウドコントローラーサービス</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>クラウドコントローラー</"" ""primary><secondary>コンセプト</secondary></indexterm>"" msgid """" ""The cloud controller provides the central management system for OpenStack "" ""deployments. Typically, the cloud controller manages authentication and "" ""sends messaging to all the systems through a message queue."" msgstr """" ""クラウドコントローラは、複数ノードで構成されるOpenStack構成に対する集中管理機"" ""能を提供します。典型的には、クラウドコントローラは認証および、メッセージ"" ""キューを通じたメッセージのやりとりを管理します。""""The cloud controller manages the following services for the cloud:<indexterm "" ""class=\""singular\""><primary>cloud controllers</primary><secondary>services "" ""managed by</secondary></indexterm>"" msgstr """" ""クラウドコントローラーはクラウドの次のサービスを管理します:<indexterm class="" ""\""singular\""><primary>クラウドコントローラー</primary><secondary>管理対象サー"" ""ビス</secondary></indexterm>"" msgid """" ""Tracks current information about users and instances, for example, in a "" ""database, typically one database instance managed per service"" msgstr """" ""ユーザとインスタンスの現在の状態をトラッキングします。例えば、一般的なデータ"" ""ベースでは1つのデータベースインスタンスはサービス毎に管理されます。"" msgid ""Message queue services"" msgstr ""メッセージキューサービス"" msgid """" ""All AMQP—Advanced Message Queue Protocol—messages for services are received "" ""and sent according to the queue broker<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgstr """" ""サービスのためのすべてのAMQP（Advavnced Message Queue Protocol）メッセージは"" ""キューブローカーによって送受信されます。<indexterm class=\""singular"" ""\""><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"" msgid ""Conductor services"" msgstr ""コンダクターサービス"" msgid ""Proxy requests to a database"" msgstr ""データベースリクエストのプロクシ"" msgid ""Authentication and authorization for identity management"" msgstr ""アイデンティティ管理のための認証と認可"" msgid """" ""Indicates which users can do what actions on certain cloud resources; quota "" ""management is spread out among services, however<indexterm class=\""singular"" ""\""><primary>authentication</primary></indexterm>"" msgstr """" ""ある特定のクラウドリソースで誰が何をしようとしているか示します。しかし、ク"" ""オータ管理は全体のサービスに展開されます。<indexterm class=\""singular"" ""\""><primary>認証</primary></indexterm>"" msgid ""Image-management services"" msgstr ""イメージ管理サービス"" msgid """" ""Stores and serves images with metadata on each, for launching in the cloud"" msgstr """" ""クラウド内で起動するための各メタデータが付属したイメージデータを蓄え、提供し"" ""ます"" msgid ""Scheduling services"" msgstr ""スケジュールサービス"" msgid """" ""Indicates which resources to use first; for example, spreading out where "" ""instances are launched based on an algorithm"" msgstr """" ""どのリソースを最初に使用するかを示します。例えば、インスタンスをどこで起動す"" ""るかをアルゴリズムに乗っ取って展開します。"" msgid ""User dashboard"" msgstr ""ユーザーダッシュボード"" msgid """" ""Provides a web-based frontend for users to consume OpenStack cloud services"" msgstr """" ""利用ユーザ用のOpenStackクラウドサービスのウェブインターフェースを提供します。"" msgid ""API endpoints"" msgstr ""APIエンドポイント"" msgid """" ""Offers each service's REST API access, where the API endpoint catalog is "" ""managed by the Identity Service"" msgstr """" ""それぞれのサービス用のAPIアクセスを提供します。APIエンドポイントカタログの場"" ""所はIIdentity サービスが管理しています。"" msgid """"""As another example, you could use pairs of servers for a collective cloud "" ""controller—one active, one standby—for redundant nodes providing a given set "" ""of related services, such as:""""他の例として、コントローラーをクラスタとして構成し1つはアクティブ、もう一つは"" ""スタンバイとして冗長ノードが以下のような機能を提供できるように複数のサーバを"" ""使用する事ができます。""msgid ""Database and message queue server (such as MySQL, RabbitMQ)"" msgstr ""データベースとメッセージキューサーバ（例:MySQL、RabbitMQ）""""Now that you see the myriad designs for controlling your cloud, read more "" ""about the further considerations to help with your design decisions.""""クラウドコントローラの設計は無数にあります、クラウドコントローラの設計の助け"" ""として更なる考慮事項をお読みください。""""A cloud controller's hardware can be the same as a compute node, though you "" ""may want to further specify based on the size and type of cloud that you run."" ""<indexterm class=\""singular\""><primary>hardware</primary><secondary>design "" ""considerations</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>design considerations</primary><secondary>hardware "" ""considerations</secondary></indexterm>""""クラウドの大きさやタイプによってハードウェアを指定したいかもしれませんが、ク"" ""ラウドコントローラーのハードウェアはコンピュートノードと同じ物を利用する事が"" ""できます。<indexterm class=\""singular\""><primary>ハードウェア</"" ""primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class="" ""\""singular\""><primary>設計上の考慮事項</primary><secondary>ハードウェアの考慮"" ""点</secondary></indexterm>""""<xref linkend=\""controller-hardware-sizing\""/> contains common "" ""considerations to review when sizing hardware for the cloud controller "" ""design.<indexterm class=\""singular\""><primary>cloud controllers</"" ""primary><secondary>hardware sizing considerations</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Active Directory</primary></"" ""indexterm><indexterm class=\""singular\""><primary>dashboard</primary></"" ""indexterm>""""<xref linkend=\""controller-hardware-sizing\""/> クラウドコントローラー設計の"" ""ハードウェアサイジングにおける一般的な考慮事項<indexterm class=\""singular"" ""\""><primary>クラウドコントローラー</primary><secondary>ハードウェアサイジング"" ""に関する考慮事項</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>Active Directory</primary></indexterm><indexterm class=\""singular"" ""\""><primary>ダッシュボード</primary></indexterm>""msgid ""Cloud controller hardware sizing considerations"" msgstr ""クラウドコントローラーのハードウェアサイジングに関する考慮事項""msgid ""Consideration"" msgstr ""考慮事項""msgid ""Ramification"" msgstr ""派生問題""msgid ""How many instances will run at once?"" msgstr ""同時に何インスタンス実行されますか？""""Size your database server accordingly, and scale out beyond one cloud "" ""controller if many instances will report status at the same time and "" ""scheduling where a new instance starts up needs computing power.""""データベースサーバーを負荷に応じてサイジングしてください。もし、多数のインス"" ""タンスが同時に状態を報告したり、CPU能力が必要な新規インスタンス起動のスケ"" ""ジューリングを行う場合は、１台のクラウドコントローラーを超えてスケールアウト"" ""してください。"" msgid ""How many compute nodes will run at once?"" msgstr ""同時にコンピュートノードが何ノード実行されますか？"" msgid """" ""Ensure that your messaging queue handles requests successfully and size "" ""accordingly."" msgstr """" ""メッセージキューが正しくリクエストを処理することを保証し、適切にサイジングし"" ""てください。"" msgid ""How many users will access the API?"" msgstr ""どのくらいの数のユーザがAPIにアクセスしますか？"" msgid """" ""If many users will make multiple requests, make sure that the CPU load for "" ""the cloud controller can handle it."" msgstr """" ""もし多数のユーザが複数のリクエストを発行するのであれば、クラウドコントロー"" ""ラーがそれらを扱えるよう、CPU負荷を確認してください。"" msgid """" ""How many users will access the <glossterm>dashboard</glossterm> versus the "" ""REST API directly?"" msgstr """" ""REST APIに直接アクセスに対してどのくらい多くのユーザが <glossterm>ダッシュ"" ""ボード</glossterm>にアクセスしますか？"" msgid """" ""The dashboard makes many requests, even more than the API access, so add "" ""even more CPU if your dashboard is the main interface for your users."" msgstr """" ""ダッシュボードは、APIアクセスよりもさらに多くのリクエストを発行します。そのた"" ""め、もしユーザに対するインタフェースがダッシュボードなのであれば、より多くの"" ""CPUを追加してください。"" msgid """" ""How many <code>nova-api</code> services do you run at once for your cloud?"" msgstr """" ""あなたのクラウドで、何個の<code>nova-api</code>サービスを同時に実行しますか？"" msgid ""You need to size the controller with a core per service."" msgstr """" ""サービスごとに１コア割り当ててコントローラーをサイジングする必要があります。"" msgid ""How long does a single instance run?"" msgstr ""１つのインスタンスがどのくらい実行され続けますか？"" msgid """" ""Starting instances and deleting instances is demanding on the compute node "" ""but also demanding on the controller node because of all the API queries and "" ""scheduling needs."" msgstr """" ""インスタンスの起動と停止は コンピュートノードに負荷をかけますが、それだけで"" ""なく、すべてのAPI処理とスケジューリングの必要性のために、コントローラーノード"" ""にも負荷をかけます。"" msgid ""Does your authentication system also verify externally?"" msgstr ""認証システムは外部に確認を行いますか？"" msgid """" ""External systems such as LDAP or <glossterm>Active Directory</glossterm> "" ""require network connectivity between the cloud controller and an external "" ""authentication system. Also ensure that the cloud controller has the CPU "" ""power to keep up with requests."" msgstr """" ""LDAPや<glossterm>Active Directory</glossterm>のような外部認証システムを利用す"" ""る場合クラウドコントローラと外部認証システムとの間のネットワーク接続性が良好"" ""である必要があります。また、クラウドコントローラがそれらのリクエストを処理す"" ""るための十分のCPUパワーが必要です。"" msgid ""Separation of Services"" msgstr ""サービスの分離"" msgid """" ""While our example contains all central services in a single location, it is "" ""possible and indeed often a good idea to separate services onto different "" ""physical servers. <xref linkend=\""sep-services-table\""/> is a list of "" ""deployment scenarios we've seen and their justifications.<indexterm class="" ""\""singular\""><primary>provisioning/deployment</primary><secondary>deployment "" ""scenarios</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>services</primary><secondary>separation of</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>separation of services</"" ""primary></indexterm><indexterm class=\""singular\""><primary>design "" ""considerations</primary><secondary>separation of services</secondary></"" ""indexterm>"" msgstr """" ""この例ではすべての中心的なサービスが1つの場所にありますが、サービスを分割して"" ""それぞれ別の物理サーバに配置する事は可能であり、本当に良いアイデアです。"" ""<xref linkend=\""sep-services-table\""/> は構築のシナリオと設計の理由です。"" ""<indexterm class=\""singular\""><primary>プロビジョニング/構築</"" ""primary><secondary>構築シナリオ</secondary></indexterm><indexterm class="" ""\""singular\""><primary>サービス</primary><secondary>分離</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>サービスの分離</primary></"" ""indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>サービスの分離</secondary></indexterm>"" msgid ""Deployment scenarios"" msgstr ""構成シナリオ"" msgid ""Scenario"" msgstr ""シナリオ""msgid """" ""Run <code>glance-*</code> servers on the <code>swift-proxy</code> server."" msgstr ""<code>swift-proxy</code> サーバで<code>glance-*</code>サーバを稼働する""""This deployment felt that the spare I/O on the Object Storage proxy server "" ""was sufficient and that the Image Delivery portion of glance benefited from "" ""being on physical hardware and having good connectivity to the Object "" ""Storage backend it was using.""""この構成ではオブジェクトストレージプロクシサーバのI/Oの空きが十分にあり、"" ""glance のイメージ配信部分は物理ハードウェアとオブジェクトストレージのバック"" ""エンドに使用している良好なネットワーク接続性の恩恵を十分に受ける事ができると"" ""感じた。""msgid ""Run a central dedicated database server."" msgstr ""中央データベースサーバを構成する""""This deployment used a central dedicated server to provide the databases for "" ""all services. This approach simplified operations by isolating database "" ""server updates and allowed for the simple creation of slave database servers "" ""for failover.""""この構成では、すべてのサービスに対するデータベースサービスを提供する専用サー"" ""バを設置しました。これにより、データベースサーバーのアップデートを分離でき、"" ""運用がシンプルになりました。また、フェイルオーバーのためのスレーブデータベー"" ""スサーバーの設置が単純になりました。""msgid ""Run one VM per service."" msgstr ""1サービスにつき1つのVMを稼働させる""""This deployment ran central services on a set of servers running KVM. A "" ""dedicated VM was created for each service (<literal>nova-scheduler</"" ""literal>, rabbitmq, database, etc). This assisted the deployment with "" ""scaling because administrators could tune the resources given to each "" ""virtual machine based on the load it received (something that was not well "" ""understood during installation).""""この構成では中央サーバをKVM上のサーバで実行しました。専用のVMをそれぞれのサー"" ""ビスで用意しました(<literal>nova-scheduler</literal>, RabbitMQ, データベース"" ""など)。この構成はクラウド管理者が(インストール時によく推測できないので)それぞ"" ""れのサービスへの負荷のかかり具合によって各バーチャルマシンへのリソース割当を"" ""変更する事ができる構成でした。""msgid ""Use an external load balancer."" msgstr ""外部ロードバランサーの使用""""This deployment had an expensive hardware load balancer in its organization. "" ""It ran multiple <code>nova-api</code> and <code>swift-proxy</code> servers "" ""on different physical servers and used the load balancer to switch between "" ""them.""""この構成は、組織内に高価なハードウェアロードバランサーを持っていました。彼ら"" ""は複数の <code>nova-api</code> と<code>swift-proxy</code> サーバーを異なる物"" ""理サーバーで動作させ、その振り分けにロードバランサーを利用し増した。""""One choice that always comes up is whether to virtualize. Some services, "" ""such as <code>nova-compute</code>, <code>swift-proxy</code> and <code>swift-"" ""object</code> servers, should not be virtualized. However, control servers "" ""can often be happily virtualized—the performance penalty can usually be "" ""offset by simply running more of the service.""""仮想化するかどうかについてはいつも問題になります。 <code>nova-compute</"" ""code>、<code>swift-proxy</code> 、 <code>swift-object</code> といったいくつか"" ""のサーバーは仮想化にすべきではありません。しかし、制御系のサーバについては仮"" ""想化にすると幸せになります。それによる性能のペナルティは単純により多くのサー"" ""ビスを動かす事で相殺する事ができます。""""OpenStack Compute uses a SQL database to store and retrieve stateful "" ""information. MySQL is the popular database choice in the OpenStack community."" ""<indexterm class=\""singular\""><primary>databases</primary><secondary>design "" ""considerations</secondary></indexterm><indexterm class=\""singular"" ""\""><primary>design considerations</primary><secondary>database choice</"" ""secondary></indexterm>""""OpenStackコンピュートはステートフルな情報を保存、取得するためにSQLデータベー"" ""スを使用します。MySQLはOpenStackコミュニティでポピュラーな選択です。"" ""<indexterm class=\""singular\""><primary>データベース</primary><secondary>設計"" ""上の考慮事項</secondary></indexterm><indexterm class=\""singular\""><primary>設"" ""計上の考慮事項</primary><secondary>データベースの選択</secondary></indexterm>""msgid ""Conductor Services"" msgstr ""コンダクターサービス""""In the previous version of OpenStack, all <literal>nova-compute</literal> "" ""services required direct access to the database hosted on the cloud "" ""controller. This was problematic for two reasons: security and performance. "" ""With regard to security, if a compute node is compromised, the attacker "" ""inherently has access to the database. With regard to performance, "" ""<literal>nova-compute</literal> calls to the database are single-threaded "" ""and blocking. This creates a performance bottleneck because database "" ""requests are fulfilled serially rather than in parallel.<indexterm class="" ""\""singular\""><primary>conductors</primary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>conductor "" ""services</secondary></indexterm>""""以前のバージョンのOpenStackではすべての<literal>nova-compute</literal>サービ"" ""スはクラウドコントローラーに搭載されたデータベースに直接アクセスする必要があ"" ""りました。これはセキュリティとパフォーマンスという2つの問題を抱えていました。"" ""セキュリティに関してはもしコンピュートノードに侵入された場合、アタッカーは"" ""データベースにアクセスできてしまいます。パフォーマンスに関しては、"" ""<literal>nova-compute</literal>はデータベースの呼び出しをシングルスレッドで行"" ""い、他の呼び出しをブロックする点です。データベースリクエストはシリアルリクエ"" ""ストよりパラレルリクエストの方が効率がいいのでこの点はパフォーマンスのボトル"" ""ネックになります。<indexterm class=\""singular\""><primary>コンダクター</"" ""primary></indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>コンダクターサービス</secondary></indexterm>""""If you are using <literal>nova-network</literal> and multi-host networking "" ""in your cloud environment, <literal>nova-compute</literal> still requires "" ""direct access to the database.<indexterm class=\""singular\""><primary>multi-"" ""host networking</primary></indexterm>""""あなたのクラウド環境で、<literal>nova-network</literal>とマルチホストネット"" ""ワークを使用している場合、 <literal>nova-compute</literal>は現在もデータベー"" ""スへの直接アクセスを必要とします。<indexterm class=\""singular\""><primary>マル"" ""チホストネットワーク</primary></indexterm>""""The <literal>nova-conductor</literal> service is horizontally scalable. To "" ""make <literal>nova-conductor</literal> highly available and fault tolerant, "" ""just launch more instances of the <code>nova-conductor</code> process, "" ""either on the same server or across multiple servers.""""<literal>nova-conductor</literal>サービスは水平方向にスケーラブルです。"" ""<literal>nova-conductor</literal>を冗長構成になるためには、<code>nova-"" ""conductor</code> プロセスを同一サーバまたは複数のサーバに渡って複数起動するだ"" ""けです。"" msgid ""Application Programming Interface (API)"" msgstr ""Application Programming Interface (API)""""All public access, whether direct, through a command-line client, or through "" ""the web-based dashboard, uses the API service. Find the API reference at "" ""<link href=\""http://api.openstack.org/\""/>.<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</"" ""primary><secondary>design considerations</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>design considerations</primary><secondary>API "" ""support</secondary></indexterm>""""すべてのパブリックアクセス（直接アクセス、コマンドライン、ウェブベースダッ"" ""シュボード）はすべてAPIサービスを使用します。APIリファレンスは<link href="" ""\""http://api.openstack.org/\""/>です。<indexterm class=\""singular"" ""\""><primary>API (application programming interface)</primary><secondary>設計"" ""上の考慮事項</secondary></indexterm><indexterm class=\""singular\""><primary>設"" ""計上の考慮事項</primary><secondary>API サポート</secondary></indexterm>""""You must choose whether you want to support the Amazon EC2 compatibility "" ""APIs, or just the OpenStack APIs. One issue you might encounter when running "" ""both APIs is an inconsistent experience when referring to images and "" ""instances.""""Amazon EC2 互換 API をサポートしたいか、OpenStack API だけなのか、選択しなけ"" ""ればなりません。両方の API を運用する場合、イメージとインスタンスを参照する際"" ""の見え方が違うことが一つの論点になります。""""For example, the EC2 API refers to instances using IDs that contain "" ""hexadecimal, whereas the OpenStack API uses names and digits. Similarly, the "" ""EC2 API tends to rely on DNS aliases for contacting virtual machines, as "" ""opposed to OpenStack, which typically lists IP addresses.<indexterm class="" ""\""singular\""><primary>DNS (Domain Name Server, Service or System)</"" ""primary><secondary>DNS aliases</secondary></indexterm><indexterm class="" ""\""singular\""><primary>troubleshooting</primary><secondary>DNS issues</""msgstr """" ""例えば、EC2 API では、16 進数を含む ID を使ってインスタンスを参照するのに対し"" ""て、OpenStack API では名前と数値を使います。同様に、EC2 API は仮想マシンに接"" ""続するのに DNS エイリアスに頼る傾向がありますが、OpenStack では典型的には IP "" ""アドレスを使います。<indexterm class=\""singular\""><primary>DNS (Domain Name "" ""Server, Service or System)</primary><secondary>DNS エイリアス</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>トラブルシューティング</"" ""primary><secondary>DNS 問題</secondary></indexterm>""""If OpenStack is not set up in the right way, it is simple to have scenarios "" ""in which users are unable to contact their instances due to having only an "" ""incorrect DNS alias. Despite this, EC2 compatibility can assist users "" ""migrating to your cloud.""""もしOpenStakcが正しく構成されていない場合、正しくないDNSエイリアスしな無いた"" ""め、ユーザはインスタンスへアクセスできないというシンプルな事態が生じます。そ"" ""れにもかかわらず、EC2互換はユーザをあなたのクラウドへ移行することをアシストし"" ""ます。""""As with databases and message queues, having more than one <glossterm>API "" ""server</glossterm> is a good thing. Traditional HTTP load-balancing "" ""techniques can be used to achieve a highly available <code>nova-api</code> "" ""service.<indexterm class=\""singular\""><primary>API (application programming "" ""interface)</primary><secondary>API server</secondary></indexterm>""""データベースやメッセージキューのように、１台以上の<glossterm>API サーバー</"" ""glossterm> を設置する事は良い案です。<code>nova-api</code> サービスを高可用"" ""にするために、伝統的な HTTP 負荷分散技術を利用することができます。"" msgid ""Extensions"" msgstr ""API 拡張""""The OpenStack Compute API is extensible. An extension adds capabilities to "" ""an API beyond those defined in the core. The introduction of new features, "" ""MIME types, actions, states, headers, parameters, and resources can all be "" ""accomplished by means of extensions to the core API. This allows the "" ""introduction of new features in the API without requiring a version change "" ""and allows the introduction of vendor-specific niche functionality.""""OpenStack Compute API は拡張可能です。ある拡張は、ある API にコア定義を超えた"" ""ケイパビリティを追加します。新機能、新しい MIME タイプ、アクション、状態、"" ""ヘッダ、パラメータ、そしてリソースの導入は、コア API の拡張によって達成するこ"" ""とができます。これにより、API に対してバージョンを変更することなく新機能を導"" ""入することができ、ベンダー固有の特定の機能を導入することもできます。""msgid ""Scheduling"" msgstr ""スケジューリング""msgid """" ""The <code>glance-api</code> part is an abstraction layer that allows a "" ""choice of backend. Currently, it supports:"" msgstr """" ""<code>glance-api</code>部はバックエンドを選択する事ができる抽象的なレイヤーで"" ""す。現在、以下をサポートしています：""msgid ""OpenStack Object Storage"" msgstr ""OpenStack オブジェクトストレージ"" msgid ""Allows you to store images as objects."" msgstr ""イメージをオブジェクトとして格納する事を許可します"" msgid ""File system"" msgstr ""ファイルシステム"" msgid ""Uses any traditional file system to store the images as files."" msgstr """" ""イメージをファイルとして格納するために一般的なファイルシステムを使用します。"" msgid ""S3"" msgstr ""S3"" msgid ""Allows you to fetch images from Amazon S3."" msgstr ""Amazon S3からイメージを取得する事を許可します。"" msgid ""HTTP"" msgstr ""HTTP""""Allows you to fetch images from a web server. You cannot write images by "" ""using this mode.""""イメージをウェブサーバから取得する事を許可します。このモードではイメージの書"" ""き込みはできません。""""If you have an OpenStack Object Storage service, we recommend using this as "" ""a scalable place to store your images. You can also use a file system with "" ""sufficient performance or Amazon S3—unless you do not need the ability to "" ""upload new images through OpenStack.""""OpenStack Storageサービスがある場合は、イメージを保存するためにスケーラブルな"" ""場所を利用する事を推奨します。また、OpenStackをとおして新しいイメージをアップ"" ""ロードする必要がない場合を除いて、十分な性能を備えたファイルシステムかAmazon "" ""S3を使用する事もできます。""""The OpenStack dashboard (horizon) provides a web-based user interface to the "" ""various OpenStack components. The dashboard includes an end-user area for "" ""users to manage their virtual infrastructure and an admin area for cloud "" ""operators to manage the OpenStack environment as a whole.<indexterm class="" ""\""singular\""><primary>dashboard</primary></indexterm><indexterm class="" ""\""singular\""><primary>design considerations</primary><secondary>dashboard</"" ""secondary></indexterm>""""OpenStackダッシュボード(horizon)は様々なOpenStackコンポーネントのウェブベース"" ""ユーザーインターフェースを提供します。ダッシュボードにはエンドユーザの仮想イ"" ""ンフラを管理するための領域と、OpenStack環境全体を管理するためのクラウド管理者"" ""のための管理者領域が含まれます。<indexterm class=\""singular\""><primary>ダッ"" ""シュボード</primary></indexterm><indexterm class=\""singular\""><primary>設計上"" ""の考慮事項</primary><secondary>ダッシュボード</secondary></indexterm>""""The dashboard is implemented as a Python web application that normally runs "" ""in <glossterm>Apache</glossterm><code>httpd</code>. Therefore, you may treat "" ""it the same as any other web application, provided it can reach the API "" ""servers (including their admin endpoints) over the <phrase role=\""keep-"" ""together\"">network</phrase>.<indexterm class=\""singular\""><primary>Apache</""""ダッシュボードはPythonのウェブアプリケーションとして実装され、通常は"" ""<glossterm>Apache</glossterm><code>httpd</code>サーバ上で稼働します。したがっ"" ""て、そこから <phrase role=\""keep-together\"">ネットワーク</phrase>経由で (管理"" ""者 エンドポイントを含む) API サーバーにアクセスできるという条件の下、他の任意"" ""の Web アプリケーションと同じように取り扱うことができます。<indexterm class="" ""\""singular\""><primary>Apache</primary></indexterm>"" msgid ""Authentication and Authorization"" msgstr ""認証と認可""""The concepts supporting OpenStack's authentication and authorization are "" ""derived from well-understood and widely used systems of a similar nature. "" ""Users have credentials they can use to authenticate, and they can be a "" ""member of one or more groups (known as projects or tenants, interchangeably)."" ""<indexterm class=\""singular\""><primary>credentials</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authorization</primary></"" ""indexterm><indexterm class=\""singular\""><primary>authentication</primary></"" ""indexterm><indexterm class=\""singular\""><primary>design considerations</"" ""primary><secondary>authentication/authorization</secondary></indexterm>""""OpenStackの認証と承認は良く知られ、幅広いシステムで良く利用されている物から来"" ""ています。ユーザは認証のためにクレデンシャルを持ち、1つ以上のグループ(プロ"" ""ジェクトまたはテナントと呼ばれます)のメンバーとなる事ができます。<indexterm "" ""class=\""singular\""><primary>クレデンシャル</primary></indexterm><indexterm "" ""class=\""singular\""><primary>認証</primary></indexterm><indexterm class="" ""\""singular\""><primary>承認</primary></indexterm><indexterm class=\""singular"" ""\""><primary>設計上の考慮事項</primary><secondary>認証/承認</secondary></""msgid """" ""For example, a cloud administrator might be able to list all instances in "" ""the cloud, whereas a user can see only those in his current group. Resources "" ""quotas, such as the number of cores that can be used, disk space, and so on, "" ""are associated with a project."" msgstr """" ""例えば、クラウドのユーザは自分の現在のグループに属するインスタンスのみが見え"" ""るのに対して、クラウドの管理者はそのクラウドのすべてのインスタンスの一覧をと"" ""ることができるでしょう。利用可能なコア数、ディスク容量等のリソースのクォータ"" ""はプロジェクトに対して関連づけられています。""""The OpenStack Identity Service (keystone) is the point that provides the "" ""authentication decisions and user attribute information, which is then used "" ""by the other OpenStack services to perform authorization. Policy is set in "" ""the <filename>policy.json</filename> file. For <phrase role=\""keep-together"" ""\"">information</phrase> on how to configure these, see <xref linkend="" ""\""projects_users\""/>.<indexterm class=\""singular\""><primary>Identity "" ""Service</primary><secondary>authentication decisions</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Identity Service</"" ""primary><secondary>plug-in support</secondary></indexterm>""""OpenStack Identity Service (Keystone) は、認証の判定とユーザの属性情報を提供"" ""する場となり、他の OpenStack サービスから認証のために使用されます。ポリシー"" ""は <filename>policy.json</filename> で記述されます。これらを設定するための"" ""<phrase role=\""keep-together\"">情報</phrase>については、<xref linkend="" ""\""projects_users\""/> を参照してください。<indexterm class=\""singular"" ""\""><primary>Identity サービス</primary><secondary>認証の判定</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>Identity サービス</"" ""primary><secondary>プラグインサポート</secondary></indexterm>"" msgid """" ""The Identity Service supports different plug-ins for authentication "" ""decisions and identity storage. Examples of these plug-ins include:"" msgstr """" ""Identity サービスは、バックエンド認証と情報保持のために種々のプラグインをサ"" ""ポートしています。これらの選択肢は、現在は以下の物が含まれています。"" msgid ""In-memory key-value Store (a simplified internal storage structure)"" msgstr ""メモリ内のキーバリュー型ストア（シンプルな内部ストレージ構造）"" msgid ""SQL database (such as MySQL or PostgreSQL)"" msgstr ""SQL データベース (MySQL や PostgreSQL など)"" msgid ""PAM (Pluggable Authentication Module)"" msgstr ""PAM (Pluggable Authentication Module)"" msgid ""LDAP (such as OpenLDAP or Microsoft's Active Directory)"" msgstr ""LDAP (OpenLDAP や Microsoft の Active Directory)"" msgid """" ""Many deployments use the SQL database; however, LDAP is also a popular "" ""choice for those with existing authentication infrastructure that needs to "" ""be integrated."" msgstr """" ""多くのデプロイメントで SQL データベースが使われていますが、既存の認証インフラ"" ""とインテグレーションする必要のある環境では、LDAP もポピュラーな選択肢です。"" msgid ""Network Considerations"" msgstr ""ネットワークの考慮事項"" msgid """" ""Because the cloud controller handles so many different services, it must be "" ""able to handle the amount of traffic that hits it. For example, if you "" ""choose to host the OpenStack Imaging Service on the cloud controller, the "" ""cloud controller should be able to support the transferring of the images at "" ""an acceptable speed.<indexterm class=\""singular\""><primary>cloud "" ""controllers</primary><secondary>network traffic and</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>networks</"" ""primary><secondary>design considerations</secondary></indexterm><indexterm "" ""class=\""singular\""><primary>design considerations</"" ""primary><secondary>networks</secondary></indexterm>"" msgstr """" ""クラウドコントローラーは非常に多くのサービスを取り扱うため、それらすべてのト"" ""ラフィックを処理できなければなりません。例えば、クラウドコントローラー上に "" ""OpenStack イメージ サービスを乗せることにした場合、そのクラウドコントローラー"" ""は許容可能な速度でイメージの転送できなければなりません。<indexterm class="" ""\""singular\""><primary>クラウドコントローラー</primary><secondary>ネットワーク"" ""トラフィック</secondary></indexterm><indexterm class=\""singular\""><primary>"" ""ネットワーク</primary><secondary>設計上の考慮事項</secondary></"" ""indexterm><indexterm class=\""singular\""><primary>設計上の考慮事項</"" ""primary><secondary>ネットワーク</secondary></indexterm>"" msgid """" ""As another example, if you choose to use single-host networking where the "" ""cloud controller is the network gateway for all instances, then the cloud "" ""controller must support the total amount of traffic that travels between "" ""your cloud and the public Internet."" msgstr """" ""他の例としては、クラウドコントローラーがすべてのインスタンスのゲートウェイと"" ""なるような単一ホスト・ネットワークモデルを使うことにした場合、クラウドコント"" ""ローラーは外部インターネットとあなたのクラウドの間でやりとりされるすべてのト"" ""ラフィックを支えられなければなりません。"" msgid ""Logging and Monitoring"" msgstr ""ロギングと監視"" msgid ""Where Are the Logs?"" msgstr ""ログはどこにあるのか？"" msgid ""Service"" msgstr ""サービス"" msgid ""nova-*"" msgstr ""nova-*"" msgid ""/var/log/nova"" msgstr ""/var/log/nova"" msgid ""glance-*"" msgstr ""glance-*"" msgid ""/var/log/glance"" msgstr ""/var/log/glance"" msgid ""cinder-*"" msgstr ""cinder-*"" msgid ""/var/log/cinder"" msgstr ""/var/log/cinder"" msgid ""/var/log/keystone"" msgstr ""/var/log/keystone"" msgid ""/var/log/apache2/"" msgstr ""/var/log/apache2/"" msgid ""/var/log/syslog"" msgstr ""/var/log/syslog"" msgid ""libvirt"" msgstr ""libvirt"" msgid ""Tracing Instance Requests"" msgstr ""インスタンスリクエストの追跡"" msgid """" ""The typical way is to trace the UUID associated with an instance across the "" ""service logs."" msgstr """" ""一般的な方法はインスタンスのUUIDをキーにして、各サービスのログを追跡すること"" ""です。"" msgid ""Consider the following example:"" msgstr ""次のような例を考えてみましょう。"" msgid ""Adding Custom Logging Statements"" msgstr ""カスタムログの追加""msgid ""To add a DEBUG logging statement, you would do:"" msgstr ""DEBUGログステートメントを追加するには次のようにします。""msgid ""RabbitMQ Web Management Interface or rabbitmqctl"" msgstr ""RabbitMQ Web管理インターフェイス および rabbitmqctl""""Items to monitor for RabbitMQ include the number of items in each of the "" ""queues and the processing time statistics for the server.""""RabbitMQで監視すべき項目としては、各キューでのアイテムの数と、サーバーでの処"" ""理時間の統計情報があります。""msgid ""Centrally Managing Logs"" msgstr ""ログの集中管理""msgid ""rsyslog Client Configuration"" msgstr ""rsyslog クライアント設定""msgid ""rsyslog Server Configuration"" msgstr ""rsyslog サーバー設定""msgid ""/var/log/rsyslog/c01.example.com/nova.log"" msgstr ""/var/log/rsyslog/c01.example.com/nova.log""msgid ""/var/log/rsyslog/nova.log"" msgstr ""/var/log/rsyslog/nova.log""msgid ""/var/log/rsyslog/c02.example.com/nova.log"" msgstr ""/var/log/rsyslog/c02.example.com/nova.log""msgid ""Monitoring"" msgstr ""監視""msgid ""Process Monitoring"" msgstr ""プロセス監視""""Then on the actual compute node, create the following NRPE configuration:""""そして、対象のコンピュートノードにおいて、次のようなNRPE設定を作成します。"" msgid ""Resource Alerting"" msgstr ""リソースのアラート"" msgid ""Some of the resources that you want to monitor include:"" msgstr ""監視項目に含む幾つかのリソースをあげます。"" msgid ""Available vCPUs"" msgstr ""利用可能な vCPU 数"" msgid """" ""For example, to monitor disk capacity on a compute node with Nagios, add the "" ""following to your Nagios configuration:"" msgstr """" ""例として、コンピュートノード上のディスク容量をNagiosを使って監視する場合、次"" ""のようなNagios設定を追加します。"" msgid ""On the compute node, add the following to your NRPE configuration:"" msgstr ""コンピュートノード上では、次のようなNRPE設定を追加します。"" msgid ""StackTach"" msgstr ""StackTach"" msgid ""OpenStack Telemetry"" msgstr ""OpenStack Telemetry"" msgid """" ""Next, the <code>nova</code> database contains three tables that store usage "" ""information."" msgstr """" ""次に <code>nova</code> データベースは 利用情報に関して3つのテーブルを持ってい""""The <code>nova.quota_usages</code> table keeps track of how many resources "" ""the tenant currently has in use:""""<code>nova.quota_usages</code>テーブルはどのくらいリソースをテナントが利用し"" ""ているかを記録しています。""""This script is specific to a certain OpenStack installation and must be "" ""modified to fit your environment. However, the logic should easily be "" ""transferable.""""このスクリプトは特定のOpenStackインストール環境向けなので、自身の環境に適用す"" ""る際には変更しなくてはいけませんが、ロジックは簡単に変更できるでしょう。""msgid ""Intelligent Alerting"" msgstr ""インテリジェントなアラート""msgid ""Some other examples for Intelligent Alerting include:"" msgstr ""インテリジェントなアラートのその他の例としては以下があります。"" msgid ""Can users be created?"" msgstr ""ユーザの作成は可能か?"" msgid ""Can objects be stored and deleted?"" msgstr ""オブジェクトの保存と削除は可能か?"" msgid ""Can volumes be created and destroyed?"" msgstr ""ボリュームの作成と削除は可能か?"" msgid ""Trending"" msgstr ""トレンド"" msgid ""The number of instances on each compute node"" msgstr ""各コンピュートノード上のインスタンス数"" msgid ""The types of flavors in use"" msgstr ""使用中のフレーバー"" msgid ""The number of volumes in use"" msgstr ""使用中のボリューム数"" msgid ""The number of Object Storage requests each hour"" msgstr ""1時間あたりの Object Storage リクエスト数"" msgid ""The I/O statistics of your storage services"" msgstr ""ストレージサービスの I/O の統計"" ""You can obtain further statistics by looking for the number of successful "" ""requests:"" msgstr ""成功したリクエストを検索することで、更なる情報を取得できます。"" msgid """" ""By running this command periodically and keeping a record of the result, you "" ""can create a trending report over time that shows whether your <code>nova-"" ""api</code> usage is increasing, decreasing, or keeping steady.""""このコマンドを定期的に実行し結果を記録することで、トレンドレポートを作ること"" ""ができます。これにより<code>/var/log/nova/nova-api.log</code>の使用量が増えて"" ""いるのか、減っているのか、安定しているのか、を知ることができます。""",8621,8675
openstack%2Fha-guide~master~Ie15352908e8a8a13f55aef2146eaf4b0e1a0584f,openstack/ha-guide,master,Ie15352908e8a8a13f55aef2146eaf4b0e1a0584f,Imported Translations from Transifex,MERGED,2015-05-28 06:00:47.000000000,2015-05-28 06:58:01.000000000,2015-05-28 06:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-28 06:00:47.000000000', 'files': ['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/high-availability-guide/locale/zh_CN.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/68f55ad39a8231ea6a71d2b81c17ea968dad2e0d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie15352908e8a8a13f55aef2146eaf4b0e1a0584f\n'}]",0,186263,68f55ad39a8231ea6a71d2b81c17ea968dad2e0d,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ie15352908e8a8a13f55aef2146eaf4b0e1a0584f
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/63/186263/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/high-availability-guide/locale/zh_CN.po']",3,68f55ad39a8231ea6a71d2b81c17ea968dad2e0d,transifex/translations,"""POT-Creation-Date: 2015-05-27 09:53+0000\n"" ""PO-Revision-Date: 2015-05-15 06:29+0000\n""msgid ""2"" msgstr ""2"" msgid ""2012"" msgstr ""2012"" msgid ""2012-01-16"" msgstr ""2012-01-16"" msgid ""2012-05-24"" msgstr ""2012-05-24"" msgid ""2013"" msgstr ""2013"" msgid ""2014"" msgstr ""2014"" msgid ""2014-04-17"" msgstr ""2014-04-17"" msgid ""2014-05-16"" msgstr ""2014-05-16"" msgid ""2014-10-17"" msgstr ""2014-10-17"" msgid ""<application>Memcached</application> service"" msgstr ""<application>Memcached</application> 服务""""<link href=\""http://galeracluster.com/\"">MySQL/Galera</link> is an "" ""alternative method of configuring MySQL for high availability. It is likely "" ""to become the preferred method of achieving MySQL high availability once it "" ""has sufficiently matured. At the time of writing, however, the Pacemaker/"" ""DRBD based approach remains the recommended one for OpenStack environments.""""<link href=\""http://galeracluster.com/\"">MySQL/Galera</link> 是实现 MySQL 数"" ""据库高可用的另一种可选方案，一旦该方案足够成熟，可能会是更好的选择。不过在本"" ""文写作时，基于 Pacemaker/DRBD 的方案仍然是 OpenStack 环境的推荐方式。""""<link href=\""http://www.rabbitmq.com/ha.html\"">Active-active mirrored "" ""queues</link> is another method for configuring RabbitMQ versions 3.3.0 and "" ""later for high availability. You can also manage a RabbitMQ cluster with "" ""active-active mirrored queues using the Pacemaker cluster manager.""""<link href=\""http://www.rabbitmq.com/ha.html\"">主/主镜像队列</link> 是实现 "" ""RabbitMQ 高可用的另一种可选方案（适用于 RabbitMQ 3.3.0 及之后的版本），同样，"" ""也可以通过 Pacemaker 来管理使用“主/主镜像队列”架构的 RabbitMQ 集群。""""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live Pacemaker configuration, and then make "" ""changes as required.""""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。""""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live Pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_glance-"" ""api</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address.""""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_glance-api</literal>，编辑资源以匹配可"" ""供使用的虚拟IP地址。""""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required.""""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。""""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_cinder-"" ""api</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address.""""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_cinder-api</literal>，编辑资源以匹配可"" ""供使用的虚拟IP地址。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_keystone</"" ""literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_keystone</literal>，编辑资源以匹配可供"" ""使用的虚拟IP地址。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_neutron-"" ""server</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_keystone</literal>，编辑资源以匹配可供"" ""使用的虚拟IP地址"" msgid """" ""<literal>ms_drbd_mysql</literal>, the master/slave set managing the "" ""<literal>mysql</literal> DRBD resource,"" msgstr ""<literal>ms_drbd_mysql</literal>，管理 DRBD 设备的主/从资源，"" msgid """" ""<literal>ms_drbd_rabbitmq</literal>, the master/slave set managing the "" ""<literal>rabbitmq</literal> DRBD resource,"" msgstr ""<literal>ms_drbd_rabbitmq</literal>，管理 DRBD 设备的主/从资源，"" msgid """" ""<literal>mysql</literal> DRBD resource configuration (<filename>/etc/drbd.d/"" ""mysql.res</filename>)"" msgstr """" ""<literal>mysql</literal> DRBD 资源配置文件（ <filename>/etc/drbd.d/mysql."" ""res</filename> ）"" msgid """" ""<literal>p_ceilometer-agent-central</literal>, a resource for managing the "" ""Ceilometer Central Agent service"" msgstr """" ""<literal>p_ceilometer-agent-central</literal>, 用来管理 Ceilometer 监控代理服"" ""务的资源 "" msgid """" ""<literal>p_cinder-api</literal>, a resource for manage Block Storage API "" ""service"" msgstr """" ""<literal>p_cinder-api</literal> 资源，对 OpenStack 身份认证服务进行管理。"" msgid """" ""<literal>p_fs_mysql</literal>, a Pacemaker managed filesystem mounted to "" ""<filename>/var/lib/mysql</filename> on whatever node currently runs the "" ""MySQL service,"" msgstr """" ""<literal>p_fs_mysql</literal>，Pacemaker 管理的文件系统，挂载点为 <filename>/"" ""var/lib/mysql</filename>，该文件系统将在运行 MySQL 服务的节点上挂载，"" msgid """" ""<literal>p_fs_rabbitmq</literal>, a Pacemaker managed filesystem mounted to "" ""<filename>/var/lib/rabbitmq</filename> on whatever node currently runs the "" ""RabbitMQ service,"" msgstr """" ""<literal>p_fs_rabbitmq</literal>，Pacemaker 管理的文件系统，挂载点为 "" ""<filename>/var/lib/rabbitmq</filename>，该文件系统将在运行 RabbitMQ 服务的节"" ""点上挂载，"" msgid """" ""<literal>p_glance-api</literal>, a resource for managing OpenStack Image API "" ""service"" msgstr ""<literal>p_glance-api</literal> 资源，对 OpenStack 镜像服务进行管理。"" msgid """" ""<literal>p_ip_mysql</literal>, a virtual IP address for use by MySQL "" ""(<literal>192.168.42.101</literal>),"" msgstr """" ""<literal>p_ip_mysql</literal>，MySQL 服务将会使用的虚拟 IP 地址"" ""（<literal>192.168.42.101</literal>），"" msgid """" ""<literal>p_ip_rabbitmq</literal>, a virtual IP address for use by RabbitMQ "" ""(<literal>192.168.42.100</literal>),"" msgstr """" ""<literal>p_ip_rabbitmq</literal>，RabbitMQ 服务将会使用的虚拟 IP 地址"" ""（<literal>192.168.42.100</literal>），"" msgid """" ""<literal>p_neutron-l3-agent</literal>, a resource for manage Neutron L3 "" ""Agent service"" msgstr """" ""<literal>p_neutron-l3-agent</literal>资源，对 neutron L3 代理程序进行管理。"" msgid """" ""<literal>p_neutron-metadata-agent</literal>, a resource for manage Neutron "" ""Metadata Agent service"" msgstr """" ""<literal>p_neutron-metadata-agent</literal>资源，对 neutron metadata 代理程序"" ""进行管理。"" msgid """" ""<literal>rabbitmq</literal> DRBD resource configuration (<filename>/etc/drbd."" ""d/rabbitmq.res</filename>)"" msgstr """" ""<literal>rabbitmq</literal> DRBD 资源配置文件（ <filename>/etc/drbd.d/"" ""rabbitmq.res</filename> ）"" msgid """" ""<package>fence-agents</package> (Fedora only; all other distributions use "" ""fencing agents from <package>cluster-glue</package>)"" msgstr """" ""<package>fence-agents</package> （说明：只针对 Fedora 发行版；其它 Linux 发行"" ""版都使用 <package>cluster-glue</package> 软件包中的 fence 资源代理）"" msgid """" ""<package>pacemaker</package> (Note that the crm shell should be downloaded "" ""separately.)"" msgstr """" ""<package>pacemaker</package> （说明：crm 命令行工具需要另外单独下载。）"" msgid ""<placeholder-1/> (LSB)"" msgstr ""<placeholder-1/> （LSB）"" msgid ""<placeholder-1/> (LSB, alternate)"" msgstr ""<placeholder-1/> （LSB，另一种方法）"" msgid ""<placeholder-1/> (systemd)"" msgstr ""<placeholder-1/> （systemd）"" msgid ""<placeholder-1/> (upstart)"" msgstr ""<placeholder-1/> （upstart）"" msgid """" ""<placeholder-1/> supports batch input, so you may copy and paste the above "" ""into your live pacemaker configuration, and then make changes as required. "" ""For example, you may enter <literal>edit p_ip_mysql</literal> from the "" ""<placeholder-2/> menu and edit the resource to match your preferred virtual "" ""IP address."" msgstr """" ""<placeholder-1/> 支持批量输入的配置，因此可以直接复制上述配置示例，粘贴到实际"" ""的 Pacemaker 配置环境，然后根据具体情况调整配置项。例如，在 <placeholder-2/"" ""> 菜单中，输入 <literal>edit p_ip_mysql</literal>，可以对虚拟 IP 地址资源进行"" ""编辑。"" msgid """" ""<placeholder-1/> supports batch input, so you may copy and paste the above "" ""into your live pacemaker configuration, and then make changes as required. "" ""For example, you may enter <literal>edit p_ip_rabbitmq</literal> from the "" ""<placeholder-2/> menu and edit the resource to match your preferred virtual "" ""IP address."" msgstr """" ""<placeholder-1/> 支持批量输入的配置，因此可以直接复制上述配置示例，粘贴到实际"" ""的 Pacemaker 配置环境，然后根据具体情况调整配置项。例如，在 <placeholder-2/"" ""> 菜单中，输入 <literal>edit p_ip_rabbitmq</literal>，可以对虚拟 IP 地址资源"" ""进行编辑。""""A stateful service is one where subsequent requests to the service depend on "" ""the results of the first request. Stateful services are more difficult to "" ""manage because a single action typically involves more than one request, so "" ""simply providing additional instances and load balancing will not solve the "" ""problem. For example, if the Horizon user interface reset itself every time "" ""you went to a new page, it wouldn't be very useful. OpenStack services that "" ""are stateful include the OpenStack database and message queue.""""有状态服务，是指客户端发送的后续请求依赖于之前相关请求的处理结果。由于单独一"" ""项操作可能涉及若干相关请求，有状态服务相对难于管理，只是通过多个实例和负载均"" ""衡无法实现高可用。例如，如果每次访问 Horizon 时都是打开一个全新的页面（之前的"" ""操作都消失了），对于用户来说是毫无意义的。OpenStack 中有状态服务包括 "" ""OpenStack 数据库和消息队列。""""A typical active/passive installation for a stateful service maintains a "" ""replacement resource that can be brought online when required. A separate "" ""application (such as Pacemaker or Corosync) monitors these services, "" ""bringing the backup online as necessary.""""有状态服务的“主/从”模式高可用则是维护一套额外的备份资源，当故障发生时，可以直"" ""接替代失效部份继续工作。单独的应用程序（如 Pacemaker 、Corosync 等）负责监控"" ""各项服务，并在发生故障时激活备份资源。"" msgid ""API node cluster stack"" msgstr ""API 服务节点 HA 集群配置"" msgid ""API services"" msgstr ""API 服务"" msgid ""Accidental deletion or destruction of data."" msgstr ""意外发生的数据删除和数据损坏。"" msgid ""Active/Active"" msgstr ""主/主"" msgid ""Active/Passive"" msgstr ""主/从"" msgid ""Add Block Storage API resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 块设备存储服务资源"" msgid ""Add MySQL resources to Pacemaker"" msgstr ""在 Pacemaker 中添加 MySQL 资源"" msgid ""Add OpenStack Identity resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 认证服务资源"" msgid ""Add OpenStack Image API resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 镜像服务资源"" msgid ""Add OpenStack Networking Server resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 网络服务资源"" msgid ""Add RabbitMQ resources to Pacemaker"" msgstr ""在 Pacemaker 中添加 RabbitMQ 资源"" msgid ""Add neutron DHCP agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron DHCP 代理程序资源"" msgid ""Add neutron L3 agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron L3 代理程序资源"" msgid ""Add neutron metadata agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron metadata 代理程序资源"" msgid ""Add the Telemetry central agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 Telemetry 监控中心资源"" msgid ""Adjust the configuration:"" msgstr ""调整配置文件："" msgid ""After each change of this file, you should restart HAProxy."" msgstr ""每次修改配置文件之后，必须重启 HAProxy 服务。"" msgid """" ""After the copy make sure that all files are the same, you can do this by "" ""using the following command:"" msgstr ""复制之后需确保所有的文件都是相同的，你能通过使用如下命令确认："" msgid ""All OpenStack API services"" msgstr ""所有 OpenStack API 服务"" msgid ""All OpenStack configuration files should refer to virtual IP addresses."" msgstr ""所有 OpenStack 组件的配置中也相应使用虚拟 IP 地址。"" msgid ""All OpenStack schedulers"" msgstr ""所有 OpenStack 调度相关的服务"" msgid ""All other nodes can now be started using:"" msgstr ""其他所有节点现在能被启动："" msgid """" ""And for any additional information about Galera, you can access this guide: "" ""<link href=\""http://galeracluster.com/documentation-webpages/gettingstarted."" ""html\"">http://galeracluster.com/documentation-webpages/gettingstarted.html</"" ""link>"" msgstr """" ""更多关于 Galera 的信息，请参阅：<link href=\""http://galeracluster.com/"" ""documentation-webpages/gettingstarted.html\"">http://galeracluster.com/"" ""documentation-webpages/gettingstarted.html</link>"" msgid ""Applications and automatic service migration"" msgstr ""应用程序以及服务自动迁移工具；"" msgid ""Begin trunk designation."" msgstr ""开始主干指定。"" msgid """" ""Besides installing the <package>Corosync</package> package, you must also "" ""create a configuration file, stored in <filename>/etc/corosync/corosync."" ""conf</filename>. Corosync can be configured to work with either multicast or "" ""unicast IP addresses."" msgstr """" ""除了安装 <package>Corosync</package> 之外，还需要创建一个配置文件 <filename>/"" ""etc/corosync/corosync.conf</filename> 。Corosync 可以使用组播或者单播 IP 地址"" ""进行集群心跳通信。"" msgid """" ""By default, <literal>controller1</literal> handles the caching service but "" ""if the host goes down, <literal>controller2</literal> does the job. For more "" ""information about <application>Memcached</application> installation, see the "" ""<link href=\""http://docs.openstack.org/admin-guide-cloud/content/\""> "" ""OpenStack Cloud Administrator Guide</link>."" msgstr """" ""默认情况下，服务器 <literal>controller1</literal> 处理所有缓存，一旦它无法工"" ""作，服务器 <literal>controller2</literal> 会自动接管。更多关于 "" ""<application>Memcached</application> 布署的信息请参阅 <link href=\""http://"" ""docs.openstack.org/admin-guide-cloud/content/\""> OpenStack 云计算平台管理员手"" ""册</link>。"" msgid """" ""Check that the nodes can access each other through the firewall. Depending "" ""on your environment, this might mean adjusting iptables, as in:"" msgstr """" ""检查各节点之间的网络通信有没有被防火墙拦截。根据布署环境的不同，检查方法也各"" ""不相同。如，某些环境中，这一步只需要对 iptables 进行配置："" msgid ""Cloud controller cluster stack"" msgstr ""OpenStack 控制服务 HA 集群配置"" msgid ""Configure Block Storage API service"" msgstr ""配置 OpenStack 块设备存储服务"" msgid ""Configure DRBD"" msgstr ""配置 DRBD"" msgid ""Configure OpenStack Identity service"" msgstr ""配置 OpenStack 身份认证服务"" msgid ""Configure OpenStack Identity to listen on the VIP address,"" msgstr ""配置 OpenStack 身份认证服务监听虚拟 IP 地址，"" msgid ""Configure OpenStack Networking server"" msgstr ""配置 OpenStack 网络服务"" msgid ""Configure OpenStack Networking to listen on the virtual IP address,"" msgstr ""配置 OpenStack 网络服务监听虚拟 IP 地址，"" msgid ""Configure OpenStack services for highly available MySQL"" msgstr ""配置 OpenStack 各服务使用高可用的 MySQL 数据库"" msgid ""Configure OpenStack services for highly available RabbitMQ"" msgstr ""配置 OpenStack 各服务使用高可用的 RabbitMQ 服务"" msgid ""Configure OpenStack services to use Rabbit HA queues"" msgstr ""配置其它 OpenStack 服务使用高可用的 RabbitMQ 服务"" msgid ""Configure OpenStack services to use RabbitMQ"" msgstr ""配置 OpenStack 各服务使用高可用的 RabbitMQ 服务"" msgid ""Configure OpenStack services to use high available OpenStack Image API"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack镜像服务"" msgid ""Configure OpenStack services to use highly available Block Storage API"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 块设备存储服务"" msgid """" ""Configure OpenStack services to use highly available OpenStack Networking "" ""server"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 网络服务"" msgid """" ""Configure OpenStack services to use the highly available OpenStack Identity"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 身份认证服务"" msgid ""Configure OpenStack services to use the virtual IP address."" msgstr ""配置 OpenStack 服务使用该虚拟 IP 地址。"" msgid ""Configure OpenStack services to use this IP address."" msgstr ""配置 OpenStack 服务使用该虚拟 IP 地址。"" msgid ""Configure Pacemaker group"" msgstr ""配置 Pacemaker 资源组"" msgid ""Configure RabbitMQ"" msgstr ""配置 RabbitMQ"" msgid ""Configure RabbitMQ for HA queues"" msgstr ""配置 RabbitMQ 实现高可用的消息队列"" msgid ""Configure Telemetry central agent service"" msgstr ""配置 Telemetry 监中心"" msgid ""Configure the VIP"" msgstr ""配置VIP"" msgid ""Configuring Block Storage to listen on the VIP address"" msgstr ""配置块存储监听于VIP地址"" msgid ""Configuring MySQL to listen on that IP address"" msgstr ""配置 MySQL 监听那个 IP 地址"" msgid ""Configuring MySQL to use a data directory residing on that DRBD device"" msgstr ""配置MySQL使用位于DRBD设备上的数据目录"" msgid ""Configuring OpenStack services to use this IP address"" msgstr ""使用该 IP 地址配置 OpenStack 服务"" msgid ""Configuring a DRBD device for use by MySQL"" msgstr ""配置被MySQL使用的DRBD设备"" msgid """" ""Copy this file to all other databases servers and change the value of "" ""<literal>wsrep_cluster_address</literal> and <literal>wsrep_node_name</"" ""literal> accordingly."" msgstr """" ""将此文件拷贝到所有的其他数据库服务器上并相应的修改"" ""<literal>wsrep_cluster_address</literal> 和<literal>wsrep_node_name</literal>"" ""的值。""msgid ""Corosync configuration file (<filename>corosync.conf</filename>)"" msgstr ""Corosync 配置文件（<filename>corosync.conf</filename>）""""Corosync configuration file fragment (<filename>corosync.conf</filename>)"" msgstr """" ""Corosync 配置文件片断：\n"" ""（ <filename>corosync.conf</filename> ）"" msgid """" ""Corosync is started as a regular system service. Depending on your "" ""distribution, it may ship with an LSB init script, an upstart job, or a "" ""systemd unit file. Either way, the service is usually named <systemitem "" ""class=\""service\"">corosync</systemitem>:"" msgstr """" ""Corosync 启动方法和普通的系统服务没有区别，根据 Linux 发行版的不同，可能是 "" ""LSB init 脚本、upstart 任务、systemd 服务。不过习惯上，都会统一使用 "" ""<systemitem class=\""service\"">corosync</systemitem> 这一名称："" msgid ""Create a file system"" msgstr ""创建文件系统"" msgid ""Create the <filename>/etc/mysql/conf.d/wsrep.cnf</filename> file."" msgstr ""创建<filename>/etc/mysql/conf.d/wsrep.cnf</filename>文件"" msgid """" ""Creates the <filename>/dev/drbd1</filename> device node, attaches the DRBD "" ""device to its backing store, and connects the DRBD node to its peer. Must be "" ""completed on both nodes."" msgstr """" ""创建 <literal>/dev/drbd1</literal> 设备文件，将指定的后端存储设备附加到该 "" ""DRBD 资源，同时建立所有节点服务器之间的通信连接。两台节点服务器上都必须完成该"" ""操作。"" msgid """" ""Creates the <literal>/dev/drbd0</literal> device node, attaches the DRBD "" ""device to its backing store, and connects the DRBD node to its peer. Must be "" ""completed on both nodes."" msgstr """" ""创建 <literal>/dev/drbd0</literal> 设备文件，将指定的后端存储设备附加到该 "" ""DRBD 资源，同时建立所有节点服务器之间的通信连接。两台节点服务器上都必须完成该"" ""操作。"" msgid ""Creating a file system"" msgstr ""创建文件系统"" msgid ""Data loss"" msgstr ""数据丢失"" msgid ""Database"" msgstr ""数据库"" msgid ""Description"" msgstr ""描述"" msgid ""Do this configuration on all services using RabbitMQ:"" msgstr ""对所有使用 RabbitMQ 的组件进行配置："" msgid ""Edit <filename>/etc/ceilometer/ceilometer.conf</filename>:"" msgstr ""编辑 <filename>/etc/ceilometer/ceilometer.conf</filename>："" msgid ""Edit <filename>/etc/cinder/cinder.conf</filename>:"" msgstr ""编辑 <filename>/etc/cinder/cinder.conf</filename>："" msgid ""Edit <filename>/etc/glance/glance-api.conf</filename>:"" msgstr ""编辑 <filename>/etc/glance/glance-api.conf</filename>："" msgid ""Edit <filename>/etc/neutron/neutron.conf</filename>:"" msgstr ""编辑 <filename>/etc/neutron/neutron.conf</filename>："" msgid """" ""Enabling a DRBD resource is explained in detail in <link href=\""http://www."" ""drbd.org/users-guide-8.3/s-first-time-up.html\""> the DRBD User's Guide</"" ""link>. In brief, the proper sequence of commands is this:"" msgstr """" ""激活 DRBD 设备的详细说明请参阅 <link href=\""http://www.drbd.org/users-"" ""guide-8.3/s-first-time-up.html\""> DRBD 用户手册 </link>，下面仅列出必要的命令"" ""及其执行顺序："" msgid """" ""Enabling a DRBD resource is explained in detail in <link href=\""http://www."" ""drbd.org/users-guide-8.3/s-first-time-up.html\"">the DRBD User's Guide</"" ""link>. In brief, the proper sequence of commands is this:"" msgstr """" ""激活 DRBD 设备的详细说明请参阅 <link href=\""http://www.drbd.org/users-"" ""guide-8.3/s-first-time-up.html\""> DRBD 用户手册 </link>，下面仅列出必要的命令"" ""及其执行顺序："" msgid ""Example configuration with two hosts:"" msgstr ""使用 2 个 memcached 节点的配置示例："" msgid ""Facility services such as power, air conditioning, and fire protection"" msgstr ""辅助设施，如电源、空调、防火等；"" msgid """" ""Finally, we need to create a service <literal>group</literal> to ensure that "" ""the virtual IP is linked to the API services resources:"" msgstr """" ""最后，创建一个资源组 <literal>group</literal>，将所有 API 服务资源和该虚拟 "" ""IP 地址联系起来。"" msgid ""First of all, you need to download the resource agent to your system:"" msgstr ""首先，下载 Pacemaker 资源代理："" msgid """" ""First, you must select and assign a virtual IP address (VIP) that can freely "" ""float between cluster nodes."" msgstr ""首先选择并绑定一个可以在各集群节点之间迁移的虚拟 IP 地址 （即 VIP ）。"" msgid """" ""For OpenStack Compute, for example, if your OpenStack Image API service IP "" ""address is <literal>192.168.42.103</literal> as in the configuration "" ""explained here, you would use the following configuration in your "" ""<filename>nova.conf</filename> file:"" msgstr """" ""以 OpenStack 计算服务为例，如果 OpenStack 镜像服务的虚拟 IP 地址是 "" ""<literal>192.168.42.103</literal>，那么在 OpenStack 计算服务的配置文件"" ""（ <filename>nova.conf</filename> ）中应该使用如下配置："" msgid """" ""For OpenStack Image, for example, if your MySQL service IP address is "" ""<literal>192.168.42.101</literal> as in the configuration explained here, "" ""you would use the following line in your OpenStack Image registry "" ""configuration file (<filename>glance-registry.conf</filename>):"" msgstr """" ""以 OpenStack 镜像服务为例，如果 MySQL 数据库的虚拟 IP 地址是 "" ""<literal>192.168.42.101</literal>，那么在 OpenStack 镜像服务的配置文件"" ""（ <filename>glance-registry.conf</filename> ）中应该使用如下配置："" msgid """" ""For OpenStack Image, for example, if your RabbitMQ service IP address is "" ""<literal>192.168.42.100</literal> as in the configuration explained here, "" ""you would use the following line in your OpenStack Image API configuration "" ""file (<filename>glance-api.conf</filename>):"" msgstr """" ""以 OpenStack 镜像服务为例，如果 RabbitMQ 服务的虚拟 IP 地址是 "" ""<literal>192.168.42.100</literal>，那么在 OpenStack 镜像服务的配置文件"" ""（ <filename>glance-api.conf</filename> ）中应该使用如下配置："" msgid """" ""For UDPU, every node that should be a member of the membership must be "" ""specified."" msgstr ""对于 UDPU ，每台节点服务器都需要配置所属的传输组。"" msgid """" ""For a new MySQL installation with no existing data, you may also run the "" ""<placeholder-1/> command:"" msgstr ""如果使用全新的数据库，可以执行 <placeholder-1/> 命令："" msgid """" ""For example with OpenStack Compute, if your OpenStack Identity service IP "" ""address is <literal>192.168.42.103</literal> as in the configuration "" ""explained here, you would use the following line in your API configuration "" ""file (<literal>api-paste.ini</literal>):"" msgstr """" ""以 OpenStack 计算服务为例，如果 OpenStack 身份认证服务的虚拟 IP 地址是 "" ""<literal>192.168.42.103</literal>，那么在 OpenStack 计算服务的配置文件"" ""（ <literal>api-paste.ini</literal> ）中应该使用如下配置："" msgid """" ""For example, you should configure OpenStack Compute for using highly "" ""available OpenStack Networking server in editing <literal>nova.conf</"" ""literal> file:"" msgstr """" ""以 OpenStack 计算服务为例，在 OpenStack 计算服务的配置文件（ <literal>nova."" ""conf</literal> ）中应该使用如下配置："" msgid """" ""For firewall configurations, note that Corosync communicates over UDP only, "" ""and uses <literal>mcastport</literal> (for receives) and <literal>mcastport "" ""- 1</literal> (for sends)."" msgstr """" ""Corosync 通信使用 UDP 协议，端口为 <literal>mcastport</literal> （接收数据）"" ""和 <literal>mcastport - 1</literal> （发送数据）。配置防火墙时需要打开这两个"" ""端口。"" msgid """" ""For installing HAProxy on your nodes, you should consider its <link href="" ""\""http://haproxy.1wt.eu/#docs\"">official documentation</link>. Also, you "" ""have to consider that this service should not be a single point of failure, "" ""so you need at least two nodes running HAProxy."" msgstr """" ""HAProxy 的安装，请参阅项目<link href=\""http://haproxy.1wt.eu/#docs\"">官方文档"" ""</link>。别外，为了避免 HAProxy 本身成为整个系统的单点故障，最少应配置 2 台 "" ""HAProxy 节点服务器。"" msgid ""From the <filename>debian.cnf</filename> get the database password:"" msgstr ""从<filename>debian.cnf</filename>中获取数据库密码："" msgid ""HA using active/active"" msgstr ""主/主模式高可用集群"" msgid ""HA using active/passive"" msgstr ""主/从模式高可用集群"" msgid ""HAProxy nodes"" msgstr ""HAProxy 节点服务器"" msgid ""Here is an example of the HAProxy configuration file:"" msgstr ""下面是 HAProxy 配置文件的示例："" msgid ""High Availability systems seek to minimize two things:"" msgstr ""实现系统高可用是为了减少以下 2 种异常情况："" msgid """" ""High-availability systems typically achieve an uptime percentage of 99.99% "" ""or more, which roughly equates to less than an hour of cumulative downtime "" ""per year. In order to achieve this, high availability systems should keep "" ""recovery times after a failure to about one to two minutes, sometimes "" ""significantly less."" msgstr """" ""通常，高可用系统能够保证 99.99% 的在线时间，相当于一年之中发生系统故障的累积"" ""时间不超过 1 个小时。要达到这一目标，高可用系统应将故障恢复时间控制在 1 ～ 2 "" ""分钟之内甚至更短。"" msgid ""Highly available Block Storage API"" msgstr ""高可用 OpenStack 块设备存储服务"" msgid ""Highly available MySQL"" msgstr ""高可用的MySQL"" msgid ""Highly available OpenStack Identity"" msgstr ""高可用 OpenStack 身份认证服务"" msgid ""Highly available OpenStack Image API"" msgstr ""高可用 OpenStack 镜像 API 服务"" msgid ""Highly available OpenStack Networking server"" msgstr ""高可用 OpenStack 网络服务"" msgid ""Highly available RabbitMQ"" msgstr ""高可用的 RabbitMQ"" msgid ""Highly available Telemetry central agent"" msgstr ""高可用 Telemetry 监控代理"" msgid ""Highly available neutron DHCP agent"" msgstr ""高可用 neutron DHCP 代理程序"" msgid ""Highly available neutron L3 agent"" msgstr ""高可用 neutron L3 代理程序"" msgid ""Highly available neutron metadata agent"" msgstr ""高可用 neutron metadata 代理程序"" msgid ""How frequently to retry connecting with RabbitMQ:"" msgstr ""重新尝试连接 RabbitMQ 服务的时间间隔："" msgid ""How long to back-off for between retries when connecting to RabbitMQ:"" msgstr ""每次重新尝试连接 RabbitMQ 服务应后延多长时间："" msgid """" ""If the <placeholder-1/> is set to yes, the broadcast address is used for "" ""communication. If this option is set, <placeholder-2/> should not be set."" msgstr """" ""如果将 <placeholder-1/> 设置为 yes ，集群心跳将通过广播实现。设置该参数时，"" ""不能设置 <placeholder-2/> 。"" msgid """" ""If the cluster is working, you can now proceed to creating users and "" ""passwords for queues."" msgstr ""如果集群运行正常，就可以开始为消息队列创建用户和密码。"" msgid """" ""If you are using Corosync version 2 on Ubuntu 14.04, remove or comment out "" ""lines under the service stanza, which enables Pacemaker to start up."" msgstr """" ""如果是在 Ubuntu 14.04 系统中运行 Corosync 2，那么应该将 stanza 对应的 "" ""service 配置段删除或者全部注释，以确保 Pacemaker 可以启动。"" msgid """" ""If you are using Corosync version 2, use the <placeholder-1/> utility as it "" ""is a direct replacement for <placeholder-2/>."" msgstr """" ""如果使用 Corosync v2 版本，请使用 <placeholder-2/> 命令的替代命令 "" ""<placeholder-1/> 。"" msgid """" ""If you are using both private and public IP addresses, you should create two "" ""Virtual IP addresses and define your endpoint like this:"" msgstr """" ""如果要同时使用私有和公开的 IP 地址，需要创建两个虚拟 IP 地址资源，并建立类似"" ""如下的服务端点："" msgid """" ""If you are using both private and public IP, you should create two Virtual "" ""IPs and define your endpoint like this:"" msgstr """" ""如果要同时使用私有和公开的 IP 地址，需要创建两个虚拟 IP 地址资源，并建立类似"" ""如下的服务端点："" msgid """" ""If you are using the horizon dashboard, you should edit the "" ""<literal>local_settings.py</literal> file:"" msgstr """" ""如果配置了 Horizon 面板，也需要修改 Horizon 的配置文件 "" ""<literal>local_settings.py</literal> ： "" msgid """" ""If you change the configuration from an old setup which did not use HA "" ""queues, you should interrupt the service:"" msgstr """" ""如果是直接俢改没有启用队列镜像特性的 RabbitMQ 服务的配置，那么对服务作一次重"" ""置："" msgid """" ""If you have mariaDB already installed you need to re-apply all the "" ""permissions from the installation guide. It will purge all privileges!"" msgstr """" ""如果您已经安装了mariaDB，您需要重新申请安装指南中的所有权限。此将清理所有的权"" ""限！"" msgid """" ""In Corosync configurations using redundant networking (with more than one "" ""<placeholder-1/>), you must select a Redundant Ring Protocol (RRP) mode "" ""other than <literal>none</literal>. <literal>active</literal> is the "" ""recommended RRP mode."" msgstr """" ""Cororsync 可以使用冗余的心跳网络（即多个 <placeholder-1/> 配置），但是必须同"" ""时将 RRP 模式设置为除 <literal>none</literal>之外的其它值，建议使用 "" ""<literal>active</literal> 模式。"" msgid """" ""In an active/active configuration, systems also use a backup but will manage "" ""both the main and redundant systems concurrently. This way, if there is a "" ""failure the user is unlikely to notice. The backup system is already online, "" ""and takes on increased load while the main system is fixed and brought back "" ""online."" msgstr """" ""在“主/主”模式中，服务的冗余实例和主实例会同时工作。这样主实例发生故障，不会对"" ""用户产生影响，因为冗余实例一直处于在线状态，后续客户端的请求直接由冗余实例处"" ""理，而主实例的故障恢复可以同步进行。"" msgid """" ""In an active/passive configuration, systems are set up to bring additional "" ""resources online to replace those that have failed. For example, OpenStack "" ""would write to the main database while maintaining a disaster recovery "" ""database that can be brought online in the event that the main database "" ""fails."" msgstr """" ""在“主/从”模式中，当系统中的资源失效时，新的资源会被激活，替代失效部份继续提供"" ""服务。例如，在 OpenStack 集群中，可以在主数据库之外维护一套灾备数据库，当主数"" ""据库发生故障时，激活灾备数据库可以保证集群继续正常运行。"" msgid """" ""In order for Pacemaker monitoring to function properly, you must ensure that "" ""MySQL's database files reside on the DRBD device. If you already have an "" ""existing MySQL database, the simplest approach is to just move the contents "" ""of the existing <filename>/var/lib/mysql</filename> directory into the newly "" ""created filesystem on the DRBD device."" msgstr """" ""要通过 Pacemaker 实现 MySQL 高可用，必须首先保证 MySQL 的数据文件使用 DRBD 存"" ""储设备。如果使用已有的数据库，最简单的方法是将已有的数据库文件 <filename>/"" ""var/lib/mysql</filename> 迁移到 DRBD 设备之上的文件系统中。"" msgid """" ""In order for Pacemaker monitoring to function properly, you must ensure that "" ""RabbitMQ's <filename>.erlang.cookie</filename> files are identical on all "" ""nodes, regardless of whether DRBD is mounted there or not. The simplest way "" ""of doing so is to take an existing <filename>.erlang.cookie</filename> from "" ""one of your nodes, copying it to the RabbitMQ data directory on the other "" ""node, and also copying it to the DRBD-backed filesystem."" msgstr """" ""要通过 Pacemaker 实现 RabbitMQ 高可用，必须首先保证 RabbitMQ 的文件 "" ""<filename>.erlang.cookie</filename> 不论在 DRBD 设备有没有挂载的情况下，都完"" ""全相同。最简单的方法是将其中一台节点服务器上已经生成的 <filename>.erlang."" ""cookie</filename> 文件复制到所有其它节点，同时也复制一份到 DRBD 设备上的文件"" ""系统之中。"" msgid """" ""In the <filename>/etc/mysql/my.conf</filename> file, make the following "" ""changes:"" msgstr ""在<filename>/etc/mysql/my.conf</filename>文件中，进行如下修改："" msgid """" ""In versions prior to Juno, this option was called "" ""<literal>glance_api_servers</literal> in the <literal>[DEFAULT]</literal> "" ""section."" msgstr """" ""对于 Juno 之前的版本，该配置项对应的是 <literal>[DEFAULT]</literal> 段之下的 "" ""<literal>glance_api_servers</literal>。"" msgid """" ""Initializes DRBD metadata and writes the initial set of metadata to "" ""<filename>/dev/data/rabbitmq</filename>. Must be completed on both nodes."" msgstr """" ""初始化 DRBD 元数据，并在 <filename>/dev/data/rabbitmq</filename> 上初始元数据"" ""集。两台节点服务器上都必须完成该操作。"" msgid """" ""Initializes DRBD metadata and writes the initial set of metadata to "" ""<literal>/dev/data/mysql</literal>. Must be completed on both nodes."" msgstr """" ""初始化 DRBD 元数据，并在 <literal>/dev/data/mysql</literal> 上初始元数据集。"" ""两台节点服务器上都必须完成该操作。"" msgid ""Install RabbitMQ"" msgstr ""安装 RabbitMQ"" msgid ""Install packages"" msgstr ""安装软件包"" msgid ""Installing Galera through a MySQL version patched for wsrep:"" msgstr ""为已经加上 wresp 补丁的 MySQL 数据库安装 Galera ："" msgid ""Introduction to OpenStack High Availability"" msgstr ""OpenStack高可用介绍"" msgid """" ""Kicks off the initial device synchronization, and puts the device into the "" ""<literal>primary</literal> (readable and writable) role. See <link href="" ""\""http://www.drbd.org/users-guide-8.3/ch-admin.html#s-roles\""> Resource "" ""roles</link> (from the DRBD User's Guide) for a more detailed description of "" ""the primary and secondary roles in DRBD. Must be completed on one node only, "" ""namely the one where you are about to continue with creating your filesystem."" msgstr """" ""启动 DRBD 设备的初始化同步，并将之设置为 <literal>primary</literal> 角色。关"" ""于 “primary” 和 “secondary” 角色的详细说明请查阅 <link href=\""http://www."" ""drbd.org/users-guide-8.3/ch-admin.html#s-roles\""> Resource roles</link> "" ""（ DRBD 用户手册）。这一操作只应在其中一台节点服务器上执行，此处指的是将被用"" ""于执行创建文件系统的节点。"" msgid """" ""Making stateful services highly available can depend on whether you choose "" ""an active/passive or active/active configuration."" msgstr ""实现有状态服务高可用的方案有“主/从”和“主/主” 2 种模式。"" msgid """" ""Making the Block Storage (cinder) API service highly available in active / "" ""passive mode involves:"" msgstr ""使得块存储(cinder)API服务在主/被模式中高可用包括:"" msgid """" ""Making the Telemetry central agent service highly available in active / "" ""passive mode involves managing its daemon with the Pacemaker cluster manager."" msgstr """" ""Telemetry 监控中心的主/从模式高可用是通过 Pacemaker 管理其后台守护进程实现。"" msgid ""Manage network resources"" msgstr ""组织网络相关资源"" msgid """" ""Manage the OpenStack Networking API Server daemon with the Pacemaker cluster "" ""manager,"" msgstr ""使用 Pacemaker 管理 OpenStack 网络服务，"" msgid ""Managing Block Storage API daemon with the Pacemaker cluster manager"" msgstr ""使用 Pacemaker 管理 OpenStack 块设备存储服务"" msgid ""Managing OpenStack Identity daemon with the Pacemaker cluster manager,"" msgstr ""使用 Pacemaker 管理 OpenStack 身份认证服务，"" msgid """" ""Managing all resources, including the MySQL daemon itself, with the "" ""Pacemaker cluster manager"" msgstr ""使用 Pacemaker 管理上述所有资源，包括 MySQL 数据库"" msgid """" ""Maximum retries with trying to connect to RabbitMQ (infinite by default):"" msgstr ""连接 RabbitMQ 服务时最大的重试次数（默认没有限制）："" msgid ""Memcached"" msgstr ""Memcached"" msgid """" ""Memory caching is managed by oslo-incubator, so the way to use multiple "" ""memcached servers is the same for all projects."" msgstr """" ""基于内存的缓存统一由 oslo-incubator 管理，因此对 OpenStack 服务来说，使用多"" ""个 memcached 服务节点作为后端的方法完全相同。""msgid """" ""Mirrored queues in RabbitMQ improve the availability of service since it "" ""will be resilient to failures."" msgstr ""RabbitMQ 实现队列镜像更能提高整个集群的高可用性。"" msgid """" ""More information about <link href=\""http://www.rabbitmq.com/ha.html\""> "" ""highly available queues</link> and <link href=\""https://www.rabbitmq.com/"" ""clustering.html\""> clustering</link> can be found in the official RabbitMQ "" ""documentation."" msgstr """" ""关于 RabbitMQ 的高可用配置，请参阅 RabbitMQ 的官方文档：<link href=\""http://"" ""www.rabbitmq.com/ha.html\""> highly available queues</link> and <link href="" ""\""https://www.rabbitmq.com/clustering.html\""> clustering</link>。"" msgid """" ""Most distributions ship an example configuration file (<filename>corosync."" ""conf.example</filename>) as part of the documentation bundled with the "" ""<package>Corosync</package> package. An example Corosync configuration file "" ""is shown below:"" msgstr """" ""大多数 Linux 发行版都会中在 <package>Corosync</package> 软件包中附带一份配置"" ""示例(<filename>corosync.conf.example</filename>)。Corosync示例配置文件如下："" msgid """" ""Most high availability systems guarantee protection against system downtime "" ""and data loss only in the event of a single failure. However, they are also "" ""expected to protect against cascading failures, where a single failure "" ""deteriorates into a series of consequential failures."" msgstr """" ""大多数的高可用系统只能在发生单一故障的情况下为降低停机时间和避免数据丢失提供"" ""保障。但是用户也期望高可用系统同样能够处理由单一故障演变为一系列连锁故障的情"" ""况。"" msgid """" ""Most high availability systems will fail in the event of multiple "" ""independent (non-consequential) failures. In this case, most systems will "" ""protect data over maintaining availability."" msgstr """" ""大多数高可用系统都无法应对发生一连串不相关故障的情况，此时保护数据优先于保证"" ""系统的高可用性。"" msgid """" ""Multicast groups (<placeholder-1/>) must not be reused across cluster "" ""boundaries. In other words, no two distinct clusters should ever use the "" ""same multicast group. Be sure to select multicast addresses compliant with "" ""<link href=\""http://www.ietf.org/rfc/rfc2365.txt\"">RFC 2365, "" ""\""Administratively Scoped IP Multicast\""</link>."" msgstr """" ""多播地址的使用（<placeholder-1/> ） 不要跨越集群的边界，也即是说，不要在不同"" ""的集群中使用相同的多播地址。使用多播地址时，请依据 <link href=\""http://www."" ""ietf.org/rfc/rfc2365.txt\"">RFC 2365, \""Administratively Scoped IP Multicast"" ""\""</link> 。"" msgid """" ""MySQL is the default database server used by many OpenStack services. Making "" ""the MySQL service highly available involves:"" msgstr """" ""MySQL是许多OpenStack服务所使用的默认数据库服务。确保MySQL服务高可用涉及到："" msgid ""MySQL with Galera"" msgstr ""MySQL 和 Galera"" msgid """" ""MySQL with Galera is by no means the only way to achieve database HA. "" ""MariaDB Galera Cluster (<link href=\""https://mariadb.org/\"">https://mariadb."" ""org/</link>) and Percona XtraDB Cluster (<link href=\""http://www.percona.com/"" ""\"">http://www.percona.com/</link>) also work with Galera. You also have the "" ""option to use PostgreSQL, which has its own replication, or another database "" ""HA option."" msgstr """" ""同样，MySQL + Galera 也并非唯一一种实现数据库高可用的方案。MariaDB Galera 集"" ""群(<link href=\""https://mariadb.org/\"">https://mariadb.org/</link>) 和 "" ""Percona XtraDB 集群(<link href=\""http://www.percona.com/\"">http://www."" ""percona.com/</link>) 都可以和 Galera 一起配置使用。另外 OpenStack 也支持 "" ""PostgreSQL，PostgreSQL 有自己相应的数据镜像和高可用方案。"" msgid ""NODE"" msgstr ""NODE"" msgid ""NODE_NAME"" msgstr ""NODE_NAME"" msgid ""Network components, such as switches and routers"" msgstr ""网络设备，如交换机、路由器；""msgid ""Neutron DHCP agent"" msgstr ""Neutron DHCP 代理服务"" msgid ""Neutron L2 agent"" msgstr ""Neutron L2 代理服务"" msgid ""Neutron L3 agent"" msgstr ""Neutron L3 代理服务"" msgid ""Neutron LBaaS agent"" msgstr ""Neutron LBaas 代理服务"" msgid ""Neutron metadata agent"" msgstr ""Neutron 元数据代理服务"" ""Neutron metadata agent allows Compute API metadata to be reachable by VMs on "" ""tenant networks. High availability for the metadata agent is achieved by "" ""adopting Pacemaker.""""Neutron metadata 代理程序的作用是让运行在租户网络上的虚拟机实例能够访问 "" ""OpenStack 计算服务 API 元数据。Neutron metadata 代理程序的高可用也通过 "" ""Pacemaker 实现。"" msgid """" ""No other changes are necessary to your OpenStack configuration. If the node "" ""currently hosting your RabbitMQ experiences a problem necessitating service "" ""failover, your OpenStack services may experience a brief RabbitMQ "" ""interruption, as they would in the event of a network hiccup, and then "" ""continue to run normally."" msgstr """" ""除此之外，不需要更改其它配置。如果运行数据库服务的节点发生故障，RabbitMQ 服务"" ""会自动迁移到其它节点，OpenStack 服务会经历短暂的临时 RabbitMQ 中断，和偶然发"" ""生的网络中断类似，之后会继续正常运行。"" msgid """" ""No other changes are necessary to your OpenStack configuration. If the node "" ""currently hosting your database experiences a problem necessitating service "" ""failover, your OpenStack services may experience a brief MySQL interruption, "" ""as they would in the event of a network hiccup, and then continue to run "" ""normally."" msgstr """" ""除此之外，不需要更改其它配置。如果运行数据库服务的节点发生故障，MySQL 服务会"" ""自动迁移到其它节点，OpenStack 服务会经历短暂的临时 MySQL 中断，和偶然发生的网"" ""络中断类似，之后会继续正常运行。"" msgid """" ""Note that the installation requirements call for careful attention. Read the "" ""guide <link href=\""https://launchpadlibrarian.net/66669857/README-wsrep"" ""\"">https://launchpadlibrarian.net/66669857/README-wsrep</link> to ensure you "" ""follow all the required steps."" msgstr """" ""请仔细阅读 Wresp API 的安装说明 —— <link href=\""https://launchpadlibrarian."" ""net/66669857/README-wsrep\"">https://launchpadlibrarian.net/66669857/README-"" ""wsrep</link>，并按要求完成安装。"" msgid """" ""Occurs when a user-facing service is unavailable beyond a specified maximum "" ""amount of time."" msgstr ""面向客户的服务无法正常工作的时间超出服务承诺的上限。"" msgid ""Official manual for installing RabbitMQ on Fedora and RHEL"" msgstr ""在 Fedora 和 RHEL 发行版上安装 RabbitMQ 的官方文档"" msgid ""Official manual for installing RabbitMQ on Ubuntu and Debian"" msgstr ""在 Ubuntu 和 Debian 发行版上安装 RabbitMQ 的官方文档"" msgid ""Official manual for installing RabbitMQ on openSUSE"" msgstr ""在 openSUSE 发行版上安装 RabbitMQ 的官方文档"" msgid ""On Fedora and RHEL"" msgstr ""对于 Fedora 和 RHEL 发行版"" msgid ""On Havana:"" msgstr ""对于 Havana 版本："" msgid ""On Ubuntu and Debian"" msgstr ""对于 Ubuntu 和 Debian 发行版"" msgid """" ""On any host that is meant to be part of a Pacemaker cluster, you must first "" ""establish cluster communications through the Corosync messaging layer. This "" ""involves installing the following packages (and their dependencies, which "" ""your package manager will normally install automatically):"" msgstr """" ""Pacemaker 中的节点服务器之间必须通过 Corosync 建立集群通信，需要安装以下软件"" ""包(以及它们的依赖软件包，通常软件包管理器将自动所有依赖软件包)："" msgid ""On openSUSE and SLES"" msgstr ""对 openSUSE 和 SLES 发行版"" msgid ""On openSUSE:"" msgstr ""在 openSUSE 系统中："" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the Block Storage API service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 块设备存储存服务（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the Ceilometer Central Agent service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 "" ""Telemetry 监控中心（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Identity service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 "" ""OpenStack 身份认证服务（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Image API service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 镜像服务（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Networking API service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 网络服务（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron DHCP agent service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""DHCP 代理程序（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron L3 agent service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""L3 代理程序（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron metadata agent service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""metadata 代理程序（包括所有相关资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <placeholder-1/> menu. Pacemaker will "" ""then start the MySQL service, and its dependent resources, on one of your "" ""nodes."" msgstr """" ""配置完成后，在 <placeholder-1/> 菜单下输入 <literal>commit</literal> 提交所有"" ""配置变更。随后 Pacemaker 会其中一台节点服务器上启动 MySQL 服务（包括所有相关"" ""资源）。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <placeholder-1/> menu. Pacemaker will "" ""then start the RabbitMQ service, and its dependent resources, on one of your "" ""nodes."" msgstr """" ""配置完成后，在 <placeholder-1/> 菜单下输入 <literal>commit</literal> 提交所有"" ""配置变更。随后 Pacemaker 会其中一台节点服务器上启动 RabbitMQ 服务（包括所有相"" ""关资源）。"" msgid """" ""Once completed, you may safely return the device to the secondary role. Any "" ""ongoing device synchronization will continue in the background:"" msgstr """" ""完成后，可以安全地把设备变回 “secondary” 角色。已经启动的设备同步将在后台继续"" ""进行："" msgid """" ""Once created, the <filename>corosync.conf</filename> file (and the "" ""<filename>authkey</filename> file if the <placeholder-1/> option is enabled) "" ""must be synchronized across all cluster nodes."" msgstr """" ""<filename>corosync.conf</filename> （以及 <filename>authkey</filename> ，如"" ""果 <placeholder-1/> 启用）一旦创建，则必须在各节点服务器之间保持同步。"" msgid """" ""Once the Corosync services have been started and you have established that "" ""the cluster is communicating properly, it is safe to start <systemitem class="" ""\""service\"">pacemakerd</systemitem>, the Pacemaker master control process:"" msgstr """" ""Corosync 服务启动之后，一旦各节点正常建立集群通信，就可启动 <systemitem "" ""class=\""service\"">pacemakerd</systemitem> （ Pacemaker 主进程）："" msgid """" ""Once the DRBD resource is running and in the primary role (and potentially "" ""still in the process of running the initial device synchronization), you may "" ""proceed with creating the filesystem for MySQL data. XFS is generally the "" ""recommended filesystem due to its journaling, efficient allocation, and "" ""performance:"" msgstr """" ""当 DRBD 资源已经激活并处于 “primay” 角色(可能初始化同步正在进行，还没有完"" ""成)，可以开始创建文件系统。 XFS 由于拥有日志系统，分配效率高，性能好等优点，"" ""是建议选择的文件系统。"" msgid """" ""Once the DRBD resource is running and in the primary role (and potentially "" ""still in the process of running the initial device synchronization), you may "" ""proceed with creating the filesystem for RabbitMQ data. XFS is generally the "" ""recommended filesystem:"" msgstr """" ""当 DRBD 资源已经激活并处于 “primay” 角色（可能初始化同步正在进行，还没有完"" ""成），可以开始创建文件系统。 XFS 由于拥有日志系统，分配效率高，性能好等优点，"" ""是建议选择的文件系统："" msgid """" ""Once the Pacemaker services have started, Pacemaker will create a default "" ""empty cluster configuration with no resources. You may observe Pacemaker's "" ""status with the <placeholder-1/> utility:"" msgstr """" ""Pacemaker 服务启动之后，会自动建立一份空白的集群配置，不包含任何资源。可以通"" ""过 <placeholder-1/> 工具查看 Packemaker 集群的状态："" msgid """" ""Once you have made these changes, you may <literal>commit</literal> the "" ""updated configuration."" msgstr ""作完这些改变后，可以提交更新配置。"" msgid """" ""Once your Pacemaker cluster is set up, it is recommended to set a few basic "" ""cluster properties. To do so, start the <placeholder-1/> shell and change "" ""into the configuration menu by entering <literal>configure</literal>. "" ""Alternatively, you may jump straight into the Pacemaker configuration menu "" ""by typing <placeholder-2/> directly from a shell prompt."" msgstr """" ""Pacemaker 启动之后，建议首先对集群基本属性进行配置。配置时，首先执行 "" ""<placeholder-1/> 命令，然后输入 <literal>configure</literal> 进入配置菜单。也"" ""可以执行 <placeholder-2/> 命令直接进入 Pacemaker 配置菜单。"" msgid ""OpenStack"" msgstr ""OpenStack"" msgid ""OpenStack Block Storage"" msgstr ""OpenStack 块设备存储服务"" msgid ""OpenStack Compute"" msgstr ""OpenStack 计算服务"" msgid ""OpenStack Contributors"" msgstr ""OpenStack贡献者"" msgid ""OpenStack High Availability Guide"" msgstr ""OpenStack高可用指南"" msgid """" ""OpenStack Identity is the Identity Service in OpenStack and used by many "" ""services. Making the OpenStack Identity service highly available in active / "" ""passive mode involves"" msgstr """" ""OpenStack 身份认证服务被很多其他服务使用。实现 OpenStack 身份认证服务主/从模"" ""式的高可用包括以下步骤："" msgid ""OpenStack Networking"" msgstr ""OpenStack 网络服务"" msgid """" ""OpenStack Networking is the network connectivity service in OpenStack. "" ""Making the OpenStack Networking Server service highly available in active / "" ""passive mode involves the following tasks:"" msgstr """" ""OpenStack 网络服务为 OpenStack 集群提供网络基础服务。实现 OpenStack 网络服务"" ""主/从模式的高可用包括以下步骤："" msgid ""OpenStack controller nodes"" msgstr ""OpenStack 控制节点服务器"" msgid ""OpenStack controller nodes contain:"" msgstr ""OpenStack 控制节点服务器上运行以下服务："" msgid """" ""OpenStack currently meets such availability requirements for its own "" ""infrastructure services, meaning that an uptime of 99.99% is feasible for "" ""the OpenStack infrastructure proper. However, OpenStack does not guarantee "" ""99.99% availability for individual guest instances."" msgstr """" ""OpenStack 的基础服务，在合理配置的情况下，能够满足上述 99.99% 在线时间的高可"" ""用性要求。但是 OpenStack 不能保证单个虚拟机实例的 99.99% 在线时间。"" msgid """" ""OpenStack infrastructure high availability relies on the <link href=\""http://"" ""www.clusterlabs.org\"">Pacemaker</link> cluster stack, the state-of-the-art "" ""high availability and load balancing stack for the Linux platform. Pacemaker "" ""is storage and application-agnostic, and is in no way specific to OpenStack."" msgstr """" ""OpenStack 基础服务的高可用基于 <link href=\""http://www.clusterlabs.org"" ""\"">Pacemaker</link> 实现（ Pacemaker 是 Linux 系统平台上常见的高可用和负载均"" ""衡组件）。 Packermaker 是通用的高可用组件，不限于特定的应用程序或者存储设备，"" ""也不是专用于 OpenStack 项目的。"" msgid ""OpenStack network nodes"" msgstr ""OpenStack 网络节点服务器"" msgid ""OpenStack network nodes contain:"" msgstr ""OpenStack 网络节点运行以下服务："" msgid ""Option"" msgstr ""选项"" msgid ""Organizes guide based on cloud controller and compute nodes."" msgstr ""本指南将介绍如何安装控制节点和计算节点"" msgid ""PASSWORD"" msgstr ""密码"" msgid ""PRIMARY_NODE_IP"" msgstr ""PRIMARY_NODE_IP"" msgid """" ""Pacemaker relies on the <link href=\""http://www.corosync.org\"">Corosync</"" ""link> messaging layer for reliable cluster communications. Corosync "" ""implements the Totem single-ring ordering and membership protocol. It also "" ""provides UDP and InfiniBand based messaging, quorum, and cluster membership "" ""to Pacemaker."" msgstr """" ""Pacemaker 使用 <link href=\""http://www.corosync.org\"">Corosync</link> 作为消"" ""息传输层，以实现集群内部通信的可靠性。Corosync 通过 Totem 协议来维护集群通信"" ""的消息序列以及集群成员变动，支持通过 UDP 或 InfiniBand 传输消息，为 "" ""Pacemaker 提供集群成员以及合法节点等信息。""msgid """" ""Pacemaker uses an event-driven approach to cluster state processing. "" ""However, certain Pacemaker actions occur at a configurable interval, "" ""<placeholder-1/>, which defaults to 15 minutes. It is usually prudent to "" ""reduce this to a shorter interval, such as 5 or 3 minutes."" msgstr """" ""Pacemaker 处理集群状况时使用事件驱动机制。但是某些 Pacemaker 操作只会在固定的"" ""时间间隔触发。该时间间隔可以配置，<placeholder-1/>，默认值是 15 分钟。针对特"" ""定的集群，可以适当缩短这一间隔，如 5 分钟或者 3 分钟。"" msgid ""Paste the following lines in this file:"" msgstr ""将如下内容粘贴到文件中：""""Please refer to the <link linkend=\""s-rabbitmq\"">RabbitMQ section</link> for "" ""configuring these services with multiple messaging servers.""""请参阅 <link linkend=\""s-rabbitmq\"">RabbitMQ 部分</link> 将 OpenStack 各组件"" ""配置为可同时使用多个消息队列服务器。"" msgid ""Possible options are:"" msgstr ""可用的节点服务器配置项有："" msgid ""Prepare MySQL for Pacemaker high availability"" msgstr ""MySQL 针对 Pacemaker HA 架构的前期准备"" msgid ""Prepare RabbitMQ for Pacemaker high availability"" msgstr ""RabbitMQ 针对 Pacemaker HA 架构的前期准备""""Preventing single points of failure can depend on whether or not a service "" ""is stateless."" msgstr ""避免单点故障的方法根据该服务是否属于无状态类型而有所不同。"" msgid ""RabbitMQ"" msgstr ""RabbitMQ"" msgid ""RabbitMQ HA cluster host:port pairs:"" msgstr ""RabbitMQ HA 集群服务地址及端口："" msgid ""RabbitMQ is packaged on both distros:"" msgstr ""RabbitMQ 已经有可用的软件安装包：""""RabbitMQ is the default AMQP server used by many OpenStack services. Making "" ""the RabbitMQ service highly available involves the following steps:""""RabbitMQ 是多数 OpenStack 服务的默认 AMQP 服务程序。实现 RabbitMQ 的高可用包"" ""括以下步骤：""""RabbitMQ is the default AMQP server used by many OpenStack services. Making "" ""the RabbitMQ service highly available involves:""""RabbitMQ 是多数 OpenStack 服务的默认 AMQP 服务程序。实现 RabbitMQ 的高可用包"" ""括以下步骤：""""Regardless of the approach, the steps outlined here must be completed on "" ""only one cluster node."" msgstr ""这里列出的这些步骤只需要在其中一个集群节点上操作一遍即可。"" msgid ""Remove user accounts with empty user names because they cause problems:"" msgstr ""删除所有用户名为空的 MySQL 帐户（这些帐户会产生安全隐患）：""msgid ""Run OpenStack API and schedulers"" msgstr ""运行 OpenStack API 和 调度服务""msgid ""Run neutron L3 agent"" msgstr ""运行 neutron L3 代理服务""msgid ""Run neutron metadata agent"" msgstr ""运行 neutron 元数据代理服务"" msgid ""SECONDARY_NODE_IP"" msgstr ""SECONDARY_NODE_IP"" msgid ""Schedulers"" msgstr ""调度程序""msgid ""Services currently working with HA queues:"" msgstr ""目前支持高可用 RabbitMQ 服务的 OpenStack 组件有：""msgid ""Set up Corosync"" msgstr ""Corosync 基本配置"" msgid ""Set up Corosync with multicast"" msgstr ""配置 Corosync 使用组播"" msgid ""Set up Corosync with unicast"" msgstr ""配置 Corosync 使用单播""""Some environments may not support multicast. For such cases, Corosync should "" ""be configured for unicast. An example fragment of the Corosync configuration "" ""file is shown below:""""某些环境中可能不支持组播。这时应该配置 Corosync 使用单播，下面是使用单播的 "" ""Corosync 配置文件的一部分："" msgid ""Start Pacemaker"" msgstr ""启动 Pacemaker"" msgid ""Start mysql as root and execute the following queries:"" msgstr ""使用root启动mysql并执行以下查询：""msgid ""Stateless vs. Stateful services"" msgstr ""无状态和有状态服务"" msgid """" ""Stop all the mysql servers and start the first server with the following "" ""command:"" msgstr ""停止所有的mysql服务器然后使用如下命令启动第一个服务器："" msgid ""Storage components"" msgstr ""存储设备；"" msgid ""System downtime"" msgstr ""系统停机"" msgid ""Telemetry"" msgstr ""Telemetry"" msgid """" ""Telemetry (ceilometer) is the metering and monitoring service in OpenStack. "" ""The Central agent polls for resource utilization statistics for resources "" ""not tied to instances or compute nodes."" msgstr """" ""Telemtry （ ceilometer ）是 OpenStack 系统中的计量和监控服务。监控中心收集包"" ""括虚拟机实例和计算节点在内各种资源的使用情况。"" msgid """" ""The <literal>service</literal> declaration for the <literal>pacemaker</"" ""literal> service may be placed in the <filename>corosync.conf</filename> "" ""file directly, or in its own separate file, <filename>/etc/corosync/service."" ""d/pacemaker</filename>."" msgstr """" ""<literal>pacemaker</literal> 对应的 <literal>service</literal> 配置段，可以放"" ""在 <filename>corosync.conf</filename> ，也可以单独作为一个配置文件 "" ""<filename>/etc/corosync/service.d/pacemaker</filename> 。"" msgid """" ""The <placeholder-1/> configuration option is optional when using IPv4 and "" ""required when using IPv6. This is a 32-bit value specifying the node "" ""identifier delivered to the cluster membership service. If this is not "" ""specified with IPv4, the node id will be determined from the 32-bit IP "" ""address the system to which the system is bound with ring identifier of 0. "" ""The node identifier value of zero is reserved and should not be used."" msgstr """" ""<placeholder-1/> 在使用 IPv4 的网络环境中是可选配置，但在 IPv6 的网络环境中则"" ""必须进行配置。它是一个 32 位的数字，用于在整个集群中标识一台节点服务器。在 "" ""IPv4 网络环境中如果不进行配置，节点 ID 将根据 ring0 对应的 IP 地址自动生成。"" ""节点 ID 0 是保留值，不能在配置文件中使用。"" msgid """" ""The <placeholder-1/> directive controls the transport mechanism used. To "" ""avoid the use of multicast entirely, a unicast transport parameter "" ""<placeholder-2/> should be specified. This requires specifying the list of "" ""members in <placeholder-3/> directive; this could potentially make up the "" ""membership before deployment. The default is <placeholder-4/>. The transport "" ""type can also be set to <placeholder-5/> or <placeholder-6/>."" msgstr """" ""<placeholder-1/> 配置项决定集群通信方式。要完全禁用组播，应该配置单播传输参"" ""数 <placeholder-2/> 。这要求将所有的节点服务器信息写入 <placeholder-3/> ，也"" ""就是需要在配署 HA 集群之前确定节点组成。配认配置是 <placeholder-4/> 。通信方"" ""式类型还支持 <placeholder-5/> 和 <placeholder-6/> 。"" msgid """" ""The <placeholder-1/> is the network address of the interfaces to bind to. "" ""The example uses two network addresses of <literal>/24</literal> IPv4 "" ""subnets."" msgstr """" ""<placeholder-1/> 是心跳网卡 IP 地址对应的网络地址。示例中使用了两个子网掩码"" ""为 <literal>/24</literal> 的 IPv4 网段。"" msgid """" ""The <placeholder-1/> must differ between all configured interfaces, starting "" ""with 0."" msgstr ""所有心跳网络的 <placeholder-1/> 配置不能重复，最小值为 0 。"" msgid """" ""The <placeholder-1/> specifies IP address of one of the nodes. X is ring "" ""number."" msgstr """" ""<placeholder-1/> 对应该节点服务器用于集群通信的 IP 地址，其中 X 对应集群通信"" ""环路序号。"" msgid """" ""The <placeholder-1/> utility can be used to dump the Corosync cluster member "" ""list:"" msgstr ""<placeholder-1/> 命令可以列出 Corosync 集群的成员节点列表：""""The <placeholder-1/> value specifies the time, in milliseconds, during which "" ""the Corosync token is expected to be transmitted around the ring. When this "" ""timeout expires, the token is declared lost, and after <placeholder-2/> lost "" ""tokens the non-responding processor (cluster node) is declared dead. In "" ""other words, <placeholder-3/> × <placeholder-4/> is the maximum time a node "" ""is allowed to not respond to cluster messages before being considered dead. "" ""The default for <placeholder-5/> is 1000 (1 second), with 4 allowed "" ""retransmits. These defaults are intended to minimize failover times, but can "" ""cause frequent \""false alarms\"" and unintended failovers in case of short "" ""network interruptions. The values used here are safer, albeit with slightly "" ""extended failover times.""""<placeholder-1/> 是时间，单位为毫秒，在该配置项指定的时间内， Corosync 令牌应"" ""该完成在回环网络中的传输。如果令牌传输超时就会被丢弃，而一台节点服务器连续出"" ""现 <placeholder-2/> 令牌失效，将会被认为是无效节点。也就是说，一台节点服务器"" ""最长的无响应时间不能超对 <placeholder-3/> × <placeholder-4/> 的乘积（单位毫"" ""秒），否则会被认为是无效节点。<placeholder-5/> 的默认值是 1000 （即 1 秒），"" ""同时默认的重试次数为 4 。默认配置的目标是尽量缩短故障恢复时间，但是可能出现较"" ""多的 “false alarm” 提醒，发生短期的网络故障时也有可能导致失效切换。本处示例中"" ""的配置参数更安全一些，但是失效切换的时间会长一些。""""The API node exposes OpenStack API endpoints onto external network "" ""(Internet). It must talk to the cloud controller on the management network.""""API 服务节点对外（整个互联网）提供 OpenStack API 接口。它们通过管理网络和 "" ""OpenStack 控制节点进行交互。""""The OpenStack Networking service has a scheduler that lets you run multiple "" ""agents across nodes. Also, the DHCP agent can be natively highly available. "" ""You can configure the number of DHCP agents per network using the parameter "" ""<placeholder-1/> in <filename>neutron.conf</filename>. By default this is "" ""equal to 1. To achieve high availability assign more than one DHCP agent per "" ""network.""""OpenStack 网络服务拥有一个调度程序，所有可以在多个节点同时运行各种代理程序。"" ""同样，DHCP 代理服务自身就是支持高可用的。每个网络使用多少 DHCP 代理程序是可以"" ""通过配置文件 <filename>neutron.conf</filename> 中的 <placeholder-1/> 进行配置"" ""的。默认值是 1 ，要实现 DHCP 代理服务的高可用，应为每个网络设置多个 DHCP 代理"" ""程序。"" msgid """" ""The Pacemaker based MySQL server requires a DRBD resource from which it "" ""mounts the <literal>/var/lib/mysql</literal> directory. In this example, the "" ""DRBD resource is simply named <literal>mysql</literal>:"" msgstr """" ""基于 Pacemaker 的 MySQL 数据库需要一个 DRBD 设备，并将之挂载到 <literal>/var/"" ""lib/mysql</literal> 目录。在示例中，DRBD 资源被简单命名为 <literal>mysql</"" ""literal>："" msgid """" ""The Pacemaker based RabbitMQ server requires a DRBD resource from which it "" ""mounts the <filename>/var/lib/rabbitmq</filename> directory. In this "" ""example, the DRBD resource is simply named <literal>rabbitmq</literal>:"" msgstr """" ""基于 Pacemaker 的 RabbitMQ 服务需要一个 DRBD 设备，并将之挂载到 <filename>/"" ""var/lib/rabbitmq</filename> 目录。在示例中，DRBD 资源被简单命名为 "" ""<literal>rabbitmq</literal>："" msgid ""The Pacemaker cluster stack"" msgstr ""Packmaker 集群"" msgid """" ""The choice of database isn't a foregone conclusion; you're not required to "" ""use <application>MySQL</application>. It is, however, a fairly common choice "" ""in OpenStack installations, so we'll cover it here."" msgstr """" ""<application>MySQL</application> 并不是唯一的选择，以它作为示例是因为目前已有"" ""的 OpenStack 布署案例中，使用 <application>MySQL</application> 作为数据库比较"" ""常见。"" msgid """" ""The cloud controller runs on the management network and must talk to all "" ""other services."" msgstr """" ""OpenStack 控制服务运行在管理网络上，可以和其它任何 OpenStack 服务进行交互。"" msgid """" ""The network controller sits on the management and data network, and needs to "" ""be connected to the Internet if an instance will need access to the Internet."" msgstr """" ""网络控制节点运行在管理网络和数据网络中，如果虚拟机实例要连接到互联网，网络控"" ""制节点也需要具备互联网连接。"" msgid """" ""The neutron L2 agent does not need to be highly available. It has to be "" ""installed on each data forwarding node and controls the virtual networking "" ""drivers as Open vSwitch or Linux Bridge. One L2 agent runs per node and "" ""controls its virtual interfaces. That's why it cannot be distributed and "" ""highly available."" msgstr """" ""Neutron L2 代理服务不需要实现高可用。在所有提供数据转发的服务器上都要安装 "" ""Neutron L2 代理程序，对诸如 Open vSwitch 、Linux Bridge 等虚拟网络驱动进行管"" ""理。每台节点服务器各运行一个 L2 代理程序，负责管理该节点上的虚拟网络接口。这"" ""也是 Neutron L2 代理服务无法实现多节点分布以及高可用的原因。"" msgid """" ""The neutron L3 agent provides L3/NAT forwarding to ensure external network "" ""access for VMs on tenant networks. High availability for the L3 agent is "" ""achieved by adopting Pacemaker."" msgstr """" ""Neutron L3 代理程序负责实现 L3/NAT 转发，让运行在租户网络上的虚拟机实例能够访"" ""问外部网络。Neutron L3 代理程序实现高可用也基于 Pacemaker 。""msgid ""The result will look like this:"" msgstr ""结果将如下所示："" msgid ""Then, set the following properties:"" msgstr ""然后，设置下列属性："" msgid """" ""There are several things to note about the recommended interface "" ""configuration:"" msgstr ""在推荐的网络接口配置中有几件事需要注意："" msgid """" ""There is no native feature to make this service highly available. At this "" ""time, the Active / Passive solution exists to run the neutron metadata agent "" ""in failover mode with <application>Pacemaker</application>. See the <link "" ""linkend=\""ha-using-active-passive\"">active/passive section</link> of this "" ""guide."" msgstr """" ""Neutron 元数据代理服务自身是不支持高可用的。目前针对 Neutron L3 代理服务只有"" ""主/从模式的高可用方案通过 <application>Pacemaker</application> 可以实现失效切"" ""换。参阅本手册的 <link linkend=\""ha-using-active-passive\"">主/从模式高可用架"" ""构部分</link>。"" msgid """" ""These are some of the more common ways to implement these high availability "" ""architectures, but they are by no means the only ways to do it. The "" ""important thing is to make sure that your services are redundant, and "" ""available; how you achieve that is up to you. This document will cover some "" ""of the more common options for highly available systems."" msgstr """" ""上面提到的是较为常见的高可用实现方案，但是并非只有这些方案可以实现系统的高可"" ""用。基本原则只是保证服务冗余和可用，具体如何实现则是视需求而定的。本文档会提"" ""供如何实现高可用系统的一些通用建议。"" msgid ""This configuration creates"" msgstr ""这个配置创建"" msgid """" ""This configuration creates <literal>p_ip_api</literal>, a virtual IP address "" ""for use by the API node (<literal>192.168.42.103</literal>):"" msgstr """" ""该配置新建了一个 <literal>p_ip_mysql</literal> 资源，是 API 节点将会使用的虚"" ""拟 IP 地址（<literal>192.168.42.103</literal>）："" msgid """" ""This configuration creates <literal>p_keystone</literal>, a resource for "" ""managing the OpenStack Identity service."" msgstr """" ""该配置增加 <literal>p_keystone</literal> 资源，对 OpenStack 身份认证服务进行"" ""管理。"" msgid """" ""This configuration creates <literal>p_neutron-server</literal>, a resource "" ""for manage OpenStack Networking Server service"" msgstr """" ""该配置增加 <literal>p_neutron-server</literal> 资源，对 OpenStack 网络服务进"" ""行管理。"" msgid ""This configuration creates:"" msgstr ""该配置会创建："" msgid """" ""This guide describes how to install, configure, and manage OpenStack for "" ""high availability."" msgstr ""本手册将对如何实现 OpenStack 各服务的高可用进行说明。"" msgid """" ""This guide has gone through editorial changes to follow the OpenStack "" ""documentation conventions. Various smaller issues have been fixed."" msgstr ""本手册根据 OpenStack 文档规范进行了修订，改正了不少细微的错误。"" msgid """" ""This method does not ensure a zero downtime since it has to recreate all the "" ""namespaces and virtual routers on the node."" msgstr """" ""这种高可用方案不能实现“零停机”需求，原因是neutron L3 代理程序切换时需要重新创"" ""建网络命名空间和虚拟路由器。"" msgid """" ""This might also mean configuring any NAT firewall between nodes to allow "" ""direct connections. You might need to disable SELinux, or configure it to "" ""allow <systemitem class=\""service\"">mysqld</systemitem> to listen to sockets "" ""at unprivileged ports."" msgstr """" ""在某些环境中，可能还需要对 NAT 防火墙进行配置，以保证节点服务器之间可以直接通"" ""信。另外，可能需要禁用 SELinux，或者允许 <systemitem class=\""service"" ""\"">mysqld</systemitem> 监听非特权端口。"" msgid """" ""This resource uses an underlying local disk (in DRBD terminology, a backing "" ""device) named <filename>/dev/data/mysql</filename> on both cluster nodes, "" ""<literal>node1</literal> and <literal>node2</literal>. Normally, this would "" ""be an LVM Logical Volume specifically set aside for this purpose. The DRBD "" ""meta-disk is internal, meaning DRBD-specific metadata is being stored at the "" ""end of the disk device itself. The device is configured to communicate "" ""between IPv4 addresses <literal>10.0.42.100</literal> and "" ""<literal>10.0.42.254</literal>, using TCP port 7700. Once enabled, it will "" ""map to a local DRBD block device with the device minor number 0, that is, "" ""<filename>/dev/drbd0</filename>."" msgstr """" ""该资源使用了一块本地磁盘（DRBD 术语为“后端设备”， a backing device），该磁盘"" ""在两台节点服务器（ <literal>node1</literal> ， <literal>node2</literal> ）上"" ""对应相同的设备文件 —— <filename>/dev/data/mysql</filename> ，一 般情况下，该"" ""磁盘是一个专门为此配置的 LVM 逻辑卷。meta-disk 配置项的值是 internal，指的是 "" ""DRBD 元数据保存在后端设备的结尾（即元数据和实际数据保存在同一存储设备上）。设"" ""备数据同步通过 <literal>10.0.42.100</literal> 和 <literal>10.0.42.254</"" ""literal> 完成，使用 TCP 7700 端口。当 DRBD 资源激活之后，系统中将对应生成一"" ""个 DRBD 设备文件，次设备号为 0 ，设备文件是 <filename>/dev/drbd0</"" ""filename> 。"" msgid """" ""This resource uses an underlying local disk (in DRBD terminology, a backing "" ""device) named <filename>/dev/data/rabbitmq</filename> on both cluster nodes, "" ""<literal>node1</literal> and <literal>node2</literal>. Normally, this would "" ""be an LVM Logical Volume specifically set aside for this purpose. The DRBD "" ""meta-disk is internal, meaning DRBD-specific metadata is being stored at the "" ""end of the disk device itself. The device is configured to communicate "" ""between IPv4 addresses <literal>10.0.42.100</literal> and "" ""<literal>10.0.42.254</literal>, using TCP port 7701. Once enabled, it will "" ""map to a local DRBD block device with the device minor number 1, that is, "" ""<filename>/dev/drbd1</filename>."" msgstr """" ""该资源使用了一块本地磁盘（DRBD 术语为“后端设备”， a backing device），该磁盘"" ""在两台节点服务器（ <literal>node1</literal> ， <literal>node2</literal> ）上"" ""对应相同的设备文件 ——<filename>/dev/data/rabbitmq</filename> ，一 般情况下，"" ""该磁盘是一个专门为此配置的 LVM 逻辑卷。meta-disk 配置项的值是 internal，指的"" ""是 DRBD 元数据保存在后端设备的结尾（即元数据和实际数据保存在同一存储设备"" ""上）。设备数据同步通过 <literal>10.0.42.100</literal> 和 "" ""<literal>10.0.42.254</literal> 完成，使用 TCP 7701 端口。当 DRBD 资源激活之"" ""后，系统中将对应生成一个 DRBD 设备文件，次设备号为 1 ，设备文件是 "" ""<filename>/dev/drbd1</filename> 。"" msgid """" ""To be sure all data will be highly available, you should be sure that you "" ""store everything in the MySQL database (which is also highly available):"" msgstr """" ""为了保证所有的数据都是高可用的，应使用 MySQL 数据库服务（同样也要保证 MySQL "" ""服务是高可用的）："" msgid """" ""To do so, stop RabbitMQ everywhere and copy the cookie from the first node "" ""to the other node(s):"" msgstr """" ""因此，首先在所有节点服务器停止 RabbitMQ 服务，然后将第一台节点服务上的 "" ""cookis 文件复制到其它节点："" msgid """" ""To install and configure it, read the <link href=\""http://code.google.com/p/"" ""memcached/wiki/NewStart\""> official documentation</link>."" msgstr """" ""<application>Memcached</application> 的安装和配置，请参阅 <link href="" ""\""http://code.google.com/p/memcached/wiki/NewStart\""> 官方文档</link>。"" msgid """" ""To use highly available and scalable API services, we need to ensure that:"" msgstr ""要实现高可用和可扩展的 API 服务，需要保证："" msgid ""To verify the cluster status:"" msgstr ""检查集群状态："" msgid """" ""Typically, an active/active installation for a stateless service would "" ""maintain a redundant instance, and requests are load balanced using a "" ""virtual IP address and a load balancer such as HAProxy."" msgstr """" ""通常，无状态服务“主/主”模式的高可用会维护冗余的服务实例，同时通过虚拟 IP 地址"" ""以及负载调度程序（如 HAProxy ）对客户端的请求进行负载均衡。"" msgid """" ""Typically, an active/passive installation for a stateless service would "" ""maintain a redundant instance that can be brought online when required. "" ""Requests may be handled using a virtual IP address to facilitate return to "" ""service with minimal reconfiguration required."" msgstr """" ""通常情况下，针对无状态服务实现“主/从”模式的高可用是维护该服务的一个冗余实例，"" ""在必要时，这一实例会被激活。客户端的请求统一发送到一个虚拟的 IP 地址（该地址"" ""指向实际的后端服务），这样当发生切换时，后端服务和客户端几乎不需要进行任何改"" ""动。"" msgid ""Update your system and install the required packages: <placeholder-1/>"" msgstr ""升级您的系统并安装必要的软件包：<placeholder-1/>"" msgid ""Use HA queues in RabbitMQ (x-ha-policy: all):"" msgstr ""否使用 RabbitMMQ 的队列镜像特性（ x-ha-policy: all ）："" msgid ""Use durable queues in RabbitMQ:"" msgstr ""是否使用持久的消息队列："" msgid """" ""Verify the wsrep replication by logging in as root under mysql and running "" ""the following command:"" msgstr ""通过以root身份登录mysql并运行以下命令来确认wsrep复制：""""We consider that we run (at least) two RabbitMQ servers and we call the "" ""nodes <literal>rabbit1</literal> and <literal>rabbit2</literal>. To build a "" ""broker, we need to ensure that all nodes have the same Erlang cookie file."" msgstr """" ""示例中会布署 2 台 RabbitMQ 服务器，<literal>rabbit1</literal> 和 "" ""<literal>rabbit2</literal>。要构建一个 RabbitMQ broker 服务，必须保证所有节点"" ""服务器的 Erlang cookie 文件完全相同。"" msgid """" ""We have to configure the OpenStack components to use at least two RabbitMQ "" ""nodes."" msgstr """" ""现在可以配置 OpenStack 其它组件使用高可用 RabbitMQ 集群（最少使用其中 2 台节"" ""点服务器）。"" msgid """"""With <placeholder-1/> enabled, Corosync nodes mutually authenticate using a "" ""128-byte shared secret stored in <filename>/etc/corosync/authkey</filename>, "" ""which may be generated with the <placeholder-2/> utility. When using "" ""<placeholder-3/>, cluster communications are also encrypted.""""当启用 <placeholder-1/> 时，Corosync 节点之间通信时会使用一个 128 位的密钥进"" ""行双向认证。密钥存放在 <filename>/etc/corosync/authkey</filename> 文件中，可"" ""以通过 <placeholder-2/> 命令生成。启用 <placeholder-3/> 后，集群通信数据也会"" ""进行加密。""""Within the <placeholder-1/> directive, it is possible to specify specific "" ""information about nodes in cluster. Directive can contain only the "" ""<placeholder-2/> sub-directive, which specifies every node that should be a "" ""member of the membership, and where non-default options are needed. Every "" ""node must have at least the <placeholder-3/> field filled.""""在 <placeholder-1/> 之下可以为某一节点设置只与该节点相关的信息，这些设置项只"" ""能包含在 <placeholder-2/> 之中，即只能对属于集群的节点服务器进行设置，而且只"" ""应包括那些与默认设置不同的参数。每台服务器都必须配置 <placeholder-3/> 。"" msgid ""You also need to create the OpenStack Identity Endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。""""You can change the mirror to one near you on: <link href=\""https://downloads."" ""mariadb.org/mariadb/repositories/\"">downloads.mariadb.org</link>""""您可以改变镜像到离您最近的一个：<link href=\""https://downloads.mariadb.org/"" ""mariadb/repositories/\"">downloads.mariadb.org</link>""""You can now add the Pacemaker configuration for Block Storage API resource. "" ""Connect to the Pacemaker cluster with <literal>crm configure</literal>, and "" ""add the following cluster resources:""""现在可以在 Pacemaker 中填加 OpenStack 块设备存储服务相关资源。执行 "" ""<literal>crm configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集"" ""群资源："" msgid """" ""You can now add the Pacemaker configuration for MySQL resources. Connect to "" ""the Pacemaker cluster with <placeholder-1/>, and add the following cluster "" ""resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 MySQL 相关资源。执行 <placeholder-1/> 命令进入 "" ""Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""You can now add the Pacemaker configuration for OpenStack Identity resource. "" ""Connect to the Pacemaker cluster with <literal>crm configure</literal>, and "" ""add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 OpenStack 身份认证服务相关资源。执行 "" ""<literal>crm configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集"" ""群资源："" msgid """" ""You can now add the Pacemaker configuration for OpenStack Networking Server "" ""resource. Connect to the Pacemaker cluster with <literal>crm configure</"" ""literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 OpenStack 网络服务相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""You can now add the Pacemaker configuration for managing all network "" ""resources together with a group. Connect to the Pacemaker cluster with "" ""<literal>crm configure</literal>, and add the following cluster resources:"" msgstr """" ""创建一个资源组将所有网络服务相关资源联系起来。执行 <literal>crm configure</"" ""literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid ""You can now check the Corosync connectivity with two tools."" msgstr ""使用以下两个工具检查 Corosync 连接状态。"" msgid """" ""You may also use the alternate device path for the DRBD device, which may be "" ""easier to remember as it includes the self-explanatory resource name:"" msgstr ""也可以使用 DRBD 设备的另外一个名称，该名称有解释含义，更容易记忆："" msgid """" ""You may now proceed with adding the Pacemaker configuration for RabbitMQ "" ""resources. Connect to the Pacemaker cluster with <placeholder-1/>, and add "" ""the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 RabbitMQ 相关资源。执行 <placeholder-1/> 命令进"" ""入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""You may now proceed with adding the Pacemaker configuration for neutron DHCP "" ""agent resource. Connect to the Pacemaker cluster with <literal>crm "" ""configure</literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 neutron DHCP 代理程序相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""You may now proceed with adding the Pacemaker configuration for neutron L3 "" ""agent resource. Connect to the Pacemaker cluster with <literal>crm "" ""configure</literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 neutron L3 代理程序相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源：""""You may then proceed with adding the Pacemaker configuration for the "" ""Telemetry central agent resource. Connect to the Pacemaker cluster with """"现在可以在 Pacemaker 中填加 Telemetry 监中心相关资源。执行 <literal>crm ""msgid ""You must also create the OpenStack Image API endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。""""You must complete the next step while the MySQL database server is shut down."" msgstr ""下面的步骤在必须关闭MySQL数据库服务器之后进行。"" msgid ""You must create the Block Storage API endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid """" ""You need to create the OpenStack Networking server endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid """" ""You need to edit your OpenStack Identity configuration file "" ""(<filename>keystone.conf</filename>) and change the bind parameters:""""编辑 OpenStack 身份认证服务的配置文件（ <filename>keystone.conf</"" ""filename> ），调整以下配置项："" msgid """" ""You should see a <literal>status=joined</literal> entry for each of your "" ""constituent cluster nodes."" msgstr ""status=joined标示着每一个集群节点成员。"" msgid """" ""You use virtual IP addresses when configuring OpenStack Identity endpoints."" msgstr ""为 OpenStack 身份认证中的服务端点配置虚拟 IP 地址。"" msgid """" ""You will find at <link href=\""http://docs.openstack.org/developer/ceilometer/"" ""install/manual.html#installing-the-central-agent\"">this page</link> the "" ""process to install the Telemetry central agent."" msgstr """" ""参见 Telemtry 服务监控中心的安装<link href=\""http://docs.openstack.org/"" ""developer/ceilometer/install/manual.html#installing-the-central-agent\""> 文"" ""档 </link>。"" msgid """" ""Your OpenStack services must now point their Block Storage API configuration "" ""to the highly available, virtual cluster IP address — rather than a Block "" ""Storage API server’s physical IP address as you normally would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 块设备存"" ""储服务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""Your OpenStack services must now point their MySQL configuration to the "" ""highly available, virtual cluster IP addressrather than a MySQL server's "" ""physical IP address as you normally would."" msgstr """" ""现在可以将各 OpenStack 服务配置文件中使用物理 IP 地址的 MySQL 访问方式，更改"" ""为访问高可用、使用虚拟 IP 地址的 MySQL 服务。"" msgid """" ""Your OpenStack services must now point their OpenStack Identity "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than a OpenStack Identity server’s physical IP address as you normally would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 身份认证"" ""服务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""Your OpenStack services must now point their OpenStack Image API "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than an OpenStack Image API server’s physical IP address as you normally "" ""would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 镜像服"" ""务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""Your OpenStack services must now point their OpenStack Networking Server "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than an OpenStack Networking server’s physical IP address as you normally "" ""would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 网络服"" ""务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""Your OpenStack services must now point their RabbitMQ configuration to the "" ""highly available, virtual cluster IP addressrather than a RabbitMQ server's "" ""physical IP address as you normally would."" msgstr """" ""现在可以将各 OpenStack 服务配置文件中使用物理 IP 地址的 RabbitMQ 访问方式，更"" ""改为访问高可用、使用虚拟 IP 地址的 RabbitMQ 服务。"" msgid """" ""a service <literal>group</literal> and <literal>order</literal> and "" ""<literal>colocation</literal> constraints to ensure resources are started on "" ""the correct nodes, and in the correct sequence."" msgstr ""资源组以及顺序、协同约束条件，会确保资源在正确的节点安照正确次序启动。"" msgid """" ""a service group and order and colocation constraints to ensure resources are "" ""started on the correct nodes, and in the correct sequence."" msgstr ""资源组以及顺序、协同约束条件，会确保资源在正确的节点安照正确次序启动。"" msgid ""ceilometer-collector"" msgstr ""ceilometer-collector"" msgid ""cinder-scheduler"" msgstr ""cinder-scheduler"" msgid ""cluster-glue"" msgstr ""cluster-glue"" msgid ""configuring RabbitMQ to listen on that IP address,"" msgstr ""配置 RabbitMQ 监听该 IP 地址，"" msgid """" ""configuring RabbitMQ to use a data directory residing on that DRBD device,"" msgstr ""配置 RabbitMQ 使用建立在 DRBD 设备之上的数据目录，"" msgid ""configuring a DRBD device for use by RabbitMQ,"" msgstr ""为 RabbitMQ 配置一个 DRBD 设备"" msgid ""corosync"" msgstr ""corosync"" msgid ""crmsh"" msgstr ""crmsh"" msgid ""current"" msgstr ""current"" msgid ""heat-engine"" msgstr ""heat-engine"" msgid ""l3_ha"" msgstr ""l3_ha"" msgid """" ""managing all resources, including the RabbitMQ daemon itself, with the "" ""Pacemaker cluster manager."" msgstr ""使用 Pacemaker 管理上述所有资源，包括 RabbitMQ 守护进程本身。"" msgid ""max_l3_agents_per_router"" msgstr ""max_l3_agents_per_router"" msgid ""min_l3_agents_per_router"" msgstr ""min_l3_agents_per_router"" msgid ""neutron-server"" msgstr ""neutron-server"" msgid ""nova-conductor"" msgstr ""nova-conductor"" msgid ""nova-scheduler"" msgstr ""nova-scheduler"" msgid ""resource-agents"" msgstr ""resource-agents"" msgid """" ""selecting and assigning a virtual IP address (VIP) that can freely float "" ""between cluster nodes,"" msgstr ""选择并绑定一个可以在各集群节点之间迁移的虚拟 IP 地址 （即 VIP ），""","""POT-Creation-Date: 2015-05-06 19:56+0000\n"" ""PO-Revision-Date: 2015-05-06 19:56+0000\n""msgid ""Cloud controller cluster stack"" msgstr ""OpenStack 控制服务 HA 集群配置""""The cloud controller runs on the management network and must talk to all "" ""other services.""""OpenStack 控制服务运行在管理网络上，可以和其它任何 OpenStack 服务进行交互。"" msgid ""OpenStack network nodes"" msgstr ""OpenStack 网络节点服务器"" msgid ""OpenStack network nodes contain:"" msgstr ""OpenStack 网络节点运行以下服务："" msgid ""Neutron DHCP agent"" msgstr ""Neutron DHCP 代理服务"" msgid ""Neutron L2 agent"" msgstr ""Neutron L2 代理服务"" msgid ""Neutron L3 agent"" msgstr ""Neutron L3 代理服务"" msgid ""Neutron metadata agent"" msgstr ""Neutron 元数据代理服务"" msgid ""Neutron LBaaS agent"" msgstr ""Neutron LBaas 代理服务""""The neutron L2 agent does not need to be highly available. It has to be "" ""installed on each data forwarding node and controls the virtual networking "" ""drivers as Open vSwitch or Linux Bridge. One L2 agent runs per node and "" ""controls its virtual interfaces. That's why it cannot be distributed and "" ""highly available.""""Neutron L2 代理服务不需要实现高可用。在所有提供数据转发的服务器上都要安装 "" ""Neutron L2 代理程序，对诸如 Open vSwitch 、Linux Bridge 等虚拟网络驱动进行管"" ""理。每台节点服务器各运行一个 L2 代理程序，负责管理该节点上的虚拟网络接口。这"" ""也是 Neutron L2 代理服务无法实现多节点分布以及高可用的原因。"" msgid ""The Pacemaker cluster stack"" msgstr ""Packmaker 集群""""OpenStack infrastructure high availability relies on the <link href=\""http://"" ""www.clusterlabs.org\"">Pacemaker</link> cluster stack, the state-of-the-art "" ""high availability and load balancing stack for the Linux platform. Pacemaker "" ""is storage and application-agnostic, and is in no way specific to OpenStack.""""OpenStack 基础服务的高可用基于 <link href=\""http://www.clusterlabs.org"" ""\"">Pacemaker</link> 实现（ Pacemaker 是 Linux 系统平台上常见的高可用和负载均"" ""衡组件）。 Packermaker 是通用的高可用组件，不限于特定的应用程序或者存储设备，"" ""也不是专用于 OpenStack 项目的。""""Pacemaker relies on the <link href=\""http://www.corosync.org\"">Corosync</"" ""link> messaging layer for reliable cluster communications. Corosync "" ""implements the Totem single-ring ordering and membership protocol. It also "" ""provides UDP and InfiniBand based messaging, quorum, and cluster membership "" ""to Pacemaker.""""Pacemaker 使用 <link href=\""http://www.corosync.org\"">Corosync</link> 作为消"" ""息传输层，以实现集群内部通信的可靠性。Corosync 通过 Totem 协议来维护集群通信"" ""的消息序列以及集群成员变动，支持通过 UDP 或 InfiniBand 传输消息，为 "" ""Pacemaker 提供集群成员以及合法节点等信息。"" msgid ""RabbitMQ"" msgstr ""RabbitMQ""""RabbitMQ is the default AMQP server used by many OpenStack services. Making "" ""the RabbitMQ service highly available involves the following steps:""""RabbitMQ 是多数 OpenStack 服务的默认 AMQP 服务程序。实现 RabbitMQ 的高可用包"" ""括以下步骤："" msgid ""Install RabbitMQ"" msgstr ""安装 RabbitMQ"" msgid ""Configure RabbitMQ for HA queues"" msgstr ""配置 RabbitMQ 实现高可用的消息队列"" msgid ""Configure OpenStack services to use Rabbit HA queues"" msgstr ""配置其它 OpenStack 服务使用高可用的 RabbitMQ 服务"" msgid ""Introduction to OpenStack High Availability"" msgstr ""OpenStack高可用介绍"" msgid ""High Availability systems seek to minimize two things:"" msgstr ""实现系统高可用是为了减少以下 2 种异常情况："" msgid ""System downtime"" msgstr ""系统停机""""Occurs when a user-facing service is unavailable beyond a specified maximum "" ""amount of time."" msgstr ""面向客户的服务无法正常工作的时间超出服务承诺的上限。"" msgid ""Data loss"" msgstr ""数据丢失"" msgid ""Accidental deletion or destruction of data."" msgstr ""意外发生的数据删除和数据损坏。"" msgid """" ""Most high availability systems guarantee protection against system downtime "" ""and data loss only in the event of a single failure. However, they are also "" ""expected to protect against cascading failures, where a single failure "" ""deteriorates into a series of consequential failures.""""大多数的高可用系统只能在发生单一故障的情况下为降低停机时间和避免数据丢失提供"" ""保障。但是用户也期望高可用系统同样能够处理由单一故障演变为一系列连锁故障的情"" ""况。""msgid ""Network components, such as switches and routers"" msgstr ""网络设备，如交换机、路由器；"" msgid ""Applications and automatic service migration"" msgstr ""应用程序以及服务自动迁移工具；"" msgid ""Storage components"" msgstr ""存储设备；"" msgid ""Facility services such as power, air conditioning, and fire protection"" msgstr ""辅助设施，如电源、空调、防火等；"" ""Most high availability systems will fail in the event of multiple "" ""independent (non-consequential) failures. In this case, most systems will "" ""protect data over maintaining availability.""""大多数高可用系统都无法应对发生一连串不相关故障的情况，此时保护数据优先于保证"" ""系统的高可用性。"" msgid """" ""High-availability systems typically achieve an uptime percentage of 99.99% "" ""or more, which roughly equates to less than an hour of cumulative downtime "" ""per year. In order to achieve this, high availability systems should keep "" ""recovery times after a failure to about one to two minutes, sometimes "" ""significantly less."" msgstr """" ""通常，高可用系统能够保证 99.99% 的在线时间，相当于一年之中发生系统故障的累积"" ""时间不超过 1 个小时。要达到这一目标，高可用系统应将故障恢复时间控制在 1 ～ 2 "" ""分钟之内甚至更短。"" msgid """" ""OpenStack currently meets such availability requirements for its own "" ""infrastructure services, meaning that an uptime of 99.99% is feasible for "" ""the OpenStack infrastructure proper. However, OpenStack does not guarantee "" ""99.99% availability for individual guest instances."" msgstr """" ""OpenStack 的基础服务，在合理配置的情况下，能够满足上述 99.99% 在线时间的高可"" ""用性要求。但是 OpenStack 不能保证单个虚拟机实例的 99.99% 在线时间。"" msgid """" ""Preventing single points of failure can depend on whether or not a service "" ""is stateless."" msgstr ""避免单点故障的方法根据该服务是否属于无状态类型而有所不同。"" msgid ""Stateless vs. Stateful services"" msgstr ""无状态和有状态服务""""A stateful service is one where subsequent requests to the service depend on "" ""the results of the first request. Stateful services are more difficult to "" ""manage because a single action typically involves more than one request, so "" ""simply providing additional instances and load balancing will not solve the "" ""problem. For example, if the Horizon user interface reset itself every time "" ""you went to a new page, it wouldn't be very useful. OpenStack services that "" ""are stateful include the OpenStack database and message queue."" msgstr """" ""有状态服务，是指客户端发送的后续请求依赖于之前相关请求的处理结果。由于单独一"" ""项操作可能涉及若干相关请求，有状态服务相对难于管理，只是通过多个实例和负载均"" ""衡无法实现高可用。例如，如果每次访问 Horizon 时都是打开一个全新的页面（之前的"" ""操作都消失了），对于用户来说是毫无意义的。OpenStack 中有状态服务包括 "" ""OpenStack 数据库和消息队列。"" msgid """" ""Making stateful services highly available can depend on whether you choose "" ""an active/passive or active/active configuration."" msgstr ""实现有状态服务高可用的方案有“主/从”和“主/主” 2 种模式。"" msgid ""Active/Passive"" msgstr ""主/从"" msgid """" ""In an active/passive configuration, systems are set up to bring additional "" ""resources online to replace those that have failed. For example, OpenStack "" ""would write to the main database while maintaining a disaster recovery "" ""database that can be brought online in the event that the main database "" ""fails."" msgstr """" ""在“主/从”模式中，当系统中的资源失效时，新的资源会被激活，替代失效部份继续提供"" ""服务。例如，在 OpenStack 集群中，可以在主数据库之外维护一套灾备数据库，当主数"" ""据库发生故障时，激活灾备数据库可以保证集群继续正常运行。"" msgid """" ""Typically, an active/passive installation for a stateless service would "" ""maintain a redundant instance that can be brought online when required. "" ""Requests may be handled using a virtual IP address to facilitate return to "" ""service with minimal reconfiguration required."" msgstr """" ""通常情况下，针对无状态服务实现“主/从”模式的高可用是维护该服务的一个冗余实例，"" ""在必要时，这一实例会被激活。客户端的请求统一发送到一个虚拟的 IP 地址（该地址"" ""指向实际的后端服务），这样当发生切换时，后端服务和客户端几乎不需要进行任何改"" ""动。"" msgid """" ""A typical active/passive installation for a stateful service maintains a "" ""replacement resource that can be brought online when required. A separate "" ""application (such as Pacemaker or Corosync) monitors these services, "" ""bringing the backup online as necessary."" msgstr """" ""有状态服务的“主/从”模式高可用则是维护一套额外的备份资源，当故障发生时，可以直"" ""接替代失效部份继续工作。单独的应用程序（如 Pacemaker 、Corosync 等）负责监控"" ""各项服务，并在发生故障时激活备份资源。"" msgid ""Active/Active"" msgstr ""主/主"" msgid """" ""In an active/active configuration, systems also use a backup but will manage "" ""both the main and redundant systems concurrently. This way, if there is a "" ""failure the user is unlikely to notice. The backup system is already online, "" ""and takes on increased load while the main system is fixed and brought back "" ""online."" msgstr """" ""在“主/主”模式中，服务的冗余实例和主实例会同时工作。这样主实例发生故障，不会对"" ""用户产生影响，因为冗余实例一直处于在线状态，后续客户端的请求直接由冗余实例处"" ""理，而主实例的故障恢复可以同步进行。"" msgid """" ""Typically, an active/active installation for a stateless service would "" ""maintain a redundant instance, and requests are load balanced using a "" ""virtual IP address and a load balancer such as HAProxy."" msgstr """" ""通常，无状态服务“主/主”模式的高可用会维护冗余的服务实例，同时通过虚拟 IP 地址"" ""以及负载调度程序（如 HAProxy ）对客户端的请求进行负载均衡。"" msgid """"""These are some of the more common ways to implement these high availability "" ""architectures, but they are by no means the only ways to do it. The "" ""important thing is to make sure that your services are redundant, and "" ""available; how you achieve that is up to you. This document will cover some "" ""of the more common options for highly available systems.""""上面提到的是较为常见的高可用实现方案，但是并非只有这些方案可以实现系统的高可"" ""用。基本原则只是保证服务冗余和可用，具体如何实现则是视需求而定的。本文档会提"" ""供如何实现高可用系统的一些通用建议。"" msgid ""OpenStack High Availability Guide"" msgstr ""OpenStack高可用指南"" msgid ""OpenStack Contributors"" msgstr ""OpenStack贡献者"" msgid ""2012"" msgstr ""2012"" msgid ""2013"" msgstr ""2013"" msgid ""2014"" msgstr ""2014"" msgid ""current"" msgstr ""current"" msgid ""OpenStack"" msgstr ""OpenStack""msgid """" ""This guide describes how to install, configure, and manage OpenStack for "" ""high availability."" msgstr ""本手册将对如何实现 OpenStack 各服务的高可用进行说明。"" msgid ""2014-10-17"" msgstr ""2014-10-17""""This guide has gone through editorial changes to follow the OpenStack "" ""documentation conventions. Various smaller issues have been fixed."" msgstr ""本手册根据 OpenStack 文档规范进行了修订，改正了不少细微的错误。"" msgid ""2014-05-16"" msgstr ""2014-05-16"" msgid ""2014-04-17"" msgstr ""2014-04-17""msgid ""2012-01-16"" msgstr ""2012-01-16"" msgid ""Organizes guide based on cloud controller and compute nodes."" msgstr ""本指南将介绍如何安装控制节点和计算节点"" msgid ""2012-05-24"" msgstr ""2012-05-24"" msgid ""Begin trunk designation."" msgstr ""开始主干指定。""""The network controller sits on the management and data network, and needs to "" ""be connected to the Internet if an instance will need access to the Internet.""""网络控制节点运行在管理网络和数据网络中，如果虚拟机实例要连接到互联网，网络控"" ""制节点也需要具备互联网连接。""msgid ""HAProxy nodes"" msgstr ""HAProxy 节点服务器""""For installing HAProxy on your nodes, you should consider its <link href="" ""\""http://haproxy.1wt.eu/#docs\"">official documentation</link>. Also, you "" ""have to consider that this service should not be a single point of failure, "" ""so you need at least two nodes running HAProxy.""""HAProxy 的安装，请参阅项目<link href=\""http://haproxy.1wt.eu/#docs\"">官方文档"" ""</link>。别外，为了避免 HAProxy 本身成为整个系统的单点故障，最少应配置 2 台 "" ""HAProxy 节点服务器。"" msgid ""Here is an example of the HAProxy configuration file:"" msgstr ""下面是 HAProxy 配置文件的示例："" msgid ""After each change of this file, you should restart HAProxy."" msgstr ""每次修改配置文件之后，必须重启 HAProxy 服务。"" msgid ""OpenStack controller nodes"" msgstr ""OpenStack 控制节点服务器"" msgid ""OpenStack controller nodes contain:"" msgstr ""OpenStack 控制节点服务器上运行以下服务："" msgid ""All OpenStack API services"" msgstr ""所有 OpenStack API 服务"" msgid ""All OpenStack schedulers"" msgstr ""所有 OpenStack 调度相关的服务"" msgid ""<application>Memcached</application> service"" msgstr ""<application>Memcached</application> 服务"" msgid ""HA using active/passive"" msgstr ""主/从模式高可用集群"" msgid ""API node cluster stack"" msgstr ""API 服务节点 HA 集群配置""""The API node exposes OpenStack API endpoints onto external network "" ""(Internet). It must talk to the cloud controller on the management network."" msgstr """" ""API 服务节点对外（整个互联网）提供 OpenStack API 接口。它们通过管理网络和 "" ""OpenStack 控制节点进行交互。"" msgid ""Database"" msgstr ""数据库""""The choice of database isn't a foregone conclusion; you're not required to "" ""use <application>MySQL</application>. It is, however, a fairly common choice "" ""in OpenStack installations, so we'll cover it here.""""<application>MySQL</application> 并不是唯一的选择，以它作为示例是因为目前已有"" ""的 OpenStack 布署案例中，使用 <application>MySQL</application> 作为数据库比较"" ""常见。""""MySQL with Galera is by no means the only way to achieve database HA. "" ""MariaDB Galera Cluster (<link href=\""https://mariadb.org/\"">https://mariadb."" ""org/</link>) and Percona XtraDB Cluster (<link href=\""http://www.percona.com/"" ""\"">http://www.percona.com/</link>) also work with Galera. You also have the "" ""option to use PostgreSQL, which has its own replication, or another database "" ""HA option.""""同样，MySQL + Galera 也并非唯一一种实现数据库高可用的方案。MariaDB Galera 集"" ""群(<link href=\""https://mariadb.org/\"">https://mariadb.org/</link>) 和 "" ""Percona XtraDB 集群(<link href=\""http://www.percona.com/\"">http://www."" ""percona.com/</link>) 都可以和 Galera 一起配置使用。另外 OpenStack 也支持 "" ""PostgreSQL，PostgreSQL 有自己相应的数据镜像和高可用方案。"" msgid ""HA using active/active"" msgstr ""主/主模式高可用集群"" msgid ""MySQL with Galera"" msgstr ""MySQL 和 Galera""""Note that the installation requirements call for careful attention. Read the "" ""guide <link href=\""https://launchpadlibrarian.net/66669857/README-wsrep"" ""\"">https://launchpadlibrarian.net/66669857/README-wsrep</link> to ensure you "" ""follow all the required steps."" msgstr """" ""请仔细阅读 Wresp API 的安装说明 —— <link href=\""https://launchpadlibrarian."" ""net/66669857/README-wsrep\"">https://launchpadlibrarian.net/66669857/README-"" ""wsrep</link>，并按要求完成安装。"" msgid """" ""And for any additional information about Galera, you can access this guide: "" ""<link href=\""http://galeracluster.com/documentation-webpages/gettingstarted."" ""html\"">http://galeracluster.com/documentation-webpages/gettingstarted.html</"" ""link>"" msgstr """" ""更多关于 Galera 的信息，请参阅：<link href=\""http://galeracluster.com/"" ""documentation-webpages/gettingstarted.html\"">http://galeracluster.com/"" ""documentation-webpages/gettingstarted.html</link>"" msgid ""Installing Galera through a MySQL version patched for wsrep:"" msgstr ""为已经加上 wresp 补丁的 MySQL 数据库安装 Galera ："" msgid """" ""You can change the mirror to one near you on: <link href=\""https://downloads."" ""mariadb.org/mariadb/repositories/\"">downloads.mariadb.org</link>"" msgstr """" ""您可以改变镜像到离您最近的一个：<link href=\""https://downloads.mariadb.org/"" ""mariadb/repositories/\"">downloads.mariadb.org</link>"" msgid ""Update your system and install the required packages: <placeholder-1/>"" msgstr ""升级您的系统并安装必要的软件包：<placeholder-1/>"" msgid """" ""If you have mariaDB already installed you need to re-apply all the "" ""permissions from the installation guide. It will purge all privileges!"" msgstr """" ""如果您已经安装了mariaDB，您需要重新申请安装指南中的所有权限。此将清理所有的权"" ""限！"" msgid ""Adjust the configuration:"" msgstr ""调整配置文件："" msgid """" ""In the <filename>/etc/mysql/my.conf</filename> file, make the following "" ""changes:"" msgstr ""在<filename>/etc/mysql/my.conf</filename>文件中，进行如下修改："" msgid ""Create the <filename>/etc/mysql/conf.d/wsrep.cnf</filename> file."" msgstr ""创建<filename>/etc/mysql/conf.d/wsrep.cnf</filename>文件"" msgid ""Paste the following lines in this file:"" msgstr ""将如下内容粘贴到文件中："" msgid ""PRIMARY_NODE_IP"" msgstr ""PRIMARY_NODE_IP"" msgid ""SECONDARY_NODE_IP"" msgstr ""SECONDARY_NODE_IP"" msgid ""NODE_NAME"" msgstr ""NODE_NAME""msgid """" ""Copy this file to all other databases servers and change the value of "" ""<literal>wsrep_cluster_address</literal> and <literal>wsrep_node_name</"" ""literal> accordingly."" msgstr """" ""将此文件拷贝到所有的其他数据库服务器上并相应的修改"" ""<literal>wsrep_cluster_address</literal> 和<literal>wsrep_node_name</literal>"" ""的值。"" msgid ""Start mysql as root and execute the following queries:"" msgstr ""使用root启动mysql并执行以下查询："" msgid ""Remove user accounts with empty user names because they cause problems:"" msgstr ""删除所有用户名为空的 MySQL 帐户（这些帐户会产生安全隐患）："" msgid """" ""Check that the nodes can access each other through the firewall. Depending "" ""on your environment, this might mean adjusting iptables, as in:"" msgstr """" ""检查各节点之间的网络通信有没有被防火墙拦截。根据布署环境的不同，检查方法也各"" ""不相同。如，某些环境中，这一步只需要对 iptables 进行配置："" msgid """" ""This might also mean configuring any NAT firewall between nodes to allow "" ""direct connections. You might need to disable SELinux, or configure it to "" ""allow <systemitem class=\""service\"">mysqld</systemitem> to listen to sockets "" ""at unprivileged ports."" msgstr """" ""在某些环境中，可能还需要对 NAT 防火墙进行配置，以保证节点服务器之间可以直接通"" ""信。另外，可能需要禁用 SELinux，或者允许 <systemitem class=\""service"" ""\"">mysqld</systemitem> 监听非特权端口。"" msgid """" ""After the copy make sure that all files are the same, you can do this by "" ""using the following command:"" msgstr ""复制之后需确保所有的文件都是相同的，你能通过使用如下命令确认："" msgid ""From the <filename>debian.cnf</filename> get the database password:"" msgstr ""从<filename>debian.cnf</filename>中获取数据库密码："" msgid ""The result will look like this:"" msgstr ""结果将如下所示："" msgid """" ""Stop all the mysql servers and start the first server with the following "" ""command:"" msgstr ""停止所有的mysql服务器然后使用如下命令启动第一个服务器："" msgid ""All other nodes can now be started using:"" msgstr ""其他所有节点现在能被启动："" msgid """" ""Verify the wsrep replication by logging in as root under mysql and running "" ""the following command:"" msgstr ""通过以root身份登录mysql并运行以下命令来确认wsrep复制："" msgid ""PASSWORD"" msgstr ""密码"" msgid ""Run neutron L3 agent"" msgstr ""运行 neutron L3 代理服务"" msgid ""Option"" msgstr ""选项"" msgid ""Description"" msgstr ""描述"" msgid ""l3_ha"" msgstr ""l3_ha"" msgid ""max_l3_agents_per_router"" msgstr ""max_l3_agents_per_router"" msgid ""2"" msgstr ""2"" msgid ""min_l3_agents_per_router"" msgstr ""min_l3_agents_per_router"" msgid ""Run neutron metadata agent"" msgstr ""运行 neutron 元数据代理服务"" msgid """" ""There is no native feature to make this service highly available. At this "" ""time, the Active / Passive solution exists to run the neutron metadata agent "" ""in failover mode with <application>Pacemaker</application>. See the <link "" ""linkend=\""ha-using-active-passive\"">active/passive section</link> of this "" ""guide."" msgstr """" ""Neutron 元数据代理服务自身是不支持高可用的。目前针对 Neutron L3 代理服务只有"" ""主/从模式的高可用方案通过 <application>Pacemaker</application> 可以实现失效切"" ""换。参阅本手册的 <link linkend=\""ha-using-active-passive\"">主/从模式高可用架"" ""构部分</link>。""msgid """" ""The OpenStack Networking service has a scheduler that lets you run multiple "" ""agents across nodes. Also, the DHCP agent can be natively highly available. "" ""You can configure the number of DHCP agents per network using the parameter "" ""<placeholder-1/> in <filename>neutron.conf</filename>. By default this is "" ""equal to 1. To achieve high availability assign more than one DHCP agent per "" ""network."" msgstr """" ""OpenStack 网络服务拥有一个调度程序，所有可以在多个节点同时运行各种代理程序。"" ""同样，DHCP 代理服务自身就是支持高可用的。每个网络使用多少 DHCP 代理程序是可以"" ""通过配置文件 <filename>neutron.conf</filename> 中的 <placeholder-1/> 进行配置"" ""的。默认值是 1 ，要实现 DHCP 代理服务的高可用，应为每个网络设置多个 DHCP 代理"" ""程序。""msgid ""Highly available Block Storage API"" msgstr ""高可用 OpenStack 块设备存储服务"" msgid """" ""Making the Block Storage (cinder) API service highly available in active / "" ""passive mode involves:"" msgstr ""使得块存储(cinder)API服务在主/被模式中高可用包括:"" msgid ""Configuring Block Storage to listen on the VIP address"" msgstr ""配置块存储监听于VIP地址"" msgid ""Managing Block Storage API daemon with the Pacemaker cluster manager"" msgstr ""使用 Pacemaker 管理 OpenStack 块设备存储服务"" msgid ""Configuring OpenStack services to use this IP address"" msgstr ""使用该 IP 地址配置 OpenStack 服务"" msgid ""Add Block Storage API resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 块设备存储服务资源"" msgid ""First of all, you need to download the resource agent to your system:"" msgstr ""首先，下载 Pacemaker 资源代理："" msgid """" ""You can now add the Pacemaker configuration for Block Storage API resource. "" ""Connect to the Pacemaker cluster with <literal>crm configure</literal>, and "" ""add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 OpenStack 块设备存储服务相关资源。执行 "" ""<literal>crm configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集"" ""群资源："" msgid ""This configuration creates"" msgstr ""这个配置创建"" msgid """" ""<literal>p_cinder-api</literal>, a resource for manage Block Storage API "" ""service"" msgstr """" ""<literal>p_cinder-api</literal> 资源，对 OpenStack 身份认证服务进行管理。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_cinder-"" ""api</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_cinder-api</literal>，编辑资源以匹配可"" ""供使用的虚拟IP地址。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the Block Storage API service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 块设备存储存服务（包括所有相关资源）。"" msgid ""Configure Block Storage API service"" msgstr ""配置 OpenStack 块设备存储服务"" msgid ""Edit <filename>/etc/cinder/cinder.conf</filename>:"" msgstr ""编辑 <filename>/etc/cinder/cinder.conf</filename>："" msgid ""Configure OpenStack services to use highly available Block Storage API"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 块设备存储服务"" msgid """" ""Your OpenStack services must now point their Block Storage API configuration "" ""to the highly available, virtual cluster IP address — rather than a Block "" ""Storage API server’s physical IP address as you normally would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 块设备存"" ""储服务，而不在使用其所在服务器的物理 IP 地址。"" msgid ""You must create the Block Storage API endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid """" ""If you are using both private and public IP, you should create two Virtual "" ""IPs and define your endpoint like this:"" msgstr """" ""如果要同时使用私有和公开的 IP 地址，需要创建两个虚拟 IP 地址资源，并建立类似"" ""如下的服务端点："" msgid ""Configure Pacemaker group"" msgstr ""配置 Pacemaker 资源组"" msgid """" ""Finally, we need to create a service <literal>group</literal> to ensure that "" ""the virtual IP is linked to the API services resources:"" msgstr """" ""最后，创建一个资源组 <literal>group</literal>，将所有 API 服务资源和该虚拟 "" ""IP 地址联系起来。"" msgid ""Highly available OpenStack Image API"" msgstr ""高可用 OpenStack 镜像 API 服务"" msgid ""Configure OpenStack services to use this IP address."" msgstr ""配置 OpenStack 服务使用该虚拟 IP 地址。"" msgid ""Add OpenStack Image API resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 镜像服务资源"" msgid """" ""<literal>p_glance-api</literal>, a resource for managing OpenStack Image API "" ""service"" msgstr ""<literal>p_glance-api</literal> 资源，对 OpenStack 镜像服务进行管理。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live Pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_glance-"" ""api</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_glance-api</literal>，编辑资源以匹配可"" ""供使用的虚拟IP地址。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Image API service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 镜像服务（包括所有相关资源）。"" msgid ""Edit <filename>/etc/glance/glance-api.conf</filename>:"" msgstr ""编辑 <filename>/etc/glance/glance-api.conf</filename>："" msgid ""Configure OpenStack services to use high available OpenStack Image API"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack镜像服务"" msgid """" ""Your OpenStack services must now point their OpenStack Image API "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than an OpenStack Image API server’s physical IP address as you normally "" ""would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 镜像服"" ""务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""For OpenStack Compute, for example, if your OpenStack Image API service IP "" ""address is <literal>192.168.42.103</literal> as in the configuration "" ""explained here, you would use the following configuration in your "" ""<filename>nova.conf</filename> file:"" msgstr """" ""以 OpenStack 计算服务为例，如果 OpenStack 镜像服务的虚拟 IP 地址是 "" ""<literal>192.168.42.103</literal>，那么在 OpenStack 计算服务的配置文件"" ""（ <filename>nova.conf</filename> ）中应该使用如下配置："" msgid """" ""In versions prior to Juno, this option was called "" ""<literal>glance_api_servers</literal> in the <literal>[DEFAULT]</literal> "" ""section."" msgstr """" ""对于 Juno 之前的版本，该配置项对应的是 <literal>[DEFAULT]</literal> 段之下的 "" ""<literal>glance_api_servers</literal>。"" msgid ""You must also create the OpenStack Image API endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid """" ""If you are using both private and public IP addresses, you should create two "" ""Virtual IP addresses and define your endpoint like this:"" msgstr """" ""如果要同时使用私有和公开的 IP 地址，需要创建两个虚拟 IP 地址资源，并建立类似"" ""如下的服务端点："" msgid ""Highly available OpenStack Networking server"" msgstr ""高可用 OpenStack 网络服务"" msgid """" ""OpenStack Networking is the network connectivity service in OpenStack. "" ""Making the OpenStack Networking Server service highly available in active / "" ""passive mode involves the following tasks:"" msgstr """" ""OpenStack 网络服务为 OpenStack 集群提供网络基础服务。实现 OpenStack 网络服务"" ""主/从模式的高可用包括以下步骤："" msgid ""Configure OpenStack Networking to listen on the virtual IP address,"" msgstr ""配置 OpenStack 网络服务监听虚拟 IP 地址，"" msgid """" ""Manage the OpenStack Networking API Server daemon with the Pacemaker cluster "" ""manager,"" msgstr ""使用 Pacemaker 管理 OpenStack 网络服务，"" msgid ""Configure OpenStack services to use the virtual IP address."" msgstr ""配置 OpenStack 服务使用该虚拟 IP 地址。"" msgid ""Add OpenStack Networking Server resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 网络服务资源"" msgid """" ""You can now add the Pacemaker configuration for OpenStack Networking Server "" ""resource. Connect to the Pacemaker cluster with <literal>crm configure</"" ""literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 OpenStack 网络服务相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""This configuration creates <literal>p_neutron-server</literal>, a resource "" ""for manage OpenStack Networking Server service"" msgstr """" ""该配置增加 <literal>p_neutron-server</literal> 资源，对 OpenStack 网络服务进"" ""行管理。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_neutron-"" ""server</literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_keystone</literal>，编辑资源以匹配可供"" ""使用的虚拟IP地址"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Networking API service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动"" ""OpenStack 网络服务（包括所有相关资源）。"" msgid ""Configure OpenStack Networking server"" msgstr ""配置 OpenStack 网络服务"" msgid ""Edit <filename>/etc/neutron/neutron.conf</filename>:"" msgstr ""编辑 <filename>/etc/neutron/neutron.conf</filename>："" msgid """" ""Configure OpenStack services to use highly available OpenStack Networking "" ""server"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 网络服务"" msgid """" ""Your OpenStack services must now point their OpenStack Networking Server "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than an OpenStack Networking server’s physical IP address as you normally "" ""would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 网络服"" ""务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""For example, you should configure OpenStack Compute for using highly "" ""available OpenStack Networking server in editing <literal>nova.conf</"" ""literal> file:"" msgstr """" ""以 OpenStack 计算服务为例，在 OpenStack 计算服务的配置文件（ <literal>nova."" ""conf</literal> ）中应该使用如下配置："" msgid """" ""You need to create the OpenStack Networking server endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid ""Highly available Telemetry central agent"" msgstr ""高可用 Telemetry 监控代理"" msgid """" ""Telemetry (ceilometer) is the metering and monitoring service in OpenStack. "" ""The Central agent polls for resource utilization statistics for resources "" ""not tied to instances or compute nodes."" msgstr """" ""Telemtry （ ceilometer ）是 OpenStack 系统中的计量和监控服务。监控中心收集包"" ""括虚拟机实例和计算节点在内各种资源的使用情况。"" msgid """" ""Making the Telemetry central agent service highly available in active / "" ""passive mode involves managing its daemon with the Pacemaker cluster manager."" msgstr """" ""Telemetry 监控中心的主/从模式高可用是通过 Pacemaker 管理其后台守护进程实现。"" msgid """" ""You will find at <link href=\""http://docs.openstack.org/developer/ceilometer/"" ""install/manual.html#installing-the-central-agent\"">this page</link> the "" ""process to install the Telemetry central agent."" msgstr """" ""参见 Telemtry 服务监控中心的安装<link href=\""http://docs.openstack.org/"" ""developer/ceilometer/install/manual.html#installing-the-central-agent\""> 文"" ""档 </link>。"" msgid ""Add the Telemetry central agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 Telemetry 监控中心资源"" msgid """" ""You may then proceed with adding the Pacemaker configuration for the "" ""Telemetry central agent resource. Connect to the Pacemaker cluster with "" ""<literal>crm configure</literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 Telemetry 监中心相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""<literal>p_ceilometer-agent-central</literal>, a resource for managing the "" ""Ceilometer Central Agent service"" msgstr """" ""<literal>p_ceilometer-agent-central</literal>, 用来管理 Ceilometer 监控代理服"" ""务的资源 "" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the Ceilometer Central Agent service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 "" ""Telemetry 监控中心（包括所有相关资源）。"" msgid ""Configure Telemetry central agent service"" msgstr ""配置 Telemetry 监中心"" msgid ""Edit <filename>/etc/ceilometer/ceilometer.conf</filename>:"" msgstr ""编辑 <filename>/etc/ceilometer/ceilometer.conf</filename>："" msgid ""Highly available OpenStack Identity"" msgstr ""高可用 OpenStack 身份认证服务"" msgid """" ""OpenStack Identity is the Identity Service in OpenStack and used by many "" ""services. Making the OpenStack Identity service highly available in active / "" ""passive mode involves"" msgstr """" ""OpenStack 身份认证服务被很多其他服务使用。实现 OpenStack 身份认证服务主/从模"" ""式的高可用包括以下步骤："" msgid ""Configure OpenStack Identity to listen on the VIP address,"" msgstr ""配置 OpenStack 身份认证服务监听虚拟 IP 地址，"" msgid ""Managing OpenStack Identity daemon with the Pacemaker cluster manager,"" msgstr ""使用 Pacemaker 管理 OpenStack 身份认证服务，"" msgid ""Add OpenStack Identity resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 OpenStack 认证服务资源"" msgid """" ""You can now add the Pacemaker configuration for OpenStack Identity resource. "" ""Connect to the Pacemaker cluster with <literal>crm configure</literal>, and "" ""add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 OpenStack 身份认证服务相关资源。执行 "" ""<literal>crm configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集"" ""群资源："" msgid """" ""This configuration creates <literal>p_keystone</literal>, a resource for "" ""managing the OpenStack Identity service."" msgstr """" ""该配置增加 <literal>p_keystone</literal> 资源，对 OpenStack 身份认证服务进行"" ""管理。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live pacemaker configuration, and then make "" ""changes as required. For example, you may enter <literal>edit p_ip_keystone</"" ""literal> from the <literal>crm configure</literal> menu and edit the "" ""resource to match your preferred virtual IP address."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。例如，可以从 <literal>crm configure</"" ""literal> 菜单中进入 <literal>edit p_ip_keystone</literal>，编辑资源以匹配可供"" ""使用的虚拟IP地址。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the OpenStack Identity service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 "" ""OpenStack 身份认证服务（包括所有相关资源）。"" msgid ""Configure OpenStack Identity service"" msgstr ""配置 OpenStack 身份认证服务"" msgid """" ""You need to edit your OpenStack Identity configuration file "" ""(<filename>keystone.conf</filename>) and change the bind parameters:"" msgstr """" ""编辑 OpenStack 身份认证服务的配置文件（ <filename>keystone.conf</"" ""filename> ），调整以下配置项："" msgid ""On Havana:"" msgstr ""对于 Havana 版本："" msgid """" ""To be sure all data will be highly available, you should be sure that you "" ""store everything in the MySQL database (which is also highly available):"" msgstr """" ""为了保证所有的数据都是高可用的，应使用 MySQL 数据库服务（同样也要保证 MySQL "" ""服务是高可用的）："" msgid """" ""Configure OpenStack services to use the highly available OpenStack Identity"" msgstr ""配置 OpenStack 各服务使用高可用的 OpenStack 身份认证服务"" msgid """" ""Your OpenStack services must now point their OpenStack Identity "" ""configuration to the highly available, virtual cluster IP address — rather "" ""than a OpenStack Identity server’s physical IP address as you normally would."" msgstr """" ""其它 OpenStack 服务也相应地使用高可用、使用虚拟 IP 地址的 OpenStack 身份认证"" ""服务，而不在使用其所在服务器的物理 IP 地址。"" msgid """" ""For example with OpenStack Compute, if your OpenStack Identity service IP "" ""address is <literal>192.168.42.103</literal> as in the configuration "" ""explained here, you would use the following line in your API configuration "" ""file (<literal>api-paste.ini</literal>):"" msgstr """" ""以 OpenStack 计算服务为例，如果 OpenStack 身份认证服务的虚拟 IP 地址是 "" ""<literal>192.168.42.103</literal>，那么在 OpenStack 计算服务的配置文件"" ""（ <literal>api-paste.ini</literal> ）中应该使用如下配置："" msgid ""You also need to create the OpenStack Identity Endpoint with this IP."" msgstr ""在 OpenStack 身份认证服务中需要为该 IP 地址创建对应的服务端点。"" msgid """" ""If you are using the horizon dashboard, you should edit the "" ""<literal>local_settings.py</literal> file:"" msgstr """" ""如果配置了 Horizon 面板，也需要修改 Horizon 的配置文件 "" ""<literal>local_settings.py</literal> ： "" msgid ""Configure the VIP"" msgstr ""配置VIP"" msgid """" ""First, you must select and assign a virtual IP address (VIP) that can freely "" ""float between cluster nodes."" msgstr ""首先选择并绑定一个可以在各集群节点之间迁移的虚拟 IP 地址 （即 VIP ）。"" msgid """" ""This configuration creates <literal>p_ip_api</literal>, a virtual IP address "" ""for use by the API node (<literal>192.168.42.103</literal>):"" msgstr """" ""该配置新建了一个 <literal>p_ip_mysql</literal> 资源，是 API 节点将会使用的虚"" ""拟 IP 地址（<literal>192.168.42.103</literal>）："" msgid ""Highly available RabbitMQ"" msgstr ""高可用的 RabbitMQ"" msgid """" ""RabbitMQ is the default AMQP server used by many OpenStack services. Making "" ""the RabbitMQ service highly available involves:"" msgstr """" ""RabbitMQ 是多数 OpenStack 服务的默认 AMQP 服务程序。实现 RabbitMQ 的高可用包"" ""括以下步骤："" msgid ""configuring a DRBD device for use by RabbitMQ,"" msgstr ""为 RabbitMQ 配置一个 DRBD 设备"" msgid """" ""configuring RabbitMQ to use a data directory residing on that DRBD device,"" msgstr ""配置 RabbitMQ 使用建立在 DRBD 设备之上的数据目录，"" msgid """" ""selecting and assigning a virtual IP address (VIP) that can freely float "" ""between cluster nodes,"" msgstr ""选择并绑定一个可以在各集群节点之间迁移的虚拟 IP 地址 （即 VIP ），"" msgid ""configuring RabbitMQ to listen on that IP address,"" msgstr ""配置 RabbitMQ 监听该 IP 地址，"" msgid """" ""managing all resources, including the RabbitMQ daemon itself, with the "" ""Pacemaker cluster manager."" msgstr ""使用 Pacemaker 管理上述所有资源，包括 RabbitMQ 守护进程本身。"" msgid """" ""<link href=\""http://www.rabbitmq.com/ha.html\"">Active-active mirrored "" ""queues</link> is another method for configuring RabbitMQ versions 3.3.0 and "" ""later for high availability. You can also manage a RabbitMQ cluster with "" ""active-active mirrored queues using the Pacemaker cluster manager."" msgstr """" ""<link href=\""http://www.rabbitmq.com/ha.html\"">主/主镜像队列</link> 是实现 "" ""RabbitMQ 高可用的另一种可选方案（适用于 RabbitMQ 3.3.0 及之后的版本），同样，"" ""也可以通过 Pacemaker 来管理使用“主/主镜像队列”架构的 RabbitMQ 集群。"" msgid ""Configure DRBD"" msgstr ""配置 DRBD"" msgid """" ""The Pacemaker based RabbitMQ server requires a DRBD resource from which it "" ""mounts the <filename>/var/lib/rabbitmq</filename> directory. In this "" ""example, the DRBD resource is simply named <literal>rabbitmq</literal>:"" msgstr """" ""基于 Pacemaker 的 RabbitMQ 服务需要一个 DRBD 设备，并将之挂载到 <filename>/"" ""var/lib/rabbitmq</filename> 目录。在示例中，DRBD 资源被简单命名为 "" ""<literal>rabbitmq</literal>："" msgid """" ""<literal>rabbitmq</literal> DRBD resource configuration (<filename>/etc/drbd."" ""d/rabbitmq.res</filename>)"" msgstr """" ""<literal>rabbitmq</literal> DRBD 资源配置文件（ <filename>/etc/drbd.d/"" ""rabbitmq.res</filename> ）"" msgid """" ""This resource uses an underlying local disk (in DRBD terminology, a backing "" ""device) named <filename>/dev/data/rabbitmq</filename> on both cluster nodes, "" ""<literal>node1</literal> and <literal>node2</literal>. Normally, this would "" ""be an LVM Logical Volume specifically set aside for this purpose. The DRBD "" ""meta-disk is internal, meaning DRBD-specific metadata is being stored at the "" ""end of the disk device itself. The device is configured to communicate "" ""between IPv4 addresses <literal>10.0.42.100</literal> and "" ""<literal>10.0.42.254</literal>, using TCP port 7701. Once enabled, it will "" ""map to a local DRBD block device with the device minor number 1, that is, "" ""<filename>/dev/drbd1</filename>."" msgstr """" ""该资源使用了一块本地磁盘（DRBD 术语为“后端设备”， a backing device），该磁盘"" ""在两台节点服务器（ <literal>node1</literal> ， <literal>node2</literal> ）上"" ""对应相同的设备文件 ——<filename>/dev/data/rabbitmq</filename> ，一 般情况下，"" ""该磁盘是一个专门为此配置的 LVM 逻辑卷。meta-disk 配置项的值是 internal，指的"" ""是 DRBD 元数据保存在后端设备的结尾（即元数据和实际数据保存在同一存储设备"" ""上）。设备数据同步通过 <literal>10.0.42.100</literal> 和 "" ""<literal>10.0.42.254</literal> 完成，使用 TCP 7701 端口。当 DRBD 资源激活之"" ""后，系统中将对应生成一个 DRBD 设备文件，次设备号为 1 ，设备文件是 "" ""<filename>/dev/drbd1</filename> 。"" msgid """" ""Enabling a DRBD resource is explained in detail in <link href=\""http://www."" ""drbd.org/users-guide-8.3/s-first-time-up.html\"">the DRBD User's Guide</"" ""link>. In brief, the proper sequence of commands is this:"" msgstr """" ""激活 DRBD 设备的详细说明请参阅 <link href=\""http://www.drbd.org/users-"" ""guide-8.3/s-first-time-up.html\""> DRBD 用户手册 </link>，下面仅列出必要的命令"" ""及其执行顺序："" msgid """" ""Initializes DRBD metadata and writes the initial set of metadata to "" ""<filename>/dev/data/rabbitmq</filename>. Must be completed on both nodes."" msgstr """" ""初始化 DRBD 元数据，并在 <filename>/dev/data/rabbitmq</filename> 上初始元数据"" ""集。两台节点服务器上都必须完成该操作。"" msgid """" ""Creates the <filename>/dev/drbd1</filename> device node, attaches the DRBD "" ""device to its backing store, and connects the DRBD node to its peer. Must be "" ""completed on both nodes."" msgstr """" ""创建 <literal>/dev/drbd1</literal> 设备文件，将指定的后端存储设备附加到该 "" ""DRBD 资源，同时建立所有节点服务器之间的通信连接。两台节点服务器上都必须完成该"" ""操作。"" msgid """" ""Kicks off the initial device synchronization, and puts the device into the "" ""<literal>primary</literal> (readable and writable) role. See <link href="" ""\""http://www.drbd.org/users-guide-8.3/ch-admin.html#s-roles\""> Resource "" ""roles</link> (from the DRBD User's Guide) for a more detailed description of "" ""the primary and secondary roles in DRBD. Must be completed on one node only, "" ""namely the one where you are about to continue with creating your filesystem."" msgstr """" ""启动 DRBD 设备的初始化同步，并将之设置为 <literal>primary</literal> 角色。关"" ""于 “primary” 和 “secondary” 角色的详细说明请查阅 <link href=\""http://www."" ""drbd.org/users-guide-8.3/ch-admin.html#s-roles\""> Resource roles</link> "" ""（ DRBD 用户手册）。这一操作只应在其中一台节点服务器上执行，此处指的是将被用"" ""于执行创建文件系统的节点。"" msgid ""Create a file system"" msgstr ""创建文件系统"" msgid """" ""Once the DRBD resource is running and in the primary role (and potentially "" ""still in the process of running the initial device synchronization), you may "" ""proceed with creating the filesystem for RabbitMQ data. XFS is generally the "" ""recommended filesystem:"" msgstr """" ""当 DRBD 资源已经激活并处于 “primay” 角色（可能初始化同步正在进行，还没有完"" ""成），可以开始创建文件系统。 XFS 由于拥有日志系统，分配效率高，性能好等优点，"" ""是建议选择的文件系统："" msgid """" ""You may also use the alternate device path for the DRBD device, which may be "" ""easier to remember as it includes the self-explanatory resource name:"" msgstr ""也可以使用 DRBD 设备的另外一个名称，该名称有解释含义，更容易记忆："" msgid """" ""Once completed, you may safely return the device to the secondary role. Any "" ""ongoing device synchronization will continue in the background:"" msgstr """" ""完成后，可以安全地把设备变回 “secondary” 角色。已经启动的设备同步将在后台继续"" ""进行："" msgid ""Prepare RabbitMQ for Pacemaker high availability"" msgstr ""RabbitMQ 针对 Pacemaker HA 架构的前期准备"" msgid """" ""In order for Pacemaker monitoring to function properly, you must ensure that "" ""RabbitMQ's <filename>.erlang.cookie</filename> files are identical on all "" ""nodes, regardless of whether DRBD is mounted there or not. The simplest way "" ""of doing so is to take an existing <filename>.erlang.cookie</filename> from "" ""one of your nodes, copying it to the RabbitMQ data directory on the other "" ""node, and also copying it to the DRBD-backed filesystem."" msgstr """" ""要通过 Pacemaker 实现 RabbitMQ 高可用，必须首先保证 RabbitMQ 的文件 "" ""<filename>.erlang.cookie</filename> 不论在 DRBD 设备有没有挂载的情况下，都完"" ""全相同。最简单的方法是将其中一台节点服务器上已经生成的 <filename>.erlang."" ""cookie</filename> 文件复制到所有其它节点，同时也复制一份到 DRBD 设备上的文件"" ""系统之中。"" msgid ""Add RabbitMQ resources to Pacemaker"" msgstr ""在 Pacemaker 中添加 RabbitMQ 资源"" msgid """" ""You may now proceed with adding the Pacemaker configuration for RabbitMQ "" ""resources. Connect to the Pacemaker cluster with <placeholder-1/>, and add "" ""the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 RabbitMQ 相关资源。执行 <placeholder-1/> 命令进"" ""入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""<literal>p_ip_rabbitmq</literal>, a virtual IP address for use by RabbitMQ "" ""(<literal>192.168.42.100</literal>),"" msgstr """" ""<literal>p_ip_rabbitmq</literal>，RabbitMQ 服务将会使用的虚拟 IP 地址"" ""（<literal>192.168.42.100</literal>），"" msgid """" ""<literal>p_fs_rabbitmq</literal>, a Pacemaker managed filesystem mounted to "" ""<filename>/var/lib/rabbitmq</filename> on whatever node currently runs the "" ""RabbitMQ service,"" msgstr """" ""<literal>p_fs_rabbitmq</literal>，Pacemaker 管理的文件系统，挂载点为 "" ""<filename>/var/lib/rabbitmq</filename>，该文件系统将在运行 RabbitMQ 服务的节"" ""点上挂载，"" msgid """" ""<literal>ms_drbd_rabbitmq</literal>, the master/slave set managing the "" ""<literal>rabbitmq</literal> DRBD resource,"" msgstr ""<literal>ms_drbd_rabbitmq</literal>，管理 DRBD 设备的主/从资源，"" msgid """" ""a service group and order and colocation constraints to ensure resources are "" ""started on the correct nodes, and in the correct sequence."" msgstr ""资源组以及顺序、协同约束条件，会确保资源在正确的节点安照正确次序启动。"" msgid """" ""<placeholder-1/> supports batch input, so you may copy and paste the above "" ""into your live pacemaker configuration, and then make changes as required. "" ""For example, you may enter <literal>edit p_ip_rabbitmq</literal> from the "" ""<placeholder-2/> menu and edit the resource to match your preferred virtual "" ""IP address."" msgstr """" ""<placeholder-1/> 支持批量输入的配置，因此可以直接复制上述配置示例，粘贴到实际"" ""的 Pacemaker 配置环境，然后根据具体情况调整配置项。例如，在 <placeholder-2/"" ""> 菜单中，输入 <literal>edit p_ip_rabbitmq</literal>，可以对虚拟 IP 地址资源"" ""进行编辑。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <placeholder-1/> menu. Pacemaker will "" ""then start the RabbitMQ service, and its dependent resources, on one of your "" ""nodes."" msgstr """" ""配置完成后，在 <placeholder-1/> 菜单下输入 <literal>commit</literal> 提交所有"" ""配置变更。随后 Pacemaker 会其中一台节点服务器上启动 RabbitMQ 服务（包括所有相"" ""关资源）。"" msgid ""Configure OpenStack services for highly available RabbitMQ"" msgstr ""配置 OpenStack 各服务使用高可用的 RabbitMQ 服务"" msgid """" ""Your OpenStack services must now point their RabbitMQ configuration to the "" ""highly available, virtual cluster IP addressrather than a RabbitMQ server's "" ""physical IP address as you normally would."" msgstr """" ""现在可以将各 OpenStack 服务配置文件中使用物理 IP 地址的 RabbitMQ 访问方式，更"" ""改为访问高可用、使用虚拟 IP 地址的 RabbitMQ 服务。"" msgid """" ""For OpenStack Image, for example, if your RabbitMQ service IP address is "" ""<literal>192.168.42.100</literal> as in the configuration explained here, "" ""you would use the following line in your OpenStack Image API configuration "" ""file (<filename>glance-api.conf</filename>):"" msgstr """" ""以 OpenStack 镜像服务为例，如果 RabbitMQ 服务的虚拟 IP 地址是 "" ""<literal>192.168.42.100</literal>，那么在 OpenStack 镜像服务的配置文件"" ""（ <filename>glance-api.conf</filename> ）中应该使用如下配置："" msgid """" ""No other changes are necessary to your OpenStack configuration. If the node "" ""currently hosting your RabbitMQ experiences a problem necessitating service "" ""failover, your OpenStack services may experience a brief RabbitMQ "" ""interruption, as they would in the event of a network hiccup, and then "" ""continue to run normally."" msgstr """" ""除此之外，不需要更改其它配置。如果运行数据库服务的节点发生故障，RabbitMQ 服务"" ""会自动迁移到其它节点，OpenStack 服务会经历短暂的临时 RabbitMQ 中断，和偶然发"" ""生的网络中断类似，之后会继续正常运行。"" msgid ""Highly available MySQL"" msgstr ""高可用的MySQL"" msgid """" ""MySQL is the default database server used by many OpenStack services. Making "" ""the MySQL service highly available involves:"" msgstr """" ""MySQL是许多OpenStack服务所使用的默认数据库服务。确保MySQL服务高可用涉及到："" msgid ""Configuring a DRBD device for use by MySQL"" msgstr ""配置被MySQL使用的DRBD设备"" msgid ""Configuring MySQL to use a data directory residing on that DRBD device"" msgstr ""配置MySQL使用位于DRBD设备上的数据目录""msgid ""Configuring MySQL to listen on that IP address"" msgstr ""配置 MySQL 监听那个 IP 地址"" msgid """" ""Managing all resources, including the MySQL daemon itself, with the "" ""Pacemaker cluster manager"" msgstr ""使用 Pacemaker 管理上述所有资源，包括 MySQL 数据库"" msgid """" ""<link href=\""http://galeracluster.com/\"">MySQL/Galera</link> is an "" ""alternative method of configuring MySQL for high availability. It is likely "" ""to become the preferred method of achieving MySQL high availability once it "" ""has sufficiently matured. At the time of writing, however, the Pacemaker/"" ""DRBD based approach remains the recommended one for OpenStack environments."" msgstr """" ""<link href=\""http://galeracluster.com/\"">MySQL/Galera</link> 是实现 MySQL 数"" ""据库高可用的另一种可选方案，一旦该方案足够成熟，可能会是更好的选择。不过在本"" ""文写作时，基于 Pacemaker/DRBD 的方案仍然是 OpenStack 环境的推荐方式。"" msgid """" ""The Pacemaker based MySQL server requires a DRBD resource from which it "" ""mounts the <literal>/var/lib/mysql</literal> directory. In this example, the "" ""DRBD resource is simply named <literal>mysql</literal>:"" msgstr """" ""基于 Pacemaker 的 MySQL 数据库需要一个 DRBD 设备，并将之挂载到 <literal>/var/"" ""lib/mysql</literal> 目录。在示例中，DRBD 资源被简单命名为 <literal>mysql</"" ""literal>："" msgid """" ""<literal>mysql</literal> DRBD resource configuration (<filename>/etc/drbd.d/"" ""mysql.res</filename>)"" msgstr """" ""<literal>mysql</literal> DRBD 资源配置文件（ <filename>/etc/drbd.d/mysql."" ""res</filename> ）"" msgid """" ""This resource uses an underlying local disk (in DRBD terminology, a backing "" ""device) named <filename>/dev/data/mysql</filename> on both cluster nodes, "" ""<literal>node1</literal> and <literal>node2</literal>. Normally, this would "" ""be an LVM Logical Volume specifically set aside for this purpose. The DRBD "" ""meta-disk is internal, meaning DRBD-specific metadata is being stored at the "" ""end of the disk device itself. The device is configured to communicate "" ""between IPv4 addresses <literal>10.0.42.100</literal> and "" ""<literal>10.0.42.254</literal>, using TCP port 7700. Once enabled, it will "" ""map to a local DRBD block device with the device minor number 0, that is, "" ""<filename>/dev/drbd0</filename>."" msgstr """" ""该资源使用了一块本地磁盘（DRBD 术语为“后端设备”， a backing device），该磁盘"" ""在两台节点服务器（ <literal>node1</literal> ， <literal>node2</literal> ）上"" ""对应相同的设备文件 —— <filename>/dev/data/mysql</filename> ，一 般情况下，该"" ""磁盘是一个专门为此配置的 LVM 逻辑卷。meta-disk 配置项的值是 internal，指的是 "" ""DRBD 元数据保存在后端设备的结尾（即元数据和实际数据保存在同一存储设备上）。设"" ""备数据同步通过 <literal>10.0.42.100</literal> 和 <literal>10.0.42.254</"" ""literal> 完成，使用 TCP 7700 端口。当 DRBD 资源激活之后，系统中将对应生成一"" ""个 DRBD 设备文件，次设备号为 0 ，设备文件是 <filename>/dev/drbd0</"" ""filename> 。"" msgid """" ""Enabling a DRBD resource is explained in detail in <link href=\""http://www."" ""drbd.org/users-guide-8.3/s-first-time-up.html\""> the DRBD User's Guide</"" ""link>. In brief, the proper sequence of commands is this:"" msgstr """" ""激活 DRBD 设备的详细说明请参阅 <link href=\""http://www.drbd.org/users-"" ""guide-8.3/s-first-time-up.html\""> DRBD 用户手册 </link>，下面仅列出必要的命令"" ""及其执行顺序："" msgid """" ""Initializes DRBD metadata and writes the initial set of metadata to "" ""<literal>/dev/data/mysql</literal>. Must be completed on both nodes."" msgstr """" ""初始化 DRBD 元数据，并在 <literal>/dev/data/mysql</literal> 上初始元数据集。"" ""两台节点服务器上都必须完成该操作。"" msgid """" ""Creates the <literal>/dev/drbd0</literal> device node, attaches the DRBD "" ""device to its backing store, and connects the DRBD node to its peer. Must be "" ""completed on both nodes."" msgstr """" ""创建 <literal>/dev/drbd0</literal> 设备文件，将指定的后端存储设备附加到该 "" ""DRBD 资源，同时建立所有节点服务器之间的通信连接。两台节点服务器上都必须完成该"" ""操作。"" msgid ""Creating a file system"" msgstr ""创建文件系统"" msgid """" ""Once the DRBD resource is running and in the primary role (and potentially "" ""still in the process of running the initial device synchronization), you may "" ""proceed with creating the filesystem for MySQL data. XFS is generally the "" ""recommended filesystem due to its journaling, efficient allocation, and "" ""performance:"" msgstr """" ""当 DRBD 资源已经激活并处于 “primay” 角色(可能初始化同步正在进行，还没有完"" ""成)，可以开始创建文件系统。 XFS 由于拥有日志系统，分配效率高，性能好等优点，"" ""是建议选择的文件系统。"" msgid ""Prepare MySQL for Pacemaker high availability"" msgstr ""MySQL 针对 Pacemaker HA 架构的前期准备"" msgid """" ""In order for Pacemaker monitoring to function properly, you must ensure that "" ""MySQL's database files reside on the DRBD device. If you already have an "" ""existing MySQL database, the simplest approach is to just move the contents "" ""of the existing <filename>/var/lib/mysql</filename> directory into the newly "" ""created filesystem on the DRBD device."" msgstr """" ""要通过 Pacemaker 实现 MySQL 高可用，必须首先保证 MySQL 的数据文件使用 DRBD 存"" ""储设备。如果使用已有的数据库，最简单的方法是将已有的数据库文件 <filename>/"" ""var/lib/mysql</filename> 迁移到 DRBD 设备之上的文件系统中。"" msgid """" ""You must complete the next step while the MySQL database server is shut down."" msgstr ""下面的步骤在必须关闭MySQL数据库服务器之后进行。"" msgid """" ""For a new MySQL installation with no existing data, you may also run the "" ""<placeholder-1/> command:"" msgstr ""如果使用全新的数据库，可以执行 <placeholder-1/> 命令："" msgid """" ""Regardless of the approach, the steps outlined here must be completed on "" ""only one cluster node."" msgstr ""这里列出的这些步骤只需要在其中一个集群节点上操作一遍即可。"" msgid ""Add MySQL resources to Pacemaker"" msgstr ""在 Pacemaker 中添加 MySQL 资源"" msgid """" ""You can now add the Pacemaker configuration for MySQL resources. Connect to "" ""the Pacemaker cluster with <placeholder-1/>, and add the following cluster "" ""resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 MySQL 相关资源。执行 <placeholder-1/> 命令进入 "" ""Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""<literal>p_ip_mysql</literal>, a virtual IP address for use by MySQL "" ""(<literal>192.168.42.101</literal>),"" msgstr """" ""<literal>p_ip_mysql</literal>，MySQL 服务将会使用的虚拟 IP 地址"" ""（<literal>192.168.42.101</literal>），"" msgid """" ""<literal>p_fs_mysql</literal>, a Pacemaker managed filesystem mounted to "" ""<filename>/var/lib/mysql</filename> on whatever node currently runs the "" ""MySQL service,"" msgstr """" ""<literal>p_fs_mysql</literal>，Pacemaker 管理的文件系统，挂载点为 <filename>/"" ""var/lib/mysql</filename>，该文件系统将在运行 MySQL 服务的节点上挂载，"" msgid """" ""<literal>ms_drbd_mysql</literal>, the master/slave set managing the "" ""<literal>mysql</literal> DRBD resource,"" msgstr ""<literal>ms_drbd_mysql</literal>，管理 DRBD 设备的主/从资源，"" msgid """" ""a service <literal>group</literal> and <literal>order</literal> and "" ""<literal>colocation</literal> constraints to ensure resources are started on "" ""the correct nodes, and in the correct sequence."" msgstr ""资源组以及顺序、协同约束条件，会确保资源在正确的节点安照正确次序启动。"" msgid """" ""<placeholder-1/> supports batch input, so you may copy and paste the above "" ""into your live pacemaker configuration, and then make changes as required. "" ""For example, you may enter <literal>edit p_ip_mysql</literal> from the "" ""<placeholder-2/> menu and edit the resource to match your preferred virtual "" ""IP address."" msgstr """" ""<placeholder-1/> 支持批量输入的配置，因此可以直接复制上述配置示例，粘贴到实际"" ""的 Pacemaker 配置环境，然后根据具体情况调整配置项。例如，在 <placeholder-2/"" ""> 菜单中，输入 <literal>edit p_ip_mysql</literal>，可以对虚拟 IP 地址资源进行"" ""编辑。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <placeholder-1/> menu. Pacemaker will "" ""then start the MySQL service, and its dependent resources, on one of your "" ""nodes."" msgstr """" ""配置完成后，在 <placeholder-1/> 菜单下输入 <literal>commit</literal> 提交所有"" ""配置变更。随后 Pacemaker 会其中一台节点服务器上启动 MySQL 服务（包括所有相关"" ""资源）。"" msgid ""Configure OpenStack services for highly available MySQL"" msgstr ""配置 OpenStack 各服务使用高可用的 MySQL 数据库"" msgid """" ""Your OpenStack services must now point their MySQL configuration to the "" ""highly available, virtual cluster IP addressrather than a MySQL server's "" ""physical IP address as you normally would."" msgstr """" ""现在可以将各 OpenStack 服务配置文件中使用物理 IP 地址的 MySQL 访问方式，更改"" ""为访问高可用、使用虚拟 IP 地址的 MySQL 服务。"" msgid """" ""For OpenStack Image, for example, if your MySQL service IP address is "" ""<literal>192.168.42.101</literal> as in the configuration explained here, "" ""you would use the following line in your OpenStack Image registry "" ""configuration file (<filename>glance-registry.conf</filename>):"" msgstr """" ""以 OpenStack 镜像服务为例，如果 MySQL 数据库的虚拟 IP 地址是 "" ""<literal>192.168.42.101</literal>，那么在 OpenStack 镜像服务的配置文件"" ""（ <filename>glance-registry.conf</filename> ）中应该使用如下配置："" msgid """" ""No other changes are necessary to your OpenStack configuration. If the node "" ""currently hosting your database experiences a problem necessitating service "" ""failover, your OpenStack services may experience a brief MySQL interruption, "" ""as they would in the event of a network hiccup, and then continue to run "" ""normally."" msgstr """" ""除此之外，不需要更改其它配置。如果运行数据库服务的节点发生故障，MySQL 服务会"" ""自动迁移到其它节点，OpenStack 服务会经历短暂的临时 MySQL 中断，和偶然发生的网"" ""络中断类似，之后会继续正常运行。"" msgid ""Memcached"" msgstr ""Memcached"" msgid """" ""Most OpenStack services use an application to offer persistence and store "" ""ephemeral data like tokens. <application>Memcached</application> is one of "" ""them and can scale-out easily without any specific tricks required."" msgstr """" ""大部分 OpenStack 服务都会使用另外一个应用程序来提供持久化存储并存储类似认证令"" ""牌的附加数据。<application>Memcached</application> 是其中一种，而且无需特殊配"" ""置就可以分布式地运行在多个节点服务器上。"" msgid """" ""To install and configure it, read the <link href=\""http://code.google.com/p/"" ""memcached/wiki/NewStart\""> official documentation</link>."" msgstr """" ""<application>Memcached</application> 的安装和配置，请参阅 <link href="" ""\""http://code.google.com/p/memcached/wiki/NewStart\""> 官方文档</link>。"" msgid """" ""Memory caching is managed by oslo-incubator, so the way to use multiple "" ""memcached servers is the same for all projects."" msgstr """" ""基于内存的缓存统一由 oslo-incubator 管理，因此对 OpenStack 服务来说，使用多"" ""个 memcached 服务节点作为后端的方法完全相同。"" msgid ""Example configuration with two hosts:"" msgstr ""使用 2 个 memcached 节点的配置示例："" msgid """" ""By default, <literal>controller1</literal> handles the caching service but "" ""if the host goes down, <literal>controller2</literal> does the job. For more "" ""information about <application>Memcached</application> installation, see the "" ""<link href=\""http://docs.openstack.org/admin-guide-cloud/content/\""> "" ""OpenStack Cloud Administrator Guide</link>."" msgstr """" ""默认情况下，服务器 <literal>controller1</literal> 处理所有缓存，一旦它无法工"" ""作，服务器 <literal>controller2</literal> 会自动接管。更多关于 "" ""<application>Memcached</application> 布署的信息请参阅 <link href=\""http://"" ""docs.openstack.org/admin-guide-cloud/content/\""> OpenStack 云计算平台管理员手"" ""册</link>。"" msgid ""Run OpenStack API and schedulers"" msgstr ""运行 OpenStack API 和 调度服务"" msgid ""API services"" msgstr ""API 服务"" msgid """" ""To use highly available and scalable API services, we need to ensure that:"" msgstr ""要实现高可用和可扩展的 API 服务，需要保证："" msgid """" ""You use virtual IP addresses when configuring OpenStack Identity endpoints."" msgstr ""为 OpenStack 身份认证中的服务端点配置虚拟 IP 地址。"" msgid ""All OpenStack configuration files should refer to virtual IP addresses."" msgstr ""所有 OpenStack 组件的配置中也相应使用虚拟 IP 地址。"" msgid ""Schedulers"" msgstr ""调度程序"" msgid ""nova-scheduler"" msgstr ""nova-scheduler"" msgid ""nova-conductor"" msgstr ""nova-conductor"" msgid ""cinder-scheduler"" msgstr ""cinder-scheduler"" msgid ""neutron-server"" msgstr ""neutron-server"" msgid ""ceilometer-collector"" msgstr ""ceilometer-collector"" msgid ""heat-engine"" msgstr ""heat-engine"" msgid """" ""Please refer to the <link linkend=\""s-rabbitmq\"">RabbitMQ section</link> for "" ""configuring these services with multiple messaging servers."" msgstr """" ""请参阅 <link linkend=\""s-rabbitmq\"">RabbitMQ 部分</link> 将 OpenStack 各组件"" ""配置为可同时使用多个消息队列服务器。"" msgid ""Start Pacemaker"" msgstr ""启动 Pacemaker"" msgid """" ""Once the Corosync services have been started and you have established that "" ""the cluster is communicating properly, it is safe to start <systemitem class="" ""\""service\"">pacemakerd</systemitem>, the Pacemaker master control process:"" msgstr """" ""Corosync 服务启动之后，一旦各节点正常建立集群通信，就可启动 <systemitem "" ""class=\""service\"">pacemakerd</systemitem> （ Pacemaker 主进程）："" msgid ""<placeholder-1/> (LSB)"" msgstr ""<placeholder-1/> （LSB）"" msgid ""<placeholder-1/> (LSB, alternate)"" msgstr ""<placeholder-1/> （LSB，另一种方法）"" msgid ""<placeholder-1/> (upstart)"" msgstr ""<placeholder-1/> （upstart）"" msgid ""<placeholder-1/> (systemd)"" msgstr ""<placeholder-1/> （systemd）"" msgid """" ""Once the Pacemaker services have started, Pacemaker will create a default "" ""empty cluster configuration with no resources. You may observe Pacemaker's "" ""status with the <placeholder-1/> utility:"" msgstr """" ""Pacemaker 服务启动之后，会自动建立一份空白的集群配置，不包含任何资源。可以通"" ""过 <placeholder-1/> 工具查看 Packemaker 集群的状态："" msgid ""Set up Corosync"" msgstr ""Corosync 基本配置"" msgid """" ""Besides installing the <package>Corosync</package> package, you must also "" ""create a configuration file, stored in <filename>/etc/corosync/corosync."" ""conf</filename>. Corosync can be configured to work with either multicast or "" ""unicast IP addresses."" msgstr """" ""除了安装 <package>Corosync</package> 之外，还需要创建一个配置文件 <filename>/"" ""etc/corosync/corosync.conf</filename> 。Corosync 可以使用组播或者单播 IP 地址"" ""进行集群心跳通信。"" msgid ""Set up Corosync with multicast"" msgstr ""配置 Corosync 使用组播"" msgid """" ""Most distributions ship an example configuration file (<filename>corosync."" ""conf.example</filename>) as part of the documentation bundled with the "" ""<package>Corosync</package> package. An example Corosync configuration file "" ""is shown below:"" msgstr """" ""大多数 Linux 发行版都会中在 <package>Corosync</package> 软件包中附带一份配置"" ""示例(<filename>corosync.conf.example</filename>)。Corosync示例配置文件如下："" msgid ""Corosync configuration file (<filename>corosync.conf</filename>)"" msgstr ""Corosync 配置文件（<filename>corosync.conf</filename>）"" msgid """" ""The <placeholder-1/> value specifies the time, in milliseconds, during which "" ""the Corosync token is expected to be transmitted around the ring. When this "" ""timeout expires, the token is declared lost, and after <placeholder-2/> lost "" ""tokens the non-responding processor (cluster node) is declared dead. In "" ""other words, <placeholder-3/> × <placeholder-4/> is the maximum time a node "" ""is allowed to not respond to cluster messages before being considered dead. "" ""The default for <placeholder-5/> is 1000 (1 second), with 4 allowed "" ""retransmits. These defaults are intended to minimize failover times, but can "" ""cause frequent \""false alarms\"" and unintended failovers in case of short "" ""network interruptions. The values used here are safer, albeit with slightly "" ""extended failover times."" msgstr """" ""<placeholder-1/> 是时间，单位为毫秒，在该配置项指定的时间内， Corosync 令牌应"" ""该完成在回环网络中的传输。如果令牌传输超时就会被丢弃，而一台节点服务器连续出"" ""现 <placeholder-2/> 令牌失效，将会被认为是无效节点。也就是说，一台节点服务器"" ""最长的无响应时间不能超对 <placeholder-3/> × <placeholder-4/> 的乘积（单位毫"" ""秒），否则会被认为是无效节点。<placeholder-5/> 的默认值是 1000 （即 1 秒），"" ""同时默认的重试次数为 4 。默认配置的目标是尽量缩短故障恢复时间，但是可能出现较"" ""多的 “false alarm” 提醒，发生短期的网络故障时也有可能导致失效切换。本处示例中"" ""的配置参数更安全一些，但是失效切换的时间会长一些。"" msgid """" ""With <placeholder-1/> enabled, Corosync nodes mutually authenticate using a "" ""128-byte shared secret stored in <filename>/etc/corosync/authkey</filename>, "" ""which may be generated with the <placeholder-2/> utility. When using "" ""<placeholder-3/>, cluster communications are also encrypted."" msgstr """" ""当启用 <placeholder-1/> 时，Corosync 节点之间通信时会使用一个 128 位的密钥进"" ""行双向认证。密钥存放在 <filename>/etc/corosync/authkey</filename> 文件中，可"" ""以通过 <placeholder-2/> 命令生成。启用 <placeholder-3/> 后，集群通信数据也会"" ""进行加密。"" msgid """" ""In Corosync configurations using redundant networking (with more than one "" ""<placeholder-1/>), you must select a Redundant Ring Protocol (RRP) mode "" ""other than <literal>none</literal>. <literal>active</literal> is the "" ""recommended RRP mode."" msgstr """" ""Cororsync 可以使用冗余的心跳网络（即多个 <placeholder-1/> 配置），但是必须同"" ""时将 RRP 模式设置为除 <literal>none</literal>之外的其它值，建议使用 "" ""<literal>active</literal> 模式。"" msgid """" ""There are several things to note about the recommended interface "" ""configuration:"" msgstr ""在推荐的网络接口配置中有几件事需要注意："" msgid """" ""The <placeholder-1/> must differ between all configured interfaces, starting "" ""with 0."" msgstr ""所有心跳网络的 <placeholder-1/> 配置不能重复，最小值为 0 。"" msgid """" ""The <placeholder-1/> is the network address of the interfaces to bind to. "" ""The example uses two network addresses of <literal>/24</literal> IPv4 "" ""subnets."" msgstr """" ""<placeholder-1/> 是心跳网卡 IP 地址对应的网络地址。示例中使用了两个子网掩码"" ""为 <literal>/24</literal> 的 IPv4 网段。"" msgid """" ""Multicast groups (<placeholder-1/>) must not be reused across cluster "" ""boundaries. In other words, no two distinct clusters should ever use the "" ""same multicast group. Be sure to select multicast addresses compliant with "" ""<link href=\""http://www.ietf.org/rfc/rfc2365.txt\"">RFC 2365, "" ""\""Administratively Scoped IP Multicast\""</link>."" msgstr """" ""多播地址的使用（<placeholder-1/> ） 不要跨越集群的边界，也即是说，不要在不同"" ""的集群中使用相同的多播地址。使用多播地址时，请依据 <link href=\""http://www."" ""ietf.org/rfc/rfc2365.txt\"">RFC 2365, \""Administratively Scoped IP Multicast"" ""\""</link> 。"" msgid """" ""For firewall configurations, note that Corosync communicates over UDP only, "" ""and uses <literal>mcastport</literal> (for receives) and <literal>mcastport "" ""- 1</literal> (for sends)."" msgstr """" ""Corosync 通信使用 UDP 协议，端口为 <literal>mcastport</literal> （接收数据）"" ""和 <literal>mcastport - 1</literal> （发送数据）。配置防火墙时需要打开这两个"" ""端口。"" msgid """" ""The <literal>service</literal> declaration for the <literal>pacemaker</"" ""literal> service may be placed in the <filename>corosync.conf</filename> "" ""file directly, or in its own separate file, <filename>/etc/corosync/service."" ""d/pacemaker</filename>."" msgstr """" ""<literal>pacemaker</literal> 对应的 <literal>service</literal> 配置段，可以放"" ""在 <filename>corosync.conf</filename> ，也可以单独作为一个配置文件 "" ""<filename>/etc/corosync/service.d/pacemaker</filename> 。"" msgid """" ""If you are using Corosync version 2 on Ubuntu 14.04, remove or comment out "" ""lines under the service stanza, which enables Pacemaker to start up."" msgstr """" ""如果是在 Ubuntu 14.04 系统中运行 Corosync 2，那么应该将 stanza 对应的 "" ""service 配置段删除或者全部注释，以确保 Pacemaker 可以启动。"" msgid """" ""Once created, the <filename>corosync.conf</filename> file (and the "" ""<filename>authkey</filename> file if the <placeholder-1/> option is enabled) "" ""must be synchronized across all cluster nodes."" msgstr """" ""<filename>corosync.conf</filename> （以及 <filename>authkey</filename> ，如"" ""果 <placeholder-1/> 启用）一旦创建，则必须在各节点服务器之间保持同步。"" msgid ""Set up Corosync with unicast"" msgstr ""配置 Corosync 使用单播"" msgid """" ""Some environments may not support multicast. For such cases, Corosync should "" ""be configured for unicast. An example fragment of the Corosync configuration "" ""file is shown below:"" msgstr """" ""某些环境中可能不支持组播。这时应该配置 Corosync 使用单播，下面是使用单播的 "" ""Corosync 配置文件的一部分："" msgid """" ""Corosync configuration file fragment (<filename>corosync.conf</filename>)"" msgstr """" ""Corosync 配置文件片断：\n"" ""（ <filename>corosync.conf</filename> ）"" msgid """" ""If the <placeholder-1/> is set to yes, the broadcast address is used for "" ""communication. If this option is set, <placeholder-2/> should not be set."" msgstr """" ""如果将 <placeholder-1/> 设置为 yes ，集群心跳将通过广播实现。设置该参数时，"" ""不能设置 <placeholder-2/> 。"" msgid """" ""The <placeholder-1/> directive controls the transport mechanism used. To "" ""avoid the use of multicast entirely, a unicast transport parameter "" ""<placeholder-2/> should be specified. This requires specifying the list of "" ""members in <placeholder-3/> directive; this could potentially make up the "" ""membership before deployment. The default is <placeholder-4/>. The transport "" ""type can also be set to <placeholder-5/> or <placeholder-6/>."" msgstr """" ""<placeholder-1/> 配置项决定集群通信方式。要完全禁用组播，应该配置单播传输参"" ""数 <placeholder-2/> 。这要求将所有的节点服务器信息写入 <placeholder-3/> ，也"" ""就是需要在配署 HA 集群之前确定节点组成。配认配置是 <placeholder-4/> 。通信方"" ""式类型还支持 <placeholder-5/> 和 <placeholder-6/> 。"" msgid """" ""Within the <placeholder-1/> directive, it is possible to specify specific "" ""information about nodes in cluster. Directive can contain only the "" ""<placeholder-2/> sub-directive, which specifies every node that should be a "" ""member of the membership, and where non-default options are needed. Every "" ""node must have at least the <placeholder-3/> field filled."" msgstr """" ""在 <placeholder-1/> 之下可以为某一节点设置只与该节点相关的信息，这些设置项只"" ""能包含在 <placeholder-2/> 之中，即只能对属于集群的节点服务器进行设置，而且只"" ""应包括那些与默认设置不同的参数。每台服务器都必须配置 <placeholder-3/> 。"" msgid """" ""For UDPU, every node that should be a member of the membership must be "" ""specified."" msgstr ""对于 UDPU ，每台节点服务器都需要配置所属的传输组。"" msgid ""Possible options are:"" msgstr ""可用的节点服务器配置项有："" msgid """" ""The <placeholder-1/> specifies IP address of one of the nodes. X is ring "" ""number."" msgstr """" ""<placeholder-1/> 对应该节点服务器用于集群通信的 IP 地址，其中 X 对应集群通信"" ""环路序号。"" msgid """" ""The <placeholder-1/> configuration option is optional when using IPv4 and "" ""required when using IPv6. This is a 32-bit value specifying the node "" ""identifier delivered to the cluster membership service. If this is not "" ""specified with IPv4, the node id will be determined from the 32-bit IP "" ""address the system to which the system is bound with ring identifier of 0. "" ""The node identifier value of zero is reserved and should not be used."" msgstr """" ""<placeholder-1/> 在使用 IPv4 的网络环境中是可选配置，但在 IPv6 的网络环境中则"" ""必须进行配置。它是一个 32 位的数字，用于在整个集群中标识一台节点服务器。在 "" ""IPv4 网络环境中如果不进行配置，节点 ID 将根据 ring0 对应的 IP 地址自动生成。"" ""节点 ID 0 是保留值，不能在配置文件中使用。"" msgid ""Install packages"" msgstr ""安装软件包"" msgid """" ""On any host that is meant to be part of a Pacemaker cluster, you must first "" ""establish cluster communications through the Corosync messaging layer. This "" ""involves installing the following packages (and their dependencies, which "" ""your package manager will normally install automatically):"" msgstr """" ""Pacemaker 中的节点服务器之间必须通过 Corosync 建立集群通信，需要安装以下软件"" ""包(以及它们的依赖软件包，通常软件包管理器将自动所有依赖软件包)："" msgid """" ""<package>pacemaker</package> (Note that the crm shell should be downloaded "" ""separately.)"" msgstr """" ""<package>pacemaker</package> （说明：crm 命令行工具需要另外单独下载。）"" msgid ""crmsh"" msgstr ""crmsh"" msgid ""corosync"" msgstr ""corosync"" msgid ""cluster-glue"" msgstr ""cluster-glue"" msgid """" ""<package>fence-agents</package> (Fedora only; all other distributions use "" ""fencing agents from <package>cluster-glue</package>)"" msgstr """" ""<package>fence-agents</package> （说明：只针对 Fedora 发行版；其它 Linux 发行"" ""版都使用 <package>cluster-glue</package> 软件包中的 fence 资源代理）"" msgid ""resource-agents"" msgstr ""resource-agents""msgid """" ""Once your Pacemaker cluster is set up, it is recommended to set a few basic "" ""cluster properties. To do so, start the <placeholder-1/> shell and change "" ""into the configuration menu by entering <literal>configure</literal>. "" ""Alternatively, you may jump straight into the Pacemaker configuration menu "" ""by typing <placeholder-2/> directly from a shell prompt."" msgstr """" ""Pacemaker 启动之后，建议首先对集群基本属性进行配置。配置时，首先执行 "" ""<placeholder-1/> 命令，然后输入 <literal>configure</literal> 进入配置菜单。也"" ""可以执行 <placeholder-2/> 命令直接进入 Pacemaker 配置菜单。"" msgid ""Then, set the following properties:"" msgstr ""然后，设置下列属性：""""Pacemaker uses an event-driven approach to cluster state processing. "" ""However, certain Pacemaker actions occur at a configurable interval, "" ""<placeholder-1/>, which defaults to 15 minutes. It is usually prudent to "" ""reduce this to a shorter interval, such as 5 or 3 minutes.""""Pacemaker 处理集群状况时使用事件驱动机制。但是某些 Pacemaker 操作只会在固定的"" ""时间间隔触发。该时间间隔可以配置，<placeholder-1/>，默认值是 15 分钟。针对特"" ""定的集群，可以适当缩短这一间隔，如 5 分钟或者 3 分钟。"" msgid """" ""Once you have made these changes, you may <literal>commit</literal> the "" ""updated configuration."" msgstr ""作完这些改变后，可以提交更新配置。""msgid """" ""Corosync is started as a regular system service. Depending on your "" ""distribution, it may ship with an LSB init script, an upstart job, or a "" ""systemd unit file. Either way, the service is usually named <systemitem "" ""class=\""service\"">corosync</systemitem>:"" msgstr """" ""Corosync 启动方法和普通的系统服务没有区别，根据 Linux 发行版的不同，可能是 "" ""LSB init 脚本、upstart 任务、systemd 服务。不过习惯上，都会统一使用 "" ""<systemitem class=\""service\"">corosync</systemitem> 这一名称："" msgid ""You can now check the Corosync connectivity with two tools."" msgstr ""使用以下两个工具检查 Corosync 连接状态。""""The <placeholder-1/> utility can be used to dump the Corosync cluster member "" ""list:"" msgstr ""<placeholder-1/> 命令可以列出 Corosync 集群的成员节点列表："" msgid """" ""You should see a <literal>status=joined</literal> entry for each of your "" ""constituent cluster nodes."" msgstr ""status=joined标示着每一个集群节点成员。"" msgid """" ""If you are using Corosync version 2, use the <placeholder-1/> utility as it "" ""is a direct replacement for <placeholder-2/>.""""如果使用 Corosync v2 版本，请使用 <placeholder-2/> 命令的替代命令 "" ""<placeholder-1/> 。"" msgid ""Configure OpenStack services to use RabbitMQ"" msgstr ""配置 OpenStack 各服务使用高可用的 RabbitMQ 服务""""We have to configure the OpenStack components to use at least two RabbitMQ "" ""nodes.""""现在可以配置 OpenStack 其它组件使用高可用 RabbitMQ 集群（最少使用其中 2 台节"" ""点服务器）。"" msgid ""Do this configuration on all services using RabbitMQ:"" msgstr ""对所有使用 RabbitMQ 的组件进行配置："" msgid ""RabbitMQ HA cluster host:port pairs:"" msgstr ""RabbitMQ HA 集群服务地址及端口："" msgid ""How frequently to retry connecting with RabbitMQ:"" msgstr ""重新尝试连接 RabbitMQ 服务的时间间隔："" msgid ""How long to back-off for between retries when connecting to RabbitMQ:"" msgstr ""每次重新尝试连接 RabbitMQ 服务应后延多长时间：""""Maximum retries with trying to connect to RabbitMQ (infinite by default):"" msgstr ""连接 RabbitMQ 服务时最大的重试次数（默认没有限制）："" msgid ""Use durable queues in RabbitMQ:"" msgstr ""是否使用持久的消息队列："" msgid ""Use HA queues in RabbitMQ (x-ha-policy: all):"" msgstr ""否使用 RabbitMMQ 的队列镜像特性（ x-ha-policy: all ）："" msgid """" ""If you change the configuration from an old setup which did not use HA "" ""queues, you should interrupt the service:""""如果是直接俢改没有启用队列镜像特性的 RabbitMQ 服务的配置，那么对服务作一次重"" ""置："" msgid ""Services currently working with HA queues:"" msgstr ""目前支持高可用 RabbitMQ 服务的 OpenStack 组件有："" msgid ""OpenStack Compute"" msgstr ""OpenStack 计算服务"" msgid ""OpenStack Block Storage"" msgstr ""OpenStack 块设备存储服务"" msgid ""OpenStack Networking"" msgstr ""OpenStack 网络服务"" msgid ""Telemetry"" msgstr ""Telemetry"" msgid ""On Ubuntu and Debian"" msgstr ""对于 Ubuntu 和 Debian 发行版"" msgid ""RabbitMQ is packaged on both distros:"" msgstr ""RabbitMQ 已经有可用的软件安装包："" msgid ""Official manual for installing RabbitMQ on Ubuntu and Debian"" msgstr ""在 Ubuntu 和 Debian 发行版上安装 RabbitMQ 的官方文档"" msgid ""On Fedora and RHEL"" msgstr ""对于 Fedora 和 RHEL 发行版"" msgid ""Official manual for installing RabbitMQ on Fedora and RHEL"" msgstr ""在 Fedora 和 RHEL 发行版上安装 RabbitMQ 的官方文档"" msgid ""On openSUSE and SLES"" msgstr ""对 openSUSE 和 SLES 发行版"" msgid ""On openSUSE:"" msgstr ""在 openSUSE 系统中："" msgid ""Official manual for installing RabbitMQ on openSUSE"" msgstr ""在 openSUSE 发行版上安装 RabbitMQ 的官方文档""msgid ""Configure RabbitMQ"" msgstr ""配置 RabbitMQ""""Mirrored queues in RabbitMQ improve the availability of service since it "" ""will be resilient to failures."" msgstr ""RabbitMQ 实现队列镜像更能提高整个集群的高可用性。"" msgid """" ""We consider that we run (at least) two RabbitMQ servers and we call the "" ""nodes <literal>rabbit1</literal> and <literal>rabbit2</literal>. To build a "" ""broker, we need to ensure that all nodes have the same Erlang cookie file.""""示例中会布署 2 台 RabbitMQ 服务器，<literal>rabbit1</literal> 和 "" ""<literal>rabbit2</literal>。要构建一个 RabbitMQ broker 服务，必须保证所有节点"" ""服务器的 Erlang cookie 文件完全相同。""""To do so, stop RabbitMQ everywhere and copy the cookie from the first node "" ""to the other node(s):""""因此，首先在所有节点服务器停止 RabbitMQ 服务，然后将第一台节点服务上的 "" ""cookis 文件复制到其它节点："" msgid ""NODE"" msgstr ""NODE"" msgid ""To verify the cluster status:"" msgstr ""检查集群状态：""""If the cluster is working, you can now proceed to creating users and "" ""passwords for queues."" msgstr ""如果集群运行正常，就可以开始为消息队列创建用户和密码。"" msgid """" ""More information about <link href=\""http://www.rabbitmq.com/ha.html\""> "" ""highly available queues</link> and <link href=\""https://www.rabbitmq.com/"" ""clustering.html\""> clustering</link> can be found in the official RabbitMQ "" ""documentation.""""关于 RabbitMQ 的高可用配置，请参阅 RabbitMQ 的官方文档：<link href=\""http://"" ""www.rabbitmq.com/ha.html\""> highly available queues</link> and <link href="" ""\""https://www.rabbitmq.com/clustering.html\""> clustering</link>。"" msgid ""Highly available neutron metadata agent"" msgstr ""高可用 neutron metadata 代理程序""""Neutron metadata agent allows Compute API metadata to be reachable by VMs on "" ""tenant networks. High availability for the metadata agent is achieved by "" ""adopting Pacemaker.""""Neutron metadata 代理程序的作用是让运行在租户网络上的虚拟机实例能够访问 "" ""OpenStack 计算服务 API 元数据。Neutron metadata 代理程序的高可用也通过 "" ""Pacemaker 实现。"" msgid ""Add neutron metadata agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron metadata 代理程序资源""""<literal>p_neutron-metadata-agent</literal>, a resource for manage Neutron "" ""Metadata Agent service"" msgstr """" ""<literal>p_neutron-metadata-agent</literal>资源，对 neutron metadata 代理程序"" ""进行管理。"" msgid """" ""<literal>crm configure</literal> supports batch input, so you may copy and "" ""paste the above into your live Pacemaker configuration, and then make "" ""changes as required."" msgstr """" ""<literal>crm configure</literal> 支持批量输入，因此可以拷贝粘贴上面到现有的 "" ""Pacemaker 配置中，然后根据需要再作修改。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron metadata agent service, and its "" ""dependent resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""metadata 代理程序（包括所有相关资源）。"" msgid ""Highly available neutron L3 agent"" msgstr ""高可用 neutron L3 代理程序"" msgid """" ""The neutron L3 agent provides L3/NAT forwarding to ensure external network "" ""access for VMs on tenant networks. High availability for the L3 agent is "" ""achieved by adopting Pacemaker."" msgstr """" ""Neutron L3 代理程序负责实现 L3/NAT 转发，让运行在租户网络上的虚拟机实例能够访"" ""问外部网络。Neutron L3 代理程序实现高可用也基于 Pacemaker 。"" msgid ""Add neutron L3 agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron L3 代理程序资源"" msgid """" ""You may now proceed with adding the Pacemaker configuration for neutron L3 "" ""agent resource. Connect to the Pacemaker cluster with <literal>crm "" ""configure</literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 neutron L3 代理程序相关资源。执行 <literal>crm "" ""configure</literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid """" ""<literal>p_neutron-l3-agent</literal>, a resource for manage Neutron L3 "" ""Agent service"" msgstr """" ""<literal>p_neutron-l3-agent</literal>资源，对 neutron L3 代理程序进行管理。"" msgid """" ""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron L3 agent service, and its dependent "" ""resources, on one of your nodes."" msgstr """" ""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""L3 代理程序（包括所有相关资源）。"" msgid """" ""This method does not ensure a zero downtime since it has to recreate all the "" ""namespaces and virtual routers on the node."" msgstr """" ""这种高可用方案不能实现“零停机”需求，原因是neutron L3 代理程序切换时需要重新创"" ""建网络命名空间和虚拟路由器。"" msgid ""Manage network resources"" msgstr ""组织网络相关资源"" msgid """" ""You can now add the Pacemaker configuration for managing all network "" ""resources together with a group. Connect to the Pacemaker cluster with """"创建一个资源组将所有网络服务相关资源联系起来。执行 <literal>crm configure</"" ""literal> 命令进入 Pacemaker 配置菜单，然后加入下列集群资源："" msgid ""Highly available neutron DHCP agent"" msgstr ""高可用 neutron DHCP 代理程序"" msgid ""Add neutron DHCP agent resource to Pacemaker"" msgstr ""在 Pacemaker 中添加 neutron DHCP 代理程序资源"" msgid """" ""You may now proceed with adding the Pacemaker configuration for neutron DHCP "" ""agent resource. Connect to the Pacemaker cluster with <literal>crm "" ""configure</literal>, and add the following cluster resources:"" msgstr """" ""现在可以在 Pacemaker 中填加 neutron DHCP 代理程序相关资源。执行 <literal>crm ""msgid ""This configuration creates:"" msgstr ""该配置会创建：""""Once completed, commit your configuration changes by entering "" ""<literal>commit</literal> from the <literal>crm configure</literal> menu. "" ""Pacemaker will then start the neutron DHCP agent service, and its dependent "" ""resources, on one of your nodes.""""配置完成后，在 <literal>crm configure</literal> 菜单下输入 <literal>commit</"" ""literal> 提交所有配置变更。随后 Pacemaker 会其中一台节点服务器上启动 neutron "" ""DHCP 代理程序（包括所有相关资源）。""",3288,3297
openstack%2Fsecurity-doc~master~I65999334b91248e317a45df2131f9e4167a6ed77,openstack/security-doc,master,I65999334b91248e317a45df2131f9e4167a6ed77,Imported Translations from Transifex,MERGED,2015-05-28 06:01:31.000000000,2015-05-28 06:57:54.000000000,2015-05-28 06:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-28 06:01:31.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/806600885e28209f6e863eb928425afc0ed1f4cf', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I65999334b91248e317a45df2131f9e4167a6ed77\n'}]",0,186266,806600885e28209f6e863eb928425afc0ed1f4cf,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I65999334b91248e317a45df2131f9e4167a6ed77
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/66/186266/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,806600885e28209f6e863eb928425afc0ed1f4cf,transifex/translations,"""POT-Creation-Date: 2015-05-27 10:00+0000\n"" ""PO-Revision-Date: 2015-05-27 09:57+0000\n""msgid ""!EXP"" msgstr ""!EXP"" msgid ""!LOW:!MEDIUM"" msgstr ""!LOW:!MEDIUM"" msgid ""!MD5"" msgstr ""!MD5"" msgid ""!RC4"" msgstr ""!RC4"" msgid ""!aNULL:!eNULL"" msgstr ""!aNULL:!eNULL""""\""<emphasis>any information about an individual maintained by an agency, "" ""including (1) any information that can be used to distinguish or trace an "" ""individual's identity, such as name, social security number, date and place "" ""of birth, mother's maiden name, or biometric records; and (2) any other "" ""information that is linked or linkable to an individual, such as medical, "" ""educational, financial, and employment information</emphasis>\""""""\""<emphasis>政府機関が保有するあらゆる個人情報、(1)個人を特定、追跡しうるあら"" ""ゆる情報、たとえば氏名、社会保障番号、出生年月日、出生地、母の旧姓、生体情報"" ""など。および、(2)個人に結びつく、結びつけられるあらゆる情報、たとえば医療、教"" ""育、金融、雇用情報など</emphasis>\""""""\""<emphasis>provide system-inherent separation mechanisms to the resources "" ""of virtual machines. This separation ensures that large software component "" ""used for virtualizing and simulating devices executing for each virtual "" ""machine cannot interfere with each other. Using the SELinux multi-category "" ""mechanism, the virtualization and simulation software instances are "" ""isolated. The virtual machine management framework configures SELinux multi-"" ""category settings transparently to the administrator</emphasis>\""""""\""<emphasis>provide system-inherent separation mechanisms to the resources "" ""of virtual machines. This separation ensures that large software component "" ""used for virtualizing and simulating devices executing for each virtual "" ""machine cannot interfere with each other. Using the SELinux multi-category "" ""mechanism, the virtualization and simulation software instances are "" ""isolated. The virtual machine management framework configures SELinux multi-"" ""category settings transparently to the administrator</emphasis>\"" (システム固"" ""有の分離機構を仮想マシンのリソースに提供する。この分離により、各仮想マシン用"" ""に実行される仮想および擬似デバイスに対して使用される大規模なソフトウェアコン"" ""ポーネントが、お互いに干渉しないことを保証する。仮想マシンの管理フレームワー"" ""クは、管理者に対して SELinux のマルチカテゴリ設定を透過的に設定する。)""""\""The <link href=\""http://www.fedramp.gov\"">Federal Risk and Authorization "" ""Management Program</link> (FedRAMP) is a government-wide program that "" ""provides a standardized approach to security assessment, authorization, and "" ""continuous monitoring for cloud products and services\"". NIST 800-53 is the "" ""basis for both FISMA and FedRAMP which mandates security controls "" ""specifically selected to provide protection in cloud environments. FedRAMP "" ""can be extremely intensive from specificity around security controls, and "" ""the volume of documentation required to meet government standards.""""\""<link href=\""http://www.fedramp.gov\"">Federal Risk and Authorization "" ""Management Program</link> (FedRAMP)は米国連邦政府全体のプログラムであり、クラ"" ""ウド製品とサービスのセキュリティ評価、認証、および継続的モニタリングの、標準"" ""化された手順を提供します\"" NIST 800-53はFISMAとRedRAMPの両方の基礎であり、特"" ""にクラウド環境における保護を提供するために選択されたセキュリティ統制を強制し"" ""ます。セキュリティ統制に関する具体性と政府標準を満たすための文書量を、FedRAMP"" ""は徹底しています。""""* Features in this table might not be applicable to all hypervisors or "" ""directly mappable between hypervisors.""""* この表にある機能はすべてのハイパーバイザーに適用できないかもしれません。ま"" ""た、ハイパーバイザー間で直接対応付けできないかもしれません。"" msgid ""-"" msgstr ""-"" msgid ""1024, 2048, or 3072 bits"" msgstr ""1024、2048、3072 ビット"" msgid ""128, 192, or 256 bit"" msgstr ""128、196、256 ビット"" msgid ""128, 192, or 256 bits"" msgstr ""128、196、256 ビット"" msgid ""168 bits"" msgstr ""168 ビット"" msgid ""2013"" msgstr ""2013"" msgid ""2013-07-02"" msgstr ""2013-07-02"" msgid ""2013-10-17"" msgstr ""2013-10-17"" msgid ""2013-12-02"" msgstr ""2013-12-02"" msgid ""2014"" msgstr ""2014"" msgid ""6000"" msgstr ""6000"" msgid ""6001"" msgstr ""6001"" msgid ""6002"" msgstr ""6002"" msgid ""873"" msgstr ""873""""<anchor xml:id=\""PCI-SIG_I.2FO_virtualization_.28IOV.29\""/>PCI-SIG I/O "" ""virtualization""""<anchor xml:id=\""PCI-SIG_I.2FO_virtualization_.28IOV.29\""/>PCI-SIG I/O 仮想化""""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://"" ""docs.openstack.org/user-guide/content/cli_openrc.html\"">Download and source "" ""the OpenStack RC file</link>""""<citetitle>OpenStack エンドユーザーガイド</citetitle> の項 <link href="" ""\""http://docs.openstack.org/ja/user-guide/content/cli_openrc.html"" ""\"">OpenStack RC ファイルのダウンロードと読み込み</link>""""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://"" ""docs.openstack.org/user-guide/content/section_cli_overview.html\"">command-"" ""line clients overview</link>""""<citetitle>OpenStack エンドユーザーガイド</citetitle> の項: <link href="" ""\""http://docs.openstack.org/ja/user-guide/content/section_cli_overview.html"" ""\"">コマンドラインクライアントの概要</link>""""<citetitle>OpenStack Operations Guide</citetitle> on <link href=\""http://"" ""docs.openstack.org/openstack-ops/content/backup_and_recovery.html\"">backup "" ""and recovery</link>""""<citetitle>OpenStack 運用ガイド</citetitle> の <link href=\""http://docs."" ""openstack.org/openstack-ops/content/backup_and_recovery.html\"">バックアップと"" ""リカバリー</link>"" msgid ""<emphasis role=\""bold\"">Andrew Hay</emphasis>, CloudPassage"" msgstr ""<emphasis role=\""bold\"">Andrew Hay</emphasis>, CloudPassage"" msgid ""<emphasis role=\""bold\"">Ben de Bont</emphasis>, HP"" msgstr ""<emphasis role=\""bold\"">Ben de Bont</emphasis>, HP"" msgid ""<emphasis role=\""bold\"">Bryan D. Payne</emphasis>, Nebula"" msgstr ""<emphasis role=\""bold\"">Bryan D. Payne</emphasis>, Nebula"" msgid ""<emphasis role=\""bold\"">Cody Bunch</emphasis>, Rackspace"" msgstr ""<emphasis role=\""bold\"">Cody Bunch</emphasis>, Rackspace""""<emphasis role=\""bold\"">Control selection:</emphasis>Based upon system "" ""security category as defined in FIPS 199, an organization utilizes FIPS 200 "" ""to identify specific security control requirements for the information "" ""system. For example, if a system is categorized as \""moderate\"" a "" ""requirement may be introduced to mandate \""secure passwords\"".""""<emphasis role=\""bold\"">統制の選択</emphasis> FIPS 199で定められたシステムセ"" ""キュリティのカテゴリにもとづき、組織は情報システムのための特定のセキュリティ"" ""統制要求を特定すべく、FIPS 200を活用します 。たとえば、もしシステムが「中程"" ""度」と分類されているのであれば、「安全なパスワード」の強制が求められるでしょ"" ""う。""""<emphasis role=\""bold\"">Control tailoring:</emphasis> Once system security "" ""controls are identified, an OpenStack architect will utilize NIST 800-53 to "" ""extract tailored control selection. For example, specification of what "" ""constitutes a \""secure password\"".""""<emphasis role=\""bold\"">統制の適用</emphasis> システムのセキュリティが特定さ"" ""れれば、OpenStackアーキテクトは選択した統制を適用するために、NIST 800-53を活"" ""用します。たとえば、「安全なパスワード」の構成を仕様化するなど。"" msgid ""<emphasis role=\""bold\"">Eric Lopez</emphasis>, VMware"" msgstr ""<emphasis role=\""bold\"">Eric Lopez</emphasis>, VMware"" msgid ""<emphasis role=\""bold\"">Eric Windisch</emphasis>, Cloudscaling"" msgstr ""<emphasis role=\""bold\"">Eric Windisch</emphasis>, Cloudscaling""""<emphasis role=\""bold\"">Gregg Tally</emphasis>, Johns Hopkins University "" ""Applied Physics Laboratory""""<emphasis role=\""bold\"">Gregg Tally</emphasis>, Johns Hopkins University "" ""Applied Physics Laboratory""""<emphasis role=\""bold\"">Highly capable groups</emphasis> — This refers to "" ""'Hacktivist' type organizations who are not typically commercially funded "" ""but can pose a serious threat to service providers and cloud operators.""""<emphasis role=\""bold\"">非常に有能な組織</emphasis> — これは通常ビジネスから"" ""資金を調達しているのではありませんが、サービスプロバイダーやクラウドオペレー"" ""ターに対して重大な脅威をもたらす可能性のある「ハクティビスト」タイプの組織の"" ""ことを指します。""msgid """" ""<emphasis role=\""bold\"">Intelligence services</emphasis> — Considered by "" ""this guide as the most capable adversary. Intelligence Services and other "" ""state actors can bring tremendous resources to bear on a target. They have "" ""capabilities beyond that of any other actor. It is very difficult to defend "" ""against these actors without incredibly stringent controls in place, both "" ""human and technical."" msgstr """" ""<emphasis role=\""bold\"">インテリジェンスサービス</emphasis> — このガイドでは"" ""最も有能な攻撃者とされています。インテリジェンスサービスやその他の国家主体"" ""は、ターゲットに圧力をかけるために莫大なリソースを費やすことができます。他の"" ""どのアクターよりも能力があります。人や技術両方の面で非常に厳しい制御なしで"" ""は、これらのアクターから防御することは極めて困難です。"" msgid ""<emphasis role=\""bold\"">Keith Basil</emphasis>, Red Hat"" msgstr ""<emphasis role=\""bold\"">Keith Basil</emphasis>, Red Hat"" msgid ""<emphasis role=\""bold\"">Malini Bhandaru</emphasis>, Intel"" msgstr ""<emphasis role=\""bold\"">Malini Bhandaru</emphasis>, Intel""""<emphasis role=\""bold\"">Motivated individuals</emphasis> — Acting alone, "" ""these attackers come in many guises, such as rogue or malicious employees, "" ""disaffected customers, or small-scale industrial espionage.""""<emphasis role=\""bold\"">動機のある個人</emphasis> — 一人で行動するこれらの攻"" ""撃者は、詐欺師または悪意のある従業員、不満を持った顧客、小規模の産業スパイな"" ""ど多くのものに扮して攻撃します。""""<emphasis role=\""bold\"">Nathanael Burton</emphasis>, National Security Agency""""<emphasis role=\""bold\"">Nathanael Burton</emphasis>, National Security Agency"" msgid ""<emphasis role=\""bold\"">Robert Clark</emphasis>, HP"" msgstr ""<emphasis role=\""bold\"">Robert Clark</emphasis>, HP"" msgid ""<emphasis role=\""bold\"">Rodney D. Beede</emphasis>, Seagate Technology"" msgstr ""<emphasis role=\""bold\"">Rodney D. Beede</emphasis>, Seagate Technology""""<emphasis role=\""bold\"">Script kiddies</emphasis> — Automated vulnerability "" ""scanning/exploitation. Non-targeted attacks. Often only a nuisance, "" ""compromise by one of these actors presents a major risk to an organization's "" ""reputation.""""<emphasis role=\""bold\"">スクリプトキディ</emphasis> — 自動化された脆弱性のス"" ""キャンやエクスプロイト。非標的型の攻撃。単なるいたずらの場合が多く、上記のア"" ""クターのいずれかによる情報漏洩により組織の評判に大きなリスクを与えます。"" msgid ""<emphasis role=\""bold\"">Shawn Wells</emphasis>, Red Hat"" msgstr ""<emphasis role=\""bold\"">Shawn Wells</emphasis>, Red Hat""""<emphasis>Code injection</emphasis>: If memory or disk transfers are not "" ""handled securely, then an attacker could manipulate executables, either on "" ""disk or in memory, during the migration.""""<emphasis>コードの挿入</emphasis>: メモリやディスクの転送が安全ではない場合、"" ""マイグレーション中に攻撃者によってディスクやメモリ上の実行ファイルが操作され"" ""る可能性があります。""""<emphasis>Data exposure</emphasis>: Memory or disk transfers must be handled "" ""securely.""""<emphasis>データの公開</emphasis>: メモリやディスクの転送は安全に行う必要があ"" ""ります。"" msgid """" ""<emphasis>Data manipulation</emphasis>: If memory or disk transfers are not "" ""handled securely, then an attacker could manipulate user data during the "" ""migration."" msgstr """" ""<emphasis>データの操作</emphasis>: メモリやディスクの転送がセキュアに処理され"" ""なければ、攻撃者がマイグレーション中にユーザーデータを操作できる可能性があり"" ""ます。"" msgid """" ""<emphasis>Denial of Service (DoS)</emphasis>: If something fails during the "" ""migration process, the instance could be lost."" msgstr """" ""<emphasis>Denial of Service (DoS)</emphasis>: マイグレーションプロセス中に何"" ""かが失敗した場合、インスタンスを失う可能性があります。"" msgid ""<filename>$PGDATA/root.crl</filename> - Certificate revocation list"" msgstr ""<filename>$PGDATA/root.crl</filename> - 証明書失効リスト"" msgid ""<filename>$PGDATA/root.crt</filename> - Trusted certificate authorities"" msgstr ""<filename>$PGDATA/root.crt</filename> - 信頼された認証局"" msgid ""<filename>$PGDATA/server.crt</filename> - Server certificate"" msgstr ""<filename>$PGDATA/server.crt</filename> - サーバー証明書"" msgid """" ""<filename>$PGDATA/server.key</filename> - Private key corresponding to "" ""<filename>server.crt</filename>"" msgstr """" ""<filename>$PGDATA/server.key</filename> - <filename>server.crt</filename> に"" ""対応する秘密鍵"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/1aa-logical-neutron-flow.png'; "" ""md5=3589a1ef10ea2bbe189ca90e3c932df2"" msgstr """" ""@@image: 'static/1aa-logical-neutron-flow.png'; "" ""md5=3589a1ef10ea2bbe189ca90e3c932df2"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/1aa-network-domains-diagram.png'; "" ""md5=135806775939d9e5e750264d8a5fe8de"" msgstr """" ""@@image: 'static/1aa-network-domains-diagram.png'; "" ""md5=135806775939d9e5e750264d8a5fe8de"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/book-sprint-all-logos.png'; "" ""md5=f2d97c3130c32f31412f5af41ad72d39"" msgstr """" ""@@image: 'static/book-sprint-all-logos.png'; "" ""md5=f2d97c3130c32f31412f5af41ad72d39"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/bridging_domains_clouduser.png'; "" ""md5=17c8a233ee7de17d2f600c7f6f6afe24"" msgstr """" ""@@image: 'static/bridging_domains_clouduser.png'; "" ""md5=17c8a233ee7de17d2f600c7f6f6afe24"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/bridging_security_domains_1.png'; "" ""md5=0d5ca26c51882ce3253405e91a597715"" msgstr """" ""@@image: 'static/bridging_security_domains_1.png'; "" ""md5=0d5ca26c51882ce3253405e91a597715"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/databaseusername.png'; md5=a6a5dadedbc1517069ca388c7ac5940a"" msgstr """" ""@@image: 'static/databaseusername.png'; md5=a6a5dadedbc1517069ca388c7ac5940a"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/databaseusernamessl.png'; "" ""md5=9c43242c47eb159b6f61ac41f3d8bced"" msgstr """" ""@@image: 'static/databaseusernamessl.png'; "" ""md5=9c43242c47eb159b6f61ac41f3d8bced"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/filteringWorkflow1.png'; "" ""md5=c144af5cbdee1bd17a7bde0bea5b5fe7"" msgstr """" ""@@image: 'static/filteringWorkflow1.png'; "" ""md5=c144af5cbdee1bd17a7bde0bea5b5fe7"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid ""@@image: 'static/group.png'; md5=aec1f0af66d29c1a5d1f174df1f12812"" msgstr ""@@image: 'static/group.png'; md5=aec1f0af66d29c1a5d1f174df1f12812"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/high-capability.png'; md5=b7ab599c8b40558a52c0ca86aad89741"" msgstr """" ""@@image: 'static/high-capability.png'; md5=b7ab599c8b40558a52c0ca86aad89741"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/node-provisioning-pxe.png'; "" ""md5=51b76c5aced74f935490b37ba921dc43"" msgstr """" ""@@image: 'static/node-provisioning-pxe.png'; "" ""md5=51b76c5aced74f935490b37ba921dc43"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/novaconductor.png'; md5=dbc1ba139bd1af333f0415bb48704843"" msgstr """" ""@@image: 'static/novaconductor.png'; md5=dbc1ba139bd1af333f0415bb48704843"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/sdn-connections.png'; md5=1de9169834b34c83f574f2a1225b27f0"" msgstr """" ""@@image: 'static/sdn-connections.png'; md5=1de9169834b34c83f574f2a1225b27f0"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/services-protocols-ports.png'; "" ""md5=fb1e9f47d969127b7a5ca683d38cfe20"" msgstr """" ""@@image: 'static/services-protocols-ports.png'; "" ""md5=fb1e9f47d969127b7a5ca683d38cfe20""#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all.""@@image: 'static/threat_actors.png'; md5=114c2f9bd9d0319bdd83f9e229d44649""""@@image: 'static/threat_actors.png'; md5=114c2f9bd9d0319bdd83f9e229d44649"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all.""@@image: 'static/untrusted_trusted.png'; md5=a582dac2ad0b3f439fd4b08386853056""""@@image: 'static/untrusted_trusted.png'; md5=a582dac2ad0b3f439fd4b08386853056"" msgid """" ""A <emphasis>bridge</emphasis> is a component that exists inside more than "" ""one security domain. Any component that bridges security domains with "" ""different trust levels or authentication requirements must be carefully "" ""configured. These bridges are often the weak points in network architecture. "" ""A bridge should always be configured to meet the security requirements of "" ""the highest trust level of any of the domains it is bridging. In many cases "" ""the security controls for bridges should be a primary concern due to the "" ""likelihood of attack.""""<emphasis>ブリッジ</emphasis>とは、複数のセキュリティドメイン内に存在するコン"" ""ポーネントです。異なる信頼レベルまたは認証要件が指定されたセキュリテイドメイ"" ""ン間をブリッジするコンポーネントは、慎重に設定する必要があります。ネットワー"" ""クアーキテクチャの中で、これらのブリッジは弱点となることが多くなっています。"" ""常に、ブリッジするドメインの中で最も高い信頼レベルのセキュリティ要件を満たす"" ""ように、ブリッジを設定するようにしてください。多くの場合、攻撃の可能性の高さ"" ""から、主にブリッジのセキュリティ制御について考慮する必要があります。""""A bare metal server driver for Compute was under development and has since "" ""moved into a separate project called <link href=\""https://wiki.openstack.org/"" ""wiki/Ironic\"">ironic</link>. At the time of this writing, ironic does not "" ""appear to address sanitization of tenant data resident the physical hardware.""""Compute の物理サーバドライバは開発中だったのですが、<link href=\""https://"" ""wiki.openstack.org/wiki/Ironic\"">ironic</link>と呼ばれる独立したプロジェクト"" ""に移管される事になりました。この文書の執筆時点では、ironic には物理ハードウェ"" ""ア上にあるテナントデータのサニタイズ機能はまだありません。""""A cloud architect should decide what devices to make available to cloud "" ""users. Anything that is not needed should be removed from QEMU. This step "" ""requires recompiling QEMU after modifying the options passed to the QEMU "" ""configure script. For a complete list of up-to-date options simply run "" ""<placeholder-1/> from within the QEMU source directory. Decide what is "" ""needed for your deployment, and disable the remaining options.""""クラウドアーキテクトは、どのデバイスがクラウドユーザーに利用可能であるかを判"" ""断すべきです。必要ないすべてのデバイスは QEMU から削除すべきです。この手順"" ""は、QEMU 設定スクリプトに渡されるオプションを変更した後で、QEMU を再コンパイ"" ""ルする必要があります。最新の完全なオプション一覧は、QEMU ソースディレクトリの"" ""中で <placeholder-1/> を単に実行します。お使いの環境に必要なものを判断し、残"" ""りのオプションを無効化します。""""A cloud can be abstracted as a collection of logical components by virtue of "" ""their function, users, and shared security concerns, which we call security "" ""domains. Threat actors and vectors are classified based on their motivation "" ""and access to resources. Our goal is to provide you a sense of the security "" ""concerns with respect to each domain depending on your risk/vulnerability "" ""protection objectives.""""クラウドとは、セキュリティドメインと呼ばれる、機能やユーザー、共有セキュリ"" ""ティの懸念点に基づいた論理コンポーネントの集まりであると要約できます。脅威に"" ""関するアクターやベクトルは、リソースへのアクセスや動機をベースに分類されま"" ""す。OpenStack の目標は、リスクや脆弱性保護の目的にあわせてドメインごとにセ"" ""キュリティの懸念点に関する判断材料を提供することです。""""A cloud deployment is a living system. Machines age and fail, software "" ""becomes outdated, vulnerabilities are discovered. When errors or omissions "" ""are made in configuration, or when software fixes must be applied, these "" ""changes must be made in a secure, but convenient, fashion. These changes are "" ""typically solved through configuration management.""""クラウドデプロイメントは生きているシステムです。機械は老朽化して障害が発生"" ""し、ソフトウェアは古くなり、脆弱性が発見されます。設定にエラーや抜けがあった"" ""場合、ソフトウェアの修正を適用する必要が出た場合、セキュアかつ利便的に、これ"" ""らの変更を加える必要があります。通常、これらの変更は構成管理などで解決されま""""A cloud will always have bugs. Some of these will be security problems. For "" ""this reason, it is critically important to be prepared to apply security "" ""updates and general software updates. This involves smart use of "" ""configuration management tools, which are discussed below. This also "" ""involves knowing when an upgrade is necessary.""""クラウドには必ずバグがあります。その中にはセキュリティの問題も含まれていま"" ""す。このような理由から、セキュリティ更新や一般的なソフトウェア更新の適用準備"" ""を行うことが極めて重要です。例えば、構成管理ツールを賢く利用していくことにな"" ""ります。これについては以下で説明しています。また、アップグレードが必要な時期"" ""を把握することも重要です。""""A cloud will host many virtual instances, and monitoring these instances "" ""goes beyond hardware monitoring and log files which may just contain CRUD "" ""events.""""クラウドには多数の仮想インスタンスがあり、これらのインスタンスの監視はハード"" ""ウェア監視と CRUD イベントのみ含むログファイルの背後にあります。""""A complete tutorial on secure boot deployment is beyond the scope of this "" ""book. Instead, here we provide a framework for how to integrate secure boot "" ""technologies with the typical node provisioning process. For additional "" ""details, cloud architects should refer to the related specifications and "" ""software configuration manuals.""""セキュアブートのデプロイに関する完全なチュートリアルは、本書の範囲外なので、"" ""その代わりとして、標準的なノードプロビジョニングプロセスにセキュアブートテク"" ""ノロジーを統合する方法の枠組みを提供します。クラウドアーキテクトが更に詳しい"" ""情報を確認するには、関連する仕様およびソフトウェア設定のマニュアルを参照する"" ""ことをお勧めします。""""A lot of activity goes on within a cloud environment. It is a mix of "" ""hardware, operating systems, virtual machine managers, the OpenStack "" ""services, cloud-user activity such as creating instances and attaching "" ""storage, the network underlying the whole, and finally end-users using the "" ""applications running on the various instances.""""多数の活動がクラウド環境内で行われます。これはハードウェア、オペレーティング"" ""システム、仮想マシンマネージャ、OpenStackサービス群、インスタンス作成やスト"" ""レージアタッチのようなクラウド⇔ユーザ活動、全体の土台であるネットワーク、最後"" ""に様々なインスタンス上で実行されるアプリケーションを使用するエンドユーザの"" ""ミックスです。""""A major business driver for Bob is to provide an advanced networking "" ""services to his customers. Bob's customers would like to deploy multi-tiered "" ""application stacks. This multi-tiered application are either existing "" ""enterprise application or newly deployed applications. Since Bob's public "" ""cloud is a multi-tenancy enterprise service, the choice to use for L2 "" ""isolation in this environment is to use overlay networking. Another aspect "" ""of Bob's cloud is the self-service aspect where the customer can provision "" ""available networking services as needed. These networking services encompass "" ""L2 networks, L3 Routing, Network <glossterm>ACL</glossterm> and NAT. It is "" ""important that per-tenant quota's be implemented in this environment.""""ボブの主要なビジネス目的は彼の顧客に先進的なネットワークサービスを提供する事"" ""です。ボブの顧客はマルチタイアのアプリケーションスタックをデプロイしようとし"" ""ています。マルチタイアのアプリケーションは、既存の商用アプリケーションや新し"" ""くデプロイされるアプリケーションのいずれかです。ボブのパブリッククラウドはマ"" ""ルチテナントの商用サービスである為、この環境の L2 アイソレーションに使用する"" ""選択肢は、オーバレイネットワークです。ボブのクラウドの他の側面は、必要に応じ"" ""て顧客が利用可能なネットワークサービスをプロビジョンできるセルフサービス指向"" ""です。これらのネットワークサービスは、L2 ネットワーク、L3 ルーティング、ネッ"" ""トワーク<glossterm>ACL</glossterm>、NAT を含みます。\n"" ""\n"" ""It is important that per-tenant quota's be implemented in this environment.""""A network topology should be provided with highlights specifically calling "" ""out the data flows and bridging points between the security domains. Network "" ""ingress and egress points should be identified along with any OpenStack "" ""logical system boundaries. Multiple diagrams may be needed to provide "" ""complete visual coverage of the system. A network topology document should "" ""include virtual networks created on behalf of tenants by the system along "" ""with virtual machine instances and gateways created by OpenStack.""""ネットワークトポロジーは、セキュリティドメイン間のデータフローとブリッジング"" ""ポイントをはっきりと識別して強調するようにして作成すべきです。OpenStack の論"" ""理的なシステム境界とともに、ネットワークの受信および送信ポイントを明確にする"" ""ことを推奨します。システムを完全に視覚的に網羅するには、図を複数作成する必要"" ""がある場合があります。また、ネットワークトポロジーの文書には、テナントに代"" ""わってシステムが作成した仮想ネットワークや、OpenStack によって作成された仮想"" ""マシンインスタンスとゲートウェイを含めるべきです。""""A notable difference in the attack surface of public clouds is that they "" ""must provide internet access to their services. Instance connectivity, "" ""access to files over the internet and the ability to interact with the cloud "" ""controlling fabric such as the API endpoints and dashboard are must-haves "" ""for the public cloud.""""パブリッククラウドの攻撃対象領域での顕著な相違点は、サービスに対してインター"" ""ネットアクセスを提供しなければならない点です。API エンドポイントやダッシュ"" ""ボードなど、インスタンスの接続性、インターネット経由でのファイルアクセス、ク"" ""ラウド制御のファブリックとの対話機能は、パブリッククラウドで必須アイテムなの"" ""です。""""A production quality cloud should always use tools to automate configuration "" ""and deployment. This eliminates human error, and allows the cloud to scale "" ""much more rapidly. Automation also helps with continuous integration and "" ""testing.""""実稼働環境の品質を持つクラウドは設定とデプロイメントの自動化ツールを必ず使用"" ""しています。こうすることで、人的ミスをなくし、クラウドの迅速なスケールアウト"" ""が可能になります。自動化により、継続的な統合やテストが行いやすくなります。""msgid """" ""A security domain comprises users, applications, servers or networks that "" ""share common trust requirements and expectations within a system. Typically "" ""they have the same authentication and authorization (AuthN/Z) requirements "" ""and users."" msgstr """" ""セキュリティドメインは、システム内の信頼性に関する共通の要件や期待を共有する"" ""ユーザー、アプリケーション、サーバー、ネットワークのいずれかで構成されていま"" ""す。通常、これらのドメインには、同じ認証と承認 (AuthN/Z) 要件およびユーザー"" ""が指定されています。"" msgid """" ""A separate database administrator (DBA) account should be created and "" ""protected that has full privileges to create/drop databases, create user "" ""accounts, and update user privileges. This simple means of separation of "" ""responsibility helps prevent accidental misconfiguration, lowers risk and "" ""lowers scope of compromise."" msgstr """" ""データベースの作成と削除、ユーザーアカウントの作成、ユーザーの権限の更新に関"" ""する完全な権限を持つ、別々のデータベース管理者 (DBA) アカウントが作成され、保"" ""護されるべきです。これは、不注意な設定ミスを防ぎ、リスクを減らし、被害の範囲"" ""を小さくする、責任の分離を実現する簡単な方法です。"" msgid """" ""A standard OpenStack Networking setup has up to four distinct physical data "" ""center networks:"" msgstr """" ""標準的な OpenStack Networking セットアップは最大４つの物理データセンターネッ"" ""トワークがあります。"" msgid """" ""A threat actor is an abstract way to refer to a class of adversary that you "" ""may attempt to defend against. The more capable the actor, the more "" ""expensive the security controls that are required for successful attack "" ""mitigation and prevention. Security is a tradeoff between cost, usability "" ""and defense. In some cases it will not be possible to secure a cloud "" ""deployment against all of the threat actors we describe here. Those "" ""deploying an OpenStack cloud will have to decide where the balance lies for "" ""their deployment / usage."" msgstr """" ""脅威のアクターとは、防御の対象となりえる攻撃者のクラスを抽象的に表したもので"" ""す。アクターの技術が高くなるにつれ、攻撃の軽減や防止を成功させるために必要な"" ""セキュリティ制御にかかるコストが嵩みます。セキュリティはコスト、使いやすさ、"" ""防御の間でのトレードオフということになります。ここで記載した脅威のアクターす"" ""べてから、クラウドのデプロイメントを保護することはできません。OpenStack クラ"" ""ウドをデプロイする方は、デプロイメントと用途の間でバランスが確保できるポイン"" ""トを決定する必要が出てきます。"" msgid ""AES"" msgstr ""AES"" msgid ""AIDE"" msgstr ""AIDE"" msgid ""API endpoint configuration recommendations"" msgstr ""APIエンドポイント構成に関する推奨事項"" msgid ""API endpoint process isolation and policy"" msgstr ""APIエンドポイントのプロセス分離とポリシー"" msgid ""API endpoints"" msgstr ""APIエンドポイント"" msgid ""API network"" msgstr ""API ネットワーク"" msgid ""Access control lists"" msgstr ""アクセス制御リスト""msgid ""Account service"" msgstr ""アカウントサービス"" msgid ""Acknowledgments"" msgstr ""謝辞"" msgid ""Act as a reference for auditors when evaluating OpenStack deployments."" msgstr ""監査人がOpenStack環境を評価する際のリファレンスとなる"" msgid ""Active developer and user communities"" msgstr ""活発な開発者とユーザーのコミュニティ""msgid ""Additional security features"" msgstr ""追加のセキュリティ機能"" ""Additionally, Bob adds strong network ACL rulesets to enforce which "" ""endpoints can communicate with the message servers. This second control "" ""provides some additional assurance should the other protections fail.""""さらにボブは、メッセージサーバーと通信できるエンドポイントを、強力なネット"" ""ワークの ACL ルールセットで制限することにしました。この2個目の制限が、他の防"" ""御が失敗した場合の保険として機能します。"" msgid """" ""Additionally, due to the risk and complexities associated with PCI "" ""passthrough, it should be disabled by default. If enabled for a specific "" ""need, you will need to have appropriate processes in place to ensure the "" ""hardware is clean before re-issue."" msgstr """" ""加えて、PCI パススルーに関連したリスクと複雑性のため、これはデフォルトで無効"" ""化されるべきです。特定の用途のために有効化する場合、ハードウェアが再発行され"" ""る前に確実にクリアするために、適切なプロセスを実行する必要があります。"" msgid """" ""Additionally, the following security-related criteria are highly encouraged "" ""to be evaluated when selecting a hypervisor for OpenStack deployments:"" msgstr """" ""加えて、OpenStack 環境のハイパーバイザーを選択する際に、以下のセキュリティ関"" ""連の認証を評価することが推奨されます。"" msgid """" ""Additionally, when combined with a version control system such as Git or "" ""SVN, you can track changes to your environment over time and re-mediate "" ""unauthorized changes that may occur. For example, a <filename>nova.conf</"" ""filename> file or other configuration file falls out of compliance with your "" ""standard, your configuration management tool can revert or replace the file "" ""and bring your configuration back into a known state. Finally a "" ""configuration management tool can also be used to deploy updates; "" ""simplifying the security patch process. These tools have a broad range of "" ""capabilities that are useful in this space. The key point for securing your "" ""cloud is to choose a tool for configuration management and use it."" msgstr """" ""さらに、Git や SVN などのバージョン管理システムと統合すると、経年の環境の変化"" ""をチェックして、発生する可能性のある未認証の変更を修正することができます。例"" ""えば、<filename>nova.conf</filename> ファイルやその他の設定ファイルが規格に準"" ""拠しなくなった場合、既知の状態に構成管理ツールはファイルを復元または置き換え"" ""ることができるでしょう。最後に、構成管理ツールを使用して、更新のデプロイも可"" ""能で、セキュリティパッチのプロセスを簡素化します。これらのツールには、この項"" ""において便利な機能が幅広く含まれています。クラウドのセキュリティ確保の主な目"" ""的は、構成管理のツールを選択して使用することです。"" msgid ""Address Space Layout Randomization (ASLR)"" msgstr ""Address Space Layout Randomization (ASLR)"" msgid ""Administrative users"" msgstr ""管理ユーザー"" msgid """" ""After completing these initial certifications, the remaining certifications "" ""are more deployment specific. For example, clouds processing credit card "" ""transactions will need PCI-DSS, clouds storing health care information "" ""require HIPAA, and clouds within the federal government may require FedRAMP/"" ""FISMA, and ITAR, certifications."" msgstr """" ""これらの基本的認証を取得したのち、より環境特有の認証を検討します。たとえば、"" ""クラウドがクレジットカードのトランザクションを扱うのであればPCI-DSSが必要です"" ""し、ヘルスケア情報を保持するならHIPPAが、連邦政府向けにはFedRAMP/FISMA、ITAR"" ""認証が必要となるでしょう。""msgid """" ""After you are notified of a security update, the next step is to determine "" ""how critical this update is to a given cloud deployment. In this case, it is "" ""useful to have a pre-defined policy. Existing vulnerability rating systems "" ""such as the common vulnerability scoring system (CVSS) v2 do not properly "" ""account for cloud deployments."" msgstr """" ""セキュリティ更新を通知された後、次のステップとして、指定のクラウドデプロイメ"" ""ントにとって、この更新がどの程度重要かを判断します。このような場合、ポリシー"" ""を事前定義しておくと便利です。共通脆弱性評価システム (CVSS) v2 などの既存の脆"" ""弱性評価システムは、クラウドデプロイメントに正しく対応していません。"" msgid ""Algorithm"" msgstr ""アルゴリズム""""Alice also deploys the dashboard to manage many aspects of the cloud. She "" ""deploys the dashboard with HSTS to ensure that only HTTPS is used. The "" ""dashboard resides within an internal subdomain of the private network domain "" ""name system.""""アリスはクラウドのさまざまな観点を管理するために Dashboard も導入します。必"" ""ず HTTPS のみを使用するために HSTS と共に Dashboard を導入します。Dashboard "" ""はプライベートネットワークの DNS の内部サブドメインの中にあります。""""Alice decides to use SPICE instead of VNC for the virtual console. She wants "" ""to take advantage of the emerging capabilities in SPICE."" msgstr """" ""アリスは仮想コンソールに VNC の代わりに SPICE を使用することを決めました。"" ""SPICE の先進的な機能の利点を得ようと思います。"" msgid """" ""Alice is building an OpenStack private cloud for the United States "" ""government, specifically to provide elastic compute environments for signal "" ""processing. Alice has researched government compliance requirements, and has "" ""identified that her private cloud will be required to certify against FISMA "" ""and follow the FedRAMP accreditation process, which is required for all "" ""federal agencies, departments and contractors to become a Certified Cloud "" ""Provider (CCP). In this particular scenario for signal processing, the FISMA "" ""controls required will most likely be FISMA High, which indicates possible "" ""\""severe or catastrophic adverse effects\"" should the information system "" ""become compromised. In addition to FISMA Moderate controls Alice must ensure "" ""her private cloud is FedRAMP certified, as this is a requirement for all "" ""agencies that currently utilize, or host federal information within a cloud "" ""environment."" msgstr """" ""アリスはOpenStackプライベートクラウドを米国政府向けに構築しています。具体的に"" ""は、信号処理向けの柔軟なコンピューティング環境です。アリスは政府向けコンプラ"" ""イアンス要件を調査した結果、これから構築しようとしているプライベートクラウド"" ""はFISMAおよびFedRAMP認定が必要であると判断しました。これは政府系機関、行政"" ""部、および契約者、どのような立場であっても、認定クラウドプロバイダー"" ""(Certified Cloud Provider, CCP)になるために必要な手続きです。特に信号処理は、"" ""FISMAはそれを\""深刻で壊滅的な影響\""をシステムに与えうるとしているため、FISMA"" ""影響度が\""高\""となりがちです。加えてFISMA Moderateレベルにおいて、アリスはそ"" ""のプライベートクラウドを確実にFedRAMP認証としなければいけません。これはクラウ"" ""ド内に政府の情報を保有する、全ての機関に求められてる条件です。"" msgid """"msgid ""Alice's private cloud"" msgstr ""アリスのプライベートクラウド"" msgid """" ""All SSH daemons have private host keys and, upon connection, offer a host "" ""key fingerprint. This host key fingerprint is the hash of an unsigned public "" ""key. It is important these host key fingerprints are known in advance of "" ""making SSH connections to those hosts. Verification of host key fingerprints "" ""is instrumental in detecting man-in-the-middle attacks."" msgstr """" ""SSH デーモンにはすべてプライベートのホストキーがあり、接続するとホストキーの"" ""フィンガープリントが提供されます。このホストキーのフィンガープリントは未署名"" ""のパブリックキーのハッシュです。これらのホストに SSH 接続する前に、ホスト"" ""キーのフィンガープリントを把握しておくことが重要です。ホストキーのフィンガー"" ""プリントの検証は中間者攻撃の検出に役立ちます。"" msgid ""All database communications be isolated to a management network"" msgstr ""すべてのデータベース通信の管理ネットワークへの分離"" msgid """" ""All of the services within an OpenStack project access a single database. "" ""There are presently no reference policies for creating table or row based "" ""access restrictions to the database."" msgstr """" ""OpenStack プロジェクトの中にあるすべてのサービスは単一のデータベースにアクセ"" ""スします。データベースへのテーブルの作成や行単位のアクセス制限に関する明確な"" ""ポリシーは今のところありません。"" msgid ""Allow confined virtual guests to interact with the sanlock."" msgstr ""制限された仮想マシンが sanlock を操作することを許可します。"" msgid ""Allow virt to manage CIFS mounted files."" msgstr ""仮想化が CIFS マウントされたファイルを管理することを許可します。"" msgid ""Allow virt to manage NFS mounted files."" msgstr ""仮想化が NFS マウントされたファイルを管理することを許可します。"" msgid ""Allow virt to manage device configuration (PCI)."" msgstr ""仮想マシンがデバイス設定 (PCI) を管理することを許可します。"" msgid ""Allow virt to read FUSE mounted files."" msgstr ""仮想化が FUSE マウントされたファイルを読み取ることを許可します。"" msgid ""Allow virt to use USB devices."" msgstr ""仮想化が USB デバイスを使用することを許可します。"" msgid ""Allow virt to use serial/parallel communication ports."" msgstr """" ""仮想化がシリアル通信ポートとパラレル通信ポートを使用することを許可します。"" msgid ""Allow virtual machine to interact with the X Window System."" msgstr ""仮想マシンが X Window System と通信することを許可します。"" msgid ""Allowed hosts"" msgstr ""許可されたホスト"" msgid """" ""Also known as Data Execution Prevention (DEP), ensures that data sections of "" ""the executable can not be executed."" msgstr """" ""Data Execution Prevention (DEP) としても知られています。実行ファイルのデータ"" ""部分を必ず実行できなくします。"" msgid """" ""Although SPICE has many advantages over VNC, the spice-html5 browser "" ""integration currently doesn't really allow admins to take advantage of any "" ""of the benefits. To take advantage of SPICE features like multi-monitor, USB "" ""pass through, etc. admins are recommended to use a standalone SPICE client "" ""within the Management Network."" msgstr """" ""SPICE は VNC よりも多くの点で優れていますが、現在 spice-html5 ブラウザー統合"" ""は管理者がすべての利点を利用することができません。マルチモニター、USB パスス"" ""ルーなどの SPICE 機能の利点を利用するためには、管理ネットワークの中でスタンド"" ""アロン SPICE クライアントを使用することが推奨されます。"" msgid """" ""Although you may desire to break these domains down further (we later "" ""discuss where this may be appropriate), we generally refer to four distinct "" ""security domains which form the bare minimum that is required to deploy any "" ""OpenStack cloud securely. These security domains are:"" msgstr """" ""これらのドメインをさらに分類する場合もありますが (該当箇所で説明)、一般的に "" ""OpenStack クラウドをセキュアにデプロイしていく上で最低限必要な部分を構成す"" ""る、4 つの異なるセキュリティドメインのことを指します。以下に、これらのセキュ"" ""リティドメインを示しています。"" msgid """" ""An OpenStack deployment will likely need to demonstrate compliance with an "" ""organization's Privacy Policy, with the U.S.-E.U. Safe Harbor framework, the "" ""ISO/IEC 29100:2011 privacy framework or with other privacy-specific "" ""guidelines. In the U.S. the AICPA has <link href=\""http://www.aicpa.org/"" ""interestareas/informationtechnology/resources/privacy/"" ""generallyacceptedprivacyprinciples/\"">defined 10 privacy areas of focus</"" ""link>, OpenStack deployments within a commercial environment may desire to "" ""attest to some or all of these principles."" msgstr """" ""OpenStack環境では、組織のプライバシーポリシー、米国 - EU間のセーフハーバーフ"" ""レームワーク、ISO/IEC 29100:2011 プライバシーフレームワークなど、プライバシー"" ""特化ガイドライン遵守の証明を求められることが多いです。米国ではAICPAが<link "" ""href=\""http://www.aicpa.org/interestareas/informationtechnology/resources/"" ""privacy/generallyacceptedprivacyprinciples/\"">重視すべき10のプライバシー項目"" ""</link>を公表しており、ビジネス用途のOpenStack環境はそのうちのいくつか、もし"" ""くは全原則の立証を期待されます。"" msgid """" ""An added benefit with utilizing OpenStack Networking is when new advanced "" ""networking services become available, these new features can be easily "" ""provided to the end customers."" msgstr """" ""OpenStack Networking 利用の追加的な利点は、新しい先進的なネットワークサービス"" ""が利用可能になった場合、これらの新しい機能をエンドユーザに簡単に提供できる事"" ""です。"" msgid """" ""An example diagram from the OpenStack Object Storage Administration Guide "" ""(2013)"" msgstr ""OpenStack Object Storage Administration Guide (2013) からのサンプル図"" msgid """" ""An exception process is an important component of an ISMS. When certain "" ""actions are not compliant with security policies that an organization has "" ""defined, they must be logged. Appropriate justification, description and "" ""mitigation details need to be included, and signed off by appropriate "" ""authorities. OpenStack default configurations may vary in meeting various "" ""compliance criteria, areas that fail to meet compliance requirements should "" ""be logged, with potential fixes considered for contribution to the community."" msgstr """" ""例外プロセスはISMSの重要な要素です。とある行動が組織の定義したセキュリティポ"" ""リシーに準拠していない場合、それは記録されなければいけません。適正な理由と緩"" ""和策の詳細が含まれ、関係当局に認められる必要があります。OpenStackのデフォルト"" ""構成は、様々なコンプライアンス基準、記録されるべきコンプライアンス基準を満た"" ""すべく、変化していくでしょう。またそれは、コミュニティへの貢献によって修正さ"" ""れていく可能性があります。"" msgid """" ""An optional system to which a CA delegates certain management functions."" msgstr ""CAが一定の管理機能を委任する追加システム。"" msgid """" ""Andrew Hay is the Director of Applied Security Research at CloudPassage, "" ""Inc. where he leads the security research efforts for the company and its "" ""server security products purpose-built for dynamic public, private, and "" ""hybrid cloud hosting environments."" msgstr """" ""Andrew Hay は CloudPassage, Inc. の Applied Security Research の Director で"" ""す。社内セキュリティおよび、ダイナミックパブリック、プライベート、ハイブリッ"" ""ドクラウドのホスティング環境向けに設計されたサーバーセキュリティ製品のセキュ"" ""リティ研究チームを率いています。"" msgid ""Another as a \""private\"" interface with access to the storage nodes"" msgstr """" ""ストレージノードにアクセスする「プライベート」インターフェースとしてもう一つ"" msgid """" ""Another thing to look into when selecting a hypervisor platform is the "" ""availability of specific security features. In particular, we are referring "" ""to features like Xen Server's XSM or Xen Security Modules, sVirt, Intel TXT, "" ""and AppArmor. The presence of these features increase your security profile "" ""as well as provide a good foundation."" msgstr """" ""ハイパーバイザー選択時に検討すべき他の事項は、特定のセキュリティ機能の利用可"" ""否です。とくに、Xen Server の XSM (Xen Security Modules)、sVirt、Intel TXT、"" ""AppArmor のような機能を利用しています。これらの機能の存在は、セキュリティプロ"" ""ファイルを向上するだけでなく、良い基盤を提供します。"" msgid ""Ansible"" msgstr ""Ansible"" msgid ""Apache"" msgstr ""Apache"" msgid ""Apache Qpid Authentication"" msgstr ""Apache Qpid 認証"" msgid ""Apache Qpid Authorization"" msgstr ""Apache Qpid 認可"" msgid ""Apache Qpid SSL"" msgstr ""Apache Qpid SSL"" msgid ""Apache httpd"" msgstr ""Apache httpd"" msgid ""AppArmor"" msgstr ""AppArmor"" msgid """" ""Appropriate logging is implemented to monitor for unauthorized use, incident "" ""response and forensics. It is highly recommended that selected audit "" ""subsystems be Common Criteria certified, which provides non-attestable event "" ""records in most countries."" msgstr """" ""適切なロギングは、不正利用の監視や障害対応、証拠収集に役立ちます。多くの国に"" ""おいて、それを再度証明する必要が無い、Common Criteria認定をうけた監査サブシス"" ""テムの採用を強くおすすめします。"" msgid ""Architecture"" msgstr ""アーキテクチャー"" msgid """" ""As OpenStack adoption continues to grow and the product matures, security "" ""has become a priority. The OpenStack Security Group has recognized the need "" ""for a comprehensive and authoritative security guide. The <emphasis role="" ""\""bold\"">OpenStack Security Guide</emphasis> has been written to provide an "" ""overview of security best practices, guidelines, and recommendations for "" ""increasing the security of an OpenStack deployment. The authors bring their "" ""expertise from deploying and securing OpenStack in a variety of environments."" msgstr """" ""OpenStack が拡大を続け、製品が成熟してきたので、セキュリティが重要事項になっ"" ""てきました。OpenStack Security Group は包括的かつ権威のあるセキュリティガイド"" ""の必要性を認識しました。<emphasis role=\""bold\"">OpenStack セキュリティガイド"" ""</emphasis>は、OpenStack のセキュリティ向上を目的とした、セキュリティのベスト"" ""プラクティス、ガイドライン、推奨事項の概要について記載しています。著者は\n"" ""さまざまな環境で OpenStack の導入やセキュア化をした専門知識をもたらします。"" msgid """" ""As OpenStack is a popular open source project, much of the codebase and "" ""architecture has been scrutinized by individual contributors, organizations "" ""and enterprises. This can be advantageous from a security perspective, "" ""however the need for security reviews is still a critical consideration for "" ""service providers, as deployments vary, and security is not always the "" ""primary concern for contributors. A comprehensive security review process "" ""may include architectural review, threat modelling, source code analysis and "" ""penetration testing. There are many techniques and recommendations for "" ""conducting security reviews that can be found publicly posted. A well-tested "" ""example is the <link href=\""http://www.microsoft.com/security/sdl/process/"" ""release.aspx\"">Microsoft SDL</link>, created as part of the Microsoft "" ""Trustworthy Computing Initiative."" msgstr """" ""OpenStackは人気のあるオープンソースプロジェクトです。多くのソースコードとアー"" ""キテクチャはデベロッパー、組織、企業によって精査されています。これはセキュリ"" ""ティの観点から大きな利点ですが、セキュリティ検査はサービスプロバイダーにとっ"" ""て、それでもなお重大な懸念事項です。環境は変化しつづけますが、セキュリティは"" ""必ずしも開発者の一番の関心事ではないからです。包括的なセキュリティ検査プロセ"" ""スとして、アーキテクチャ検査、脅威のモデリング、ソースコード分析と侵入テスト"" ""などが挙げられます。そして、セキュリティ検査には広く公開されている多くのテク"" ""ニックと推奨があります。よくテストされた例として、Microsoft Trustworthy "" ""Computing Initiativeのとりくみとして作成された、<link href=\""http://www."" ""microsoft.com/security/sdl/process/release.aspx\"">Microsoft SDL</link>があり"" ""ます。"" msgid """" ""As a cloud administrator, the dashboard provides an overall view of the size "" ""and state of your cloud. You can create users and tenants/projects, assign "" ""users to tenant/projects and set limits on the resources available for them."" msgstr """" ""クラウド管理者として、ダッシュボードはクラウドのサイズや状態の俯瞰図を確認で"" ""きます。また、ユーザーやプロジェクト (テナント) の作成、プロジェクトへのユー"" ""ザーの割り当て、ユーザーやプロジェクトで利用可能なリソースの制限設定が可能で"" ""す。 "" msgid """" ""As a web service, OpenStack API is susceptible to familiar web site attack "" ""vectors such as denial of service attacks."" msgstr """" ""Web サービスとして OpenStack API は、サービス妨害 (DoS) 攻撃など、よく知られ"" ""ている Web サイト攻撃ベクトルからの影響を受けます。"" msgid """" ""As an alternative to VNC, OpenStack provides remote desktop access to guest "" ""virtual machines using the Simple Protocol for Independent Computing "" ""Environments (SPICE) protocol."" msgstr """" ""VNC の代替として、OpenStack は Simple Protocol for Independent Computing "" ""Environments (SPICE) プロトコルを使用した、仮想マシンへのリモートデスクトップ"" ""アクセスを提供します。"" msgid """" ""As both block storage and compute support LVM backed storage, we can easily "" ""provide an example applicable to both systems. In deployments using LVM, "" ""encryption may be performed against the backing physical volumes. An "" ""encrypted block device would be created using the standard Linux tools, with "" ""the LVM physical volume (PV) created on top of the decrypted block device "" ""using pvcreate. Then, the vgcreate or vgmodify tool may be used to add the "" ""encrypted physical volume to an LVM volume group (VG)."" msgstr """" ""Block Storage と Compute は両方、LVM ベースのストレージをサポートしているの"" ""で、両システムに簡単に適用可能な例を提供します。LVM を用いたデプロイでは、暗"" ""号化はベースの物理ボリュームに対して実施できます。暗号化ブロックデバイスは、"" ""pvcreate を使用して復号化したブロックデバイスの上に作成した LVM 物理ボリュー"" ""ム (PV) を用いて、標準の Linux ツールを使用して作成する事ができます。それか"" ""ら、vgcreate 又は vgmodify ツールを使用して、暗号化した物理ボリュームを LVM "" ""のボリュームグループ (VG) に追加できます。"" msgid """" ""As is the case for VNC, at this time we recommend using SPICE from the "" ""management network in addition to limiting use to few individuals."" msgstr """" ""VNC の場合のように、今のところ数人の利用者に制限して管理ネットワークから "" ""SPICE を使用することを推奨します。"" msgid """" ""As part of your hypervisor selection process, you must consider a number of "" ""important factors to help increase your security posture. Specifically, you "" ""must become familiar with these areas:"" msgstr """" ""ハイパーバイザーの選択において、セキュリティを保証するために考慮すべき重要な"" ""要因がいくつかあります。特に下記の面に注目します。"" msgid """" ""As shown above, sVirt isolation is provided regardless of the guest "" ""Operating System running inside the virtual machineLinux or Windows VMs can "" ""be used. Additionally, many Linux distributions provide SELinux within the "" ""operating system, allowing the virtual machine to protect internal virtual "" ""resources from threats."" msgstr """" ""上に示したとおり、sVirt による分離は仮想マシン内で動作しているゲストオペレー"" ""ティングシステムに関わらず提供されます。Linux や Windows の仮想マシンを使用で"" ""きます。さらに、多くの Linux ディストリビューションはオペレーティングシステム"" ""内の SELinux を提供しています。仮想マシンが内部の仮想リソースを脅威から保護で"" ""きます。"" msgid """" ""As stated during the introduction to Alice's case study, data protection is "" ""of an extremely high priority. She needs to ensure that a compromise of one "" ""tenant's data does not cause loss of other tenant data. She also has strong "" ""regulator requirements that require documentation of data destruction "" ""activities. Alice does this using the following:"" msgstr """" ""アリスのケーススタディで説明したように、データ保護は非常に重要です。アリス"" ""は、あるテナントのデータの情報漏洩が、他のテナントデータの損害を引き起こさな"" ""いように、保証することが必要です。アリスはまた、データ破壊の文書化を必要とす"" ""る強い規制上の要件を持っています。アリスは、以下の方法でこれを提供します："" msgid """" ""As stated during the introduction to Bob's case study, tenant privacy is of "" ""an extremely high priority. In addition to the requirements and actions Bob "" ""will take to isolate tenants from one another at the infrastructure layer, "" ""Bob also needs to provide assurances for tenant data privacy. Bob does this "" ""using the following:"" msgstr """" ""ボブのケーススタディの最初で説明したように、テナントのプライバシーは非常に重"" ""要です。ボブはインフラレイヤーで相互にテナントを分離する要件およびアクション"" ""に加えて、ボブはまたテナントデータのプライバシーを保する必要があります。 ボブ"" ""は以下を用いて、これを提供します："" msgid """" ""As with the OpenStack Operations Guide, we followed the book sprint "" ""methodology. The book sprint process allows for rapid development and "" ""production of large bodies of written work. Coordinators from the OpenStack "" ""Security Group re-enlisted the services of Adam Hyde as facilitator. "" ""Corporate support was obtained and the project was formally announced during "" ""the OpenStack summit in Portland, Oregon."" msgstr """" ""本書はOpenStack Operations Guide（OpenStack 運用ガイド）と同様に「ブックスプ"" ""リントメソッド」を用いました。このメソッドでは、迅速な大量文章の作成を実現し"" ""ます。OpenStack Security Group のコーディネーターは再びAdam Hydeをファシリ"" ""テーターとして力を借りました。さらに企業からのサポートが得られ、オレゴン州"" ""ポートランドで開催されたOpenStack サミットでプロジェクトが正式に公表されまし"" ""た。"" msgid """" ""At the end of the audit period Bob has arranged for an external audit team "" ""to review in-scope security controls at randomly sampled points of time over "" ""a 6 month period. The audit team provides Bob with an official report for "" ""SOC 1 and SOC 2, and separately for ISO 27001/2. As Bob has been diligent in "" ""ensuring security controls are in place for his OpenStack public cloud, "" ""there are no additional gaps exposed on the report. Bob can now provide "" ""these official reports to his customers under NDA, and advertise that he is "" ""SOC 1, SOC 2 and ISO 27001/2 compliant on his website."" msgstr """" ""監査期間の最後にボブは外部監査人チームとの調整を行います。目的は、6ヶ月以上に"" ""わたって無作為なタイミングで実施した、セキュリティ統制のレビューです。そし"" ""て、監査人チームはボブにSOC 1とSOC 2、また別途ISO 27001/2向けの公式な報告書を"" ""提供します。ボブのパブリッククラウド採用における勤勉な取り組みの結果、指摘さ"" ""れるような追加のギャップはありませんでした。ボブは正式な報告書を彼の顧客にNDA"" ""下で提供でき、また、SOC 1、SOC 2、およびISO 27001/2に準拠していることを彼の"" ""ウェブサイトでアピールできるようになりました。"" msgid """" ""At the opposite end of the spectrum is the private cloud. As NIST defines "" ""it, a private cloud is provisioned for exclusive use by a single "" ""organization comprising multiple consumers, such as business units. It may "" ""be owned, managed, and operated by the organization, a third-party, or some "" ""combination of them, and it may exist on or off premises. Private cloud use "" ""cases are diverse, as such, their individual security concerns vary."" msgstr """" ""パブリッククラウドの対極にあるのがプライベートクラウドです。NIST は、プライ"" ""ベートクラウドを、事業組織などの複数の利用者から成る単一の組織の専用使用のた"" ""めに提供されるクラウドと定義しています。プライベートクラウドの所有、管理、お"" ""よび運用は、その組織、第三者、もしくはそれらの組み合わせにより行われ、存在場"" ""所としては、その組織の施設内または外部の場合があります。プライベートクラウド"" ""のユースケースは多様であるため、セキュリティ課題もそれぞれで異なります。"" msgid """" ""At the time of this writing, very few clouds are using secure boot "" ""technologies in a production environment. As a result, these technologies "" ""are still somewhat immature. We recommend planning carefully in terms of "" ""hardware selection. For example, ensure that you have a TPM and Intel TXT "" ""support. Then verify how the node hardware vendor populates the PCR values. "" ""For example, which values will be available for validation. Typically the "" ""PCR values listed under the software context in the table above are the ones "" ""that a cloud architect has direct control over. But even these may change as "" ""the software in the cloud is upgraded. Configuration management should be "" ""linked into the PCR policy engine to ensure that the validation is always up "" ""to date."" msgstr """" ""本ガイドの執筆時点では、実稼働環境でセキュアブートテクノロジーを使用するクラ"" ""ウドはほとんどありませんでした。このため、これらのテクノロジーはまだ若干未成"" ""熟な状態です。ハードウェアは、慎重に計画した上で選択することを推奨します "" ""(例: TPM および Intel TXT の対応を確認するなど)。次に、ノードのハードウェアベ"" ""ンダーが PCR 値をどのように事前設定しているかを検証します (例: どの値を検証で"" ""きるか)。上記の表のコンテキストにソフトウェアと記載されている PCR 値は通常、"" ""クラウドアーキテクトが直接コントロールできます。ただし、これらの値は、クラウ"" ""ド内のソフトウェアをアップグレードすると変更される場合があります。設定管理"" ""は、PCR ポリシーエンジン内にリンクして、検証を常に最新の状態 に確保すべきで"" ""す。"" msgid """" ""At this point we know that the node has booted with the correct kernel and "" ""underlying components. There are many paths for hardening a given operating "" ""system deployment. The specifics on these steps are outside of the scope of "" ""this book. We recommend following the guidance from a hardening guide "" ""specific to your operating system. For example, the <link href=\""http://iase."" ""disa.mil/stigs/\"">security technical implementation guides</link> (STIG) and "" ""the <link href=\""http://www.nsa.gov/ia/mitigation_guidance/"" ""security_configuration_guides/\"">NSA guides</link> are useful starting "" ""places."" msgstr """" ""この時点で、ノードが正しいカーネルと配下のコンポーネントでブートしていること"" ""が分かります。オペレーティングシステムのデプロイメントのセキュリティを強化す"" ""るには、数多くの方法があります。これらの手順についての詳しい説明は本書の範囲"" ""外です。お使いのオペレーティングシステム固有のセキュリティ強化ガイドのアドバ"" ""イスに従うことを推奨します。例えば、<link href=\""http://iase.disa.mil/stigs/"" ""\"">security technical implementation guides</link> (STIG) や <link href="" ""\""http://www.nsa.gov/ia/mitigation_guidance/security_configuration_guides/"" ""\"">NSA guides</link> を最初に参考にすると役立ちます。"" msgid """" ""At this time, live migration is enabled in OpenStack by default. Live "" ""migrations can be disabled by adding the following lines to the nova "" ""<filename>policy.json</filename> file:"" msgstr """" ""現在、OpenStackではデフォルトでライブマイグレーションを有効にしています。ライ"" ""ブマイグレーションは nova <filename>policy.json</filename> ファイルへ下記の行"" ""を追加することによって無効化できます。"" msgid """" ""At various stages of the live migration process the contents of an instances "" ""run time memory and disk are transmitted over the network in plain text. "" ""Thus there are several risks that need to be addressed when using live "" ""migration. The following in-exhaustive list details some of these risks:"" msgstr """" ""ライブマイグレーションのステージによっては、インスタンスのランタイムメモリや"" ""ディスクの今テンスが平文でネットワーク上転送されます。そのため、ライブマイグ"" ""レーション中には対処が必要なリスクがあります。次は一部のリスクの詳細を列挙し"" ""ています。"" msgid ""Attack types"" msgstr ""攻撃の種類"" msgid ""Attacker position / Privilege level"" msgstr ""攻撃者の位置付け/権限レベル"" msgid ""Audit"" msgstr ""監査"" msgid ""Audit records can be transferred to a remote audit daemon."" msgstr ""監査レコードはリモート監査デーモンに転送できます。"" msgid ""Audit reference"" msgstr ""監査参照"" msgid ""Auth services"" msgstr ""認証サービス"" msgid ""Authentication"" msgstr ""認証"" msgid ""Authentication configuration example: Qpid"" msgstr ""認証設定例: Qpid"" msgid ""Authentication configuration example: RabbitMQ"" msgstr ""認証設定例: RabbitMQ"" msgid ""Authentication methods"" msgstr ""認証方式"" msgid ""Authentication with X.509 certificates"" msgstr ""X.509 証明書を用いた認証"" msgid ""Authentication, key exchange"" msgstr ""認証、鍵交換"" msgid ""Authorization"" msgstr ""認可"" msgid ""Availability of expertise"" msgstr ""ノウハウの入手先"" msgid ""Backup and disaster recovery"" msgstr ""バックアップと災害対策"" msgid ""Bare metal server sanitization"" msgstr ""物理サーバのサニタイズ"" msgid ""Basic web server configuration"" msgstr ""基本的なウェブサーバーの設定"" msgid """" ""Before an instance is created, a host for the image instantiation must be "" ""selected. This selection is performed by the <systemitem class=\""service"" ""\"">nova-scheduler</systemitem> which determines how to dispatch compute and "" ""volume requests."" msgstr """" ""インスタンスを生成する前に、イメージのインスタンス化のためのホストを選択する"" ""必要があります。この選択は<systemitem class=\""service\"">nova-scheduler</"" ""systemitem>によって行われ、さらにコンピュートとボリューム要求の伝達方法も決定"" ""します。"" msgid """" ""Before we delve into the configurations, we briefly discuss the ciphers' "" ""configuration element and its format. A more exhaustive treatment on "" ""available ciphers and the OpenSSL cipher list format can be found at: <link "" ""href=\""https://www.openssl.org/docs/apps/ciphers.html\"">ciphers</link>."" msgstr """" ""設定を掘り下げる前に、暗号の設定要素とその形式について簡単に議論します。利用"" ""可能な暗号におけるより包括的な使い方、および OpenSSL 暗号一覧形式が <link "" ""href=\""https://www.openssl.org/docs/apps/ciphers.html\"">ciphers</link> にあり"" ""ます。"" msgid """" ""Being able to detect the load on the OpenStack servers also enables "" ""responding by way of introducing additional servers for load balancing to "" ""ensure high availability."" msgstr """" ""OpenStack サーバ群の負荷を検知可能にする事はまた、高可用化対応の為に負荷分散"" ""用追加サーバを導入する為の対応を可能にする事でもあります。"" msgid """" ""Below is a snippet of the Block Storage service <filename>policy.json</"" ""filename> file."" msgstr """" ""以下は Block Storage Service の <filename>policy.json</filename> ファイルの抜"" ""粋です。"" msgid """" ""Ben de Bont is the CSO for HP Cloud Services. Prior to his current role Ben "" ""led the information security group at MySpace and the incident response team "" ""at MSN Security. Ben holds a master's degree in Computer Science from the "" ""Queensland University of Technology."" msgstr """" ""Ben de Bont は HP Cloud Services の CSO です。その前は、MySpace の情報セキュ"" ""リティグループ、MSN Security のインシデントレスポンスチームを率いていました。"" ""Queensland University of Technology のコンピューターサイエンスの修士号を保持"" ""しています。"" msgid ""Block Storage"" msgstr ""Block Storage"" msgid ""Block Storage volume data"" msgstr ""ブロックストレージボリュームデータ"" msgid ""Block Storage volumes and instance ephemeral filesystems"" msgstr ""Block Storage ボリュームとインスタンスの一時ファイルシステム"" msgid """" ""Bob decides to use VNC for his virtual console for its maturity and security "" ""features."" msgstr """" ""ボブはその成熟度とセキュリティ機能から仮想コンソールに VNC を使用することを決"" ""めました。"" msgid """" ""Bob is a lead architect for a company that deploys a large greenfield public "" ""cloud. This cloud provides IaaS for the masses and enables any consumer with "" ""a valid credit card access to utility computing and storage, but the primary "" ""focus is enterprise customers. Data privacy concerns are a big priority for "" ""Bob as they are seen as a major barrier to large-scale adoption of the cloud "" ""by organizations."" msgstr """" ""ボブは、新規展開の大規模なパブリッククラウドのデプロイを行う会社のリードアー"" ""キテクトです。このクラウドは、有効なクレジットカードを持つ消費者が、ユーティ"" ""リティコンピューティングやストレージに使用できる一般大衆向けの IaaS を提供し"" ""ますが、第一のターゲットは 企業顧客です。企業の間では、データプライバシー問題"" ""は、大規模なクラウド導入の大きな障害とみなされているため、ボブにとって優先課"" ""題となっています。"" msgid """" ""Bob is aware that entropy will be a concern for some of his customers, such "" ""as those in the financial industry. However, due to the added cost and "" ""complexity, Bob has decided to forgo integrating hardware entropy into the "" ""first iteration of his cloud. He adds hardware entropy as a fast-follow to "" ""do for a later improvement for the second generation of his cloud "" ""architecture."" msgstr """" ""ボブは、金融業界の企業ユーザの幾つかにとってエントロピーが重要となる事を理解"" ""しています。しかしながら、費用と複雑さが増える為、ボブは彼のクラウドの初回導"" ""入分にハードウェアエントロピーの導入を見送る事を決めました。彼は自分の２世代"" ""目のクラウドアーキテクチャに向けた後の改善では、早期のフォローとしてハード"" ""ウェアエントロピーを追加します。"" msgid """" ""Bob is tasked with compliance for a new OpenStack public cloud deployment, "" ""that is focused on providing cloud services to both small developers and "" ""startups, as well as large enterprises. Bob recognizes that individual "" ""developers are not necessarily concerned with compliance certifications, but "" ""to larger enterprises certifications are critical. Specifically Bob desires "" ""to achieve SOC 1, SOC 2 Security, as well as ISO 27001/2 as quickly as "" ""possible. Bob references the Cloud Security Alliance Cloud Control Matrix "" ""(CCM) to assist in identifying common controls across these three "" ""certifications (such as periodic access reviews, auditable logging and "" ""monitoring services, risk assessment activities, security reviews, etc). Bob "" ""then engages an experienced audit team to conduct a gap analysis on the "" ""public cloud deployment, reviews the results and fills any gaps identified. "" ""Bob works with other team members to ensure that these security controls and "" ""activities are regularly conducted for a typical audit period (~6-12 months)."" msgstr """" ""ボブは新たなOpenStackクラウド環境のコンプライアンス活動を任されています。この"" ""クラウドは小規模の開発者やスタートアップだけでなく、大規模企業向けにも注力し"" ""ています。ボブは個人開発者はコンプライアンス認証を意識することが多くないが、"" ""いっぽうで大規模企業向けには認証が重要であることを認識しています。ボブは特に"" ""SOC 1、SOC 2、およびISO 27001/2認証を早急に取得したいと考えています。そこでボ"" ""ブは3つの認証に共通する統制を特定するため、Cloud Security Alliance Cloud "" ""Control Matrix (CCM)を参考にしました (例えば、定期的なアクセス検査、監査可能"" ""なロギングや監視サービス、リスク評価活動、セキュリティレビューなど)。それから"" ""ボブは、パブリッククラウドのギャップ評価、結果のレビュー、そして特定された"" ""ギャップを埋めるため、経験ある監査人チームと契約します。ボブは他のチームメン"" ""バーとともに、それらのセキュリティ統制と活動が一般的な監査期間(〜6-12ヶ月)に"" ""おいて、定期的に、確実に機能するようにします。"" msgid ""Bob's public cloud"" msgstr ""ボブのパブリッククラウド"" msgid ""Booleans"" msgstr ""ブーリアン"" msgid """" ""Both RabbitMQ and Qpid are Advanced Message Queuing Protocol (AMQP) "" ""frameworks, which provide message queues for peer-to-peer communication. "" ""Queue implementations are typically deployed as a centralized or "" ""decentralized pool of queue servers. ZeroMQ provides direct peer-to-peer "" ""communication through TCP sockets."" msgstr """" ""RabbitMQ と Qpid は両方とも、Advanced Message Queuing Protocol (AMQP) フレー"" ""ムワークであり、ピアツーピア通信にメッセージキューを提供する仕組みです。\n"" ""キューの実装は通常、キューサーバのプールを集中型か分散型で展開します。\n"" ""ZeroMQ はピア間の通信に直接 TCP ソケットを使うところが異なっています。"" msgid ""Bridging security domains"" msgstr ""セキュリティドメインのブリッジ"" msgid """" ""By default, each of the OpenStack services and their processes access the "" ""database using a shared set of credentials. This makes auditing database "" ""operations and revoking access privileges from a service and its processes "" ""to the database particularly difficult."" msgstr """" ""OpenStack の各サービスとそれらのプロセスはデフォルトで、共有クレデンシャルを"" ""使用してデータベースにアクセスします。これにより、データベース操作の監査およ"" ""び、サービスとそのプロセスからデータベースへのアクセス権の剥奪が特に難しくな"" ""ります。"" msgid ""Capabilities"" msgstr ""機能"" msgid ""Case studies"" msgstr ""ケーススタディ"" msgid ""Case studies: Identity management"" msgstr ""ケーススタディ: ID 管理"" msgid ""Case study: Alice, the private cloud builder"" msgstr ""事例: プライベートクラウド構築者のアリス"" msgid ""Case study: Bob, the public cloud provider"" msgstr ""事例: パブリッククラウドプロバイダーのボブ"" msgid ""Certification Authority (<glossterm>CA</glossterm>)"" msgstr ""認証局 (<glossterm>CA</glossterm>)"" msgid ""Certification and compliance statements"" msgstr ""認証とコンプライアンスの報告書"" msgid ""Certification authorities"" msgstr ""認証局(CA)"" msgid ""Certifications and attestations"" msgstr ""証明書"" msgid ""Chapter on Object Storage added."" msgstr ""Object Storage に関する章を追加しました。"" msgid ""Chef"" msgstr ""Chef"" msgid ""Cinder volume data"" msgstr ""Cinder のボリュームデータ"" msgid """" ""Cipher string options are separated by \"":\"", while \""!\"" provides negation "" ""of the immediately following element. Element order indicates preference "" ""unless overridden by qualifiers such as HIGH. Let us take a closer look at "" ""the elements in the above sample strings."" msgstr """" ""暗号オプションの文字列は「:」で区切られます。「!」は直後の要素の否定を意味し"" ""ます。要素の順番は、HIGH のような修飾語句により上書きされない限り、優先度を意"" ""味します。上のサンプル文字列の要素をもう少し具体的に見ていきましょう。"" msgid """" ""Cipher suites using the <link href=\""http://en.wikipedia.org/wiki/RSA_"" ""%28cryptosystem%29\"">RSA</link> exchange, authentication or either "" ""respectively."" msgstr """" ""<link href=\""http://en.wikipedia.org/wiki/RSA_%28cryptosystem%29\"">RSA</"" ""link> の鍵交換、認証、またはその両方を使用する暗号スイート。"" msgid ""Cloud Security Alliance (CSA) Common Control Matrix (CCM)"" msgstr ""Cloud Security Alliance (CSA) Common Control Matrix (CCM)"" msgid ""Cloud admin"" msgstr ""クラウドの管理者"" msgid ""Cloud administration"" msgstr ""クラウド管理"" msgid ""Cloud types"" msgstr ""クラウドのタイプ"" msgid ""Cloud user"" msgstr ""クラウドユーザー"" msgid """" ""Cody Bunch is a Private Cloud architect with Rackspace. Cody has co-authored "" ""an update to \""The OpenStack Cookbook\"" as well as books on VMware "" ""automation."" msgstr """" ""Cody Bunch は Rackspace の Private Cloud architect です。『The OpenStack "" ""Cookbook』と VMware 自動化の書籍の共同執筆者です。"" msgid """" ""Collection of objects. Metadata on the container is available for ACLs. The "" ""meaning of ACLs is dependent on the authentication system used."" msgstr """" ""オブジェクトの集合体。コンテナーにあるメタデータは ACL が利用可能です。ACL の"" ""意味は使用する認証システムに依存します。"" msgid """" ""Combining configuration management and security auditing tools creates a "" ""powerful combination. The auditing tools will highlight deployment concerns. "" ""And the configuration management tools simplify the process of changing each "" ""system to address the audit concerns. Used together in this fashion, these "" ""tools help to maintain a cloud that satisfies security requirements ranging "" ""from basic hardening to compliance validation."" msgstr """" ""構成管理とセキュリティ監査ツールを組み合わせることで強力になります。監査ツー"" ""ルはデプロイメントの課題をハイライトし、構成管理ツールは各システムの変更プロ"" ""セスを簡素化して監査の課題に対応していきます。このような方法で組み合わせて使"" ""用することで、これらのツールは、基本的なセキュリティの強化からコンプライアン"" ""スのバリデーションに至るまで、このようなセキュリティ要件を満たすクラウドを維"" ""持できるようにします。"" msgid ""Commercial standards"" msgstr ""商業規格"" msgid """" ""Common Criteria is an internationally standardized software evaluation "" ""process, used by governments and commercial companies to validate software "" ""technologies perform as advertised. In the government sector, NSTISSP No. 11 "" ""mandates that U.S. Government agencies only procure software which has been "" ""Common Criteria certified, a policy which has been in place since July 2002. "" ""It should be specifically noted that OpenStack has not undergone Common "" ""Criteria certification, however many of the available hypervisors have."" msgstr """" ""共通の条件は国際的に標準化されたソフトウェア評価プロセスです。これは、宣伝目"" ""的でソフトウェア技術の実行を検証する為に政府や企業が使用します。政府部門で"" ""は、NSTISSP No. 11 のみ政府機関にコモンクライテリア認証（2002年7月に登場した"" ""ポリシー）を受けたソフトウェアの調達権限を与えます。特に、Opentack はコモンク"" ""ライテリア認証を受けておらず、多くの入手可能なハイパーバイザーは受けている事"" ""に注意すべきでしょう。"" msgid ""Common criteria"" msgstr ""コモンクライテリア (Common Criteria)"" msgid """" ""Commonly, implementers add middleware to extend OpenStack's base "" ""functionality. We recommend implementers make careful consideration of the "" ""potential exposure introduced by the addition of non-standard software "" ""components to their HTTP request pipeline."" msgstr """" ""実装者がOpenStackの基本機能を拡張するためにミドルウェアを追加することは一般的"" ""です。私たちは非標準のソフトウェアコンポーネントをHTTPリクエストパイプライン"" ""へ追加することによって生じる潜在的なセキュリティについて慎重に検討する事を推"" ""奨しています。"" msgid ""Community cloud"" msgstr ""コミュニティクラウド"" msgid ""Compartmentalize"" msgstr ""コンパートメント化"" msgid ""Compiler hardening"" msgstr ""コンパイラーのセキュリティ強化機能"" msgid ""Compliance"" msgstr ""コンプライアンス"" msgid ""Compliance activities"" msgstr ""コンプライアンス活動"" msgid """" ""Compliance and security are not exclusive, and must be addressed together. "" ""OpenStack deployments are unlikely to satisfy compliance requirements "" ""without security hardening. The listing below provides an OpenStack "" ""architect foundational knowledge and guidance to achieve compliance against "" ""commercial and government certifications and standards."" msgstr """" ""コンプライアンスとセキュリティは排他的でなく、あわせて取り組むべきものです。"" ""OpenStack環境は、セキュリティの強化なしに、コンプライアンス要件を充足すること"" ""ができないでしょう。以下のリストは、OpenStackアーキテクト向けの、商業規格およ"" ""び政府機関の認証を得るための基本的な知識とガイダンスです。"" msgid ""Compliance maintenance"" msgstr ""コンプライアンスの維持"" msgid ""Compliance overview"" msgstr ""コンプライアンス概要"" msgid """" ""Comprehensive privacy management requires significant preparation, thought "" ""and investment. Additional complications are introduced when building global "" ""OpenStack clouds, for example navigating the differences between U.S. and "" ""more restrictive E.U. privacy laws. In addition, extra care needs to be "" ""taken when dealing with sensitive PII that may include information such as "" ""credit card numbers or medical records. This sensitive data is not only "" ""subject to privacy laws but also regulatory and governmental regulations. By "" ""deferring to established best practices, including those published by "" ""governments, a holistic privacy management policy may be created and "" ""practiced for OpenStack deployments."" msgstr """" ""包括的なプライバシー管理には、十分な準備、考慮と投資が必要です。また、グロー"" ""バルなOpenStackクラウドの構築時には、さらなる複雑さに気づくでしょう。米国およ"" ""び、それより厳しいEUのプライバシー法令の違いが良い例です。加えて、クレジット"" ""カード番号や医療情報など、機密性の高い個人情報を扱う場合にはさらなる注意が必"" ""要です。これら機密性の高い情報はプライバシー法令だけでなく、監視当局や政府規"" ""制にも関連します。政府によって発行されたものなど、ベストプラクティスに従うこ"" ""とで、OpenStack環境向けの総合的なプライバシー管理ポリシーが確立、実践されてい"" ""くでしょう。"" msgid ""Compute"" msgstr ""Compute"" msgid """" ""Compute API SSL endpoint in Apache, which you must pair with a short WSGI "" ""script."" msgstr """" ""Apache 中の Compute API SSL エンドポイント (短い WSGI スクリプトと組み合わせ"" ""る必要あり)"" msgid ""Compute API endpoints"" msgstr ""Compute APIエンドポイント"" msgid ""Compute instance ephemeral filesystem storage"" msgstr ""Compute のインスタンスの一時的ファイルシステムストレージ"" msgid ""Compute instance ephemeral storage"" msgstr ""Compute インスタンスの一時ストレージ"" msgid ""Compute instance memory"" msgstr ""Compute インスタンスのメモリ"" msgid """" ""Compute, storage, or other resource nodes. Provide storage capacity or "" ""virtual machines for your cloud."" msgstr """" ""コンピュート、ストレージ、その他のリソースのノード。クラウド用のストレージ容"" ""量や仮想マシンを提供するノードです。"" msgid ""Configuration example #1: (MySQL)"" msgstr ""設定例 #1: (MySQL)"" msgid ""Configuration example #1: nova"" msgstr ""構成例#1: nova"" msgid ""Configuration example #2: (PostgreSQL)"" msgstr ""設定例 #2: (PostgreSQL)"" msgid ""Configuration example #2: cinder"" msgstr ""構成例#2: cinder"" msgid ""Configuration management"" msgstr ""設定管理"" msgid """" ""Configuration management and security auditing tools will introduce another "" ""layer of complexity into the cloud. This complexity brings additional "" ""security concerns with it. We view this as an acceptable risk trade-off, "" ""given their security benefits. Securing the operational use of these tools "" ""is beyond the scope of this guide."" msgstr """" ""構成管理およびセキュリティ監査ツールは、もう１つのレベルで複雑性をクラウドに"" ""もたらします。この複雑性により、新たなセキュリティの課題が出てきます。これに"" ""ついては、セキュリティの利点もあるため、許容範囲のリスクのトレードオフという"" ""見解を持っています。これらのツールの運用におけるセキュリティ確保については、"" ""本書の対象外となっています。"" msgid """" ""Configure HTTP requests to the dashboard domain to redirect to the fully "" ""qualified HTTPS URL."" msgstr """" ""ダッシュボードのドメインに対する HTTP リクエストは、完全修飾された HTTPS URL "" ""にリダイレクトされるよう設定します。"" msgid ""Configure applications for internal URLs"" msgstr ""内部URL用のアプリケーション構成"" msgid """" ""Configure your web server to send a restrictive CORS header with each "" ""response, allowing only the dashboard domain and protocol:"" msgstr """" ""ウェブブラウザが各レスポンスに限定的な CORS ヘッダーを付けて送信するよう設定"" ""します。ダッシュボードのドメインとプロトコルのみを許可します。"" msgid ""Container service"" msgstr ""コンテナーサービス"" msgid ""Context"" msgstr ""コンテキスト"" msgid ""Continuous systems management"" msgstr ""継続的なシステム管理"" msgid ""Control plane"" msgstr ""制御プレーン"" msgid ""Cookies"" msgstr ""クッキー"" msgid ""Copyright details are filled in by the template."" msgstr ""Copyright details are filled in by the template."" msgid """" ""Core Root of Trust Measurement (CRTM), BIOS code, Host platform extensions"" msgstr """" ""Core Root of Trust Measurement (CRTM)、 BIOS コード、ホストプラットフォームの"" ""拡張機能"" msgid """" ""Create and manage security groups through dashboard. The security groups "" ""allows L3-L4 packet filtering for security policies to protect virtual "" ""machines."" msgstr """" ""ダッシュボードからセキュリティグループを作成・管理します。セキュリティグルー"" ""プにより、セキュリティポリシーに関する L3-L4 パケットをフィルダリングして仮想"" ""マシンの保護が可能になります。"" msgid """" ""Creating unique database user accounts per OpenStack service endpoint "" ""(illustrated below)"" msgstr """" ""OpenStack サービスのエンドポイントごとに一意なデータベースユーザーアカウント"" ""の作成 (下図)"" msgid ""Critical"" msgstr ""重要"" msgid ""Critical / high"" msgstr ""重要/高"" msgid ""Cross Origin Resource Sharing (CORS)"" msgstr ""クロスオリジンリソースシェアリング (CORS)"" msgid ""Cross Site Request Forgery (CSRF)"" msgstr ""クロスサイトリクエストフォージェリ (CSRF)"" msgid ""Cross Site Scripting (XSS)"" msgstr ""クロスサイトスクリプティング (XSS)"" msgid ""Cryptographic algorithms, cipher modes, and protocols"" msgstr ""暗号化アルゴリズム、暗号モード、プロトコル"" msgid ""Cryptography standards"" msgstr ""暗号標準"" msgid """" ""DEB packages: <link href=\""http://wiki.debian.org/HardeningWalkthrough"" ""\"">Hardening Walkthrough</link>"" msgstr """" ""DEB パッケージ: <link href=\""http://wiki.debian.org/HardeningWalkthrough"" ""\"">Hardening Walkthrough</link>"" msgid """" ""DHCP agent (<systemitem class=\""service\"">neutron-dhcp-agent</systemitem>)"" msgstr """" ""DHCP エージェント (<systemitem class=\""service\"">neutron-dhcp-agent</"" ""systemitem>)"" msgid ""DSA"" msgstr ""DSA"" msgid ""Dashboard"" msgstr ""Dashboard"" msgid ""Data"" msgstr ""データ"" msgid """" ""Data Classification defines a method for classifying and handling "" ""information, often to protect customer information from accidental or "" ""deliberate theft, loss, or inappropriate disclosure. Most commonly this "" ""involves classifying information as sensitive or non-sensitive, or as "" ""personally identifiable information (PII). Depending on the context of the "" ""deployment various other classifying criteria may be used (government, "" ""health-care etc). The underlying principle is that data classifications are "" ""clearly defined and in-use. The most common protective mechanisms include "" ""industry standard encryption technologies. See the data security section for "" ""additional details."" msgstr """" ""データの分類作業は、多くの場合、顧客情報を事故、故意の窃盗、損失、不適切な公"" ""開から保護するため、情報の分類と扱いの方法を定義します。一般的にこの作業は、"" ""情報を機密性の有無、個人識別の可不可(Personally Identifiable Information, "" ""PII)による分類を含みます。使用される基準はその環境、背景によって様々です(政"" ""府、ヘルスケアなど)。そして根本的な原則は、そのデータ分類が明確に定義され、通"" ""常利用されていることです。もっとも一般的な保護メカニズムには、業界標準の暗号"" ""化技術が挙げられます。詳細はデータセキュリティの節を参照してください。"" msgid ""Data classification"" msgstr ""データの分類"" msgid ""Data disposal"" msgstr ""データの処分"" msgid ""Data encryption"" msgstr ""データ暗号化"" msgid ""Data not securely erased"" msgstr ""安全に消去されなかったデータ"" msgid ""Data passed to OpenStack Compute's configuration-drive extension"" msgstr ""OpenStack Compute の設定用ドライブ拡張に渡されたデータ"" msgid ""Data privacy concerns"" msgstr ""データプライバシ関連"" msgid ""Data processing"" msgstr ""Data processing"" msgid ""Data processing service"" msgstr ""Data processing サービス"" msgid ""Data replication and recovery"" msgstr ""データの複製およびリカバリー"" msgid ""Data residency"" msgstr ""データの所在"" msgid ""Database access control"" msgstr ""データベースアクセス制御"" msgid ""Database authentication and access control"" msgstr ""データベースの認証とアクセス制御"" msgid ""Database server"" msgstr ""データベースサーバー"" msgid ""Database server IP address binding"" msgstr ""データベースサーバーの IP アドレスバインド"" msgid ""Database transport"" msgstr ""データベース通信"" msgid ""Database transport security"" msgstr ""データベース通信セキュリティ"" msgid ""Databases"" msgstr ""データベース"" msgid ""Debug"" msgstr ""デバッグ"" msgid ""Defines certificate policies, management, and issuance of certificates."" msgstr ""証明ポリシーの定義、管理、証明書の発行。"" msgid """" ""Denial of Service refers to an exploited vulnerability that may cause "" ""service or system disruption. This includes both distributed attacks to "" ""overwhelm network resources, and single-user attacks that are typically "" ""caused through resource allocation bugs or input induced system failure "" ""flaws."" msgstr """" ""サービス妨害 (DoS) とは、サービスやシステムの中断を引き起こす脆弱性を悪用する"" ""ことを指します。これには、ネットワークリソースを大量に使用する分散型攻撃や、"" ""リソース割り当てのバグや誘導型でのシステム障害の問題などで一般的に引き起こさ"" ""れるシングルユーザー攻撃の両方が含まれます。"" msgid ""Denial of service"" msgstr ""サービス妨害 (DoS)"" msgid """" ""Depending on the strategy selected, in the event of a failure the node will "" ""either fail to boot or it can report the failure back to another entity in "" ""the cloud. For secure boot, the node will fail to boot and a provisioning "" ""service within the management security domain must recognize this and log "" ""the event. For boot attestation, the node will already be running when the "" ""failure is detected. In this case the node should be immediately quarantined "" ""by disabling its network access. Then the event should be analyzed for the "" ""root cause. In either case, policy should dictate how to proceed after a "" ""failure. A cloud may automatically attempt to re-provision a node a certain "" ""number of times. Or it may immediately notify a cloud administrator to "" ""investigate the problem. The right policy here will be deployment and "" ""failure mode specific."" msgstr """" ""選択した戦略に応じて、障害発生時にノードがブートに失敗するか、クラウド内の別"" ""のエンティティに障害を報告することができます。セキュアブートの場合には、ノー"" ""ドがブートに失敗し、管理セキュリティドメイン内のプロビジョニングサービスがこ"" ""の問題を認識してイベントログを記録する必要があります。ブートアテステーション"" ""の場合には、障害検出時にはノードがすでに稼働している状態です。この場合、ネッ"" ""トワークアクセスを無効にすることによってノードの検疫を直ちに行った後に、イベ"" ""ントを解析して根本原因を特定するべきです。いずれの場合も、ポリシーにより、障"" ""害発生後の対処方法を指示する必要があります。クラウドが、特定の回数、ノードの"" ""再プロビジョニングを自動的に試みるようにしたり、問題を調査するようにクラウド"" ""管理者に直ちに通知するようにすることができます。この場合に適正となるポリシー"" ""は、デプロイメントと障害のモードによって異なります。 "" msgid """" ""Deploy automated testing tools to ensure that the cloud remains compliant "" ""over time."" msgstr """" ""クラウドがコンプライアンスを維持し続けるために、自動テストツールを導入してく"" ""ださい。"" msgid """" ""Deploy the dashboard behind a secure <glossterm>HTTPS</glossterm> server by "" ""using a valid, trusted certificate from a recognized certificate authority "" ""(CA). Private organization-issued certificates are only appropriate when the "" ""root of trust is pre-installed in all user browsers."" msgstr """" ""ダッシュボードは、認知されている認証局 (CA) から発行された有効かつ信頼できる"" ""証明書を使用しているセキュアな <glossterm>HTTPS</glossterm> サーバーの後ろに"" ""導入します。プライベートな組織で発行された証明書は、ルート証明機関がお使いの"" ""すべてのブラウザーに事前インストールされているときのみ、適切に動作します。"" msgid """" ""Deployers or users of OpenStack with strong security requirements may want "" ""to consider deploying these technologies. Not all are applicable in every "" ""situation, indeed in some cases technologies may be ruled out for use in a "" ""cloud because of prescriptive business requirements. Similarly some "" ""technologies inspect instance data such as run state which may be "" ""undesirable to the users of the system."" msgstr """" ""高いセキュリティ要件を持つOpenStackユーザーや配備者はこれらの技術の採用を検討"" ""すると良いかもしれませんが、状況によっては適用できない場合があります。クラウ"" ""ド運用においては、規範的なビジネス要件のために技術の選択肢が削られることがあ"" ""ります。また、run stateなど、仕組みによってはインスタンス内のデータを調べる機"" ""構もあり、システムのユーザーからは好まれないものもあります。"" msgid ""Deploying the updates"" msgstr ""更新のデプロイ"" msgid ""Deployment"" msgstr ""デプロイ"" msgid ""Description"" msgstr ""記述"" msgid ""Destroy cloud system media that cannot be sanitized."" msgstr ""サニタイズできないクラウドシステム媒体を破壊すること。"" msgid """" ""Detecting the absence of log generation is an event of high value. Such an "" ""event would indicate a service failure or even an intruder who has "" ""temporarily switched off logging or modified the log level to hide their "" ""tracks."" msgstr """" ""ログ生成無しの検知は価値の高いイベントです。このようなイベントはサービス障"" ""害、または一時的にログをオフにしたり、監視者から隠れるためにログレベルを変更"" ""した侵入者を示している可能性があります。"" msgid ""Determining audit scope"" msgstr ""監査の範囲を決定する"" msgid """" ""Determining audit scope, specifically what controls are needed and how to "" ""design or modify an OpenStack deployment to satisfy them, should be the "" ""initial planning step."" msgstr """" ""何をコントロールするのか、OpenStack環境をいかにデザイン、変更していくかを明確"" ""にするため、監査範囲は初期の計画段階で決定すべきです。"" msgid """" ""Direct memory access (DMA) is a feature that permits certain hardware "" ""devices to access arbitrary physical memory addresses in the host computer. "" ""Often video cards have this capability. However, an instance should not be "" ""given arbitrary physical memory access because this would give it full view "" ""of both the host system and other instances running on the same node. "" ""Hardware vendors use an input/output memory management unit (IOMMU) to "" ""manage DMA access in these situations. Therefore, cloud architects should "" ""ensure that the hypervisor is configured to utilize this hardware feature."" msgstr """" ""ダイレクトメモリアクセス (DMA) は、特定のハードウェアがホストコンピューターで"" ""任意の物理メモリアドレスにアクセスできる機能です。ビデオカードはときどきこの"" ""機能を有しています。しかしながら、インスタンスは指定された任意の物理メモリア"" ""クセスをすべきではありません。なぜなら、これはホストシステムと同じノードで実"" ""行している他のインスタンスを完全に表示できるかもしれないからです。ハードウェ"" ""アベンダーはこれらの状況で DMA アクセスを管理するために input/output memory "" ""management unit (IOMMU) を使用します。そのため、クラウドアーキテクトは、ハイ"" ""パーバイザーがこのハードウェア機能を使用するよう設定されていることを確実にす"" ""べきです。"" msgid ""Disable live migration"" msgstr ""ライブマイグレーションの無効化"" msgid """" ""Disaster Recovery (DR) and Business Continuity Planning (BCP) plans are "" ""common requirements for ISMS and compliance activities. These plans must be "" ""periodically tested as well as documented. In OpenStack key areas are found "" ""in the management security domain, and anywhere that single points of "" ""failure (SPOFs) can be identified. See the section on secure backup and "" ""recovery for additional details."" msgstr """" ""災害対策(Disaster Recovery, DR)とビジネス継続計画(Business Continuity "" ""Planning, BCP)はISMSとコンプライアンス活動で共通の要件です。それらの計画は定"" ""期的な検査と文書化が必要とします。OpenStackの主要領域はマネジメントセキュリ"" ""ティ領域にあたり、すべての単一障害点(Single Point of Failures, SPOFs)が特定さ"" ""れなければいけません。詳細は、安全なバックアップとリカバリーの節を参照してく"" ""ださい。"" msgid ""Discretionary Access Control"" msgstr ""任意アクセス制御"" msgid """" ""Discretionary Access Control (<glossterm>DAC</glossterm>) restricts access "" ""to file system objects based on <glossterm baseform=\""access control list"" ""\"">Access Control Lists</glossterm> (ACLs) that include the standard UNIX "" ""permissions for user, group and others. Access control mechanisms also "" ""protect IPC objects from unauthorized access."" msgstr """" ""任意アクセス制御 (<glossterm>DAC</glossterm>) は、ユーザー、グループ、その他"" ""に対する標準 UNIX パーミッションを含む<glossterm baseform=\""access control "" ""list\"">アクセス制御リスト</glossterm> (ACL) に基づいてファイルシステムオブ"" ""ジェクトへのアクセスを制限します。アクセス制御機構は権限のないアクセスから "" ""IPC オブジェクトも保護します。"" msgid """" ""Discuss common control frameworks and certification resources to achieve "" ""industry certifications or regulator attestations."" msgstr """" ""業界認定や監督当局の認証を得るために必要な、共通コントロールフレームワークと"" ""認定リソースを説明する"" msgid ""Discuss upcoming security features"" msgstr ""今後予定されているセキュリティ機能の議論"" msgid """" ""Django security releases are generally well tested and aggressively "" ""backwards compatible. In almost all cases, new major releases of Django are "" ""also fully backwards compatible with previous releases. Dashboard "" ""implementers are strongly encouraged to run the latest stable release of "" ""Django with up-to-date security releases."" msgstr """" ""Django セキュリティリリースは、一般的に十分にテストされ、積極的に後方互換性を"" ""確保しています。ほぼすべての場合、Django の新しいメジャーリリースも前のリリー"" ""スと後方互換性があります。ダッシュボードの実装者は、最新のセキュリティリリー"" ""スを持つ最新の安定リリースの Django を実行することを強く推奨されます。"" msgid """" ""Documentation should provide a general description of the OpenStack "" ""environment and cover all systems used (production, development, test, "" ""etc.). Documenting system components, networks, services, and software often "" ""provides the bird's-eye view needed to thoroughly cover and consider "" ""security concerns, attack vectors and possible security domain bridging "" ""points. A system inventory may need to capture ephemeral resources such as "" ""virtual machines or virtual disk volumes that would otherwise be persistent "" ""resources in a traditional IT system."" msgstr """" ""文書には、OpenStack 環境の概要を記載し、使用する全システム (実稼働、開発、テ"" ""ストなど) を対象とするべきです。多くの場合、システムコンポーネント、ネット"" ""ワーク、サービス、およびソフトウェアについて文書化することにより、セキュリ"" ""ティ課題、攻撃ベクトル、考えられるセキュリティドメインのブリッジングポイント"" ""を完全に網羅して検討するにあたって必要な概観が提供されます。システムインベン"" ""トリには、従来の IT システムでは永続的なリソースとされている、仮想マシンや仮"" ""想ディスクボリュームなどの一時的なリソースを取り込む必要がある場合がありま"" ""す。"" msgid ""Domain names"" msgstr ""ドメイン名"" msgid """" ""Domains are high-level containers for projects, users and groups. As such, "" ""they can be used to centrally manage all keystone-based identity components. "" ""With the introduction of account domains, server, storage and other "" ""resources can now be logically grouped into multiple projects (previously "" ""called tenants) which can themselves be grouped under a master account-like "" ""container. In addition, multiple users can be managed within an account "" ""domain and assigned roles that vary for each project."" msgstr """" ""ドメインはプロジェクト、ユーザー、グループの高いレベルでのコンテナーです。そ"" ""のように、すべての keystone ベースの識別コンポーネントを一元的に管理するため"" ""に使用されます。アカウントドメインを導入すると、サーバー、ストレージ、他のリ"" ""ソースは複数のプロジェクト (以前はテナントと呼ばれていました) の中で論理的に"" ""グループ化できます。これは、アカウントのようなマスターコンテナーの下でグルー"" ""プ化できます。さらに、複数のユーザーがアカウントドメインの中で管理でき、各プ"" ""ロジェクトで変化するロールを割り当てられます。"" msgid """" ""Dr. Bryan D. Payne is the Director of Security Research at Nebula and co-"" ""founder of the OpenStack Security Group (OSSG). Prior to joining Nebula, he "" ""worked at Sandia National Labs, the National Security Agency, BAE Systems, "" ""and IBM Research. He graduated with a Ph.D. in Computer Science from the "" ""Georgia Tech College of Computing, specializing in systems security."" msgstr """" ""Dr. Bryan D. Payne は、Nebula の Security Research の Director です。また、"" ""OpenStack Security Group (OSSG) の共同創設者です。Nebula に参加する前は、"" ""Sandia National Labs、National Security Agency、BAE Systems、IBM Research に"" ""勤務していました。Georgia Tech College of Computing でシステムセキュリティを"" ""専攻し、コンピューターサイエンスの Ph.D. を取得しました。"" msgid """" ""During the sprint we also had help from Anne Gentle, Warren Wang, Paul "" ""McMillan, Brian Schott and Lorin Hochstein."" msgstr """" ""また、ブックスプリント期間中、Anne Gentle、Warren Wang、Paul McMillan、Brian "" ""Schott、Lorin Hochstein からの支援がありました。"" msgid ""ESXi"" msgstr ""ESXi"" msgid """" ""Each KVM-based virtual machine is a process which is labeled by SELinux, "" ""effectively establishing a security boundary around each virtual machine. "" ""This security boundary is monitored and enforced by the Linux kernel, "" ""restricting the virtual machine's access to resources outside of its "" ""boundary such as host machine data files or other VMs."" msgstr """" ""各 KVM ベースの仮想マシンは SELinux によりラベル付けされているプロセスです。"" ""これは各仮想マシンのセキュリティ境界を効率的に確立します。このセキュリティ境"" ""界は、Linux カーネルにより監視され、強制されます。ホストマシンのデータファイ"" ""ルや他の仮想マシンのような、仮想マシンの境界外のリソースへのアクセスは制限さ"" ""れます。"" msgid """" ""Each OpenStack deployment embraces a wide variety of technologies, spanning "" ""Linux distributions, database systems, messaging queues, OpenStack "" ""components themselves, access control policies, logging services, security "" ""monitoring tools, and much more. It should come as no surprise that the "" ""security issues involved are equally diverse, and their in-depth analysis "" ""would require several guides. We strive to find a balance, providing enough "" ""context to understand OpenStack security issues and their handling, and "" ""provide external references for further information. The guide could be read "" ""from start to finish or sampled as necessary like a reference."" msgstr """" ""OpenStack の各デプロイメントには、Linux ディストリビューション、データベース"" ""システム、メッセージキュー、OpenStack のコンポーネント自体、アクセス制御ポリ"" ""シー、ログサービス、セキュリティ監視ツールなどに及ぶ、多種多様なテクノロジー"" ""が採用されます。このため、デプロイに伴うセキュリティ問題が、同じように多様と"" ""なることは当然です。それらの内容を奥深く分析するには、マニュアルが数冊必要と"" ""なります。 本ガイドでは、OpenStack のセキュリティ問題とその対処方法を理解する"" ""ために十分な情報を提供しつつ、さらなる情報の外部参照先を掲載することにより、"" ""バランスを図っています。本書は、全体を通読する方法または参考資料として必要箇"" ""所のみを参照する方法のいずれでもご利用いただくことができます。"" msgid """" ""Each OpenStack service has a policy file in JSON format, called "" ""<filename>policy.json</filename>. The policy file specifies rules, and the "" ""rule that governs each resource. A resource could be API access, the ability "" ""to attach to a volume, or to fire up instances."" msgstr """" ""各 OpenStack サービスは <filename>policy.json</filename> という JSON 形式のポ"" ""リシーファイルを持ちます。ポリシーファイルはルールを指定します。ルールは各リ"" ""ソースを決定します。リソースは API アクセスできます。ボリュームの接続やインス"" ""タンスの起動などです。"" msgid """" ""Each TPM has at least 24 PCRs. The TCG Generic Server Specification, v1.0, "" ""March 2005, defines the PCR assignments for boot-time integrity "" ""measurements. The table below shows a typical PCR configuration. The context "" ""indicates if the values are determined based on the node hardware (firmware) "" ""or the software provisioned onto the node. Some values are influenced by "" ""firmware versions, disk sizes, and other low-level information. Therefore, "" ""it is important to have good practices in place around configuration "" ""management to ensure that each system deployed is configured exactly as "" ""desired."" msgstr """" ""各 TPM には少なくとも 24 の PCR が含まれます。TCG Generic Server "" ""Specification ( v1.0、2005 年 3 月版) には、ブート時の完全性計測のための PCR "" ""の割り当てが定義されています。以下の表には、標準的な PCR 設定を記載していま"" ""す。コンテキストには、その値がノードのハードウェア (ファームウェア) をベース"" ""に決定されるか、ノードにプロビジョニングされているソフトウェアをベースに決定"" ""されるかを示しています。一部の値は、ファームウェアのバージョンやディスクサイ"" ""ズ、その他の低レベルの情報によって影響を受けます。このため、設定管理の適切な"" ""プラクティスを整備し、デプロイするシステムが要望通りに設定されるようにしてお"" ""くことが重要となります。"" msgid """" ""Each manufacturer must provide the BIOS and firmware code for their servers. "" ""Different servers, hypervisors, and operating systems will choose to "" ""populate different PCRs. In most real world deployments, it will be "" ""impossible to validate every PCR against a known good quantity (\""golden "" ""measurement\""). Experience has shown that, even within a single vendor's "" ""product line, the measurement process for a given PCR may not be consistent. "" ""We recommend establishing a baseline for each server and monitoring the PCR "" ""values for unexpected changes. Third-party software may be available to "" ""assist in the TPM provisioning and monitoring process, depending upon your "" ""chosen hypervisor solution."" msgstr """" ""各メーカーは、サーバーの BIOS とファームウェアのコードを提供する必要がありま"" ""す。サーバー、ハイパーバイザー、オペレーティングシステムによって、事前設定さ"" ""れる PCR 値の選択が異なります。実際のデプロイメントではほとんどの場合、既知の"" ""適切な量 (「黄金の計測値」) と対照して各 PCR を検証することは不可能です。単一"" ""のベンダー の製品ラインの場合でも、一定の PCR の計測プロセスに一貫性がない場"" ""合があることが、経験により実証されています。各サーバーに基準値を定め、 PCR 値"" ""の予期せぬ変化を監視することを推奨します。選択したハイパーバイザーソリュー"" ""ションによっては、TPM プロビジョニングおよび監視プロセスを支援する サードパー"" ""ティー製のソフトウェアが提供されている可能性があります。"" msgid """" ""Each project provides a number of services which send and consume messages. "" ""Each binary which sends a message is expected to consume messages, if only "" ""replies, from the queue."" msgstr """" ""各プロジェクトは多数のサービスを提供し、それぞれがメッセージを送信、消費しま"" ""す。メッセージを送信した各バイナリは、リプライのみの場合、該当キューからメッ"" ""セージを消費するはずです。"" msgid ""Encrypted live migration"" msgstr ""ライブマイグレーションの暗号化"" msgid ""Encryption / decryption"" msgstr ""暗号化 / 復号"" msgid ""End entity"" msgstr ""エンドエンティティ"" msgid ""End users"" msgstr ""エンドユーザー"" msgid """" ""Ensure only authenticated users and backup clients have access to the backup "" ""server."" msgstr """" ""認証済みのユーザーおよびバックアップクライアントのみがバックアップサーバーに"" ""アクセスできるようにすること"" msgid """" ""Ensure that the .rc file which has your credential information is secured."" msgstr """" ""認証情報が含まれている .rc ファイルのセキュリティが確保されているようにしま"" ""す。"" msgid """" ""Ensure that the network interfaces are on their own private(management or a "" ""separate) network. Segregate management domains with firewalls or other "" ""network gear."" msgstr """" ""ネットワークインターフェースはプライベート (管理または個別) ネットワークに設"" ""定されていることを確認します。管理ドメインはファイアウォールか他のネットワー"" ""ク機器で分離してください。"" msgid ""Entropy to instances"" msgstr ""インスタンスへのエントロピー"" msgid """" ""Ephemeral Diffie-Hellman (abbreviated either as EDH or DHE) uses prime field "" ""groups."" msgstr """" ""一時ディフィー・ヘルマン (EDH や DHE と略す) は素体グループを使用します。"" msgid """" ""Ephemeral Elliptic Curve Diffie-Hellman (abbreviated as EECDH and ECDHE)."" msgstr ""楕円曲線ディフィー・ヘルマン (EECDH や ECDHE と略す)"" msgid """" ""Ephemeral Elliptic Curves require the server to be configured with a named "" ""curve, and provide better security than prime field groups and at lower "" ""computational cost. However, prime field groups are more widely implemented, "" ""and thus typically both are included in list."" msgstr """" ""一時楕円曲線はサーバーが名前付き曲線を用いて設定されている必要があります。素"" ""体グループよりセキュリティが高く、計算コストが低いです。しかしながら、素体グ"" ""ループはより幅広く実装されているので、一般的にどちらも一覧に含まれます。"" msgid """" ""Eric Lopez is Senior Solution Architect at VMware's Networking and Security "" ""Business Unit where he helps customers implement OpenStack and VMware NSX "" ""(formerly known as Nicira's Network Virtualization Platform). Prior to "" ""joining VMware (through the company's acquisition of Nicira), he worked for "" ""Q1 Labs, Symantec, Vontu, and Brightmail. He has a B.S in Electrical "" ""Engineering/Computer Science and Nuclear Engineering from U.C. Berkeley and "" ""MBA from the University of San Francisco."" msgstr """" ""Eric Lopez は VMware の Networking and Security Business Unit の Senior "" ""Solution Architect です。顧客が OpenStack や VMware NSX (以前は Nicira の "" ""Network Virtualization Platform として知られていました) を導入する支援をして"" ""います。VMware (Nicira の企業買収により) に参加する前は、Q1 Labs、Symantec、"" ""Vontu、Brightmail に勤務していました。U.C. Berkeley の Electrical "" ""Engineering/Computer Science、Nuclear Engineering の B.S. を保持してます。ま"" ""た、University of San Francisco の MBA を保持しています。"" msgid """" ""Eric Windisch is a Principal Engineer at Cloudscaling where he has been "" ""contributing to OpenStack for over two years. Eric has been in the trenches "" ""of hostile environments, building tenant isolation and infrastructure "" ""security through more than a decade of experience in the web hosting "" ""industry. He has been building cloud computing infrastructure and automation "" ""since 2007."" msgstr """" ""Eric Windisch は Cloudscaling の Principal Engineer です。OpenStack に 2 年以"" ""上貢献しています。ウェブホスティング業界における 10 年以上の経験から、ホス"" ""ティング環境の分離性、テナント独立性の構築、インフラセキュリティに携わってい"" ""ます。2007 年以降、クラウドコンピューティング環境の構築と自動化に携わっていま"" ""す。"" msgid ""Establish formal access control policies"" msgstr ""公式なアクセス制御ポリシーの確立"" msgid """" ""Establishing procedures to sanitize customer data when a customer churns."" msgstr """" ""顧客が不適切な顧客データを大量生産する時に、削除するための手順を確立する。"" msgid """" ""Establishing procedures to sanitize tenant data when a program or project "" ""ends."" msgstr """" ""プログラムやプロジェクトが終了する際に、好ましくないテナントデータを削除する"" ""ための手順を確立すること。"" msgid """" ""Example of RHEL 6 CCE-26976-1 which will help implement NIST 800-53 "" ""Section<emphasis>AC-19(d) in</emphasis> Oz."" msgstr """" ""OzでNIST 800-53 セクション<emphasis>AC-19(d)</emphasis> の実装を手助けする"" ""RHEL 6 CCE-26976-1の例"" msgid ""Examples"" msgstr ""例"" msgid ""Exception process"" msgstr ""例外プロセス"" msgid ""Explanation"" msgstr ""説明"" msgid """" ""Exposes all OpenStack APIs, including the OpenStack Networking API, to "" ""tenants. The IP addresses on this network should be reachable by anyone on "" ""the Internet. This may be the same network as the external network, as it is "" ""possible to create a subnet for the external network that uses IP allocation "" ""ranges to use only less than the full range of IP addresses in an IP block. "" ""This network is considered the Public Security Domain."" msgstr """" ""テナントに OpenStack Networking API を含む全 OpenStack API を晒します。この"" ""ネットワーク上の IP アドレスはインターネット上の誰もがアクセス可能であるべき"" ""です。これは外部ネットワークと同じネットワークであっても構いません。外部ネッ"" ""トワーク用に、IP ブロック中の全 IP アドレス範囲より少ない部分を使う為の IP 割"" ""当範囲を使用するサブネットを作成する事が出来るからです。このネットワークはパ"" ""ブロックセキュリティドメインで検討します。"" msgid ""External"" msgstr ""外部"" msgid ""External audit"" msgstr ""外部監査"" msgid ""External authentication methods"" msgstr ""外部認証方式"" msgid ""External network"" msgstr ""外部ネットワーク"" msgid ""FIPS 140-2"" msgstr ""FIPS 140-2"" msgid ""FISMA"" msgstr ""FISMA"" msgid ""Fail securely"" msgstr ""フェイルセキュア"" msgid """" ""False positives occur when the security monitoring tool produces a security "" ""alert for a benign event. Due to the nature of security monitoring tools, "" ""false positives will most certainly occur from time to time. Typically a "" ""cloud administrator can tune security monitoring tools to reduce the false "" ""positives, but this may also reduce the overall detection rate at the same "" ""time. These classic trade-offs must be understood and accounted for when "" ""setting up a security monitoring system in the cloud."" msgstr """" ""誤検知は、セキュリティ監視ツールが害のないイベントのセキュリティ警告を出した"" ""場合に発生します。セキュリティ警告ツールの性質上、時々誤検知が発生することは"" ""間違いありません。通常、クラウド管理者は、セキュリティ監視ツールを微調整し"" ""て、誤検知を少なくすることができますが、これにより、全体的な検知率も同時に下"" ""がる場合があります。このような典型的トレードオフを理解し、クラウドにセキュリ"" ""ティ管理システムをセットアップする際には考慮に入れる必要があります。"" msgid ""FedRAMP"" msgstr ""FedRAMP"" msgid ""File permissions"" msgstr ""ファイルパーミッション"" msgid """" ""File system objects and memory and IPC objects are cleared before they can "" ""be reused by a process belonging to a different user."" msgstr """" ""ファイルシステムのオブジェクト、メモリ、IPC オブジェクトは、他のユーザーに属"" ""するプロセスにより再利用される前に、クリアされます。"" msgid """" ""Filesystem storage is a more secure solution for ephemeral block storage "" ""devices than LVM as dirty extents cannot be provisioned to users. However, "" ""it is important to be mindful that user data is not destroyed, so it is "" ""suggested to encrypt the backing filesystem."" msgstr """" ""データが含まれたエクステンドがユーザに用意されないので、一時ブロックストレー"" ""ジデバイス用としてファイルシステムストレージは LVM より安全なソリューションで"" ""す。しかしながら、ユーザデータが破壊されない事を覚えておく事は重要であり、こ"" ""のためバックエンドのファイルシステムの暗号化が提案されています。"" msgid """" ""Finally, Alice disables instance migrations as this feature is less critical "" ""for the high performance application workloads expected to run in this "" ""cloud. This helps avoid the various security concerns related to instance "" ""migrations."" msgstr """" ""最後に、アリスはインスタンスのマイグレーションを無効化しました。この機能はこ"" ""のクラウドで実行される予定の高パフォーマンスアプリケーション負荷にはほとんど"" ""不要だからです。これにより、インスタンスマイグレーションにまつわる様々なセ"" ""キュリティ関連を避ける事ができます。"" msgid """" ""Finally, administrators must perform command and control over the cloud for "" ""various operational functions. It is important these command and control "" ""facilities are understood and secured."" msgstr """" ""最後に、管理者は様々なオペレーション機能に対してクラウド上で指揮統制を行う必"" ""要があります。これらの指揮統制機能を理解、確保することが重要です。"" msgid """" ""Finally, due to the time constraints around a book sprint, the team chose to "" ""use KVM as the hypervisor in our example implementations and architectures."" msgstr """" ""最後に、ブックスプリントの時間的制約のため、実装例とアーキテクチャ例にハイ"" ""パーバイザーとして KVM を使用することにしました。"" msgid """" ""Finally, the node kernel should have a mechanism to validate that the rest "" ""of the node starts in a known good state. This provides the necessary link "" ""from the boot validation process to validating the entire system. The steps "" ""for doing this will be deployment specific. As an example, a kernel module "" ""could verify a hash over the blocks comprising the file system before "" ""mounting it using <link href=\""https://code.google.com/p/cryptsetup/wiki/"" ""DMVerity\"">dm-verity</link>."" msgstr """" ""最後に、ノードのカーネルには、残りのノードが既知の良好な状態で起動することを"" ""検証するメカニズムを取り入れるべきです。これにより、ブート検証プロセスからシ"" ""ステム全体の検証に至るまでの必要なリンクが提供されます。手順はデプロイメント"" ""によって異なります。例えば、カーネルモジュールは、<link href=\""https://code."" ""google.com/p/cryptsetup/wiki/DMVerity\"">dm-verity</link> を使用して、ファイル"" ""システムをマウントする前に、そのファイルシステムを構成するブロック上のハッ"" ""シュを検証することができます。"" msgid """" ""Finally, while not a feature of OpenStack, vendors and implementors may "" ""choose to add or support encryption of volumes. In this case, destruction of "" ""data is as simple as throwing away the key."" msgstr """" ""最後に、これは OpenStack の機能ではありませんが、ベンダーと開発者がボリューム"" ""の暗号化機能をサポートするか、あるいは追加可能であるかも知れません。この場"" ""合、データの破壊は単にキーを破棄するだけです。"" msgid ""Firewalls"" msgstr ""ファイアウォール"" msgid ""First thing to secure: the network"" msgstr ""最初にセキュア化するもの: ネットワーク"" msgid ""Flow analysis (through open source or third-party plug-ins)"" msgstr ""フロー分析 (オープンソースのサードパーティプラグイン使用)"" msgid ""For Volume storage:"" msgstr ""ボリュームストレージ"" msgid ""For additional configuration information see:"" msgstr ""追加の設定情報は以下を参照してください。"" msgid """" ""For additional information see the <link href=\""http://docs.openstack.org/"" ""admin-guide-cloud/content/ch_networking.html\"">Networking chapter</link> in "" ""the <citetitle>OpenStack Cloud Administrator Guide</citetitle>."" msgstr """" ""更なる情報は、<citetitle>OpenStack Cloud Administrator Guide</citetitle> 中"" ""の <link href=\""http://docs.openstack.org/admin-guide-cloud/content/"" ""ch_networking.html\"">Networking</link> の章を参照して下さい。"" msgid """" ""For commercial deployments of OpenStack, it is recommended that SOC 1/2 "" ""combined with ISO 2700 1/2 be considered as a starting point for OpenStack "" ""certification activities. The required security activities mandated by these "" ""certifications facilitate a foundation of security best practices and common "" ""control criteria that can assist in achieving more stringent compliance "" ""activities, including government attestations and certifications."" msgstr """" ""OpenStackの商用環境向けには、まずは開始点として、SOC 1/2とISO 27001/2の検討を"" ""推奨します。そこで要求されるセキュリティ活動を確実に実行することで、セキュリ"" ""ティのベストプラクティスと共通統制基準を導入を促進し、政府系認定などの、より"" ""厳格なコンプライアンス活動の取得にも役立ちます。"" msgid ""For configuration information see:"" msgstr ""設定情報は以下を参照してください。"" msgid ""For example,"" msgstr ""たとえば、"" msgid """" ""For information about the current state of feature support, see <link href="" ""\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack "" ""Hypervisor Support Matrix</link>."" msgstr """" ""機能サポートの現在の状況に関する情報は、 <link href=\""https://wiki.openstack."" ""org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support Matrix</"" ""link> を参照してください。"" msgid """" ""For instance scheduling, Alice uses the trusted compute pools to ensure that "" ""all cloud workloads are deployed to nodes that presented a proper boot time "" ""attestation. Alice decides to disable user permissions for image uploading "" ""to help ensure that the images used in the cloud are generated in a known "" ""and trusted manner by the cloud administrators."" msgstr """" ""インスタンススケジューリングでは、全てのクラウド負荷が適切な起動時間保証を示"" ""すノードにデプロイされるようにする為、アリスは信頼できる compute プールを使用"" ""します。クラウド中で使用されるイメージがクラウド管理者に既知で信頼できる方法"" ""で作成されたものである事を保証するため、アリスはユーザにイメージをアップロー"" ""ドする権限を与えない事を決めました。"" msgid """" ""For more details see <link href=\""http://www.27000.org/iso-27001.htm\"">ISO "" ""27001</link>."" msgstr """" ""詳細は<link href=\""http://www.27000.org/iso-27001.htm\"">ISO 27001</link>を参"" ""照してください。"" msgid """" ""For more details see <link href=\""http://www.gsa.gov/portal/"" ""category/102371\"">http://www.gsa.gov/portal/category/102371</link>."" msgstr """" ""詳細は<link href=\""http://www.gsa.gov/portal/category/102371\"">http://www."" ""gsa.gov/portal/category/102371</link>を参照してください。"" msgid """" ""For more details see <link href=\""https://www.pcisecuritystandards.org/"" ""security_standards/\"">PCI security standards</link>."" msgstr """" ""詳細は<link href=\""https://www.pcisecuritystandards.org/security_standards/"" ""\"">PCI security standards</link>を参照してください。"" msgid """" ""For more details see <link href=\""https://www.pmddtc.state.gov/"" ""regulations_laws/itar.html\"">https://www.pmddtc.state.gov/regulations_laws/"" ""itar.html</link>."" msgstr """" ""詳細は <link href=\""https://www.pmddtc.state.gov/regulations_laws/itar.html"" ""\"">https://www.pmddtc.state.gov/regulations_laws/itar.html</link> を参照して"" ""ください。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC1Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to User Entities' Internal "" ""Control over Financial Reporting</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC1Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to User Entities' Internal "" ""Control over Financial Reporting</link>を参照してください。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC2Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to Security, Availability, "" ""Processing Integrity, Confidentiality or Privacy</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC2Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to Security, Availability, "" ""Processing Integrity, Confidentiality or Privacy</link>を参照してください。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC3Report.aspx\"">AICPA Trust Services "" ""Report for Service Organizations</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC3Report.aspx\"">AICPA Trust Services "" ""Report for Service Organizations</link>を参照してください。"" msgid """" ""For more details see the <link href=\""https://www.cms.gov/Regulations-and-"" ""Guidance/HIPAA-Administrative-Simplification/HIPAAGenInfo/downloads/HIPAALaw."" ""pdf\"">Health Insurance Portability And Accountability Act</link>."" msgstr """" ""詳細は<link href=\""https://www.cms.gov/Regulations-and-Guidance/HIPAA-"" ""Administrative-Simplification/HIPAAGenInfo/downloads/HIPAALaw.pdf\"">Health "" ""Insurance Portability And Accountability Act</link>を参照してください。"" msgid """" ""For more information about Paste Deploy, see <link href=\""http://pythonpaste."" ""org/deploy/\"">http://pythonpaste.org/deploy/</link>."" msgstr """" ""Paste Deployに関する追加情報は <link href=\""http://pythonpaste.org/deploy/"" ""\"">http://pythonpaste.org/deploy/</link> を参照してください。"" msgid ""For more information on RabbitMQ SSL configuration see:"" msgstr ""RabbitMQ の SSL 設定に関する詳細は、以下を参照してください。"" msgid """" ""For the purpose of performance, many storage protocols are unencrypted. Some "" ""protocols such as iSCSI can provide authentication and encrypted sessions, "" ""it is our recommendation to enable these features."" msgstr """" ""性能の為に、多くのストレージプロトコルは暗号化されていません。iSCSI のような"" ""幾つかのプロトコルは、認証と暗号化セッションを提供できます。これらの機能を有"" ""効にする事を推奨します。"" msgid """" ""For the purposes of this document, we treat Community and Hybrid similarly, "" ""dealing explicitly only with the extremes of Public and Private clouds from "" ""a security perspective. Your security measures depend where your deployment "" ""falls upon the private public continuum."" msgstr """" ""本ガイドにおいては、コミュニティクラウドとハイブリッドクラウドを同様に扱い、"" ""パブリッククラウドとプライベートクラウドの両極のみをセキュリティ面から明確に"" ""説明します。セキュリティ対策は、デプロイメントがプライベートクラウド/パブリッ"" ""ククラウドの連続体のどこに位置するかによって異なります。"" msgid """" ""For these and other hypervisors, we recommend referring to hypervisor-"" ""specific documentation."" msgstr """" ""これらや他のハイパーバイザでは、ハイパーバイザ毎のドキュメントを参照すると良"" ""いでしょう。"" msgid """" ""For this document the components will be grouped into the following primary "" ""groups:"" msgstr """" ""このドキュメントの場合、コンポーネントは以下の主要なグループに分けています。"" msgid ""Forensics and incident response"" msgstr ""フォレンジングとインシデント対応"" msgid """" ""Fortunately, a cloud architect may address these issues by providing a high "" ""quality source of entropy to the cloud instances. This can be done by having "" ""enough hardware random number generators (HRNG) in the cloud to support the "" ""instances. In this case, \""enough\"" is somewhat domain specific. For "" ""everyday operations, a modern HRNG is likely to produce enough entropy to "" ""support 50-100 compute nodes. High bandwidth HRNGs, such as the RdRand "" ""instruction available with Intel Ivy Bridge and newer processors could "" ""potentially handle more nodes. For a given cloud, an architect needs to "" ""understand the application requirements to ensure that sufficient entropy is "" ""available."" msgstr """" ""これらの課題は、クラウドアーキテクトが高品質のエントロピーをクラウドインスタ"" ""ンスに提供することで対応できます。例えば、クラウド内にインスタンス用に適量な"" ""ハードウェア乱数生成器(HRNG)があれば解決できます（適量はドメインによって異な"" ""る）。一般的なハードウェア乱数生成器なら通常運用されている50-100台のコン"" ""ピュートノード分のエントロピーを生成することが可能です。高帯域ハードウェア乱"" ""数生成器（Intel Ivy Bridgeや最新プロセッサなどと提供されるRdRand instruction"" ""など）はさらに多くのノードに対応できます。エントロピーの量が十分かどうかを判"" ""断するためには、クラウド上で運用するアプリケーションの要求を理解している必要"" ""があります。"" msgid ""Front end caching"" msgstr ""フロントエンドキャッシュ"" msgid """" ""Further, the quality of community, as it surrounds an open source hypervisor "" ""like KVM or Xen, has a direct impact on the timeliness of bug fixes and "" ""security updates. When investigating both commercial and open source "" ""hypervisors, you must look into their release and support cycles as well as "" ""the time delta between the announcement of a bug or security issue and a "" ""patch or response. Lastly, the supported capabilities of OpenStack compute "" ""vary depending on the hypervisor chosen. See the <link href=\""https://wiki."" ""openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support "" ""Matrix</link> for OpenStack compute feature support by hypervisor."" msgstr """" ""さらに、コミュニティが KVM や Xen のようなオープンソースのハイパーバイザーを"" ""取り巻くので、その質はバグ修正やセキュリティ更新の適時性に直接的な影響があり"" ""ます。商用ハイパーバイザーとオープンソースのものを調査するとき、リリース間隔"" ""やサポートサイクルだけではなく、バグやセキュリティ問題のアナウンスから、パッ"" ""チや対応までの時間間隔を調査する必要があります。最後に、OpenStack Compute の"" ""サポート能力は、お使いのハイパーバイザーにより異なります。ハイパーバイザーに"" ""よりサポートされる OpenStack Compute の機能は、<link href=\""https://wiki."" ""openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support "" ""Matrix</link> を参照してください。"" msgid """" ""Further, when you evaluate a hypervisor platform, consider the "" ""supportability of the hardware on which the hypervisor will run. "" ""Additionally, consider the additional features available in the hardware and "" ""how those features are supported by the hypervisor you chose as part of the "" ""OpenStack deployment. To that end, hypervisors each have their own hardware "" ""compatibility lists (HCLs). When selecting compatible hardware it is "" ""important to know in advance which hardware-based virtualization "" ""technologies are important from a security perspective."" msgstr """" ""さらに、ハイパーバイザープラットフォームの評価時、ハイパーバイザーを実行する"" ""ハイパーバイザーを考慮すべきです。加えて、ハードウェアで利用可能な追加機能を"" ""評価します。また、それらの機能が OpenStack 環境の一部として選択したハイパーバ"" ""イザーによりどのようにサポートされるかを考慮します。そのためにも、ハイパーバ"" ""イザーはそれぞれ自身のハードウェア互換性リスト (HCL) を持つでしょう。互換性の"" ""あるハードウェアの選択時、まずどのハードウェア仮想化技術がセキュリティの観点"" ""から重要であるかを理解することが重要です。"" msgid ""Future"" msgstr ""将来"" msgid """" ""General data disposal and sanitization guidelines as adopted from NIST "" ""recommended security controls. Cloud operators should:"" msgstr """" ""NIST が採用した汎用のデータ破棄とサニタイズのガイドラインは、セキュリティ制御"" ""を推奨しています。クラウドオペレータは以下のことをすべきです。"" msgid ""Government standards"" msgstr ""政府標準"" msgid ""Granular access control"" msgstr ""精細なアクセス制御"" msgid """" ""Gregg Tally is the Chief Engineer at JHU/APL's Cyber Systems Group within "" ""the Asymmetric Operations Department. He works primarily in systems security "" ""engineering. Previously, he has worked at SPARTA, McAfee, and Trusted "" ""Information Systems where he was involved in cyber security research "" ""projects."" msgstr """" ""Gregg Tally は Asymmetric Operations Department の JHU/APL's Cyber Systems "" ""Group の Chief Engineer です。主にシステムセキュリティエンジニアリングに関す"" ""る仕事をしています。以前は、サイバーセキュリティ研究プロジェクトに関わり、"" ""SPARTA、McAfee、Trusted Information Systems に勤務していました。"" msgid ""Guest"" msgstr ""ゲスト"" msgid ""Guest network"" msgstr ""ゲストネットワーク"" msgid ""HIGH"" msgstr ""HIGH"" msgid ""HIPAA / HITECH"" msgstr ""HIPAA / HITECH"" msgid """" ""HIPAA is not a certification, rather a guide for protecting healthcare data. "" ""Similar to the PCI-DSS, the most important issues with both PCI and HIPPA is "" ""that a breach of credit card information, and health data, does not occur. "" ""In the instance of a breach the cloud provider will be scrutinized for "" ""compliance with PCI and HIPPA controls. If proven compliant, the provider "" ""can be expected to immediately implement remedial controls, breach "" ""notification responsibilities, and significant expenditure on additional "" ""compliance activities. If not compliant, the cloud provider can expect on-"" ""site audit teams, fines, potential loss of merchant ID (PCI), and massive "" ""reputation impact."" msgstr """" ""HIPPAは認証ではなく、カルテ情報の保護に関するガイドラインです。PCI-DSSと似て"" ""います。PCIとHIPAAの両方でもっとも重要な課題は、クレジットカード情報とカルテ"" ""情報が流出しないようにすることです。クラウドプロバイダーによる流出があった場"" ""合、PCIとHIPAAの統制下において検査されます。その内容が遵守に足るものであれ"" ""ば、そのプロバイダーはすみやかに是正措置の実行と情報流出の通知、およびコンプ"" ""ライアンス活動予算の大幅な追加を期待されます。もし足るものでなければ、現地で"" ""の査察、罰金、merchant ID (PCI)の失効、および評判に大きな傷がつくことが予想さ"" ""れます。"" msgid ""HTTP Strict Transport Security (HSTS)"" msgstr ""HTTP Strict Transport Security (HSTS)"" msgid ""HTTP listening port"" msgstr ""HTTP リッスンポート"" msgid ""HTTP strict transport security"" msgstr ""HTTP Strict Transport Security"" msgid ""HTTPS"" msgstr ""HTTPS"" msgid ""Hacking servers that are turned off"" msgstr ""オフ状態のサーバーのハッキング"" msgid ""Hadoop"" msgstr ""Hadoop"" msgid ""Hardening the virtualization layers"" msgstr ""仮想化層のセキュリティ強化"" msgid """" ""Hardens the data sections of an executable. Both full and partial RELRO "" ""modes are supported by gcc. For QEMU full RELRO is your best choice. This "" ""will make the global offset table read-only and place various internal data "" ""sections before the program data section in the resulting executable."" msgstr """" ""実行ファイルのデータ部分をセキュリティ強化します。全体 RELRO モードと部分 "" ""RELRO モードが gcc によりサポートされます。QEMU 完全 RELRO が最善の選択肢で"" ""す。これにより、グローバルオフセットテーブルが読み込み専用になり、出力実行"" ""ファイルのプログラムデータセクションの前にさまざまな内部データ部分が置かれま"" ""す。"" msgid ""Hardware"" msgstr ""ハードウェア"" msgid ""Hardware concerns"" msgstr ""ハードウェア関連"" msgid ""Hardware inventory"" msgstr ""ハードウェアインベントリ"" msgid """" ""Has the hypervisor undergone Common Criteria certification? If so, to what "" ""levels?"" msgstr """" ""ハイパーバイザーはCommon Criteria認定を取得していますか？取得している場合はど"" ""のレベルですか？"" msgid ""Havana release."" msgstr ""Havana リリース。"" msgid ""High"" msgstr ""高"" msgid """" ""Highlight security concerns and potential mitigations in present day "" ""OpenStack"" msgstr ""現在の OpenStack におけるセキュリティ懸念事項と実現可能な軽減策の紹介"" msgid ""Hive"" msgstr ""Hive"" msgid ""Horizon image upload"" msgstr ""Horizon のイメージのアップロード"" msgid """" ""Horizon is the OpenStack dashboard that provides users a self-service portal "" ""to provision their own resources within the limits set by administrators. "" ""These include provisioning users, defining instance flavors, uploading VM "" ""images, managing networks, setting up security groups, starting instances, "" ""and accessing the instances through a console."" msgstr """" ""Horizon は OpenStack のダッシュボードです。管理者により設定された制限の範囲内"" ""でユーザー自身のリソースを展開できるセルフサービスポータルをユーザーに提供し"" ""ます。これらには、ユーザーの管理、インスタンスのフレーバーの定義、仮想マシン"" ""イメージのアップロード、ネットワークの管理、セキュリティグループのセットアッ"" ""プ、インスタンスの起動、インスタンスへのコンソール経由のアクセスなどがありま"" ""す。"" msgid ""Host key fingerprints"" msgstr ""ホストキーのフィンガープリント"" msgid ""Host platform configuration"" msgstr ""ハードウェアプラットフォームの設定"" msgid ""Host platform manufacturer control"" msgstr ""ホストプラットフォームのメーカーによる制御"" msgid """" ""Host-based intrusion detection tools are also useful for automated "" ""validation of the cloud internals. There are a wide variety of host-based "" ""intrusion detection tools available. Some are open source projects that are "" ""freely available, while others are commercial. Typically these tools analyze "" ""data from a variety of sources and produce security alerts based on rule "" ""sets and/or training. Typical capabilities include log analysis, file "" ""integrity checking, policy monitoring, and rootkit detection. More advanced "" ""-- often custom -- tools can validate that in-memory process images match "" ""the on-disk executable and validate the execution state of a running process."" msgstr """" ""ホストベースの侵入検知ツールは、クラウド内部の検証の自動化にも役立ちます。ホ"" ""ストベースの侵入検知ツールにはさまざまな種類があります。オープンソースで自由"" ""に利用できるツールもあれば、商用のツールもあります。通常、これらのツールは、"" ""さまざまなソースからデータを分析し、ルールセットやトレーニングに基づいてセ"" ""キュリティ警告を出します。標準的な機能には、ログ解析、ファイルの完全性チェッ"" ""ク、ポリシー監視、ルートキット検出などがあります。また、より高度なツール (カ"" ""スタムの場合が多い) を使用すると、インメモリープロセスイメージがオンディスク"" ""の実行可能ファイルと一致するかどうかを確認して、実行中のプロセスの実行状態を"" ""検証することができます。"" msgid ""How"" msgstr ""本書の執筆方法"" msgid ""How are users granted access to build systems?"" msgstr ""どのようにしてユーザがビルドシステムへのアクセスを許可されるのか？"" msgid ""How is source code management performed?"" msgstr ""どのようにしてソースコード管理が行われるのか？"" msgid ""How to contribute to this book"" msgstr ""本書への貢献方法"" msgid ""Hybrid cloud"" msgstr ""ハイブリッドクラウド"" msgid ""Hyper-V"" msgstr ""Hyper-V"" msgid ""Hypervisor memory optimization"" msgstr ""ハイパーバイザーのメモリ最適化"" msgid ""Hypervisor selection"" msgstr ""ハイパーバイザーの選択"" msgid ""Hypervisor vs. baremetal"" msgstr ""ハードウェア対ベアメタル"" msgid ""Hypervisors in OpenStack"" msgstr ""OpenStack におけるハイパーバイザー"" msgid ""I/O MMU"" msgstr ""I/O MMU"" msgid ""IP ADDRESS OF SERVER"" msgstr ""IP ADDRESS OF SERVER"" msgid ""IP addresses of users"" msgstr ""ユーザの IP アドレス"" msgid ""IPL code configuration and data"" msgstr ""IPL コードの設定およびデータ"" msgid ""ISO 27001/2"" msgstr ""ISO 27001/2"" msgid ""ISO 27001/2:2013"" msgstr ""ISO 27001/2:2013"" msgid ""ITAR"" msgstr ""ITAR"" msgid ""Icehouse Release Notes"" msgstr ""Icehouse リリースノート"" msgid ""Identification and Authentication"" msgstr ""IDと認証"" msgid """" ""Identification and authentication using pluggable authentication modules "" ""(PAM) based upon user passwords. The quality of the passwords used can be "" ""enforced through configuration options."" msgstr """" ""pluggable authentication modules (PAM) を使用した識別と認証はユーザーパスワー"" ""ドに基づいています。使用されるパスワードの質は設定オプションにより強制できま"" ""す。"" msgid ""Identification and authentication, protected data transfer"" msgstr ""識別と認証、保護されたデータ転送"" msgid ""Identify the security domains in OpenStack"" msgstr ""OpenStack のセキュリティ領域の明確化"" msgid """" ""Identify where risks exist in a cloud architecture and apply controls to "" ""mitigate the risks. In areas of significant concern, layered defences "" ""provide multiple complementary controls to manage risk down to an acceptable "" ""level. For example, to ensure adequate isolation between cloud tenants, we "" ""recommend hardening QEMU, using a hypervisor with SELinux support, enforcing "" ""mandatory access control policies, and reducing the overall attack surface. "" ""The foundational principle is to harden an area of concern with multiple "" ""layers of defense such that if any one layer is compromised, other layers "" ""will exist to offer protection and minimize exposure."" msgstr """" ""クラウドアーキテクチャ内にあるリスクの存在場所を特定し、そのリスクを受容可能"" ""なレベルに管理すべく、コントロールします。特に心配される部分では、多層防御は"" ""さらなるリスク緩和のため、相互補完的なコントロールを提供します。たとえば、ク"" ""ラウドテナント間の十分な独立性を確保するには、QEMUの強化、SELinuxサポートのハ"" ""イパーバイザーを使う、強制アクセス制御の適用、攻撃対象面の縮小、などがおすす"" ""めです。この基本的な原則により、もしある階層が危険にさらされても、他の階層が"" ""防御し、露出を最小化することで、懸念される部分が強化されるのです。"" msgid ""Identity"" msgstr ""Identity"" msgid ""Identity API endpoints"" msgstr ""Identity APIエンドポイント"" msgid ""Identity service"" msgstr ""Identity"" msgid """" ""If Alice has adequately scoped and executed these compliance activities, she "" ""may begin the process to become FedRAMP compliant by hiring an approved "" ""third-party auditor. Typically this process takes up to 6 months, after "" ""which she will receive an Authority to Operate and can offer OpenStack cloud "" ""services to the government."" msgstr """" ""もしアリスが十分な範囲を定義し、それらのコンプライアンス活動を実施できたので"" ""あれば、次は認定外部監査人によるFedRAMP認証の取得プロセスに移ります。一般的に"" ""このプロセスは最長6ヶ月を要します。このステップを経て、Authority to Operate "" ""- 注意影響レベル認定 を取得し、OpenStackクラウドサービスを政府に提案できるよ"" ""うになります。"" msgid """" ""If a cloud deployment requires strong separation of tenants, as is the "" ""situation with public clouds and some private clouds, deployers should "" ""consider disabling TPS and KSM memory optimizations."" msgstr """" ""テナントを強く分離する必要があるクラウド環境の場合、つまりパブリッククラウド"" ""や特定のプライベートクラウドの場合、導入者は TPS や KSM メモリ最適化を無効化"" ""することを検討すべきです。"" msgid """" ""If network namespace support is not present, a further limitation of the L3 "" ""agent is that only a single logical router is supported."" msgstr """" ""ネットワークネームスペースサポートがない場合、L3エージェントでは追加の制限事"" ""項として単一の論理ルータのみサポートされます。"" msgid """" ""If nodes that run either <systemitem class=\""service\"">neutron-l3-agent</"" ""systemitem> or <systemitem class=\""service\"">neutron-dhcp-agent</systemitem> "" ""use overlapping IP addresses, those nodes must use Linux network namespaces. "" ""By default, the DHCP and L3 agents use Linux network namespaces. However, if "" ""the host does not support these namespaces, run the DHCP and L3 agents on "" ""different hosts."" msgstr """" ""<systemitem class=\""service\"">neutron-l3-agent</systemitem> か <systemitem "" ""class=\""service\"">neutron-dhcp-agent</systemitem> のいずれかを実行するノード"" ""が重複した IP アドレスを使用する場合、これらのノード群は Linux のネットワーク"" ""ネームスペースを使用する必要があります。デフォルトでは、DHCP と L3 エージェン"" ""トは Linux ネットワークネームスペースを使用しています。しかしながら、ホストが"" ""このネームスペースをサポートしていない場合、DHCP と L3 エージェントは異なるホ"" ""ストで実行して下さい。"" msgid """" ""If your deployment of OpenStack provides multiple external access points "" ""into different security domains it is important that you limit the tenant's "" ""ability to attach multiple vNICs to multiple external access pointsthis "" ""would bridge these security domains and could lead to unforeseen security "" ""compromise. It is possible mitigate this risk by utilizing the host "" ""aggregates functionality provided by OpenStack Compute or through splitting "" ""the tenant VMs into multiple tenant projects with different virtual network "" ""configurations."" msgstr """" ""あなたの OpenStack のデプロイが異なるセキュリティドメインに向けて複数の外部ア"" ""クセスポイントを提供する場合、複数の外部アクセスポイントへ複数の仮想NICをア"" ""タッチするテナントの機能を制限する事は重要です。これは、これらのセキュリティ"" ""ドメインのブリッジになり、思いがけないセキュリティの妥協を導くかも知れませ"" ""ん。OpenStack Compute が提供するホストアグリゲート機能の活用や、異なる仮想"" ""ネットワーク設定を持つ複数のテナントプロジェクトにテナントVMを分割する事で、"" ""リスクを緩和する事が可能です。"" msgid ""Image creation process"" msgstr ""イメージ作成プロセス"" msgid ""Image provenance and validation"" msgstr ""イメージの出所と妥当性確認"" msgid ""Image service"" msgstr ""Image サービス"" msgid ""Implementation standard"" msgstr ""実装標準"" msgid ""Improves performance of network I/O on hypervisors"" msgstr ""ハイパーバイザーにおけるネットワーク I/O の性能を改善します"" msgid ""In <filename>my.cnf</filename>:"" msgstr ""<filename>my.cnf</filename>:"" msgid ""In <filename>postgresql.conf</filename>:"" msgstr ""<filename>postgresql.conf</filename>:"" msgid """" ""In addition to validating a technologies capabilities, the Common Criteria "" ""process evaluates <emphasis>how</emphasis> technologies are developed."" msgstr """" ""Common Criteria のプロセスは、技術的な機能の評価に加えて、技術が<emphasis>ど"" ""のように</emphasis>開発されているのかを評価します。"" msgid """" ""In addition, mechanisms for protection against stack overflow attacks are "" ""provided."" msgstr ""さらに、スタックオーバーフロー攻撃に対する保護機構が提供されます。"" msgid ""In an OpenStack deployment you will need to address the following:"" msgstr ""OpenStack デプロイでは、以下の事も実施する必要があるでしょう。"" msgid ""In file <filename>pg_hba.conf</filename>:"" msgstr ""<filename>pg_hba.conf</filename> ファイル:"" msgid """" ""In general, there are two different strategies for verifying the boot "" ""process. Traditional <emphasis>secure boot</emphasis> will validate the code "" ""run at each step in the process, and stop the boot if code is incorrect. "" ""<emphasis>Boot attestation</emphasis> will record which code is run at each "" ""step, and provide this information to another machine as proof that the boot "" ""process completed as expected. In both cases, the first step is to measure "" ""each piece of code before it is run. In this context, a measurement is "" ""effectively a SHA-1 hash of the code, taken before it is executed. The hash "" ""is stored in a platform configuration register (PCR) in the TPM."" msgstr """" ""ブートプロセスの検証には、通常 2 つの異なる戦略があります。従来の<emphasis>セ"" ""キュアブート</emphasis>は、プロセスの各ステップに実行されるコードを検証し、"" ""コードが正しくない場合にはブートを中止します。<emphasis>ブートアテステーショ"" ""ン</emphasis>は、どのステップでどのコードが実行されるかを記録し、ブートプロセ"" ""スが想定通りに完了した証拠として、この情報を別のマシンに提供します。いずれの"" ""ケースにおいても、第 1 のステップでは、実行前にコードの各要素を計測します。こ"" ""の場合、計測値は実質的にはコードの SHA-1 ハッシュで、実行前に取得されます。 "" ""このハッシュは、TPM 内の Platform Configuration Register (PCR) に保管されま"" ""す。"" msgid """" ""In particular, you must assure your end users that the node has been "" ""properly sanitized of their data prior to re-provisioning. Additionally, "" ""prior to reusing a node, you must provide assurances that the hardware has "" ""not been tampered or otherwise compromised."" msgstr """" ""とくに、ノードが再配備する前にデータを適切に無害化されることをエンドユーザー"" ""に保証する必要があります。加えて、ノードを再利用する前に、ハードウェアが汚染"" ""されていたり、侵入されたりしていないことを保証する必要があります。"" msgid """" ""In some cases deployers may want to consider securing a bridge to a higher "" ""standard than any of the domains in which it resides. Given the above "" ""example of an API endpoint, an adversary could potentially target the API "" ""endpoint from the public domain, leveraging it in the hopes of compromising "" ""or gaining access to the management domain."" msgstr """" ""デプロイ担当者は、ブリッジするどのドメインよりも高い基準でブリッジのセキュリ"" ""ティを確保するように考えるようにしてください。API エンドポイントの上記の例で"" ""は、攻撃者はパブリックドメインから API エンドポイントをターゲットにして、情報"" ""漏洩や管理ドメインへアクセス権の獲得を期待しつつこのエンドポイントを利用する"" ""のです。"" msgid """" ""In some deployments it may be required to add host-based IDS on sensitive "" ""components on security domain bridges. A host-based IDS may detect anomalous "" ""activity by compromised or unauthorized processes on the component. The IDS "" ""should transmit alert and log information on the Management network."" msgstr """" ""一部のデプロイメントでは、ホストベースの IDS をセキュリティドメインブリッジ上"" ""の機密性の高いコンポーネントに追加する必要がある場合があります。ホストベース"" ""の IDS は、そのコンポーネント上の侵害された、あるいは許可されていないプロセス"" ""による異常なアクティビティを検知することができます。IDS は管理ネットワーク上"" ""で警告およびログ情報を伝送すべきです。"" msgid """" ""In the United States the National Institute of Science and Technology (NIST) "" ""certifies cryptographic algorithms through a process known the Cryptographic "" ""Module Validation Program. NIST certifies algorithms for conformance against "" ""Federal Information Processing Standard 140-2 (FIPS 140-2), which ensures:"" msgstr """" ""アメリカでは、National Institute of Science and Technology (NIST) が "" ""Cryptographic Module Validation Program として知られるプロセスにより暗号アル"" ""ゴリズムを認証します。NIST は、以下を保証する Federal Information Processing "" ""Standard 140-2 (FIPS 140-2) に適合するアルゴリズムを認証します。"" msgid """" ""In the beginning of this chapter we discuss the use of both physical and "" ""virtual hardware by instances, the associated security risks, and some "" ""recommendations for mitigating those risks. We conclude the chapter with a "" ""discussion of sVirt, an open source project for integrating SELinux "" ""mandatory access controls with the virtualization components."" msgstr """" ""本章の初めに、インスタンスによる物理ハードウェアと仮想ハードウェアの両方の使"" ""用、関連するセキュリティリスク、それらのリスクを軽減するためのいくつかの推奨"" ""事項について議論します。SELinux 強制アクセス制御を仮想化コンポーネントと統合"" ""するためのオープンソースプロジェクトである sVirt の議論で本章を終わります。""msgid ""In this case, Bob will approach these steps the same as Alice."" msgstr ""今回のケーススタディでは、ボブはアリスと同様の手段を取ります。"" msgid """" ""In this chapter we explore these technologies and describe the situations "" ""where they can be used to enhance security for instances or underlying "" ""instances. We also seek to highlight where privacy concerns may exist. These "" ""include data pass through, introspection, or providing a source of entropy. "" ""In this section we highlight the following additional security services:"" msgstr """" ""本章では、これらの仕組みの詳細とどのような状況においてインスタンスのセキュリ"" ""ティが向上されるかを説明します。また、プライバシー観点における懸念箇所にも焦"" ""点をあてます。データのパススルー、イントロスペクション、またエントロピー元の"" ""提供などが該当します。本セクションでは、下記のセキュリティサービスに焦点を当"" ""てます:"" msgid """" ""In this example we introduce a scoring matrix that places vulnerabilities in "" ""three categories: Privilege Escalation, Denial of Service and Information "" ""Disclosure. Understanding the type of vulnerability and where it occurs in "" ""your infrastructure will enable you to make reasoned response decisions."" msgstr """" ""以下の例では、権限昇格、DoS (サービス妨害)、情報開示の 3 つのカテゴリーに脆弱"" ""性を分類した評価一覧表を紹介しています。脆弱性の種類やインフラストラクチャー"" ""内での発生箇所を理解することで、裏付けに基いた対応意思決定を下すことができま"" ""す。"" msgid ""Incidence response"" msgstr ""インシデントレスポンス"" msgid """" ""Industry standard security principles provide a baseline for compliance "" ""certifications and attestations. If these principles are considered and "" ""referenced throughout an OpenStack deployment, certification activities may "" ""be simplified."" msgstr """" ""業界標準のセキュリティ原則は、コンプライアンス認証、認定のための基準を提供し"" ""ます。もしそれらの原則が対象のOpenStack環境で考慮、適用されていれば、認証を得"" ""る活動はシンプルになるでしょう。"" msgid """" ""Information Disclosure vulnerabilities reveal information about your system "" ""or operations. These vulnerabilities range from debugging information "" ""disclosure, to exposure of critical security data, such as authentication "" ""credentials and passwords."" msgstr """" ""情報開示の脆弱性は、システムや操作の情報を公開します。これらの脆弱性は、情報"" ""開示のデバッグから認証情報やパスワードなどの重要なセキュリティデータの公開な"" ""どが当てはまります。"" msgid ""Information Security Management system (ISMS)"" msgstr ""Information Security Management System (ISMS)"" msgid ""Information disclosure"" msgstr ""情報開示"" msgid """" ""Information system security compliance is reliant on the completion of two "" ""foundational processes:"" msgstr """" ""情報システムのセキュリティコンプライアンスは、二つの基本的なプロセスの完了を"" ""前提としています。"" msgid ""Initial Program Loader (IPL) code. For example, master boot record."" msgstr ""Initial Program Loader (IPL) コード (例: マスターブートレコード) "" msgid ""Initial creation..."" msgstr ""初版作成..."" msgid ""Instance memory scrubbing"" msgstr ""インスタンスメモリの消去"" msgid ""Instance migrations"" msgstr ""インスタンスのマイグレーション"" msgid ""Integrity life-cycle"" msgstr ""完全性ライフサイクル"" msgid ""Intel TXT / SEM"" msgstr ""Intel TXT / SEM"" msgid ""Intel Trusted Execution Technology"" msgstr ""Intel Trusted Execution Technology"" msgid ""Intended purpose"" msgstr ""想定用途"" msgid ""Internal API communications"" msgstr ""内部API通信"" msgid ""Internal audit"" msgstr ""内部監査"" msgid ""Internally generated private keys for compute image bundling"" msgstr ""Compute イメージ作成用に内部で生成されたプライベートキー"" msgid ""Internally implemented authentication methods"" msgstr ""内部実装認証方式"" msgid """" ""Introduce privacy considerations specific to OpenStack and cloud "" ""environments."" msgstr ""OpenStackおよびクラウド環境におけるプライバシーの考慮事項を説明する"" msgid """" ""Introduced into the Linux kernel in version 2.6.32, Kernel Samepage Merging "" ""(KSM) consolidates identical memory pages between Linux processes. As each "" ""guest VM under the KVM hypervisor runs in its own process, KSM can be used "" ""to optimize memory use between VMs."" msgstr """" ""Linux カーネル 2.6.32 に導入された、Kernel Samepage Merging (KSM) は複数の "" ""Linux プロセスの同一メモリページを集約します。KVM ハイパーバイザーにある各ゲ"" ""スト仮想マシンは、自身のプロセスで動作するので、KSM は仮想マシン間でメモリ使"" ""用量を最適化するために使用できます。"" msgid ""Introduction"" msgstr ""はじめに"" msgid ""Introduction to OpenStack"" msgstr ""OpenStack の概要"" msgid ""Introduction to case studies"" msgstr ""ケーススタディの概要"" msgid ""Intrusion detection system"" msgstr ""侵入検知システム"" msgid ""Invalid login attempts"" msgstr ""無効なログイン試行"" msgid ""Is the technology cryptographically signed before distribution?"" msgstr ""技術は配布前に暗号署名されるのか？"" msgid ""Is the underlying cryptography certified by a third-party?"" msgstr ""採用している暗号化技術は第三者によって認定されていますか？"" msgid ""Isolated migration network"" msgstr ""マイグレーションネットワークの分離"" msgid """" ""It has become industry practice to use secure shell (SSH) access for the "" ""management of Linux and Unix systems. SSH uses secure cryptographic "" ""primitives for communication. With the scope and importance of SSH in "" ""typical OpenStack deployments, it is important to understand best practices "" ""for deploying SSH."" msgstr """" ""Linux や Unix システムの管理にはセキュアシェル (SSH) を使用するのが業界の慣習"" ""となっています。SSH は通信にセキュアな暗号化機能を使用します。一般的な "" ""OpenStack デプロイメントでの SSH の範囲や重要性において、SSH デプロイメントの"" ""ベストプラクティスを把握することが重要です。"" msgid """" ""It is an extensible <glossterm>Django</glossterm> web application that "" ""allows easy plug-in of third-party products and services, such as billing, "" ""monitoring, and additional management tools."" msgstr """" ""Hirozon は拡張可能な <glossterm>Django</glossterm> Web アプリケーションで、請"" ""求、監視、追加管理ツールなど、サードパーティーの製品やサービスを簡単にプラグ"" ""インできるようにします。"" msgid ""It is highly recommended to use HTTP Strict Transport Security (HSTS)."" msgstr ""HTTP Strict Transport Security (HSTS) の使用が強く推奨されます。"" msgid """" ""It is important to include Backup procedures and policies in the overall "" ""System Security Plan. For a good overview of OpenStack's Backup and Recovery "" ""capabilities and procedures, please refer to the OpenStack Operations Guide."" msgstr """" ""全体的なシステムセキュリティプランにバックアップ手順とポリシーを含めることは"" ""重要です。OpenStack のバックアップ／リカバリー機能や手順についての適切な概要"" ""は、OpenStack 運用ガイドを参照してください。"" msgid """" ""It is important to note that use of the Xen memory balloon feature is likely "" ""to result in information disclosure. We strongly recommended to avoid use of "" ""this feature."" msgstr """" ""Xen のメモリバルーン機能の使用は情報漏えいの結果になりかねないという事への注"" ""意は重要です。"" msgid """" ""It is important to understand that object storage differs from traditional "" ""file system storage. It is best used for static data such as media files "" ""(MP3s, images, videos), virtual machine images, and backup files."" msgstr """" ""オブジェクトストレージは、従来のファイルシステムストレージと異なる点を理解し"" ""ておくことが重要です。メディアファイル (MP3、画像、ビデオ) や仮想マシンイメー"" ""ジ、バックアップファイルなどの静的データに使用するのに最適です。"" msgid """" ""It is necessary for administrators to perform command and control over the "" ""cloud for various operational functions. It is important these command and "" ""control facilities are understood and secured."" msgstr """" ""管理者は、様々な運用機能に対してクラウドの管理統制を行う必要があります。ま"" ""た、これらの管理統制機能を理解して、セキュリティの確保を行うことが重要です。"" msgid """" ""It is our recommendation to leverage per tenant L3 routing and Floating IPs "" ""for more granular connectivity of tenant VMs."" msgstr """" ""テナント VM のより粒度の細かいテナント L3 ルーティングとフローティング IP 単"" ""位で設定する事をお勧めします。"" msgid ""KVM"" msgstr ""KVM"" msgid ""KVM Kernel Samepage Merging"" msgstr ""KVM Kernel Samepage Merging"" msgid """" ""KVM-based virtual machine instances are labelled with their own SELinux data "" ""type, known as svirt_image_t. Kernel level protections prevent unauthorized "" ""system processes, such as malware, from manipulating the virtual machine "" ""image files on disk. When virtual machines are powered off, images are "" ""stored as svirt_image_t as shown below:"" msgstr """" ""KVM ベースの仮想マシンインスタンスは、svirt_image_t として知られる、独自の "" ""SELinux データタイプでラベル付けされています。カーネルレベルの保護により、悪"" ""意のあるソフトウェアのような権限のないシステムプロセスが、ディスクにある仮想"" ""マシンのイメージファイルを操作することを防ぎます。仮想マシンが電源オフのと"" ""き、イメージは以下のように svirt_image_t として保存されます。"" msgid """" ""KVM: <link href=\""http://www.linux-kvm.org/page/"" ""How_to_assign_devices_with_VT-d_in_KVM\"">How to assign devices with VT-d in "" ""KVM</link>"" msgstr """" ""KVM: <link href=\""http://www.linux-kvm.org/page/"" ""How_to_assign_devices_with_VT-d_in_KVM\"">How to assign devices with VT-d in "" ""KVM</link>"" msgid """" ""Keith Basil is a Principal Product Manager for Red Hat OpenStack and is "" ""focused on Red Hat's OpenStack product management, development and strategy. "" ""Within the US public sector, Basil brings previous experience from the "" ""design of an authorized, secure, high-performance cloud architecture for "" ""Federal civilian agencies and contractors."" msgstr """" ""Keith Basil は Red Hat OpenStack の Principal Product Manager です。Red Hat "" ""の OpenStack 製品マネジメント、開発、戦略に注力しています。アメリカの公共部門"" ""の中で、アメリカの民間機関と委託業者向けの認定済み、セキュアかつハイパフォー"" ""マンスなクラウドアーキテクチャの設計から、これまでの経験をもたらします。"" msgid ""Kerberos"" msgstr ""Kerberos"" msgid ""Key length"" msgstr ""鍵の長さ"" msgid ""Key management"" msgstr ""キーマネージメント"" msgid ""Keystone"" msgstr ""Keystone"" msgid """" ""Keystone is the commonly used Identity provider in OpenStack. It may also be "" ""used for authentication in Object Storage. Coverage of securing keystone is "" ""already provided in <xref linkend=\""identity\""/>."" msgstr """" ""Keystone が OpenStack で一般的に使用される認証プロバイダーです。これは "" ""Object Storage でも認証のために使用できます。keystone のセキュア化については"" ""すでに <xref linkend=\""identity\""/> で提供されています。"" msgid ""L2 tunneling"" msgstr ""L2 トンネリング"" msgid ""L3 agent (<systemitem class=\""service\"">neutron-l3-agent</systemitem>)"" msgstr """" ""L3 エージェント (<systemitem class=\""service\"">neutron-l3-agent</systemitem>)"" msgid ""L3 routing and NAT"" msgstr ""L3 ルーティングおよび NAT"" msgid ""L=1024, N=160 bits"" msgstr ""L=1024、N=160 ビット""""LDAP simplifies integration of Identity authentication into an "" ""organization's existing directory service and user account management "" ""processes.""""LDAP により、組織の既存のディレクトリサービスやユーザーアカウント管理プロセス"" ""に Identity 認証をシンプルに統合できます。"" msgid ""Labels and categories"" msgstr ""ラベルとカテゴリ""""Later in the guide, we focus generically on the virtualization stack as it "" ""relates to hypervisors.""""本ガイドの後半では、ハイパーバイザーと関連する仮想化スタックに焦点をあてて、"" ""包括的に解説します。"" msgid ""Layered defenses"" msgstr ""階層防御"" msgid ""Least privilege"" msgstr ""最小権限"" msgid """" ""Likewise, it is important to protect the cloud deployment from being "" ""configured or manipulated by malicious entities. With many systems in a "" ""cloud employing compute and networking virtualization, there are distinct "" ""challenges applicable to OpenStack which must be addressed through integrity "" ""lifecycle management."" msgstr """" ""同様に、悪意のある組織により設定または操作されないように、クラウドデプロイメ"" ""ントを保護することが重要です。コンピュートやネットワークの仮想化を採用するク"" ""ラウド内の多くのシステムでは、OpenStack に適用される問題が明らかに存在し、整"" ""合性のライフサイクル管理で対応していく必要があります。"" msgid ""Limitations"" msgstr ""制限事項"" msgid ""Live migration mitigations"" msgstr ""ライブマイグレーションのリスクの軽減"" msgid ""Live migration risks"" msgstr ""ライブマイグレーションのリスク"" msgid ""Load balancer"" msgstr ""負荷分散装置"" msgid ""Load balancing"" msgstr ""負荷分散"" msgid ""Logging"" msgstr ""ロギング"" msgid ""Logging capability"" msgstr ""ロギング機能"" msgid """" ""Logs are not only valuable for proactive security and continuous compliance "" ""activities, but they are also a valuable information source for "" ""investigating and responding to incidents."" msgstr """" ""ログは率先したセキュリティや継続的なコンプライアンス活動に有用であるのみなら"" ""ず、インシデントの調査と対応の為の情報源としても有用です。"" msgid ""Low"" msgstr ""低"" msgid ""MAC Policy"" msgstr ""MAC ポリシー"" msgid """" ""MAC Policy: Mandatory Access Control; may be implemented with SELinux or "" ""other operating systems"" msgstr """" ""MAC ポリシー: 強制アクセス制御は SELinux または他のオペレーティングシステムを"" ""用いて実装されます"" msgid ""Machine snapshots"" msgstr ""マシンのスナップショット"" msgid """" ""Maintain good records from your internal audit. These will prove useful "" ""during the external audit so you can be prepared to answer questions about "" ""mapping the compliance controls to a particular deployment."" msgstr """" ""内部監査での良好な状態を維持してください。それらは外部監査の実施期間に証明と"" ""して役立ちます。またそれは、コンプライアンス統制に関する詳細な質疑応答の備え"" ""となります。"" msgid """" ""Malini Bhandaru is a security architect at Intel. She has a varied "" ""background, having worked on platform power and performance at Intel, speech "" ""products at Nuance, remote monitoring and management at ComBrio, and web "" ""commerce at Verizon. She has a Ph.D. in Artificial Intelligence from the "" ""University of Massachusetts, Amherst."" msgstr """" ""Malini Bhandaru は Intel のセキュリティアーキテクトです。Intel でプラット"" ""フォームの電力とパフォーマンス、Nuance でスピーチ製品、ComBrio でリモートモニ"" ""タリングと管理、Verizon でウェブコマースに関するさまざまなバックグラウンドを"" ""持ちます。University of Massachusetts, Amherst で人工知能に関する Ph.D. を"" ""持っています。"" msgid ""Management"" msgstr ""管理"" msgid ""Management interfaces"" msgstr ""管理インターフェース"" msgid ""Management network"" msgstr ""管理ネットワーク"" msgid ""Management utilities"" msgstr ""管理ユーティリティ"" msgid ""Mandatory Access Control"" msgstr ""強制アクセス制御"" msgid ""Mandatory access controls"" msgstr ""強制アクセス制御"" msgid """" ""Many hypervisors offer a functionality known as PCI passthrough. This allows "" ""an instance to have direct access to a piece of hardware on the node. For "" ""example, this could be used to allow instances to access video cards or GPUs "" ""offering the compute unified device architecture (CUDA) for high performance "" ""computation. This feature carries two types of security risks: direct memory "" ""access and hardware infection."" msgstr """" ""多くのハイパーバイザーは PCI パススルーとして知られる機能を提供します。これに"" ""より、インスタンスがノードにあるハードウェアの一部に直接アクセスできます。た"" ""とえば、インスタンスがハイパフォーマンスコンピューティング用の compute "" ""unified device architecture (CUDA) を提供するビデオカードや GPU にアクセスす"" ""るために使用されます。この機能は 2 種類のセキュリティリスクをもたらします。ダ"" ""イレクトメモリアクセスとハードウェア感染です。"" msgid """" ""Many modern Linux distributions already build QEMU with compiler hardening "" ""enabled, so you may want to verify your existing executable before "" ""proceeding with the information below. One tool that can assist you with "" ""this verification is called <link href=\""http://www.trapkit.de/tools/"" ""checksec.html\""><literal>checksec.sh</literal></link>."" msgstr """" ""ほとんどの最近の Linux ディストリビューションは、すでにコンパイラーのセキュリ"" ""ティ強化を有効化して QEMU をビルドしています。そのため、以下の情報を続ける前"" ""に、既存のバイナリを確認したいでしょう。この確認を手助けできるツールの 1 つ"" ""は <link href=\""http://www.trapkit.de/tools/checksec.html"" ""\""><literal>checksec.sh</literal></link> と呼ばれます。"" msgid """" ""Many operating systems now provide compartmentalization support. Linux "" ""supports namespaces to assign processes into independent domains. Other "" ""parts of this guide cover system compartmentalization in more detail."" msgstr """" ""多くのOSは現在コンパートメント化をサポートしています。Linuxではプロセスに独立"" ""したドメインを割り当てる名前空間をサポートしています。システムのコンパートメ"" ""ント化についてはこのマニュアルの別の部分で詳しく説明されています。"" msgid """" ""Many organizations have an established Public Key Infrastructure with their "" ""own certification authority (CA), certificate policies, and management for "" ""which they should use to issue certificates for internal OpenStack users or "" ""services. Organizations in which the public security domain is Internet "" ""facing will additionally need certificates signed by a widely recognized "" ""public CA. For cryptographic communications over the management network, it "" ""is recommended one not use a public CA. Instead, we expect and recommend "" ""most deployments deploy their own internal CA."" msgstr """" ""多くの組織には、内部のOpenStackユーザやサービス用に証明書を発行する為に使用さ"" ""れるべき場所用の自身の認証局(CA)、証明ポリシー、管理を備えたPublic Key "" ""Infrastructure (PKI)が設置されています\n"" ""。加えて、パブリックセキュリティドメインがインターネットに面している所の組織"" ""は、幅広く認識された公共のCAにより署名された証明書が必要になるでしょう。管理"" ""ネットワーク上の暗号化通信用には、パブリックCAを使用しない事をお勧めします。"" ""代わりに、多くのデプロイでは自身の内部CAを設置していると思われますし、推奨し"" ""ます。"" msgid """" ""Many organizations typically deploy web applications at subdomains of an "" ""overarching organization domain. It is natural for users to expect a domain "" ""of the form <uri>openstack.example.org</uri>. In this context, there are "" ""often many other applications deployed in the same second-level namespace, "" ""often serving user-controlled content. This name structure is convenient and "" ""simplifies name server maintenance."" msgstr """" ""多くの組織は一般的に、組織全体のドメインのサブドメインに Web アプリケーション"" ""を配備します。ユーザーが <uri>openstack.example.org</uri> 形式のドメインを期"" ""待することは自然です。これに関連して、しばしば同じセカンドレベルの名前空間に"" ""配備された、ユーザーが管理できるコンテンツを取り扱う他の多くのアプリケーショ"" ""ンがあります。この名前の構造は便利であり、ネームサーバーのメンテナンスを簡単"" ""にします。"" msgid ""Medium"" msgstr ""中"" msgid ""Medium / low"" msgstr ""中/低"" msgid ""Message Digest"" msgstr ""メッセージダイジェスト"" msgid ""Message queue process isolation and policy"" msgstr ""メッセージキュープロセスのアイソレーションとポリシー"" msgid """" ""Message queue service processes should be isolated from each other and other "" ""processes on a machine."" msgstr """" ""メッセージキューサービスのプロセスは、他のキューサービスのプロセスや、同一マ"" ""シン上の他プロセスと分離すべきです。"" msgid """" ""Message queues effectively facilitate command and control functions across "" ""OpenStack deployments. Once access to the queue is permitted no further "" ""authorization checks are performed. Services accessible through the queue do "" ""validate the contexts and tokens within the actual message payload. However, "" ""you must note the expiration date of the token because tokens are "" ""potentially re-playable and can authorize other services in the "" ""infrastructure."" msgstr """" ""メッセージキューは、OpenStack 内における指揮系統の機能を担います。一度キュー"" ""へのアクセスが許可されると、その後の認証チェックは行われません。キューを使用"" ""するサービスがメッセージペイロード内のコンテキストとトークンのチェックを行い"" ""ます。\n"" ""とはいえ、トークンの期限切れには注意を払う必要があります。これは、トークンが"" ""潜在的に再発行可能であり、インフラストラクチャ内の他のサービスを許可する可能"" ""性があるためです。"" msgid ""Message queuing"" msgstr ""メッセージキュー"" msgid """" ""Message queuing services facilitate inter-process communication in "" ""OpenStack. OpenStack supports these message queuing service back ends:"" msgstr """" ""メッセージキューイングサービスは、OpenStack 内におけるプロセス間通信を担いま"" ""す。OpenStack は次のキューイングサービスをサポートしています。"" msgid ""Messaging security"" msgstr ""メッセージングのセキュリティ"" msgid ""Messaging server"" msgstr ""メッセージングサーバー"" msgid ""Messaging transport security"" msgstr ""メッセージ通信路のセキュリティ"" msgid """" ""Metadata stored by an OpenStack cloud includes the following non-exhaustive "" ""items:"" msgstr ""以下の不完全な一覧を含む、OpenStack クラウドが保存したメタデータ:"" msgid ""Migration network"" msgstr ""マイグレーションネットワーク"" msgid ""Minimizing the QEMU code base"" msgstr ""QEMU コードベースの最小化"" msgid """" ""Monitor the traffic on the management network. The anomalies might be easier "" ""to track than on the busier compute nodes."" msgstr """" ""管理ネットワークのトラフィックを監視します。トラフィックの多いコンピュート"" ""ノードよりも例外のトラッキングが簡単になる場合があります。"" msgid ""Monitoring and logging"" msgstr ""監視とログ採取"" msgid ""Monitoring use cases"" msgstr ""監視ユースケース"" msgid """" ""Most cloud deployments will not want to build software such as QEMU by hand. "" ""It is better to use packaging to ensure that the process is repeatable and "" ""to ensure that the end result can be easily deployed throughout the cloud. "" ""The references below provide some additional details on applying compiler "" ""hardening options to existing packages."" msgstr """" ""ほとんどのクラウド環境は QEMU のようなソフトウェアを手動でビルドしたくないで"" ""しょう。プロセスが確実に繰り返し可能であり、最終結果を簡単にクラウドにデプロ"" ""イできるようにするために、パッケージを使用するほうが良いでしょう。以下の参考"" ""情報は、既存のパッケージにコンパイラーのセキュリティ強化オプションを適用する"" ""ことの詳細を提供します。"" msgid """" ""Most likely, the most important aspect in hypervisor selection is the "" ""expertise of your staff in managing and maintaining a particular hypervisor "" ""platform. The more familiar your team is with a given product, its "" ""configuration, and its eccentricities, the fewer the configuration mistakes. "" ""Additionally, having staff expertise spread across an organization on a "" ""given hypervisor increases availability of your systems, allows segregation "" ""of duties, and mitigates problems in the event that a team member is "" ""unavailable."" msgstr """" ""多分、ハイパーバイザー選択における一番重要な観点はある特定のハイパーバイザー"" ""プラットフォームの管理と保守におけるあなたのスタッフのノウハウです。あなたの"" ""チームが与えられた製品、その設定、クセに慣れていればいるほど、設定ミスは少な"" ""くなります。加えて、あなたのスタッフが与えられたハイパーバイザーについて組織"" ""を横断してノウハウを広めていけば、あなたのシステムの可用性は向上し、職務分掌"" ""が可能になり、チームメンバーが対応できない場合での問題を軽減します。"" msgid """" ""Most types of cloud deployment, public or private, are exposed to some form "" ""of attack. In this chapter we categorize attackers and summarize potential "" ""types of attacks in each security domain."" msgstr """" ""クラウドデプロイメントの種類の多く (パブリックまたはプライベート) は、なんら"" ""かの攻撃にさらされています。本章では、攻撃者を分類して、各セキュリティドメイ"" ""ンで考えられる攻撃の種類をまとめていきます。"" msgid ""Multi-factor authentication"" msgstr ""多要素認証"" msgid """" ""Multi-factor authentication: The authentication service requires the user to "" ""provide information based on something they have, such as a one-time "" ""password token or X.509 certificate, and something they know, such as a "" ""password."" msgstr """" ""多要素認証: 認証サービスが、ユーザーが持っているもの (例: ワンタイムパスワー"" ""ドトークン、X.509 証明書) と知っていること (例: パスワード) に基づいた情報を"" ""提示するよう要求します。"" msgid ""Multi-host DHCP-agent"" msgstr ""マルチホスト DHCP エージェント"" msgid ""MySQL Pluggable Authentication"" msgstr ""MySQL Pluggable Authentication"" msgid ""MySQL SSL configuration"" msgstr ""MySQL SSL 設定"" msgid """" ""MySQL has a large community, widespread adoption, and provides high "" ""availability options. MySQL also has the ability to provide enhanced client "" ""authentication by way of plug-in authentication mechanisms. Forked "" ""distributions in the MySQL community provide many options for consideration. "" ""It is important to choose a specific implementation of MySQL based on a "" ""thorough evaluation of the security posture and the level of support "" ""provided for the given distribution."" msgstr """" ""MySQL は大規模なコミュニティを持ち、幅広く適用され、高可用性のオプションを提"" ""供しています。MySQL も、プラグイン認証機構の方法により高度なクライアント認証"" ""を提供する機能があります。MySQL コミュニティから派生したディストリビューショ"" ""ンは、考慮事項に対する多くのオプションを提供しています。セキュリティの考え方"" ""やディストリビューションに提供されるサポートレベルの評価に基づいて、特定の "" ""MySQL ディストリビューションを選択することが重要です。"" msgid ""MySQL:"" msgstr ""MySQL:"" msgid """" ""NIST defines a community cloud as one whose infrastructure is provisioned "" ""for the exclusive use by a specific community of consumers from "" ""organizations that have shared concerns. For example, mission, security "" ""requirements, policy, and compliance considerations. It may be owned, "" ""managed, and operated by one or more of the organizations in the community, "" ""a third-party, or some combination of them, and it may exist on or off "" ""premises."" msgstr """" ""NIST では、コミュニティクラウドを、共通の関心事 (例えば、任務、セキュリティの"" ""必要、ポリシー、法令順守に関わる考慮事項 ) を持つ複数の組織から成る特定の利用"" ""者の共同体の専用使用のために提供されるクラウドと定義しています。コミュニティ"" ""クラウドの所有、管理、および運用は、共同体内の 1 つまたは複数の組織、第三者、"" ""もしくはそれらの組み合わせにより行われ、存在場所はその組織の施設内または外部"" ""の場合があります。""msgid ""NOVA_DBPASS"" msgstr ""NOVA_DBPASS"" msgid ""Namespaces"" msgstr ""名前空間"" msgid """" ""Nathanael Burton is a Computer Scientist at the National Security Agency. He "" ""has worked for the Agency for over 10 years working on distributed systems, "" ""large-scale hosting, open source initiatives, operating systems, security, "" ""storage, and virtualization technology. He has a B.S. in Computer Science "" ""from Virginia Tech."" msgstr """" ""Nathanael Burton は National Security Agency のコンピューターサイエンティスト"" ""です。Agency に 10 年以上勤務し、分散システム、大規模ホスティング、オープン"" ""ソースイニシアティブ、オペレーティングシステム、セキュリティ、ストレージ、仮"" ""想化技術に携わっています。Virginia Tech でコンピューターサイエンスの B.S. を"" ""取得しました。"" msgid ""National Security Agency, Suite B Cryptography"" msgstr ""国家安全保障局、Suite B 暗号化"" msgid ""Network connectivity of physical servers"" msgstr ""物理サーバのネットワーク接続性"" msgid ""Network data"" msgstr ""ネットワークデータ"" msgid """" ""Network intrusion detection tools complement the host-based tools. OpenStack "" ""doesn't have a specific network IDS built-in, but OpenStack Networking "" ""provides a plug-in mechanism to enable different technologies through the "" ""Networking API. This plug-in architecture will allow tenants to develop API "" ""extensions to insert and configure their own advanced networking services "" ""like a firewall, an intrusion detection system, or a VPN between the VMs."" msgstr """" ""ネットワーク侵入検知ツールは、ホストベースのツールを補完します。OpenStack に"" ""は、特定のネットワーク IDS は組み込まれていませんが、OpenStack Networking "" ""は、Networking API を使用して異なるテクノロジーを有効にするプラグインメカニズ"" ""ムを提供しています。このプラグインのアーキテクチャーにより、テナントは API 拡"" ""張機能を開発して、ファイアウォール、侵入検知システム、仮想マシン間の VPN など"" ""の独自の高度なネットワークサービスを挿入/設定することができます。"" msgid """" ""Network namespaces are highly recommended for all services running on "" ""OpenStack Compute Hypervisors. This will help prevent against the bridging "" ""of network traffic between VM guests and the management network."" msgstr """" ""ネットワーク名前空間の設定は、OpenStack コンピュートハイパーバイザを動作させ"" ""る全てのサービスで強く推奨します。ネットワーク名前空間を用いることで、VM ゲス"" ""トと管理ネットワークのトラフィックがブリッジングされることを防ぎます。"" msgid ""Network policy"" msgstr ""ネットワークポリシー"" msgid ""Network services"" msgstr ""ネットワークサービス"" msgid ""Network services extensions"" msgstr ""ネットワークサービス拡張"" msgid ""Network topology"" msgstr ""ネットワークトポロジー""msgid ""Network virtualization"" msgstr ""ネットワーク仮想化"" msgid ""Networking"" msgstr ""ネットワーク"" msgid ""Networking API endpoints"" msgstr ""Networking APIエンドポイント"" msgid ""Networking architecture"" msgstr ""Networking アーキテクチャ"" msgid ""Networking resource policy engine"" msgstr ""Networking リソースポリシーエンジン"" msgid ""Networking services""msgid ""Networking services security best practices"" msgstr ""Networking サービス セキュリティベストプラクティス"" msgid ""Never allow the wild card origin."" msgstr ""ワイルドカードオリジンを許可してはいけません。""""Never configure CSRF or session cookies to have a wild card domain with a "" ""leading dot. Horizon's session and CSRF cookie should be secured when "" ""deployed with HTTPS:""""ドットから始まるワイルドカードドメインを持つよう、CSRF やセッションクッキーを"" ""設定してはいけません。Horizon のセッションクッキーと CSRF クッキーは HTTPS を"" ""使用した環境のときにセキュア化すべきです。"" msgid ""Never eXecute (NX)"" msgstr ""Never eXecute (NX)""""No MD5. MD5 is not collision resistant, and thus not acceptable for Message "" ""Authentication Codes (MAC) or signatures.""""MD5 使用不可。MD5 は衝突耐性がないため、メッセージ認証コード (MAC) や署名に利"" ""用できません。"" msgid ""Node hardening"" msgstr ""ノードのセキュリティ強化機能"" msgid ""Node provisioning"" msgstr ""ノードのプロビジョニング""""Nodes should use Preboot eXecution Environment (PXE) for provisioning. This "" ""significantly reduces the effort required for redeploying nodes. The typical "" ""process involves the node receiving various boot stagesthat is progressively "" ""more complex software to execute from a server."" msgstr """" ""ノードは、プロビジョニングに Preboot eXecution Environment (PXE) を使用すべき"" ""です。これにより、ノードの再デプロイに必要な作業が大幅に軽減されます。標準的"" ""なプロセスでは、ノードがサーバーからさまざまなブート段階 (実行するソフトウェ"" ""アが徐々に複雑化) を受信する必要があります。"" msgid """" ""Non-kernel TSF software and data are protected by DAC and process isolation "" ""mechanisms. In the evaluated configuration, the reserved user ID root owns "" ""the directories and files that define the TSF configuration. In general, "" ""files and directories containing internal TSF data, such as configuration "" ""files and batch job queues, are also protected from reading by DAC "" ""permissions."" msgstr """" ""非カーネル TSF ソフトウェアとデータが DAC とプロセス分離機構により保護されま"" ""す。評価済みの設定で、予約済みユーザー ID root は TSF 設定を定義するディレク"" ""トリとファイルを所有します。一般的に、設定ファイルやバッチジョブのキューのよ"" ""うな、内部 TSF データを含むファイルとディレクトリも、DAC パーミッションにより"" ""読み取りから保護されます。"" msgid """" ""Note the <emphasis role=\""bold\"">default</emphasis> rule specifies that the "" ""user must be either an admin or the owner of the volume. It essentially says "" ""only the owner of a volume or the admin may create/delete/update volumes. "" ""Certain other operations such as managing volume types are accessible only "" ""to admin users."" msgstr """" ""<emphasis role=\""bold\"">デフォルト</emphasis>のルールは、ユーザーが管理者であ"" ""るか、ボリュームの所有者である必要があることを指定しています。つまり、ボ"" ""リュームの所有者と管理者のみがボリュームを作成、削除、更新できます。ボリュー"" ""ム形式の管理など、他の特定の操作は管理ユーザーのみがアクセス可能です。"" msgid """" ""Note this command only adds the ability to communicate over SSL and is non-"" ""exclusive. Other access methods that may allow unencrypted transport should "" ""be disabled so that SSL is the sole access method."" msgstr """" ""このコマンドは SSL 経由で通信する機能を追加するのみであり、排他的ではないこと"" ""に注意してください。SSL を唯一のアクセス方法にするために、暗号化されていない"" ""通信を許可するかもしれない他のアクセス方法は無効化されるべきです。"" msgid """" ""Note, as <systemitem class=\""service\"">nova-conductor</systemitem> only "" ""applies to OpenStack Compute, direct database access from compute hosts may "" ""still be necessary for the operation of other OpenStack components such as "" ""Telemetry (ceilometer), Networking, and Block Storage."" msgstr """" ""<systemitem class=\""service\"">nova-conductor</systemitem> は OpenStack "" ""Compute のみに適用されるので、Telemetry (ceilometer)、Networking、Block "" ""Storage のような他の OpenStack コンポーネントの動作のために、コンピュートホス"" ""トから直接データベースにアクセスする必要があるかもしれないことに注意してくだ"" ""さい。"" msgid """" ""Note, the <literal>tcp_listeners</literal> option is set to <literal>[]</"" ""literal> to prevent it from listening an on non-SSL port. The "" ""<literal>ssl_listeners</literal> option should be restricted to only listen "" ""on the management network for the services."" msgstr """" ""<literal>tcp_listeners</literal> オプションを <literal>[]</literal> に指定"" ""し、非 SSL ポートの接続を受け付けない設定にしていることに注意してください。 "" ""<literal>ssl_listeners</literal> オプションはサービスの管理ネットワークのみ受"" ""け付けるよう限定すべきです。"" msgid ""Note: SHA-1 is used here because this is what the TPM chips support."" msgstr ""注記: ここで SHA-1 を使用するのは、TPM チップが対応しているためです。"" msgid ""Nova-conductor"" msgstr ""Nova-conductor"" msgid """" ""Nova-conductor receives requests over RPC and performs actions on behalf of "" ""the calling service without granting granular access to the database, its "" ""tables, or data within. Nova-conductor essentially abstracts direct database "" ""access away from compute nodes."" msgstr """" ""Nova-conductor は RPC 経由でリクエストを受信します。そして、データベース、"" ""テーブル、データへの精細なアクセス権なしでサービスを呼び出す動作を実行しま"" ""す。Nova-conductor は本質的にコンピュートノードがデータベースに直接アクセスす"" ""ることを抽象化します。"" msgid ""Number of hours running instances or storing data"" msgstr ""実行中のインスタンス又は保存されたデータの経過時間"" msgid """" ""Number or size of running instances, buckets, objects, volumes, and other "" ""quota-related items"" msgstr """" ""実行中のインスタンスのサイズ、バケット、オブジェクト、ボリューム、その他"" ""クォータ関連の項目"" msgid """" ""Numerous OpenStack services maintain data and metadata belonging to tenants "" ""or reference tenant information."" msgstr """" ""多数の OpenStack サービス群は、テナントやテナント情報の所在に属するデータとメ"" ""タデータを管理します。"" msgid ""OSSEC"" msgstr ""OSSEC"" msgid ""OWASP Guide to Cryptography"" msgstr ""OWASP Guide to Cryptography"" msgid ""OWASP MySQL Hardening"" msgstr ""OWASP MySQL Hardening"" msgid ""OWASP PostgreSQL Hardening"" msgstr ""OWASP PostgreSQL Hardening"" msgid ""OWASP Transport Layer Protection Cheat Sheet"" msgstr ""OWASP Transport Layer Protection Cheat Sheet"" msgid ""Object Reuse"" msgstr ""オブジェクト再利用"" msgid ""Object Storage"" msgstr ""Object Storage"" msgid ""Object Storage network architecture with a management node (OSAM)"" msgstr """" ""マネジメントノードを持つオブジェクトストレージネットワークアーキテクチャー "" ""(OSAM: Object storage network architecture with a management node)"" msgid ""Object Storage objects"" msgstr ""Object Storage オブジェクト"" msgid """" ""Object security should focus on access control and encryption of data in "" ""transit and at rest. Other concerns may relate to system abuse, illegal or "" ""malicious content storage, and cross authentication attack vectors."" msgstr """" ""オブジェクトのセキュリティは、アクセス制御と、伝送中および静止中のデータの暗"" ""号化に重点を置くべきです。その他の懸念事項には、システムの悪用、不法または悪"" ""意のあるコンテンツの保管、クロス認証の攻撃ベクトルなどに関する問題があげられ"" ""ます。"" msgid ""Object service"" msgstr ""オブジェクトサービス"" msgid ""Objectives"" msgstr ""本書の目的"" msgid """" ""Often overlooked is the need for key management for SSH hosts. As most or "" ""all hosts in an OpenStack deployment will provide an SSH service, it is "" ""important to have confidence in connections to these hosts. It cannot be "" ""understated that failing to provide a reasonably secure and accessible "" ""method to verify SSH host key fingerprints is ripe for abuse and "" ""exploitation."" msgstr """" ""頻繁に見逃されるのが SSH ホストのキー管理の必要性です。OpenStack デプロイメン"" ""トホストのすべてまたは多くが SSH サービスを提供します。このようなホストへの接"" ""続の信頼性を確保することが重要です。SSH ホストキーのフィンガープリントの検証"" ""に関して比較的セキュアでアクセス可能なメソッドを提供できないと、悪用やエクス"" ""プロイトの温床となるといっても過言ではありません。"" msgid """" ""Often, data encryption relates positively to the ability to reliably destroy "" ""tenant and per-instance data, simply by throwing away the keys. It should be "" ""noted that in doing so, it becomes of great importance to destroy those keys "" ""in a reliable and secure manner."" msgstr """" ""時々、データ暗号化は単に暗号鍵を捨てるという事による、信頼できるテナントやイ"" ""ンスタンス単位のデータ削除可能性と明確に関係があります。そうするよう記述すべ"" ""きですし、信頼できる安全な方法でこれらの鍵を破壊する事が従来になります。"" msgid """" ""On the RabbitMQ server, delete the default <literal>guest</literal> user:"" msgstr """" ""RabbitMQ サーバで、デフォルトの <literal>guest</literal> ユーザを削除します。"" msgid """" ""On the RabbitMQ server, for each OpenStack service or node that communicates "" ""with the message queue set up user accounts and privileges:"" msgstr """" ""RabbitMQ サーバにて、メッセージキューを使用する各 OpenStack サービス、また"" ""は、ノード毎にユーザアカウントと権限を設定します。"" msgid """" ""Once a cloud is deployed, it is time for an internal audit. This is the time "" ""compare the controls you identified above with the design, features, and "" ""deployment strategies utilized in your cloud. The goal is to understand how "" ""each control is handled and where gaps exist. Document all of the findings "" ""for future reference."" msgstr """" ""クラウドが導入されたのであれば、内部監査が必要です。あなたが採用を決めた統制"" ""基準と、あなたのクラウドの設計、機能、配備戦略を比較する時です。目的はそれぞ"" ""れの統制がどのように扱われているか、ギャップがどこに存在するか、理解すること"" ""です。そして、その全てを将来のために文書化します。"" msgid """" ""Once the internal audit results look good, it is time to prepare for an "" ""external audit. There are several key actions to take at this stage, these "" ""are outlined below:"" msgstr """" ""内部監査の結果が良好であれば、いよいよ外部監査の準備です。この段階では、いく"" ""つかの鍵となる活動があります。概要は以下です。"" msgid """" ""Once the node is running, we need to ensure that it remains in a good state "" ""over time. Broadly speaking, this includes both configuration management and "" ""security monitoring. The goals for each of these areas are different. By "" ""checking both, we achieve higher assurance that the system is operating as "" ""desired. We discuss configuration management in the management section, and "" ""security monitoring below."" msgstr """" ""ノードが稼働したら、長時間にわたって良好な状態で稼働を継続するように確保する"" ""必要があります。大まかに言うと、これには設定管理とセキュリティ監視が含まれま"" ""す。これらの各領域の目標は異なります。両方を確認することにより、システムが希"" ""望通りに稼働していることをより確実に保証します。設定管理については、管理のセ"" ""クションおよび次のセキュリティ監視で説明します。"" msgid """" ""Once the updates are fully tested, they can be deployed to the production "" ""environment. This deployment should be fully automated using the "" ""configuration management tools described below."" msgstr """" ""更新の完全なテストが終了すると、実稼働環境にデプロイすることができます。この"" ""デプロイメントは、以下に記載の構成管理ツールで完全に自動的に行われます。"" msgid """" ""One additional consideration when selecting a hypervisor is the availability "" ""of various formal certifications and attestations. While they may not be "" ""requirements for your specific organization, these certifications and "" ""attestations speak to the maturity, production readiness, and thoroughness "" ""of the testing a particular hypervisor platform has been subjected to."" msgstr """" ""ハイパーバイザーを選択する際にもう１つ考慮すべき点は、様々な公式の認証や証明"" ""書が利用可能かという事です。あなたの特定の組織の要件ではないかも知れません"" ""が、これらの認証や証明書は、成熟度、商利用可能、特定のハイパーバイザーが目標"" ""としてきたテストの徹底さを物語ります。"" msgid ""One as a \""public\"" interface for consumers to reach"" msgstr ""利用者が到達できる「パブリック」インターフェースとして一つ"" msgid """" ""One critical policy decision for a cloud architect is what to do with the "" ""output from a security monitoring tool. There are effectively two options. "" ""The first is to alert a human to investigate and/or take corrective action. "" ""This could be done by including the security alert in a log or events feed "" ""for cloud administrators. The second option is to have the cloud take some "" ""form of remedial action automatically, in addition to logging the event. "" ""Remedial actions could include anything from re-installing a node to "" ""performing a minor service configuration. However, automated remedial action "" ""can be challenging due to the possibility of false positives."" msgstr """" ""セキュリティ監視ツールの出力の処理方法は、クラウドアーキテクトにとっての重要"" ""なポリシー決定の一つです。オプションは実質的に 2 つあります。第 1 のオプショ"" ""ンは、問題を調査して修正措置を取るように、人間に警告を発する方法です。これ"" ""は、クラウド管理者向けのログまたはイベントのフィードにセキュリティ警告を組み"" ""込むことによって可能となります。第 2 のオプションは、イベントのログ記録に加え"" ""て、クラウドが何らかの形の修復措置を自動的に実行するように設定する方法です。"" ""修復措置にはノードの再インストールから、マイナーなサービス設定の実行まで含め"" ""ることができます。ただし、自動修復措置は、誤検知の可能性があるため、困難とな"" ""る場合があります。"" msgid """" ""One decision a cloud architect will need to make regarding Compute service "" ""configuration is whether to use <glossterm baseform=\""Virtual Network "" ""Computing (VNC)\"">VNC</glossterm> or <glossterm>SPICE</glossterm>. Below we "" ""provide some details on the differences between these options."" msgstr """" ""クラウドアーキテクトが判断する必要があることの一つは、Compute Service の設定"" ""が <glossterm baseform=\""Virtual Network Computing (VNC)\"">VNC</glossterm> "" ""と <glossterm>SPICE</glossterm> のどちらを使用するかです。以下は、これらの選"" ""択肢の違いに関する詳細を提供します。"" msgid """" ""One of the biggest indicators of a hypervisor's maturity is the size and "" ""vibrancy of the community that surrounds it. As this concerns security, the "" ""quality of the community affects the availability of expertise if you need "" ""additional cloud operators. It is also a sign of how widely deployed the "" ""hypervisor is, in turn leading to the battle readiness of any reference "" ""architectures and best practices."" msgstr """" ""ハイパーバイザーの完成度の最大の指標の１つに、それを取り巻くコミュニティのサ"" ""イズと活気があります。これはセキュリティに関するので、コミュニティの質はあな"" ""たが追加のクラウドオペレーターを必要とする、利用可能なノウハウに影響します。"" ""これはまた、ハイパーバイザーがいかに広く開発されているかの印でもあり、同様"" ""に、リファレンスアーキテクチャやベストプラクティスの戦闘準備につながるので"" ""す。"" msgid """" ""One of the virtues of running instances in a virtualized environment is that "" ""it opens up new opportunities for security controls that are not typically "" ""available when deploying onto bare metal. There are several technologies "" ""that can be applied to the virtualization stack that bring improved "" ""information assurance for cloud tenants."" msgstr """" ""仮想環境でインスタンスを運用する長所の一つは、ベアメタルで配備した際には利用"" ""できないセキュリティ管理方法の選択肢が増えることです。仮想スタック上のクラウ"" ""ドテナントの情報管理を改善する技術は多数存在します。"" msgid """" ""Only the minimum level of access for users and system services is granted. "" ""This access is based upon role, responsibility and job function. This "" ""security principal of least privilege is written into several international "" ""government security policies, such as NIST 800-53 Section AC-6 within the "" ""United States."" msgstr """" ""ユーザーとシステムサービスには最小限のアクセス権限のみを付与すべきです。アク"" ""セス権限は役割、責任と職務にもとづきます。この最小権限原則は、いくつかの国際"" ""セキュリティポリシーに明記されています。たとえば米国のNIST 800-53 AC-6項が挙"" ""げられます。"" msgid ""OpenSSL and FIPS 140-2"" msgstr ""OpenSSL and FIPS 140-2"" msgid ""OpenStack"" msgstr ""OpenStack"" msgid ""OpenStack API"" msgstr ""OpenStack API"" msgid """" ""OpenStack Compute offers a sub-service called <systemitem class=\""service"" ""\"">nova-conductor</systemitem> which proxies database connections, with the "" ""primary purpose of having the nova compute nodes interfacing with "" ""<systemitem class=\""service\"">nova-conductor</systemitem> to meet data "" ""persistence needs as opposed to directly communicating with the database."" msgstr """" ""OpenStack Compute は <systemitem class=\""service\"">nova-conductor</"" ""systemitem> というサブサービスを提供します。これは、<systemitem class="" ""\""service\"">nova-conductor</systemitem> と直接接する nova コンピュートノード"" ""がデータ永続性の要求を満たすことを主目的として、それらがデータベースと直接通"" ""信する代わりにデータベース接続を中継します。"" msgid """" ""OpenStack Compute supports tenant network traffic access controls directly "" ""when deployed with the legacy nova-network service, or may defer access "" ""control to the OpenStack Networking service."" msgstr """" ""OpenStack Compute は、旧式の nova-network サービスでデプロイする場合、テナン"" ""トネットワーク通信のアクセス制御を直接サポートします。又は、OpenStack "" ""Networking サービスにアクセス制御を任せる事も出来ます。"" msgid ""OpenStack Foundation"" msgstr ""OpenStack Foundation"" msgid ""OpenStack Identity: Management"" msgstr ""OpenStack Identity: 管理"" msgid """" ""OpenStack Networking allows cloud tenants to manage their guest network "" ""configurations. Security concerns with the networking service include "" ""network traffic isolation, availability, integrity and confidentiality."" msgstr """" ""OpenStack Networking により、クラウドテナントはゲストのネットワーク設定を管理"" ""することができます。ネットワークサービスに伴うセキュリティ上の問題には、 ネッ"" ""トワークトラフィックの隔離、可用性、完全性、機密性などがあげられます。"" msgid """" ""OpenStack Networking also supports per-tenant quotas limit through a quota "" ""extension API. To enable per-tenant quotas, you must set the "" ""<literal>quota_driver</literal> option in <filename>neutron.conf</filename>."" msgstr """" ""OpenStack Networking はまた、クォータ拡張 API 経由で、テナント単位のクォータ"" ""をサポートしています。テナント単位クォータを有効にするためには、"" ""<filename>neutron.conf</filename> 中の <literal>quota_driver</literal> を設定"" ""する必要があります。"" msgid """" ""OpenStack Networking enables the end-user or tenant to define, utilize, and "" ""consume networking resources. OpenStack Networking provides a tenant-facing "" ""API for defining network connectivity and IP addressing for instances in the "" ""cloud in addition to orchestrating the network configuration. With the "" ""transition to an API-centric networking service, cloud architects and "" ""administrators should take into consideration best practices to secure "" ""physical and virtual network infrastructure and services."" msgstr """" ""OpenStack Networking により、エンドユーザーまたはテナントは、ネットワークリ"" ""ソースを定義、利用、消費することが可能です。OpenStack Networking は、ネット"" ""ワーク設定のオーケストレーションに加えて、クラウド内のインスタンスを対象とし"" ""たネットワーク接続の定義と IP アドレス指定用の対テナント API を提供します。"" ""API 中心のネットワークサービスへの移行にあたっては、クラウドのアーキテクトや"" ""管理者が、物理/仮想ネットワークのインフラストラクチャーとサービスをセキュリ"" ""ティ保護するためのベストプラクティスを考慮すべきです。"" msgid ""OpenStack Networking has the following known limitations:"" msgstr ""OpenStack Networking は以下の制限があります。"" msgid """" ""OpenStack Networking is a standalone service that often deploys several "" ""processes across a number of nodes. These processes interact with each other "" ""and other OpenStack services. The main process of the OpenStack Networking "" ""service is <systemitem class=\""service\"">neutron-server</systemitem>, a "" ""Python daemon that exposes the OpenStack Networking API and passes tenant "" ""requests to a suite of plug-ins for additional processing."" msgstr """" ""OpenStack Networking は多数ノード間において幾つかのプロセスのデプロイにしばし"" ""ば含まれる独立サービスです。OpenStack Networking サービスのメインプロセスは "" ""<systemitem class=\""service\"">neutron-server</systemitem> で、これは "" ""OpenStack Networking API を提供し、追加処理用の適切なプラグインにテナントのリ"" ""クエストを渡します。"" msgid """" ""OpenStack Networking routers can connect multiple L2 networks, and can also "" ""provide a <emphasis>gateway</emphasis> that connects one or more private L2 "" ""networks to a shared <emphasis>external</emphasis> network, such as a public "" ""network for access to the Internet."" msgstr """" ""OpenStack Networking のルータは複数の L2 ネットワークを接続でき、１つ以上のプ"" ""ライベート L2 ネットワークを共有<emphasis>外部</emphasis>ネットワーク（イン"" ""ターネットアクセス用のパブリックネットワーク等）に接続する<emphasis>ゲート"" ""ウェイ</emphasis>を提供する事も出来ます。"" msgid ""OpenStack Networking service configuration"" msgstr ""OpenStack Networking サービス設定"" msgid ""OpenStack Networking service placement on physical servers"" msgstr ""OpenStack Networking の配置と物理サービス"" msgid """" ""OpenStack Networking supports multiple L3 and DHCP agents with load "" ""balancing. However, tight coupling of the location of the virtual machine is "" ""not supported."" msgstr """" ""OpenStack Networking は複数の L3 エージェントと DHCP エージェントによる負荷分"" ""散をサポートしています。しかしながら、（訳注：nova-network がサポートしてい"" ""た）仮想マシンとの配置上の強い紐付けはサポートされていません。"" msgid """" ""OpenStack Networking was designed with a plug-in architecture that provides "" ""extensibility of the API through open source community or third-party "" ""services. As you evaluate your architectural design requirements, it is "" ""important to determine what features are available in OpenStack Networking "" ""core services, any additional services that are provided by third-party "" ""products, and what supplemental services are required to be implemented in "" ""the physical infrastructure."" msgstr """" ""OpenStack Networking は、オープンソースコミュニティやサードパーティーのサービ"" ""スによる API の拡張性を提供するプラグインアーキテクチャーで設計されました。"" ""アーキテクチャーの設計要件を評価するにあたっては、OpenStack Networking のコア"" ""サービスではどのような機能が提供されているか、サードパーティの製品によって提"" ""供される追加のサービスがあるかどうか、物理インフラストラクチャーにはどのよう"" ""な補足サービスを実装する必要があるかを判断することが重要です。"" msgid ""OpenStack Object Storage containers"" msgstr ""OpenStack Object Storage コンテナー"" msgid ""OpenStack Object Storage objects"" msgstr ""OpenStack Object Storage オブジェクト"" msgid """" ""OpenStack Security Advisories (OSSA) are created by the OpenStack "" ""Vulnerability Management Team (VMT). They pertain to security holes in core "" ""OpenStack services. More information on the VMT can be found here: <link "" ""href=\""https://wiki.openstack.org/wiki/Vulnerability_Management\"">https://"" ""wiki.openstack.org/wiki/Vulnerability_Management</link>"" msgstr """" ""OpenStack セキュリティアドバイザリ (OSSA: OpenStack Security Advisories) は、"" ""OpenStack 脆弱性管理チーム (VMT: Vulnerability Management Team) が作成してい"" ""ます。コアとなる OpenStack サービスのセキュリティホールに関連するものです。"" ""VMT に関する詳細情報は、<link href=\""https://wiki.openstack.org/wiki/"" ""Vulnerability_Management\"">https://wiki.openstack.org/wiki/"" ""Vulnerability_Management</link> を参照してください。"" msgid ""OpenStack Security Guide"" msgstr ""OpenStack セキュリティガイド"" msgid """" ""OpenStack architects interpret and respond to HIPAA statements, with data "" ""encryption remaining a core practice. Currently this would require any "" ""protected health information contained within an OpenStack deployment to be "" ""encrypted with industry standard encryption algorithms. Potential future "" ""OpenStack projects such as object encryption will facilitate HIPAA "" ""guidelines for compliance with the act."" msgstr """" ""OpenStackアーキテクトはHIPAAの条項を解釈し、対応します。データ暗号化はその中"" ""核となる活動です。現在、OpenStack環境に保存される、いかなる保護カルテ情報にも"" ""暗号化を要求され、業界標準の暗号化アルゴリズムの採用が期待されます。なお、将"" ""来予定されている、例えばオブジェクト暗号化などのOpenStackプロジェクトは、法令"" ""遵守のためHPAAガイドラインの適用を促進するでしょう。"" msgid """" ""OpenStack can be configured to provide remote desktop console access to "" ""instances for tenants and/or administrators using the Virtual Network "" ""Computer (VNC) protocol."" msgstr """" ""OpenStack は Virtual Network Computer (VNC) プロトコルを使用して、プロジェク"" ""トと管理者がインスタンスのリモートデスクトップコンソールにアクセスできるよう"" ""に設定できます。"" msgid ""OpenStack compute node: Management and guest"" msgstr ""OpenStack Compute ノード: 管理、ゲスト"" msgid ""OpenStack dashboard (horizon)"" msgstr ""OpenStack dashboard (horizon)"" msgid ""OpenStack dashboard: Public and management"" msgstr ""OpenStack Dashboard: パブリック、管理"" msgid ""OpenStack database access model"" msgstr ""OpenStack データベースアクセスモデル"" msgid """" ""OpenStack deployments which stores, processes, or transmits payment card "" ""details are in scope for the PCI-DSS. All OpenStack components that are not "" ""properly segmented from systems or networks that handle payment data fall "" ""under the guidelines of the PCI-DSS. Segmentation in the context of PCI-DSS "" ""does not support multi-tenancy, but rather physical separation (host/"" ""network)."" msgstr """" ""カード情報を保存、処理、転送するOpenStack環境は、PCI-DSSの対象です。カード情"" ""報を扱うシステムやネットワークが正しく分離されていないすべてのOpenStackコン"" ""ポーネントは、PCI-DSSのガイドラインに適合しません。PCI-DSSでいう分離は、マル"" ""チ手ナンシーを認めておらず、(サーバーおよびネットワークの)物理的な分離が必要"" ""です。"" msgid """" ""OpenStack does not support message-level confidence, such as message "" ""signing. Consequently, you must secure and authenticate the message "" ""transport itself. For high-availability (HA) configurations, you must "" ""perform queue-to-queue authentication and encryption."" msgstr """" ""OpenStack は、メッセージへの署名のようなメッセージレベルのコンフィデンスはサ"" ""ポートしていません。そのため、メッセージの通信路そのものがセキュア化され、か"" ""つ、キューサーバーへのアクセスの際に認証が行なわれる必要があります。\n"" ""また、HA 設定の際には、キュー間の認証と暗号化も同様に実施するべきです。"" msgid """" ""OpenStack embraces a modular architecture to provide a set of core services "" ""that facilitates scalability and elasticity as core design tenets. This "" ""chapter briefly reviews OpenStack components, their use cases and security "" ""considerations."" msgstr """" ""OpenStack は、モジュール型アーキテクチャを採用し、中核的な設計理念としてス"" ""ケーラビリティと柔軟性を促進する一式のコアサービスを提供します。本章では、"" ""OpenStack のコンポーネントとそれらのユースケースおよびセキュリティに関する考"" ""慮事項を簡単に説明します。"" msgid """" ""OpenStack is a key enabler in adoption of cloud technology and has several "" ""common deployment use cases. These are commonly known as Public, Private, "" ""and Hybrid models. The following sections use the National Institute of "" ""Standards and Technology (NIST) <link href=\""http://csrc.nist.gov/"" ""publications/nistpubs/800-145/SP800-145.pdf\"">definition of cloud</link> to "" ""introduce these different types of cloud as they apply to OpenStack."" msgstr """" ""OpenStack は、クラウドテクノロジーの導入における重要なイネーブラーであり、一"" ""般的なデプロイメントユースケースがいくつかあります。これらは、パブリック、プ"" ""ライベート、およびハイブリッドモデルとして一般に知られています。以下のセク"" ""ションでは、National Institute of Standards and Technology (NIST) <link href="" ""\""http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\""> のクラ"" ""ウドの定義</link> を取り上げ、OpenStack に適用するクラウドの異なるタイプにつ"" ""いて説明します。"" msgid """" ""OpenStack management relies on out-of-band management interfaces such as the "" ""IPMI protocol to access into nodes running OpenStack components. IPMI is a "" ""very popular specification to remotely manage, diagnose, and reboot servers "" ""whether the operating system is running or the system has crashed."" msgstr """" ""OpenStack コンポーネントを実行するノードにアクセスする場合、OpenStack の管理"" ""は IPMI プロトコルなどのアウトオブバンド管理インターフェースに依存します。"" ""IPMI は非常に有名な仕様で、オペレーティングシステムが実行中である場合やシステ"" ""ムがクラッシュした場合でもリモートでのサーバー管理、診断、リブートを行えま"" ""す。"" msgid """" ""OpenStack management utilities such as <systemitem class=\""service\"">nova-"" ""manage</systemitem> and <systemitem class=\""service\"">glance-manage</"" ""systemitem>"" msgstr """" ""<systemitem class=\""service\"">nova-manage</systemitem>、<systemitem class="" ""\""service\"">glance-manage</systemitem> などの OpenStack 管理ユーティリティ"" msgid """" ""OpenStack network node: Management, guest, and possibly public depending "" ""upon neutron-plugin in use."" msgstr """" ""OpenStack ネットワークノード: 管理、ゲスト（使用する neutron プラグインによっ"" ""てはパブリックも可能性あり）"" msgid """" ""OpenStack operators should strive to provide a certain level of tenant data "" ""disposal assurance. Best practices suggest that the operator sanitize cloud "" ""system media (digital and non-digital) prior to disposal, release out of "" ""organization control or release for reuse. Sanitization methods should "" ""implement an appropriate level of strength and integrity given the specific "" ""security domain and sensitivity of the information."" msgstr """" ""OpenStack オペレータは、ある一定レベルのテナントデータ破棄保証が提供できるよ"" ""う努力しなければんりません。ベストプラクティスは、クラウドシステムメディア "" ""(デジタル・非デジタル) を破棄、組織コントロール外へのリリース、再利用の為の開"" ""放より前にオペレータがメディアをクリアする事を推奨しています。メディアのクリ"" ""ア方法は、特定のセキュリティドメインと情報のデリケートさが与えられた、適切な"" ""レベルの強度と完全性を実装すべきです。"" msgid """" ""OpenStack provides both public facing and private API endpoints. By default, "" ""OpenStack components use the publicly defined endpoints. The recommendation "" ""is to configure these components to use the API endpoint within the proper "" ""security domain."" msgstr """" ""OpenStackはパブリックとプライベート両方のAPIエンドポイントを提供します。デ"" ""フォルトではOpenStackコンポーネントはパブリックとして定義されたエンドポイント"" ""を使用します。推奨はこれらのコンポーネントを適切なセキュリティドメイン内で使"" ""用するよう構成することです。"" msgid """" ""OpenStack provides several management interfaces for operators and tenants:"" msgstr """" ""OpenStack は、オペレーターやプロジェクト向けに複数の管理インターフェースを提"" ""供しています。"" msgid """" ""OpenStack releases security information through two channels. <placeholder-1/"" "">"" msgstr """" ""OpenStack は 2 つのチャネルからセキュリティ情報を発信しています。 "" ""<placeholder-1/>"" msgid ""OpenStack service configuration: Qpid"" msgstr ""OpenStack サービス設定: Qpid"" msgid ""OpenStack service configuration: RabbitMQ"" msgstr ""OpenStack サービス設定: RabbitMQ"" msgid ""OpenStack service database configuration"" msgstr ""OpenStack サービスのデータベース設定"" msgid ""OpenStack service overview"" msgstr ""OpenStack サービスの概観"" msgid """" ""OpenStack's sVirt implementation aspires to protect hypervisor hosts and "" ""virtual machines against two primary threat vectors:"" msgstr """" ""OpenStack の sVirt 実装は、2 種類の主要な脅威ベクターに対して、ハイパーバイ"" ""ザーホストと仮想マシンを保護することを目指しています。"" msgid ""Opportunities to encrypt data for users are present:"" msgstr ""ユーザ用のデータ暗号化をする機会は現存します。"" msgid ""Option ROM code"" msgstr ""オプションの ROM コード"" msgid ""Option ROM configuration and data"" msgstr ""オプションの ROM 設定およびデータ"" msgid """" ""Optionally, if using SASL with Qpid specify the SASL mechanisms in use by "" ""adding:"" msgstr """" ""オプションとして Qpid で SASL を使用する場合は、下記のように SASL メカニズム"" ""を指定します。"" msgid """" ""Optionally, if you wish to restrict the set of SSL ciphers used for the "" ""encrypted connection. See <link href=\""http://www.openssl.org/docs/apps/"" ""ciphers.html\"">http://www.openssl.org/docs/apps/ciphers.html</link> for a "" ""list of ciphers and the syntax for specifying the cipher string:"" msgstr """" ""オプションとして、暗号化通信に使用される SSL 暗号を制限したい場合、暗号の一覧"" ""と暗号文字列を設定するための構文は <link href=\""http://www.openssl.org/docs/"" ""apps/ciphers.html\"">http://www.openssl.org/docs/apps/ciphers.html</link> を参"" ""照してください。"" msgid ""Orchestration"" msgstr ""オーケストレーション"" msgid ""Organization name"" msgstr ""組織名"" msgid """" ""Organizations may desire to implement external authentication for "" ""compatibility with existing authentication services or to enforce stronger "" ""authentication policy requirements. Although passwords are the most common "" ""form of authentication, they can be compromised through numerous methods, "" ""including keystroke logging and password compromise. External authentication "" ""services can provide alternative forms of authentication that minimize the "" ""risk from weak passwords."" msgstr """" ""組織は、既存の認証サービスとの互換性のために外部認証を実装したいかもしれませ"" ""ん。または、より強固な認証ポリシー要件を強制するためかもしれません。パスワー"" ""ドが認証のもっとも一般的な形式ですが、キー入力ロギングやパスワード推測など、"" ""さまざまな方法で破られる可能性があります。外部認証サービスにより、弱いパス"" ""ワードのリスクを最小化する他の認証形式を提供できます。"" msgid """" ""Other events that are actionable are networking bridges going down, ip "" ""tables being flushed on compute nodes and consequential loss of access to "" ""instances resulting in unhappy customers."" msgstr """" ""行動可能な他のイベントはネットワークブリッジがダウンした事です。compute ノー"" ""ド上で設定がクリアされた iptables や、インスタンスへのアクセスの重大なロスは"" ""ユーザを不幸にします。"" msgid ""Other notable items"" msgstr ""他の重要事項"" msgid ""Other supporting technology"" msgstr ""その他の支援技術"" msgid """" ""Out of band management interfaces also often include graphical machine "" ""console access. It is often possible, although not necessarily default, that "" ""these interfaces are encrypted. Consult with your system software "" ""documentation for encrypting these interfaces."" msgstr """" ""また、アウトオブバンド管理インターフェースはグラフィカルのコンソールアクセス"" ""が可能な場合が多くあります。デフォルトではない可能性もありますが、これらのイ"" ""ンターフェースは暗号化されていることがあります。これらのインターフェースの暗"" ""号化については、お使いのシステムのソフトウェア文書を確認してください。"" msgid ""Out-of-band management interface"" msgstr ""帯域外管理インターフェース"" msgid ""Out-of-band management interfaces, such as IPMI"" msgstr ""帯域外管理インターフェース (IPMI など)"" msgid ""Outbound attacks and reputational risk"" msgstr ""アウトバウンド攻撃とレピュテーションリスク"" msgid ""Overlapping IP addresses"" msgstr ""IP アドレスの重複"" msgid ""PCI-DSS"" msgstr ""PCI-DSS"" msgid ""PCR-00"" msgstr ""PCR-00"" msgid ""PCR-01"" msgstr ""PCR-01"" msgid ""PCR-02"" msgstr ""PCR-02"" msgid ""PCR-03"" msgstr ""PCR-03"" msgid ""PCR-04"" msgstr ""PCR-04"" msgid ""PCR-05"" msgstr ""PCR-05"" msgid ""PCR-06"" msgstr ""PCR-06"" msgid ""PCR-07"" msgstr ""PCR-07"" msgid ""PCR-08"" msgstr ""PCR-08"" msgid ""PCR-09"" msgstr ""PCR-09"" msgid ""PCR-10 to PCR-23"" msgstr ""PCR-10 から PCR-23"" msgid """" ""Password policy enforcement: Requires user passwords to conform to minimum "" ""standards for length, diversity of characters, expiration, or failed login "" ""attempts."" msgstr """" ""パスワードポリシー強制: ユーザーパスワードが、長さ、文字種の量、有効期限、失"" ""敗試行回数の最低基準を満たしていることを要求します。"" msgid ""Paste and middleware"" msgstr ""Paste と ミドルウェア"" msgid """" ""Periodic access and log reviews are required to ensure authentication, "" ""authorization, and accountability in a service deployment. Specific guidance "" ""for OpenStack on these topics are discussed in-depth in the logging section."" msgstr """" ""定期的なアクセスとログの検査は、認証、認可とサービス配備における責任を明確に"" ""するため、必要です。これらのトピックに関するOpenStack向けのガイダンスは、ロギ"" ""ングの節で詳細に説明します。"" msgid ""Physical hardware (PCI passthrough)"" msgstr ""物理ハードウェア (PCI パススルー)"" msgid ""Physical server issues"" msgstr ""物理サーバーの問題"" msgid ""Pig"" msgstr ""Pig"" msgid """" ""Places values on the stack and verifies their presence to help prevent "" ""buffer overflow attacks."" msgstr """" ""バッファーオーバーフロー攻撃を防ぐ役に立てるために、スタックに値を置き、それ"" ""らの存在を検証します。"" msgid ""Platform specific"" msgstr ""プラットフォーム固有"" msgid ""Platform specific, often Initramfs"" msgstr ""プラットフォーム固有、多くの場合は Initramfs"" msgid ""Platform specific, often kernel, kernel extensions, and drivers"" msgstr """" ""プラットフォーム固有、多くの場合はカーネル、カーネル拡張機能、ドライバー"" msgid ""Policies"" msgstr ""ポリシー"" msgid ""Policy changes"" msgstr ""ポリシーの変更"" msgid ""Port"" msgstr ""ポート"" msgid ""Port mirroring (through open source or third-party plug-ins)"" msgstr ""ポートミラーリング (オープンソースのサードパーティ製プラグイン使用)"" msgid ""Position Independent Executable (PIE)"" msgstr ""Position Independent Executable (PIE)"" msgid ""PostgreSQL SSL configuration"" msgstr ""PostgreSQL SSL 設定"" msgid """" ""PostgreSQL has a number of desirable security features such as Kerberos "" ""authentication, object-level security, and encryption support. The "" ""PostgreSQL community has done well to provide solid guidance, documentation, "" ""and tooling to promote positive security practices."" msgstr """" ""PostgreSQL は、Kerberos 認証、オブジェクトレベルのセキュリティ、暗号化のサ"" ""ポートなど、数多くの望ましいセキュリティ機能を有します。PostgreSQL コミュニ"" ""ティは実用的なセキュリティ実践を推進するために、わかりやすいガイダンス、ド"" ""キュメント、ツールを十分に提供してきました。"" msgid ""PostgreSQL:"" msgstr ""PostgreSQL:"" msgid ""Pound"" msgstr ""Pound"" msgid ""Prepare for external audit"" msgstr ""外部監査に備える"" msgid """" ""Prevention is possible by using an external authentication system that "" ""blocks out an account after some configured number of failed login attempts. "" ""The account then may only be unlocked with further side-channel intervention."" msgstr """" ""ログイン試行を指定した回数だけ失敗すると、アカウントをブロックするような外部"" ""認証システムを使用することにより、防止することができます。アカウントは、別の"" ""連絡手段を介してのみ、ロック解除するようにできます。"" msgid ""Privacy"" msgstr ""プライバシー"" msgid """" ""Privacy is an increasingly important element of a compliance program. "" ""Businesses are being held to a higher standard by their customers, who have "" ""increased interest in understanding how their data is treated from a privacy "" ""perspective."" msgstr """" ""プライバシーはコンプライアンスプログラムの重要な要素になりつつあります。顧客"" ""はプライバシーの観点から、データがいかに扱われているか関心を高めており、デー"" ""タを扱う企業はより高い基準を期待されています。"" msgid ""Private cloud"" msgstr ""プライベートクラウド"" msgid """" ""Private clouds are typically deployed by enterprises or institutions inside "" ""their networks and behind their firewalls. Enterprises will have strict "" ""policies on what data is allowed to exit their network and may even have "" ""different clouds for specific purposes. Users of a private cloud are "" ""typically employees of the organization that owns the cloud and are able to "" ""be held accountable for their actions. Employees often attend training "" ""sessions before accessing the cloud and will likely take part in regular "" ""scheduled security awareness training. Public clouds by contrast cannot make "" ""any assertions about their users, cloud use-cases or user motivations. This "" ""immediately pushes the guest security domain into a completely "" ""<emphasis>untrusted</emphasis> state for public cloud providers."" msgstr """" ""通常プライベートクラウドは企業や組織により、内部のネットワークやファイア"" ""ウォールの内側にデプロイされます。企業は、社内のネットワークから出すことので"" ""きるデータが何であるか、厳密な方針が設定されており、特定の目的ごとに別のクラ"" ""ウドを設定する場合さえもあります。プライベートクラウドのユーザーは通常、クラ"" ""ウドを所有して各自の行動に責任を課される組織内の従業員です。このような従業員"" ""は、クラウドにアクセスする前にトレーニングセッションに出席することもしばしば"" ""あり、定期的に予定されるセキュリティ認識トレーニングに参加する場合も多くあり"" ""ます。反対に、パブリッククラウドはユーザー、クラウドのユースケース、ユーザー"" ""の動機を断定することができません。このように、すぐにゲストのセキュリティドメ"" ""インは、パブリッククラウドプロバイダーにとっては完全に <emphasis>untrusted</"" ""emphasis> な状態となります。"" msgid ""Privilege elevation (1 level)"" msgstr ""権限昇格 (1つのレベル)"" msgid ""Privilege elevation (2 levels)"" msgstr ""権限昇格 (2 つのレベル)"" msgid ""Privilege elevation (3 levels)"" msgstr ""権限昇格 (3 つのレベル)"" msgid ""Privileges"" msgstr ""権限"" msgid """" ""Produces a position independent executable, which is necessary for ASLR."" msgstr ""位置に依存しない実行ファイルを生成します。ASLR のために必要です。"" msgid ""Product or project maturity"" msgstr ""製品やプロジェクトの成熟度"" msgid """" ""Products validated as conforming to FIPS 140-2 are accepted by the Federal "" ""agencies of both countries [United States and Canada] for the protection of "" ""sensitive information (United States) or Designated Information (Canada). "" ""The goal of the CMVP is to promote the use of validated cryptographic "" ""modules and provide Federal agencies with a security metric to use in "" ""procuring equipment containing validated cryptographic modules."" msgstr """" ""FIPS 140-2 への適合性を検証された製品は、機密情報 (アメリカ) や指定情報 (カナ"" ""ダ) の保護のために、両国 (アメリカとカナダ) の連邦機関により受け入れられま"" ""す。CMVP の目標は、検証済み暗号モジュールを含む物品調達で使用するために、検証"" ""済み暗号モジュール利用を推進することと、連邦機関へのセキュリティ評価基準を提"" ""供することです。"" msgid ""Promote privacy"" msgstr ""プライバシー保護の奨励"" msgid ""Protected data transfer"" msgstr ""保護されたデータ転送"" msgid ""Protected data transfer, protection for data at rest"" msgstr ""保護されたデータ転送、保存データの保護"" msgid ""Protection for data at rest, identification and authentication"" msgstr ""保存データの保護、識別と認証"" msgid ""Protection of data at rest"" msgstr ""保存データの保護"" msgid ""Protection of data at rest, protected data transfer"" msgstr ""保存データの保護、保護されたデータ転送"" msgid ""Protocol"" msgstr ""プロトコル"" msgid ""Protocols"" msgstr ""プロトコル"" msgid ""Provide guidance to secure your OpenStack deployment"" msgstr ""OpenStack をセキュア化するガイドの提供"" msgid """" ""Provides DHCP services to tenant networks. This agent is the same across all "" ""plug-ins and is responsible for maintaining DHCP configuration. The "" ""<systemitem class=\""service\"">neutron-dhcp-agent</systemitem> requires "" ""message queue access."" msgstr """" ""テナントネットワークに DHCP サービスを提供します。このエージェントは全てのプ"" ""ラグインと同様で、DHCP 設定の管理を担当します。<systemitem class=\""service"" ""\"">neutron-dhcp-agent</systemitem> はメッセージキューアクセスが必要です。"" msgid """" ""Provides L3/NAT forwarding for external network access of VMs on tenant "" ""networks. Requires message queue access. <emphasis>Optional depending on "" ""plug-in.</emphasis>"" msgstr """" ""テナントネットワーク上の VM において外部ネットワーク用 L3/NAT 転送を提供しま"" ""す。メッセージキューが必要です。<emphasis>プラグイン次第では別の物が必要にな"" ""ります。</emphasis>"" msgid ""Proxy services"" msgstr ""プロキシサービス"" msgid ""Public"" msgstr ""パブリック"" msgid ""Public and private cloud considerations"" msgstr ""パブリッククラウドとプライベートクラウドの考慮点"" msgid ""Public cloud"" msgstr ""パブリッククラウド"" msgid ""Puppet"" msgstr ""Puppet"" msgid ""QPID_PASS"" msgstr ""QPID_PASS"" msgid ""Qpid"" msgstr ""Qpid"" msgid ""Qpid server SSL configuration"" msgstr ""Qpid サーバ SSL 設定"" msgid ""Quality of Service (QoS)"" msgstr ""サービス品質(QoS)"" msgid ""Queue authentication and access control"" msgstr ""キューの認証およびアクセス制御"" msgid """" ""Queue servers should only accept connections from the management network. "" ""This applies to all implementations. This should be implemented through "" ""configuration of services and optionally enforced through global network "" ""policy."" msgstr """" ""キューサーバーは管理ネットワークからの接続のみを受け付けるべきであり、この方"" ""針はあらゆる実装に適用されます。サービスの設定を通して実装し、任意でグローバ"" ""ルネットワークポリシーを追加で実装します。"" msgid ""Quotas"" msgstr ""クォータ"" msgid """" ""Quotas provide the ability to limit the number of network resources "" ""available to tenants. You can enforce default quotas for all tenants. The "" ""<filename>/etc/neutron/neutron.conf</filename> includes these options for "" ""quota:"" msgstr """" ""クォータは、テナントに対して利用可能なネットワークリソース数を制限する機能を"" ""提供します。全てのテナントに対してデフォルトのクォータを強制する事が出来ま"" ""す。<filename>/etc/neutron/neutron.conf</filename> にクォータに関するこれらの"" ""オプションがあります。"" msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" msgid ""RELocation Read-Only (RELRO)"" msgstr ""RELocation Read-Only (RELRO)"" msgid ""RFC 4253"" msgstr ""RFC 4253"" msgid """" ""RPM packages: <link href=\""http://fedoraproject.org/wiki/"" ""How_to_create_an_RPM_package\"">How to create an RPM package</link>"" msgstr """" ""RPM パッケージ: <link href=\""http://fedoraproject.org/wiki/"" ""How_to_create_an_RPM_package\"">How to create an RPM package</link>"" msgid ""RSA"" msgstr ""RSA"" msgid ""RabbitMQ"" msgstr ""RabbitMQ"" msgid ""RabbitMQ Access Control"" msgstr ""RabbitMQ アクセス制御"" msgid ""RabbitMQ Authentication"" msgstr ""RabbitMQ 認証"" msgid ""RabbitMQ Configuration"" msgstr ""RabbitMQ 設定"" msgid ""RabbitMQ Plugins"" msgstr ""RabbitMQ プラグイン"" msgid ""RabbitMQ SASL External Auth"" msgstr ""RabbitMQ SASL 外部認証"" msgid ""RabbitMQ SSL"" msgstr ""RabbitMQ SSL"" msgid """" ""RabbitMQ and Qpid offer authentication and access control mechanisms for "" ""controlling access to queues. ZeroMQ offers no such mechanisms."" msgstr """" ""RabbitMQ と Qpid はキューへのアクセス制御を目的とした、認証およびアクセス制御"" ""の仕組みを持っています。ZeroMQ にはこのような仕組みは備わっていません。"" msgid ""RabbitMQ server SSL configuration"" msgstr ""RabbitMQ サーバにおける SSL 設定"" msgid ""Rate-limiting on a per port/network/tenant basis."" msgstr ""ポート・ネットワーク・テナント単位のレートリミット"" msgid """" ""Red Hat Enterprise Linux-based KVM deployments utilize the following sVirt "" ""booleans:"" msgstr """" ""Red Hat Enterprise Linux ベースの KVM 環境は以下の sVirt ブーリアンを利用しま"" ""す。"" msgid ""References"" msgstr ""参考資料"" msgid """" ""Referencing a table of services, protocols and ports can help in "" ""understanding the relationship between OpenStack components. It is highly "" ""recommended that OpenStack deployments have information similar to this on "" ""record."" msgstr """" ""サービス、プロトコル、ポートの表を参照すると、OpenStack のコンポーネント間の"" ""関係を理解するのに役立ちます。OpenStack のデプロイメントには、これと同様の情"" ""報を記録することを強く推奨します。"" msgid ""Register"" msgstr ""レジスター"" msgid ""Registration Authority (RA)"" msgstr ""登録局 (RA)"" msgid ""Relying party"" msgstr ""信頼機関"" msgid """" ""Remove any unnecessary software packages. This should result in a very "" ""stripped down installation because a compute node has a relatively small "" ""number of dependencies."" msgstr """" ""不要なソフトウェアパッケージは削除します。これにより、コンピュートノードの依"" ""存関係が比較的少なくなるので、インストールを小さく絞ることができます。"" msgid """" ""Replace <replaceable>RABBIT_PASS</replaceable> with a suitable password."" msgstr """" ""<replaceable>RABBIT_PASS</replaceable> を適切なパスワードに置き換えます。"" msgid ""Repository"" msgstr ""リポジトリ"" msgid ""Require user accounts to require SSL transport"" msgstr ""SSL 通信利用のための必須ユーザーアカウント"" msgid ""Required for dynamic attestation services"" msgstr ""動的証明サービスに必要です"" msgid ""Required for protecting PCI-passthrough"" msgstr ""PCI パススルーの保護に必要です"" msgid ""Required to allow secure sharing of PCI Express devices"" msgstr ""PCI Express デバイスをセキュアに共有するために必要です"" msgid ""Restrict DB and RPC communication of the OpenStack Networking services"" msgstr ""OpenStack Networking サービス群の DB と RPC 通信の制限"" msgid ""Restrict bind address of the API server: neutron-server"" msgstr ""API サーバがバインドするアドレスの制限: neutron-server"" msgid ""Restricting bind address for MySQL"" msgstr ""MySQL のバインドアドレスの制限"" msgid ""Restricting listen address for PostgreSQL"" msgstr ""PostgreSQL のバインドアドレスの制限"" msgid ""Review common security principles."" msgstr ""共通のセキュリティ原則を確認する"" msgid ""Risk assessment"" msgstr ""リスク評価"" msgid """" ""Robert Clark is the Lead Security Architect for HP Cloud Services and co-"" ""founder of the OpenStack Security Group (OSSG). Prior to being recruited by "" ""HP, he worked in the UK Intelligence Community. Robert has a strong "" ""background in threat modeling, security architecture and virtualization "" ""technology. Robert has a master's degree in Software Engineering from the "" ""University of Wales."" msgstr """" ""Robert Clark は、Nebula の HP Cloud Services の Lead Security Architect で"" ""す。また、OpenStack Security Group (OSSG) の共同創設者です。HP に入社する前"" ""は、UK Intelligence Community に勤務していました。脅威モデリング、セキュリ"" ""ティアーキテクチャ、仮想化技術に関する強固なバックグラウンドを持ちます。"" ""University of Wales のソフトウェアエンジニアリングの修士号を持っています。"" msgid """" ""Rodney D. Beede is the Cloud Security Engineer for Seagate Technology. He "" ""contributed the missing chapter on securing OpenStack Object Storage "" ""(swift). He holds a M.S. in Computer Science from the University of Colorado."" msgstr """" ""Rodney D. Beede は Seagate Technology の Cloud Security Engineer です。彼は "" ""OpenStack Object Storage (swift) のセキュア化に関する不足していた章に貢献しま"" ""した。University of Colorado の Computer Science に関する M.S. を保持していま"" ""す。"" msgid ""Role-Based Access Control"" msgstr ""ロールベースアクセス制御"" msgid """" ""Role-based access control (RBAC) allows separation of roles to eliminate the "" ""need for an all-powerful system administrator."" msgstr """" ""ロールベースアクセス制御 (RBAC) は、全権を持つシステム管理者の必要性を減らす"" ""ために、役割を分割できるようにします。"" msgid ""Run the following commands:"" msgstr ""以下のコマンドを実行します。"" msgid ""Runtime verification"" msgstr ""ランタイムの検証"" msgid ""SAML assertion"" msgstr ""SAML アサーション"" msgid """" ""SDN services node: Management, guest and possibly public depending upon "" ""product used."" msgstr """" ""SDB サービスノード：管理、ゲスト （使用する製品によってはパブリックも可能性あ"" ""り）"" msgid """" ""SELinux categories are attached to virtual machines and its resources. The "" ""access control policy enforced using these categories grant virtual machines "" ""access to resources if the category of the virtual machine is identical to "" ""the category of the accessed resource."" msgstr """" ""SELinux カテゴリが仮想マシンとそのリソースに付けられます。仮想マシンのカテゴ"" ""リがアクセスされるリソースのカテゴリと同じ場合、これらのカテゴリを使用して強"" ""制されたアクセス制御ポリシーは、仮想マシンのそのリソースへのアクセスが許可さ"" ""れます。"" msgid ""SHA-1"" msgstr ""SHA-1"" msgid ""SHA-2 (224, 256, 384, or 512 bits)"" msgstr ""SHA-2 (224、256、384、512 ビット)"" msgid ""SLA and security monitoring"" msgstr ""SLA およびセキュリティの監視"" msgid ""SOC 1 (SSAE 16) / ISAE 3402"" msgstr ""SOC 1 (SSAE 16) / ISAE 3402"" msgid ""SOC 2"" msgstr ""SOC 2"" msgid ""SOC 3"" msgstr ""SOC 3"" msgid """" ""SPICE is supported by the OpenStack dashboard (horizon) directly on the "" ""instance web page. This requires the <systemitem class=\""service\"">nova-"" ""spicehtml5proxy</systemitem> service."" msgstr """" ""SPICE は OpenStack Dashboard (Horizon) により直接インスタンスのウェブページで"" ""サポートされます。これには nova-spicehtml5proxy サービスが必要です。"" msgid ""SR-IOV, MR-IOV, ATS"" msgstr ""SR-IOV, MR-IOV, ATS"" msgid ""Salt Stack"" msgstr ""Salt Stack"" msgid ""Samhain"" msgstr ""Samhain"" msgid """" ""Sanitize portable, removable storage devices prior to connecting such "" ""devices to the cloud infrastructure."" msgstr """" ""持ち運び可能なリムーバルストレージデバイスをクラウドインフラに接続する前にサ"" ""ニタイズすること。"" msgid ""Scheduling instances to nodes"" msgstr ""ノードへのインスタンスのスケジューリング"" msgid """" ""Scope reduction helps ensure OpenStack architects establish high quality "" ""security controls which are tailored to a particular deployment, however it "" ""is paramount to ensure these practices do not omit areas or features from "" ""security hardening. A common example is applicable to PCI-DSS guidelines, "" ""where payment related infrastructure may be scrutinized for security issues, "" ""but supporting services are left ignored, and vulnerable to attack."" msgstr """" ""範囲を限定することで、限定された環境に対し、OpenStackの設計者は高いセキュリ"" ""ティ品質を確立しやすくなります。しかしその取り組みの中で、セキュリティ強化の"" ""範囲や機能を不当に省かないことが重要です。典型的な例はPCI-DSSガイドラインで"" ""す。決済に関わるインフラはセキュリティを精査されるでしょう。が、その影でその"" ""周辺サービスが放置されれば、そこが攻撃に対し無防備となります。"" msgid ""Secret key"" msgstr ""シークレットキー"" msgid ""Secure Communication"" msgstr ""セキュア通信"" msgid ""Secure backup and recovery"" msgstr ""セキュアなバックアップとリカバリ"" msgid ""Secure bootstrapping"" msgstr ""セキュアブートストラップ"" msgid ""Secure data erasure"" msgstr ""安全なデータの消去"" msgid ""Secure shell (SSH)"" msgstr ""secure shell (SSH)"" msgid ""Securing OpenStack Networking services"" msgstr ""OpenStack Networking サービスのセキュリティ強化"" msgid ""Securing proxy services"" msgstr ""プロキシサービスのセキュア化"" msgid ""Securing services: general"" msgstr ""サービスのセキュア化: 一般"" msgid ""Securing storage services"" msgstr ""ストレージサービスのセキュア化"" msgid ""Security Management"" msgstr ""セキュリティ管理"" msgid ""Security auditing tools"" msgstr ""セキュリティ監査ツール"" msgid """" ""Security auditing tools can complement the configuration management tools. "" ""Security auditing tools automate the process of verifying that a large "" ""number of security controls are satisfied for a given system configuration. "" ""These tools help to bridge the gap from security configuration guidance "" ""documentation (for example, the STIG and NSA Guides) to a specific system "" ""installation. For example, <link href=\""https://fedorahosted.org/scap-"" ""security-guide/\"">SCAP</link> can compare a running system to a pre-defined "" ""profile. SCAP outputs a report detailing which controls in the profile were "" ""satisfied, which ones failed, and which ones were not checked."" msgstr """" ""セキュリティ監査ツールは、構成管理ツールを補完することができます。セキュリ"" ""ティ監査ツールは、セキュリティ制御の多くが指定のシステム設定を満たしているこ"" ""とを確認するプロセスを自動化します。これらのツールは、セキュリティ設定方針文"" ""書 (例: STIG および NSA ガイド) から個別のシステムインストール環境のギャップ"" ""を埋めるサポートをします。例えば、<link href=\""https://fedorahosted.org/scap-"" ""security-guide/\"">SCAP</link> は実行中のシステムと事前定義済みのプロファイル"" ""を比較することができます。SCAP はプロファイル内のどの制御に対応しているか、問"" ""題があるものはどれか、確認されていないものはどれかを詳細にまとめたレポートを"" ""出力します。"" msgid ""Security boundaries and threats"" msgstr ""セキュリティ境界と脅威"" msgid """" ""Security concerns here pertain to trust in authentication, management of "" ""authorization tokens, and secure communication."" msgstr """" ""ここでのセキュリティ課題には、認証の信頼、承認トークンの管理、セキュリティ保"" ""護された通信などがあげられます。"" msgid ""Security considerations"" msgstr ""セキュリティの課題"" msgid """" ""Security considerations for block storage are similar to that of object "" ""storage."" msgstr ""Block Storage のセキュリティ課題は、Object Storage の場合と同様です。"" msgid ""Security considerations for memory optimization"" msgstr ""メモリ最適化に関するセキュリティの課題"" msgid ""Security domains"" msgstr ""セキュリティドメイン"" msgid ""Security function"" msgstr ""セキュリティ機能"" msgid ""Security groups"" msgstr ""セキュリティグループ"" msgid """" ""Security groups allow administrators and tenants the ability to specify the "" ""type of traffic, and direction (ingress/egress) that is allowed to pass "" ""through a virtual interface port. Security groups rules are stateful L2-L4 "" ""traffic filters."" msgstr """" ""セキュリティグループでは、管理者とテナントが仮想インターフェースポート通過を"" ""許可する通信のタイプと方向（内向き／外向き）を指定できるようになっています。"" msgid ""Security in MySQL"" msgstr ""Security in MySQL"" msgid """" ""Security may be enhanced by requiring X.509 client certificates for "" ""authentication. Authenticating to the database in this manner provides "" ""greater identity assurance of the client making the connection to the "" ""database and ensures that the communications are encrypted."" msgstr """" ""認証に X.509 クライアント証明書を要求することにより、セキュリティを向上させら"" ""れるかもしれません。この方法でデータベースに認証することにより、データベース"" ""に接続しているクライアントの ID 確認をより強力にでき、通信が確実に暗号化され"" ""ます。"" msgid ""Security principles"" msgstr ""セキュリティ原則"" msgid ""Security references for database back ends"" msgstr ""データベースバックエンドのセキュリティ参考資料"" msgid ""Security reviews"" msgstr ""セキュリティの検査"" msgid ""Security services for instances"" msgstr ""インスタンスのセキュリティサービス"" msgid ""Security training"" msgstr ""セキュリティトレーニング"" msgid """" ""Security updates are critical to any IaaS deployment, whether private or "" ""public. Vulnerable systems expand attack surfaces, and are obvious targets "" ""for attackers. Common scanning technologies and vulnerability notification "" ""services can help mitigate this threat. It is important that scans are "" ""authenticated and that mitigation strategies extend beyond simple perimeter "" ""hardening. Multi-tenant architectures such as OpenStack are particularly "" ""prone to hypervisor vulnerabilities, making this a critical part of the "" ""system for vulnerability management. See the section on instance isolation "" ""for additional details."" msgstr """" ""セキュリティアップデートはプライベート、パブリックを問わず、あらゆるIaaS環境"" ""において重要です。脆弱なシステムは攻撃面を広げ、攻撃者にターゲットをさらして"" ""しまいます。一般的なスキャニング技術と脆弱性検知サービスはこの脅威を和らげる"" ""のに役立ちます。スキャンが認証されたものであり、その緩和戦略が単なる境界線の"" ""防御力向上にとどまらないことが重要です。OpenStackのようなマルチテナントアーキ"" ""テクチャは特にハイパーバイザーの脆弱性に影響されやすく、それはシステムの脆弱"" ""性管理の重点項目です。詳細はインスタンス隔離の節を参照してください。"" msgid """" ""See the chapter on PKI/SSL Everywhere for more specific recommendations and "" ""server configurations for HTTPS configurations, including the configuration "" ""of HSTS."" msgstr """" ""HSTS の設定を含め、HTTPS の設定に関するより具体的な推奨事項とサーバー設定は、"" ""PKI/SSL の章全体を参照してください。"" msgid ""Select an auditor."" msgstr ""監査人を選ぶ"" msgid """" ""Selecting an auditor can be challenging. Ideally, you are looking for "" ""someone with experience in cloud compliance audits. OpenStack experience is "" ""another big plus. Often it is best to consult with people who have been "" ""through this process for referrals. Cost can vary greatly depending on the "" ""scope of the engagement and the audit firm considered."" msgstr """" ""監査人の選定は困難を伴うことがあります。クラウドのコンプライアンス監査経験が"" ""ある人を見つけてくるのが理想です。OpenStackの経験があれば、なお良しです。この"" ""プロセスを経験している人に相談するのがベストでしょう。なお、費用は契約の範囲"" ""と監査法人に大きく依存します。"" msgid ""Selection criteria"" msgstr ""選択基準"" msgid """" ""Selects highest possible security cipher in the negotiation phase. These "" ""typically have keys of length 128 bits or longer."" msgstr """" ""ネゴシエーション段階で利用可能な最高のセキュリティ暗号を選択します。これらは"" ""一般的に 128 ビット以上の鍵を持ちます。"" msgid ""Self service"" msgstr ""セルフサービス"" msgid ""Serpent"" msgstr ""Serpent"" msgid """" ""Service Organization Controls (SOC) 2 is a self attestation of controls that "" ""affect the security, availability, and processing integrity of the systems a "" ""service organization uses to process users' data and the confidentiality and "" ""privacy of information processed by these system. Examples of users are "" ""those responsible for governance of the service organization; customers of "" ""the service organization; regulators; business partners; suppliers and "" ""others who have an understanding of the service organization and its "" ""controls."" msgstr """" ""Service Organization Controls (SOC) 2は、サービス提供組織がユーザーデータとそ"" ""の情報の機密性とプライバシーを制御するために使っているシステムのセキュリ"" ""ティ、可用性、および処理の完全性に関する統制の自己証明です。ユーザーの例は、"" ""サービス組織を統制する人、サービス組織の顧客、監視当局、ビジネスパートナー、"" ""サプライヤー、およびサービス組織の理解者やそれを統制する人です。"" msgid """" ""Service Organization Controls (SOC) 3 is a trust services report for service "" ""organizations. These reports are designed to meet the needs of users who "" ""want assurance on the controls at a service organization related to "" ""security, availability, processing integrity, confidentiality, or privacy "" ""but do not have the need for or the knowledge necessary to make effective "" ""use of a SOC 2 Report. These reports are prepared using the AICPA/Canadian "" ""Institute of Chartered Accountants (CICA) Trust Services Principles, "" ""Criteria, and Illustrations for Security, Availability, Processing "" ""Integrity, Confidentiality, and Privacy. Because they are general use "" ""reports, SOC 3 Reports can be freely distributed or posted on a website as a "" ""seal."" msgstr """" ""Service Organization Controls (SOC) 3はサービス提供組織のための公的なサービス"" ""報告書です。これらのレポートはサービス組織のセキュリティ、可用性、処理の完全"" ""性、機密性、またはプライバシーに関する統制の保証を求めるユーザーニーズを満た"" ""すためのレポートです。ただし、SOC 2報告書ほどの情報は必要ありません。SOC 3報"" ""告書はAICPA/Canadian Institute of Chartered Accountants (CICA)のTrust "" ""Services Principles, Criteria, and Illustrations for Security, Availability, "" ""Processing Integrity, Confidentiality, and Privacyをもって作成されています。"" ""SOC 3は一般的に使われる報告書であり、Webサイト上で証明書として自由に配布でき"" ""ます。"" msgid """" ""Service Organization Controls (SOC) criteria are defined by the <link href="" ""\""http://www.aicpa.org/\"">American Institute of Certified Public "" ""Accountants</link> (AICPA). SOC controls assess relevant financial "" ""statements and assertions of a service provider, such as compliance with the "" ""Sarbanes-Oxley Act. SOC 1 is a replacement for Statement on Auditing "" ""Standards No. 70 (SAS 70) Type II report. These controls commonly include "" ""physical data centers in scope."" msgstr """" ""Service Organization Controls (SOC)基準は米国公認会計士協会 - <link href="" ""\""http://www.aicpa.org/\"">American Institute of Certified Public "" ""Accountants</link> (AICPA)によって定められています。SOC統制はサービスプロバイ"" ""ダーの関連財務諸表と主張を評価します。例えばSarbanes-Oxley法への準拠などで"" ""す。SOC 1 はStatement on Auditing Standards No. 70 (SAS 70) Type II 報告書を"" ""代替します。これらの統制は物理的なデータセンターを評価範囲に含みます。"" msgid ""Service authorization"" msgstr ""サービス認可"" msgid ""Service name"" msgstr ""サービス名"" msgid """" ""Services select their respective API endpoints based on the OpenStack "" ""service catalog. These services might not obey the listed public or internal "" ""API end point values. This can lead to internal management traffic being "" ""routed to external API endpoints."" msgstr """" ""サービスはOpenStackサービスカタログに基づいて、それぞれのAPIエンドポイントを"" ""選択します。これらのサービスは、リストされた外部もしくは内部APIエンドポイント"" ""の値に従わないことがあります。これは内部管理トラフィックが外部APIエンドポイン"" ""トへルーティングされる可能性があります。"" msgid ""Services, protocols and ports"" msgstr ""サービス、プロトコル、およびポート"" msgid ""Session Cookies should be set to HTTPONLY:"" msgstr ""セッションクッキーは HTTPONLY に設定すべきです。"" msgid """" ""Several cryptography algorithms are available within OpenStack for "" ""identification and authorization, data transfer and protection of data at "" ""rest. When selecting a hypervisor, the following are recommended algorithms "" ""and implementation standards to ensure the virtualization layer supports:"" msgstr """" ""いくつかの暗号アルゴリズムは、認証と識別、データ転送、保存データの保護のため"" ""に、OpenStack の中で利用可能です。ハイパーバイザーの選択時、以下が推奨アルゴ"" ""リズムで、仮想化層のサポートを確実にするための実装標準です。"" msgid """" ""Several of the components use databases though it is not explicitly called "" ""out. Securing the access to the databases and their contents is yet another "" ""security concern, and consequently discussed in more detail later in this "" ""guide."" msgstr """" ""一部のコンポーネントは、間接的にデータベースを使用します。データベースおよび"" ""そのコンテンツへのアクセスのセキュリティ保護は、もう一つのセキュリティ課題で"" ""あるため、本ガイドの後半でさらに詳しく説明します。"" msgid """" ""Shawn Wells is the Director, Innovation Programs at Red Hat, focused on "" ""improving the process of adopting, contributing to, and managing open source "" ""technologies within the U.S. Government. Additionally, Shawn is an upstream "" ""maintainer of the SCAP Security Guide project which forms virtualization and "" ""operating system hardening policy with the U.S. Military, NSA, and DISA. "" ""Formerly an NSA civilian, Shawn developed SIGINT collection systems "" ""utilizing large distributed computing infrastructures."" msgstr """" ""Shawn Wells は Red Hat の Innovation Programs の Director です。アメリカ政府"" ""の中でオープンソース技術を適用、貢献、管理するプロセスを改善することに注力し"" ""ています。さらに、SCAP Security Guide プロジェクトのアップストリームのメンテ"" ""ナーです。このプロジェクトは、 U.S. Military、NSA、DISA で仮想化とオペレー"" ""ティングシステムの強化ポリシーを作成しています。NSA の契約者になる前は、大規"" ""模分散コンピューティング環境を利便化する SIGINT 収集システムを開発していまし"" ""た。"" msgid """" ""Similar to host-based tools, the selection and configuration of a network-"" ""based intrusion detection tool is deployment specific. <link href=\""http://"" ""www.snort.org/\"">Snort</link> is the leading open source networking "" ""intrusion detection tool, and a good starting place to learn more."" msgstr """" ""ホストベースのツールと同様に、ネットワークベースの侵入検知ツールはデプロイメ"" ""ントによって異なります。 <link href=\""http://www.snort.org/\"">Snort</link> "" ""は、先進的なオープンソースのネットワーク侵入検知ツールです。このツールを起点"" ""として、更に知識を深めてゆくとよいでしょう。"" msgid ""Simple Protocol for Independent Computing Environments (SPICE)"" msgstr ""Simple Protocol for Independent Computing Environments (SPICE)"" msgid """" ""SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate "" ""trust model enhancements"" msgstr """" ""SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate "" ""trust model enhancements"" msgid ""Software"" msgstr ""ソフトウェア"" msgid ""Software inventory"" msgstr ""ソフトウェアインベントリ"" msgid ""Spark"" msgstr ""Spark"" msgid """" ""Specific to various hypervisors is the treatment of instance memory. This "" ""behavior is not defined in OpenStack Compute, although it is generally "" ""expected of hypervisors that they will make a best effort to scrub memory "" ""either upon deletion of an instance, upon creation of an instance, or both."" msgstr """" ""様々なハイパーバイザの特色はインスタンスメモリの扱いにあります。\n"" ""\n"" ""This behavior is not defined in OpenStack Compute, although it is generally "" ""expected of hypervisors that they will make a best effort to scrub memory "" ""either upon deletion of an instance, upon creation of an instance, or both.\n"" ""\n"" ""この挙動は OpenStack Compute で定義されておらず、ハイパーバイザがインスタンス"" ""作成時または削除時、あるいはその両方において、ベストエフォートでメモリのクリ"" ""ンアップを行うだろうと一般に考えられています。"" msgid ""Stack canaries"" msgstr ""スタックカナリア"" msgid ""Start instance on destination host"" msgstr ""目的先ホストでインスタンスを起動"" msgid ""Start the guest"" msgstr ""ゲストを起動"" msgid ""State transition and wake events"" msgstr ""状態遷移とウェイクイベント"" msgid ""Static media"" msgstr ""静的メディア"" msgid ""Stop the guest &amp; sync disks"" msgstr ""ゲスト&amp;syncディスクを停止"" msgid ""Storage API endpoints"" msgstr ""ストレージAPIエンドポイント"" msgid ""Storage Encryption"" msgstr ""ストレージ暗号化"" msgid ""Storage services"" msgstr ""ストレージサービス"" msgid ""Stud"" msgstr ""Stud"" msgid ""Summary"" msgstr ""概要"" msgid ""System documentation"" msgstr ""システムドキュメント"" msgid ""System documentation requirements"" msgstr ""システムの文書化における要件"" msgid ""System inventory"" msgstr ""システムインベントリ"" msgid ""System roles and types"" msgstr ""システムのロールとタイプ"" msgid """" ""Systems should be segregated in a such way that if one machine, or system-"" ""level service, is compromised the security of the other systems will remain "" ""intact. Practically, the enablement and proper usage of SELinux helps "" ""accomplish this goal."" msgstr """" ""システムは、仮にあるマシンやシステムレベルのサービスが危険にさらされたとして"" ""も、他の無傷なシステムとは分離されているべきです。実際、SELinuxの正しい使用"" ""は、この目標を達成するのに役立ちます。"" msgid ""TCP"" msgstr ""TCP"" msgid ""TDES"" msgstr ""TDES"" msgid ""TSF Protection"" msgstr ""TSF 保護"" msgid ""TXT"" msgstr ""TXT"" msgid ""Team expertise"" msgstr ""チーム習熟度"" msgid ""Technology"" msgstr ""技術"" msgid ""TempAuth"" msgstr ""TempAuth"" msgid ""Tenant data privacy"" msgstr ""テナントデータのプライバシー"" msgid """" ""Tenant data stored in an OpenStack cloud may include the following items:"" msgstr ""OpenStack クラウドに保存されたテナントデータは以下の項目を含まれます："" msgid ""Tenant network services workflow"" msgstr ""テナントネットワークサービスのワークフロー"" msgid """" ""Test data recovery options regularly. One of the things that can be restored "" ""from secured backups is the images. In case of a compromise, the best "" ""practice would be to terminate running instances immediately and then "" ""relaunch the instances from the images in the secured backup repository."" msgstr """" ""データのリカバリーオプションを定期的にテストすること。セキュアなバックアップ"" ""からリストアが可能なものの 1 つにイメージがあります。情報漏洩などが発生した場"" ""合のベストプラクティスは、すぐに実行中のインスタンスを終了して、セキュアな"" ""バックアップリポジトリにあるイメージからインスタンスを再起動することです。"" msgid ""Test sanitation equipment and procedures to verify proper performance."" msgstr """" ""適切なパフォーマンスを検証する為、サニタイズ設備と過程の評価を行うこと。"" msgid ""Testing the updates"" msgstr ""更新のテスト"" msgid """" ""The <filename>/etc/swift</filename> directory contains information about the "" ""ring topology and environment configuration. The following permissions are "" ""recommended:"" msgstr """" ""<filename>/etc/swift</filename> はリングのトポロジーと環境設定に関する情報を"" ""含みます。以下のパーミッションが推奨されます。"" msgid """" ""The <link href=\""https://cloudsecurityalliance.org/research/ccm/\"">Cloud "" ""Security Alliance Cloud Controls Matrix</link> (CCM) assists both cloud "" ""providers and consumers in assessing the overall security of a cloud "" ""provider. The CSA CMM provides a controls framework that map to many "" ""industry-accepted standards and regulations including the ISO 27001/2, "" ""ISACA, COBIT, PCI, NIST, Jericho Forum and NERC CIP."" msgstr """" ""<link href=\""https://cloudsecurityalliance.org/research/ccm/\"">Cloud "" ""Security Alliance Cloud Controls Matrix</link> (CCM)はクラウドプロバイダーの"" ""セキュリティを総合的に評価するにあたって、プロバイダーとユーザーの両方に役立"" ""ちます。CSA CCMはISO 27001/2、ISACA、COBIT、PIC、NIST、Jericho Forum、NERC "" ""CIPといった、多くの業界で認められた標準、規制をひも付けた統制フレームワークを"" ""提供します。"" msgid """" ""The <link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP "" ""Security Guide</link> is another useful reference. This is still an emerging "" ""source, but we anticipate that this will grow into a tool with controls "" ""mappings that are more focused on the US federal government certifications "" ""and recommendations. For example, the SCAP Security Guide currently has some "" ""mappings for security technical implementation guides (STIGs) and "" ""NIST-800-53."" msgstr """" ""<link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP Security "" ""Guide</link>はもうひとつの有用なリファレンスです。まだ出来たばかりですが、米"" ""国連邦政府の認証、推奨への対応に重点を絞ったツールとして普及すると予想されま"" ""す。例えば、SCAP Security Guideは現在、security technical implementation "" ""guides (STIGs)とNIST-800-53にある程度対応しています。"" msgid """" ""The <literal>md5</literal> parameter defines the authentication method as a "" ""hashed password. We provide a secure authentication example in the section "" ""below."" msgstr """" ""<literal>md5</literal> パラメーターは認証方式をハッシュ化パスワードとして定義"" ""します。以下のセクションでセキュアな認証例を提供します。"" msgid """" ""The <placeholder-1/> command-line utility can return a URL for the VNC "" ""console for access by the <systemitem class=\""service\"">nova</systemitem> "" ""Java VNC client. This requires the <systemitem class=\""service\"">nova-"" ""xvpvncproxy</systemitem> service to bridge from the public network to the "" ""management network."" msgstr """" ""<placeholder-1/> コマンドラインユーティリティは <systemitem class=\""service"" ""\"">nova</systemitem> Java VNC クライアントによりアクセスするための VNC の "" ""URL を返すことができます。これには、<systemitem class=\""service\"">nova-"" ""xvpvncproxy</systemitem> サービスがパブリックネットワークから管理ネットワーク"" ""にブリッジする必要があります。"" msgid """" ""The <systemitem class=\""service\"">nova-novncproxy</systemitem> and "" ""<systemitem class=\""service\"">nova-xvpvncproxy</systemitem> services by "" ""default open public-facing ports that are token authenticated."" msgstr """" ""デフォルトのオープンなパブリックポートによる <systemitem class=\""service"" ""\"">nova-novncproxy</systemitem> サービスと <systemitem class=\""service"" ""\"">nova-xvpvncproxy</systemitem> サービスがトークン認証されます。"" msgid """" ""The <systemitem class=\""service\"">nova-spicehtml5proxy</systemitem> service "" ""by default opens public-facing ports that are token authenticated."" msgstr """" ""<systemitem class=\""service\"">nova-spicehtml5proxy</systemitem> サービスはデ"" ""フォルトで、トークン認証されるパブリックポートをオープンします。"" msgid """" ""The API provides a tenant interface for provisioning, managing, and "" ""accessing their resources."" msgstr """" ""API はリソースのプロビジョニング、管理、アクセスに使用するプロジェクトイン"" ""ターフェースを提供します。"" msgid ""The Apache Foundation has a messaging security guide for Qpid. See:"" msgstr """" ""Apache Foundation が Qpid のメッセージングセキュリティガイドを発行していま"" ""す。"" msgid """" ""The Compute service (nova) is one of the more complex OpenStack services. It "" ""runs in many locations throughout the cloud and interacts with a variety of "" ""internal services. For this reason, most of our recommendations regarding "" ""best practices for Compute service configuration are distributed throughout "" ""this book. We provide specific details in the sections on Management, API "" ""Endpoints, Messaging, and Database."" msgstr """" ""Compute Service (Nova) は最も複雑な OpenStack サービスの一つです。クラウドの"" ""隅々まで多くの場所で動作し、さまざまな内部サービスと通信します。この理由によ"" ""り、Compute Service 設定のベストプラクティスに関する推奨事項の多くは、本書を"" ""通して配布されます。管理、API エンドポイント、メッセージング、データベースの"" ""セクションで具体的な詳細を提供します。"" msgid """" ""The Compute service facilitates this management through an abstraction layer "" ""that interfaces with supported hypervisors, which we address later on in "" ""more detail."" msgstr """" ""Compute は、サポート対象のハイパーバイザーと連動する抽象化レイヤーを介してこ"" ""のような管理を行います。ハイパーバイザーについては、後半で詳しく説明します。"" msgid """" ""The Federal Information Security Management Act requires that government "" ""agencies create a comprehensive plan to implement numerous government "" ""security standards, and was enacted within the E-Government Act of 2002. "" ""FISMA outlines a process, which utilizing multiple NIST publications, "" ""prepares an information system to store and process government data."" msgstr """" ""米国連邦情報セキュリティマネジメント法 - Federal Information Security "" ""Management Act requires、FISMAは、政府機関は多数の政府セキュリティ標準を実装"" ""するために、包括的な計画を作成する必要があるとして、2002年 電子政府法 - E-"" ""Government Act of 2002 内で制定されました。FISMAは多数のNIST公表文献を活用"" ""し、政府のデータを保存、処理する情報システムを作成するためのプロセスを説明し"" ""ています。"" msgid """" ""The Health Insurance Portability and Accountability Act (HIPAA) is a United "" ""States congressional act that governs the collection, storage, use and "" ""destruction of patient health records. The act states that Protected Health "" ""Information (PHI) must be rendered \""unusable, unreadable, or indecipherable"" ""\"" to unauthorized persons and that encryption for data 'at-rest' and "" ""'inflight' should be addressed."" msgstr """" ""Health Insurance Portability and Accountability Act (HIPAA)は米国の健康保険に"" ""おける可搬性と責任に関する法律で、カルテ情報の収集、保存、および廃棄に関する"" ""ルールを定めています。この法律は、保護医療情報 (Protected Health "" ""Information, PHI)は、権限のない人が\""利用できない、読めない、複合できない\""よ"" ""うに変換されなければいけないこと、また、データが保存中でも、処理中でも、暗号"" ""化するべきであることに言及しています。"" msgid ""The IOMMU feature is marketed as VT-d by Intel and AMD-Vi by AMD."" msgstr """" ""IOMMU 機能は、Intel により VT-d、AMD により AMD-Vi として提供されています。"" msgid """" ""The ISO/IEC 27001/2 standards replace BS7799-2, and are specifications for "" ""an Information Security Management System (ISMS). An ISMS is a comprehensive "" ""set of policies and processes that an organization creates and maintains to "" ""manage risk to information assets. These risks are based upon the "" ""confidentiality, integrity, and availability (CIA) of user information. The "" ""CIA security triad has been used as a foundation for much of the chapters in "" ""this book."" msgstr """" ""ISO/IEC 27001/2はBS7799-2の後継標準で、Information Security Management "" ""System (ISMS)の要件です。ISMSは組織が情報資産のリスクを管理するために作成、維"" ""持する、ポリシーとプロセスの包括的なセットです。それらのリスクはユーザー情報"" ""のConfidentiality - 機密性、Integrity - 完全性、および Availability - 可用性 "" ""(CIA)に深く関係しています。CIAセキュリティの三要素は、このガイドの多くの章で"" ""基本となっています。"" msgid """" ""The Identity service catalog should be aware of your internal URLs. While "" ""this feature is not utilized by default, it may be leveraged through "" ""configuration. Additionally, it should be forward-compatible with expectant "" ""changes once this behavior becomes the default."" msgstr """" ""Identity のカタログは内部 URL を認識できるようにすべきです。この機能はデフォ"" ""ルトで利用されませんが、設定により有効化できます。さらに、この動作が標準にな"" ""ると、予期される変更と前方互換性があるべきです。"" msgid """" ""The International Traffic in Arms Regulations (ITAR) is a set of United "" ""States government regulations that control the export and import of defense-"" ""related articles and services on the United States Munitions List (USML) and "" ""related technical data. ITAR is often approached by cloud providers as an "" ""\""operational alignment\"" rather than a formal certification. This typically "" ""involves implementing a segregated cloud environment following practices "" ""based on the NIST 800-53 framework, as per FISMA requirements, complemented "" ""with additional controls restricting access to \""U.S. Persons\"" only and "" ""background screening."" msgstr """" ""International Traffic in Arms Regulations (ITAR)は米国政府規制の集合であり、"" ""米国軍需品リスト(United States Munitions List, USML)と関連技術情報に関係する"" ""防衛物品・サービスの輸出入を統制します。ITARは正式な認証というより、\""軍事活"" ""動支援\""の位置づけでクラウドプロバイダーから提示されます。この統制は一般的"" ""に、NIST 800-53フレームワークにもとづき、分離されたクラウド環境の実装を意味し"" ""ます。FISMA要件により、米国民かつ身元審査された人のみがアクセスできるよう、追"" ""加の統制で補完します。"" msgid """" ""The KVM hypervisor has been Common Criteria certified through the U.S. "" ""Government and commercial distributions, which have been validated to "" ""separate the runtime environment of virtual machines from each other, "" ""providing foundational technology to enforce instance isolation. In addition "" ""to virtual machine isolation, KVM has been Common Criteria certified to"" msgstr """" ""KVM ハイパーバイザーはアメリカ政府から Common Criteria 認証された商用ディスト"" ""リビューションです。インスタンス分離を強制するための基礎的な技術を提供し、仮"" ""想マシンの実行環境を分離できることが検証されました。仮想マシンの分離に加え"" ""て、KVM は次のとおり Common Criteria 認証されています。"" msgid """" ""The L3 router provides basic Network Address Translation (NAT) capabilities "" ""on <emphasis>gateway</emphasis> ports that uplink the router to external "" ""networks. This router SNATs (Static NAT) all traffic by default, and "" ""supports floating IPs, which creates a static one-to-one mapping from a "" ""public IP on the external network to a private IP on one of the other "" ""subnets attached to the router."" msgstr """" ""L3 ルータは、外部ネットワークへのルータに接続する<emphasis>ゲートウェイ</"" ""emphasis>ポート上の基本的なネットワークアドレス変換 (NAT) 機能を提供します。"" ""このルータはデフォルトで全てのネットワークの SNAT (静的 NAT) を行います。これ"" ""は、外部ネットワーク上のパブリック IP アドレスから、ルータにアタッチされた他"" ""の１サブネットのプライベート IP アドレスへ変換する静的な１対１マッピングを作"" ""成します。"" msgid """" ""The Most Dangerous Code in the World: Validating SSL Certificates in Non-"" ""Browser Software"" msgstr """" ""The Most Dangerous Code in the World: Validating SSL Certificates in Non-"" ""Browser Software"" msgid """" ""The OpenStack API is a RESTful web service endpoint to access, provision and "" ""automate cloud-based resources. Operators and users typically access the API "" ""through command-line utilities (for example, <placeholder-1/> or "" ""<placeholder-2/>), language-specific libraries, or third-party tools."" msgstr """" ""OpenStack API はクラウドベースのリソースのアクセス、プロビジョニング、自動化"" ""を行う RESTful Web サービスのエンドポイントです。オペレーターやユーザーは通"" ""常、コマンドラインユーティリティ (<placeholder-1/>、<placeholder-2/> など)、"" ""言語固有のライブラリ、またはサードパーティのツールで API にアクセスします。"" msgid """" ""The OpenStack Management Utilities are open-source Python command-line "" ""clients that make API calls. There is a client for each OpenStack service "" ""(for example, <systemitem class=\""service\"">nova</systemitem>, <systemitem "" ""class=\""service\"">glance</systemitem>). In addition to the standard CLI "" ""client, most of the services have a management command-line utility which "" ""makes direct calls to the database. These dedicated management utilities are "" ""slowly being deprecated."" msgstr """" ""OpenStack 管理ユーテリティは、API 呼び出しを行う、オープンソースの Python の"" ""コマンドラインクライアントです。OpenStack サービス (<systemitem class="" ""\""service\"">nova</systemitem>、<systemitem class=\""service\"">glance</"" ""systemitem> など) 毎にクライアントがあります。標準の CLI クライアントに加え、"" ""サービスの多くには管理コマンドラインがあり、データベースへ直接呼び出しを行い"" ""ます。これらの専用の管理ユーテリティは徐々に廃止予定となっています。"" msgid ""The OpenStack Networking components are:"" msgstr ""OpenStack Networking のコンポーネントは以下のとおりです。"" msgid """" ""The OpenStack Security Group would like to acknowledge contributions from "" ""the following organizations that were instrumental in making this book "" ""possible. The organizations are:"" msgstr """" ""OpenStack Security Group は、このドキュメントの作成を手助けしていただいた以下"" ""の組織の貢献に感謝いたします。"" msgid """" ""The OpenStack dashboard (horizon) can provide a VNC console for instances "" ""directly on the web page using the HTML5 noVNC client. This requires the "" ""<systemitem class=\""service\"">nova-novncproxy</systemitem> service to bridge "" ""from the public network to the management network."" msgstr """" ""OpenStack Dashboard (Horizon) は HTML5 の非 VNC クライアントを使用して、ウェ"" ""ブページから直接インスタンスの VNC コンソールを提供できます。これには、"" ""<systemitem class=\""service\"">nova-novncproxy</systemitem> サービスがパブリッ"" ""クネットワークから管理ネットワークにブリッジする必要があります。"" msgid """" ""The OpenStack dashboard (horizon) provides administrators and tenants with a "" ""web-based graphical interface to provision and access cloud-based resources. "" ""The dashboard communicates with the back-end services through calls to the "" ""OpenStack API."" msgstr """" ""OpenStack dashboard (horizon) は、管理者やプロジェクトに対して、クラウドベー"" ""スのリソースのプロビジョンやアクセスができるように Web ベースのグラフィカル"" ""インターフェースを提供します。ダッシュボードは、OpenStack API に呼び出しを行"" ""うことでバックエンドサービスと対話します。"" msgid """" ""The Payment Card Industry Data Security Standard (PCI DSS) is defined by the "" ""Payment Card Industry Standards Council, and created to increase controls "" ""around card holder data to reduce credit card fraud. Annual compliance "" ""validation is assessed by an external Qualified Security Assessor (QSA) who "" ""creates a Report on Compliance (ROC), or by a Self-Assessment Questionnaire "" ""(SAQ) dependent on volume of card-holder transactions."" msgstr """" ""Payment Card Industry Data Security Standard (PCI DSS)はPayment Card "" ""Industry Standards Councilで定義されました。目的は、クレジットカード不正の防"" ""止のため、カード所有者情報に関する統制度を向上することです。コンプライアンス"" ""検査は年次で、外部のコンプライアンス評価報告書(Report on Compliance, ROC)を作"" ""成する認定評価機関 (Qualified Security Assessor, QSA)、もしくは、自己評価問診"" ""票(Self-Assessment Questionnaire, SAQ)によって実施されます。これはカード所有"" ""者のトランザクション量に依存します。"" msgid """" ""The TOE implements non-hierarchical categories to control access to virtual "" ""machines."" msgstr """" ""TOE は、仮想マシンへのアクセスを制御するために、非階層的なカテゴリを実装しま"" ""す。"" msgid """" ""The ability to encrypt objects in Object Storage is presently limited to "" ""disk-level encryption per node. However, there does exist third-party "" ""extensions and modules for per-object encryption. These modules have been "" ""proposed upstream, but have not per this writing been formally accepted. "" ""Below are some pointers:"" msgstr """" ""Object Storage 中のオブジェクトの暗号化の可能性は、現時点ではノード単位のディ"" ""スクレベル暗号化に限定されています。しかしながら、オブジェクト単位の暗号化用"" ""のサードパーティ拡張やモジュールが存在します。これらのモジュールはアップスト"" ""リームに提案されていますが、この文書を書いている時点では公式に認可されていま"" ""せん。下記はそれらの幾つかへのポインタです。"" msgid """" ""The amount of information that can be gathered about a system and its users "" ""should be minimized."" msgstr ""システムとそのユーザーに関わる、収集可能な情報の量は最小化すべきです。"" msgid """" ""The basics of logging: configuration, setting log level, location of the log "" ""files, and how to use and customize logs, as well as how to do centralized "" ""collections of logs is well covered in the <link href=\""http://docs."" ""openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></"" ""link>."" msgstr """" ""ロギングの基本: ログを集中収集する方法と同様、設定、ログレベル設定、ログファ"" ""イルの位置、ログの使用とカスタマイズ方法は、<link href=\""http://docs."" ""openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></"" ""link> で充分にカバーされています。"" msgid """" ""The choice of technology to provide L2 isolation is dependent upon the scope "" ""and size of tenant networks that will be created in your deployment. If your "" ""environment has limited VLAN ID availability or will have a large number of "" ""L2 networks, it is our recommendation that you utilize tunneling."" msgstr """" ""L2 分断を提供する技術の選択は、あなたのデプロイで作成される予定のテナントネッ"" ""トワークの範囲とサイズに依存します。あなたの環境が VLAN ID の利用で制限がある"" ""場合や、大多数の L2 ネットワークが見込まれる場合、トンネリングの使用を推奨し"" ""ます。"" msgid """" ""The choice of tenant network isolation affects how the network security and "" ""control boundary is implemented for tenant services. The following "" ""additional network services are either available or currently under "" ""development to enhance the security posture of the OpenStack network "" ""architecture."" msgstr """" ""テナントネットワーク分断の選択はネットワークセキュリティと制御境界をどのよう"" ""に実装するかに影響します。\n"" ""以下の追加ネットワークサービスは利用可能か、OpenStack ネットワークアーキテク"" ""チャのセキュリティポーズを拡張する為の開発中かのいずれかです。"" msgid """" ""The compute nodes are the least trusted of the services in OpenStack because "" ""they host tenant instances. The <systemitem class=\""service\"">nova-"" ""conductor</systemitem> service has been introduced to serve as a database "" ""proxy, acting as an intermediary between the compute nodes and the database. "" ""We discuss its ramifications later in this chapter."" msgstr """" ""コンピュートノードは、プロジェクトのインスタンスをホストするため、OpenStack "" ""で最も信頼できないサービスです。<systemitem class=\""service\"">nova-"" ""conductor</systemitem> サービスは、コンピュートノードとデータベースの中継役と"" ""して動作する、データベースプロキシとして処理するために導入されました。その結"" ""果について本章で後ほど議論します。"" msgid """" ""The creation and destruction of ephemeral storage will be somewhat dependent "" ""on the chosen hypervisor and the OpenStack Compute plug-in."" msgstr """" ""一時ストレージの作成・削除は選択したハイパーバイザや OpenStack Compute プラグ"" ""インに依存するでしょう。"" msgid """" ""The dashboard can also be branded for service providers and other commercial "" ""vendors."" msgstr """" ""また、ダッシュボードはサービスプロバイダーや他の商業ベンダー向けにブランディ"" ""ングすることも可能です。"" msgid """" ""The dashboard provides GUI support for routers and load-balancers. For "" ""example, the dashboard now implements all of the main Networking features."" msgstr """" ""また、ダッシュボードではルーターやロードバランサーにも GUI 対応しています。例"" ""えば、ダッシュボードは主な Networking 機能をすべて実装するようになりました。"" msgid """" ""The dashboard provides tenant-users a self-service portal to provision their "" ""own resources within the limits set by administrators."" msgstr """" ""ダッシュボードでは、プロジェクト/ユーザーに対して、管理者が設定した制限値内で"" ""自身のリソースをプロビジョニングするためのセルフサービスポータルを提供しま"" ""す。"" msgid """" ""The dashboard requires cookies and JavaScript to be enabled in the web "" ""browser."" msgstr """" ""ダッシュボードは Web ブラウザーのクッキーと JavaScript を有効にする必要があり"" ""ます。"" msgid """" ""The dashboard ships with reasonable default security settings, and has good "" ""<link href=\""http://docs.openstack.org/developer/horizon/topics/deployment."" ""html\"">deployment and configuration documentation</link>."" msgstr """" ""ダッシュボードは適度なデフォルトのセキュリティ設定をしてあります。また、素晴"" ""らしい <link href=\""http://docs.openstack.org/developer/horizon/topics/"" ""deployment.html\"">deployment and configuration documentation</link> (導入と設"" ""定のドキュメント) があります。"" msgid """" ""The database user accounts created for the OpenStack services and for each "" ""node should have privileges limited to just the database relevant to the "" ""service where the node is a member."" msgstr """" ""データベースユーザーアカウントは OpenStack サービスのために作成され、ノードが"" ""メンバーであるサービスに関連するデータベースだけに制限された権限を持つ各ノー"" ""ドのために作成されます。"" msgid """" ""The dedicated management utilities (*-manage) in some cases use the direct "" ""database connection."" msgstr """" ""場合によっては専用の管理ユーテリティ (*-manage) は直接データベースへの接続を"" ""使用することがあります。"" msgid """" ""The design of OpenStack is such that separation of security domains is "" ""difficult - as core services will usually bridge at least two domains, "" ""special consideration must be given when applying security controls to them."" msgstr """" ""OpenStack のデザインではセキュリティドメインの分離が困難です。コアサービスは"" ""通常少なくとも 2 つのドメインをブリッジしているため、ドメインのセキュリティ制"" ""御を適用する場合、細心の注意を払う必要があります。"" msgid """" ""The diagram shows the types of attacks that may be expected from the actors "" ""described in the previous section. Note that there will always be exceptions "" ""to this diagram but in general, this describes the sorts of attack that "" ""could be typical for each actor."" msgstr """" ""以下の図は、前項で説明したアクターから出される可能性のある攻撃の種類を記載し"" ""ています。このような図では常に例外が存在しますが、アクター毎に典型的であると"" ""考えられる攻撃の種類を一般論として記述しています。"" msgid ""The endpoint that is trusting that the CA is valid."" msgstr ""CAが有効であると証明するエンドポイント"" msgid """" ""The final option is to use an automated image builder. The following example "" ""uses the Oz image builder. The OpenStack community has recently created a "" ""newer tool worth investigating: disk-image-builder. We have not evaluated "" ""this tool from a security perspective."" msgstr """" ""最後の手段として説明するのはイメージの自動生成機構の使用です。次の例では、Oz "" ""image builderを採用しています。OpenStackコミュニティでは、disk-image-builder"" ""というさらに新しいツールが公開されています。本ツールはセキュリティ観点におい"" ""て未検証です。"" msgid ""The first option is to obtain boot media from a trusted source."" msgstr ""最初の選択肢は、信頼された提供元からブートメディアを入手することです。"" msgid """" ""The following are the default listening ports for the various storage "" ""services:"" msgstr ""以下はさまざまなストレージサービスのデフォルトのリッスンポートです。"" msgid ""The following figure demonstrates one possible network architecture."" msgstr ""以下の図はある実現可能なネットワークアーキテクチャを説明します。"" msgid """" ""The following figure shows an architectural and networking flow diagram of "" ""the OpenStack Networking components:"" msgstr """" ""以下の図は OpenStack Networking コンポーネント群の構造・ネットワークフローダ"" ""イアグラムを示しています。"" msgid """" ""The following lines should be added in the system-wide MySQL configuration "" ""file:"" msgstr ""以下の行をシステム全体の MySQL 設定ファイルに追加する必要があります。"" msgid """" ""The following lines should be added in the system-wide PostgreSQL "" ""configuration file, <filename>postgresql.conf</filename>."" msgstr """" ""以下の行をシステム全体の PostgreSQL 設定ファイル <filename>postgresql.conf</"" ""filename> に追加する必要があります。"" msgid """" ""The following lines should be added to the system-wide RabbitMQ "" ""configuration file, typically <filename>/etc/rabbitmq/rabbitmq.config</"" ""filename>:"" msgstr """" ""下記の設定を RabbitMQ のシステム設定ファイルに追加します。通常、<filename>/"" ""etc/rabbitmq/rabbitmq.config</filename> に保存されています。"" msgid """" ""The following table calls out these features by common hypervisor platforms."" msgstr """" ""以下の表は一般的なハイパーバイザーにおけるこれらの機能の対応状況を示します。"" msgid """" ""The functionality and integration are still evolving. We will access the "" ""features in the next release and make recommendations."" msgstr """" ""機能と統合は進化中です。次のリリースの機能を確認し、推奨事項を作成します。"" msgid """" ""The generation and collection of logs is an important component of securely "" ""monitoring an OpenStack infrastructure. Logs provide visibility into the day-"" ""to-day actions of administrators, tenants, and guests, in addition to the "" ""activity in the compute, networking, and storage and other components that "" ""comprise your OpenStack deployment."" msgstr """" ""ログの生成と収集は OpenStack インフラのセキュリティ監視の重要なコンポーネント"" ""です。ログは日々の管理者・テナント・ゲストの行動に加え、あなたの OpenStack デ"" ""プロイを構成する Compute、Networking、ストレージ、他のコンポーネントの活動の"" ""可視性を提供します。"" msgid """" ""The importance of encrypting data on behalf of tenants is largely related to "" ""the risk assumed by a provider that an attacker could access tenant data. "" ""There may be requirements here in government, as well as requirements per-"" ""policy, in private contract, or even in case law in regard to private "" ""contracts for public cloud providers. It is recommended that a risk "" ""assessment and legal consul advised before choosing tenant encryption "" ""policies."" msgstr """" ""テナントの為のデータ暗号化の重要性は、攻撃者がテナントデータにアクセスできる"" ""事をプロバイダが想定するリスクに広く関係しています。政府での要件があるかも知"" ""れませんし、（ポリシー単位の要件と同様）パブリッククラウド提供者用の随意契約"" ""に関しては、随意契約の中、あるいは判例法の中でさえ要求されるかも知れません。"" ""テナント暗号化ポリシーを選択する前に、リスク分析と法務コンサルの忠告を受ける"" ""事をお勧めします。"" msgid """" ""The initial work on this book was conducted in an overly air-conditioned "" ""room that served as our group office for the entirety of the documentation "" ""sprint."" msgstr """" ""執筆作業の初めは空調が効きすぎの部屋で行われました。最終的に、その部屋がグ"" ""ループのオフィスとして執筆スプリント期間中使用されました。"" msgid """" ""The libvirt plug-in for compute may maintain ephemeral storage directly on a "" ""filesystem, or in LVM. Filesystem storage generally will not overwrite data "" ""when it is removed, although there is a guarantee that dirty extents are not "" ""provisioned to users."" msgstr """" ""compute 用の libvirt プラグインは、ファイルシステム又は LVM 上の一時ストレー"" ""ジを直接管理出来ます。ファイルシステムストレージは一般にデータを削除する際に"" ""上書きはしませんが、ユーザに対して汚れたエクステンドが用意されないという保証"" ""があります。"" msgid """" ""The management of the security critical parameters of the system is "" ""performed by administrative users. A set of commands that require root "" ""privileges (or specific roles when RBAC is used) are used for system "" ""management. Security parameters are stored in specific files that are "" ""protected by the access control mechanisms of the system against "" ""unauthorized access by users that are not administrative users."" msgstr """" ""セキュリティ的に重要なシステムパラメーターの管理が、管理ユーザーにより実行さ"" ""れます。root 権限 (または RBAC 使用時の特定のロール) が必要となる一組のコマン"" ""ドが、システム管理のために使用されます。セキュリティ関連のパラメーターは特定"" ""のファイルに保存されます。これらは、システムのアクセス制御機構により、管理"" ""ユーザー以外の権限のないアクセスに対して保護されます。"" msgid """" ""The maturity of a given hypervisor product or project is critical to your "" ""security posture as well. Product maturity has a number of effects once you "" ""have deployed your cloud:"" msgstr """" ""ハイパーバイザー製品またはプロジェクトの成熟度もセキュリティ上重要です。製品"" ""の成熟度はクラウドを配備してから大きな影響が現れます。"" msgid """" ""The method for configuring your web server to start and run as a non-root "" ""user varies by web server and OS."" msgstr """" ""ウェブサーバーを root 以外のユーザーで起動して実行する設定方法はウェブサー"" ""バーと OS により異なります。"" msgid """" ""The nature of the nodes makes additional hardening possible. We recommend "" ""the following additional steps for production nodes:"" msgstr """" ""ノードはその性質上、追加のセキュリティ強化が可能です。実稼働用のノードには、"" ""次の追加手順に従うことを推奨します。"" msgid """" ""The neutron-l3-agent, used by many plug-ins to implement L3 forwarding, "" ""supports only IPv4 forwarding."" msgstr """" ""neutron-l3-agent （L3 転送の実装用に多くのプラグインが使用）は IPv4 転送のみ"" ""サポートしています。"" msgid """" ""The next step is to harden QEMU using compiler hardening options. Modern "" ""compilers provide a variety of compile time options to improve the security "" ""of the resulting binaries. These features, which we will describe in more "" ""detail below, include relocation read-only (RELRO), stack canaries, never "" ""execute (NX), position independent executable (PIE), and address space "" ""layout randomization (ASLR)."" msgstr """" ""次の手順は、コンパイラーのセキュリティ強化オプションを使用して QEMU をセキュ"" ""リティ強化することです。最近のコンパイラーは、出力バイナリのセキュリティを改"" ""善するために、さまざまなコンパイル時オプションを提供します。これらの機能に"" ""は、より詳細を以下で説明しますが、relocation read-only (RELRO)、Stack "" ""Canaries、never execute (NX)、position independent executable (PIE)、address "" ""space layout randomization (ASLR) があります。"" msgid """" ""The nova command-line utility can return a URL for SPICE console for access "" ""by a SPICE-html client."" msgstr """" ""nova コマンドラインユーティリティは SPICE-html クライアントによりアクセスする"" ""ための SPICE コンソールの URL を返すことができます。"" msgid """" ""The policies can be updated by the cloud administrator to further control "" ""access to the various resources. The middleware could also be further "" ""customized. Note that your users must be assigned to groups/roles that you "" ""refer to in your policies."" msgstr """" ""さまざまなリソースへのアクセス権をさらに制御するために、クラウド管理者がポリ"" ""シーを更新できます。ミドルウェアによりさらにカスタマイズすることもできます。"" ""そのポリシーを参照しているグループやロールにユーザーを割り当てる必要があるこ"" ""とに注意してください。"" msgid """" ""The prescriptive defense for each form of attack is beyond the scope of this "" ""document. The above diagram can assist you in making an informed decision "" ""about which types of threats, and threat actors, should be protected "" ""against. For commercial public cloud deployments this might include "" ""prevention against serious crime. For those deploying private clouds for "" ""government use, more stringent protective mechanisms should be in place, "" ""including carefully protected facilities and supply chains. In contrast "" ""those standing up basic development or test environments will likely require "" ""less restrictive controls (middle of the spectrum)."" msgstr """" ""攻撃の形式ごとの規範的な防御については、本書の対象範囲外となっています。上記"" ""の図は、対策を行うべき脅威の種類、脅威のアクターについて詳細な情報を得た状態"" ""で意思決定ができるように支援します。商業的なパブリッククラウドのデプロイに関"" ""しては重大な犯罪の防止などが含まれる場合があります。 政府で使用するプライベー"" ""トクラウドをデプロイする方は、細心の注意を払って設置された対策施設やサプライ"" ""チェーンなど、より厳密な保護メカニズムを設置する必要があります。反対に、基本"" ""的なデプロイメントやテスト環境を設定する方は、制御に関する制約が少なくて済む"" ""でしょう。"" msgid """" ""The privacy and isolation of data has consistently been cited as the primary "" ""barrier to cloud adoption over the past few years. Concerns over who owns "" ""data in the cloud and whether the cloud operator can be ultimately trusted "" ""as a custodian of this data have been significant issues in the past."" msgstr """" ""データのプライバシーと分割は、ここ数年クラウド採用の最初の障壁としてずっと言"" ""及されてきました。クラウド中でデータを所有するのは誰か、このデータの管理人と"" ""してクラウドオペレータは結局信用できるのか否かという事は、これまで重要な問題"" ""でした。"" msgid """" ""The process doesn't end with a single external audit. Most certifications "" ""require continual compliance activities which means repeating the audit "" ""process periodically. We recommend integrating automated compliance "" ""verification tools into a cloud to ensure that it is compliant at all times. "" ""This should be in done in addition to other security monitoring tools. "" ""Remember that the goal is both security <emphasis>and</emphasis> compliance. "" ""Failing on either of these fronts will significantly complicate future "" ""audits."" msgstr """" ""このプロセスは一度の外部監査で終わることがありません。多くの認証は継続的なコ"" ""ンプライアンス活動、すなわち、定期的な監査を要求します。わたしたちは、常に準"" ""拠を確実にするために、自動化されたコンプライアンス検証ツールをクラウド内に作"" ""ることをおすすめします。これは他のセキュリティ監視ツールに加え実装されるべき"" ""です。このゴールがセキュリティ<emphasis>および</emphasis>コンプライアンスであ"" ""ることを忘れないでください。これらのどちらかに不具合があれば、将来の監査にお"" ""いて非常に面倒なことになります。"" msgid """" ""The public security domain is an entirely untrusted area of the cloud "" ""infrastructure. It can refer to the Internet as a whole or simply to "" ""networks over which you have no authority. Any data that transits this "" ""domain with confidentiality or integrity requirements should be protected "" ""using compensating controls."" msgstr """" ""パブリックのセキュリティドメインとは、クラウドインフラストラクチャーの中で完"" ""全に信頼できないエリアのことです。インターネット全体を指す場合や、単に権限を"" ""持たないネットワークを指す場合があります。機密性や完全性の要件を持つデータが"" ""このドメインを通過する場合には、補完コントロールを使用してこのデータを保護す"" ""る必要があります。"" msgid """" ""The security of Compute is critical for an OpenStack deployment. Hardening "" ""techniques should include support for strong instance isolation, secure "" ""communication between Compute sub-components, and resiliency of public-"" ""facing <glossterm>API</glossterm> endpoints."" msgstr """" ""OpenStack のデプロイメントでは、Compute のセキュリティが極めて重要となりま"" ""す。セキュリティ強化のテクニックには、頑強なインスタンスの隔離、Compute のサ"" ""ブコンポーネント間におけるセキュアな通信、一般向けの <glossterm>API</"" ""glossterm> エンドポイントの弾力性などがあげられます。"" msgid """" ""The selection and configuration of a host-based intrusion detection tool is "" ""highly deployment specific. We recommend starting by exploring the following "" ""open source projects which implement a variety of host-based intrusion "" ""detection and file monitoring features."" msgstr """" ""ホストベースの侵入検知ツールの選択と設定はデプロイメントによって大幅に異なり"" ""ます。多様なホストベースの侵入検知/ファイル監視機能を実装する以下のオープン"" ""ソースプロジェクトの検討から開始することをお勧めします。"" msgid """" ""The server certificate, key, and certificate authority (CA) files should be "" ""placed in the $PGDATA directory in the following files:"" msgstr """" ""サーバー証明書、鍵、認証局 (CA) のファイルを $PGDATA ディレクトリの以下のファ"" ""イルに置く必要があります。"" msgid """" ""The system administrator can define a rule base to restrict auditing to the "" ""events they are interested in. This includes the ability to restrict "" ""auditing to specific events, specific users, specific objects or a "" ""combination of all of this."" msgstr """" ""システム管理者は、関心のあるイベントに監査を制限するために、ルールベースを定"" ""義できます。これには、特定のイベント、特定のユーザー、特定のオブジェクトやこ"" ""れらすべての組み合わせに監査を制限する機能が含まれます。"" msgid """" ""The system and the hardware and firmware components are required to be "" ""physically protected from unauthorized access. The system kernel mediates "" ""all access to the hardware mechanisms themselves, other than program visible "" ""CPU instruction functions."" msgstr """" ""システム、ハードウェア、ファームウェアのコンポーネントは、権限のないアクセス"" ""から物理的に保護される必要があります。システムカーネルは、プログラムから利用"" ""できる CPU 命令ファンクション以外に、ハードウェア機構自身へのすべてのアクセス"" ""を調停します。"" msgid """" ""The system documentation for an OpenStack cloud deployment should follow the "" ""templates and best practices for the Enterprise Information Technology "" ""System in your organization. Organizations often have compliance "" ""requirements which may require an overall System Security Plan to inventory "" ""and document the architecture of a given system. There are common challenges "" ""across the industry related to documenting the dynamic cloud infrastructure "" ""and keeping the information up-to-date."" msgstr """" ""OpenStack クラウドデプロイメントのシステム文書化は、その組織のエンタープライ"" ""ズ IT システムを対象とするテンプレートとベストプラクティスに従って行うべきで"" ""す。組織には大抵、コンプライアンス要件が設定されており、それによって対象シス"" ""テムのインベントリ作成とアーキテクチャの文書化を行う全体的なシステムセキュリ"" ""ティ計画が義務付けられている場合があります。動的なクラウドインフラストラク"" ""チャーを文書化し、情報を最新の状態に維持するのあたっては、業界全体の共通課題"" ""があります。 "" msgid """" ""The system includes the ext4 file system, which supports POSIX ACLs. This "" ""allows defining access rights to files within this type of file system down "" ""to the granularity of a single user."" msgstr """" ""システムは POSIX ACL をサポートする ext4 ファイルシステムを含みます。この種類"" ""のファイルシステムにあるファイルにユーザー単位でアクセス権を定義できます。"" msgid """" ""The system provides the capability to audit a large number of events "" ""including individual system calls as well as events generated by trusted "" ""processes. Audit data is collected in regular files in ASCII format. The "" ""system provides a program for the purpose of searching the audit records."" msgstr """" ""システムは、個々のシステムコールを含む大多数のイベントおよび信頼されたプロセ"" ""スにより生成されたイベントを監査する機能を提供します。監査データは通常のファ"" ""イルに ASCII 形式で収集されます。システムは、監査レコードを検索するためのプロ"" ""グラムを提供します。"" msgid """" ""The system supports encrypted block devices to provide storage "" ""confidentiality via dm_crypt."" msgstr """" ""システムは dm_crypt 経由でストレージの機密性を提供するために暗号化ブロックデ"" ""バイスを提供します。"" msgid """" ""The system supports the definition of trusted channels using SSH. Password "" ""based authentication is supported. Only a restricted number of cipher suites "" ""are supported for those protocols in the evaluated configuration."" msgstr """" ""システムは SSH を使用する信頼チャネルの定義をサポートします。パスワードによる"" ""認証がサポートされます。少しの暗号スイートのみが、評価された設定でそれらのプ"" ""ロトコルのためにサポートされます。"" msgid """" ""The team converged in Annapolis, MD due to the close proximity of some key "" ""members of the group. This was a remarkable collaboration between public "" ""sector intelligence community members, silicon valley startups and some "" ""large, well-known technology companies. The book sprint ran during the last "" ""week in June 2013 and the first edition was created in five days."" msgstr """" ""チームは、グループの主要なメンバーが集まるために、メリーランド州アナポリスに"" ""集まりました。これは、公共部門のインテリジェンス・コミュニティーのメンバー、"" ""シリコンバレーのスタートアップ、いくつかの有名な大手技術企業の間での驚くべき"" ""コラボレーションです。Book Sprint は 2013 年 6 月の最終週に行われ、初版は 5 "" ""日間で作成されました。"" msgid ""The team included:"" msgstr ""チームメンバーは以下のとおりです。"" msgid """" ""The trust level of this network is heavily dependent on deployment decisions "" ""and as such we do not assign this any default level of trust."" msgstr """" ""このネットワークの信頼レベルは、デプロイメントの意思決定により左右されるた"" ""め、デフォルトの信頼レベルは割り当てていません。"" msgid """" ""The two broadly defined types of nodes that generally make up an OpenStack "" ""installation are:"" msgstr """" ""通常 OpenStack のインストールを構成している、広く定義された 2 つのノードタイ"" ""プは次のとおりです。"" msgid """" ""There are a few important security considerations for network and host-based "" ""intrusion detection systems."" msgstr """" ""ネットワークおよびホストベースの侵入検知システムには、いくつかの重要なセキュ"" ""リティ課題があります。"" msgid """" ""There are a number of standard activities that will greatly assist with the "" ""compliance process. In this chapter we outline some of the most common "" ""compliance activities. These are not specific to OpenStack, however we "" ""provide references to relevant sections in this book as useful context."" msgstr """" ""コンプライアンスのプロセスを大きく推進する、標準的な活動は数多くあります。こ"" ""の章ではいくつかの代表的なコンプライアンス活動を紹介します。これらはOpenStack"" ""固有ではありませんが、関係がわかるよう、このガイドの関連する節への参照も記載"" ""します。"" msgid """"""There are four main services that interact with OpenStack Networking. In a "" ""typical OpenStack deployment these services map to the following security "" ""domains:""""OpenStack Networking と交信する主要なサービスが４つあります。典型的な "" ""OpenStack デプロイでは、これらのサービスは以下のセキュリティドメインにマッピ"" ""ングされます。""""There are many configuration management solutions; at the time of this "" ""writing there are two in the marketplace that are robust in their support of "" ""OpenStack environments: <glossterm>Chef</glossterm> and <glossterm>Puppet</"" ""glossterm>. A non-exhaustive listing of tools in this space is provided "" ""below:""""構成管理ソリューションは多数存在しますが、本書の作成時点で市場にあるソリュー"" ""ションで OpenStack 環境のサポートが強力なものは <glossterm>Chef</glossterm> "" ""と <glossterm>Puppet</glossterm> の 2 種類となっています。以下に完全ではあり"" ""ませんが、ツールのリストを示しています。""""There are no general provisions for granular control of database operations "" ""in OpenStack. Access and privileges are granted simply based on whether a "" ""node has access to the database or not. In this scenario, nodes with access "" ""to the database may have full privileges to DROP, INSERT, or UPDATE "" ""functions.""""OpenStack には、データベース操作の詳細な制御に関する一般的な決まりがありませ"" ""ん。アクセス権と権限は単にノードがデータベースにアクセスするかしないかに基づ"" ""いて与えられます。このシナリオでは、データベースにアクセスするノードは、"" ""DROP、INSERT、UPDATE 関数の完全な権限を持っているでしょう。""""There are several methods to mitigate some of the risk associated with live "" ""migrations, the following list details some of these:""""ライブマイグレーションに関連するリスクを軽減するためには様々な手法がありま"" ""す。次のリストで詳しく説明します。"" msgid ""There are two types of SOC 1 reports:"" msgstr ""SOC 1報告書には二つの種類があります。"" msgid ""There are two types of SOC 2 reports:"" msgstr ""SOC 2報告書には二つの種類があります。""""There is an <link href=\""https://bugs.launchpad.net/ossn/"" ""+bug/1155566\"">OpenStack Security Note (OSSN) regarding potential DoS "" ""attacks</link>.""""<link href=\""https://bugs.launchpad.net/ossn/+bug/1155566\"">潜在的な DoS 攻撃"" ""に関する OpenStack Security Note (OSSN)</link> があります。""""There is an <link href=\""https://bugs.launchpad.net/ossn/"" ""+bug/1168252\"">OpenStack Security Note (OSSN) regarding keystone.conf "" ""permissions</link>.""""<link href=\""https://bugs.launchpad.net/ossn/+bug/1168252\"">keystone.conf の"" ""パーミッションに関する OpenStack Security Note (OSSN)</link> があります。"" msgid """" ""There is an OpenStack Security Note pertaining to the <link href=\""https://"" ""bugs.launchpad.net/ossn/+bug/1098582\"">use of LXC in Compute</link>."" msgstr """" ""<link href=\""https://bugs.launchpad.net/ossn/+bug/1098582\"">use of LXC in "" ""Compute</link> に関する OpenStack Security Note があります。"" msgid """" ""These control mappings will help identify common control criteria across "" ""certifications, and provide visibility to both auditors and auditees on "" ""problem areas within control sets for particular compliance certifications "" ""and attestations."" msgstr """" ""これらのコントロールマッピングは、認証間で共通の統制基準を特定します。また、"" ""監査人と被監査者両方にとって問題となる、特定のコンプライアンス認証、認定に必"" ""要なコントロールセットを可視化するのに役立ちます。"" msgid ""These include:"" msgstr ""これらは以下のものが含まれます。"" msgid """" ""This abstraction offers the advantage of restricting services to executing "" ""methods with parameters, similar to stored procedures, preventing a large "" ""number of systems from directly accessing or modifying database data. This "" ""is accomplished without having these procedures stored or executed within "" ""the context or scope of the database itself, a frequent criticism of typical "" ""stored procedures."" msgstr """" ""この抽象化は、サービスがパラメーター、ストアドプロシージャーのようなものを用"" ""いたメソッドの実行を制限し、数多くのシステムがデータベースのデータに直接アク"" ""セスしたり変更したりすることを防ぐという利点を提供します。これは、一般的なス"" ""トアドプロシージャーという頻繁に批判される、データベース自体の文脈や範囲の中"" ""で、これらの手順を保存して実行することなく実現されます。"" msgid """" ""This book provides best practices and conceptual information about securing "" ""an OpenStack cloud."" msgstr """" ""本書は OpenStack クラウドを安全にするためのベストプラクティスと基本的な考え方"" ""について書かれています。"" msgid ""This chapter has several objectives:"" msgstr ""この章の目的は以下の通りです。"" msgid ""This domain should always be considered <emphasis>untrusted</emphasis>."" msgstr """" ""このドメインは常に、<emphasis>信頼できない</emphasis>と考えなければなりませ"" ""ん。 "" msgid """" ""This ensures that placement of both code and data regions will be "" ""randomized. Enabled by the kernel (all modern Linux kernels support ASLR), "" ""when the executable is built with PIE."" msgstr """" ""コード領域とデータ領域の配置を確実にランダム化します。実行ファイルが PIE を用"" ""いてビルドされるとき、カーネルにより有効化されます (最近の Linux カーネルはす"" ""べて ASLR をサポートします)。"" msgid ""This example shows the sVirt category identifier:"" msgstr ""この例は sVirt カテゴリー識別子を示します。"" msgid """" ""This guide focuses on a standard architecture that includes a "" ""<emphasis>cloud controller</emphasis> host, a <emphasis>network</emphasis> "" ""host, and a set of <emphasis>compute</emphasis> hypervisors for running VMs."" msgstr """" ""このガイドは、<emphasis>クラウドコントローラ</emphasis>ホスト１台、<emphasis>"" ""ネットワーク</emphasis>ホスト１台、VMを実行する<emphasis>compute</emphasis>ハ"" ""イパーバイザーの集合を含む標準的なアーキテクチャにフォーカスします。"" msgid """" ""This guide refers to two running case studies, which are introduced here and "" ""referred to at the end of each chapter."" msgstr """" ""本ガイドでは、全体を通して、2 つの運用事例を参照しています。ここでは、これら"" ""を概要を説明し、各章末で参照します。"" msgid """" ""This is the formal audit process. Auditors will test security controls in "" ""scope for a specific certification, and demand evidentiary requirements to "" ""prove that these controls were also in place for the audit window (for "" ""example SOC 2 audits generally evaluate security controls over a 6-12 months "" ""period). Any control failures are logged, and will be documented in the "" ""external auditors final report. Dependent on the type of OpenStack "" ""deployment, these reports may be viewed by customers, so it is important to "" ""avoid control failures. This is why audit preparation is so important."" msgstr """" ""これが正式な監査プロセスです。監査人は、特定の認定向けのセキュリティ統制を確"" ""認し、これらの統制が監査期間において整っているか証明する根拠を要求します (た"" ""とえば、SOC 2監査は一般的に6-12ヶ月のセキュリティ統制を評価します)。どのよう"" ""な統制上の不具合も記録され、外部監査の最終報告書で文書化されます。OpenStack環"" ""境の種別に依存しますが、これらの報告書は顧客に公開されるでしょう。それゆえ統"" ""制上の不具合を避けることは重要です。これが監査への準備が重要であることの理由"" ""です。"" msgid ""This process is broken apart into three primary categories:"" msgstr ""このプロセスは三つの主要カテゴリに分割されています。"" msgid """" ""This recommendation provides insulation from brute force, social "" ""engineering, and both spear and mass phishing attacks that may compromise "" ""administrator passwords."" msgstr """" ""このお勧めの方式は、管理者パスワードを流出させる可能性のある、総当たり、ソー"" ""シャルエンジニアリング、標的型と無差別のフィッシング攻撃に対する防御になりま""""This section discusses OpenStack Networking configuration best practices as "" ""they apply to tenant network security within your OpenStack deployment.""""この章では、あなたの OpenStack デプロイの中でテナントネットワークセキュリティ"" ""を適用する為に、OpenStack Networking の設定のベストプラクティスについて議論し"" ""ます。""""This section is a high-level overview of what processes and best practices "" ""should be considered when implementing OpenStack Networking. We will talk "" ""about the current state of services that are available, what future services "" ""will be implemented, and the current limitations in this project.""""本項には、OpenStack Networking を実装する際に検討すべきプロセスとベストプラク"" ""ティスについての大まかな概要をまとめています。提供されているサービスの現在の"" ""状況 、将来実装されるサービス、本プロジェクトにおける現在の制限事項などについ"" ""て説明します。""""This service runs on the network node to service the Networking API and its "" ""extensions. It also enforces the network model and IP addressing of each "" ""port. The neutron-server and plugin agents require access to a database for "" ""persistent storage and access to a message queue for inter-communication.""""このサービスはネットワークノード上で実行され、Networking API とその拡張を提供"" ""します。これはまた、各ポートのネットワークモデルと IP アドレスを管理します。"" ""neutron-server とプラグインエージェントは、永続ストレージ用のデータベースへの"" ""アクセスと、内部通信用のメッセージキューへのアクセスを要求します。""""This table illustrates a generic approach to measuring the impact of a "" ""vulnerability based on where it occurs in your deployment and the effect. "" ""For example, a single level privilege escalation on a Compute API node "" ""potentially allows a standard user of the API to escalate to have the same "" ""privileges as the root user on the node.""""この表は、デプロイメントの発生箇所や影響をもとに脆弱性から受ける影響レベルを"" ""測定するための一般的な手法を示しています。例えば、Compute API ノードで権限レ"" ""ベルを 1 つ昇格すると、API の標準ユーザーはこのノード上の root ユーザーと同等"" ""の権限にまで昇格することが可能です。"" msgid """" ""Those deploying MySQL or PostgreSQL are advised to refer to existing "" ""security guidance. Some references are listed below:"" msgstr """" ""MySQL や PostgreSQL を導入する人は、既存のセキュリティガイダンスを参照するこ"" ""とが推奨されます。いくつかの参考資料を以下に一覧化します。"" msgid ""Threat actors"" msgstr ""脅威のアクター"" msgid ""Threat classification, actors and attack vectors"" msgstr ""脅威の分類、アクター、攻撃ベクトル"" msgid ""Timeliness and availability of updates"" msgstr ""タイムラインとアップデートの入手先"" msgid """" ""To aid OpenStack architects in the protection of personal data, it is "" ""recommended that OpenStack architects review the NIST publication 800-122, "" ""titled \""<emphasis>Guide to Protecting the Confidentiality of Personally "" ""Identifiable Information (PII)</emphasis>.\"" This guide steps through the "" ""process of protecting:"" msgstr """" ""個人情報の保護に取り組むOpenStackアーキテクトを支援するため、OpenStackアーキ"" ""テクトには、NIST刊行 800-122 \""<emphasis>Guide to Protecting the "" ""Confidentiality of Personally Identifiable Information (PII)</emphasis>.をお"" ""すすめします。このガイドは以下を保護するプロセスについて述べています。"" msgid """" ""To disable the <systemitem class=\""service\"">nova-conductor</systemitem>, "" ""place the following into your <filename>nova.conf</filename> file (on your "" ""compute hosts):"" msgstr """" ""<systemitem class=\""service\"">nova-conductor</systemitem> を無効化するため"" ""に、以下の事項を (コンピュートホストの) <filename>nova.conf</filename> ファイ"" ""ルに記入します。"" msgid """" ""To ease scaling and reduce management overhead Bob implements a "" ""configuration management system. For customer data assurances, Bob offers a "" ""backup as a service product as requirements will vary between customers. "" ""Finally, Bob does not provide a \""baremetal\"" or the ability to schedule an "" ""entire node, so to reduce management overhead and increase operational "" ""efficiency Bob does not implement any node boot time security."" msgstr """" ""管理オーバーヘッドのスケーリングや削減を簡単にするため、構成管理システムを実"" ""装します。顧客のデータ保証に対しては、顧客ごとに要件が変わるためサービス商品"" ""としてバックアップを提供します。最後に、「ベアメタル」やノード全体のスケ"" ""ジュール機能を提供せず、管理オーバーヘッドの削減、運用効率の向上を図るため、"" ""ノードのブート時におけるセキュリティは実装しません。"" msgid """" ""To ease the administrative burden of managing SELinux, many enterprise Linux "" ""platforms utilize SELinux Booleans to quickly change the security posture of "" ""sVirt."" msgstr """" ""SELinux の管理負担を減らすために、多くのエンタープライズ Linux プラットフォー"" ""ムは sVirt のセキュリティ設定を簡単に変更するために、SELinux ブーリアンを利用"" ""します。"" msgid """" ""To enforce policies, you can configure services, host-based firewalls (such "" ""as iptables), local policy (SELinux or AppArmor), and optionally global "" ""network policy."" msgstr """" ""ポリシーを強制するために、サービス、ホストベースのファイアウォール(例えば"" ""iptables)、ローカルポリシー(SELinuxやAppArmor)、オプションとしてグローバル"" ""ネットワークポリシーを設定できます。"" msgid """" ""To isolate sensitive data communication between the OpenStack Networking "" ""services and other OpenStack core services, configure these communication "" ""channels to only allow communication over an isolated management network."" msgstr """" ""OpenStack Networking サービスと他の OpenStack コアサービス間の扱いの難しい"" ""データ通信を分離する為、通信を独立した管理ネットワーク上でのみ行うように通信"" ""路を設定します。"" msgid """" ""To isolate sensitive database communications between the services and the "" ""database, we strongly recommend that the database server(s) be configured to "" ""only allow communications to and from the database over an isolated "" ""management network. This is achieved by restricting the interface or IP "" ""address on which the database server binds a network socket for incoming "" ""client connections."" msgstr """" ""サービスとデータベース間の機微なデータベース通信を隔離するために、データベー"" ""スサーバーが隔離された管理ネットワーク経由のみでデータベースと通信できるよう"" ""に設定することを強く推奨します。データベースサーバーがクライアントからの通信"" ""用のネットワークソケットをバインドするインターフェースまたは IP アドレスを制"" ""限することにより、これを実現できます。"" msgid """" ""To meet these strict government regulations Alice undertakes a number of "" ""activities. Scoping of requirements is particularly important due to the "" ""volume of controls that must be implemented, which will be defined in NIST "" ""Publication 800-53."" msgstr """" ""これらの厳しい政府規制の要件を満たすため、アリスは多くの活動を行います。範囲"" ""の決定作業は、実装すべき統制の量に影響するため、特に重要です。これはNIST刊行 "" ""800-53で定められています。"" msgid """" ""To provide a community driven facility for knowledge capture and "" ""dissemination"" msgstr ""コミュニティ主導のナレッジ蓄積と普及の場の提供"" msgid """" ""To provide secure ephemeral instance storage, Alice implements qcow2 files "" ""on an encrypted filesystem."" msgstr """" ""安全な一時ディスクを提供するために、アリスは暗号化ファイルシステム上に qcow2 "" ""のファイルを実装しています。"" msgid """" ""To provide secure ephemeral instance storage, Bob implements qcow2 files on "" ""an encrypted filesystems."" msgstr """" ""安全な一時ディスクを提供するために、ボブは暗号化ファイルシステム上に qcow2 の"" ""ファイルを実装しています。"" msgid ""To register an internal URL for an endpoint:"" msgstr ""エンドポイント用の内部URL登録"" msgid """" ""To restrict the interface or IP address on which the OpenStack Networking "" ""API service binds a network socket for incoming client connections, specify "" ""the bind_host and bind_port in the neutron.conf file as shown:"" msgstr """" ""OpenStack Networking API サービスが外からのクライアント通信用にネットワークソ"" ""ケットをバインドするネットワークインターフェース又は IP アドレスを制限する"" ""為、neutron.conf ファイル中の bind_host と bind_port を以下のように指定しま"" ""す。"" msgid """" ""To secure OpenStack Networking, you must understand how the workflow process "" ""for tenant instance creation needs to be mapped to security domains."" msgstr """" ""OpenStack Networking のセキュリティを強化する為に、どの程度テナントインスタン"" ""ス作成用のワークフロープロセスをセキュリティドメインにマッピングさせる必要が"" ""あることを理解しなくてはいけません。"" msgid """" ""To the cloud administrator, the API provides an overall view of the size and "" ""state of the cloud deployment and allows the creation of users, tenants/"" ""projects, assigning users to tenants/projects, and specifying resource "" ""quotas on a per tenant/project basis."" msgstr """" ""API はクラウド管理者がクラウドデプロイメントのサイズや状態の概要を把握できる"" ""ようにするだけでなく、ユーザー、プロジェクトの作成、プロジェクトへのユーザー"" ""の割り当て、プロジェクトベースのリソースクォータの指定などができるようにしま"" ""す。"" msgid ""Tokens"" msgstr ""トークン"" msgid ""Total security in a PostgreSQL database"" msgstr ""Total security in a PostgreSQL database"" msgid """" ""Track the destruction of both the customer data and metadata through "" ""ticketing in a CMDB."" msgstr """" ""CMDBのチケット発行を使用して、顧客データとメタデータの両方の破壊を追跡しま"" ""す。"" msgid """" ""Track the destruction of both the tenant data and metadata through ticketing "" ""in a CMDB."" msgstr """" ""CMDBのチケット発行を使用して、顧客データとメタデータの両方の破壊を追跡する。"" msgid ""Track, document and verify media sanitization and disposal actions."" msgstr ""媒体サニタイズと破棄行為の追跡・文書化・検証を行うこと。"" msgid ""Traffic shaping through DSCP markings"" msgstr ""DSCP マーキングによるトラフィックシェーピング"" msgid ""Transfer memory"" msgstr ""メモリを転送"" msgid ""Transfer state"" msgstr ""転送状態となる"" msgid ""Triage"" msgstr ""トリアージ"" msgid ""Tripwire"" msgstr ""Tripwire"" msgid ""Trusted images"" msgstr ""信頼されたイメージ"" msgid """" ""Trusted processes for managing the life cycle of disk images are required, "" ""as are all the previously mentioned issues with respect to data security."" msgstr """" ""前述したデータセキュリティに関する問題と同様に、ディスクイメージのライフサイ"" ""クル管理には信頼されたプロセスが必要です。"" msgid ""Twofish"" msgstr ""Twofish"" msgid ""Type"" msgstr ""種別"" msgid """" ""Type 1 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design of the controls to achieve the related control objectives included in "" ""the description as of a specified date."" msgstr """" ""Type 1 - サービス提供組織がその管理について説明し、その公正さをレポートしま"" ""す。特定時点で関連する管理対象を統制できているか、その設計の持続可能性も報告"" ""します。"" msgid """" ""Type 2 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design and operating effectiveness of the controls to achieve the related "" ""control objectives included in the description throughout a specified period"" msgstr """" ""Type 2 - サービス組織が統制対象を統制するために使用するシステム、設計の持続"" ""性、および運用効率性に関する管理者の説明内容が公正かをレポートします。特定期"" ""間を通しての説明も必要です。"" msgid """" ""Type 2 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design and operating effectiveness of the controls to achieve the related "" ""control objectives included in the description throughout a specified period."" msgstr """" ""Type 2 - サービス組織が統制対象を統制するために使用するシステム、設計の持続"" ""性、および運用効率性に関する管理者の説明内容が公正かをレポートします。特定期"" ""間を通しての説明も必要です。"" msgid """" ""Typically this is achieved through Copy-On-Write (COW) mechanisms. These "" ""mechanisms have been shown to be vulnerable to side-channel attacks where "" ""one VM can infer something about the state of another and might not be "" ""appropriate for multi-tenant environments where not all tenants are trusted "" ""or share the same levels of trust."" msgstr """" ""これは一般的に、Copy-On-Write (COW) 機構により実現されます。これらの機構は、"" ""ある仮想マシンが別の仮想マシンの状態に関する何かに影響する可能性がある、サイ"" ""ドチャネル攻撃に脆弱なため、必ずしもすべてのテナントが信頼できず、同じ信頼レ"" ""ベルを共有できないようなマルチテナント環境に適していません。"" msgid """" ""Typically used for compute instance-to-instance traffic, the guest security "" ""domain handles compute data generated by instances on the cloud but not "" ""services that support the operation of the cloud, such as API calls."" msgstr """" ""ゲストのセキュリティドメインは、Compute のインスタンス間通信に通常使用されま"" ""すが、API の呼び出しなどクラウドのオペレーションをサポートするサービスではな"" ""く、クラウド上のインスタンスが生成する Compute データを処理します。"" msgid """" ""Typically, when an SSH daemon is installed, host keys will be generated. It "" ""is necessary that the hosts have sufficient entropy during host key "" ""generation. Insufficient entropy during host key generation can result in "" ""the possibility to eavesdrop on SSH sessions."" msgstr """" ""通常、SSH デーモンがインストールされると、ホストキーが生成されます。ホスト"" ""キーの生成時に、ホストには十分なエントロピーが必要になります。ホストキーの生"" ""成時にエントロピーが十分にないと、SSH セッションの傍受が発生してしまう可能性"" ""があります。"" msgid ""U.S. NIST FIPS PUB 186-3"" msgstr ""U.S. NIST FIPS PUB 186-3"" msgid """" ""US Export restrictions on cryptography systems have been lifted and no "" ""longer need to be supported."" msgstr """" ""暗号システムにおけるアメリカ輸出規制を解かれていて、もはやサポートする必要が"" ""ありません。"" msgid ""Understanding the audit process"" msgstr ""監査プロセスを理解する"" msgid """" ""Unfortunately, it is not currently possible to force Compute to validate an "" ""image hash immediately prior to starting an instance. To understand the "" ""situation, we begin with a brief overview of how images are handled around "" ""the time of image launch."" msgstr """" ""残念ながら、現在はインスタンス起動直前にコンピュートにイメージのハッシュを検"" ""証を強制する方法がありません。状況を理解するために、イメージ起動の際にイメー"" ""ジがどのように扱われるのかを簡単に説明します。"" msgid """" ""Unfortunately, this solution complicates the task of more fine-grained "" ""access control and the ability to audit data access. Because the <systemitem "" ""class=\""service\"">nova-conductor</systemitem> service receives requests over "" ""RPC, it highlights the importance of improving the security of messaging. "" ""Any node with access to the message queue may execute these methods provided "" ""by the <systemitem class=\""service\"">nova-conductor</systemitem> and "" ""effectively modifying the database."" msgstr """" ""残念なことに、このソリューションはより詳細なアクセス制御とデータアクセスの監"" ""査機能を複雑にします。<systemitem class=\""service\"">nova-conductor</"" ""systemitem> サービスは RPC 経由でリクエストを受信するため、メッセージングのセ"" ""キュリティを改善する重要性を強調させます。メッセージキューにアクセスするすべ"" ""てのノードは、<systemitem class=\""service\"">nova-conductor</systemitem> によ"" ""り提供されるこれらの方式を実行し、データベースを効率的に変更するかもしれませ"" ""ん。"" msgid ""Upgrading"" msgstr ""アップグレード"" msgid """" ""Use a dedicated and hardened backup servers. The logs for the backup server "" ""must be monitored daily and accessible by only few individuals."" msgstr """" ""セキュリティが強化された専用のバックアップサーバーを使用すること。バックアッ"" ""プサーバーのログは日次で監査し、ほんの一握りの人だけがこのログにアクセスでき"" ""るようにしなければいけません。"" msgid """" ""Use a mandatory access control policy to contain the instances, the node "" ""services, and any other critical processes and data on the node. See the "" ""discussions on sVirt / SELinux and AppArmor below."" msgstr """" ""強制アクセス制御ポリシーを使用して、インスタンス、ノードサービス、その他の重"" ""要なプロセスおよびノード上のデータが含まれるようにします。以下に記載の "" ""sVirt / SELinux および AppArmor についての説明を参照してください。""""Use both mandatory access controls (MACs) and discretionary access controls "" ""(DACs) to restrict the configuration for processes to only those processes. "" ""This restriction prevents these processes from being isolated from other "" ""processes that run on the same machine(s).""""強制アクセス制御と任意アクセス制御を併用して、プロセスの設定をそれらのプロセ"" ""スのみに制限します。この制限により、これらのプロセスが、同じマシンで動作して"" ""いる他のプロセスから分離されることを防ぎます。"" msgid ""Use data encryption options for storage and transmission of backups."" msgstr ""バックアップの保存や送信にはデータ暗号化オプションを使用すること""""Used for VM data communication within the cloud deployment. The IP "" ""addressing requirements of this network depend on the OpenStack Networking "" ""plug-in in use and the network configuration choices of the virtual networks "" ""made by the tenant. This network is considered the Guest Security Domain.""""クラウドデプロイ中の VM データ通信に使用されます。このネットワークの IP アド"" ""レス要件は、使用中の OpenStack Networking プラグインとテナントにより作成され"" ""る仮想ネットワークのネットワーク設定の選定に依存します。このネットワークはゲ"" ""ストセキュリティドメインで検討します。""""Used for internal communication between OpenStack Components. The IP "" ""addresses on this network should be reachable only within the data center "" ""and is considered the Management Security Domain.""""OpenStack コンポーネント間の内部通信に使用されます。このネットワークの IP ア"" ""ドレスはデータセンター内でのみ到達可能であるべきです。管理セキュリティドメイ"" ""ンで検討します。"" msgid ""User's \""Real Name\"""" msgstr ""ユーザの「実名」"" msgid ""User, process, or system that is the subject of a certificate."" msgstr ""証明対象のユーザ、プロセス、システム。""""Users or organizations that possess PHI must support HIPAA requirements and "" ""are HIPAA covered entities. If an entity intends to use a service, or in "" ""this case, an OpenStack cloud that might use, store or have access to that "" ""PHI, then a Business Associate Agreement must be signed. The BAA is a "" ""contract between the HIPAA covered entity and the OpenStack service provider "" ""that requires the provider to handle that PHI in accordance with HIPAA "" ""requirements. If the service provider does not handle the PHI, such as with "" ""security controls and hardening, then they are subject to HIPAA fines and "" ""penalties.""""カルテ情報を所有するユーザーや組織はHIPPAの要件をサポートし、HIPAA対象事業者"" ""となる必要があります。もしこの事業者がサービスを、この場合は対象のOpenStackク"" ""ラウドがカルテ情報を利用、保存、アクセスしうるのであれば、HIPAA Business "" ""Associate Agreement - BAAの締結が必要です。BAAはHIPAA対象事業者と、HIPAA要件"" ""に従ってカルテ情報を扱っているOpenStackサービスプロバイダーの間で締結されま"" ""す。もしサービスプロバイダーがセキュリティ統制、強化を怠るなど、カルテ情報を"" ""要件通りに扱っていなければHIPAAの罰金や罰則が適用されることがあります。""""VLAN configuration complexity depends on your OpenStack design requirements. "" ""In order to allow OpenStack Networking to efficiently use VLANs, you must "" ""allocate a VLAN range (one for each tenant) and turn each compute node "" ""physical switch port into a VLAN trunk port.""""VLAN 設定の複雑さはあなたの OpenStack 設計要件に依存します。OpenStack "" ""Networking がVLAN を効率良く使用できるようにする為に、VLAN 範囲を (各テナント"" ""に１つ) 割り当てて、各 compute ノードの物理スイッチポートを VLAN トランクポー"" ""トに変更する必要があります。"" msgid ""VLANs"" msgstr ""VLAN""""VLANs are realized as packets on a specific physical network containing IEEE "" ""802.1Q headers with a specific VLAN ID (VID) field value. VLAN networks "" ""sharing the same physical network are isolated from each other at L2, and "" ""can even have overlapping IP address spaces. Each distinct physical network "" ""supporting VLAN networks is treated as a separate VLAN trunk, with a "" ""distinct space of VID values. Valid VID values are 1 through 4094.""""VLAN は特別な VLAN ID (VID) フィールド値を持つ IEEE 802.1Q ヘッダを含む特別な"" ""物理ネットワーク上のパケットを実現します。同じ物理ネットワークを共有する "" ""VLAN ネットワーク群は、L2 において相互から独立しており、重複する IP アドレス"" ""空間を持つ事すら可能です。VLAN ネットワークに対応した各個別の物理ネットワーク"" ""は、独自の VID 値を持つ独立した VLAN トランクとして扱われます。有効な VID 値"" ""は1～4094です。"" msgid ""VT-c"" msgstr ""VT-c"" msgid ""VT-d / AMD-Vi"" msgstr ""VT-d / AMD-Vi""""Various components of the OpenStack Networking services use either the "" ""messaging queue or database connections to communicate with other components "" ""in OpenStack Networking.""""OpenStack Networking サービスの様々なコンポーネントは、OpenStack Networking "" ""中の他のコンポーネントとの通信にメッセージキュー又はデータベース接続のいずれ"" ""かを使用します。"" msgid ""Verified boot"" msgstr ""検証済みブート"" msgid ""Vibha Fauver"" msgstr ""Vibha Fauver""""Vibha Fauver, GWEB, CISSP, PMP, has over fifteen years of experience in "" ""Information Technology. Her areas of specialization include software "" ""engineering, project management and information security. She has a B.S. in "" ""Computer &amp; Information Science and a M.S. in Engineering Management with "" ""specialization and a certificate in Systems Engineering.""""Vibha Fauver (GWEB, CISSP, PMP) は情報技術に関する 15 年以上の経験がありま"" ""す。専門分野はソフトウェアエンジニアリング、プロジェクト管理と情報セキュリ"" ""ティです。Computer &amp; Information Science の B.S. と Engineering "" ""Management の M.S. を保持しています。Systems Engineering の資格を保持していま"" ""す。"" msgid ""Virtual Network Computer (VNC)"" msgstr ""Virtual Network Computer (VNC)"" msgid ""Virtual hardware (QEMU)"" msgstr ""仮想ハードウェア (QEMU)"" msgid ""Vulnerability management"" msgstr ""脆弱性管理""""We briefly introduce the kinds of clouds: private, public, and hybrid before "" ""presenting an overview of the OpenStack components and their related "" ""security concerns in the remainder of the chapter.""""本章では、プライベート、パブリック、ハイブリッドというクラウドの各種類につい"" ""て簡単に説明した後、後半に OpenStack のコンポーネントおよびそれらに関連するセ"" ""キュリティ課題について概説します。""""We define integrity life cycle as a deliberate process that provides "" ""assurance that we are always running the expected software with the expected "" ""configurations throughout the cloud. This process begins with secure "" ""bootstrapping and is maintained through configuration management and "" ""security monitoring. This chapter provides recommendations on how to "" ""approach the integrity life-cycle process.""""OpenStack では、完全性ライフサイクルを「クラウド全体にわたって想定されている"" ""ソフトウェアが想定されている設定で常に実行されることを保証する計画的なプロセ"" ""ス」と定義しています。このプロセスは、セキュアなブートストラッピングで開始"" ""し、設定管理およびセキュリティ監視の機能により維持されます。本章では、完全性"" ""ライフサイクルプロセスのアプローチ方法について説明します。""""We recommend testing your QEMU executable file after it is compiled to "" ""ensure that the compiler hardening worked properly.""""コンパイラーが確実に適切なセキュリティ強化を動作させるようコンパイルした後"" ""で、お使いの QEMU 実行ファイルをテストすることを推奨します。""""We recommend that implementers <link href=\""http://docs.openstack.org/"" ""developer/horizon/topics/deployment.html#file-uploads\"">disable "" ""HORIZON_IMAGES_ALLOW_UPLOAD</link> unless they have implemented a plan to "" ""prevent resource exhaustion and denial of service.""""導入者はリソース枯渇とサービス妨害を防ぐ計画を実装していなければ、<link href="" ""\""http://docs.openstack.org/developer/horizon/topics/deployment.html#file-"" ""uploads\"">HORIZON_IMAGES_ALLOW_UPLOAD を無効化</link> することを強く推奨しま"" ""す。"" msgid ""We strongly recommend:"" msgstr ""以下の事項を強く推奨します。"" msgid ""What is measured"" msgstr ""計測の対象""""When addressing compliance, you can increase efficiency and reduce work "" ""effort by identifying common areas and criteria that apply across multiple "" ""certifications. Much of the audit principles and guidelines discussed in "" ""this book will assist in identifying these controls, additionally a number "" ""of external entities provide comprehensive lists. The following are some "" ""examples:""""コンプライアンスに取り組む際、複数の認証で共通の領域と基準を明確にできれば、"" ""効率的に手間を減らすことができます。この本で取り上げている監査原則とガイドラ"" ""インの多くは、それらを特定するのに役立ちます。加えて、総合的なリストを提供す"" ""るガイドラインが多くあります。以下に例を挙げます。""""When auditing an OpenStack cloud it is important to appreciate the multi-"" ""tenant environment inherent in the OpenStack architecture. Some critical "" ""areas for concern include data disposal, hypervisor security, node "" ""hardening, and authentication mechanisms.""""OpenStackクラウドを監査するとき、OpenStackアーキテクチャ固有のマルチテナント"" ""環境を理解することが重要です。データの廃棄、ハイパーバイザーのセキュリティ、"" ""ノードの強化、および認証メカニズムなど、いくつか重要な部分があります。""""When building an OpenStack cloud it is strongly recommended to approach your "" ""design and implementation with a configuration management tool or framework "" ""in mind. Configuration management allows you to avoid the many pitfalls "" ""inherent in building, managing, and maintaining an infrastructure as complex "" ""as OpenStack. By producing the manifests, cookbooks, or templates required "" ""for a configuration management utility, you are able to satisfy a number of "" ""documentation and regulatory reporting requirements. Further, configuration "" ""management can also function as part of your business continuity plan (BCP) "" ""and data recovery (DR) plans wherein you can rebuild a node or service back "" ""to a known state in a DR event or given a compromise.""""OpenStack クラウドの構築時は、構成管理ツールまたはフレームワークを念頭に設"" ""計、実装に着手するように強く推奨します。構成管理により、OpenStack のように複"" ""雑なインフラストラクチャーの構築、管理、維持において陥りやすい多くの問題を回"" ""避することができます。構成管理ユーティリティに必要なマニフェスト、クックブッ"" ""ク、テンプレートを作成することで、多くの文書や監督機関へのレポート要件を満た"" ""すことができます。さらに、構成管理は、ビジネス継続性計画 (BCP) および災害復"" ""旧 (DR) プランの一部としても機能する可能性もあります。その場合、DR やセキュリ"" ""ティ侵害が合った場合にノードやサービスを既知の状態へ再構築することができま"" ""す。"" msgid """" ""When evaluating base hypervisor technologies, consider if the hypervisor has "" ""been certified against FIPS 140-2. Not only is conformance against FIPS "" ""140-2 mandated per U.S. Government policy, formal certification indicates "" ""that a given implementation of a cryptographic algorithm has been reviewed "" ""for conformance against module specification, cryptographic module ports and "" ""interfaces; roles, services, and authentication; finite state model; "" ""physical security; operational environment; cryptographic key management; "" ""electromagnetic interference/electromagnetic compatibility (EMI/EMC); self-"" ""tests; design assurance; and mitigation of other attacks."" msgstr """" ""ハイパーバイザーの基礎技術の評価時、ハイパーバイザーが FIPS 140-2 に認証され"" ""ているかどうかを考慮します。正式な認証は、指定された暗号アルゴリズムの実装"" ""が、アメリカ政府機関のポリシーごとに強制される FIPS 140-2 への適合性だけでは"" ""なく、モジュール仕様、暗号モジュールのポートとインターフェース、ロール、サー"" ""ビス、認証、有限オートマトン、物理セキュリティ、運用環境、暗号鍵管理、EMI/"" ""EMC、自己テスト、設計保証、他の攻撃の緩和に対する適合性をレビューされることを"" ""意味します。"" msgid """" ""When installing the certificate and key files, ensure that the file "" ""permissions are restricted, for example <placeholder-1/>, and the ownership "" ""is restricted to the database daemon user to prevent unauthorized access by "" ""other processes and users on the database server."" msgstr """" ""証明書と鍵ファイルをインストールするとき、ファイルのパーミッションが制限され"" ""ていることを確認します。たとえば、<placeholder-1/> を実行すると、データベース"" ""サーバー上の他のプロセスやユーザーによる権限のないアクセスを防ぐために、所有"" ""者がデータベースデーモンのユーザーに制限されます。"" msgid """" ""When running a virtual machine, virtual hardware is a software layer that "" ""provides the hardware interface for the virtual machine. Instances use this "" ""functionality to provide network, storage, video, and other devices that may "" ""be needed. With this in mind, most instances in your environment will "" ""exclusively use virtual hardware, with a minority that will require direct "" ""hardware access. The major open source hypervisors use QEMU for this "" ""functionality. While QEMU fills an important need for virtualization "" ""platforms, it has proven to be a very challenging software project to write "" ""and maintain. Much of the functionality in QEMU is implemented with low-"" ""level code that is difficult for most developers to comprehend. Furthermore, "" ""the hardware virtualized by QEMU includes many legacy devices that have "" ""their own set of quirks. Putting all of this together, QEMU has been the "" ""source of many security problems, including hypervisor breakout attacks."" msgstr """" ""仮想マシンの実行時、仮想ハードウェアは仮想マシンにハードウェアインターフェー"" ""スを提供するソフトウェア層です。インスタンスは必要となるネットワーク、スト"" ""レージ、ビデオ、他のデバイスを提供するためにこの機能を使用します。これで覚え"" ""ておくことは、お使いのほとんどのインスタンスは排他的に仮想ハードウェアを使用"" ""することです。一部はハードウェアに直接アクセスする必要があります。主要なオー"" ""プンソースのハイパーバイザーはこの機能のために QEMU を使用します。QEMU は仮想"" ""化プラットフォームのニーズを満たしますが、作成と維持することが非常に挑戦的な"" ""ソフトウェアプロジェクトであるとわかってきました。QEMU の機能のほとんどは、多"" ""くの開発者が理解しにくい低レベルなコードで実装されています。さらに、QEMU によ"" ""り仮想化されるハードウェアには、独自の癖を持つレガシーデバイスが数多くありま"" ""す。これを一括りにするので、QEMU はハイパーバイザー突破攻撃を含む多くのセキュ"" ""リティ問題の元になってきました。"" msgid """" ""When scoping OpenStack deployments for compliance purposes, consider "" ""prioritizing controls around sensitive services, such as command and control "" ""functions and the base virtualization technology. Compromises of these "" ""facilities may impact an OpenStack environment in its entirety."" msgstr """" ""OpenStack環境の範囲をコンプライアンス目的で明確化する際は、制御機能や仮想化技"" ""術など、慎重に扱うべきサービスの周辺を優先するよう、考慮すべきです。それらを"" ""妥協することは、OpenStack環境全体に影響を与えかねません。"" msgid """" ""When using LVM backed ephemeral storage, which is block-based, it is "" ""necessary that the OpenStack Compute software securely erases blocks to "" ""prevent information disclosure. There have in the past been information "" ""disclosure vulnerabilities related to improperly erased ephemeral block "" ""storage devices."" msgstr """" ""ブロックデバイスベースである LVM をバックエンドにした一時ストレージを使用する"" ""場合、OpenStack Compute は情報漏えいを防ぐために、安全にブロックを削除する必"" ""要があります。これらには、過去において、不適切な一時ブロックストレージデバイ"" ""スの削除に関連する情報漏洩の脆弱性がありました。"" msgid """" ""When using ZeroMQ messaging, each host must run at least one ZeroMQ message "" ""receiver to receive messages from the network and forward messages to local "" ""processes through IPC. It is possible and advisable to run an independent "" ""message receiver per project within an IPC namespace, along with other "" ""services within the same project."" msgstr """" ""ZeroMQ メッセージングを使用する場合、ネットワーク経由のメッセージ受信と、IPC"" ""経由によるローカルプロセスへのメッセージ送信のために、各ホストに最低 1 つの "" ""ZeroMQ メッセージレシーバーを走らせる必要があります。IPC 名前空間内にプロジェ"" ""クト毎で独立したメッセージレシーバーを構築することが可能であり望ましいです。"" ""また同様に、同一プロジェクト内でも異なるサービスごとに独立したメッセージレ"" ""シーバーを構築することが望ましいです。"" msgid """" ""When using ZeroMQ messaging, each project should run a separate ZeroMQ "" ""receiver process on a port dedicated to services belonging to that project. "" ""This is equivalent to the AMQP concept of control exchanges."" msgstr """" ""ZeroMQ を使用するのであれば、各プロジェクトで独立した専用のポート上で動作す"" ""る ZeroMQ レシーバープロセスを用意すべきです。これは、AMQP のコントロール "" ""exchange の概念に相当します。"" msgid """" ""When using the security group API through OpenStack Compute, security groups "" ""are applied to all virtual interface ports on an instance. The reason for "" ""this is that OpenStack Compute security group APIs are instance based and "" ""not virtual interface port based as OpenStack Networking."" msgstr """" ""OpenStack Compute のセキュリティグループ API を使用する場合、セキュリティグ"" ""ループは１インスタンス上の全仮想インターフェースポートに適用されます。この理"" ""由は、OpenStack Compute のセキュリティグループ API がインスタンスベースであ"" ""り、OpenStack Networking のような仮想インターフェースポートベースではないから"" ""です。"" msgid """" ""When you use a user name and password to authenticate, Identity does not "" ""enforce policies on password strength, expiration, or failed authentication "" ""attempts as recommended by NIST Special Publication 800-118 (draft). "" ""Organizations that desire to enforce stronger password policies should "" ""consider using Identity extensions or external authentication services."" msgstr """" ""認証のためにユーザー名とパスワードを使用する場合、Identity は NIST Special "" ""Publication 800-118 (draft) により推奨されている、パスワード強度、有効期限、"" ""ログイン試行回数制限に関するポリシーを強制できません。より強固なパスワードポ"" ""リシーを強制したい組織は、Identity 拡張や外部認証サービスの使用を検討すべきで"" ""す。"" msgid """" ""Where a rule may specify access to only admin users and users belonging to "" ""the tenant, the mapping may be trivial. In other scenarios the cloud "" ""administrator may need to approve the mapping routines per tenant."" msgstr """" ""ルールにより管理ユーザーとテナントに所属するユーザーのみにアクセス権を設定さ"" ""れるかもしれないため、マッピングは些細なことかもしれません。他のシナリオの場"" ""合、クラウド管理者がテナントごとのマッピング作業を承認する必要があるかもしれ"" ""ません。"" msgid """" ""Where the end entity certificates and certificate revocation lists are "" ""stored and looked up - sometimes referred to as the <emphasis role=\""italic"" ""\"">certificate bundle</emphasis>."" msgstr """" ""エンドエンティティが証明され、証明書の廃止リストが保存・参照される場所 - 時々"" ""<emphasis role=\""italic\"">証明バンドル(Certificate bundle)</emphasis>と呼ばれ"" ""ます。""""While OpenStack has a baremetal project, a discussion of the particular "" ""security implications of running baremetal is beyond the scope of this book."" msgstr """" ""OpenStack はベアメタルのプロジェクトを持ちますが、ベアメタル実行の具体的なセ"" ""キュリティ実装に関する議論は本書の範囲外です。"" msgid """" ""While in operation, the kernel software and data are protected by the "" ""hardware memory protection mechanisms. The memory and process management "" ""components of the kernel ensure a user process cannot access kernel storage "" ""or storage belonging to other processes."" msgstr """" ""動作中、カーネルソフトウェアとデータがハードウェアメモリ保護機構により保護さ"" ""れます。カーネルのメモリとプロセスの管理コンポーネントにより、ユーザープロセ"" ""スがカーネルストレージや他のプロセスのストレージにアクセスできないことが保証"" ""されます。"" msgid ""Why and how we wrote this book"" msgstr ""本書の作成理由と方法"" msgid """" ""With ZeroMQ messaging, IPC sockets are used on individual machines. Because "" ""these sockets are vulnerable to attack, ensure that the cloud operator has "" ""secured them."" msgstr """" ""ZeroMQ メッセージングでは、IPC ソケットが各マシンで使用されます。これらのソ"" ""ケットは管理者がセキュア化しない限り、ローカルメッセージインジェクションやス"" ""ヌーピングの攻撃に脆弱な可能性があります。"" msgid """" ""With unique kernel-level architecture and National Security Agency (NSA) "" ""developed security mechanisms, KVM provides foundational isolation "" ""technologies for multi-tenancy. With developmental origins dating back to "" ""2002, the Secure Virtualization (sVirt) technology is the application of "" ""SELinux against modern day virtualization. SELinux, which was designed to "" ""apply separation control based upon labels, has been extended to provide "" ""isolation between virtual machine processes, devices, data files and system "" ""processes acting upon their behalf."" msgstr """" ""KVM は複数のテナントを分離する基本技術を提供します。カーネルレベルの独特の"" ""アーキテクチャーを用いて、National Security Agency (NSA) により開発されたセ"" ""キュリティ機構です。開発の起源は 2002 年までさかのぼり、Secure "" ""Virtualization (sVirt) 技術は最近の仮想化向けの SELinux の応用技術です。"" ""SELinux は、ラベルに基づいた分離制御を適用するために設計され、仮想マシンのプ"" ""ロセス、デバイス、データファイル、それらの上で動作するシステムプロセス間の分"" ""離を提供するために拡張されました。"" msgid """" ""Within OpenStack some data may be deleted, but not securely erased in the "" ""context of the NIST standards outlined above. This is generally applicable "" ""to most or all of the above-defined metadata and information stored in the "" ""database. This may be remediated with database and/or system configuration "" ""for auto vacuuming and periodic free-space wiping."" msgstr """" ""OpenStack 中でいくつかのデータは削除されるかも知れませんが、上記で触れた "" ""NIST 標準の文脈における安全な消去ではありません。これは一般に、データベースに"" ""保存された上記で定義したメタデータと情報の大半又は全てに当てはまります。これ"" ""は、データベースとシステム設定のどちらか又は両方で、自動バキュームと定期的な"" ""空き領域のクリアを実施する事で解決する事ができるかも知れません。"" msgid """"msgid ""XSM"" msgstr ""XSM"" msgid ""Xen"" msgstr ""Xen"" msgid """" ""Xen explicitly assigns dedicated memory regions to instances and scrubs data "" ""upon the destruction of instances (or domains in Xen parlance). KVM depends "" ""more greatly on Linux page management; A complex set of rules related to KVM "" ""paging is defined in the <link href=\""http://www.linux-kvm.org/page/Memory"" ""\"">KVM documentation</link>."" msgstr """" ""Xen は、専用のメモリ範囲をインスタンスに明確に割り当て、インスタンス (又は "" ""Xen の用語でドメイン) 破棄時にそのデータをクリンアップします。KVM はより大い"" ""に Linux のページ管理に依存しています。 KVM のページングに関する複雑なルール"" ""セットは、<link href=\""http://www.linux-kvm.org/page/Memory\"">KVM の文書</"" ""link>で定義されています。"" msgid ""Xen: <link href=\""http://wiki.xen.org/wiki/VTd_HowTo\"">VTd Howto</link>"" msgstr """" ""Xen: <link href=\""http://wiki.xen.org/wiki/VTd_HowTo\"">VTd Howto</link>"" ""You can force some services to use specific API endpoints. Therefore, it is "" ""recommended that each OpenStack service communicating to the API of another "" ""service must be explicitly configured to access the proper internal API "" ""endpoint.""""いくつかのサービスは特定のAPIエンドポイントの仕様を強制することができます。"" ""従って、それぞれのOpenStackサービスと他サービスとの通信は明示的に適切な内部"" ""APIエンドポイントへアクセスするよう構成する必要があります。""msgid ""ZeroMQ or 0MQ"" msgstr ""ZeroMQ、または、0MQ"" msgid ""cgroups"" msgstr ""cgroups"" msgid ""current"" msgstr ""カレント"" msgid ""http://www.cl.cam.ac.uk/~rja14/Papers/serpent.pdf"" msgstr ""http://www.cl.cam.ac.uk/~rja14/Papers/serpent.pdf""""http://www.mirantis.com/blog/on-disk-encryption-prototype-for-openstack-"" ""swift/""""http://www.mirantis.com/blog/on-disk-encryption-prototype-for-openstack-"" ""swift/""msgid ""http://www.schneier.com/paper-twofish-paper.html"" msgstr ""http://www.schneier.com/paper-twofish-paper.html"" msgid ""https://github.com/Mirantis/swift-encrypt"" msgstr ""https://github.com/Mirantis/swift-encrypt"" msgid ""kEECDH:kEDH"" msgstr ""kEECDH:kEDH"" msgid ""kRSA"" msgstr ""kRSA"" msgid ""n/a"" msgstr ""なし"" msgid ""network provider services (SDN server/services)"" msgstr ""ネットワークプロバイダーサービス (SDN サーバー/サービス)""msgid ""nginx"" msgstr ""nginx"" msgid ""or"" msgstr ""または""msgid ""sVirt"" msgstr ""sVirt"" msgid ""sVirt SELinux Boolean"" msgstr ""sVirt SELinux ブーリアン"" msgid ""sVirt: SELinux and virtualization"" msgstr ""sVirt: SELinux と 仮想化"" msgid ""virt_use_common"" msgstr ""virt_use_common"" msgid ""virt_use_fusefs"" msgstr ""virt_use_fusefs"" msgid ""virt_use_nfs"" msgstr ""virt_use_nfs"" msgid ""virt_use_samba"" msgstr ""virt_use_samba"" msgid ""virt_use_sanlock"" msgstr ""virt_use_sanlock"" msgid ""virt_use_sysfs"" msgstr ""virt_use_sysfs"" msgid ""virt_use_usb"" msgstr ""virt_use_usb"" msgid ""virt_use_xserver"" msgstr ""virt_use_xserver""","""POT-Creation-Date: 2015-05-23 00:51+0000\n"" ""PO-Revision-Date: 2015-05-21 22:41+0000\n""msgid ""Case studies"" msgstr ""ケーススタディ"" msgid ""Alice's private cloud"" msgstr ""アリスのプライベートクラウド"" msgid ""Bob's public cloud"" msgstr ""ボブのパブリッククラウド"" msgid ""Management"" msgstr ""管理"" msgid """" ""A cloud deployment is a living system. Machines age and fail, software "" ""becomes outdated, vulnerabilities are discovered. When errors or omissions "" ""are made in configuration, or when software fixes must be applied, these "" ""changes must be made in a secure, but convenient, fashion. These changes are "" ""typically solved through configuration management."" msgstr """" ""クラウドデプロイメントは生きているシステムです。機械は老朽化して障害が発生"" ""し、ソフトウェアは古くなり、脆弱性が発見されます。設定にエラーや抜けがあった"" ""場合、ソフトウェアの修正を適用する必要が出た場合、セキュアかつ利便的に、これ"" ""らの変更を加える必要があります。通常、これらの変更は構成管理などで解決されま"" ""す。""""Likewise, it is important to protect the cloud deployment from being "" ""configured or manipulated by malicious entities. With many systems in a "" ""cloud employing compute and networking virtualization, there are distinct "" ""challenges applicable to OpenStack which must be addressed through integrity "" ""lifecycle management.""""同様に、悪意のある組織により設定または操作されないように、クラウドデプロイメ"" ""ントを保護することが重要です。コンピュートやネットワークの仮想化を採用するク"" ""ラウド内の多くのシステムでは、OpenStack に適用される問題が明らかに存在し、整"" ""合性のライフサイクル管理で対応していく必要があります。""""Finally, administrators must perform command and control over the cloud for "" ""various operational functions. It is important these command and control "" ""facilities are understood and secured.""""最後に、管理者は様々なオペレーション機能に対してクラウド上で指揮統制を行う必"" ""要があります。これらの指揮統制機能を理解、確保することが重要です。"" msgid ""Database transport security"" msgstr ""データベース通信セキュリティ"" msgid ""Database server IP address binding"" msgstr ""データベースサーバーの IP アドレスバインド""""To isolate sensitive database communications between the services and the "" ""database, we strongly recommend that the database server(s) be configured to "" ""only allow communications to and from the database over an isolated "" ""management network. This is achieved by restricting the interface or IP "" ""address on which the database server binds a network socket for incoming "" ""client connections.""""サービスとデータベース間の機微なデータベース通信を隔離するために、データベー"" ""スサーバーが隔離された管理ネットワーク経由のみでデータベースと通信できるよう"" ""に設定することを強く推奨します。データベースサーバーがクライアントからの通信"" ""用のネットワークソケットをバインドするインターフェースまたは IP アドレスを制"" ""限することにより、これを実現できます。"" msgid ""Restricting bind address for MySQL"" msgstr ""MySQL のバインドアドレスの制限"" msgid ""In <filename>my.cnf</filename>:"" msgstr ""<filename>my.cnf</filename>:"" msgid ""Restricting listen address for PostgreSQL"" msgstr ""PostgreSQL のバインドアドレスの制限"" msgid ""In <filename>postgresql.conf</filename>:"" msgstr ""<filename>postgresql.conf</filename>:"" msgid ""Database transport"" msgstr ""データベース通信""""When installing the certificate and key files, ensure that the file "" ""permissions are restricted, for example <placeholder-1/>, and the ownership "" ""is restricted to the database daemon user to prevent unauthorized access by "" ""other processes and users on the database server.""""証明書と鍵ファイルをインストールするとき、ファイルのパーミッションが制限され"" ""ていることを確認します。たとえば、<placeholder-1/> を実行すると、データベース"" ""サーバー上の他のプロセスやユーザーによる権限のないアクセスを防ぐために、所有"" ""者がデータベースデーモンのユーザーに制限されます。"" msgid ""MySQL SSL configuration"" msgstr ""MySQL SSL 設定"" msgid """" ""The following lines should be added in the system-wide MySQL configuration "" ""file:"" msgstr ""以下の行をシステム全体の MySQL 設定ファイルに追加する必要があります。"" msgid """" ""Optionally, if you wish to restrict the set of SSL ciphers used for the "" ""encrypted connection. See <link href=\""http://www.openssl.org/docs/apps/"" ""ciphers.html\"">http://www.openssl.org/docs/apps/ciphers.html</link> for a "" ""list of ciphers and the syntax for specifying the cipher string:"" msgstr """" ""オプションとして、暗号化通信に使用される SSL 暗号を制限したい場合、暗号の一覧"" ""と暗号文字列を設定するための構文は <link href=\""http://www.openssl.org/docs/"" ""apps/ciphers.html\"">http://www.openssl.org/docs/apps/ciphers.html</link> を参"" ""照してください。"" msgid ""PostgreSQL SSL configuration"" msgstr ""PostgreSQL SSL 設定"" msgid """" ""The following lines should be added in the system-wide PostgreSQL "" ""configuration file, <filename>postgresql.conf</filename>."" msgstr """" ""以下の行をシステム全体の PostgreSQL 設定ファイル <filename>postgresql.conf</"" ""filename> に追加する必要があります。"" msgid """" ""The server certificate, key, and certificate authority (CA) files should be "" ""placed in the $PGDATA directory in the following files:"" msgstr """" ""サーバー証明書、鍵、認証局 (CA) のファイルを $PGDATA ディレクトリの以下のファ"" ""イルに置く必要があります。"" msgid ""<filename>$PGDATA/server.crt</filename> - Server certificate"" msgstr ""<filename>$PGDATA/server.crt</filename> - サーバー証明書"" msgid """" ""<filename>$PGDATA/server.key</filename> - Private key corresponding to "" ""<filename>server.crt</filename>"" msgstr """" ""<filename>$PGDATA/server.key</filename> - <filename>server.crt</filename> に"" ""対応する秘密鍵"" msgid ""<filename>$PGDATA/root.crt</filename> - Trusted certificate authorities"" msgstr ""<filename>$PGDATA/root.crt</filename> - 信頼された認証局"" msgid ""<filename>$PGDATA/root.crl</filename> - Certificate revocation list"" msgstr ""<filename>$PGDATA/root.crl</filename> - 証明書失効リスト"" msgid ""Authentication methods"" msgstr ""認証方式"" msgid ""Internally implemented authentication methods"" msgstr ""内部実装認証方式"" msgid """" ""When you use a user name and password to authenticate, Identity does not "" ""enforce policies on password strength, expiration, or failed authentication "" ""attempts as recommended by NIST Special Publication 800-118 (draft). "" ""Organizations that desire to enforce stronger password policies should "" ""consider using Identity extensions or external authentication services."" msgstr """" ""認証のためにユーザー名とパスワードを使用する場合、Identity は NIST Special "" ""Publication 800-118 (draft) により推奨されている、パスワード強度、有効期限、"" ""ログイン試行回数制限に関するポリシーを強制できません。より強固なパスワードポ"" ""リシーを強制したい組織は、Identity 拡張や外部認証サービスの使用を検討すべきで"" ""す。"" msgid """" ""LDAP simplifies integration of Identity authentication into an "" ""organization's existing directory service and user account management "" ""processes."" msgstr """" ""LDAP により、組織の既存のディレクトリサービスやユーザーアカウント管理プロセス"" ""に Identity 認証をシンプルに統合できます。""""There is an <link href=\""https://bugs.launchpad.net/ossn/"" ""+bug/1168252\"">OpenStack Security Note (OSSN) regarding keystone.conf "" ""permissions</link>.""""<link href=\""https://bugs.launchpad.net/ossn/+bug/1168252\"">keystone.conf の"" ""パーミッションに関する OpenStack Security Note (OSSN)</link> があります。""""There is an <link href=\""https://bugs.launchpad.net/ossn/"" ""+bug/1155566\"">OpenStack Security Note (OSSN) regarding potential DoS "" ""attacks</link>.""""<link href=\""https://bugs.launchpad.net/ossn/+bug/1155566\"">潜在的な DoS 攻撃"" ""に関する OpenStack Security Note (OSSN)</link> があります。"" msgid ""External authentication methods"" msgstr ""外部認証方式""""Organizations may desire to implement external authentication for "" ""compatibility with existing authentication services or to enforce stronger "" ""authentication policy requirements. Although passwords are the most common "" ""form of authentication, they can be compromised through numerous methods, "" ""including keystroke logging and password compromise. External authentication "" ""services can provide alternative forms of authentication that minimize the "" ""risk from weak passwords.""""組織は、既存の認証サービスとの互換性のために外部認証を実装したいかもしれませ"" ""ん。または、より強固な認証ポリシー要件を強制するためかもしれません。パスワー"" ""ドが認証のもっとも一般的な形式ですが、キー入力ロギングやパスワード推測など、"" ""さまざまな方法で破られる可能性があります。外部認証サービスにより、弱いパス"" ""ワードのリスクを最小化する他の認証形式を提供できます。"" msgid ""These include:"" msgstr ""これらは以下のものが含まれます。""""Password policy enforcement: Requires user passwords to conform to minimum "" ""standards for length, diversity of characters, expiration, or failed login "" ""attempts.""""パスワードポリシー強制: ユーザーパスワードが、長さ、文字種の量、有効期限、失"" ""敗試行回数の最低基準を満たしていることを要求します。"" msgid """" ""Multi-factor authentication: The authentication service requires the user to "" ""provide information based on something they have, such as a one-time "" ""password token or X.509 certificate, and something they know, such as a "" ""password."" msgstr """" ""多要素認証: 認証サービスが、ユーザーが持っているもの (例: ワンタイムパスワー"" ""ドトークン、X.509 証明書) と知っていること (例: パスワード) に基づいた情報を"" ""提示するよう要求します。"" msgid ""Kerberos"" msgstr ""Kerberos"" msgid ""Compliance overview"" msgstr ""コンプライアンス概要"" msgid ""Security principles"" msgstr ""セキュリティ原則""""Industry standard security principles provide a baseline for compliance "" ""certifications and attestations. If these principles are considered and "" ""referenced throughout an OpenStack deployment, certification activities may "" ""be simplified.""""業界標準のセキュリティ原則は、コンプライアンス認証、認定のための基準を提供し"" ""ます。もしそれらの原則が対象のOpenStack環境で考慮、適用されていれば、認証を得"" ""る活動はシンプルになるでしょう。"" msgid ""Layered defenses"" msgstr ""階層防御""""Identify where risks exist in a cloud architecture and apply controls to "" ""mitigate the risks. In areas of significant concern, layered defences "" ""provide multiple complementary controls to manage risk down to an acceptable "" ""level. For example, to ensure adequate isolation between cloud tenants, we "" ""recommend hardening QEMU, using a hypervisor with SELinux support, enforcing "" ""mandatory access control policies, and reducing the overall attack surface. "" ""The foundational principle is to harden an area of concern with multiple "" ""layers of defense such that if any one layer is compromised, other layers "" ""will exist to offer protection and minimize exposure.""""クラウドアーキテクチャ内にあるリスクの存在場所を特定し、そのリスクを受容可能"" ""なレベルに管理すべく、コントロールします。特に心配される部分では、多層防御は"" ""さらなるリスク緩和のため、相互補完的なコントロールを提供します。たとえば、ク"" ""ラウドテナント間の十分な独立性を確保するには、QEMUの強化、SELinuxサポートのハ"" ""イパーバイザーを使う、強制アクセス制御の適用、攻撃対象面の縮小、などがおすす"" ""めです。この基本的な原則により、もしある階層が危険にさらされても、他の階層が"" ""防御し、露出を最小化することで、懸念される部分が強化されるのです。"" msgid ""Fail securely"" msgstr ""フェイルセキュア"" msgid ""Least privilege"" msgstr ""最小権限""""Only the minimum level of access for users and system services is granted. "" ""This access is based upon role, responsibility and job function. This "" ""security principal of least privilege is written into several international "" ""government security policies, such as NIST 800-53 Section AC-6 within the "" ""United States.""""ユーザーとシステムサービスには最小限のアクセス権限のみを付与すべきです。アク"" ""セス権限は役割、責任と職務にもとづきます。この最小権限原則は、いくつかの国際"" ""セキュリティポリシーに明記されています。たとえば米国のNIST 800-53 AC-6項が挙"" ""げられます。"" msgid ""Compartmentalize"" msgstr ""コンパートメント化""""Systems should be segregated in a such way that if one machine, or system-"" ""level service, is compromised the security of the other systems will remain "" ""intact. Practically, the enablement and proper usage of SELinux helps "" ""accomplish this goal.""""システムは、仮にあるマシンやシステムレベルのサービスが危険にさらされたとして"" ""も、他の無傷なシステムとは分離されているべきです。実際、SELinuxの正しい使用"" ""は、この目標を達成するのに役立ちます。"" msgid ""Promote privacy"" msgstr ""プライバシー保護の奨励"" msgid """" ""The amount of information that can be gathered about a system and its users "" ""should be minimized."" msgstr ""システムとそのユーザーに関わる、収集可能な情報の量は最小化すべきです。"" msgid ""Logging capability"" msgstr ""ロギング機能"" msgid """" ""Appropriate logging is implemented to monitor for unauthorized use, incident "" ""response and forensics. It is highly recommended that selected audit "" ""subsystems be Common Criteria certified, which provides non-attestable event "" ""records in most countries."" msgstr """" ""適切なロギングは、不正利用の監視や障害対応、証拠収集に役立ちます。多くの国に"" ""おいて、それを再度証明する必要が無い、Common Criteria認定をうけた監査サブシス"" ""テムの採用を強くおすすめします。"" msgid ""Cloud Security Alliance (CSA) Common Control Matrix (CCM)"" msgstr ""Cloud Security Alliance (CSA) Common Control Matrix (CCM)"" msgid ""ISO 27001/2:2013"" msgstr ""ISO 27001/2:2013"" msgid ""Audit reference"" msgstr ""監査参照"" msgid """" ""One decision a cloud architect will need to make regarding Compute service "" ""configuration is whether to use <glossterm baseform=\""Virtual Network "" ""Computing (VNC)\"">VNC</glossterm> or <glossterm>SPICE</glossterm>. Below we "" ""provide some details on the differences between these options."" msgstr """" ""クラウドアーキテクトが判断する必要があることの一つは、Compute Service の設定"" ""が <glossterm baseform=\""Virtual Network Computing (VNC)\"">VNC</glossterm> "" ""と <glossterm>SPICE</glossterm> のどちらを使用するかです。以下は、これらの選"" ""択肢の違いに関する詳細を提供します。"" msgid ""Virtual Network Computer (VNC)"" msgstr ""Virtual Network Computer (VNC)"" msgid """" ""OpenStack can be configured to provide remote desktop console access to "" ""instances for tenants and/or administrators using the Virtual Network "" ""Computer (VNC) protocol."" msgstr """" ""OpenStack は Virtual Network Computer (VNC) プロトコルを使用して、プロジェク"" ""トと管理者がインスタンスのリモートデスクトップコンソールにアクセスできるよう"" ""に設定できます。"" msgid ""Capabilities"" msgstr ""機能"" msgid """" ""The OpenStack dashboard (horizon) can provide a VNC console for instances "" ""directly on the web page using the HTML5 noVNC client. This requires the "" ""<systemitem class=\""service\"">nova-novncproxy</systemitem> service to bridge "" ""from the public network to the management network."" msgstr """" ""OpenStack Dashboard (Horizon) は HTML5 の非 VNC クライアントを使用して、ウェ"" ""ブページから直接インスタンスの VNC コンソールを提供できます。これには、"" ""<systemitem class=\""service\"">nova-novncproxy</systemitem> サービスがパブリッ"" ""クネットワークから管理ネットワークにブリッジする必要があります。"" msgid """" ""The <placeholder-1/> command-line utility can return a URL for the VNC "" ""console for access by the <systemitem class=\""service\"">nova</systemitem> "" ""Java VNC client. This requires the <systemitem class=\""service\"">nova-"" ""xvpvncproxy</systemitem> service to bridge from the public network to the "" ""management network."" msgstr """" ""<placeholder-1/> コマンドラインユーティリティは <systemitem class=\""service"" ""\"">nova</systemitem> Java VNC クライアントによりアクセスするための VNC の "" ""URL を返すことができます。これには、<systemitem class=\""service\"">nova-"" ""xvpvncproxy</systemitem> サービスがパブリックネットワークから管理ネットワーク"" ""にブリッジする必要があります。"" msgid ""Security considerations"" msgstr ""セキュリティの課題"" msgid """" ""The <systemitem class=\""service\"">nova-novncproxy</systemitem> and "" ""<systemitem class=\""service\"">nova-xvpvncproxy</systemitem> services by "" ""default open public-facing ports that are token authenticated."" msgstr """" ""デフォルトのオープンなパブリックポートによる <systemitem class=\""service"" ""\"">nova-novncproxy</systemitem> サービスと <systemitem class=\""service"" ""\"">nova-xvpvncproxy</systemitem> サービスがトークン認証されます。"" msgid ""Simple Protocol for Independent Computing Environments (SPICE)"" msgstr ""Simple Protocol for Independent Computing Environments (SPICE)"" msgid """" ""As an alternative to VNC, OpenStack provides remote desktop access to guest "" ""virtual machines using the Simple Protocol for Independent Computing "" ""Environments (SPICE) protocol."" msgstr """" ""VNC の代替として、OpenStack は Simple Protocol for Independent Computing "" ""Environments (SPICE) プロトコルを使用した、仮想マシンへのリモートデスクトップ"" ""アクセスを提供します。"" msgid """" ""SPICE is supported by the OpenStack dashboard (horizon) directly on the "" ""instance web page. This requires the <systemitem class=\""service\"">nova-"" ""spicehtml5proxy</systemitem> service."" msgstr """" ""SPICE は OpenStack Dashboard (Horizon) により直接インスタンスのウェブページで"" ""サポートされます。これには nova-spicehtml5proxy サービスが必要です。"" msgid """" ""The nova command-line utility can return a URL for SPICE console for access "" ""by a SPICE-html client."" msgstr """" ""nova コマンドラインユーティリティは SPICE-html クライアントによりアクセスする"" ""ための SPICE コンソールの URL を返すことができます。"" msgid ""Limitations"" msgstr ""制限事項"" msgid """" ""Although SPICE has many advantages over VNC, the spice-html5 browser "" ""integration currently doesn't really allow admins to take advantage of any "" ""of the benefits. To take advantage of SPICE features like multi-monitor, USB "" ""pass through, etc. admins are recommended to use a standalone SPICE client "" ""within the Management Network."" msgstr """" ""SPICE は VNC よりも多くの点で優れていますが、現在 spice-html5 ブラウザー統合"" ""は管理者がすべての利点を利用することができません。マルチモニター、USB パスス"" ""ルーなどの SPICE 機能の利点を利用するためには、管理ネットワークの中でスタンド"" ""アロン SPICE クライアントを使用することが推奨されます。"" msgid """" ""The <systemitem class=\""service\"">nova-spicehtml5proxy</systemitem> service "" ""by default opens public-facing ports that are token authenticated."" msgstr """" ""<systemitem class=\""service\"">nova-spicehtml5proxy</systemitem> サービスはデ"" ""フォルトで、トークン認証されるパブリックポートをオープンします。"" msgid """" ""The functionality and integration are still evolving. We will access the "" ""features in the next release and make recommendations."" msgstr """" ""機能と統合は進化中です。次のリリースの機能を確認し、推奨事項を作成します。"" msgid """" ""As is the case for VNC, at this time we recommend using SPICE from the "" ""management network in addition to limiting use to few individuals."" msgstr """" ""VNC の場合のように、今のところ数人の利用者に制限して管理ネットワークから "" ""SPICE を使用することを推奨します。"" msgid ""Forensics and incident response"" msgstr ""フォレンジングとインシデント対応"" msgid """" ""The generation and collection of logs is an important component of securely "" ""monitoring an OpenStack infrastructure. Logs provide visibility into the day-"" ""to-day actions of administrators, tenants, and guests, in addition to the "" ""activity in the compute, networking, and storage and other components that "" ""comprise your OpenStack deployment."" msgstr """" ""ログの生成と収集は OpenStack インフラのセキュリティ監視の重要なコンポーネント"" ""です。ログは日々の管理者・テナント・ゲストの行動に加え、あなたの OpenStack デ"" ""プロイを構成する Compute、Networking、ストレージ、他のコンポーネントの活動の"" ""可視性を提供します。"" msgid """" ""Logs are not only valuable for proactive security and continuous compliance "" ""activities, but they are also a valuable information source for "" ""investigating and responding to incidents."" msgstr """" ""ログは率先したセキュリティや継続的なコンプライアンス活動に有用であるのみなら"" ""ず、インシデントの調査と対応の為の情報源としても有用です。"" msgid ""Monitoring use cases"" msgstr ""監視ユースケース"" msgid """" ""Detecting the absence of log generation is an event of high value. Such an "" ""event would indicate a service failure or even an intruder who has "" ""temporarily switched off logging or modified the log level to hide their "" ""tracks."" msgstr """" ""ログ生成無しの検知は価値の高いイベントです。このようなイベントはサービス障"" ""害、または一時的にログをオフにしたり、監視者から隠れるためにログレベルを変更"" ""した侵入者を示している可能性があります。"" msgid """" ""Being able to detect the load on the OpenStack servers also enables "" ""responding by way of introducing additional servers for load balancing to "" ""ensure high availability."" msgstr """" ""OpenStack サーバ群の負荷を検知可能にする事はまた、高可用化対応の為に負荷分散"" ""用追加サーバを導入する為の対応を可能にする事でもあります。"" msgid """" ""Other events that are actionable are networking bridges going down, ip "" ""tables being flushed on compute nodes and consequential loss of access to "" ""instances resulting in unhappy customers."" msgstr """" ""行動可能な他のイベントはネットワークブリッジがダウンした事です。compute ノー"" ""ド上で設定がクリアされた iptables や、インスタンスへのアクセスの重大なロスは"" ""ユーザを不幸にします。"" msgid """" ""A cloud will host many virtual instances, and monitoring these instances "" ""goes beyond hardware monitoring and log files which may just contain CRUD "" ""events."" msgstr """" ""クラウドには多数の仮想インスタンスがあり、これらのインスタンスの監視はハード"" ""ウェア監視と CRUD イベントのみ含むログファイルの背後にあります。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/1aa-logical-neutron-flow.png'; "" ""md5=3589a1ef10ea2bbe189ca90e3c932df2"" msgstr """" ""@@image: 'static/1aa-logical-neutron-flow.png'; "" ""md5=3589a1ef10ea2bbe189ca90e3c932df2"" msgid ""Securing OpenStack Networking services"" msgstr ""OpenStack Networking サービスのセキュリティ強化"" msgid """" ""To secure OpenStack Networking, you must understand how the workflow process "" ""for tenant instance creation needs to be mapped to security domains."" msgstr """" ""OpenStack Networking のセキュリティを強化する為に、どの程度テナントインスタン"" ""ス作成用のワークフロープロセスをセキュリティドメインにマッピングさせる必要が"" ""あることを理解しなくてはいけません。"" msgid """" ""There are four main services that interact with OpenStack Networking. In a "" ""typical OpenStack deployment these services map to the following security "" ""domains:"" msgstr """" ""OpenStack Networking と交信する主要なサービスが４つあります。典型的な "" ""OpenStack デプロイでは、これらのサービスは以下のセキュリティドメインにマッピ"" ""ングされます。"" msgid ""OpenStack dashboard: Public and management"" msgstr ""OpenStack Dashboard: パブリック、管理"" msgid ""OpenStack Identity: Management"" msgstr ""OpenStack Identity: 管理"" msgid ""OpenStack compute node: Management and guest"" msgstr ""OpenStack Compute ノード: 管理、ゲスト"" msgid """" ""OpenStack network node: Management, guest, and possibly public depending "" ""upon neutron-plugin in use."" msgstr """" ""OpenStack ネットワークノード: 管理、ゲスト（使用する neutron プラグインによっ"" ""てはパブリックも可能性あり）"" msgid """" ""SDN services node: Management, guest and possibly public depending upon "" ""product used."" msgstr """" ""SDB サービスノード：管理、ゲスト （使用する製品によってはパブリックも可能性あ"" ""り）"" msgid """" ""To isolate sensitive data communication between the OpenStack Networking "" ""services and other OpenStack core services, configure these communication "" ""channels to only allow communication over an isolated management network."" msgstr """" ""OpenStack Networking サービスと他の OpenStack コアサービス間の扱いの難しい"" ""データ通信を分離する為、通信を独立した管理ネットワーク上でのみ行うように通信"" ""路を設定します。"" msgid ""OpenStack Networking service configuration"" msgstr ""OpenStack Networking サービス設定"" msgid ""Restrict bind address of the API server: neutron-server"" msgstr ""API サーバがバインドするアドレスの制限: neutron-server"" msgid """" ""To restrict the interface or IP address on which the OpenStack Networking "" ""API service binds a network socket for incoming client connections, specify "" ""the bind_host and bind_port in the neutron.conf file as shown:"" msgstr """" ""OpenStack Networking API サービスが外からのクライアント通信用にネットワークソ"" ""ケットをバインドするネットワークインターフェース又は IP アドレスを制限する"" ""為、neutron.conf ファイル中の bind_host と bind_port を以下のように指定しま"" ""す。"" msgid ""IP ADDRESS OF SERVER"" msgstr ""IP ADDRESS OF SERVER"" msgid ""Restrict DB and RPC communication of the OpenStack Networking services"" msgstr ""OpenStack Networking サービス群の DB と RPC 通信の制限"" msgid """" ""Various components of the OpenStack Networking services use either the "" ""messaging queue or database connections to communicate with other components "" ""in OpenStack Networking."" msgstr """" ""OpenStack Networking サービスの様々なコンポーネントは、OpenStack Networking "" ""中の他のコンポーネントとの通信にメッセージキュー又はデータベース接続のいずれ"" ""かを使用します。"" msgid ""Identity"" msgstr ""Identity"" msgid ""In this case, Bob will approach these steps the same as Alice."" msgstr ""今回のケーススタディでは、ボブはアリスと同様の手段を取ります。"" msgid """" ""PostgreSQL has a number of desirable security features such as Kerberos "" ""authentication, object-level security, and encryption support. The "" ""PostgreSQL community has done well to provide solid guidance, documentation, "" ""and tooling to promote positive security practices."" msgstr """" ""PostgreSQL は、Kerberos 認証、オブジェクトレベルのセキュリティ、暗号化のサ"" ""ポートなど、数多くの望ましいセキュリティ機能を有します。PostgreSQL コミュニ"" ""ティは実用的なセキュリティ実践を推進するために、わかりやすいガイダンス、ド"" ""キュメント、ツールを十分に提供してきました。"" msgid """" ""MySQL has a large community, widespread adoption, and provides high "" ""availability options. MySQL also has the ability to provide enhanced client "" ""authentication by way of plug-in authentication mechanisms. Forked "" ""distributions in the MySQL community provide many options for consideration. "" ""It is important to choose a specific implementation of MySQL based on a "" ""thorough evaluation of the security posture and the level of support "" ""provided for the given distribution."" msgstr """" ""MySQL は大規模なコミュニティを持ち、幅広く適用され、高可用性のオプションを提"" ""供しています。MySQL も、プラグイン認証機構の方法により高度なクライアント認証"" ""を提供する機能があります。MySQL コミュニティから派生したディストリビューショ"" ""ンは、考慮事項に対する多くのオプションを提供しています。セキュリティの考え方"" ""やディストリビューションに提供されるサポートレベルの評価に基づいて、特定の "" ""MySQL ディストリビューションを選択することが重要です。"" msgid ""Security references for database back ends"" msgstr ""データベースバックエンドのセキュリティ参考資料"" msgid """" ""Those deploying MySQL or PostgreSQL are advised to refer to existing "" ""security guidance. Some references are listed below:"" msgstr """" ""MySQL や PostgreSQL を導入する人は、既存のセキュリティガイダンスを参照するこ"" ""とが推奨されます。いくつかの参考資料を以下に一覧化します。"" msgid ""MySQL:"" msgstr ""MySQL:"" msgid ""OWASP MySQL Hardening"" msgstr ""OWASP MySQL Hardening"" msgid ""MySQL Pluggable Authentication"" msgstr ""MySQL Pluggable Authentication"" msgid ""Security in MySQL"" msgstr ""Security in MySQL"" msgid ""PostgreSQL:"" msgstr ""PostgreSQL:"" msgid ""OWASP PostgreSQL Hardening"" msgstr ""OWASP PostgreSQL Hardening"" msgid ""Total security in a PostgreSQL database"" msgstr ""Total security in a PostgreSQL database"" msgid ""Monitoring and logging"" msgstr ""監視とログ採取"" msgid """" ""A lot of activity goes on within a cloud environment. It is a mix of "" ""hardware, operating systems, virtual machine managers, the OpenStack "" ""services, cloud-user activity such as creating instances and attaching "" ""storage, the network underlying the whole, and finally end-users using the "" ""applications running on the various instances."" msgstr """" ""多数の活動がクラウド環境内で行われます。これはハードウェア、オペレーティング"" ""システム、仮想マシンマネージャ、OpenStackサービス群、インスタンス作成やスト"" ""レージアタッチのようなクラウド⇔ユーザ活動、全体の土台であるネットワーク、最後"" ""に様々なインスタンス上で実行されるアプリケーションを使用するエンドユーザの"" ""ミックスです。"" msgid """" ""The basics of logging: configuration, setting log level, location of the log "" ""files, and how to use and customize logs, as well as how to do centralized "" ""collections of logs is well covered in the <link href=\""http://docs."" ""openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></"" ""link>."" msgstr """" ""ロギングの基本: ログを集中収集する方法と同様、設定、ログレベル設定、ログファ"" ""イルの位置、ログの使用とカスタマイズ方法は、<link href=\""http://docs."" ""openstack.org/ops/\""><citetitle>OpenStack Operations Guide</citetitle></"" ""link> で充分にカバーされています。"" msgid ""Hardening the virtualization layers"" msgstr ""仮想化層のセキュリティ強化"" msgid """" ""In the beginning of this chapter we discuss the use of both physical and "" ""virtual hardware by instances, the associated security risks, and some "" ""recommendations for mitigating those risks. We conclude the chapter with a "" ""discussion of sVirt, an open source project for integrating SELinux "" ""mandatory access controls with the virtualization components."" msgstr """" ""本章の初めに、インスタンスによる物理ハードウェアと仮想ハードウェアの両方の使"" ""用、関連するセキュリティリスク、それらのリスクを軽減するためのいくつかの推奨"" ""事項について議論します。SELinux 強制アクセス制御を仮想化コンポーネントと統合"" ""するためのオープンソースプロジェクトである sVirt の議論で本章を終わります。"" msgid ""Physical hardware (PCI passthrough)"" msgstr ""物理ハードウェア (PCI パススルー)"" msgid """" ""Many hypervisors offer a functionality known as PCI passthrough. This allows "" ""an instance to have direct access to a piece of hardware on the node. For "" ""example, this could be used to allow instances to access video cards or GPUs "" ""offering the compute unified device architecture (CUDA) for high performance "" ""computation. This feature carries two types of security risks: direct memory "" ""access and hardware infection."" msgstr """" ""多くのハイパーバイザーは PCI パススルーとして知られる機能を提供します。これに"" ""より、インスタンスがノードにあるハードウェアの一部に直接アクセスできます。た"" ""とえば、インスタンスがハイパフォーマンスコンピューティング用の compute "" ""unified device architecture (CUDA) を提供するビデオカードや GPU にアクセスす"" ""るために使用されます。この機能は 2 種類のセキュリティリスクをもたらします。ダ"" ""イレクトメモリアクセスとハードウェア感染です。"" msgid """" ""Direct memory access (DMA) is a feature that permits certain hardware "" ""devices to access arbitrary physical memory addresses in the host computer. "" ""Often video cards have this capability. However, an instance should not be "" ""given arbitrary physical memory access because this would give it full view "" ""of both the host system and other instances running on the same node. "" ""Hardware vendors use an input/output memory management unit (IOMMU) to "" ""manage DMA access in these situations. Therefore, cloud architects should "" ""ensure that the hypervisor is configured to utilize this hardware feature."" msgstr """" ""ダイレクトメモリアクセス (DMA) は、特定のハードウェアがホストコンピューターで"" ""任意の物理メモリアドレスにアクセスできる機能です。ビデオカードはときどきこの"" ""機能を有しています。しかしながら、インスタンスは指定された任意の物理メモリア"" ""クセスをすべきではありません。なぜなら、これはホストシステムと同じノードで実"" ""行している他のインスタンスを完全に表示できるかもしれないからです。ハードウェ"" ""アベンダーはこれらの状況で DMA アクセスを管理するために input/output memory "" ""management unit (IOMMU) を使用します。そのため、クラウドアーキテクトは、ハイ"" ""パーバイザーがこのハードウェア機能を使用するよう設定されていることを確実にす"" ""べきです。"" msgid """" ""KVM: <link href=\""http://www.linux-kvm.org/page/"" ""How_to_assign_devices_with_VT-d_in_KVM\"">How to assign devices with VT-d in "" ""KVM</link>"" msgstr """" ""KVM: <link href=\""http://www.linux-kvm.org/page/"" ""How_to_assign_devices_with_VT-d_in_KVM\"">How to assign devices with VT-d in "" ""KVM</link>"" msgid ""Xen: <link href=\""http://wiki.xen.org/wiki/VTd_HowTo\"">VTd Howto</link>"" msgstr """" ""Xen: <link href=\""http://wiki.xen.org/wiki/VTd_HowTo\"">VTd Howto</link>"" msgid ""The IOMMU feature is marketed as VT-d by Intel and AMD-Vi by AMD."" msgstr """" ""IOMMU 機能は、Intel により VT-d、AMD により AMD-Vi として提供されています。"" msgid """" ""Additionally, due to the risk and complexities associated with PCI "" ""passthrough, it should be disabled by default. If enabled for a specific "" ""need, you will need to have appropriate processes in place to ensure the "" ""hardware is clean before re-issue."" msgstr """" ""加えて、PCI パススルーに関連したリスクと複雑性のため、これはデフォルトで無効"" ""化されるべきです。特定の用途のために有効化する場合、ハードウェアが再発行され"" ""る前に確実にクリアするために、適切なプロセスを実行する必要があります。"" msgid ""Virtual hardware (QEMU)"" msgstr ""仮想ハードウェア (QEMU)"" msgid """" ""When running a virtual machine, virtual hardware is a software layer that "" ""provides the hardware interface for the virtual machine. Instances use this "" ""functionality to provide network, storage, video, and other devices that may "" ""be needed. With this in mind, most instances in your environment will "" ""exclusively use virtual hardware, with a minority that will require direct "" ""hardware access. The major open source hypervisors use QEMU for this "" ""functionality. While QEMU fills an important need for virtualization "" ""platforms, it has proven to be a very challenging software project to write "" ""and maintain. Much of the functionality in QEMU is implemented with low-"" ""level code that is difficult for most developers to comprehend. Furthermore, "" ""the hardware virtualized by QEMU includes many legacy devices that have "" ""their own set of quirks. Putting all of this together, QEMU has been the "" ""source of many security problems, including hypervisor breakout attacks."" msgstr """" ""仮想マシンの実行時、仮想ハードウェアは仮想マシンにハードウェアインターフェー"" ""スを提供するソフトウェア層です。インスタンスは必要となるネットワーク、スト"" ""レージ、ビデオ、他のデバイスを提供するためにこの機能を使用します。これで覚え"" ""ておくことは、お使いのほとんどのインスタンスは排他的に仮想ハードウェアを使用"" ""することです。一部はハードウェアに直接アクセスする必要があります。主要なオー"" ""プンソースのハイパーバイザーはこの機能のために QEMU を使用します。QEMU は仮想"" ""化プラットフォームのニーズを満たしますが、作成と維持することが非常に挑戦的な"" ""ソフトウェアプロジェクトであるとわかってきました。QEMU の機能のほとんどは、多"" ""くの開発者が理解しにくい低レベルなコードで実装されています。さらに、QEMU によ"" ""り仮想化されるハードウェアには、独自の癖を持つレガシーデバイスが数多くありま"" ""す。これを一括りにするので、QEMU はハイパーバイザー突破攻撃を含む多くのセキュ"" ""リティ問題の元になってきました。"" msgid ""Minimizing the QEMU code base"" msgstr ""QEMU コードベースの最小化"" msgid """" ""A cloud architect should decide what devices to make available to cloud "" ""users. Anything that is not needed should be removed from QEMU. This step "" ""requires recompiling QEMU after modifying the options passed to the QEMU "" ""configure script. For a complete list of up-to-date options simply run "" ""<placeholder-1/> from within the QEMU source directory. Decide what is "" ""needed for your deployment, and disable the remaining options."" msgstr """" ""クラウドアーキテクトは、どのデバイスがクラウドユーザーに利用可能であるかを判"" ""断すべきです。必要ないすべてのデバイスは QEMU から削除すべきです。この手順"" ""は、QEMU 設定スクリプトに渡されるオプションを変更した後で、QEMU を再コンパイ"" ""ルする必要があります。最新の完全なオプション一覧は、QEMU ソースディレクトリの"" ""中で <placeholder-1/> を単に実行します。お使いの環境に必要なものを判断し、残"" ""りのオプションを無効化します。"" msgid ""Compiler hardening"" msgstr ""コンパイラーのセキュリティ強化機能"" msgid """" ""The next step is to harden QEMU using compiler hardening options. Modern "" ""compilers provide a variety of compile time options to improve the security "" ""of the resulting binaries. These features, which we will describe in more "" ""detail below, include relocation read-only (RELRO), stack canaries, never "" ""execute (NX), position independent executable (PIE), and address space "" ""layout randomization (ASLR)."" msgstr """" ""次の手順は、コンパイラーのセキュリティ強化オプションを使用して QEMU をセキュ"" ""リティ強化することです。最近のコンパイラーは、出力バイナリのセキュリティを改"" ""善するために、さまざまなコンパイル時オプションを提供します。これらの機能に"" ""は、より詳細を以下で説明しますが、relocation read-only (RELRO)、Stack "" ""Canaries、never execute (NX)、position independent executable (PIE)、address "" ""space layout randomization (ASLR) があります。"" msgid """" ""Many modern Linux distributions already build QEMU with compiler hardening "" ""enabled, so you may want to verify your existing executable before "" ""proceeding with the information below. One tool that can assist you with "" ""this verification is called <link href=\""http://www.trapkit.de/tools/"" ""checksec.html\""><literal>checksec.sh</literal></link>."" msgstr """" ""ほとんどの最近の Linux ディストリビューションは、すでにコンパイラーのセキュリ"" ""ティ強化を有効化して QEMU をビルドしています。そのため、以下の情報を続ける前"" ""に、既存のバイナリを確認したいでしょう。この確認を手助けできるツールの 1 つ"" ""は <link href=\""http://www.trapkit.de/tools/checksec.html"" ""\""><literal>checksec.sh</literal></link> と呼ばれます。"" msgid ""RELocation Read-Only (RELRO)"" msgstr ""RELocation Read-Only (RELRO)"" msgid """" ""Hardens the data sections of an executable. Both full and partial RELRO "" ""modes are supported by gcc. For QEMU full RELRO is your best choice. This "" ""will make the global offset table read-only and place various internal data "" ""sections before the program data section in the resulting executable."" msgstr """" ""実行ファイルのデータ部分をセキュリティ強化します。全体 RELRO モードと部分 "" ""RELRO モードが gcc によりサポートされます。QEMU 完全 RELRO が最善の選択肢で"" ""す。これにより、グローバルオフセットテーブルが読み込み専用になり、出力実行"" ""ファイルのプログラムデータセクションの前にさまざまな内部データ部分が置かれま"" ""す。"" msgid ""Stack canaries"" msgstr ""スタックカナリア"" msgid """" ""Places values on the stack and verifies their presence to help prevent "" ""buffer overflow attacks."" msgstr """" ""バッファーオーバーフロー攻撃を防ぐ役に立てるために、スタックに値を置き、それ"" ""らの存在を検証します。"" msgid ""Never eXecute (NX)"" msgstr ""Never eXecute (NX)"" msgid """" ""Also known as Data Execution Prevention (DEP), ensures that data sections of "" ""the executable can not be executed."" msgstr """" ""Data Execution Prevention (DEP) としても知られています。実行ファイルのデータ"" ""部分を必ず実行できなくします。"" msgid ""Position Independent Executable (PIE)"" msgstr ""Position Independent Executable (PIE)"" msgid """" ""Produces a position independent executable, which is necessary for ASLR."" msgstr ""位置に依存しない実行ファイルを生成します。ASLR のために必要です。"" msgid ""Address Space Layout Randomization (ASLR)"" msgstr ""Address Space Layout Randomization (ASLR)"" msgid """" ""This ensures that placement of both code and data regions will be "" ""randomized. Enabled by the kernel (all modern Linux kernels support ASLR), "" ""when the executable is built with PIE."" msgstr """" ""コード領域とデータ領域の配置を確実にランダム化します。実行ファイルが PIE を用"" ""いてビルドされるとき、カーネルにより有効化されます (最近の Linux カーネルはす"" ""べて ASLR をサポートします)。"" msgid """" ""We recommend testing your QEMU executable file after it is compiled to "" ""ensure that the compiler hardening worked properly."" msgstr """" ""コンパイラーが確実に適切なセキュリティ強化を動作させるようコンパイルした後"" ""で、お使いの QEMU 実行ファイルをテストすることを推奨します。"" msgid """" ""Most cloud deployments will not want to build software such as QEMU by hand. "" ""It is better to use packaging to ensure that the process is repeatable and "" ""to ensure that the end result can be easily deployed throughout the cloud. "" ""The references below provide some additional details on applying compiler "" ""hardening options to existing packages."" msgstr """" ""ほとんどのクラウド環境は QEMU のようなソフトウェアを手動でビルドしたくないで"" ""しょう。プロセスが確実に繰り返し可能であり、最終結果を簡単にクラウドにデプロ"" ""イできるようにするために、パッケージを使用するほうが良いでしょう。以下の参考"" ""情報は、既存のパッケージにコンパイラーのセキュリティ強化オプションを適用する"" ""ことの詳細を提供します。"" msgid """" ""DEB packages: <link href=\""http://wiki.debian.org/HardeningWalkthrough"" ""\"">Hardening Walkthrough</link>"" msgstr """" ""DEB パッケージ: <link href=\""http://wiki.debian.org/HardeningWalkthrough"" ""\"">Hardening Walkthrough</link>"" msgid """" ""RPM packages: <link href=\""http://fedoraproject.org/wiki/"" ""How_to_create_an_RPM_package\"">How to create an RPM package</link>"" msgstr """" ""RPM パッケージ: <link href=\""http://fedoraproject.org/wiki/"" ""How_to_create_an_RPM_package\"">How to create an RPM package</link>"" msgid ""Mandatory access controls"" msgstr ""強制アクセス制御"" msgid ""sVirt: SELinux and virtualization"" msgstr ""sVirt: SELinux と 仮想化"" msgid """" ""With unique kernel-level architecture and National Security Agency (NSA) "" ""developed security mechanisms, KVM provides foundational isolation "" ""technologies for multi-tenancy. With developmental origins dating back to "" ""2002, the Secure Virtualization (sVirt) technology is the application of "" ""SELinux against modern day virtualization. SELinux, which was designed to "" ""apply separation control based upon labels, has been extended to provide "" ""isolation between virtual machine processes, devices, data files and system "" ""processes acting upon their behalf."" msgstr """" ""KVM は複数のテナントを分離する基本技術を提供します。カーネルレベルの独特の"" ""アーキテクチャーを用いて、National Security Agency (NSA) により開発されたセ"" ""キュリティ機構です。開発の起源は 2002 年までさかのぼり、Secure "" ""Virtualization (sVirt) 技術は最近の仮想化向けの SELinux の応用技術です。"" ""SELinux は、ラベルに基づいた分離制御を適用するために設計され、仮想マシンのプ"" ""ロセス、デバイス、データファイル、それらの上で動作するシステムプロセス間の分"" ""離を提供するために拡張されました。"" msgid """" ""OpenStack's sVirt implementation aspires to protect hypervisor hosts and "" ""virtual machines against two primary threat vectors:"" msgstr """" ""OpenStack の sVirt 実装は、2 種類の主要な脅威ベクターに対して、ハイパーバイ"" ""ザーホストと仮想マシンを保護することを目指しています。"" msgid """" ""Each KVM-based virtual machine is a process which is labeled by SELinux, "" ""effectively establishing a security boundary around each virtual machine. "" ""This security boundary is monitored and enforced by the Linux kernel, "" ""restricting the virtual machine's access to resources outside of its "" ""boundary such as host machine data files or other VMs."" msgstr """" ""各 KVM ベースの仮想マシンは SELinux によりラベル付けされているプロセスです。"" ""これは各仮想マシンのセキュリティ境界を効率的に確立します。このセキュリティ境"" ""界は、Linux カーネルにより監視され、強制されます。ホストマシンのデータファイ"" ""ルや他の仮想マシンのような、仮想マシンの境界外のリソースへのアクセスは制限さ"" ""れます。"" msgid """" ""As shown above, sVirt isolation is provided regardless of the guest "" ""Operating System running inside the virtual machineLinux or Windows VMs can "" ""be used. Additionally, many Linux distributions provide SELinux within the "" ""operating system, allowing the virtual machine to protect internal virtual "" ""resources from threats."" msgstr """" ""上に示したとおり、sVirt による分離は仮想マシン内で動作しているゲストオペレー"" ""ティングシステムに関わらず提供されます。Linux や Windows の仮想マシンを使用で"" ""きます。さらに、多くの Linux ディストリビューションはオペレーティングシステム"" ""内の SELinux を提供しています。仮想マシンが内部の仮想リソースを脅威から保護で"" ""きます。"" msgid ""Labels and categories"" msgstr ""ラベルとカテゴリ"" msgid """" ""KVM-based virtual machine instances are labelled with their own SELinux data "" ""type, known as svirt_image_t. Kernel level protections prevent unauthorized "" ""system processes, such as malware, from manipulating the virtual machine "" ""image files on disk. When virtual machines are powered off, images are "" ""stored as svirt_image_t as shown below:"" msgstr """" ""KVM ベースの仮想マシンインスタンスは、svirt_image_t として知られる、独自の "" ""SELinux データタイプでラベル付けされています。カーネルレベルの保護により、悪"" ""意のあるソフトウェアのような権限のないシステムプロセスが、ディスクにある仮想"" ""マシンのイメージファイルを操作することを防ぎます。仮想マシンが電源オフのと"" ""き、イメージは以下のように svirt_image_t として保存されます。"" msgid ""This example shows the sVirt category identifier:"" msgstr ""この例は sVirt カテゴリー識別子を示します。"" msgid ""Booleans"" msgstr ""ブーリアン"" msgid """" ""To ease the administrative burden of managing SELinux, many enterprise Linux "" ""platforms utilize SELinux Booleans to quickly change the security posture of "" ""sVirt."" msgstr """" ""SELinux の管理負担を減らすために、多くのエンタープライズ Linux プラットフォー"" ""ムは sVirt のセキュリティ設定を簡単に変更するために、SELinux ブーリアンを利用"" ""します。"" msgid """" ""Red Hat Enterprise Linux-based KVM deployments utilize the following sVirt "" ""booleans:"" msgstr """" ""Red Hat Enterprise Linux ベースの KVM 環境は以下の sVirt ブーリアンを利用しま"" ""す。"" msgid ""sVirt SELinux Boolean"" msgstr ""sVirt SELinux ブーリアン"" msgid ""Description"" msgstr ""記述"" msgid ""virt_use_common"" msgstr ""virt_use_common"" msgid ""Allow virt to use serial/parallel communication ports."" msgstr """" ""仮想化がシリアル通信ポートとパラレル通信ポートを使用することを許可します。"" msgid ""virt_use_fusefs"" msgstr ""virt_use_fusefs"" msgid ""Allow virt to read FUSE mounted files."" msgstr ""仮想化が FUSE マウントされたファイルを読み取ることを許可します。"" msgid ""virt_use_nfs"" msgstr ""virt_use_nfs"" msgid ""Allow virt to manage NFS mounted files."" msgstr ""仮想化が NFS マウントされたファイルを管理することを許可します。"" msgid ""virt_use_samba"" msgstr ""virt_use_samba"" msgid ""Allow virt to manage CIFS mounted files."" msgstr ""仮想化が CIFS マウントされたファイルを管理することを許可します。"" msgid ""virt_use_sanlock"" msgstr ""virt_use_sanlock"" msgid ""Allow confined virtual guests to interact with the sanlock."" msgstr ""制限された仮想マシンが sanlock を操作することを許可します。"" msgid ""virt_use_sysfs"" msgstr ""virt_use_sysfs"" msgid ""Allow virt to manage device configuration (PCI)."" msgstr ""仮想マシンがデバイス設定 (PCI) を管理することを許可します。"" msgid ""virt_use_usb"" msgstr ""virt_use_usb"" msgid ""Allow virt to use USB devices."" msgstr ""仮想化が USB デバイスを使用することを許可します。"" msgid ""virt_use_xserver"" msgstr ""virt_use_xserver"" msgid ""Allow virtual machine to interact with the X Window System."" msgstr ""仮想マシンが X Window System と通信することを許可します。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/book-sprint-all-logos.png'; "" ""md5=f2d97c3130c32f31412f5af41ad72d39"" msgstr """" ""@@image: 'static/book-sprint-all-logos.png'; "" ""md5=f2d97c3130c32f31412f5af41ad72d39"" msgid ""Acknowledgments"" msgstr ""謝辞"" msgid """" ""The OpenStack Security Group would like to acknowledge contributions from "" ""the following organizations that were instrumental in making this book "" ""possible. The organizations are:"" msgstr """" ""OpenStack Security Group は、このドキュメントの作成を手助けしていただいた以下"" ""の組織の貢献に感謝いたします。"" msgid ""System documentation"" msgstr ""システムドキュメント"" msgid """" ""The system documentation for an OpenStack cloud deployment should follow the "" ""templates and best practices for the Enterprise Information Technology "" ""System in your organization. Organizations often have compliance "" ""requirements which may require an overall System Security Plan to inventory "" ""and document the architecture of a given system. There are common challenges "" ""across the industry related to documenting the dynamic cloud infrastructure "" ""and keeping the information up-to-date."" msgstr """" ""OpenStack クラウドデプロイメントのシステム文書化は、その組織のエンタープライ"" ""ズ IT システムを対象とするテンプレートとベストプラクティスに従って行うべきで"" ""す。組織には大抵、コンプライアンス要件が設定されており、それによって対象シス"" ""テムのインベントリ作成とアーキテクチャの文書化を行う全体的なシステムセキュリ"" ""ティ計画が義務付けられている場合があります。動的なクラウドインフラストラク"" ""チャーを文書化し、情報を最新の状態に維持するのあたっては、業界全体の共通課題"" ""があります。 "" msgid ""Data encryption"" msgstr ""データ暗号化"" msgid """" ""The importance of encrypting data on behalf of tenants is largely related to "" ""the risk assumed by a provider that an attacker could access tenant data. "" ""There may be requirements here in government, as well as requirements per-"" ""policy, in private contract, or even in case law in regard to private "" ""contracts for public cloud providers. It is recommended that a risk "" ""assessment and legal consul advised before choosing tenant encryption "" ""policies."" msgstr """" ""テナントの為のデータ暗号化の重要性は、攻撃者がテナントデータにアクセスできる"" ""事をプロバイダが想定するリスクに広く関係しています。政府での要件があるかも知"" ""れませんし、（ポリシー単位の要件と同様）パブリッククラウド提供者用の随意契約"" ""に関しては、随意契約の中、あるいは判例法の中でさえ要求されるかも知れません。"" ""テナント暗号化ポリシーを選択する前に、リスク分析と法務コンサルの忠告を受ける"" ""事をお勧めします。"" msgid """" ""Often, data encryption relates positively to the ability to reliably destroy "" ""tenant and per-instance data, simply by throwing away the keys. It should be "" ""noted that in doing so, it becomes of great importance to destroy those keys "" ""in a reliable and secure manner."" msgstr """" ""時々、データ暗号化は単に暗号鍵を捨てるという事による、信頼できるテナントやイ"" ""ンスタンス単位のデータ削除可能性と明確に関係があります。そうするよう記述すべ"" ""きですし、信頼できる安全な方法でこれらの鍵を破壊する事が従来になります。"" msgid ""Opportunities to encrypt data for users are present:"" msgstr ""ユーザ用のデータ暗号化をする機会は現存します。"" msgid ""Object Storage objects"" msgstr ""Object Storage オブジェクト"" msgid ""Network data"" msgstr ""ネットワークデータ"" msgid """" ""The ability to encrypt objects in Object Storage is presently limited to "" ""disk-level encryption per node. However, there does exist third-party "" ""extensions and modules for per-object encryption. These modules have been "" ""proposed upstream, but have not per this writing been formally accepted. "" ""Below are some pointers:"" msgstr """" ""Object Storage 中のオブジェクトの暗号化の可能性は、現時点ではノード単位のディ"" ""スクレベル暗号化に限定されています。しかしながら、オブジェクト単位の暗号化用"" ""のサードパーティ拡張やモジュールが存在します。これらのモジュールはアップスト"" ""リームに提案されていますが、この文書を書いている時点では公式に認可されていま"" ""せん。下記はそれらの幾つかへのポインタです。"" msgid ""https://github.com/Mirantis/swift-encrypt"" msgstr ""https://github.com/Mirantis/swift-encrypt"" msgid """" ""http://www.mirantis.com/blog/on-disk-encryption-prototype-for-openstack-"" ""swift/"" msgstr """" ""http://www.mirantis.com/blog/on-disk-encryption-prototype-for-openstack-"" ""swift/"" msgid ""Block Storage volumes and instance ephemeral filesystems"" msgstr ""Block Storage ボリュームとインスタンスの一時ファイルシステム"" msgid """" ""For the purpose of performance, many storage protocols are unencrypted. Some "" ""protocols such as iSCSI can provide authentication and encrypted sessions, "" ""it is our recommendation to enable these features."" msgstr """" ""性能の為に、多くのストレージプロトコルは暗号化されていません。iSCSI のような"" ""幾つかのプロトコルは、認証と暗号化セッションを提供できます。これらの機能を有"" ""効にする事を推奨します。"" msgid """" ""As both block storage and compute support LVM backed storage, we can easily "" ""provide an example applicable to both systems. In deployments using LVM, "" ""encryption may be performed against the backing physical volumes. An "" ""encrypted block device would be created using the standard Linux tools, with "" ""the LVM physical volume (PV) created on top of the decrypted block device "" ""using pvcreate. Then, the vgcreate or vgmodify tool may be used to add the "" ""encrypted physical volume to an LVM volume group (VG)."" msgstr """" ""Block Storage と Compute は両方、LVM ベースのストレージをサポートしているの"" ""で、両システムに簡単に適用可能な例を提供します。LVM を用いたデプロイでは、暗"" ""号化はベースの物理ボリュームに対して実施できます。暗号化ブロックデバイスは、"" ""pvcreate を使用して復号化したブロックデバイスの上に作成した LVM 物理ボリュー"" ""ム (PV) を用いて、標準の Linux ツールを使用して作成する事ができます。それか"" ""ら、vgcreate 又は vgmodify ツールを使用して、暗号化した物理ボリュームを LVM "" ""のボリュームグループ (VG) に追加できます。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/services-protocols-ports.png'; "" ""md5=fb1e9f47d969127b7a5ca683d38cfe20"" msgstr """" ""@@image: 'static/services-protocols-ports.png'; "" ""md5=fb1e9f47d969127b7a5ca683d38cfe20"" msgid ""System documentation requirements"" msgstr ""システムの文書化における要件"" msgid ""System roles and types"" msgstr ""システムのロールとタイプ"" msgid """" ""The two broadly defined types of nodes that generally make up an OpenStack "" ""installation are:"" msgstr """" ""通常 OpenStack のインストールを構成している、広く定義された 2 つのノードタイ"" ""プは次のとおりです。"" msgid """" ""Compute, storage, or other resource nodes. Provide storage capacity or "" ""virtual machines for your cloud."" msgstr """" ""コンピュート、ストレージ、その他のリソースのノード。クラウド用のストレージ容"" ""量や仮想マシンを提供するノードです。"" msgid ""System inventory"" msgstr ""システムインベントリ"" msgid """" ""Documentation should provide a general description of the OpenStack "" ""environment and cover all systems used (production, development, test, "" ""etc.). Documenting system components, networks, services, and software often "" ""provides the bird's-eye view needed to thoroughly cover and consider "" ""security concerns, attack vectors and possible security domain bridging "" ""points. A system inventory may need to capture ephemeral resources such as "" ""virtual machines or virtual disk volumes that would otherwise be persistent "" ""resources in a traditional IT system."" msgstr """" ""文書には、OpenStack 環境の概要を記載し、使用する全システム (実稼働、開発、テ"" ""ストなど) を対象とするべきです。多くの場合、システムコンポーネント、ネット"" ""ワーク、サービス、およびソフトウェアについて文書化することにより、セキュリ"" ""ティ課題、攻撃ベクトル、考えられるセキュリティドメインのブリッジングポイント"" ""を完全に網羅して検討するにあたって必要な概観が提供されます。システムインベン"" ""トリには、従来の IT システムでは永続的なリソースとされている、仮想マシンや仮"" ""想ディスクボリュームなどの一時的なリソースを取り込む必要がある場合がありま"" ""す。"" msgid ""Hardware inventory"" msgstr ""ハードウェアインベントリ"" msgid ""Software inventory"" msgstr ""ソフトウェアインベントリ"" msgid ""Network topology"" msgstr ""ネットワークトポロジー"" msgid """" ""A network topology should be provided with highlights specifically calling "" ""out the data flows and bridging points between the security domains. Network "" ""ingress and egress points should be identified along with any OpenStack "" ""logical system boundaries. Multiple diagrams may be needed to provide "" ""complete visual coverage of the system. A network topology document should "" ""include virtual networks created on behalf of tenants by the system along "" ""with virtual machine instances and gateways created by OpenStack."" msgstr """" ""ネットワークトポロジーは、セキュリティドメイン間のデータフローとブリッジング"" ""ポイントをはっきりと識別して強調するようにして作成すべきです。OpenStack の論"" ""理的なシステム境界とともに、ネットワークの受信および送信ポイントを明確にする"" ""ことを推奨します。システムを完全に視覚的に網羅するには、図を複数作成する必要"" ""がある場合があります。また、ネットワークトポロジーの文書には、テナントに代"" ""わってシステムが作成した仮想ネットワークや、OpenStack によって作成された仮想"" ""マシンインスタンスとゲートウェイを含めるべきです。"" msgid ""Services, protocols and ports"" msgstr ""サービス、プロトコル、およびポート"" msgid """" ""Referencing a table of services, protocols and ports can help in "" ""understanding the relationship between OpenStack components. It is highly "" ""recommended that OpenStack deployments have information similar to this on "" ""record."" msgstr """" ""サービス、プロトコル、ポートの表を参照すると、OpenStack のコンポーネント間の"" ""関係を理解するのに役立ちます。OpenStack のデプロイメントには、これと同様の情"" ""報を記録することを強く推奨します。"" msgid """" ""As stated during the introduction to Alice's case study, data protection is "" ""of an extremely high priority. She needs to ensure that a compromise of one "" ""tenant's data does not cause loss of other tenant data. She also has strong "" ""regulator requirements that require documentation of data destruction "" ""activities. Alice does this using the following:"" msgstr """" ""アリスのケーススタディで説明したように、データ保護は非常に重要です。アリス"" ""は、あるテナントのデータの情報漏洩が、他のテナントデータの損害を引き起こさな"" ""いように、保証することが必要です。アリスはまた、データ破壊の文書化を必要とす"" ""る強い規制上の要件を持っています。アリスは、以下の方法でこれを提供します："" msgid """" ""Establishing procedures to sanitize tenant data when a program or project "" ""ends."" msgstr """" ""プログラムやプロジェクトが終了する際に、好ましくないテナントデータを削除する"" ""ための手順を確立すること。"" msgid """" ""Track the destruction of both the tenant data and metadata through ticketing "" ""in a CMDB."" msgstr """" ""CMDBのチケット発行を使用して、顧客データとメタデータの両方の破壊を追跡する。"" msgid ""For Volume storage:"" msgstr ""ボリュームストレージ"" msgid ""Physical server issues"" msgstr ""物理サーバーの問題"" msgid """" ""To provide secure ephemeral instance storage, Alice implements qcow2 files "" ""on an encrypted filesystem."" msgstr """" ""安全な一時ディスクを提供するために、アリスは暗号化ファイルシステム上に qcow2 "" ""のファイルを実装しています。"" msgid """" ""As stated during the introduction to Bob's case study, tenant privacy is of "" ""an extremely high priority. In addition to the requirements and actions Bob "" ""will take to isolate tenants from one another at the infrastructure layer, "" ""Bob also needs to provide assurances for tenant data privacy. Bob does this "" ""using the following:"" msgstr """" ""ボブのケーススタディの最初で説明したように、テナントのプライバシーは非常に重"" ""要です。ボブはインフラレイヤーで相互にテナントを分離する要件およびアクション"" ""に加えて、ボブはまたテナントデータのプライバシーを保する必要があります。 ボブ"" ""は以下を用いて、これを提供します："" msgid """" ""Establishing procedures to sanitize customer data when a customer churns."" msgstr """" ""顧客が不適切な顧客データを大量生産する時に、削除するための手順を確立する。"" msgid """" ""Track the destruction of both the customer data and metadata through "" ""ticketing in a CMDB."" msgstr """" ""CMDBのチケット発行を使用して、顧客データとメタデータの両方の破壊を追跡しま"" ""す。"" msgid """" ""To provide secure ephemeral instance storage, Bob implements qcow2 files on "" ""an encrypted filesystems."" msgstr """" ""安全な一時ディスクを提供するために、ボブは暗号化ファイルシステム上に qcow2 の"" ""ファイルを実装しています。"" msgid """" ""Additionally, Bob adds strong network ACL rulesets to enforce which "" ""endpoints can communicate with the message servers. This second control "" ""provides some additional assurance should the other protections fail."" msgstr """" ""さらにボブは、メッセージサーバーと通信できるエンドポイントを、強力なネット"" ""ワークの ACL ルールセットで制限することにしました。この2個目の制限が、他の防"" ""御が失敗した場合の保険として機能します。"" msgid ""Tenant data privacy"" msgstr ""テナントデータのプライバシー"" msgid ""API endpoint configuration recommendations"" msgstr ""APIエンドポイント構成に関する推奨事項"" msgid ""Internal API communications"" msgstr ""内部API通信"" msgid """" ""OpenStack provides both public facing and private API endpoints. By default, "" ""OpenStack components use the publicly defined endpoints. The recommendation "" ""is to configure these components to use the API endpoint within the proper "" ""security domain."" msgstr """" ""OpenStackはパブリックとプライベート両方のAPIエンドポイントを提供します。デ"" ""フォルトではOpenStackコンポーネントはパブリックとして定義されたエンドポイント"" ""を使用します。推奨はこれらのコンポーネントを適切なセキュリティドメイン内で使"" ""用するよう構成することです。"" msgid """" ""Services select their respective API endpoints based on the OpenStack "" ""service catalog. These services might not obey the listed public or internal "" ""API end point values. This can lead to internal management traffic being "" ""routed to external API endpoints."" msgstr """" ""サービスはOpenStackサービスカタログに基づいて、それぞれのAPIエンドポイントを"" ""選択します。これらのサービスは、リストされた外部もしくは内部APIエンドポイント"" ""の値に従わないことがあります。これは内部管理トラフィックが外部APIエンドポイン"" ""トへルーティングされる可能性があります。"" msgid """" ""The Identity service catalog should be aware of your internal URLs. While "" ""this feature is not utilized by default, it may be leveraged through "" ""configuration. Additionally, it should be forward-compatible with expectant "" ""changes once this behavior becomes the default."" msgstr """" ""Identity のカタログは内部 URL を認識できるようにすべきです。この機能はデフォ"" ""ルトで利用されませんが、設定により有効化できます。さらに、この動作が標準にな"" ""ると、予期される変更と前方互換性があるべきです。"" msgid ""To register an internal URL for an endpoint:"" msgstr ""エンドポイント用の内部URL登録"" msgid ""Configure applications for internal URLs"" msgstr ""内部URL用のアプリケーション構成"" msgid """" ""You can force some services to use specific API endpoints. Therefore, it is "" ""recommended that each OpenStack service communicating to the API of another "" ""service must be explicitly configured to access the proper internal API "" ""endpoint."" msgstr """" ""いくつかのサービスは特定のAPIエンドポイントの仕様を強制することができます。"" ""従って、それぞれのOpenStackサービスと他サービスとの通信は明示的に適切な内部"" ""APIエンドポイントへアクセスするよう構成する必要があります。"" msgid ""Configuration example #1: nova"" msgstr ""構成例#1: nova"" msgid ""Configuration example #2: cinder"" msgstr ""構成例#2: cinder"" msgid ""Paste and middleware"" msgstr ""Paste と ミドルウェア"" msgid """" ""Commonly, implementers add middleware to extend OpenStack's base "" ""functionality. We recommend implementers make careful consideration of the "" ""potential exposure introduced by the addition of non-standard software "" ""components to their HTTP request pipeline."" msgstr """" ""実装者がOpenStackの基本機能を拡張するためにミドルウェアを追加することは一般的"" ""です。私たちは非標準のソフトウェアコンポーネントをHTTPリクエストパイプライン"" ""へ追加することによって生じる潜在的なセキュリティについて慎重に検討する事を推"" ""奨しています。"" msgid """" ""For more information about Paste Deploy, see <link href=\""http://pythonpaste."" ""org/deploy/\"">http://pythonpaste.org/deploy/</link>."" msgstr """" ""Paste Deployに関する追加情報は <link href=\""http://pythonpaste.org/deploy/"" ""\"">http://pythonpaste.org/deploy/</link> を参照してください。"" msgid ""API endpoint process isolation and policy"" msgstr ""APIエンドポイントのプロセス分離とポリシー"" msgid ""Namespaces"" msgstr ""名前空間"" msgid """" ""Many operating systems now provide compartmentalization support. Linux "" ""supports namespaces to assign processes into independent domains. Other "" ""parts of this guide cover system compartmentalization in more detail."" msgstr """" ""多くのOSは現在コンパートメント化をサポートしています。Linuxではプロセスに独立"" ""したドメインを割り当てる名前空間をサポートしています。システムのコンパートメ"" ""ント化についてはこのマニュアルの別の部分で詳しく説明されています。"" msgid ""Network policy"" msgstr ""ネットワークポリシー"" msgid """" ""To enforce policies, you can configure services, host-based firewalls (such "" ""as iptables), local policy (SELinux or AppArmor), and optionally global "" ""network policy."" msgstr """" ""ポリシーを強制するために、サービス、ホストベースのファイアウォール(例えば"" ""iptables)、ローカルポリシー(SELinuxやAppArmor)、オプションとしてグローバル"" ""ネットワークポリシーを設定できます。"" msgid ""SAML assertion"" msgstr ""SAML アサーション"" msgid ""Protocol"" msgstr ""プロトコル"" msgid ""For example,"" msgstr ""たとえば、"" msgid ""or"" msgstr ""または"" msgid ""Future"" msgstr ""将来"" msgid ""Data processing"" msgstr ""Data processing"" msgid ""Authorization"" msgstr ""認可"" msgid ""Establish formal access control policies"" msgstr ""公式なアクセス制御ポリシーの確立"" msgid ""Service authorization"" msgstr ""サービス認可"" msgid ""Administrative users"" msgstr ""管理ユーザー"" msgid ""End users"" msgstr ""エンドユーザー"" msgid ""Understanding the audit process"" msgstr ""監査プロセスを理解する"" msgid """" ""Information system security compliance is reliant on the completion of two "" ""foundational processes:"" msgstr """" ""情報システムのセキュリティコンプライアンスは、二つの基本的なプロセスの完了を"" ""前提としています。""msgid ""Determining audit scope"" msgstr ""監査の範囲を決定する""""Determining audit scope, specifically what controls are needed and how to "" ""design or modify an OpenStack deployment to satisfy them, should be the "" ""initial planning step.""""何をコントロールするのか、OpenStack環境をいかにデザイン、変更していくかを明確"" ""にするため、監査範囲は初期の計画段階で決定すべきです。""""When scoping OpenStack deployments for compliance purposes, consider "" ""prioritizing controls around sensitive services, such as command and control "" ""functions and the base virtualization technology. Compromises of these "" ""facilities may impact an OpenStack environment in its entirety.""""OpenStack環境の範囲をコンプライアンス目的で明確化する際は、制御機能や仮想化技"" ""術など、慎重に扱うべきサービスの周辺を優先するよう、考慮すべきです。それらを"" ""妥協することは、OpenStack環境全体に影響を与えかねません。""""Scope reduction helps ensure OpenStack architects establish high quality "" ""security controls which are tailored to a particular deployment, however it "" ""is paramount to ensure these practices do not omit areas or features from "" ""security hardening. A common example is applicable to PCI-DSS guidelines, "" ""where payment related infrastructure may be scrutinized for security issues, "" ""but supporting services are left ignored, and vulnerable to attack.""""範囲を限定することで、限定された環境に対し、OpenStackの設計者は高いセキュリ"" ""ティ品質を確立しやすくなります。しかしその取り組みの中で、セキュリティ強化の"" ""範囲や機能を不当に省かないことが重要です。典型的な例はPCI-DSSガイドラインで"" ""す。決済に関わるインフラはセキュリティを精査されるでしょう。が、その影でその"" ""周辺サービスが放置されれば、そこが攻撃に対し無防備となります。"" msgid """" ""When addressing compliance, you can increase efficiency and reduce work "" ""effort by identifying common areas and criteria that apply across multiple "" ""certifications. Much of the audit principles and guidelines discussed in "" ""this book will assist in identifying these controls, additionally a number "" ""of external entities provide comprehensive lists. The following are some "" ""examples:"" msgstr """" ""コンプライアンスに取り組む際、複数の認証で共通の領域と基準を明確にできれば、"" ""効率的に手間を減らすことができます。この本で取り上げている監査原則とガイドラ"" ""インの多くは、それらを特定するのに役立ちます。加えて、総合的なリストを提供す"" ""るガイドラインが多くあります。以下に例を挙げます。"" msgid """" ""The <link href=\""https://cloudsecurityalliance.org/research/ccm/\"">Cloud "" ""Security Alliance Cloud Controls Matrix</link> (CCM) assists both cloud "" ""providers and consumers in assessing the overall security of a cloud "" ""provider. The CSA CMM provides a controls framework that map to many "" ""industry-accepted standards and regulations including the ISO 27001/2, "" ""ISACA, COBIT, PCI, NIST, Jericho Forum and NERC CIP."" msgstr """" ""<link href=\""https://cloudsecurityalliance.org/research/ccm/\"">Cloud "" ""Security Alliance Cloud Controls Matrix</link> (CCM)はクラウドプロバイダーの"" ""セキュリティを総合的に評価するにあたって、プロバイダーとユーザーの両方に役立"" ""ちます。CSA CCMはISO 27001/2、ISACA、COBIT、PIC、NIST、Jericho Forum、NERC "" ""CIPといった、多くの業界で認められた標準、規制をひも付けた統制フレームワークを"" ""提供します。"" msgid """" ""The <link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP "" ""Security Guide</link> is another useful reference. This is still an emerging "" ""source, but we anticipate that this will grow into a tool with controls "" ""mappings that are more focused on the US federal government certifications "" ""and recommendations. For example, the SCAP Security Guide currently has some "" ""mappings for security technical implementation guides (STIGs) and "" ""NIST-800-53."" msgstr """" ""<link href=\""https://fedorahosted.org/scap-security-guide/\"">SCAP Security "" ""Guide</link>はもうひとつの有用なリファレンスです。まだ出来たばかりですが、米"" ""国連邦政府の認証、推奨への対応に重点を絞ったツールとして普及すると予想されま"" ""す。例えば、SCAP Security Guideは現在、security technical implementation "" ""guides (STIGs)とNIST-800-53にある程度対応しています。"" msgid """" ""These control mappings will help identify common control criteria across "" ""certifications, and provide visibility to both auditors and auditees on "" ""problem areas within control sets for particular compliance certifications "" ""and attestations."" msgstr """" ""これらのコントロールマッピングは、認証間で共通の統制基準を特定します。また、"" ""監査人と被監査者両方にとって問題となる、特定のコンプライアンス認証、認定に必"" ""要なコントロールセットを可視化するのに役立ちます。"" msgid ""Internal audit"" msgstr ""内部監査"" msgid """" ""Once a cloud is deployed, it is time for an internal audit. This is the time "" ""compare the controls you identified above with the design, features, and "" ""deployment strategies utilized in your cloud. The goal is to understand how "" ""each control is handled and where gaps exist. Document all of the findings "" ""for future reference."" msgstr """" ""クラウドが導入されたのであれば、内部監査が必要です。あなたが採用を決めた統制"" ""基準と、あなたのクラウドの設計、機能、配備戦略を比較する時です。目的はそれぞ"" ""れの統制がどのように扱われているか、ギャップがどこに存在するか、理解すること"" ""です。そして、その全てを将来のために文書化します。"" msgid """" ""When auditing an OpenStack cloud it is important to appreciate the multi-"" ""tenant environment inherent in the OpenStack architecture. Some critical "" ""areas for concern include data disposal, hypervisor security, node "" ""hardening, and authentication mechanisms."" msgstr """" ""OpenStackクラウドを監査するとき、OpenStackアーキテクチャ固有のマルチテナント"" ""環境を理解することが重要です。データの廃棄、ハイパーバイザーのセキュリティ、"" ""ノードの強化、および認証メカニズムなど、いくつか重要な部分があります。"" msgid ""Prepare for external audit"" msgstr ""外部監査に備える"" msgid """" ""Once the internal audit results look good, it is time to prepare for an "" ""external audit. There are several key actions to take at this stage, these "" ""are outlined below:"" msgstr """" ""内部監査の結果が良好であれば、いよいよ外部監査の準備です。この段階では、いく"" ""つかの鍵となる活動があります。概要は以下です。"" msgid """" ""Maintain good records from your internal audit. These will prove useful "" ""during the external audit so you can be prepared to answer questions about "" ""mapping the compliance controls to a particular deployment."" msgstr """" ""内部監査での良好な状態を維持してください。それらは外部監査の実施期間に証明と"" ""して役立ちます。またそれは、コンプライアンス統制に関する詳細な質疑応答の備え"" ""となります。"" msgid """" ""Deploy automated testing tools to ensure that the cloud remains compliant "" ""over time."" msgstr """" ""クラウドがコンプライアンスを維持し続けるために、自動テストツールを導入してく"" ""ださい。"" msgid ""Select an auditor."" msgstr ""監査人を選ぶ"" msgid """" ""Selecting an auditor can be challenging. Ideally, you are looking for "" ""someone with experience in cloud compliance audits. OpenStack experience is "" ""another big plus. Often it is best to consult with people who have been "" ""through this process for referrals. Cost can vary greatly depending on the "" ""scope of the engagement and the audit firm considered."" msgstr """" ""監査人の選定は困難を伴うことがあります。クラウドのコンプライアンス監査経験が"" ""ある人を見つけてくるのが理想です。OpenStackの経験があれば、なお良しです。この"" ""プロセスを経験している人に相談するのがベストでしょう。なお、費用は契約の範囲"" ""と監査法人に大きく依存します。"" msgid ""External audit"" msgstr ""外部監査"" msgid """" ""This is the formal audit process. Auditors will test security controls in "" ""scope for a specific certification, and demand evidentiary requirements to "" ""prove that these controls were also in place for the audit window (for "" ""example SOC 2 audits generally evaluate security controls over a 6-12 months "" ""period). Any control failures are logged, and will be documented in the "" ""external auditors final report. Dependent on the type of OpenStack "" ""deployment, these reports may be viewed by customers, so it is important to "" ""avoid control failures. This is why audit preparation is so important."" msgstr """" ""これが正式な監査プロセスです。監査人は、特定の認定向けのセキュリティ統制を確"" ""認し、これらの統制が監査期間において整っているか証明する根拠を要求します (た"" ""とえば、SOC 2監査は一般的に6-12ヶ月のセキュリティ統制を評価します)。どのよう"" ""な統制上の不具合も記録され、外部監査の最終報告書で文書化されます。OpenStack環"" ""境の種別に依存しますが、これらの報告書は顧客に公開されるでしょう。それゆえ統"" ""制上の不具合を避けることは重要です。これが監査への準備が重要であることの理由"" ""です。"" msgid ""Compliance maintenance"" msgstr ""コンプライアンスの維持"" msgid """" ""The process doesn't end with a single external audit. Most certifications "" ""require continual compliance activities which means repeating the audit "" ""process periodically. We recommend integrating automated compliance "" ""verification tools into a cloud to ensure that it is compliant at all times. "" ""This should be in done in addition to other security monitoring tools. "" ""Remember that the goal is both security <emphasis>and</emphasis> compliance. "" ""Failing on either of these fronts will significantly complicate future "" ""audits."" msgstr """" ""このプロセスは一度の外部監査で終わることがありません。多くの認証は継続的なコ"" ""ンプライアンス活動、すなわち、定期的な監査を要求します。わたしたちは、常に準"" ""拠を確実にするために、自動化されたコンプライアンス検証ツールをクラウド内に作"" ""ることをおすすめします。これは他のセキュリティ監視ツールに加え実装されるべき"" ""です。このゴールがセキュリティ<emphasis>および</emphasis>コンプライアンスであ"" ""ることを忘れないでください。これらのどちらかに不具合があれば、将来の監査にお"" ""いて非常に面倒なことになります。"" msgid ""Certification and compliance statements"" msgstr ""認証とコンプライアンスの報告書"" msgid """" ""Compliance and security are not exclusive, and must be addressed together. "" ""OpenStack deployments are unlikely to satisfy compliance requirements "" ""without security hardening. The listing below provides an OpenStack "" ""architect foundational knowledge and guidance to achieve compliance against "" ""commercial and government certifications and standards."" msgstr """" ""コンプライアンスとセキュリティは排他的でなく、あわせて取り組むべきものです。"" ""OpenStack環境は、セキュリティの強化なしに、コンプライアンス要件を充足すること"" ""ができないでしょう。以下のリストは、OpenStackアーキテクト向けの、商業規格およ"" ""び政府機関の認証を得るための基本的な知識とガイダンスです。"" msgid ""Commercial standards"" msgstr ""商業規格"" msgid """" ""For commercial deployments of OpenStack, it is recommended that SOC 1/2 "" ""combined with ISO 2700 1/2 be considered as a starting point for OpenStack "" ""certification activities. The required security activities mandated by these "" ""certifications facilitate a foundation of security best practices and common "" ""control criteria that can assist in achieving more stringent compliance "" ""activities, including government attestations and certifications."" msgstr """" ""OpenStackの商用環境向けには、まずは開始点として、SOC 1/2とISO 27001/2の検討を"" ""推奨します。そこで要求されるセキュリティ活動を確実に実行することで、セキュリ"" ""ティのベストプラクティスと共通統制基準を導入を促進し、政府系認定などの、より"" ""厳格なコンプライアンス活動の取得にも役立ちます。"" msgid """" ""After completing these initial certifications, the remaining certifications "" ""are more deployment specific. For example, clouds processing credit card "" ""transactions will need PCI-DSS, clouds storing health care information "" ""require HIPAA, and clouds within the federal government may require FedRAMP/"" ""FISMA, and ITAR, certifications."" msgstr """" ""これらの基本的認証を取得したのち、より環境特有の認証を検討します。たとえば、"" ""クラウドがクレジットカードのトランザクションを扱うのであればPCI-DSSが必要です"" ""し、ヘルスケア情報を保持するならHIPPAが、連邦政府向けにはFedRAMP/FISMA、ITAR"" ""認証が必要となるでしょう。"" msgid ""SOC 1 (SSAE 16) / ISAE 3402"" msgstr ""SOC 1 (SSAE 16) / ISAE 3402"" msgid """" ""Service Organization Controls (SOC) criteria are defined by the <link href="" ""\""http://www.aicpa.org/\"">American Institute of Certified Public "" ""Accountants</link> (AICPA). SOC controls assess relevant financial "" ""statements and assertions of a service provider, such as compliance with the "" ""Sarbanes-Oxley Act. SOC 1 is a replacement for Statement on Auditing "" ""Standards No. 70 (SAS 70) Type II report. These controls commonly include "" ""physical data centers in scope."" msgstr """" ""Service Organization Controls (SOC)基準は米国公認会計士協会 - <link href="" ""\""http://www.aicpa.org/\"">American Institute of Certified Public "" ""Accountants</link> (AICPA)によって定められています。SOC統制はサービスプロバイ"" ""ダーの関連財務諸表と主張を評価します。例えばSarbanes-Oxley法への準拠などで"" ""す。SOC 1 はStatement on Auditing Standards No. 70 (SAS 70) Type II 報告書を"" ""代替します。これらの統制は物理的なデータセンターを評価範囲に含みます。"" msgid ""There are two types of SOC 1 reports:"" msgstr ""SOC 1報告書には二つの種類があります。"" msgid """" ""Type 1 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design of the controls to achieve the related control objectives included in "" ""the description as of a specified date."" msgstr """" ""Type 1 - サービス提供組織がその管理について説明し、その公正さをレポートしま"" ""す。特定時点で関連する管理対象を統制できているか、その設計の持続可能性も報告"" ""します。"" msgid """" ""Type 2 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design and operating effectiveness of the controls to achieve the related "" ""control objectives included in the description throughout a specified period"" msgstr """" ""Type 2 - サービス組織が統制対象を統制するために使用するシステム、設計の持続"" ""性、および運用効率性に関する管理者の説明内容が公正かをレポートします。特定期"" ""間を通しての説明も必要です。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC1Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to User Entities' Internal "" ""Control over Financial Reporting</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC1Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to User Entities' Internal "" ""Control over Financial Reporting</link>を参照してください。"" msgid ""SOC 2"" msgstr ""SOC 2"" msgid """" ""Service Organization Controls (SOC) 2 is a self attestation of controls that "" ""affect the security, availability, and processing integrity of the systems a "" ""service organization uses to process users' data and the confidentiality and "" ""privacy of information processed by these system. Examples of users are "" ""those responsible for governance of the service organization; customers of "" ""the service organization; regulators; business partners; suppliers and "" ""others who have an understanding of the service organization and its "" ""controls."" msgstr """" ""Service Organization Controls (SOC) 2は、サービス提供組織がユーザーデータとそ"" ""の情報の機密性とプライバシーを制御するために使っているシステムのセキュリ"" ""ティ、可用性、および処理の完全性に関する統制の自己証明です。ユーザーの例は、"" ""サービス組織を統制する人、サービス組織の顧客、監視当局、ビジネスパートナー、"" ""サプライヤー、およびサービス組織の理解者やそれを統制する人です。"" msgid ""There are two types of SOC 2 reports:"" msgstr ""SOC 2報告書には二つの種類があります。"" msgid """" ""Type 2 - report on the fairness of the presentation of management's "" ""description of the service organization's system and the suitability of the "" ""design and operating effectiveness of the controls to achieve the related "" ""control objectives included in the description throughout a specified period."" msgstr """" ""Type 2 - サービス組織が統制対象を統制するために使用するシステム、設計の持続"" ""性、および運用効率性に関する管理者の説明内容が公正かをレポートします。特定期"" ""間を通しての説明も必要です。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC2Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to Security, Availability, "" ""Processing Integrity, Confidentiality or Privacy</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC2Report.aspx\"">AICPA Report on "" ""Controls at a Service Organization Relevant to Security, Availability, "" ""Processing Integrity, Confidentiality or Privacy</link>を参照してください。"" msgid ""SOC 3"" msgstr ""SOC 3"" msgid """" ""Service Organization Controls (SOC) 3 is a trust services report for service "" ""organizations. These reports are designed to meet the needs of users who "" ""want assurance on the controls at a service organization related to "" ""security, availability, processing integrity, confidentiality, or privacy "" ""but do not have the need for or the knowledge necessary to make effective "" ""use of a SOC 2 Report. These reports are prepared using the AICPA/Canadian "" ""Institute of Chartered Accountants (CICA) Trust Services Principles, "" ""Criteria, and Illustrations for Security, Availability, Processing "" ""Integrity, Confidentiality, and Privacy. Because they are general use "" ""reports, SOC 3 Reports can be freely distributed or posted on a website as a "" ""seal."" msgstr """" ""Service Organization Controls (SOC) 3はサービス提供組織のための公的なサービス"" ""報告書です。これらのレポートはサービス組織のセキュリティ、可用性、処理の完全"" ""性、機密性、またはプライバシーに関する統制の保証を求めるユーザーニーズを満た"" ""すためのレポートです。ただし、SOC 2報告書ほどの情報は必要ありません。SOC 3報"" ""告書はAICPA/Canadian Institute of Chartered Accountants (CICA)のTrust "" ""Services Principles, Criteria, and Illustrations for Security, Availability, "" ""Processing Integrity, Confidentiality, and Privacyをもって作成されています。"" ""SOC 3は一般的に使われる報告書であり、Webサイト上で証明書として自由に配布でき"" ""ます。"" msgid """" ""For more details see the <link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC3Report.aspx\"">AICPA Trust Services "" ""Report for Service Organizations</link>."" msgstr """" ""詳細は<link href=\""http://www.aicpa.org/InterestAreas/FRC/"" ""AssuranceAdvisoryServices/Pages/AICPASOC3Report.aspx\"">AICPA Trust Services "" ""Report for Service Organizations</link>を参照してください。"" msgid ""ISO 27001/2"" msgstr ""ISO 27001/2"" msgid """" ""The ISO/IEC 27001/2 standards replace BS7799-2, and are specifications for "" ""an Information Security Management System (ISMS). An ISMS is a comprehensive "" ""set of policies and processes that an organization creates and maintains to "" ""manage risk to information assets. These risks are based upon the "" ""confidentiality, integrity, and availability (CIA) of user information. The "" ""CIA security triad has been used as a foundation for much of the chapters in "" ""this book."" msgstr """" ""ISO/IEC 27001/2はBS7799-2の後継標準で、Information Security Management "" ""System (ISMS)の要件です。ISMSは組織が情報資産のリスクを管理するために作成、維"" ""持する、ポリシーとプロセスの包括的なセットです。それらのリスクはユーザー情報"" ""のConfidentiality - 機密性、Integrity - 完全性、および Availability - 可用性 "" ""(CIA)に深く関係しています。CIAセキュリティの三要素は、このガイドの多くの章で"" ""基本となっています。"" msgid """" ""For more details see <link href=\""http://www.27000.org/iso-27001.htm\"">ISO "" ""27001</link>."" msgstr """" ""詳細は<link href=\""http://www.27000.org/iso-27001.htm\"">ISO 27001</link>を参"" ""照してください。"" msgid ""HIPAA / HITECH"" msgstr ""HIPAA / HITECH"" msgid """" ""The Health Insurance Portability and Accountability Act (HIPAA) is a United "" ""States congressional act that governs the collection, storage, use and "" ""destruction of patient health records. The act states that Protected Health "" ""Information (PHI) must be rendered \""unusable, unreadable, or indecipherable"" ""\"" to unauthorized persons and that encryption for data 'at-rest' and "" ""'inflight' should be addressed."" msgstr """" ""Health Insurance Portability and Accountability Act (HIPAA)は米国の健康保険に"" ""おける可搬性と責任に関する法律で、カルテ情報の収集、保存、および廃棄に関する"" ""ルールを定めています。この法律は、保護医療情報 (Protected Health "" ""Information, PHI)は、権限のない人が\""利用できない、読めない、複合できない\""よ"" ""うに変換されなければいけないこと、また、データが保存中でも、処理中でも、暗号"" ""化するべきであることに言及しています。"" msgid """" ""HIPAA is not a certification, rather a guide for protecting healthcare data. "" ""Similar to the PCI-DSS, the most important issues with both PCI and HIPPA is "" ""that a breach of credit card information, and health data, does not occur. "" ""In the instance of a breach the cloud provider will be scrutinized for "" ""compliance with PCI and HIPPA controls. If proven compliant, the provider "" ""can be expected to immediately implement remedial controls, breach "" ""notification responsibilities, and significant expenditure on additional "" ""compliance activities. If not compliant, the cloud provider can expect on-"" ""site audit teams, fines, potential loss of merchant ID (PCI), and massive "" ""reputation impact."" msgstr """" ""HIPPAは認証ではなく、カルテ情報の保護に関するガイドラインです。PCI-DSSと似て"" ""います。PCIとHIPAAの両方でもっとも重要な課題は、クレジットカード情報とカルテ"" ""情報が流出しないようにすることです。クラウドプロバイダーによる流出があった場"" ""合、PCIとHIPAAの統制下において検査されます。その内容が遵守に足るものであれ"" ""ば、そのプロバイダーはすみやかに是正措置の実行と情報流出の通知、およびコンプ"" ""ライアンス活動予算の大幅な追加を期待されます。もし足るものでなければ、現地で"" ""の査察、罰金、merchant ID (PCI)の失効、および評判に大きな傷がつくことが予想さ"" ""れます。"" msgid """" ""Users or organizations that possess PHI must support HIPAA requirements and "" ""are HIPAA covered entities. If an entity intends to use a service, or in "" ""this case, an OpenStack cloud that might use, store or have access to that "" ""PHI, then a Business Associate Agreement must be signed. The BAA is a "" ""contract between the HIPAA covered entity and the OpenStack service provider "" ""that requires the provider to handle that PHI in accordance with HIPAA "" ""requirements. If the service provider does not handle the PHI, such as with "" ""security controls and hardening, then they are subject to HIPAA fines and "" ""penalties."" msgstr """" ""カルテ情報を所有するユーザーや組織はHIPPAの要件をサポートし、HIPAA対象事業者"" ""となる必要があります。もしこの事業者がサービスを、この場合は対象のOpenStackク"" ""ラウドがカルテ情報を利用、保存、アクセスしうるのであれば、HIPAA Business "" ""Associate Agreement - BAAの締結が必要です。BAAはHIPAA対象事業者と、HIPAA要件"" ""に従ってカルテ情報を扱っているOpenStackサービスプロバイダーの間で締結されま"" ""す。もしサービスプロバイダーがセキュリティ統制、強化を怠るなど、カルテ情報を"" ""要件通りに扱っていなければHIPAAの罰金や罰則が適用されることがあります。"" msgid """" ""OpenStack architects interpret and respond to HIPAA statements, with data "" ""encryption remaining a core practice. Currently this would require any "" ""protected health information contained within an OpenStack deployment to be "" ""encrypted with industry standard encryption algorithms. Potential future "" ""OpenStack projects such as object encryption will facilitate HIPAA "" ""guidelines for compliance with the act."" msgstr """" ""OpenStackアーキテクトはHIPAAの条項を解釈し、対応します。データ暗号化はその中"" ""核となる活動です。現在、OpenStack環境に保存される、いかなる保護カルテ情報にも"" ""暗号化を要求され、業界標準の暗号化アルゴリズムの採用が期待されます。なお、将"" ""来予定されている、例えばオブジェクト暗号化などのOpenStackプロジェクトは、法令"" ""遵守のためHPAAガイドラインの適用を促進するでしょう。"" msgid """" ""For more details see the <link href=\""https://www.cms.gov/Regulations-and-"" ""Guidance/HIPAA-Administrative-Simplification/HIPAAGenInfo/downloads/HIPAALaw."" ""pdf\"">Health Insurance Portability And Accountability Act</link>."" msgstr """" ""詳細は<link href=\""https://www.cms.gov/Regulations-and-Guidance/HIPAA-"" ""Administrative-Simplification/HIPAAGenInfo/downloads/HIPAALaw.pdf\"">Health "" ""Insurance Portability And Accountability Act</link>を参照してください。"" msgid ""PCI-DSS"" msgstr ""PCI-DSS"" msgid """" ""The Payment Card Industry Data Security Standard (PCI DSS) is defined by the "" ""Payment Card Industry Standards Council, and created to increase controls "" ""around card holder data to reduce credit card fraud. Annual compliance "" ""validation is assessed by an external Qualified Security Assessor (QSA) who "" ""creates a Report on Compliance (ROC), or by a Self-Assessment Questionnaire "" ""(SAQ) dependent on volume of card-holder transactions."" msgstr """" ""Payment Card Industry Data Security Standard (PCI DSS)はPayment Card "" ""Industry Standards Councilで定義されました。目的は、クレジットカード不正の防"" ""止のため、カード所有者情報に関する統制度を向上することです。コンプライアンス"" ""検査は年次で、外部のコンプライアンス評価報告書(Report on Compliance, ROC)を作"" ""成する認定評価機関 (Qualified Security Assessor, QSA)、もしくは、自己評価問診"" ""票(Self-Assessment Questionnaire, SAQ)によって実施されます。これはカード所有"" ""者のトランザクション量に依存します。"" msgid """" ""OpenStack deployments which stores, processes, or transmits payment card "" ""details are in scope for the PCI-DSS. All OpenStack components that are not "" ""properly segmented from systems or networks that handle payment data fall "" ""under the guidelines of the PCI-DSS. Segmentation in the context of PCI-DSS "" ""does not support multi-tenancy, but rather physical separation (host/"" ""network)."" msgstr """" ""カード情報を保存、処理、転送するOpenStack環境は、PCI-DSSの対象です。カード情"" ""報を扱うシステムやネットワークが正しく分離されていないすべてのOpenStackコン"" ""ポーネントは、PCI-DSSのガイドラインに適合しません。PCI-DSSでいう分離は、マル"" ""チ手ナンシーを認めておらず、(サーバーおよびネットワークの)物理的な分離が必要"" ""です。"" msgid """" ""For more details see <link href=\""https://www.pcisecuritystandards.org/"" ""security_standards/\"">PCI security standards</link>."" msgstr """" ""詳細は<link href=\""https://www.pcisecuritystandards.org/security_standards/"" ""\"">PCI security standards</link>を参照してください。"" msgid ""Government standards"" msgstr ""政府標準"" msgid ""FedRAMP"" msgstr ""FedRAMP"" msgid """" ""\""The <link href=\""http://www.fedramp.gov\"">Federal Risk and Authorization "" ""Management Program</link> (FedRAMP) is a government-wide program that "" ""provides a standardized approach to security assessment, authorization, and "" ""continuous monitoring for cloud products and services\"". NIST 800-53 is the "" ""basis for both FISMA and FedRAMP which mandates security controls "" ""specifically selected to provide protection in cloud environments. FedRAMP "" ""can be extremely intensive from specificity around security controls, and "" ""the volume of documentation required to meet government standards."" msgstr """" ""\""<link href=\""http://www.fedramp.gov\"">Federal Risk and Authorization "" ""Management Program</link> (FedRAMP)は米国連邦政府全体のプログラムであり、クラ"" ""ウド製品とサービスのセキュリティ評価、認証、および継続的モニタリングの、標準"" ""化された手順を提供します\"" NIST 800-53はFISMAとRedRAMPの両方の基礎であり、特"" ""にクラウド環境における保護を提供するために選択されたセキュリティ統制を強制し"" ""ます。セキュリティ統制に関する具体性と政府標準を満たすための文書量を、FedRAMP"" ""は徹底しています。"" msgid """" ""For more details see <link href=\""http://www.gsa.gov/portal/"" ""category/102371\"">http://www.gsa.gov/portal/category/102371</link>."" msgstr """" ""詳細は<link href=\""http://www.gsa.gov/portal/category/102371\"">http://www."" ""gsa.gov/portal/category/102371</link>を参照してください。"" msgid ""ITAR"" msgstr ""ITAR"" msgid """" ""The International Traffic in Arms Regulations (ITAR) is a set of United "" ""States government regulations that control the export and import of defense-"" ""related articles and services on the United States Munitions List (USML) and "" ""related technical data. ITAR is often approached by cloud providers as an "" ""\""operational alignment\"" rather than a formal certification. This typically "" ""involves implementing a segregated cloud environment following practices "" ""based on the NIST 800-53 framework, as per FISMA requirements, complemented "" ""with additional controls restricting access to \""U.S. Persons\"" only and "" ""background screening."" msgstr """" ""International Traffic in Arms Regulations (ITAR)は米国政府規制の集合であり、"" ""米国軍需品リスト(United States Munitions List, USML)と関連技術情報に関係する"" ""防衛物品・サービスの輸出入を統制します。ITARは正式な認証というより、\""軍事活"" ""動支援\""の位置づけでクラウドプロバイダーから提示されます。この統制は一般的"" ""に、NIST 800-53フレームワークにもとづき、分離されたクラウド環境の実装を意味し"" ""ます。FISMA要件により、米国民かつ身元審査された人のみがアクセスできるよう、追"" ""加の統制で補完します。"" msgid """" ""For more details see <link href=\""https://www.pmddtc.state.gov/"" ""regulations_laws/itar.html\"">https://www.pmddtc.state.gov/regulations_laws/"" ""itar.html</link>."" msgstr """" ""詳細は <link href=\""https://www.pmddtc.state.gov/regulations_laws/itar.html"" ""\"">https://www.pmddtc.state.gov/regulations_laws/itar.html</link> を参照して"" ""ください。"" msgid ""FISMA"" msgstr ""FISMA"" msgid """" ""The Federal Information Security Management Act requires that government "" ""agencies create a comprehensive plan to implement numerous government "" ""security standards, and was enacted within the E-Government Act of 2002. "" ""FISMA outlines a process, which utilizing multiple NIST publications, "" ""prepares an information system to store and process government data."" msgstr """" ""米国連邦情報セキュリティマネジメント法 - Federal Information Security "" ""Management Act requires、FISMAは、政府機関は多数の政府セキュリティ標準を実装"" ""するために、包括的な計画を作成する必要があるとして、2002年 電子政府法 - E-"" ""Government Act of 2002 内で制定されました。FISMAは多数のNIST公表文献を活用"" ""し、政府のデータを保存、処理する情報システムを作成するためのプロセスを説明し"" ""ています。"" msgid ""This process is broken apart into three primary categories:"" msgstr ""このプロセスは三つの主要カテゴリに分割されています。""""<emphasis role=\""bold\"">Control selection:</emphasis>Based upon system "" ""security category as defined in FIPS 199, an organization utilizes FIPS 200 "" ""to identify specific security control requirements for the information "" ""system. For example, if a system is categorized as \""moderate\"" a "" ""requirement may be introduced to mandate \""secure passwords\"".""""<emphasis role=\""bold\"">統制の選択</emphasis> FIPS 199で定められたシステムセ"" ""キュリティのカテゴリにもとづき、組織は情報システムのための特定のセキュリティ"" ""統制要求を特定すべく、FIPS 200を活用します 。たとえば、もしシステムが「中程"" ""度」と分類されているのであれば、「安全なパスワード」の強制が求められるでしょ"" ""う。""""<emphasis role=\""bold\"">Control tailoring:</emphasis> Once system security "" ""controls are identified, an OpenStack architect will utilize NIST 800-53 to "" ""extract tailored control selection. For example, specification of what "" ""constitutes a \""secure password\"".""""<emphasis role=\""bold\"">統制の適用</emphasis> システムのセキュリティが特定さ"" ""れれば、OpenStackアーキテクトは選択した統制を適用するために、NIST 800-53を活"" ""用します。たとえば、「安全なパスワード」の構成を仕様化するなど。""msgid ""Object Storage"" msgstr ""Object Storage"" ""For this document the components will be grouped into the following primary "" ""groups:""""このドキュメントの場合、コンポーネントは以下の主要なグループに分けています。"" msgid ""Proxy services"" msgstr ""プロキシサービス"" msgid ""Auth services"" msgstr ""認証サービス"" msgid ""Storage services"" msgstr ""ストレージサービス"" msgid ""Account service"" msgstr ""アカウントサービス"" msgid ""Container service"" msgstr ""コンテナーサービス"" msgid ""Object service"" msgstr ""オブジェクトサービス"" ""An example diagram from the OpenStack Object Storage Administration Guide "" ""(2013)"" msgstr ""OpenStack Object Storage Administration Guide (2013) からのサンプル図"" msgid ""First thing to secure: the network"" msgstr ""最初にセキュア化するもの: ネットワーク"" msgid ""One as a \""public\"" interface for consumers to reach"" msgstr ""利用者が到達できる「パブリック」インターフェースとして一つ"" msgid ""Another as a \""private\"" interface with access to the storage nodes""""ストレージノードにアクセスする「プライベート」インターフェースとしてもう一つ"" msgid ""The following figure demonstrates one possible network architecture."" msgstr ""以下の図はある実現可能なネットワークアーキテクチャを説明します。"" msgid ""Object Storage network architecture with a management node (OSAM)""""マネジメントノードを持つオブジェクトストレージネットワークアーキテクチャー "" ""(OSAM: Object storage network architecture with a management node)"" msgid ""Securing services: general"" msgstr ""サービスのセキュア化: 一般"" msgid ""File permissions"" msgstr ""ファイルパーミッション""""The <filename>/etc/swift</filename> directory contains information about the "" ""ring topology and environment configuration. The following permissions are "" ""recommended:""""<filename>/etc/swift</filename> はリングのトポロジーと環境設定に関する情報を"" ""含みます。以下のパーミッションが推奨されます。"" msgid ""Securing storage services"" msgstr ""ストレージサービスのセキュア化""""The following are the default listening ports for the various storage "" ""services:"" msgstr ""以下はさまざまなストレージサービスのデフォルトのリッスンポートです。"" msgid ""Service name"" msgstr ""サービス名"" msgid ""Port"" msgstr ""ポート"" msgid ""Type"" msgstr ""種別"" msgid ""6002"" msgstr ""6002"" msgid ""TCP"" msgstr ""TCP"" msgid ""6001"" msgstr ""6001"" msgid ""6000"" msgstr ""6000"" msgid ""873"" msgstr ""873"" msgid ""OpenStack Object Storage containers"" msgstr ""OpenStack Object Storage コンテナー"" msgid """" ""Collection of objects. Metadata on the container is available for ACLs. The "" ""meaning of ACLs is dependent on the authentication system used.""""オブジェクトの集合体。コンテナーにあるメタデータは ACL が利用可能です。ACL の"" ""意味は使用する認証システムに依存します。"" msgid ""OpenStack Object Storage objects"" msgstr ""OpenStack Object Storage オブジェクト"" msgid ""Securing proxy services"" msgstr ""プロキシサービスのセキュア化"" msgid ""HTTP listening port"" msgstr ""HTTP リッスンポート""""The method for configuring your web server to start and run as a non-root "" ""user varies by web server and OS.""""ウェブサーバーを root 以外のユーザーで起動して実行する設定方法はウェブサー"" ""バーと OS により異なります。"" msgid ""Load balancer"" msgstr ""負荷分散装置"" msgid ""TempAuth"" msgstr ""TempAuth"" msgid ""Keystone"" msgstr ""Keystone""""Keystone is the commonly used Identity provider in OpenStack. It may also be "" ""used for authentication in Object Storage. Coverage of securing keystone is "" ""already provided in <xref linkend=\""identity\""/>.""""Keystone が OpenStack で一般的に使用される認証プロバイダーです。これは "" ""Object Storage でも認証のために使用できます。keystone のセキュア化については"" ""すでに <xref linkend=\""identity\""/> で提供されています。"" msgid ""Other notable items"" msgstr ""他の重要事項"" msgid ""End entity"" msgstr ""エンドエンティティ"" msgid ""User, process, or system that is the subject of a certificate."" msgstr ""証明対象のユーザ、プロセス、システム。"" msgid ""Certification Authority (<glossterm>CA</glossterm>)"" msgstr ""認証局 (<glossterm>CA</glossterm>)"" msgid ""Defines certificate policies, management, and issuance of certificates."" msgstr ""証明ポリシーの定義、管理、証明書の発行。"" msgid ""Registration Authority (RA)"" msgstr ""登録局 (RA)"" msgid """" ""An optional system to which a CA delegates certain management functions."" msgstr ""CAが一定の管理機能を委任する追加システム。"" msgid ""Repository"" msgstr ""リポジトリ"" msgid """" ""Where the end entity certificates and certificate revocation lists are "" ""stored and looked up - sometimes referred to as the <emphasis role=\""italic"" ""\"">certificate bundle</emphasis>."" msgstr """" ""エンドエンティティが証明され、証明書の廃止リストが保存・参照される場所 - 時々"" ""<emphasis role=\""italic\"">証明バンドル(Certificate bundle)</emphasis>と呼ばれ"" ""ます。"" msgid ""Relying party"" msgstr ""信頼機関"" msgid ""The endpoint that is trusting that the CA is valid."" msgstr ""CAが有効であると証明するエンドポイント"" msgid ""Certification authorities"" msgstr ""認証局(CA)"" msgid """" ""Many organizations have an established Public Key Infrastructure with their "" ""own certification authority (CA), certificate policies, and management for "" ""which they should use to issue certificates for internal OpenStack users or "" ""services. Organizations in which the public security domain is Internet "" ""facing will additionally need certificates signed by a widely recognized "" ""public CA. For cryptographic communications over the management network, it "" ""is recommended one not use a public CA. Instead, we expect and recommend "" ""most deployments deploy their own internal CA."" msgstr """" ""多くの組織には、内部のOpenStackユーザやサービス用に証明書を発行する為に使用さ"" ""れるべき場所用の自身の認証局(CA)、証明ポリシー、管理を備えたPublic Key "" ""Infrastructure (PKI)が設置されています\n"" ""。加えて、パブリックセキュリティドメインがインターネットに面している所の組織"" ""は、幅広く認識された公共のCAにより署名された証明書が必要になるでしょう。管理"" ""ネットワーク上の暗号化通信用には、パブリックCAを使用しない事をお勧めします。"" ""代わりに、多くのデプロイでは自身の内部CAを設置していると思われますし、推奨し"" ""ます。"" msgid ""Cryptographic algorithms, cipher modes, and protocols"" msgstr ""暗号化アルゴリズム、暗号モード、プロトコル"" msgid ""National Security Agency, Suite B Cryptography"" msgstr ""国家安全保障局、Suite B 暗号化"" msgid ""OWASP Guide to Cryptography"" msgstr ""OWASP Guide to Cryptography"" msgid ""OWASP Transport Layer Protection Cheat Sheet"" msgstr ""OWASP Transport Layer Protection Cheat Sheet"" msgid """" ""SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate "" ""trust model enhancements"" msgstr """" ""SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate "" ""trust model enhancements"" msgid """" ""The Most Dangerous Code in the World: Validating SSL Certificates in Non-"" ""Browser Software"" msgstr """" ""The Most Dangerous Code in the World: Validating SSL Certificates in Non-"" ""Browser Software"" msgid ""OpenSSL and FIPS 140-2"" msgstr ""OpenSSL and FIPS 140-2"" msgid ""Summary"" msgstr ""概要"" msgid ""Compute API endpoints"" msgstr ""Compute APIエンドポイント"" msgid ""Identity API endpoints"" msgstr ""Identity APIエンドポイント"" msgid ""Networking API endpoints"" msgstr ""Networking APIエンドポイント"" msgid ""Storage API endpoints"" msgstr ""ストレージAPIエンドポイント"" msgid ""Messaging server"" msgstr ""メッセージングサーバー"" msgid ""Database server"" msgstr ""データベースサーバー"" msgid ""Dashboard"" msgstr ""Dashboard"" msgid ""Introduction"" msgstr ""はじめに"" msgid """" ""Horizon is the OpenStack dashboard that provides users a self-service portal "" ""to provision their own resources within the limits set by administrators. "" ""These include provisioning users, defining instance flavors, uploading VM "" ""images, managing networks, setting up security groups, starting instances, "" ""and accessing the instances through a console."" msgstr """" ""Horizon は OpenStack のダッシュボードです。管理者により設定された制限の範囲内"" ""でユーザー自身のリソースを展開できるセルフサービスポータルをユーザーに提供し"" ""ます。これらには、ユーザーの管理、インスタンスのフレーバーの定義、仮想マシン"" ""イメージのアップロード、ネットワークの管理、セキュリティグループのセットアッ"" ""プ、インスタンスの起動、インスタンスへのコンソール経由のアクセスなどがありま""""The dashboard ships with reasonable default security settings, and has good "" ""<link href=\""http://docs.openstack.org/developer/horizon/topics/deployment."" ""html\"">deployment and configuration documentation</link>.""""ダッシュボードは適度なデフォルトのセキュリティ設定をしてあります。また、素晴"" ""らしい <link href=\""http://docs.openstack.org/developer/horizon/topics/"" ""deployment.html\"">deployment and configuration documentation</link> (導入と設"" ""定のドキュメント) があります。"" msgid ""Basic web server configuration"" msgstr ""基本的なウェブサーバーの設定"" msgid ""HTTPS"" msgstr ""HTTPS""""Deploy the dashboard behind a secure <glossterm>HTTPS</glossterm> server by "" ""using a valid, trusted certificate from a recognized certificate authority "" ""(CA). Private organization-issued certificates are only appropriate when the "" ""root of trust is pre-installed in all user browsers.""""ダッシュボードは、認知されている認証局 (CA) から発行された有効かつ信頼できる"" ""証明書を使用しているセキュアな <glossterm>HTTPS</glossterm> サーバーの後ろに"" ""導入します。プライベートな組織で発行された証明書は、ルート証明機関がお使いの"" ""すべてのブラウザーに事前インストールされているときのみ、適切に動作します。""""Configure HTTP requests to the dashboard domain to redirect to the fully "" ""qualified HTTPS URL.""""ダッシュボードのドメインに対する HTTP リクエストは、完全修飾された HTTPS URL "" ""にリダイレクトされるよう設定します。"" msgid ""HTTP Strict Transport Security (HSTS)"" msgstr ""HTTP Strict Transport Security (HSTS)"" msgid ""It is highly recommended to use HTTP Strict Transport Security (HSTS)."" msgstr ""HTTP Strict Transport Security (HSTS) の使用が強く推奨されます。""""See the chapter on PKI/SSL Everywhere for more specific recommendations and "" ""server configurations for HTTPS configurations, including the configuration "" ""of HSTS.""""HSTS の設定を含め、HTTPS の設定に関するより具体的な推奨事項とサーバー設定は、"" ""PKI/SSL の章全体を参照してください。"" msgid ""Front end caching"" msgstr ""フロントエンドキャッシュ"" msgid ""Domain names"" msgstr ""ドメイン名""""Many organizations typically deploy web applications at subdomains of an "" ""overarching organization domain. It is natural for users to expect a domain "" ""of the form <uri>openstack.example.org</uri>. In this context, there are "" ""often many other applications deployed in the same second-level namespace, "" ""often serving user-controlled content. This name structure is convenient and "" ""simplifies name server maintenance.""""多くの組織は一般的に、組織全体のドメインのサブドメインに Web アプリケーション"" ""を配備します。ユーザーが <uri>openstack.example.org</uri> 形式のドメインを期"" ""待することは自然です。これに関連して、しばしば同じセカンドレベルの名前空間に"" ""配備された、ユーザーが管理できるコンテンツを取り扱う他の多くのアプリケーショ"" ""ンがあります。この名前の構造は便利であり、ネームサーバーのメンテナンスを簡単"" ""にします。"" msgid ""Static media"" msgstr ""静的メディア"" msgid ""Secret key"" msgstr ""シークレットキー"" msgid ""Allowed hosts"" msgstr ""許可されたホスト"" msgid ""Cross Site Request Forgery (CSRF)"" msgstr ""クロスサイトリクエストフォージェリ (CSRF)"" msgid ""Cookies"" msgstr ""クッキー"" msgid ""Session Cookies should be set to HTTPONLY:"" msgstr ""セッションクッキーは HTTPONLY に設定すべきです。""""Never configure CSRF or session cookies to have a wild card domain with a "" ""leading dot. Horizon's session and CSRF cookie should be secured when "" ""deployed with HTTPS:""""ドットから始まるワイルドカードドメインを持つよう、CSRF やセッションクッキーを"" ""設定してはいけません。Horizon のセッションクッキーと CSRF クッキーは HTTPS を"" ""使用した環境のときにセキュア化すべきです。"" msgid ""Cross Site Scripting (XSS)"" msgstr ""クロスサイトスクリプティング (XSS)"" msgid ""Cross Origin Resource Sharing (CORS)"" msgstr ""クロスオリジンリソースシェアリング (CORS)""""Configure your web server to send a restrictive CORS header with each "" ""response, allowing only the dashboard domain and protocol:""""ウェブブラウザが各レスポンスに限定的な CORS ヘッダーを付けて送信するよう設定"" ""します。ダッシュボードのドメインとプロトコルのみを許可します。"" msgid ""Never allow the wild card origin."" msgstr ""ワイルドカードオリジンを許可してはいけません。"" msgid ""Horizon image upload"" msgstr ""Horizon のイメージのアップロード""""We recommend that implementers <link href=\""http://docs.openstack.org/"" ""developer/horizon/topics/deployment.html#file-uploads\"">disable "" ""HORIZON_IMAGES_ALLOW_UPLOAD</link> unless they have implemented a plan to "" ""prevent resource exhaustion and denial of service.""""導入者はリソース枯渇とサービス妨害を防ぐ計画を実装していなければ、<link href="" ""\""http://docs.openstack.org/developer/horizon/topics/deployment.html#file-"" ""uploads\"">HORIZON_IMAGES_ALLOW_UPLOAD を無効化</link> することを強く推奨しま"" ""す。"" msgid ""Upgrading"" msgstr ""アップグレード"" msgid """" ""Django security releases are generally well tested and aggressively "" ""backwards compatible. In almost all cases, new major releases of Django are "" ""also fully backwards compatible with previous releases. Dashboard "" ""implementers are strongly encouraged to run the latest stable release of "" ""Django with up-to-date security releases."" msgstr """" ""Django セキュリティリリースは、一般的に十分にテストされ、積極的に後方互換性を"" ""確保しています。ほぼすべての場合、Django の新しいメジャーリリースも前のリリー"" ""スと後方互換性があります。ダッシュボードの実装者は、最新のセキュリティリリー"" ""スを持つ最新の安定リリースの Django を実行することを強く推奨されます。"" msgid ""Debug"" msgstr ""デバッグ"" msgid ""Pound"" msgstr ""Pound"" msgid ""Stud"" msgstr ""Stud"" msgid ""nginx"" msgstr ""nginx"" msgid ""Apache httpd"" msgstr ""Apache httpd"" msgid ""Examples"" msgstr ""例"" msgid """" ""Before we delve into the configurations, we briefly discuss the ciphers' "" ""configuration element and its format. A more exhaustive treatment on "" ""available ciphers and the OpenSSL cipher list format can be found at: <link "" ""href=\""https://www.openssl.org/docs/apps/ciphers.html\"">ciphers</link>."" msgstr """" ""設定を掘り下げる前に、暗号の設定要素とその形式について簡単に議論します。利用"" ""可能な暗号におけるより包括的な使い方、および OpenSSL 暗号一覧形式が <link "" ""href=\""https://www.openssl.org/docs/apps/ciphers.html\"">ciphers</link> にあり"" ""ます。"" msgid """" ""Cipher string options are separated by \"":\"", while \""!\"" provides negation "" ""of the immediately following element. Element order indicates preference "" ""unless overridden by qualifiers such as HIGH. Let us take a closer look at "" ""the elements in the above sample strings."" msgstr """" ""暗号オプションの文字列は「:」で区切られます。「!」は直後の要素の否定を意味し"" ""ます。要素の順番は、HIGH のような修飾語句により上書きされない限り、優先度を意"" ""味します。上のサンプル文字列の要素をもう少し具体的に見ていきましょう。"" msgid ""kEECDH:kEDH"" msgstr ""kEECDH:kEDH"" msgid """" ""Ephemeral Elliptic Curve Diffie-Hellman (abbreviated as EECDH and ECDHE)."" msgstr ""楕円曲線ディフィー・ヘルマン (EECDH や ECDHE と略す)"" msgid """" ""Ephemeral Diffie-Hellman (abbreviated either as EDH or DHE) uses prime field "" ""groups."" msgstr """" ""一時ディフィー・ヘルマン (EDH や DHE と略す) は素体グループを使用します。"" msgid """" ""Ephemeral Elliptic Curves require the server to be configured with a named "" ""curve, and provide better security than prime field groups and at lower "" ""computational cost. However, prime field groups are more widely implemented, "" ""and thus typically both are included in list."" msgstr """" ""一時楕円曲線はサーバーが名前付き曲線を用いて設定されている必要があります。素"" ""体グループよりセキュリティが高く、計算コストが低いです。しかしながら、素体グ"" ""ループはより幅広く実装されているので、一般的にどちらも一覧に含まれます。"" msgid ""kRSA"" msgstr ""kRSA"" msgid """" ""Cipher suites using the <link href=\""http://en.wikipedia.org/wiki/RSA_"" ""%28cryptosystem%29\"">RSA</link> exchange, authentication or either "" ""respectively."" msgstr """" ""<link href=\""http://en.wikipedia.org/wiki/RSA_%28cryptosystem%29\"">RSA</"" ""link> の鍵交換、認証、またはその両方を使用する暗号スイート。"" msgid ""HIGH"" msgstr ""HIGH"" msgid """" ""Selects highest possible security cipher in the negotiation phase. These "" ""typically have keys of length 128 bits or longer."" msgstr """" ""ネゴシエーション段階で利用可能な最高のセキュリティ暗号を選択します。これらは"" ""一般的に 128 ビット以上の鍵を持ちます。"" msgid ""!RC4"" msgstr ""!RC4"" msgid ""!MD5"" msgstr ""!MD5"" msgid """" ""No MD5. MD5 is not collision resistant, and thus not acceptable for Message "" ""Authentication Codes (MAC) or signatures."" msgstr """" ""MD5 使用不可。MD5 は衝突耐性がないため、メッセージ認証コード (MAC) や署名に利"" ""用できません。"" msgid ""!aNULL:!eNULL"" msgstr ""!aNULL:!eNULL"" msgid ""!EXP"" msgstr ""!EXP"" msgid """" ""US Export restrictions on cryptography systems have been lifted and no "" ""longer need to be supported."" msgstr """" ""暗号システムにおけるアメリカ輸出規制を解かれていて、もはやサポートする必要が"" ""ありません。"" msgid ""!LOW:!MEDIUM"" msgstr ""!LOW:!MEDIUM"" msgid ""Protocols"" msgstr ""プロトコル"" msgid ""Apache"" msgstr ""Apache"" msgid """" ""Compute API SSL endpoint in Apache, which you must pair with a short WSGI "" ""script."" msgstr """" ""Apache 中の Compute API SSL エンドポイント (短い WSGI スクリプトと組み合わせ"" ""る必要あり)"" msgid ""HTTP strict transport security"" msgstr ""HTTP Strict Transport Security"" msgid ""API endpoints"" msgstr ""APIエンドポイント"" msgid ""Compliance activities"" msgstr ""コンプライアンス活動"" msgid """" ""There are a number of standard activities that will greatly assist with the "" ""compliance process. In this chapter we outline some of the most common "" ""compliance activities. These are not specific to OpenStack, however we "" ""provide references to relevant sections in this book as useful context."" msgstr """" ""コンプライアンスのプロセスを大きく推進する、標準的な活動は数多くあります。こ"" ""の章ではいくつかの代表的なコンプライアンス活動を紹介します。これらはOpenStack"" ""固有ではありませんが、関係がわかるよう、このガイドの関連する節への参照も記載"" ""します。"" msgid ""Information Security Management system (ISMS)"" msgstr ""Information Security Management System (ISMS)"" msgid ""Risk assessment"" msgstr ""リスク評価""msgid """" ""Periodic access and log reviews are required to ensure authentication, "" ""authorization, and accountability in a service deployment. Specific guidance "" ""for OpenStack on these topics are discussed in-depth in the logging section."" msgstr """" ""定期的なアクセスとログの検査は、認証、認可とサービス配備における責任を明確に"" ""するため、必要です。これらのトピックに関するOpenStack向けのガイダンスは、ロギ"" ""ングの節で詳細に説明します。"" msgid ""Backup and disaster recovery"" msgstr ""バックアップと災害対策"" msgid """" ""Disaster Recovery (DR) and Business Continuity Planning (BCP) plans are "" ""common requirements for ISMS and compliance activities. These plans must be "" ""periodically tested as well as documented. In OpenStack key areas are found "" ""in the management security domain, and anywhere that single points of "" ""failure (SPOFs) can be identified. See the section on secure backup and "" ""recovery for additional details."" msgstr """" ""災害対策(Disaster Recovery, DR)とビジネス継続計画(Business Continuity "" ""Planning, BCP)はISMSとコンプライアンス活動で共通の要件です。それらの計画は定"" ""期的な検査と文書化が必要とします。OpenStackの主要領域はマネジメントセキュリ"" ""ティ領域にあたり、すべての単一障害点(Single Point of Failures, SPOFs)が特定さ"" ""れなければいけません。詳細は、安全なバックアップとリカバリーの節を参照してく"" ""ださい。"" msgid ""Security training"" msgstr ""セキュリティトレーニング"" msgid ""Security reviews"" msgstr ""セキュリティの検査"" msgid """" ""As OpenStack is a popular open source project, much of the codebase and "" ""architecture has been scrutinized by individual contributors, organizations "" ""and enterprises. This can be advantageous from a security perspective, "" ""however the need for security reviews is still a critical consideration for "" ""service providers, as deployments vary, and security is not always the "" ""primary concern for contributors. A comprehensive security review process "" ""may include architectural review, threat modelling, source code analysis and "" ""penetration testing. There are many techniques and recommendations for "" ""conducting security reviews that can be found publicly posted. A well-tested "" ""example is the <link href=\""http://www.microsoft.com/security/sdl/process/"" ""release.aspx\"">Microsoft SDL</link>, created as part of the Microsoft "" ""Trustworthy Computing Initiative."" msgstr """" ""OpenStackは人気のあるオープンソースプロジェクトです。多くのソースコードとアー"" ""キテクチャはデベロッパー、組織、企業によって精査されています。これはセキュリ"" ""ティの観点から大きな利点ですが、セキュリティ検査はサービスプロバイダーにとっ"" ""て、それでもなお重大な懸念事項です。環境は変化しつづけますが、セキュリティは"" ""必ずしも開発者の一番の関心事ではないからです。包括的なセキュリティ検査プロセ"" ""スとして、アーキテクチャ検査、脅威のモデリング、ソースコード分析と侵入テスト"" ""などが挙げられます。そして、セキュリティ検査には広く公開されている多くのテク"" ""ニックと推奨があります。よくテストされた例として、Microsoft Trustworthy "" ""Computing Initiativeのとりくみとして作成された、<link href=\""http://www."" ""microsoft.com/security/sdl/process/release.aspx\"">Microsoft SDL</link>があり"" ""ます。"" msgid ""Vulnerability management"" msgstr ""脆弱性管理"" msgid """" ""Security updates are critical to any IaaS deployment, whether private or "" ""public. Vulnerable systems expand attack surfaces, and are obvious targets "" ""for attackers. Common scanning technologies and vulnerability notification "" ""services can help mitigate this threat. It is important that scans are "" ""authenticated and that mitigation strategies extend beyond simple perimeter "" ""hardening. Multi-tenant architectures such as OpenStack are particularly "" ""prone to hypervisor vulnerabilities, making this a critical part of the "" ""system for vulnerability management. See the section on instance isolation "" ""for additional details."" msgstr """" ""セキュリティアップデートはプライベート、パブリックを問わず、あらゆるIaaS環境"" ""において重要です。脆弱なシステムは攻撃面を広げ、攻撃者にターゲットをさらして"" ""しまいます。一般的なスキャニング技術と脆弱性検知サービスはこの脅威を和らげる"" ""のに役立ちます。スキャンが認証されたものであり、その緩和戦略が単なる境界線の"" ""防御力向上にとどまらないことが重要です。OpenStackのようなマルチテナントアーキ"" ""テクチャは特にハイパーバイザーの脆弱性に影響されやすく、それはシステムの脆弱"" ""性管理の重点項目です。詳細はインスタンス隔離の節を参照してください。"" msgid ""Data classification"" msgstr ""データの分類"" msgid """" ""Data Classification defines a method for classifying and handling "" ""information, often to protect customer information from accidental or "" ""deliberate theft, loss, or inappropriate disclosure. Most commonly this "" ""involves classifying information as sensitive or non-sensitive, or as "" ""personally identifiable information (PII). Depending on the context of the "" ""deployment various other classifying criteria may be used (government, "" ""health-care etc). The underlying principle is that data classifications are "" ""clearly defined and in-use. The most common protective mechanisms include "" ""industry standard encryption technologies. See the data security section for "" ""additional details."" msgstr """" ""データの分類作業は、多くの場合、顧客情報を事故、故意の窃盗、損失、不適切な公"" ""開から保護するため、情報の分類と扱いの方法を定義します。一般的にこの作業は、"" ""情報を機密性の有無、個人識別の可不可(Personally Identifiable Information, "" ""PII)による分類を含みます。使用される基準はその環境、背景によって様々です(政"" ""府、ヘルスケアなど)。そして根本的な原則は、そのデータ分類が明確に定義され、通"" ""常利用されていることです。もっとも一般的な保護メカニズムには、業界標準の暗号"" ""化技術が挙げられます。詳細はデータセキュリティの節を参照してください。"" msgid ""Exception process"" msgstr ""例外プロセス"" msgid """" ""An exception process is an important component of an ISMS. When certain "" ""actions are not compliant with security policies that an organization has "" ""defined, they must be logged. Appropriate justification, description and "" ""mitigation details need to be included, and signed off by appropriate "" ""authorities. OpenStack default configurations may vary in meeting various "" ""compliance criteria, areas that fail to meet compliance requirements should "" ""be logged, with potential fixes considered for contribution to the community."" msgstr """" ""例外プロセスはISMSの重要な要素です。とある行動が組織の定義したセキュリティポ"" ""リシーに準拠していない場合、それは記録されなければいけません。適正な理由と緩"" ""和策の詳細が含まれ、関係当局に認められる必要があります。OpenStackのデフォルト"" ""構成は、様々なコンプライアンス基準、記録されるべきコンプライアンス基準を満た"" ""すべく、変化していくでしょう。またそれは、コミュニティへの貢献によって修正さ"" ""れていく可能性があります。"" msgid ""Introduction to OpenStack"" msgstr ""OpenStack の概要"" msgid """" ""Each OpenStack deployment embraces a wide variety of technologies, spanning "" ""Linux distributions, database systems, messaging queues, OpenStack "" ""components themselves, access control policies, logging services, security "" ""monitoring tools, and much more. It should come as no surprise that the "" ""security issues involved are equally diverse, and their in-depth analysis "" ""would require several guides. We strive to find a balance, providing enough "" ""context to understand OpenStack security issues and their handling, and "" ""provide external references for further information. The guide could be read "" ""from start to finish or sampled as necessary like a reference."" msgstr """" ""OpenStack の各デプロイメントには、Linux ディストリビューション、データベース"" ""システム、メッセージキュー、OpenStack のコンポーネント自体、アクセス制御ポリ"" ""シー、ログサービス、セキュリティ監視ツールなどに及ぶ、多種多様なテクノロジー"" ""が採用されます。このため、デプロイに伴うセキュリティ問題が、同じように多様と"" ""なることは当然です。それらの内容を奥深く分析するには、マニュアルが数冊必要と"" ""なります。 本ガイドでは、OpenStack のセキュリティ問題とその対処方法を理解する"" ""ために十分な情報を提供しつつ、さらなる情報の外部参照先を掲載することにより、"" ""バランスを図っています。本書は、全体を通読する方法または参考資料として必要箇"" ""所のみを参照する方法のいずれでもご利用いただくことができます。"" msgid """" ""We briefly introduce the kinds of clouds: private, public, and hybrid before "" ""presenting an overview of the OpenStack components and their related "" ""security concerns in the remainder of the chapter."" msgstr """" ""本章では、プライベート、パブリック、ハイブリッドというクラウドの各種類につい"" ""て簡単に説明した後、後半に OpenStack のコンポーネントおよびそれらに関連するセ"" ""キュリティ課題について概説します。"" msgid ""Cloud types"" msgstr ""クラウドのタイプ"" msgid """" ""OpenStack is a key enabler in adoption of cloud technology and has several "" ""common deployment use cases. These are commonly known as Public, Private, "" ""and Hybrid models. The following sections use the National Institute of "" ""Standards and Technology (NIST) <link href=\""http://csrc.nist.gov/"" ""publications/nistpubs/800-145/SP800-145.pdf\"">definition of cloud</link> to "" ""introduce these different types of cloud as they apply to OpenStack."" msgstr """" ""OpenStack は、クラウドテクノロジーの導入における重要なイネーブラーであり、一"" ""般的なデプロイメントユースケースがいくつかあります。これらは、パブリック、プ"" ""ライベート、およびハイブリッドモデルとして一般に知られています。以下のセク"" ""ションでは、National Institute of Standards and Technology (NIST) <link href="" ""\""http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\""> のクラ"" ""ウドの定義</link> を取り上げ、OpenStack に適用するクラウドの異なるタイプにつ"" ""いて説明します。"" msgid ""Public cloud"" msgstr ""パブリッククラウド""msgid ""Private cloud"" msgstr ""プライベートクラウド"" msgid """" ""At the opposite end of the spectrum is the private cloud. As NIST defines "" ""it, a private cloud is provisioned for exclusive use by a single "" ""organization comprising multiple consumers, such as business units. It may "" ""be owned, managed, and operated by the organization, a third-party, or some "" ""combination of them, and it may exist on or off premises. Private cloud use "" ""cases are diverse, as such, their individual security concerns vary."" msgstr """" ""パブリッククラウドの対極にあるのがプライベートクラウドです。NIST は、プライ"" ""ベートクラウドを、事業組織などの複数の利用者から成る単一の組織の専用使用のた"" ""めに提供されるクラウドと定義しています。プライベートクラウドの所有、管理、お"" ""よび運用は、その組織、第三者、もしくはそれらの組み合わせにより行われ、存在場"" ""所としては、その組織の施設内または外部の場合があります。プライベートクラウド"" ""のユースケースは多様であるため、セキュリティ課題もそれぞれで異なります。"" msgid ""Community cloud"" msgstr ""コミュニティクラウド"" msgid """" ""NIST defines a community cloud as one whose infrastructure is provisioned "" ""for the exclusive use by a specific community of consumers from "" ""organizations that have shared concerns. For example, mission, security "" ""requirements, policy, and compliance considerations. It may be owned, "" ""managed, and operated by one or more of the organizations in the community, "" ""a third-party, or some combination of them, and it may exist on or off "" ""premises."" msgstr """" ""NIST では、コミュニティクラウドを、共通の関心事 (例えば、任務、セキュリティの"" ""必要、ポリシー、法令順守に関わる考慮事項 ) を持つ複数の組織から成る特定の利用"" ""者の共同体の専用使用のために提供されるクラウドと定義しています。コミュニティ"" ""クラウドの所有、管理、および運用は、共同体内の 1 つまたは複数の組織、第三者、"" ""もしくはそれらの組み合わせにより行われ、存在場所はその組織の施設内または外部"" ""の場合があります。"" msgid ""Hybrid cloud"" msgstr ""ハイブリッドクラウド"" msgid """" ""For the purposes of this document, we treat Community and Hybrid similarly, "" ""dealing explicitly only with the extremes of Public and Private clouds from "" ""a security perspective. Your security measures depend where your deployment "" ""falls upon the private public continuum."" msgstr """" ""本ガイドにおいては、コミュニティクラウドとハイブリッドクラウドを同様に扱い、"" ""パブリッククラウドとプライベートクラウドの両極のみをセキュリティ面から明確に"" ""説明します。セキュリティ対策は、デプロイメントがプライベートクラウド/パブリッ"" ""ククラウドの連続体のどこに位置するかによって異なります。"" msgid ""OpenStack service overview"" msgstr ""OpenStack サービスの概観"" msgid """" ""OpenStack embraces a modular architecture to provide a set of core services "" ""that facilitates scalability and elasticity as core design tenets. This "" ""chapter briefly reviews OpenStack components, their use cases and security "" ""considerations."" msgstr """" ""OpenStack は、モジュール型アーキテクチャを採用し、中核的な設計理念としてス"" ""ケーラビリティと柔軟性を促進する一式のコアサービスを提供します。本章では、"" ""OpenStack のコンポーネントとそれらのユースケースおよびセキュリティに関する考"" ""慮事項を簡単に説明します。"" msgid ""Compute"" msgstr ""Compute"" msgid """" ""The Compute service facilitates this management through an abstraction layer "" ""that interfaces with supported hypervisors, which we address later on in "" ""more detail."" msgstr """" ""Compute は、サポート対象のハイパーバイザーと連動する抽象化レイヤーを介してこ"" ""のような管理を行います。ハイパーバイザーについては、後半で詳しく説明します。"" msgid """" ""Later in the guide, we focus generically on the virtualization stack as it "" ""relates to hypervisors."" msgstr """" ""本ガイドの後半では、ハイパーバイザーと関連する仮想化スタックに焦点をあてて、"" ""包括的に解説します。"" msgid """" ""For information about the current state of feature support, see <link href="" ""\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack "" ""Hypervisor Support Matrix</link>."" msgstr """" ""機能サポートの現在の状況に関する情報は、 <link href=\""https://wiki.openstack."" ""org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support Matrix</"" ""link> を参照してください。"" msgid """" ""The security of Compute is critical for an OpenStack deployment. Hardening "" ""techniques should include support for strong instance isolation, secure "" ""communication between Compute sub-components, and resiliency of public-"" ""facing <glossterm>API</glossterm> endpoints."" msgstr """" ""OpenStack のデプロイメントでは、Compute のセキュリティが極めて重要となりま"" ""す。セキュリティ強化のテクニックには、頑強なインスタンスの隔離、Compute のサ"" ""ブコンポーネント間におけるセキュアな通信、一般向けの <glossterm>API</"" ""glossterm> エンドポイントの弾力性などがあげられます。"" msgid """" ""It is important to understand that object storage differs from traditional "" ""file system storage. It is best used for static data such as media files "" ""(MP3s, images, videos), virtual machine images, and backup files."" msgstr """" ""オブジェクトストレージは、従来のファイルシステムストレージと異なる点を理解し"" ""ておくことが重要です。メディアファイル (MP3、画像、ビデオ) や仮想マシンイメー"" ""ジ、バックアップファイルなどの静的データに使用するのに最適です。"" msgid """" ""Object security should focus on access control and encryption of data in "" ""transit and at rest. Other concerns may relate to system abuse, illegal or "" ""malicious content storage, and cross authentication attack vectors."" msgstr """" ""オブジェクトのセキュリティは、アクセス制御と、伝送中および静止中のデータの暗"" ""号化に重点を置くべきです。その他の懸念事項には、システムの悪用、不法または悪"" ""意のあるコンテンツの保管、クロス認証の攻撃ベクトルなどに関する問題があげられ"" ""ます。"" msgid ""Block Storage"" msgstr ""Block Storage"" msgid """" ""Security considerations for block storage are similar to that of object "" ""storage."" msgstr ""Block Storage のセキュリティ課題は、Object Storage の場合と同様です。"" msgid ""Networking"" msgstr ""ネットワーク"" msgid """" ""OpenStack Networking allows cloud tenants to manage their guest network "" ""configurations. Security concerns with the networking service include "" ""network traffic isolation, availability, integrity and confidentiality."" msgstr """" ""OpenStack Networking により、クラウドテナントはゲストのネットワーク設定を管理"" ""することができます。ネットワークサービスに伴うセキュリティ上の問題には、 ネッ"" ""トワークトラフィックの隔離、可用性、完全性、機密性などがあげられます。"" msgid ""Identity service"" msgstr ""Identity"" msgid """" ""Security concerns here pertain to trust in authentication, management of "" ""authorization tokens, and secure communication."" msgstr """" ""ここでのセキュリティ課題には、認証の信頼、承認トークンの管理、セキュリティ保"" ""護された通信などがあげられます。"" msgid ""Image service"" msgstr ""Image サービス"" msgid """" ""Trusted processes for managing the life cycle of disk images are required, "" ""as are all the previously mentioned issues with respect to data security."" msgstr """" ""前述したデータセキュリティに関する問題と同様に、ディスクイメージのライフサイ"" ""クル管理には信頼されたプロセスが必要です。"" msgid ""Data processing service"" msgstr ""Data processing サービス"" msgid ""Other supporting technology"" msgstr ""その他の支援技術"" msgid """" ""Several of the components use databases though it is not explicitly called "" ""out. Securing the access to the databases and their contents is yet another "" ""security concern, and consequently discussed in more detail later in this "" ""guide."" msgstr """" ""一部のコンポーネントは、間接的にデータベースを使用します。データベースおよび"" ""そのコンテンツへのアクセスのセキュリティ保護は、もう一つのセキュリティ課題で"" ""あるため、本ガイドの後半でさらに詳しく説明します。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid ""@@image: 'static/group.png'; md5=aec1f0af66d29c1a5d1f174df1f12812"" msgstr ""@@image: 'static/group.png'; md5=aec1f0af66d29c1a5d1f174df1f12812"" msgid ""Why and how we wrote this book"" msgstr ""本書の作成理由と方法"" msgid """" ""As OpenStack adoption continues to grow and the product matures, security "" ""has become a priority. The OpenStack Security Group has recognized the need "" ""for a comprehensive and authoritative security guide. The <emphasis role="" ""\""bold\"">OpenStack Security Guide</emphasis> has been written to provide an "" ""overview of security best practices, guidelines, and recommendations for "" ""increasing the security of an OpenStack deployment. The authors bring their "" ""expertise from deploying and securing OpenStack in a variety of environments."" msgstr """" ""OpenStack が拡大を続け、製品が成熟してきたので、セキュリティが重要事項になっ"" ""てきました。OpenStack Security Group は包括的かつ権威のあるセキュリティガイド"" ""の必要性を認識しました。<emphasis role=\""bold\"">OpenStack セキュリティガイド"" ""</emphasis>は、OpenStack のセキュリティ向上を目的とした、セキュリティのベスト"" ""プラクティス、ガイドライン、推奨事項の概要について記載しています。著者は\n"" ""さまざまな環境で OpenStack の導入やセキュア化をした専門知識をもたらします。"" msgid ""Objectives"" msgstr ""本書の目的"" msgid ""Identify the security domains in OpenStack"" msgstr ""OpenStack のセキュリティ領域の明確化"" msgid ""Provide guidance to secure your OpenStack deployment"" msgstr ""OpenStack をセキュア化するガイドの提供"" msgid """" ""Highlight security concerns and potential mitigations in present day "" ""OpenStack"" msgstr ""現在の OpenStack におけるセキュリティ懸念事項と実現可能な軽減策の紹介"" msgid ""Discuss upcoming security features"" msgstr ""今後予定されているセキュリティ機能の議論"" msgid """" ""To provide a community driven facility for knowledge capture and "" ""dissemination"" msgstr ""コミュニティ主導のナレッジ蓄積と普及の場の提供"" msgid ""How"" msgstr ""本書の執筆方法"" msgid """" ""As with the OpenStack Operations Guide, we followed the book sprint "" ""methodology. The book sprint process allows for rapid development and "" ""production of large bodies of written work. Coordinators from the OpenStack "" ""Security Group re-enlisted the services of Adam Hyde as facilitator. "" ""Corporate support was obtained and the project was formally announced during "" ""the OpenStack summit in Portland, Oregon."" msgstr """" ""本書はOpenStack Operations Guide（OpenStack 運用ガイド）と同様に「ブックスプ"" ""リントメソッド」を用いました。このメソッドでは、迅速な大量文章の作成を実現し"" ""ます。OpenStack Security Group のコーディネーターは再びAdam Hydeをファシリ"" ""テーターとして力を借りました。さらに企業からのサポートが得られ、オレゴン州"" ""ポートランドで開催されたOpenStack サミットでプロジェクトが正式に公表されまし"" ""た。"" msgid """" ""The team converged in Annapolis, MD due to the close proximity of some key "" ""members of the group. This was a remarkable collaboration between public "" ""sector intelligence community members, silicon valley startups and some "" ""large, well-known technology companies. The book sprint ran during the last "" ""week in June 2013 and the first edition was created in five days."" msgstr """" ""チームは、グループの主要なメンバーが集まるために、メリーランド州アナポリスに"" ""集まりました。これは、公共部門のインテリジェンス・コミュニティーのメンバー、"" ""シリコンバレーのスタートアップ、いくつかの有名な大手技術企業の間での驚くべき"" ""コラボレーションです。Book Sprint は 2013 年 6 月の最終週に行われ、初版は 5 "" ""日間で作成されました。"" msgid ""The team included:"" msgstr ""チームメンバーは以下のとおりです。"" msgid ""<emphasis role=\""bold\"">Bryan D. Payne</emphasis>, Nebula"" msgstr ""<emphasis role=\""bold\"">Bryan D. Payne</emphasis>, Nebula"" msgid """" ""Dr. Bryan D. Payne is the Director of Security Research at Nebula and co-"" ""founder of the OpenStack Security Group (OSSG). Prior to joining Nebula, he "" ""worked at Sandia National Labs, the National Security Agency, BAE Systems, "" ""and IBM Research. He graduated with a Ph.D. in Computer Science from the "" ""Georgia Tech College of Computing, specializing in systems security."" msgstr """" ""Dr. Bryan D. Payne は、Nebula の Security Research の Director です。また、"" ""OpenStack Security Group (OSSG) の共同創設者です。Nebula に参加する前は、"" ""Sandia National Labs、National Security Agency、BAE Systems、IBM Research に"" ""勤務していました。Georgia Tech College of Computing でシステムセキュリティを"" ""専攻し、コンピューターサイエンスの Ph.D. を取得しました。"" msgid ""<emphasis role=\""bold\"">Robert Clark</emphasis>, HP"" msgstr ""<emphasis role=\""bold\"">Robert Clark</emphasis>, HP"" msgid """" ""Robert Clark is the Lead Security Architect for HP Cloud Services and co-"" ""founder of the OpenStack Security Group (OSSG). Prior to being recruited by "" ""HP, he worked in the UK Intelligence Community. Robert has a strong "" ""background in threat modeling, security architecture and virtualization "" ""technology. Robert has a master's degree in Software Engineering from the "" ""University of Wales."" msgstr """" ""Robert Clark は、Nebula の HP Cloud Services の Lead Security Architect で"" ""す。また、OpenStack Security Group (OSSG) の共同創設者です。HP に入社する前"" ""は、UK Intelligence Community に勤務していました。脅威モデリング、セキュリ"" ""ティアーキテクチャ、仮想化技術に関する強固なバックグラウンドを持ちます。"" ""University of Wales のソフトウェアエンジニアリングの修士号を持っています。"" msgid ""<emphasis role=\""bold\"">Keith Basil</emphasis>, Red Hat"" msgstr ""<emphasis role=\""bold\"">Keith Basil</emphasis>, Red Hat"" msgid """" ""Keith Basil is a Principal Product Manager for Red Hat OpenStack and is "" ""focused on Red Hat's OpenStack product management, development and strategy. "" ""Within the US public sector, Basil brings previous experience from the "" ""design of an authorized, secure, high-performance cloud architecture for "" ""Federal civilian agencies and contractors."" msgstr """" ""Keith Basil は Red Hat OpenStack の Principal Product Manager です。Red Hat "" ""の OpenStack 製品マネジメント、開発、戦略に注力しています。アメリカの公共部門"" ""の中で、アメリカの民間機関と委託業者向けの認定済み、セキュアかつハイパフォー"" ""マンスなクラウドアーキテクチャの設計から、これまでの経験をもたらします。"" msgid ""<emphasis role=\""bold\"">Cody Bunch</emphasis>, Rackspace"" msgstr ""<emphasis role=\""bold\"">Cody Bunch</emphasis>, Rackspace"" msgid """" ""Cody Bunch is a Private Cloud architect with Rackspace. Cody has co-authored "" ""an update to \""The OpenStack Cookbook\"" as well as books on VMware "" ""automation."" msgstr """" ""Cody Bunch は Rackspace の Private Cloud architect です。『The OpenStack "" ""Cookbook』と VMware 自動化の書籍の共同執筆者です。"" msgid ""<emphasis role=\""bold\"">Malini Bhandaru</emphasis>, Intel"" msgstr ""<emphasis role=\""bold\"">Malini Bhandaru</emphasis>, Intel"" msgid """" ""Malini Bhandaru is a security architect at Intel. She has a varied "" ""background, having worked on platform power and performance at Intel, speech "" ""products at Nuance, remote monitoring and management at ComBrio, and web "" ""commerce at Verizon. She has a Ph.D. in Artificial Intelligence from the "" ""University of Massachusetts, Amherst."" msgstr """" ""Malini Bhandaru は Intel のセキュリティアーキテクトです。Intel でプラット"" ""フォームの電力とパフォーマンス、Nuance でスピーチ製品、ComBrio でリモートモニ"" ""タリングと管理、Verizon でウェブコマースに関するさまざまなバックグラウンドを"" ""持ちます。University of Massachusetts, Amherst で人工知能に関する Ph.D. を"" ""持っています。"" msgid """" ""<emphasis role=\""bold\"">Gregg Tally</emphasis>, Johns Hopkins University "" ""Applied Physics Laboratory"" msgstr """" ""<emphasis role=\""bold\"">Gregg Tally</emphasis>, Johns Hopkins University "" ""Applied Physics Laboratory"" msgid """" ""Gregg Tally is the Chief Engineer at JHU/APL's Cyber Systems Group within "" ""the Asymmetric Operations Department. He works primarily in systems security "" ""engineering. Previously, he has worked at SPARTA, McAfee, and Trusted "" ""Information Systems where he was involved in cyber security research "" ""projects."" msgstr """" ""Gregg Tally は Asymmetric Operations Department の JHU/APL's Cyber Systems "" ""Group の Chief Engineer です。主にシステムセキュリティエンジニアリングに関す"" ""る仕事をしています。以前は、サイバーセキュリティ研究プロジェクトに関わり、"" ""SPARTA、McAfee、Trusted Information Systems に勤務していました。"" msgid ""<emphasis role=\""bold\"">Eric Lopez</emphasis>, VMware"" msgstr ""<emphasis role=\""bold\"">Eric Lopez</emphasis>, VMware"" msgid """" ""Eric Lopez is Senior Solution Architect at VMware's Networking and Security "" ""Business Unit where he helps customers implement OpenStack and VMware NSX "" ""(formerly known as Nicira's Network Virtualization Platform). Prior to "" ""joining VMware (through the company's acquisition of Nicira), he worked for "" ""Q1 Labs, Symantec, Vontu, and Brightmail. He has a B.S in Electrical "" ""Engineering/Computer Science and Nuclear Engineering from U.C. Berkeley and "" ""MBA from the University of San Francisco."" msgstr """" ""Eric Lopez は VMware の Networking and Security Business Unit の Senior "" ""Solution Architect です。顧客が OpenStack や VMware NSX (以前は Nicira の "" ""Network Virtualization Platform として知られていました) を導入する支援をして"" ""います。VMware (Nicira の企業買収により) に参加する前は、Q1 Labs、Symantec、"" ""Vontu、Brightmail に勤務していました。U.C. Berkeley の Electrical "" ""Engineering/Computer Science、Nuclear Engineering の B.S. を保持してます。ま"" ""た、University of San Francisco の MBA を保持しています。"" msgid ""<emphasis role=\""bold\"">Shawn Wells</emphasis>, Red Hat"" msgstr ""<emphasis role=\""bold\"">Shawn Wells</emphasis>, Red Hat"" msgid """" ""Shawn Wells is the Director, Innovation Programs at Red Hat, focused on "" ""improving the process of adopting, contributing to, and managing open source "" ""technologies within the U.S. Government. Additionally, Shawn is an upstream "" ""maintainer of the SCAP Security Guide project which forms virtualization and "" ""operating system hardening policy with the U.S. Military, NSA, and DISA. "" ""Formerly an NSA civilian, Shawn developed SIGINT collection systems "" ""utilizing large distributed computing infrastructures."" msgstr """" ""Shawn Wells は Red Hat の Innovation Programs の Director です。アメリカ政府"" ""の中でオープンソース技術を適用、貢献、管理するプロセスを改善することに注力し"" ""ています。さらに、SCAP Security Guide プロジェクトのアップストリームのメンテ"" ""ナーです。このプロジェクトは、 U.S. Military、NSA、DISA で仮想化とオペレー"" ""ティングシステムの強化ポリシーを作成しています。NSA の契約者になる前は、大規"" ""模分散コンピューティング環境を利便化する SIGINT 収集システムを開発していまし"" ""た。"" msgid ""<emphasis role=\""bold\"">Ben de Bont</emphasis>, HP"" msgstr ""<emphasis role=\""bold\"">Ben de Bont</emphasis>, HP"" msgid """" ""Ben de Bont is the CSO for HP Cloud Services. Prior to his current role Ben "" ""led the information security group at MySpace and the incident response team "" ""at MSN Security. Ben holds a master's degree in Computer Science from the "" ""Queensland University of Technology."" msgstr """" ""Ben de Bont は HP Cloud Services の CSO です。その前は、MySpace の情報セキュ"" ""リティグループ、MSN Security のインシデントレスポンスチームを率いていました。"" ""Queensland University of Technology のコンピューターサイエンスの修士号を保持"" ""しています。"" msgid """" ""<emphasis role=\""bold\"">Nathanael Burton</emphasis>, National Security Agency"" msgstr """" ""<emphasis role=\""bold\"">Nathanael Burton</emphasis>, National Security Agency"" msgid """" ""Nathanael Burton is a Computer Scientist at the National Security Agency. He "" ""has worked for the Agency for over 10 years working on distributed systems, "" ""large-scale hosting, open source initiatives, operating systems, security, "" ""storage, and virtualization technology. He has a B.S. in Computer Science "" ""from Virginia Tech."" msgstr """" ""Nathanael Burton は National Security Agency のコンピューターサイエンティスト"" ""です。Agency に 10 年以上勤務し、分散システム、大規模ホスティング、オープン"" ""ソースイニシアティブ、オペレーティングシステム、セキュリティ、ストレージ、仮"" ""想化技術に携わっています。Virginia Tech でコンピューターサイエンスの B.S. を"" ""取得しました。"" msgid ""Vibha Fauver"" msgstr ""Vibha Fauver"" msgid """" ""Vibha Fauver, GWEB, CISSP, PMP, has over fifteen years of experience in "" ""Information Technology. Her areas of specialization include software "" ""engineering, project management and information security. She has a B.S. in "" ""Computer &amp; Information Science and a M.S. in Engineering Management with "" ""specialization and a certificate in Systems Engineering."" msgstr """" ""Vibha Fauver (GWEB, CISSP, PMP) は情報技術に関する 15 年以上の経験がありま"" ""す。専門分野はソフトウェアエンジニアリング、プロジェクト管理と情報セキュリ"" ""ティです。Computer &amp; Information Science の B.S. と Engineering "" ""Management の M.S. を保持しています。Systems Engineering の資格を保持していま"" ""す。"" msgid ""<emphasis role=\""bold\"">Eric Windisch</emphasis>, Cloudscaling"" msgstr ""<emphasis role=\""bold\"">Eric Windisch</emphasis>, Cloudscaling"" msgid """" ""Eric Windisch is a Principal Engineer at Cloudscaling where he has been "" ""contributing to OpenStack for over two years. Eric has been in the trenches "" ""of hostile environments, building tenant isolation and infrastructure "" ""security through more than a decade of experience in the web hosting "" ""industry. He has been building cloud computing infrastructure and automation "" ""since 2007."" msgstr """" ""Eric Windisch は Cloudscaling の Principal Engineer です。OpenStack に 2 年以"" ""上貢献しています。ウェブホスティング業界における 10 年以上の経験から、ホス"" ""ティング環境の分離性、テナント独立性の構築、インフラセキュリティに携わってい"" ""ます。2007 年以降、クラウドコンピューティング環境の構築と自動化に携わっていま"" ""す。"" msgid ""<emphasis role=\""bold\"">Andrew Hay</emphasis>, CloudPassage"" msgstr ""<emphasis role=\""bold\"">Andrew Hay</emphasis>, CloudPassage"" msgid """" ""Andrew Hay is the Director of Applied Security Research at CloudPassage, "" ""Inc. where he leads the security research efforts for the company and its "" ""server security products purpose-built for dynamic public, private, and "" ""hybrid cloud hosting environments."" msgstr """" ""Andrew Hay は CloudPassage, Inc. の Applied Security Research の Director で"" ""す。社内セキュリティおよび、ダイナミックパブリック、プライベート、ハイブリッ"" ""ドクラウドのホスティング環境向けに設計されたサーバーセキュリティ製品のセキュ"" ""リティ研究チームを率いています。""""During the sprint we also had help from Anne Gentle, Warren Wang, Paul "" ""McMillan, Brian Schott and Lorin Hochstein.""""また、ブックスプリント期間中、Anne Gentle、Warren Wang、Paul McMillan、Brian "" ""Schott、Lorin Hochstein からの支援がありました。""msgid ""<emphasis role=\""bold\"">Rodney D. Beede</emphasis>, Seagate Technology"" msgstr ""<emphasis role=\""bold\"">Rodney D. Beede</emphasis>, Seagate Technology""""Rodney D. Beede is the Cloud Security Engineer for Seagate Technology. He "" ""contributed the missing chapter on securing OpenStack Object Storage "" ""(swift). He holds a M.S. in Computer Science from the University of Colorado.""""Rodney D. Beede は Seagate Technology の Cloud Security Engineer です。彼は "" ""OpenStack Object Storage (swift) のセキュア化に関する不足していた章に貢献しま"" ""した。University of Colorado の Computer Science に関する M.S. を保持していま"" ""す。"" msgid ""How to contribute to this book"" msgstr ""本書への貢献方法"" msgid """" ""The initial work on this book was conducted in an overly air-conditioned "" ""room that served as our group office for the entirety of the documentation "" ""sprint."" msgstr """" ""執筆作業の初めは空調が効きすぎの部屋で行われました。最終的に、その部屋がグ"" ""ループのオフィスとして執筆スプリント期間中使用されました。""msgid ""Networking services"" msgstr ""ネットワークサービス""msgid ""VLANs"" msgstr ""VLAN""""VLANs are realized as packets on a specific physical network containing IEEE "" ""802.1Q headers with a specific VLAN ID (VID) field value. VLAN networks "" ""sharing the same physical network are isolated from each other at L2, and "" ""can even have overlapping IP address spaces. Each distinct physical network "" ""supporting VLAN networks is treated as a separate VLAN trunk, with a "" ""distinct space of VID values. Valid VID values are 1 through 4094.""""VLAN は特別な VLAN ID (VID) フィールド値を持つ IEEE 802.1Q ヘッダを含む特別な"" ""物理ネットワーク上のパケットを実現します。同じ物理ネットワークを共有する "" ""VLAN ネットワーク群は、L2 において相互から独立しており、重複する IP アドレス"" ""空間を持つ事すら可能です。VLAN ネットワークに対応した各個別の物理ネットワーク"" ""は、独自の VID 値を持つ独立した VLAN トランクとして扱われます。有効な VID 値"" ""は1～4094です。""""VLAN configuration complexity depends on your OpenStack design requirements. "" ""In order to allow OpenStack Networking to efficiently use VLANs, you must "" ""allocate a VLAN range (one for each tenant) and turn each compute node "" ""physical switch port into a VLAN trunk port.""""VLAN 設定の複雑さはあなたの OpenStack 設計要件に依存します。OpenStack "" ""Networking がVLAN を効率良く使用できるようにする為に、VLAN 範囲を (各テナント"" ""に１つ) 割り当てて、各 compute ノードの物理スイッチポートを VLAN トランクポー"" ""トに変更する必要があります。""msgid ""L2 tunneling"" msgstr ""L2 トンネリング""msgid """" ""The choice of technology to provide L2 isolation is dependent upon the scope "" ""and size of tenant networks that will be created in your deployment. If your "" ""environment has limited VLAN ID availability or will have a large number of "" ""L2 networks, it is our recommendation that you utilize tunneling."" msgstr """" ""L2 分断を提供する技術の選択は、あなたのデプロイで作成される予定のテナントネッ"" ""トワークの範囲とサイズに依存します。あなたの環境が VLAN ID の利用で制限がある"" ""場合や、大多数の L2 ネットワークが見込まれる場合、トンネリングの使用を推奨し"" ""ます。"" msgid ""Network services""msgid """" ""The choice of tenant network isolation affects how the network security and "" ""control boundary is implemented for tenant services. The following "" ""additional network services are either available or currently under "" ""development to enhance the security posture of the OpenStack network "" ""architecture."" msgstr """" ""テナントネットワーク分断の選択はネットワークセキュリティと制御境界をどのよう"" ""に実装するかに影響します。\n"" ""以下の追加ネットワークサービスは利用可能か、OpenStack ネットワークアーキテク"" ""チャのセキュリティポーズを拡張する為の開発中かのいずれかです。"" msgid ""Access control lists"" msgstr ""アクセス制御リスト"" msgid """" ""OpenStack Compute supports tenant network traffic access controls directly "" ""when deployed with the legacy nova-network service, or may defer access "" ""control to the OpenStack Networking service."" msgstr """" ""OpenStack Compute は、旧式の nova-network サービスでデプロイする場合、テナン"" ""トネットワーク通信のアクセス制御を直接サポートします。又は、OpenStack "" ""Networking サービスにアクセス制御を任せる事も出来ます。"" msgid """" ""Security groups allow administrators and tenants the ability to specify the "" ""type of traffic, and direction (ingress/egress) that is allowed to pass "" ""through a virtual interface port. Security groups rules are stateful L2-L4 "" ""traffic filters."" msgstr """" ""セキュリティグループでは、管理者とテナントが仮想インターフェースポート通過を"" ""許可する通信のタイプと方向（内向き／外向き）を指定できるようになっています。"" msgid ""L3 routing and NAT"" msgstr ""L3 ルーティングおよび NAT"" msgid """" ""OpenStack Networking routers can connect multiple L2 networks, and can also "" ""provide a <emphasis>gateway</emphasis> that connects one or more private L2 "" ""networks to a shared <emphasis>external</emphasis> network, such as a public "" ""network for access to the Internet."" msgstr """" ""OpenStack Networking のルータは複数の L2 ネットワークを接続でき、１つ以上のプ"" ""ライベート L2 ネットワークを共有<emphasis>外部</emphasis>ネットワーク（イン"" ""ターネットアクセス用のパブリックネットワーク等）に接続する<emphasis>ゲート"" ""ウェイ</emphasis>を提供する事も出来ます。"" msgid """" ""The L3 router provides basic Network Address Translation (NAT) capabilities "" ""on <emphasis>gateway</emphasis> ports that uplink the router to external "" ""networks. This router SNATs (Static NAT) all traffic by default, and "" ""supports floating IPs, which creates a static one-to-one mapping from a "" ""public IP on the external network to a private IP on one of the other "" ""subnets attached to the router."" msgstr """" ""L3 ルータは、外部ネットワークへのルータに接続する<emphasis>ゲートウェイ</"" ""emphasis>ポート上の基本的なネットワークアドレス変換 (NAT) 機能を提供します。"" ""このルータはデフォルトで全てのネットワークの SNAT (静的 NAT) を行います。これ"" ""は、外部ネットワーク上のパブリック IP アドレスから、ルータにアタッチされた他"" ""の１サブネットのプライベート IP アドレスへ変換する静的な１対１マッピングを作"" ""成します。"" msgid """" ""It is our recommendation to leverage per tenant L3 routing and Floating IPs "" ""for more granular connectivity of tenant VMs."" msgstr """" ""テナント VM のより粒度の細かいテナント L3 ルーティングとフローティング IP 単"" ""位で設定する事をお勧めします。"" msgid ""Quality of Service (QoS)"" msgstr ""サービス品質(QoS)"" msgid ""Traffic shaping through DSCP markings"" msgstr ""DSCP マーキングによるトラフィックシェーピング"" msgid ""Rate-limiting on a per port/network/tenant basis."" msgstr ""ポート・ネットワーク・テナント単位のレートリミット"" msgid ""Port mirroring (through open source or third-party plug-ins)"" msgstr ""ポートミラーリング (オープンソースのサードパーティ製プラグイン使用)"" msgid ""Flow analysis (through open source or third-party plug-ins)"" msgstr ""フロー分析 (オープンソースのサードパーティプラグイン使用)"" msgid ""Load balancing"" msgstr ""負荷分散"" msgid ""Firewalls"" msgstr ""ファイアウォール"" msgid ""Network services extensions"" msgstr ""ネットワークサービス拡張"" msgid ""OpenStack Networking has the following known limitations:"" msgstr ""OpenStack Networking は以下の制限があります。"" msgid ""Overlapping IP addresses"" msgstr ""IP アドレスの重複""""If nodes that run either <systemitem class=\""service\"">neutron-l3-agent</"" ""systemitem> or <systemitem class=\""service\"">neutron-dhcp-agent</systemitem> "" ""use overlapping IP addresses, those nodes must use Linux network namespaces. "" ""By default, the DHCP and L3 agents use Linux network namespaces. However, if "" ""the host does not support these namespaces, run the DHCP and L3 agents on "" ""different hosts.""""<systemitem class=\""service\"">neutron-l3-agent</systemitem> か <systemitem "" ""class=\""service\"">neutron-dhcp-agent</systemitem> のいずれかを実行するノード"" ""が重複した IP アドレスを使用する場合、これらのノード群は Linux のネットワーク"" ""ネームスペースを使用する必要があります。デフォルトでは、DHCP と L3 エージェン"" ""トは Linux ネットワークネームスペースを使用しています。しかしながら、ホストが"" ""このネームスペースをサポートしていない場合、DHCP と L3 エージェントは異なるホ"" ""ストで実行して下さい。"" msgid """" ""If network namespace support is not present, a further limitation of the L3 "" ""agent is that only a single logical router is supported."" msgstr """" ""ネットワークネームスペースサポートがない場合、L3エージェントでは追加の制限事"" ""項として単一の論理ルータのみサポートされます。"" msgid ""Multi-host DHCP-agent"" msgstr ""マルチホスト DHCP エージェント"" msgid """" ""OpenStack Networking supports multiple L3 and DHCP agents with load "" ""balancing. However, tight coupling of the location of the virtual machine is "" ""not supported."" msgstr """" ""OpenStack Networking は複数の L3 エージェントと DHCP エージェントによる負荷分"" ""散をサポートしています。しかしながら、（訳注：nova-network がサポートしてい"" ""た）仮想マシンとの配置上の強い紐付けはサポートされていません。""""The neutron-l3-agent, used by many plug-ins to implement L3 forwarding, "" ""supports only IPv4 forwarding.""""neutron-l3-agent （L3 転送の実装用に多くのプラグインが使用）は IPv4 転送のみ"" ""サポートしています。"" msgid """" ""Domains are high-level containers for projects, users and groups. As such, "" ""they can be used to centrally manage all keystone-based identity components. "" ""With the introduction of account domains, server, storage and other "" ""resources can now be logically grouped into multiple projects (previously "" ""called tenants) which can themselves be grouped under a master account-like "" ""container. In addition, multiple users can be managed within an account "" ""domain and assigned roles that vary for each project."" msgstr """" ""ドメインはプロジェクト、ユーザー、グループの高いレベルでのコンテナーです。そ"" ""のように、すべての keystone ベースの識別コンポーネントを一元的に管理するため"" ""に使用されます。アカウントドメインを導入すると、サーバー、ストレージ、他のリ"" ""ソースは複数のプロジェクト (以前はテナントと呼ばれていました) の中で論理的に"" ""グループ化できます。これは、アカウントのようなマスターコンテナーの下でグルー"" ""プ化できます。さらに、複数のユーザーがアカウントドメインの中で管理でき、各プ"" ""ロジェクトで変化するロールを割り当てられます。"" msgid """" ""Where a rule may specify access to only admin users and users belonging to "" ""the tenant, the mapping may be trivial. In other scenarios the cloud "" ""administrator may need to approve the mapping routines per tenant."" msgstr """" ""ルールにより管理ユーザーとテナントに所属するユーザーのみにアクセス権を設定さ"" ""れるかもしれないため、マッピングは些細なことかもしれません。他のシナリオの場"" ""合、クラウド管理者がテナントごとのマッピング作業を承認する必要があるかもしれ"" ""ません。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/node-provisioning-pxe.png'; "" ""md5=51b76c5aced74f935490b37ba921dc43"" msgstr """" ""@@image: 'static/node-provisioning-pxe.png'; "" ""md5=51b76c5aced74f935490b37ba921dc43"" msgid ""Integrity life-cycle"" msgstr ""完全性ライフサイクル"" msgid """" ""We define integrity life cycle as a deliberate process that provides "" ""assurance that we are always running the expected software with the expected "" ""configurations throughout the cloud. This process begins with secure "" ""bootstrapping and is maintained through configuration management and "" ""security monitoring. This chapter provides recommendations on how to "" ""approach the integrity life-cycle process."" msgstr """" ""OpenStack では、完全性ライフサイクルを「クラウド全体にわたって想定されている"" ""ソフトウェアが想定されている設定で常に実行されることを保証する計画的なプロセ"" ""ス」と定義しています。このプロセスは、セキュアなブートストラッピングで開始"" ""し、設定管理およびセキュリティ監視の機能により維持されます。本章では、完全性"" ""ライフサイクルプロセスのアプローチ方法について説明します。"" msgid ""Secure bootstrapping"" msgstr ""セキュアブートストラップ""""A complete tutorial on secure boot deployment is beyond the scope of this "" ""book. Instead, here we provide a framework for how to integrate secure boot "" ""technologies with the typical node provisioning process. For additional "" ""details, cloud architects should refer to the related specifications and "" ""software configuration manuals.""""セキュアブートのデプロイに関する完全なチュートリアルは、本書の範囲外なので、"" ""その代わりとして、標準的なノードプロビジョニングプロセスにセキュアブートテク"" ""ノロジーを統合する方法の枠組みを提供します。クラウドアーキテクトが更に詳しい"" ""情報を確認するには、関連する仕様およびソフトウェア設定のマニュアルを参照する"" ""ことをお勧めします。"" msgid ""Node provisioning"" msgstr ""ノードのプロビジョニング""""Nodes should use Preboot eXecution Environment (PXE) for provisioning. This "" ""significantly reduces the effort required for redeploying nodes. The typical "" ""process involves the node receiving various boot stagesthat is progressively "" ""more complex software to execute from a server.""""ノードは、プロビジョニングに Preboot eXecution Environment (PXE) を使用すべき"" ""です。これにより、ノードの再デプロイに必要な作業が大幅に軽減されます。標準的"" ""なプロセスでは、ノードがサーバーからさまざまなブート段階 (実行するソフトウェ"" ""アが徐々に複雑化) を受信する必要があります。"" msgid ""Verified boot"" msgstr ""検証済みブート""""In general, there are two different strategies for verifying the boot "" ""process. Traditional <emphasis>secure boot</emphasis> will validate the code "" ""run at each step in the process, and stop the boot if code is incorrect. "" ""<emphasis>Boot attestation</emphasis> will record which code is run at each "" ""step, and provide this information to another machine as proof that the boot "" ""process completed as expected. In both cases, the first step is to measure "" ""each piece of code before it is run. In this context, a measurement is "" ""effectively a SHA-1 hash of the code, taken before it is executed. The hash "" ""is stored in a platform configuration register (PCR) in the TPM.""""ブートプロセスの検証には、通常 2 つの異なる戦略があります。従来の<emphasis>セ"" ""キュアブート</emphasis>は、プロセスの各ステップに実行されるコードを検証し、"" ""コードが正しくない場合にはブートを中止します。<emphasis>ブートアテステーショ"" ""ン</emphasis>は、どのステップでどのコードが実行されるかを記録し、ブートプロセ"" ""スが想定通りに完了した証拠として、この情報を別のマシンに提供します。いずれの"" ""ケースにおいても、第 1 のステップでは、実行前にコードの各要素を計測します。こ"" ""の場合、計測値は実質的にはコードの SHA-1 ハッシュで、実行前に取得されます。 "" ""このハッシュは、TPM 内の Platform Configuration Register (PCR) に保管されま"" ""す。"" msgid ""Note: SHA-1 is used here because this is what the TPM chips support."" msgstr ""注記: ここで SHA-1 を使用するのは、TPM チップが対応しているためです。""""Each TPM has at least 24 PCRs. The TCG Generic Server Specification, v1.0, "" ""March 2005, defines the PCR assignments for boot-time integrity "" ""measurements. The table below shows a typical PCR configuration. The context "" ""indicates if the values are determined based on the node hardware (firmware) "" ""or the software provisioned onto the node. Some values are influenced by "" ""firmware versions, disk sizes, and other low-level information. Therefore, "" ""it is important to have good practices in place around configuration "" ""management to ensure that each system deployed is configured exactly as "" ""desired.""""各 TPM には少なくとも 24 の PCR が含まれます。TCG Generic Server "" ""Specification ( v1.0、2005 年 3 月版) には、ブート時の完全性計測のための PCR "" ""の割り当てが定義されています。以下の表には、標準的な PCR 設定を記載していま"" ""す。コンテキストには、その値がノードのハードウェア (ファームウェア) をベース"" ""に決定されるか、ノードにプロビジョニングされているソフトウェアをベースに決定"" ""されるかを示しています。一部の値は、ファームウェアのバージョンやディスクサイ"" ""ズ、その他の低レベルの情報によって影響を受けます。このため、設定管理の適切な"" ""プラクティスを整備し、デプロイするシステムが要望通りに設定されるようにしてお"" ""くことが重要となります。"" msgid ""Register"" msgstr ""レジスター"" msgid ""What is measured"" msgstr ""計測の対象"" msgid ""Context"" msgstr ""コンテキスト"" msgid ""PCR-00"" msgstr ""PCR-00""""Core Root of Trust Measurement (CRTM), BIOS code, Host platform extensions""""Core Root of Trust Measurement (CRTM)、 BIOS コード、ホストプラットフォームの"" ""拡張機能"" msgid ""Hardware"" msgstr ""ハードウェア"" msgid ""PCR-01"" msgstr ""PCR-01"" msgid ""Host platform configuration"" msgstr ""ハードウェアプラットフォームの設定"" msgid ""PCR-02"" msgstr ""PCR-02"" msgid ""Option ROM code"" msgstr ""オプションの ROM コード"" msgid ""PCR-03"" msgstr ""PCR-03"" msgid ""Option ROM configuration and data"" msgstr ""オプションの ROM 設定およびデータ"" msgid ""PCR-04"" msgstr ""PCR-04"" msgid ""Initial Program Loader (IPL) code. For example, master boot record."" msgstr ""Initial Program Loader (IPL) コード (例: マスターブートレコード) "" msgid ""Software"" msgstr ""ソフトウェア"" msgid ""PCR-05"" msgstr ""PCR-05"" msgid ""IPL code configuration and data"" msgstr ""IPL コードの設定およびデータ"" msgid ""PCR-06"" msgstr ""PCR-06"" msgid ""State transition and wake events"" msgstr ""状態遷移とウェイクイベント"" msgid ""PCR-07"" msgstr ""PCR-07"" msgid ""Host platform manufacturer control"" msgstr ""ホストプラットフォームのメーカーによる制御"" msgid ""PCR-08"" msgstr ""PCR-08"" msgid ""Platform specific, often kernel, kernel extensions, and drivers"" msgstr """" ""プラットフォーム固有、多くの場合はカーネル、カーネル拡張機能、ドライバー"" msgid ""PCR-09"" msgstr ""PCR-09"" msgid ""Platform specific, often Initramfs"" msgstr ""プラットフォーム固有、多くの場合は Initramfs"" msgid ""PCR-10 to PCR-23"" msgstr ""PCR-10 から PCR-23"" msgid ""Platform specific"" msgstr ""プラットフォーム固有""""At the time of this writing, very few clouds are using secure boot "" ""technologies in a production environment. As a result, these technologies "" ""are still somewhat immature. We recommend planning carefully in terms of "" ""hardware selection. For example, ensure that you have a TPM and Intel TXT "" ""support. Then verify how the node hardware vendor populates the PCR values. "" ""For example, which values will be available for validation. Typically the "" ""PCR values listed under the software context in the table above are the ones "" ""that a cloud architect has direct control over. But even these may change as "" ""the software in the cloud is upgraded. Configuration management should be "" ""linked into the PCR policy engine to ensure that the validation is always up "" ""to date.""""本ガイドの執筆時点では、実稼働環境でセキュアブートテクノロジーを使用するクラ"" ""ウドはほとんどありませんでした。このため、これらのテクノロジーはまだ若干未成"" ""熟な状態です。ハードウェアは、慎重に計画した上で選択することを推奨します "" ""(例: TPM および Intel TXT の対応を確認するなど)。次に、ノードのハードウェアベ"" ""ンダーが PCR 値をどのように事前設定しているかを検証します (例: どの値を検証で"" ""きるか)。上記の表のコンテキストにソフトウェアと記載されている PCR 値は通常、"" ""クラウドアーキテクトが直接コントロールできます。ただし、これらの値は、クラウ"" ""ド内のソフトウェアをアップグレードすると変更される場合があります。設定管理"" ""は、PCR ポリシーエンジン内にリンクして、検証を常に最新の状態 に確保すべきで""""Each manufacturer must provide the BIOS and firmware code for their servers. "" ""Different servers, hypervisors, and operating systems will choose to "" ""populate different PCRs. In most real world deployments, it will be "" ""impossible to validate every PCR against a known good quantity (\""golden "" ""measurement\""). Experience has shown that, even within a single vendor's "" ""product line, the measurement process for a given PCR may not be consistent. "" ""We recommend establishing a baseline for each server and monitoring the PCR "" ""values for unexpected changes. Third-party software may be available to "" ""assist in the TPM provisioning and monitoring process, depending upon your "" ""chosen hypervisor solution.""""各メーカーは、サーバーの BIOS とファームウェアのコードを提供する必要がありま"" ""す。サーバー、ハイパーバイザー、オペレーティングシステムによって、事前設定さ"" ""れる PCR 値の選択が異なります。実際のデプロイメントではほとんどの場合、既知の"" ""適切な量 (「黄金の計測値」) と対照して各 PCR を検証することは不可能です。単一"" ""のベンダー の製品ラインの場合でも、一定の PCR の計測プロセスに一貫性がない場"" ""合があることが、経験により実証されています。各サーバーに基準値を定め、 PCR 値"" ""の予期せぬ変化を監視することを推奨します。選択したハイパーバイザーソリュー"" ""ションによっては、TPM プロビジョニングおよび監視プロセスを支援する サードパー"" ""ティー製のソフトウェアが提供されている可能性があります。""""Depending on the strategy selected, in the event of a failure the node will "" ""either fail to boot or it can report the failure back to another entity in "" ""the cloud. For secure boot, the node will fail to boot and a provisioning "" ""service within the management security domain must recognize this and log "" ""the event. For boot attestation, the node will already be running when the "" ""failure is detected. In this case the node should be immediately quarantined "" ""by disabling its network access. Then the event should be analyzed for the "" ""root cause. In either case, policy should dictate how to proceed after a "" ""failure. A cloud may automatically attempt to re-provision a node a certain "" ""number of times. Or it may immediately notify a cloud administrator to "" ""investigate the problem. The right policy here will be deployment and "" ""failure mode specific.""""選択した戦略に応じて、障害発生時にノードがブートに失敗するか、クラウド内の別"" ""のエンティティに障害を報告することができます。セキュアブートの場合には、ノー"" ""ドがブートに失敗し、管理セキュリティドメイン内のプロビジョニングサービスがこ"" ""の問題を認識してイベントログを記録する必要があります。ブートアテステーション"" ""の場合には、障害検出時にはノードがすでに稼働している状態です。この場合、ネッ"" ""トワークアクセスを無効にすることによってノードの検疫を直ちに行った後に、イベ"" ""ントを解析して根本原因を特定するべきです。いずれの場合も、ポリシーにより、障"" ""害発生後の対処方法を指示する必要があります。クラウドが、特定の回数、ノードの"" ""再プロビジョニングを自動的に試みるようにしたり、問題を調査するようにクラウド"" ""管理者に直ちに通知するようにすることができます。この場合に適正となるポリシー"" ""は、デプロイメントと障害のモードによって異なります。 "" msgid ""Node hardening"" msgstr ""ノードのセキュリティ強化機能""""At this point we know that the node has booted with the correct kernel and "" ""underlying components. There are many paths for hardening a given operating "" ""system deployment. The specifics on these steps are outside of the scope of "" ""this book. We recommend following the guidance from a hardening guide "" ""specific to your operating system. For example, the <link href=\""http://iase."" ""disa.mil/stigs/\"">security technical implementation guides</link> (STIG) and "" ""the <link href=\""http://www.nsa.gov/ia/mitigation_guidance/"" ""security_configuration_guides/\"">NSA guides</link> are useful starting "" ""places.""""この時点で、ノードが正しいカーネルと配下のコンポーネントでブートしていること"" ""が分かります。オペレーティングシステムのデプロイメントのセキュリティを強化す"" ""るには、数多くの方法があります。これらの手順についての詳しい説明は本書の範囲"" ""外です。お使いのオペレーティングシステム固有のセキュリティ強化ガイドのアドバ"" ""イスに従うことを推奨します。例えば、<link href=\""http://iase.disa.mil/stigs/"" ""\"">security technical implementation guides</link> (STIG) や <link href="" ""\""http://www.nsa.gov/ia/mitigation_guidance/security_configuration_guides/"" ""\"">NSA guides</link> を最初に参考にすると役立ちます。""""The nature of the nodes makes additional hardening possible. We recommend "" ""the following additional steps for production nodes:""""ノードはその性質上、追加のセキュリティ強化が可能です。実稼働用のノードには、"" ""次の追加手順に従うことを推奨します。""""Use a mandatory access control policy to contain the instances, the node "" ""services, and any other critical processes and data on the node. See the "" ""discussions on sVirt / SELinux and AppArmor below.""""強制アクセス制御ポリシーを使用して、インスタンス、ノードサービス、その他の重"" ""要なプロセスおよびノード上のデータが含まれるようにします。以下に記載の "" ""sVirt / SELinux および AppArmor についての説明を参照してください。""""Remove any unnecessary software packages. This should result in a very "" ""stripped down installation because a compute node has a relatively small "" ""number of dependencies.""""不要なソフトウェアパッケージは削除します。これにより、コンピュートノードの依"" ""存関係が比較的少なくなるので、インストールを小さく絞ることができます。""""Finally, the node kernel should have a mechanism to validate that the rest "" ""of the node starts in a known good state. This provides the necessary link "" ""from the boot validation process to validating the entire system. The steps "" ""for doing this will be deployment specific. As an example, a kernel module "" ""could verify a hash over the blocks comprising the file system before "" ""mounting it using <link href=\""https://code.google.com/p/cryptsetup/wiki/"" ""DMVerity\"">dm-verity</link>.""""最後に、ノードのカーネルには、残りのノードが既知の良好な状態で起動することを"" ""検証するメカニズムを取り入れるべきです。これにより、ブート検証プロセスからシ"" ""ステム全体の検証に至るまでの必要なリンクが提供されます。手順はデプロイメント"" ""によって異なります。例えば、カーネルモジュールは、<link href=\""https://code."" ""google.com/p/cryptsetup/wiki/DMVerity\"">dm-verity</link> を使用して、ファイル"" ""システムをマウントする前に、そのファイルシステムを構成するブロック上のハッ"" ""シュを検証することができます。"" msgid ""Runtime verification"" msgstr ""ランタイムの検証""""Once the node is running, we need to ensure that it remains in a good state "" ""over time. Broadly speaking, this includes both configuration management and "" ""security monitoring. The goals for each of these areas are different. By "" ""checking both, we achieve higher assurance that the system is operating as "" ""desired. We discuss configuration management in the management section, and "" ""security monitoring below.""""ノードが稼働したら、長時間にわたって良好な状態で稼働を継続するように確保する"" ""必要があります。大まかに言うと、これには設定管理とセキュリティ監視が含まれま"" ""す。これらの各領域の目標は異なります。両方を確認することにより、システムが希"" ""望通りに稼働していることをより確実に保証します。設定管理については、管理のセ"" ""クションおよび次のセキュリティ監視で説明します。"" msgid ""Intrusion detection system"" msgstr ""侵入検知システム""""Host-based intrusion detection tools are also useful for automated "" ""validation of the cloud internals. There are a wide variety of host-based "" ""intrusion detection tools available. Some are open source projects that are "" ""freely available, while others are commercial. Typically these tools analyze "" ""data from a variety of sources and produce security alerts based on rule "" ""sets and/or training. Typical capabilities include log analysis, file "" ""integrity checking, policy monitoring, and rootkit detection. More advanced "" ""-- often custom -- tools can validate that in-memory process images match "" ""the on-disk executable and validate the execution state of a running process.""""ホストベースの侵入検知ツールは、クラウド内部の検証の自動化にも役立ちます。ホ"" ""ストベースの侵入検知ツールにはさまざまな種類があります。オープンソースで自由"" ""に利用できるツールもあれば、商用のツールもあります。通常、これらのツールは、"" ""さまざまなソースからデータを分析し、ルールセットやトレーニングに基づいてセ"" ""キュリティ警告を出します。標準的な機能には、ログ解析、ファイルの完全性チェッ"" ""ク、ポリシー監視、ルートキット検出などがあります。また、より高度なツール (カ"" ""スタムの場合が多い) を使用すると、インメモリープロセスイメージがオンディスク"" ""の実行可能ファイルと一致するかどうかを確認して、実行中のプロセスの実行状態を"" ""検証することができます。""""One critical policy decision for a cloud architect is what to do with the "" ""output from a security monitoring tool. There are effectively two options. "" ""The first is to alert a human to investigate and/or take corrective action. "" ""This could be done by including the security alert in a log or events feed "" ""for cloud administrators. The second option is to have the cloud take some "" ""form of remedial action automatically, in addition to logging the event. "" ""Remedial actions could include anything from re-installing a node to "" ""performing a minor service configuration. However, automated remedial action "" ""can be challenging due to the possibility of false positives.""""セキュリティ監視ツールの出力の処理方法は、クラウドアーキテクトにとっての重要"" ""なポリシー決定の一つです。オプションは実質的に 2 つあります。第 1 のオプショ"" ""ンは、問題を調査して修正措置を取るように、人間に警告を発する方法です。これ"" ""は、クラウド管理者向けのログまたはイベントのフィードにセキュリティ警告を組み"" ""込むことによって可能となります。第 2 のオプションは、イベントのログ記録に加え"" ""て、クラウドが何らかの形の修復措置を自動的に実行するように設定する方法です。"" ""修復措置にはノードの再インストールから、マイナーなサービス設定の実行まで含め"" ""ることができます。ただし、自動修復措置は、誤検知の可能性があるため、困難とな"" ""る場合があります。""""False positives occur when the security monitoring tool produces a security "" ""alert for a benign event. Due to the nature of security monitoring tools, "" ""false positives will most certainly occur from time to time. Typically a "" ""cloud administrator can tune security monitoring tools to reduce the false "" ""positives, but this may also reduce the overall detection rate at the same "" ""time. These classic trade-offs must be understood and accounted for when "" ""setting up a security monitoring system in the cloud.""""誤検知は、セキュリティ監視ツールが害のないイベントのセキュリティ警告を出した"" ""場合に発生します。セキュリティ警告ツールの性質上、時々誤検知が発生することは"" ""間違いありません。通常、クラウド管理者は、セキュリティ監視ツールを微調整し"" ""て、誤検知を少なくすることができますが、これにより、全体的な検知率も同時に下"" ""がる場合があります。このような典型的トレードオフを理解し、クラウドにセキュリ"" ""ティ管理システムをセットアップする際には考慮に入れる必要があります。""""The selection and configuration of a host-based intrusion detection tool is "" ""highly deployment specific. We recommend starting by exploring the following "" ""open source projects which implement a variety of host-based intrusion "" ""detection and file monitoring features.""""ホストベースの侵入検知ツールの選択と設定はデプロイメントによって大幅に異なり"" ""ます。多様なホストベースの侵入検知/ファイル監視機能を実装する以下のオープン"" ""ソースプロジェクトの検討から開始することをお勧めします。"" msgid ""OSSEC"" msgstr ""OSSEC"" msgid ""Samhain"" msgstr ""Samhain"" msgid ""Tripwire"" msgstr ""Tripwire"" msgid ""AIDE"" msgstr ""AIDE""""Network intrusion detection tools complement the host-based tools. OpenStack "" ""doesn't have a specific network IDS built-in, but OpenStack Networking "" ""provides a plug-in mechanism to enable different technologies through the "" ""Networking API. This plug-in architecture will allow tenants to develop API "" ""extensions to insert and configure their own advanced networking services "" ""like a firewall, an intrusion detection system, or a VPN between the VMs.""""ネットワーク侵入検知ツールは、ホストベースのツールを補完します。OpenStack に"" ""は、特定のネットワーク IDS は組み込まれていませんが、OpenStack Networking "" ""は、Networking API を使用して異なるテクノロジーを有効にするプラグインメカニズ"" ""ムを提供しています。このプラグインのアーキテクチャーにより、テナントは API 拡"" ""張機能を開発して、ファイアウォール、侵入検知システム、仮想マシン間の VPN など"" ""の独自の高度なネットワークサービスを挿入/設定することができます。""""Similar to host-based tools, the selection and configuration of a network-"" ""based intrusion detection tool is deployment specific. <link href=\""http://"" ""www.snort.org/\"">Snort</link> is the leading open source networking "" ""intrusion detection tool, and a good starting place to learn more.""""ホストベースのツールと同様に、ネットワークベースの侵入検知ツールはデプロイメ"" ""ントによって異なります。 <link href=\""http://www.snort.org/\"">Snort</link> "" ""は、先進的なオープンソースのネットワーク侵入検知ツールです。このツールを起点"" ""として、更に知識を深めてゆくとよいでしょう。""""There are a few important security considerations for network and host-based "" ""intrusion detection systems.""""ネットワークおよびホストベースの侵入検知システムには、いくつかの重要なセキュ"" ""リティ課題があります。""""In some deployments it may be required to add host-based IDS on sensitive "" ""components on security domain bridges. A host-based IDS may detect anomalous "" ""activity by compromised or unauthorized processes on the component. The IDS "" ""should transmit alert and log information on the Management network.""""一部のデプロイメントでは、ホストベースの IDS をセキュリティドメインブリッジ上"" ""の機密性の高いコンポーネントに追加する必要がある場合があります。ホストベース"" ""の IDS は、そのコンポーネント上の侵害された、あるいは許可されていないプロセス"" ""による異常なアクティビティを検知することができます。IDS は管理ネットワーク上"" ""で警告およびログ情報を伝送すべきです。"" msgid ""Case studies: Identity management"" msgstr ""ケーススタディ: ID 管理""""Alice also deploys the dashboard to manage many aspects of the cloud. She "" ""deploys the dashboard with HSTS to ensure that only HTTPS is used. The "" ""dashboard resides within an internal subdomain of the private network domain "" ""name system.""""アリスはクラウドのさまざまな観点を管理するために Dashboard も導入します。必"" ""ず HTTPS のみを使用するために HSTS と共に Dashboard を導入します。Dashboard "" ""はプライベートネットワークの DNS の内部サブドメインの中にあります。""""Alice decides to use SPICE instead of VNC for the virtual console. She wants "" ""to take advantage of the emerging capabilities in SPICE.""""アリスは仮想コンソールに VNC の代わりに SPICE を使用することを決めました。"" ""SPICE の先進的な機能の利点を得ようと思います。""""Bob decides to use VNC for his virtual console for its maturity and security "" ""features.""""ボブはその成熟度とセキュリティ機能から仮想コンソールに VNC を使用することを決"" ""めました。"" msgid ""Hypervisor selection"" msgstr ""ハイパーバイザーの選択"" msgid ""Hypervisors in OpenStack"" msgstr ""OpenStack におけるハイパーバイザー""msgid ""Selection criteria"" msgstr ""選択基準"" msgid """" ""As part of your hypervisor selection process, you must consider a number of "" ""important factors to help increase your security posture. Specifically, you "" ""must become familiar with these areas:"" msgstr """" ""ハイパーバイザーの選択において、セキュリティを保証するために考慮すべき重要な"" ""要因がいくつかあります。特に下記の面に注目します。"" msgid ""Team expertise"" msgstr ""チーム習熟度"" msgid ""Product or project maturity"" msgstr ""製品やプロジェクトの成熟度"" msgid ""Common criteria"" msgstr ""コモンクライテリア (Common Criteria)"" msgid ""Certifications and attestations"" msgstr ""証明書"" msgid ""Hardware concerns"" msgstr ""ハードウェア関連"" msgid ""Hypervisor vs. baremetal"" msgstr ""ハードウェア対ベアメタル"" msgid ""Additional security features"" msgstr ""追加のセキュリティ機能"" msgid """" ""Additionally, the following security-related criteria are highly encouraged "" ""to be evaluated when selecting a hypervisor for OpenStack deployments:"" msgstr """" ""加えて、OpenStack 環境のハイパーバイザーを選択する際に、以下のセキュリティ関"" ""連の認証を評価することが推奨されます。"" msgid """" ""Has the hypervisor undergone Common Criteria certification? If so, to what "" ""levels?"" msgstr """" ""ハイパーバイザーはCommon Criteria認定を取得していますか？取得している場合はど"" ""のレベルですか？"" msgid ""Is the underlying cryptography certified by a third-party?"" msgstr ""採用している暗号化技術は第三者によって認定されていますか？"" msgid """" ""Most likely, the most important aspect in hypervisor selection is the "" ""expertise of your staff in managing and maintaining a particular hypervisor "" ""platform. The more familiar your team is with a given product, its "" ""configuration, and its eccentricities, the fewer the configuration mistakes. "" ""Additionally, having staff expertise spread across an organization on a "" ""given hypervisor increases availability of your systems, allows segregation "" ""of duties, and mitigates problems in the event that a team member is "" ""unavailable."" msgstr """" ""多分、ハイパーバイザー選択における一番重要な観点はある特定のハイパーバイザー"" ""プラットフォームの管理と保守におけるあなたのスタッフのノウハウです。あなたの"" ""チームが与えられた製品、その設定、クセに慣れていればいるほど、設定ミスは少な"" ""くなります。加えて、あなたのスタッフが与えられたハイパーバイザーについて組織"" ""を横断してノウハウを広めていけば、あなたのシステムの可用性は向上し、職務分掌"" ""が可能になり、チームメンバーが対応できない場合での問題を軽減します。"" msgid """" ""The maturity of a given hypervisor product or project is critical to your "" ""security posture as well. Product maturity has a number of effects once you "" ""have deployed your cloud:"" msgstr """" ""ハイパーバイザー製品またはプロジェクトの成熟度もセキュリティ上重要です。製品"" ""の成熟度はクラウドを配備してから大きな影響が現れます。"" msgid ""Availability of expertise"" msgstr ""ノウハウの入手先"" msgid ""Active developer and user communities"" msgstr ""活発な開発者とユーザーのコミュニティ"" msgid ""Timeliness and availability of updates"" msgstr ""タイムラインとアップデートの入手先"" msgid ""Incidence response"" msgstr ""インシデントレスポンス"" msgid """" ""One of the biggest indicators of a hypervisor's maturity is the size and "" ""vibrancy of the community that surrounds it. As this concerns security, the "" ""quality of the community affects the availability of expertise if you need "" ""additional cloud operators. It is also a sign of how widely deployed the "" ""hypervisor is, in turn leading to the battle readiness of any reference "" ""architectures and best practices."" msgstr """" ""ハイパーバイザーの完成度の最大の指標の１つに、それを取り巻くコミュニティのサ"" ""イズと活気があります。これはセキュリティに関するので、コミュニティの質はあな"" ""たが追加のクラウドオペレーターを必要とする、利用可能なノウハウに影響します。"" ""これはまた、ハイパーバイザーがいかに広く開発されているかの印でもあり、同様"" ""に、リファレンスアーキテクチャやベストプラクティスの戦闘準備につながるので"" ""す。"" msgid """" ""Further, the quality of community, as it surrounds an open source hypervisor "" ""like KVM or Xen, has a direct impact on the timeliness of bug fixes and "" ""security updates. When investigating both commercial and open source "" ""hypervisors, you must look into their release and support cycles as well as "" ""the time delta between the announcement of a bug or security issue and a "" ""patch or response. Lastly, the supported capabilities of OpenStack compute "" ""vary depending on the hypervisor chosen. See the <link href=\""https://wiki."" ""openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support "" ""Matrix</link> for OpenStack compute feature support by hypervisor."" msgstr """" ""さらに、コミュニティが KVM や Xen のようなオープンソースのハイパーバイザーを"" ""取り巻くので、その質はバグ修正やセキュリティ更新の適時性に直接的な影響があり"" ""ます。商用ハイパーバイザーとオープンソースのものを調査するとき、リリース間隔"" ""やサポートサイクルだけではなく、バグやセキュリティ問題のアナウンスから、パッ"" ""チや対応までの時間間隔を調査する必要があります。最後に、OpenStack Compute の"" ""サポート能力は、お使いのハイパーバイザーにより異なります。ハイパーバイザーに"" ""よりサポートされる OpenStack Compute の機能は、<link href=\""https://wiki."" ""openstack.org/wiki/HypervisorSupportMatrix\"">OpenStack Hypervisor Support "" ""Matrix</link> を参照してください。"" msgid """" ""One additional consideration when selecting a hypervisor is the availability "" ""of various formal certifications and attestations. While they may not be "" ""requirements for your specific organization, these certifications and "" ""attestations speak to the maturity, production readiness, and thoroughness "" ""of the testing a particular hypervisor platform has been subjected to."" msgstr """" ""ハイパーバイザーを選択する際にもう１つ考慮すべき点は、様々な公式の認証や証明"" ""書が利用可能かという事です。あなたの特定の組織の要件ではないかも知れません"" ""が、これらの認証や証明書は、成熟度、商利用可能、特定のハイパーバイザーが目標"" ""としてきたテストの徹底さを物語ります。"" msgid """" ""Common Criteria is an internationally standardized software evaluation "" ""process, used by governments and commercial companies to validate software "" ""technologies perform as advertised. In the government sector, NSTISSP No. 11 "" ""mandates that U.S. Government agencies only procure software which has been "" ""Common Criteria certified, a policy which has been in place since July 2002. "" ""It should be specifically noted that OpenStack has not undergone Common "" ""Criteria certification, however many of the available hypervisors have."" msgstr """" ""共通の条件は国際的に標準化されたソフトウェア評価プロセスです。これは、宣伝目"" ""的でソフトウェア技術の実行を検証する為に政府や企業が使用します。政府部門で"" ""は、NSTISSP No. 11 のみ政府機関にコモンクライテリア認証（2002年7月に登場した"" ""ポリシー）を受けたソフトウェアの調達権限を与えます。特に、Opentack はコモンク"" ""ライテリア認証を受けておらず、多くの入手可能なハイパーバイザーは受けている事"" ""に注意すべきでしょう。"" msgid """" ""In addition to validating a technologies capabilities, the Common Criteria "" ""process evaluates <emphasis>how</emphasis> technologies are developed."" msgstr """" ""Common Criteria のプロセスは、技術的な機能の評価に加えて、技術が<emphasis>ど"" ""のように</emphasis>開発されているのかを評価します。"" msgid ""How is source code management performed?"" msgstr ""どのようにしてソースコード管理が行われるのか？"" msgid ""How are users granted access to build systems?"" msgstr ""どのようにしてユーザがビルドシステムへのアクセスを許可されるのか？"" msgid ""Is the technology cryptographically signed before distribution?"" msgstr ""技術は配布前に暗号署名されるのか？"" msgid """" ""The KVM hypervisor has been Common Criteria certified through the U.S. "" ""Government and commercial distributions, which have been validated to "" ""separate the runtime environment of virtual machines from each other, "" ""providing foundational technology to enforce instance isolation. In addition "" ""to virtual machine isolation, KVM has been Common Criteria certified to"" msgstr """" ""KVM ハイパーバイザーはアメリカ政府から Common Criteria 認証された商用ディスト"" ""リビューションです。インスタンス分離を強制するための基礎的な技術を提供し、仮"" ""想マシンの実行環境を分離できることが検証されました。仮想マシンの分離に加え"" ""て、KVM は次のとおり Common Criteria 認証されています。"" msgid """" ""\""<emphasis>provide system-inherent separation mechanisms to the resources "" ""of virtual machines. This separation ensures that large software component "" ""used for virtualizing and simulating devices executing for each virtual "" ""machine cannot interfere with each other. Using the SELinux multi-category "" ""mechanism, the virtualization and simulation software instances are "" ""isolated. The virtual machine management framework configures SELinux multi-"" ""category settings transparently to the administrator</emphasis>\"""" msgstr """" ""\""<emphasis>provide system-inherent separation mechanisms to the resources "" ""of virtual machines. This separation ensures that large software component "" ""used for virtualizing and simulating devices executing for each virtual "" ""machine cannot interfere with each other. Using the SELinux multi-category "" ""mechanism, the virtualization and simulation software instances are "" ""isolated. The virtual machine management framework configures SELinux multi-"" ""category settings transparently to the administrator</emphasis>\"" (システム固"" ""有の分離機構を仮想マシンのリソースに提供する。この分離により、各仮想マシン用"" ""に実行される仮想および擬似デバイスに対して使用される大規模なソフトウェアコン"" ""ポーネントが、お互いに干渉しないことを保証する。仮想マシンの管理フレームワー"" ""クは、管理者に対して SELinux のマルチカテゴリ設定を透過的に設定する。)"" msgid ""Identification and Authentication"" msgstr ""IDと認証"" msgid """" ""Identification and authentication using pluggable authentication modules "" ""(PAM) based upon user passwords. The quality of the passwords used can be "" ""enforced through configuration options."" msgstr """" ""pluggable authentication modules (PAM) を使用した識別と認証はユーザーパスワー"" ""ドに基づいています。使用されるパスワードの質は設定オプションにより強制できま"" ""す。"" msgid ""Audit"" msgstr ""監査"" msgid """" ""The system provides the capability to audit a large number of events "" ""including individual system calls as well as events generated by trusted "" ""processes. Audit data is collected in regular files in ASCII format. The "" ""system provides a program for the purpose of searching the audit records."" msgstr """" ""システムは、個々のシステムコールを含む大多数のイベントおよび信頼されたプロセ"" ""スにより生成されたイベントを監査する機能を提供します。監査データは通常のファ"" ""イルに ASCII 形式で収集されます。システムは、監査レコードを検索するためのプロ"" ""グラムを提供します。"" msgid """" ""The system administrator can define a rule base to restrict auditing to the "" ""events they are interested in. This includes the ability to restrict "" ""auditing to specific events, specific users, specific objects or a "" ""combination of all of this."" msgstr """" ""システム管理者は、関心のあるイベントに監査を制限するために、ルールベースを定"" ""義できます。これには、特定のイベント、特定のユーザー、特定のオブジェクトやこ"" ""れらすべての組み合わせに監査を制限する機能が含まれます。"" msgid ""Audit records can be transferred to a remote audit daemon."" msgstr ""監査レコードはリモート監査デーモンに転送できます。"" msgid ""Discretionary Access Control"" msgstr ""任意アクセス制御"" msgid """" ""Discretionary Access Control (<glossterm>DAC</glossterm>) restricts access "" ""to file system objects based on <glossterm baseform=\""access control list"" ""\"">Access Control Lists</glossterm> (ACLs) that include the standard UNIX "" ""permissions for user, group and others. Access control mechanisms also "" ""protect IPC objects from unauthorized access."" msgstr """" ""任意アクセス制御 (<glossterm>DAC</glossterm>) は、ユーザー、グループ、その他"" ""に対する標準 UNIX パーミッションを含む<glossterm baseform=\""access control "" ""list\"">アクセス制御リスト</glossterm> (ACL) に基づいてファイルシステムオブ"" ""ジェクトへのアクセスを制限します。アクセス制御機構は権限のないアクセスから "" ""IPC オブジェクトも保護します。"" msgid """" ""The system includes the ext4 file system, which supports POSIX ACLs. This "" ""allows defining access rights to files within this type of file system down "" ""to the granularity of a single user."" msgstr """" ""システムは POSIX ACL をサポートする ext4 ファイルシステムを含みます。この種類"" ""のファイルシステムにあるファイルにユーザー単位でアクセス権を定義できます。"" msgid ""Mandatory Access Control"" msgstr ""強制アクセス制御"" msgid """" ""SELinux categories are attached to virtual machines and its resources. The "" ""access control policy enforced using these categories grant virtual machines "" ""access to resources if the category of the virtual machine is identical to "" ""the category of the accessed resource."" msgstr """" ""SELinux カテゴリが仮想マシンとそのリソースに付けられます。仮想マシンのカテゴ"" ""リがアクセスされるリソースのカテゴリと同じ場合、これらのカテゴリを使用して強"" ""制されたアクセス制御ポリシーは、仮想マシンのそのリソースへのアクセスが許可さ"" ""れます。"" msgid """" ""The TOE implements non-hierarchical categories to control access to virtual "" ""machines."" msgstr """" ""TOE は、仮想マシンへのアクセスを制御するために、非階層的なカテゴリを実装しま"" ""す。"" msgid ""Role-Based Access Control"" msgstr ""ロールベースアクセス制御"" msgid """" ""Role-based access control (RBAC) allows separation of roles to eliminate the "" ""need for an all-powerful system administrator."" msgstr """" ""ロールベースアクセス制御 (RBAC) は、全権を持つシステム管理者の必要性を減らす"" ""ために、役割を分割できるようにします。"" msgid ""Object Reuse"" msgstr ""オブジェクト再利用"" msgid """" ""File system objects and memory and IPC objects are cleared before they can "" ""be reused by a process belonging to a different user."" msgstr """" ""ファイルシステムのオブジェクト、メモリ、IPC オブジェクトは、他のユーザーに属"" ""するプロセスにより再利用される前に、クリアされます。"" msgid ""Security Management"" msgstr ""セキュリティ管理"" msgid """" ""The management of the security critical parameters of the system is "" ""performed by administrative users. A set of commands that require root "" ""privileges (or specific roles when RBAC is used) are used for system "" ""management. Security parameters are stored in specific files that are "" ""protected by the access control mechanisms of the system against "" ""unauthorized access by users that are not administrative users."" msgstr """" ""セキュリティ的に重要なシステムパラメーターの管理が、管理ユーザーにより実行さ"" ""れます。root 権限 (または RBAC 使用時の特定のロール) が必要となる一組のコマン"" ""ドが、システム管理のために使用されます。セキュリティ関連のパラメーターは特定"" ""のファイルに保存されます。これらは、システムのアクセス制御機構により、管理"" ""ユーザー以外の権限のないアクセスに対して保護されます。"" msgid ""Secure Communication"" msgstr ""セキュア通信"" msgid """" ""The system supports the definition of trusted channels using SSH. Password "" ""based authentication is supported. Only a restricted number of cipher suites "" ""are supported for those protocols in the evaluated configuration."" msgstr """" ""システムは SSH を使用する信頼チャネルの定義をサポートします。パスワードによる"" ""認証がサポートされます。少しの暗号スイートのみが、評価された設定でそれらのプ"" ""ロトコルのためにサポートされます。"" msgid ""Storage Encryption"" msgstr ""ストレージ暗号化"" msgid """" ""The system supports encrypted block devices to provide storage "" ""confidentiality via dm_crypt."" msgstr """" ""システムは dm_crypt 経由でストレージの機密性を提供するために暗号化ブロックデ"" ""バイスを提供します。"" msgid ""TSF Protection"" msgstr ""TSF 保護"" msgid """" ""While in operation, the kernel software and data are protected by the "" ""hardware memory protection mechanisms. The memory and process management "" ""components of the kernel ensure a user process cannot access kernel storage "" ""or storage belonging to other processes."" msgstr """" ""動作中、カーネルソフトウェアとデータがハードウェアメモリ保護機構により保護さ"" ""れます。カーネルのメモリとプロセスの管理コンポーネントにより、ユーザープロセ"" ""スがカーネルストレージや他のプロセスのストレージにアクセスできないことが保証"" ""されます。"" msgid """" ""Non-kernel TSF software and data are protected by DAC and process isolation "" ""mechanisms. In the evaluated configuration, the reserved user ID root owns "" ""the directories and files that define the TSF configuration. In general, "" ""files and directories containing internal TSF data, such as configuration "" ""files and batch job queues, are also protected from reading by DAC "" ""permissions."" msgstr """" ""非カーネル TSF ソフトウェアとデータが DAC とプロセス分離機構により保護されま"" ""す。評価済みの設定で、予約済みユーザー ID root は TSF 設定を定義するディレク"" ""トリとファイルを所有します。一般的に、設定ファイルやバッチジョブのキューのよ"" ""うな、内部 TSF データを含むファイルとディレクトリも、DAC パーミッションにより"" ""読み取りから保護されます。"" msgid """" ""The system and the hardware and firmware components are required to be "" ""physically protected from unauthorized access. The system kernel mediates "" ""all access to the hardware mechanisms themselves, other than program visible "" ""CPU instruction functions."" msgstr """" ""システム、ハードウェア、ファームウェアのコンポーネントは、権限のないアクセス"" ""から物理的に保護される必要があります。システムカーネルは、プログラムから利用"" ""できる CPU 命令ファンクション以外に、ハードウェア機構自身へのすべてのアクセス"" ""を調停します。"" msgid """" ""In addition, mechanisms for protection against stack overflow attacks are "" ""provided."" msgstr ""さらに、スタックオーバーフロー攻撃に対する保護機構が提供されます。"" msgid ""Cryptography standards"" msgstr ""暗号標準"" msgid """" ""Several cryptography algorithms are available within OpenStack for "" ""identification and authorization, data transfer and protection of data at "" ""rest. When selecting a hypervisor, the following are recommended algorithms "" ""and implementation standards to ensure the virtualization layer supports:"" msgstr """" ""いくつかの暗号アルゴリズムは、認証と識別、データ転送、保存データの保護のため"" ""に、OpenStack の中で利用可能です。ハイパーバイザーの選択時、以下が推奨アルゴ"" ""リズムで、仮想化層のサポートを確実にするための実装標準です。"" msgid ""Algorithm"" msgstr ""アルゴリズム"" msgid ""Key length"" msgstr ""鍵の長さ"" msgid ""Intended purpose"" msgstr ""想定用途"" msgid ""Security function"" msgstr ""セキュリティ機能"" msgid ""Implementation standard"" msgstr ""実装標準"" msgid ""AES"" msgstr ""AES"" msgid ""128, 192, or 256 bits"" msgstr ""128、196、256 ビット"" msgid ""Encryption / decryption"" msgstr ""暗号化 / 復号"" msgid ""Protected data transfer, protection for data at rest"" msgstr ""保護されたデータ転送、保存データの保護"" msgid ""RFC 4253"" msgstr ""RFC 4253"" msgid ""TDES"" msgstr ""TDES"" msgid ""168 bits"" msgstr ""168 ビット"" msgid ""Protected data transfer"" msgstr ""保護されたデータ転送"" msgid ""RSA"" msgstr ""RSA"" msgid ""1024, 2048, or 3072 bits"" msgstr ""1024、2048、3072 ビット"" msgid ""Authentication, key exchange"" msgstr ""認証、鍵交換"" msgid ""Identification and authentication, protected data transfer"" msgstr ""識別と認証、保護されたデータ転送"" msgid ""U.S. NIST FIPS PUB 186-3"" msgstr ""U.S. NIST FIPS PUB 186-3"" msgid ""DSA"" msgstr ""DSA"" msgid ""L=1024, N=160 bits"" msgstr ""L=1024、N=160 ビット"" msgid ""Serpent"" msgstr ""Serpent"" msgid ""Protection of data at rest"" msgstr ""保存データの保護"" msgid ""http://www.cl.cam.ac.uk/~rja14/Papers/serpent.pdf"" msgstr ""http://www.cl.cam.ac.uk/~rja14/Papers/serpent.pdf"" msgid ""Twofish"" msgstr ""Twofish"" msgid ""128, 192, or 256 bit"" msgstr ""128、196、256 ビット"" msgid ""http://www.schneier.com/paper-twofish-paper.html"" msgstr ""http://www.schneier.com/paper-twofish-paper.html"" msgid ""SHA-1"" msgstr ""SHA-1"" msgid ""-"" msgstr ""-"" msgid ""Message Digest"" msgstr ""メッセージダイジェスト"" msgid ""Protection of data at rest, protected data transfer"" msgstr ""保存データの保護、保護されたデータ転送"" msgid ""SHA-2 (224, 256, 384, or 512 bits)"" msgstr ""SHA-2 (224、256、384、512 ビット)"" msgid ""Protection for data at rest, identification and authentication"" msgstr ""保存データの保護、識別と認証"" msgid ""FIPS 140-2"" msgstr ""FIPS 140-2"" msgid """" ""In the United States the National Institute of Science and Technology (NIST) "" ""certifies cryptographic algorithms through a process known the Cryptographic "" ""Module Validation Program. NIST certifies algorithms for conformance against "" ""Federal Information Processing Standard 140-2 (FIPS 140-2), which ensures:"" msgstr """" ""アメリカでは、National Institute of Science and Technology (NIST) が "" ""Cryptographic Module Validation Program として知られるプロセスにより暗号アル"" ""ゴリズムを認証します。NIST は、以下を保証する Federal Information Processing "" ""Standard 140-2 (FIPS 140-2) に適合するアルゴリズムを認証します。"" msgid """" ""Products validated as conforming to FIPS 140-2 are accepted by the Federal "" ""agencies of both countries [United States and Canada] for the protection of "" ""sensitive information (United States) or Designated Information (Canada). "" ""The goal of the CMVP is to promote the use of validated cryptographic "" ""modules and provide Federal agencies with a security metric to use in "" ""procuring equipment containing validated cryptographic modules."" msgstr """" ""FIPS 140-2 への適合性を検証された製品は、機密情報 (アメリカ) や指定情報 (カナ"" ""ダ) の保護のために、両国 (アメリカとカナダ) の連邦機関により受け入れられま"" ""す。CMVP の目標は、検証済み暗号モジュールを含む物品調達で使用するために、検証"" ""済み暗号モジュール利用を推進することと、連邦機関へのセキュリティ評価基準を提"" ""供することです。"" msgid """" ""When evaluating base hypervisor technologies, consider if the hypervisor has "" ""been certified against FIPS 140-2. Not only is conformance against FIPS "" ""140-2 mandated per U.S. Government policy, formal certification indicates "" ""that a given implementation of a cryptographic algorithm has been reviewed "" ""for conformance against module specification, cryptographic module ports and "" ""interfaces; roles, services, and authentication; finite state model; "" ""physical security; operational environment; cryptographic key management; "" ""electromagnetic interference/electromagnetic compatibility (EMI/EMC); self-"" ""tests; design assurance; and mitigation of other attacks."" msgstr """" ""ハイパーバイザーの基礎技術の評価時、ハイパーバイザーが FIPS 140-2 に認証され"" ""ているかどうかを考慮します。正式な認証は、指定された暗号アルゴリズムの実装"" ""が、アメリカ政府機関のポリシーごとに強制される FIPS 140-2 への適合性だけでは"" ""なく、モジュール仕様、暗号モジュールのポートとインターフェース、ロール、サー"" ""ビス、認証、有限オートマトン、物理セキュリティ、運用環境、暗号鍵管理、EMI/"" ""EMC、自己テスト、設計保証、他の攻撃の緩和に対する適合性をレビューされることを"" ""意味します。"" msgid """" ""Further, when you evaluate a hypervisor platform, consider the "" ""supportability of the hardware on which the hypervisor will run. "" ""Additionally, consider the additional features available in the hardware and "" ""how those features are supported by the hypervisor you chose as part of the "" ""OpenStack deployment. To that end, hypervisors each have their own hardware "" ""compatibility lists (HCLs). When selecting compatible hardware it is "" ""important to know in advance which hardware-based virtualization "" ""technologies are important from a security perspective."" msgstr """" ""さらに、ハイパーバイザープラットフォームの評価時、ハイパーバイザーを実行する"" ""ハイパーバイザーを考慮すべきです。加えて、ハードウェアで利用可能な追加機能を"" ""評価します。また、それらの機能が OpenStack 環境の一部として選択したハイパーバ"" ""イザーによりどのようにサポートされるかを考慮します。そのためにも、ハイパーバ"" ""イザーはそれぞれ自身のハードウェア互換性リスト (HCL) を持つでしょう。互換性の"" ""あるハードウェアの選択時、まずどのハードウェア仮想化技術がセキュリティの観点"" ""から重要であるかを理解することが重要です。"" msgid ""Technology"" msgstr ""技術"" msgid ""Explanation"" msgstr ""説明"" msgid ""I/O MMU"" msgstr ""I/O MMU"" msgid ""VT-d / AMD-Vi"" msgstr ""VT-d / AMD-Vi"" msgid ""Required for protecting PCI-passthrough"" msgstr ""PCI パススルーの保護に必要です"" msgid ""Intel Trusted Execution Technology"" msgstr ""Intel Trusted Execution Technology"" msgid ""Intel TXT / SEM"" msgstr ""Intel TXT / SEM"" msgid ""Required for dynamic attestation services"" msgstr ""動的証明サービスに必要です"" msgid """" ""<anchor xml:id=\""PCI-SIG_I.2FO_virtualization_.28IOV.29\""/>PCI-SIG I/O "" ""virtualization"" msgstr """" ""<anchor xml:id=\""PCI-SIG_I.2FO_virtualization_.28IOV.29\""/>PCI-SIG I/O 仮想化"" msgid ""SR-IOV, MR-IOV, ATS"" msgstr ""SR-IOV, MR-IOV, ATS"" msgid ""Required to allow secure sharing of PCI Express devices"" msgstr ""PCI Express デバイスをセキュアに共有するために必要です"" msgid ""Network virtualization"" msgstr ""ネットワーク仮想化"" msgid ""VT-c"" msgstr ""VT-c"" msgid ""Improves performance of network I/O on hypervisors"" msgstr ""ハイパーバイザーにおけるネットワーク I/O の性能を改善します"" msgid """" ""In particular, you must assure your end users that the node has been "" ""properly sanitized of their data prior to re-provisioning. Additionally, "" ""prior to reusing a node, you must provide assurances that the hardware has "" ""not been tampered or otherwise compromised."" msgstr """" ""とくに、ノードが再配備する前にデータを適切に無害化されることをエンドユーザー"" ""に保証する必要があります。加えて、ノードを再利用する前に、ハードウェアが汚染"" ""されていたり、侵入されたりしていないことを保証する必要があります。"" msgid """" ""While OpenStack has a baremetal project, a discussion of the particular "" ""security implications of running baremetal is beyond the scope of this book."" msgstr """" ""OpenStack はベアメタルのプロジェクトを持ちますが、ベアメタル実行の具体的なセ"" ""キュリティ実装に関する議論は本書の範囲外です。"" msgid """" ""Finally, due to the time constraints around a book sprint, the team chose to "" ""use KVM as the hypervisor in our example implementations and architectures."" msgstr """" ""最後に、ブックスプリントの時間的制約のため、実装例とアーキテクチャ例にハイ"" ""パーバイザーとして KVM を使用することにしました。"" msgid """" ""There is an OpenStack Security Note pertaining to the <link href=\""https://"" ""bugs.launchpad.net/ossn/+bug/1098582\"">use of LXC in Compute</link>."" msgstr """" ""<link href=\""https://bugs.launchpad.net/ossn/+bug/1098582\"">use of LXC in "" ""Compute</link> に関する OpenStack Security Note があります。"" msgid ""Hypervisor memory optimization"" msgstr ""ハイパーバイザーのメモリ最適化"" msgid """" ""Typically this is achieved through Copy-On-Write (COW) mechanisms. These "" ""mechanisms have been shown to be vulnerable to side-channel attacks where "" ""one VM can infer something about the state of another and might not be "" ""appropriate for multi-tenant environments where not all tenants are trusted "" ""or share the same levels of trust."" msgstr """" ""これは一般的に、Copy-On-Write (COW) 機構により実現されます。これらの機構は、"" ""ある仮想マシンが別の仮想マシンの状態に関する何かに影響する可能性がある、サイ"" ""ドチャネル攻撃に脆弱なため、必ずしもすべてのテナントが信頼できず、同じ信頼レ"" ""ベルを共有できないようなマルチテナント環境に適していません。"" msgid ""KVM Kernel Samepage Merging"" msgstr ""KVM Kernel Samepage Merging"" msgid """" ""Introduced into the Linux kernel in version 2.6.32, Kernel Samepage Merging "" ""(KSM) consolidates identical memory pages between Linux processes. As each "" ""guest VM under the KVM hypervisor runs in its own process, KSM can be used "" ""to optimize memory use between VMs."" msgstr """" ""Linux カーネル 2.6.32 に導入された、Kernel Samepage Merging (KSM) は複数の "" ""Linux プロセスの同一メモリページを集約します。KVM ハイパーバイザーにある各ゲ"" ""スト仮想マシンは、自身のプロセスで動作するので、KSM は仮想マシン間でメモリ使"" ""用量を最適化するために使用できます。"" msgid ""Security considerations for memory optimization"" msgstr ""メモリ最適化に関するセキュリティの課題"" ""If a cloud deployment requires strong separation of tenants, as is the "" ""situation with public clouds and some private clouds, deployers should "" ""consider disabling TPS and KSM memory optimizations.""""テナントを強く分離する必要があるクラウド環境の場合、つまりパブリッククラウド"" ""や特定のプライベートクラウドの場合、導入者は TPS や KSM メモリ最適化を無効化"" ""することを検討すべきです。"" msgid """" ""Another thing to look into when selecting a hypervisor platform is the "" ""availability of specific security features. In particular, we are referring "" ""to features like Xen Server's XSM or Xen Security Modules, sVirt, Intel TXT, "" ""and AppArmor. The presence of these features increase your security profile "" ""as well as provide a good foundation."" msgstr """" ""ハイパーバイザー選択時に検討すべき他の事項は、特定のセキュリティ機能の利用可"" ""否です。とくに、Xen Server の XSM (Xen Security Modules)、sVirt、Intel TXT、"" ""AppArmor のような機能を利用しています。これらの機能の存在は、セキュリティプロ"" ""ファイルを向上するだけでなく、良い基盤を提供します。"" msgid """" ""The following table calls out these features by common hypervisor platforms."" msgstr """" ""以下の表は一般的なハイパーバイザーにおけるこれらの機能の対応状況を示します。"" msgid ""XSM"" msgstr ""XSM"" msgid ""sVirt"" msgstr ""sVirt"" msgid ""TXT"" msgstr ""TXT"" msgid ""AppArmor"" msgstr ""AppArmor"" msgid ""cgroups"" msgstr ""cgroups"" msgid ""MAC Policy"" msgstr ""MAC ポリシー"" msgid ""KVM"" msgstr ""KVM"" msgid ""Xen"" msgstr ""Xen"" msgid ""ESXi"" msgstr ""ESXi"" msgid ""Hyper-V"" msgstr ""Hyper-V"" msgid """" ""MAC Policy: Mandatory Access Control; may be implemented with SELinux or "" ""other operating systems"" msgstr """" ""MAC ポリシー: 強制アクセス制御は SELinux または他のオペレーティングシステムを"" ""用いて実装されます"" msgid """" ""* Features in this table might not be applicable to all hypervisors or "" ""directly mappable between hypervisors."" msgstr """" ""* この表にある機能はすべてのハイパーバイザーに適用できないかもしれません。ま"" ""た、ハイパーバイザー間で直接対応付けできないかもしれません。"" msgid ""Deployment"" msgstr ""デプロイ"" msgid ""Orchestration"" msgstr ""オーケストレーション"" msgid ""Cloud administration"" msgstr ""クラウド管理"" msgid ""Self service"" msgstr ""セルフサービス"" msgid ""Data replication and recovery"" msgstr ""データの複製およびリカバリー"" msgid ""SLA and security monitoring"" msgstr ""SLA およびセキュリティの監視"" msgid """" ""To ease scaling and reduce management overhead Bob implements a "" ""configuration management system. For customer data assurances, Bob offers a "" ""backup as a service product as requirements will vary between customers. "" ""Finally, Bob does not provide a \""baremetal\"" or the ability to schedule an "" ""entire node, so to reduce management overhead and increase operational "" ""efficiency Bob does not implement any node boot time security."" msgstr """" ""管理オーバーヘッドのスケーリングや削減を簡単にするため、構成管理システムを実"" ""装します。顧客のデータ保証に対しては、顧客ごとに要件が変わるためサービス商品"" ""としてバックアップを提供します。最後に、「ベアメタル」やノード全体のスケ"" ""ジュール機能を提供せず、管理オーバーヘッドの削減、運用効率の向上を図るため、"" ""ノードのブート時におけるセキュリティは実装しません。"" msgid """" ""One of the virtues of running instances in a virtualized environment is that "" ""it opens up new opportunities for security controls that are not typically "" ""available when deploying onto bare metal. There are several technologies "" ""that can be applied to the virtualization stack that bring improved "" ""information assurance for cloud tenants."" msgstr """" ""仮想環境でインスタンスを運用する長所の一つは、ベアメタルで配備した際には利用"" ""できないセキュリティ管理方法の選択肢が増えることです。仮想スタック上のクラウ"" ""ドテナントの情報管理を改善する技術は多数存在します。"" msgid """" ""Deployers or users of OpenStack with strong security requirements may want "" ""to consider deploying these technologies. Not all are applicable in every "" ""situation, indeed in some cases technologies may be ruled out for use in a "" ""cloud because of prescriptive business requirements. Similarly some "" ""technologies inspect instance data such as run state which may be "" ""undesirable to the users of the system."" msgstr """" ""高いセキュリティ要件を持つOpenStackユーザーや配備者はこれらの技術の採用を検討"" ""すると良いかもしれませんが、状況によっては適用できない場合があります。クラウ"" ""ド運用においては、規範的なビジネス要件のために技術の選択肢が削られることがあ"" ""ります。また、run stateなど、仕組みによってはインスタンス内のデータを調べる機"" ""構もあり、システムのユーザーからは好まれないものもあります。"" msgid """" ""In this chapter we explore these technologies and describe the situations "" ""where they can be used to enhance security for instances or underlying "" ""instances. We also seek to highlight where privacy concerns may exist. These "" ""include data pass through, introspection, or providing a source of entropy. "" ""In this section we highlight the following additional security services:"" msgstr """" ""本章では、これらの仕組みの詳細とどのような状況においてインスタンスのセキュリ"" ""ティが向上されるかを説明します。また、プライバシー観点における懸念箇所にも焦"" ""点をあてます。データのパススルー、イントロスペクション、またエントロピー元の"" ""提供などが該当します。本セクションでは、下記のセキュリティサービスに焦点を当"" ""てます:"" msgid ""Entropy to instances"" msgstr ""インスタンスへのエントロピー"" msgid ""Scheduling instances to nodes"" msgstr ""ノードへのインスタンスのスケジューリング"" msgid ""Trusted images"" msgstr ""信頼されたイメージ"" msgid ""Instance migrations"" msgstr ""インスタンスのマイグレーション"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/untrusted_trusted.png'; md5=a582dac2ad0b3f439fd4b08386853056"" msgstr """" ""@@image: 'static/untrusted_trusted.png'; md5=a582dac2ad0b3f439fd4b08386853056"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/bridging_security_domains_1.png'; "" ""md5=0d5ca26c51882ce3253405e91a597715"" msgstr """" ""@@image: 'static/bridging_security_domains_1.png'; "" ""md5=0d5ca26c51882ce3253405e91a597715"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/bridging_domains_clouduser.png'; "" ""md5=17c8a233ee7de17d2f600c7f6f6afe24"" msgstr """" ""@@image: 'static/bridging_domains_clouduser.png'; "" ""md5=17c8a233ee7de17d2f600c7f6f6afe24"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/threat_actors.png'; md5=114c2f9bd9d0319bdd83f9e229d44649"" msgstr """" ""@@image: 'static/threat_actors.png'; md5=114c2f9bd9d0319bdd83f9e229d44649"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/high-capability.png'; md5=b7ab599c8b40558a52c0ca86aad89741"" msgstr """" ""@@image: 'static/high-capability.png'; md5=b7ab599c8b40558a52c0ca86aad89741"" msgid ""Security boundaries and threats"" msgstr ""セキュリティ境界と脅威"" msgid """" ""A cloud can be abstracted as a collection of logical components by virtue of "" ""their function, users, and shared security concerns, which we call security "" ""domains. Threat actors and vectors are classified based on their motivation "" ""and access to resources. Our goal is to provide you a sense of the security "" ""concerns with respect to each domain depending on your risk/vulnerability "" ""protection objectives."" msgstr """" ""クラウドとは、セキュリティドメインと呼ばれる、機能やユーザー、共有セキュリ"" ""ティの懸念点に基づいた論理コンポーネントの集まりであると要約できます。脅威に"" ""関するアクターやベクトルは、リソースへのアクセスや動機をベースに分類されま"" ""す。OpenStack の目標は、リスクや脆弱性保護の目的にあわせてドメインごとにセ"" ""キュリティの懸念点に関する判断材料を提供することです。"" msgid ""Security domains"" msgstr ""セキュリティドメイン"" msgid """" ""A security domain comprises users, applications, servers or networks that "" ""share common trust requirements and expectations within a system. Typically "" ""they have the same authentication and authorization (AuthN/Z) requirements "" ""and users."" msgstr """" ""セキュリティドメインは、システム内の信頼性に関する共通の要件や期待を共有する"" ""ユーザー、アプリケーション、サーバー、ネットワークのいずれかで構成されていま"" ""す。通常、これらのドメインには、同じ認証と承認 (AuthN/Z) 要件およびユーザー"" ""が指定されています。"" msgid """" ""Although you may desire to break these domains down further (we later "" ""discuss where this may be appropriate), we generally refer to four distinct "" ""security domains which form the bare minimum that is required to deploy any "" ""OpenStack cloud securely. These security domains are:"" msgstr """" ""これらのドメインをさらに分類する場合もありますが (該当箇所で説明)、一般的に "" ""OpenStack クラウドをセキュアにデプロイしていく上で最低限必要な部分を構成す"" ""る、4 つの異なるセキュリティドメインのことを指します。以下に、これらのセキュ"" ""リティドメインを示しています。"" msgid ""Public"" msgstr ""パブリック"" msgid ""Guest"" msgstr ""ゲスト"" msgid ""Data"" msgstr ""データ"" msgid """" ""The public security domain is an entirely untrusted area of the cloud "" ""infrastructure. It can refer to the Internet as a whole or simply to "" ""networks over which you have no authority. Any data that transits this "" ""domain with confidentiality or integrity requirements should be protected "" ""using compensating controls."" msgstr """" ""パブリックのセキュリティドメインとは、クラウドインフラストラクチャーの中で完"" ""全に信頼できないエリアのことです。インターネット全体を指す場合や、単に権限を"" ""持たないネットワークを指す場合があります。機密性や完全性の要件を持つデータが"" ""このドメインを通過する場合には、補完コントロールを使用してこのデータを保護す"" ""る必要があります。"" msgid ""This domain should always be considered <emphasis>untrusted</emphasis>."" msgstr """" ""このドメインは常に、<emphasis>信頼できない</emphasis>と考えなければなりませ"" ""ん。 "" msgid """" ""Typically used for compute instance-to-instance traffic, the guest security "" ""domain handles compute data generated by instances on the cloud but not "" ""services that support the operation of the cloud, such as API calls."" msgstr """" ""ゲストのセキュリティドメインは、Compute のインスタンス間通信に通常使用されま"" ""すが、API の呼び出しなどクラウドのオペレーションをサポートするサービスではな"" ""く、クラウド上のインスタンスが生成する Compute データを処理します。"" msgid """" ""The trust level of this network is heavily dependent on deployment decisions "" ""and as such we do not assign this any default level of trust."" msgstr """" ""このネットワークの信頼レベルは、デプロイメントの意思決定により左右されるた"" ""め、デフォルトの信頼レベルは割り当てていません。"" msgid ""Bridging security domains"" msgstr ""セキュリティドメインのブリッジ"" msgid """" ""A <emphasis>bridge</emphasis> is a component that exists inside more than "" ""one security domain. Any component that bridges security domains with "" ""different trust levels or authentication requirements must be carefully "" ""configured. These bridges are often the weak points in network architecture. "" ""A bridge should always be configured to meet the security requirements of "" ""the highest trust level of any of the domains it is bridging. In many cases "" ""the security controls for bridges should be a primary concern due to the "" ""likelihood of attack."" msgstr """" ""<emphasis>ブリッジ</emphasis>とは、複数のセキュリティドメイン内に存在するコン"" ""ポーネントです。異なる信頼レベルまたは認証要件が指定されたセキュリテイドメイ"" ""ン間をブリッジするコンポーネントは、慎重に設定する必要があります。ネットワー"" ""クアーキテクチャの中で、これらのブリッジは弱点となることが多くなっています。"" ""常に、ブリッジするドメインの中で最も高い信頼レベルのセキュリティ要件を満たす"" ""ように、ブリッジを設定するようにしてください。多くの場合、攻撃の可能性の高さ"" ""から、主にブリッジのセキュリティ制御について考慮する必要があります。"" msgid """" ""In some cases deployers may want to consider securing a bridge to a higher "" ""standard than any of the domains in which it resides. Given the above "" ""example of an API endpoint, an adversary could potentially target the API "" ""endpoint from the public domain, leveraging it in the hopes of compromising "" ""or gaining access to the management domain."" msgstr """" ""デプロイ担当者は、ブリッジするどのドメインよりも高い基準でブリッジのセキュリ"" ""ティを確保するように考えるようにしてください。API エンドポイントの上記の例で"" ""は、攻撃者はパブリックドメインから API エンドポイントをターゲットにして、情報"" ""漏洩や管理ドメインへアクセス権の獲得を期待しつつこのエンドポイントを利用する"" ""のです。"" msgid """" ""The design of OpenStack is such that separation of security domains is "" ""difficult - as core services will usually bridge at least two domains, "" ""special consideration must be given when applying security controls to them."" msgstr """" ""OpenStack のデザインではセキュリティドメインの分離が困難です。コアサービスは"" ""通常少なくとも 2 つのドメインをブリッジしているため、ドメインのセキュリティ制"" ""御を適用する場合、細心の注意を払う必要があります。"" msgid ""Threat classification, actors and attack vectors"" msgstr ""脅威の分類、アクター、攻撃ベクトル"" msgid """" ""Most types of cloud deployment, public or private, are exposed to some form "" ""of attack. In this chapter we categorize attackers and summarize potential "" ""types of attacks in each security domain."" msgstr """" ""クラウドデプロイメントの種類の多く (パブリックまたはプライベート) は、なんら"" ""かの攻撃にさらされています。本章では、攻撃者を分類して、各セキュリティドメイ"" ""ンで考えられる攻撃の種類をまとめていきます。"" msgid ""Threat actors"" msgstr ""脅威のアクター"" msgid """" ""A threat actor is an abstract way to refer to a class of adversary that you "" ""may attempt to defend against. The more capable the actor, the more "" ""expensive the security controls that are required for successful attack "" ""mitigation and prevention. Security is a tradeoff between cost, usability "" ""and defense. In some cases it will not be possible to secure a cloud "" ""deployment against all of the threat actors we describe here. Those "" ""deploying an OpenStack cloud will have to decide where the balance lies for "" ""their deployment / usage."" msgstr """" ""脅威のアクターとは、防御の対象となりえる攻撃者のクラスを抽象的に表したもので"" ""す。アクターの技術が高くなるにつれ、攻撃の軽減や防止を成功させるために必要な"" ""セキュリティ制御にかかるコストが嵩みます。セキュリティはコスト、使いやすさ、"" ""防御の間でのトレードオフということになります。ここで記載した脅威のアクターす"" ""べてから、クラウドのデプロイメントを保護することはできません。OpenStack クラ"" ""ウドをデプロイする方は、デプロイメントと用途の間でバランスが確保できるポイン"" ""トを決定する必要が出てきます。"" msgid """" ""<emphasis role=\""bold\"">Intelligence services</emphasis> — Considered by "" ""this guide as the most capable adversary. Intelligence Services and other "" ""state actors can bring tremendous resources to bear on a target. They have "" ""capabilities beyond that of any other actor. It is very difficult to defend "" ""against these actors without incredibly stringent controls in place, both "" ""human and technical."" msgstr """" ""<emphasis role=\""bold\"">インテリジェンスサービス</emphasis> — このガイドでは"" ""最も有能な攻撃者とされています。インテリジェンスサービスやその他の国家主体"" ""は、ターゲットに圧力をかけるために莫大なリソースを費やすことができます。他の"" ""どのアクターよりも能力があります。人や技術両方の面で非常に厳しい制御なしで"" ""は、これらのアクターから防御することは極めて困難です。"" msgid """" ""<emphasis role=\""bold\"">Highly capable groups</emphasis> — This refers to "" ""'Hacktivist' type organizations who are not typically commercially funded "" ""but can pose a serious threat to service providers and cloud operators."" msgstr """" ""<emphasis role=\""bold\"">非常に有能な組織</emphasis> — これは通常ビジネスから"" ""資金を調達しているのではありませんが、サービスプロバイダーやクラウドオペレー"" ""ターに対して重大な脅威をもたらす可能性のある「ハクティビスト」タイプの組織の"" ""ことを指します。"" msgid """" ""<emphasis role=\""bold\"">Motivated individuals</emphasis> — Acting alone, "" ""these attackers come in many guises, such as rogue or malicious employees, "" ""disaffected customers, or small-scale industrial espionage."" msgstr """" ""<emphasis role=\""bold\"">動機のある個人</emphasis> — 一人で行動するこれらの攻"" ""撃者は、詐欺師または悪意のある従業員、不満を持った顧客、小規模の産業スパイな"" ""ど多くのものに扮して攻撃します。"" msgid """" ""<emphasis role=\""bold\"">Script kiddies</emphasis> — Automated vulnerability "" ""scanning/exploitation. Non-targeted attacks. Often only a nuisance, "" ""compromise by one of these actors presents a major risk to an organization's "" ""reputation."" msgstr """" ""<emphasis role=\""bold\"">スクリプトキディ</emphasis> — 自動化された脆弱性のス"" ""キャンやエクスプロイト。非標的型の攻撃。単なるいたずらの場合が多く、上記のア"" ""クターのいずれかによる情報漏洩により組織の評判に大きなリスクを与えます。"" msgid ""Public and private cloud considerations"" msgstr ""パブリッククラウドとプライベートクラウドの考慮点"" msgid """" ""Private clouds are typically deployed by enterprises or institutions inside "" ""their networks and behind their firewalls. Enterprises will have strict "" ""policies on what data is allowed to exit their network and may even have "" ""different clouds for specific purposes. Users of a private cloud are "" ""typically employees of the organization that owns the cloud and are able to "" ""be held accountable for their actions. Employees often attend training "" ""sessions before accessing the cloud and will likely take part in regular "" ""scheduled security awareness training. Public clouds by contrast cannot make "" ""any assertions about their users, cloud use-cases or user motivations. This "" ""immediately pushes the guest security domain into a completely "" ""<emphasis>untrusted</emphasis> state for public cloud providers."" msgstr """" ""通常プライベートクラウドは企業や組織により、内部のネットワークやファイア"" ""ウォールの内側にデプロイされます。企業は、社内のネットワークから出すことので"" ""きるデータが何であるか、厳密な方針が設定されており、特定の目的ごとに別のクラ"" ""ウドを設定する場合さえもあります。プライベートクラウドのユーザーは通常、クラ"" ""ウドを所有して各自の行動に責任を課される組織内の従業員です。このような従業員"" ""は、クラウドにアクセスする前にトレーニングセッションに出席することもしばしば"" ""あり、定期的に予定されるセキュリティ認識トレーニングに参加する場合も多くあり"" ""ます。反対に、パブリッククラウドはユーザー、クラウドのユースケース、ユーザー"" ""の動機を断定することができません。このように、すぐにゲストのセキュリティドメ"" ""インは、パブリッククラウドプロバイダーにとっては完全に <emphasis>untrusted</"" ""emphasis> な状態となります。"" msgid """" ""A notable difference in the attack surface of public clouds is that they "" ""must provide internet access to their services. Instance connectivity, "" ""access to files over the internet and the ability to interact with the cloud "" ""controlling fabric such as the API endpoints and dashboard are must-haves "" ""for the public cloud."" msgstr """" ""パブリッククラウドの攻撃対象領域での顕著な相違点は、サービスに対してインター"" ""ネットアクセスを提供しなければならない点です。API エンドポイントやダッシュ"" ""ボードなど、インスタンスの接続性、インターネット経由でのファイルアクセス、ク"" ""ラウド制御のファブリックとの対話機能は、パブリッククラウドで必須アイテムなの"" ""です。"" msgid ""Outbound attacks and reputational risk"" msgstr ""アウトバウンド攻撃とレピュテーションリスク"" msgid ""Attack types"" msgstr ""攻撃の種類"" msgid """" ""The diagram shows the types of attacks that may be expected from the actors "" ""described in the previous section. Note that there will always be exceptions "" ""to this diagram but in general, this describes the sorts of attack that "" ""could be typical for each actor."" msgstr """" ""以下の図は、前項で説明したアクターから出される可能性のある攻撃の種類を記載し"" ""ています。このような図では常に例外が存在しますが、アクター毎に典型的であると"" ""考えられる攻撃の種類を一般論として記述しています。"" msgid """" ""The prescriptive defense for each form of attack is beyond the scope of this "" ""document. The above diagram can assist you in making an informed decision "" ""about which types of threats, and threat actors, should be protected "" ""against. For commercial public cloud deployments this might include "" ""prevention against serious crime. For those deploying private clouds for "" ""government use, more stringent protective mechanisms should be in place, "" ""including carefully protected facilities and supply chains. In contrast "" ""those standing up basic development or test environments will likely require "" ""less restrictive controls (middle of the spectrum)."" msgstr """" ""攻撃の形式ごとの規範的な防御については、本書の対象範囲外となっています。上記"" ""の図は、対策を行うべき脅威の種類、脅威のアクターについて詳細な情報を得た状態"" ""で意思決定ができるように支援します。商業的なパブリッククラウドのデプロイに関"" ""しては重大な犯罪の防止などが含まれる場合があります。 政府で使用するプライベー"" ""トクラウドをデプロイする方は、細心の注意を払って設置された対策施設やサプライ"" ""チェーンなど、より厳密な保護メカニズムを設置する必要があります。反対に、基本"" ""的なデプロイメントやテスト環境を設定する方は、制御に関する制約が少なくて済む"" ""でしょう。"" msgid ""Tokens"" msgstr ""トークン"" msgid ""Compliance"" msgstr ""コンプライアンス"" msgid ""This chapter has several objectives:"" msgstr ""この章の目的は以下の通りです。"" msgid ""Review common security principles."" msgstr ""共通のセキュリティ原則を確認する"" msgid """" ""Discuss common control frameworks and certification resources to achieve "" ""industry certifications or regulator attestations."" msgstr """" ""業界認定や監督当局の認証を得るために必要な、共通コントロールフレームワークと"" ""認定リソースを説明する"" msgid ""Act as a reference for auditors when evaluating OpenStack deployments."" msgstr ""監査人がOpenStack環境を評価する際のリファレンスとなる"" msgid """" ""Introduce privacy considerations specific to OpenStack and cloud "" ""environments."" msgstr ""OpenStackおよびクラウド環境におけるプライバシーの考慮事項を説明する"" msgid ""Policies"" msgstr ""ポリシー"" msgid """" ""Each OpenStack service has a policy file in JSON format, called "" ""<filename>policy.json</filename>. The policy file specifies rules, and the "" ""rule that governs each resource. A resource could be API access, the ability "" ""to attach to a volume, or to fire up instances."" msgstr """" ""各 OpenStack サービスは <filename>policy.json</filename> という JSON 形式のポ"" ""リシーファイルを持ちます。ポリシーファイルはルールを指定します。ルールは各リ"" ""ソースを決定します。リソースは API アクセスできます。ボリュームの接続やインス"" ""タンスの起動などです。"" msgid """" ""The policies can be updated by the cloud administrator to further control "" ""access to the various resources. The middleware could also be further "" ""customized. Note that your users must be assigned to groups/roles that you "" ""refer to in your policies."" msgstr """" ""さまざまなリソースへのアクセス権をさらに制御するために、クラウド管理者がポリ"" ""シーを更新できます。ミドルウェアによりさらにカスタマイズすることもできます。"" ""そのポリシーを参照しているグループやロールにユーザーを割り当てる必要があるこ"" ""とに注意してください。"" msgid """" ""Below is a snippet of the Block Storage service <filename>policy.json</"" ""filename> file."" msgstr """" ""以下は Block Storage Service の <filename>policy.json</filename> ファイルの抜"" ""粋です。"" msgid """" ""Note the <emphasis role=\""bold\"">default</emphasis> rule specifies that the "" ""user must be either an admin or the owner of the volume. It essentially says "" ""only the owner of a volume or the admin may create/delete/update volumes. "" ""Certain other operations such as managing volume types are accessible only "" ""to admin users."" msgstr """" ""<emphasis role=\""bold\"">デフォルト</emphasis>のルールは、ユーザーが管理者であ"" ""るか、ボリュームの所有者である必要があることを指定しています。つまり、ボ"" ""リュームの所有者と管理者のみがボリュームを作成、削除、更新できます。ボリュー"" ""ム形式の管理など、他の特定の操作は管理ユーザーのみがアクセス可能です。"" msgid """" ""Alice is building an OpenStack private cloud for the United States "" ""government, specifically to provide elastic compute environments for signal "" ""processing. Alice has researched government compliance requirements, and has "" ""identified that her private cloud will be required to certify against FISMA "" ""and follow the FedRAMP accreditation process, which is required for all "" ""federal agencies, departments and contractors to become a Certified Cloud "" ""Provider (CCP). In this particular scenario for signal processing, the FISMA "" ""controls required will most likely be FISMA High, which indicates possible "" ""\""severe or catastrophic adverse effects\"" should the information system "" ""become compromised. In addition to FISMA Moderate controls Alice must ensure "" ""her private cloud is FedRAMP certified, as this is a requirement for all "" ""agencies that currently utilize, or host federal information within a cloud "" ""environment."" msgstr """" ""アリスはOpenStackプライベートクラウドを米国政府向けに構築しています。具体的に"" ""は、信号処理向けの柔軟なコンピューティング環境です。アリスは政府向けコンプラ"" ""イアンス要件を調査した結果、これから構築しようとしているプライベートクラウド"" ""はFISMAおよびFedRAMP認定が必要であると判断しました。これは政府系機関、行政"" ""部、および契約者、どのような立場であっても、認定クラウドプロバイダー"" ""(Certified Cloud Provider, CCP)になるために必要な手続きです。特に信号処理は、"" ""FISMAはそれを\""深刻で壊滅的な影響\""をシステムに与えうるとしているため、FISMA"" ""影響度が\""高\""となりがちです。加えてFISMA Moderateレベルにおいて、アリスはそ"" ""のプライベートクラウドを確実にFedRAMP認証としなければいけません。これはクラウ"" ""ド内に政府の情報を保有する、全ての機関に求められてる条件です。"" msgid """" ""To meet these strict government regulations Alice undertakes a number of "" ""activities. Scoping of requirements is particularly important due to the "" ""volume of controls that must be implemented, which will be defined in NIST "" ""Publication 800-53."" msgstr """" ""これらの厳しい政府規制の要件を満たすため、アリスは多くの活動を行います。範囲"" ""の決定作業は、実装すべき統制の量に影響するため、特に重要です。これはNIST刊行 "" ""800-53で定められています。"" msgid """" ""If Alice has adequately scoped and executed these compliance activities, she "" ""may begin the process to become FedRAMP compliant by hiring an approved "" ""third-party auditor. Typically this process takes up to 6 months, after "" ""which she will receive an Authority to Operate and can offer OpenStack cloud "" ""services to the government."" msgstr """" ""もしアリスが十分な範囲を定義し、それらのコンプライアンス活動を実施できたので"" ""あれば、次は認定外部監査人によるFedRAMP認証の取得プロセスに移ります。一般的に"" ""このプロセスは最長6ヶ月を要します。このステップを経て、Authority to Operate "" ""- 注意影響レベル認定 を取得し、OpenStackクラウドサービスを政府に提案できるよ"" ""うになります。"" msgid """" ""Bob is tasked with compliance for a new OpenStack public cloud deployment, "" ""that is focused on providing cloud services to both small developers and "" ""startups, as well as large enterprises. Bob recognizes that individual "" ""developers are not necessarily concerned with compliance certifications, but "" ""to larger enterprises certifications are critical. Specifically Bob desires "" ""to achieve SOC 1, SOC 2 Security, as well as ISO 27001/2 as quickly as "" ""possible. Bob references the Cloud Security Alliance Cloud Control Matrix "" ""(CCM) to assist in identifying common controls across these three "" ""certifications (such as periodic access reviews, auditable logging and "" ""monitoring services, risk assessment activities, security reviews, etc). Bob "" ""then engages an experienced audit team to conduct a gap analysis on the "" ""public cloud deployment, reviews the results and fills any gaps identified. "" ""Bob works with other team members to ensure that these security controls and "" ""activities are regularly conducted for a typical audit period (~6-12 months)."" msgstr """" ""ボブは新たなOpenStackクラウド環境のコンプライアンス活動を任されています。この"" ""クラウドは小規模の開発者やスタートアップだけでなく、大規模企業向けにも注力し"" ""ています。ボブは個人開発者はコンプライアンス認証を意識することが多くないが、"" ""いっぽうで大規模企業向けには認証が重要であることを認識しています。ボブは特に"" ""SOC 1、SOC 2、およびISO 27001/2認証を早急に取得したいと考えています。そこでボ"" ""ブは3つの認証に共通する統制を特定するため、Cloud Security Alliance Cloud "" ""Control Matrix (CCM)を参考にしました (例えば、定期的なアクセス検査、監査可能"" ""なロギングや監視サービス、リスク評価活動、セキュリティレビューなど)。それから"" ""ボブは、パブリッククラウドのギャップ評価、結果のレビュー、そして特定された"" ""ギャップを埋めるため、経験ある監査人チームと契約します。ボブは他のチームメン"" ""バーとともに、それらのセキュリティ統制と活動が一般的な監査期間(〜6-12ヶ月)に"" ""おいて、定期的に、確実に機能するようにします。"" msgid """" ""At the end of the audit period Bob has arranged for an external audit team "" ""to review in-scope security controls at randomly sampled points of time over "" ""a 6 month period. The audit team provides Bob with an official report for "" ""SOC 1 and SOC 2, and separately for ISO 27001/2. As Bob has been diligent in "" ""ensuring security controls are in place for his OpenStack public cloud, "" ""there are no additional gaps exposed on the report. Bob can now provide "" ""these official reports to his customers under NDA, and advertise that he is "" ""SOC 1, SOC 2 and ISO 27001/2 compliant on his website."" msgstr """" ""監査期間の最後にボブは外部監査人チームとの調整を行います。目的は、6ヶ月以上に"" ""わたって無作為なタイミングで実施した、セキュリティ統制のレビューです。そし"" ""て、監査人チームはボブにSOC 1とSOC 2、また別途ISO 27001/2向けの公式な報告書を"" ""提供します。ボブのパブリッククラウド採用における勤勉な取り組みの結果、指摘さ"" ""れるような追加のギャップはありませんでした。ボブは正式な報告書を彼の顧客にNDA"" ""下で提供でき、また、SOC 1、SOC 2、およびISO 27001/2に準拠していることを彼の"" ""ウェブサイトでアピールできるようになりました。"" msgid ""Continuous systems management"" msgstr ""継続的なシステム管理"" msgid """" ""A cloud will always have bugs. Some of these will be security problems. For "" ""this reason, it is critically important to be prepared to apply security "" ""updates and general software updates. This involves smart use of "" ""configuration management tools, which are discussed below. This also "" ""involves knowing when an upgrade is necessary."" msgstr """" ""クラウドには必ずバグがあります。その中にはセキュリティの問題も含まれていま"" ""す。このような理由から、セキュリティ更新や一般的なソフトウェア更新の適用準備"" ""を行うことが極めて重要です。例えば、構成管理ツールを賢く利用していくことにな"" ""ります。これについては以下で説明しています。また、アップグレードが必要な時期"" ""を把握することも重要です。"" msgid """" ""OpenStack Security Advisories (OSSA) are created by the OpenStack "" ""Vulnerability Management Team (VMT). They pertain to security holes in core "" ""OpenStack services. More information on the VMT can be found here: <link "" ""href=\""https://wiki.openstack.org/wiki/Vulnerability_Management\"">https://"" ""wiki.openstack.org/wiki/Vulnerability_Management</link>"" msgstr """" ""OpenStack セキュリティアドバイザリ (OSSA: OpenStack Security Advisories) は、"" ""OpenStack 脆弱性管理チーム (VMT: Vulnerability Management Team) が作成してい"" ""ます。コアとなる OpenStack サービスのセキュリティホールに関連するものです。"" ""VMT に関する詳細情報は、<link href=\""https://wiki.openstack.org/wiki/"" ""Vulnerability_Management\"">https://wiki.openstack.org/wiki/"" ""Vulnerability_Management</link> を参照してください。"" msgid """" ""OpenStack releases security information through two channels. <placeholder-1/"" "">"" msgstr """" ""OpenStack は 2 つのチャネルからセキュリティ情報を発信しています。 "" ""<placeholder-1/>"" msgid ""Triage"" msgstr ""トリアージ"" msgid """" ""After you are notified of a security update, the next step is to determine "" ""how critical this update is to a given cloud deployment. In this case, it is "" ""useful to have a pre-defined policy. Existing vulnerability rating systems "" ""such as the common vulnerability scoring system (CVSS) v2 do not properly "" ""account for cloud deployments."" msgstr """" ""セキュリティ更新を通知された後、次のステップとして、指定のクラウドデプロイメ"" ""ントにとって、この更新がどの程度重要かを判断します。このような場合、ポリシー"" ""を事前定義しておくと便利です。共通脆弱性評価システム (CVSS) v2 などの既存の脆"" ""弱性評価システムは、クラウドデプロイメントに正しく対応していません。"" msgid """" ""In this example we introduce a scoring matrix that places vulnerabilities in "" ""three categories: Privilege Escalation, Denial of Service and Information "" ""Disclosure. Understanding the type of vulnerability and where it occurs in "" ""your infrastructure will enable you to make reasoned response decisions."" msgstr """" ""以下の例では、権限昇格、DoS (サービス妨害)、情報開示の 3 つのカテゴリーに脆弱"" ""性を分類した評価一覧表を紹介しています。脆弱性の種類やインフラストラクチャー"" ""内での発生箇所を理解することで、裏付けに基いた対応意思決定を下すことができま"" ""す。"" msgid """" ""Denial of Service refers to an exploited vulnerability that may cause "" ""service or system disruption. This includes both distributed attacks to "" ""overwhelm network resources, and single-user attacks that are typically "" ""caused through resource allocation bugs or input induced system failure "" ""flaws."" msgstr """" ""サービス妨害 (DoS) とは、サービスやシステムの中断を引き起こす脆弱性を悪用する"" ""ことを指します。これには、ネットワークリソースを大量に使用する分散型攻撃や、"" ""リソース割り当てのバグや誘導型でのシステム障害の問題などで一般的に引き起こさ"" ""れるシングルユーザー攻撃の両方が含まれます。"" msgid """" ""Information Disclosure vulnerabilities reveal information about your system "" ""or operations. These vulnerabilities range from debugging information "" ""disclosure, to exposure of critical security data, such as authentication "" ""credentials and passwords."" msgstr """" ""情報開示の脆弱性は、システムや操作の情報を公開します。これらの脆弱性は、情報"" ""開示のデバッグから認証情報やパスワードなどの重要なセキュリティデータの公開な"" ""どが当てはまります。"" msgid ""Attacker position / Privilege level"" msgstr ""攻撃者の位置付け/権限レベル"" msgid ""External"" msgstr ""外部"" msgid ""Cloud user"" msgstr ""クラウドユーザー"" msgid ""Cloud admin"" msgstr ""クラウドの管理者"" msgid ""Control plane"" msgstr ""制御プレーン"" msgid ""Privilege elevation (3 levels)"" msgstr ""権限昇格 (3 つのレベル)"" msgid ""Critical"" msgstr ""重要"" msgid ""n/a"" msgstr ""なし"" msgid ""Privilege elevation (2 levels)"" msgstr ""権限昇格 (2 つのレベル)"" msgid ""Privilege elevation (1 level)"" msgstr ""権限昇格 (1つのレベル)"" msgid ""Denial of service"" msgstr ""サービス妨害 (DoS)"" msgid ""High"" msgstr ""高"" msgid ""Medium"" msgstr ""中"" msgid ""Low"" msgstr ""低"" msgid ""Information disclosure"" msgstr ""情報開示"" msgid ""Critical / high"" msgstr ""重要/高"" msgid ""Medium / low"" msgstr ""中/低"" msgid """" ""This table illustrates a generic approach to measuring the impact of a "" ""vulnerability based on where it occurs in your deployment and the effect. "" ""For example, a single level privilege escalation on a Compute API node "" ""potentially allows a standard user of the API to escalate to have the same "" ""privileges as the root user on the node."" msgstr """" ""この表は、デプロイメントの発生箇所や影響をもとに脆弱性から受ける影響レベルを"" ""測定するための一般的な手法を示しています。例えば、Compute API ノードで権限レ"" ""ベルを 1 つ昇格すると、API の標準ユーザーはこのノード上の root ユーザーと同等"" ""の権限にまで昇格することが可能です。"" msgid ""Testing the updates"" msgstr ""更新のテスト""msgid ""Deploying the updates"" msgstr ""更新のデプロイ""""Once the updates are fully tested, they can be deployed to the production "" ""environment. This deployment should be fully automated using the "" ""configuration management tools described below.""""更新の完全なテストが終了すると、実稼働環境にデプロイすることができます。この"" ""デプロイメントは、以下に記載の構成管理ツールで完全に自動的に行われます。"" msgid ""Configuration management"" msgstr ""設定管理"" msgid """" ""A production quality cloud should always use tools to automate configuration "" ""and deployment. This eliminates human error, and allows the cloud to scale "" ""much more rapidly. Automation also helps with continuous integration and "" ""testing."" msgstr """" ""実稼働環境の品質を持つクラウドは設定とデプロイメントの自動化ツールを必ず使用"" ""しています。こうすることで、人的ミスをなくし、クラウドの迅速なスケールアウト"" ""が可能になります。自動化により、継続的な統合やテストが行いやすくなります。"" msgid """" ""When building an OpenStack cloud it is strongly recommended to approach your "" ""design and implementation with a configuration management tool or framework "" ""in mind. Configuration management allows you to avoid the many pitfalls "" ""inherent in building, managing, and maintaining an infrastructure as complex "" ""as OpenStack. By producing the manifests, cookbooks, or templates required "" ""for a configuration management utility, you are able to satisfy a number of "" ""documentation and regulatory reporting requirements. Further, configuration "" ""management can also function as part of your business continuity plan (BCP) "" ""and data recovery (DR) plans wherein you can rebuild a node or service back "" ""to a known state in a DR event or given a compromise."" msgstr """" ""OpenStack クラウドの構築時は、構成管理ツールまたはフレームワークを念頭に設"" ""計、実装に着手するように強く推奨します。構成管理により、OpenStack のように複"" ""雑なインフラストラクチャーの構築、管理、維持において陥りやすい多くの問題を回"" ""避することができます。構成管理ユーティリティに必要なマニフェスト、クックブッ"" ""ク、テンプレートを作成することで、多くの文書や監督機関へのレポート要件を満た"" ""すことができます。さらに、構成管理は、ビジネス継続性計画 (BCP) および災害復"" ""旧 (DR) プランの一部としても機能する可能性もあります。その場合、DR やセキュリ"" ""ティ侵害が合った場合にノードやサービスを既知の状態へ再構築することができま"" ""す。"" msgid """" ""Additionally, when combined with a version control system such as Git or "" ""SVN, you can track changes to your environment over time and re-mediate "" ""unauthorized changes that may occur. For example, a <filename>nova.conf</"" ""filename> file or other configuration file falls out of compliance with your "" ""standard, your configuration management tool can revert or replace the file "" ""and bring your configuration back into a known state. Finally a "" ""configuration management tool can also be used to deploy updates; "" ""simplifying the security patch process. These tools have a broad range of "" ""capabilities that are useful in this space. The key point for securing your "" ""cloud is to choose a tool for configuration management and use it."" msgstr """" ""さらに、Git や SVN などのバージョン管理システムと統合すると、経年の環境の変化"" ""をチェックして、発生する可能性のある未認証の変更を修正することができます。例"" ""えば、<filename>nova.conf</filename> ファイルやその他の設定ファイルが規格に準"" ""拠しなくなった場合、既知の状態に構成管理ツールはファイルを復元または置き換え"" ""ることができるでしょう。最後に、構成管理ツールを使用して、更新のデプロイも可"" ""能で、セキュリティパッチのプロセスを簡素化します。これらのツールには、この項"" ""において便利な機能が幅広く含まれています。クラウドのセキュリティ確保の主な目"" ""的は、構成管理のツールを選択して使用することです。"" msgid """" ""There are many configuration management solutions; at the time of this "" ""writing there are two in the marketplace that are robust in their support of "" ""OpenStack environments: <glossterm>Chef</glossterm> and <glossterm>Puppet</"" ""glossterm>. A non-exhaustive listing of tools in this space is provided "" ""below:"" msgstr """" ""構成管理ソリューションは多数存在しますが、本書の作成時点で市場にあるソリュー"" ""ションで OpenStack 環境のサポートが強力なものは <glossterm>Chef</glossterm> "" ""と <glossterm>Puppet</glossterm> の 2 種類となっています。以下に完全ではあり"" ""ませんが、ツールのリストを示しています。"" msgid ""Chef"" msgstr ""Chef"" msgid ""Puppet"" msgstr ""Puppet"" msgid ""Salt Stack"" msgstr ""Salt Stack"" msgid ""Ansible"" msgstr ""Ansible"" msgid ""Policy changes"" msgstr ""ポリシーの変更"" msgid ""Secure backup and recovery"" msgstr ""セキュアなバックアップとリカバリ"" msgid """" ""It is important to include Backup procedures and policies in the overall "" ""System Security Plan. For a good overview of OpenStack's Backup and Recovery "" ""capabilities and procedures, please refer to the OpenStack Operations Guide."" msgstr """" ""全体的なシステムセキュリティプランにバックアップ手順とポリシーを含めることは"" ""重要です。OpenStack のバックアップ／リカバリー機能や手順についての適切な概要"" ""は、OpenStack 運用ガイドを参照してください。"" msgid """" ""Ensure only authenticated users and backup clients have access to the backup "" ""server."" msgstr """" ""認証済みのユーザーおよびバックアップクライアントのみがバックアップサーバーに"" ""アクセスできるようにすること"" msgid ""Use data encryption options for storage and transmission of backups."" msgstr ""バックアップの保存や送信にはデータ暗号化オプションを使用すること"" msgid """" ""Use a dedicated and hardened backup servers. The logs for the backup server "" ""must be monitored daily and accessible by only few individuals."" msgstr """" ""セキュリティが強化された専用のバックアップサーバーを使用すること。バックアッ"" ""プサーバーのログは日次で監査し、ほんの一握りの人だけがこのログにアクセスでき"" ""るようにしなければいけません。"" msgid """" ""Test data recovery options regularly. One of the things that can be restored "" ""from secured backups is the images. In case of a compromise, the best "" ""practice would be to terminate running instances immediately and then "" ""relaunch the instances from the images in the secured backup repository."" msgstr """" ""データのリカバリーオプションを定期的にテストすること。セキュアなバックアップ"" ""からリストアが可能なものの 1 つにイメージがあります。情報漏洩などが発生した場"" ""合のベストプラクティスは、すぐに実行中のインスタンスを終了して、セキュアな"" ""バックアップリポジトリにあるイメージからインスタンスを再起動することです。"" msgid ""References"" msgstr ""参考資料"" msgid """" ""<citetitle>OpenStack Operations Guide</citetitle> on <link href=\""http://"" ""docs.openstack.org/openstack-ops/content/backup_and_recovery.html\"">backup "" ""and recovery</link>"" msgstr """" ""<citetitle>OpenStack 運用ガイド</citetitle> の <link href=\""http://docs."" ""openstack.org/openstack-ops/content/backup_and_recovery.html\"">バックアップと"" ""リカバリー</link>""msgid ""Security auditing tools"" msgstr ""セキュリティ監査ツール"" msgid """" ""Security auditing tools can complement the configuration management tools. "" ""Security auditing tools automate the process of verifying that a large "" ""number of security controls are satisfied for a given system configuration. "" ""These tools help to bridge the gap from security configuration guidance "" ""documentation (for example, the STIG and NSA Guides) to a specific system "" ""installation. For example, <link href=\""https://fedorahosted.org/scap-"" ""security-guide/\"">SCAP</link> can compare a running system to a pre-defined "" ""profile. SCAP outputs a report detailing which controls in the profile were "" ""satisfied, which ones failed, and which ones were not checked."" msgstr """" ""セキュリティ監査ツールは、構成管理ツールを補完することができます。セキュリ"" ""ティ監査ツールは、セキュリティ制御の多くが指定のシステム設定を満たしているこ"" ""とを確認するプロセスを自動化します。これらのツールは、セキュリティ設定方針文"" ""書 (例: STIG および NSA ガイド) から個別のシステムインストール環境のギャップ"" ""を埋めるサポートをします。例えば、<link href=\""https://fedorahosted.org/scap-"" ""security-guide/\"">SCAP</link> は実行中のシステムと事前定義済みのプロファイル"" ""を比較することができます。SCAP はプロファイル内のどの制御に対応しているか、問"" ""題があるものはどれか、確認されていないものはどれかを詳細にまとめたレポートを"" ""出力します。"" msgid """" ""Combining configuration management and security auditing tools creates a "" ""powerful combination. The auditing tools will highlight deployment concerns. "" ""And the configuration management tools simplify the process of changing each "" ""system to address the audit concerns. Used together in this fashion, these "" ""tools help to maintain a cloud that satisfies security requirements ranging "" ""from basic hardening to compliance validation."" msgstr """" ""構成管理とセキュリティ監査ツールを組み合わせることで強力になります。監査ツー"" ""ルはデプロイメントの課題をハイライトし、構成管理ツールは各システムの変更プロ"" ""セスを簡素化して監査の課題に対応していきます。このような方法で組み合わせて使"" ""用することで、これらのツールは、基本的なセキュリティの強化からコンプライアン"" ""スのバリデーションに至るまで、このようなセキュリティ要件を満たすクラウドを維"" ""持できるようにします。"" msgid """" ""Configuration management and security auditing tools will introduce another "" ""layer of complexity into the cloud. This complexity brings additional "" ""security concerns with it. We view this as an acceptable risk trade-off, "" ""given their security benefits. Securing the operational use of these tools "" ""is beyond the scope of this guide."" msgstr """" ""構成管理およびセキュリティ監査ツールは、もう１つのレベルで複雑性をクラウドに"" ""もたらします。この複雑性により、新たなセキュリティの課題が出てきます。これに"" ""ついては、セキュリティの利点もあるため、許容範囲のリスクのトレードオフという"" ""見解を持っています。これらのツールの運用におけるセキュリティ確保については、"" ""本書の対象外となっています。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/sdn-connections.png'; md5=1de9169834b34c83f574f2a1225b27f0"" msgstr """" ""@@image: 'static/sdn-connections.png'; md5=1de9169834b34c83f574f2a1225b27f0"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/1aa-network-domains-diagram.png'; "" ""md5=135806775939d9e5e750264d8a5fe8de"" msgstr """" ""@@image: 'static/1aa-network-domains-diagram.png'; "" ""md5=135806775939d9e5e750264d8a5fe8de"" msgid ""Networking architecture"" msgstr ""Networking アーキテクチャ"" msgid """" ""OpenStack Networking is a standalone service that often deploys several "" ""processes across a number of nodes. These processes interact with each other "" ""and other OpenStack services. The main process of the OpenStack Networking "" ""service is <systemitem class=\""service\"">neutron-server</systemitem>, a "" ""Python daemon that exposes the OpenStack Networking API and passes tenant "" ""requests to a suite of plug-ins for additional processing."" msgstr """" ""OpenStack Networking は多数ノード間において幾つかのプロセスのデプロイにしばし"" ""ば含まれる独立サービスです。OpenStack Networking サービスのメインプロセスは "" ""<systemitem class=\""service\"">neutron-server</systemitem> で、これは "" ""OpenStack Networking API を提供し、追加処理用の適切なプラグインにテナントのリ"" ""クエストを渡します。"" msgid ""The OpenStack Networking components are:"" msgstr ""OpenStack Networking のコンポーネントは以下のとおりです。""msgid """" ""This service runs on the network node to service the Networking API and its "" ""extensions. It also enforces the network model and IP addressing of each "" ""port. The neutron-server and plugin agents require access to a database for "" ""persistent storage and access to a message queue for inter-communication."" msgstr """" ""このサービスはネットワークノード上で実行され、Networking API とその拡張を提供"" ""します。これはまた、各ポートのネットワークモデルと IP アドレスを管理します。"" ""neutron-server とプラグインエージェントは、永続ストレージ用のデータベースへの"" ""アクセスと、内部通信用のメッセージキューへのアクセスを要求します。""msgid """" ""DHCP agent (<systemitem class=\""service\"">neutron-dhcp-agent</systemitem>)"" msgstr """" ""DHCP エージェント (<systemitem class=\""service\"">neutron-dhcp-agent</"" ""systemitem>)"" msgid """" ""Provides DHCP services to tenant networks. This agent is the same across all "" ""plug-ins and is responsible for maintaining DHCP configuration. The "" ""<systemitem class=\""service\"">neutron-dhcp-agent</systemitem> requires "" ""message queue access."" msgstr """" ""テナントネットワークに DHCP サービスを提供します。このエージェントは全てのプ"" ""ラグインと同様で、DHCP 設定の管理を担当します。<systemitem class=\""service"" ""\"">neutron-dhcp-agent</systemitem> はメッセージキューアクセスが必要です。"" msgid ""L3 agent (<systemitem class=\""service\"">neutron-l3-agent</systemitem>)"" msgstr """" ""L3 エージェント (<systemitem class=\""service\"">neutron-l3-agent</systemitem>)"" msgid """" ""Provides L3/NAT forwarding for external network access of VMs on tenant "" ""networks. Requires message queue access. <emphasis>Optional depending on "" ""plug-in.</emphasis>"" msgstr """" ""テナントネットワーク上の VM において外部ネットワーク用 L3/NAT 転送を提供しま"" ""す。メッセージキューが必要です。<emphasis>プラグイン次第では別の物が必要にな"" ""ります。</emphasis>"" msgid ""network provider services (SDN server/services)"" msgstr ""ネットワークプロバイダーサービス (SDN サーバー/サービス)"" msgid """" ""The following figure shows an architectural and networking flow diagram of "" ""the OpenStack Networking components:"" msgstr """" ""以下の図は OpenStack Networking コンポーネント群の構造・ネットワークフローダ"" ""イアグラムを示しています。"" msgid ""OpenStack Networking service placement on physical servers"" msgstr ""OpenStack Networking の配置と物理サービス"" msgid """" ""This guide focuses on a standard architecture that includes a "" ""<emphasis>cloud controller</emphasis> host, a <emphasis>network</emphasis> "" ""host, and a set of <emphasis>compute</emphasis> hypervisors for running VMs."" msgstr """" ""このガイドは、<emphasis>クラウドコントローラ</emphasis>ホスト１台、<emphasis>"" ""ネットワーク</emphasis>ホスト１台、VMを実行する<emphasis>compute</emphasis>ハ"" ""イパーバイザーの集合を含む標準的なアーキテクチャにフォーカスします。"" msgid ""Network connectivity of physical servers"" msgstr ""物理サーバのネットワーク接続性"" msgid """" ""A standard OpenStack Networking setup has up to four distinct physical data "" ""center networks:"" msgstr """" ""標準的な OpenStack Networking セットアップは最大４つの物理データセンターネッ"" ""トワークがあります。"" msgid ""Management network"" msgstr ""管理ネットワーク"" msgid """" ""Used for internal communication between OpenStack Components. The IP "" ""addresses on this network should be reachable only within the data center "" ""and is considered the Management Security Domain."" msgstr """" ""OpenStack コンポーネント間の内部通信に使用されます。このネットワークの IP ア"" ""ドレスはデータセンター内でのみ到達可能であるべきです。管理セキュリティドメイ"" ""ンで検討します。"" msgid ""Guest network"" msgstr ""ゲストネットワーク"" msgid """" ""Used for VM data communication within the cloud deployment. The IP "" ""addressing requirements of this network depend on the OpenStack Networking "" ""plug-in in use and the network configuration choices of the virtual networks "" ""made by the tenant. This network is considered the Guest Security Domain."" msgstr """" ""クラウドデプロイ中の VM データ通信に使用されます。このネットワークの IP アド"" ""レス要件は、使用中の OpenStack Networking プラグインとテナントにより作成され"" ""る仮想ネットワークのネットワーク設定の選定に依存します。このネットワークはゲ"" ""ストセキュリティドメインで検討します。"" msgid ""External network"" msgstr ""外部ネットワーク"" msgid ""API network"" msgstr ""API ネットワーク"" msgid """" ""Exposes all OpenStack APIs, including the OpenStack Networking API, to "" ""tenants. The IP addresses on this network should be reachable by anyone on "" ""the Internet. This may be the same network as the external network, as it is "" ""possible to create a subnet for the external network that uses IP allocation "" ""ranges to use only less than the full range of IP addresses in an IP block. "" ""This network is considered the Public Security Domain."" msgstr """" ""テナントに OpenStack Networking API を含む全 OpenStack API を晒します。この"" ""ネットワーク上の IP アドレスはインターネット上の誰もがアクセス可能であるべき"" ""です。これは外部ネットワークと同じネットワークであっても構いません。外部ネッ"" ""トワーク用に、IP ブロック中の全 IP アドレス範囲より少ない部分を使う為の IP 割"" ""当範囲を使用するサブネットを作成する事が出来るからです。このネットワークはパ"" ""ブロックセキュリティドメインで検討します。"" msgid """" ""For additional information see the <link href=\""http://docs.openstack.org/"" ""admin-guide-cloud/content/ch_networking.html\"">Networking chapter</link> in "" ""the <citetitle>OpenStack Cloud Administrator Guide</citetitle>."" msgstr """" ""更なる情報は、<citetitle>OpenStack Cloud Administrator Guide</citetitle> 中"" ""の <link href=\""http://docs.openstack.org/admin-guide-cloud/content/"" ""ch_networking.html\"">Networking</link> の章を参照して下さい。"" msgid ""Security groups"" msgstr ""セキュリティグループ"" msgid ""Logging"" msgstr ""ロギング"" msgid """" ""For instance scheduling, Alice uses the trusted compute pools to ensure that "" ""all cloud workloads are deployed to nodes that presented a proper boot time "" ""attestation. Alice decides to disable user permissions for image uploading "" ""to help ensure that the images used in the cloud are generated in a known "" ""and trusted manner by the cloud administrators."" msgstr """" ""インスタンススケジューリングでは、全てのクラウド負荷が適切な起動時間保証を示"" ""すノードにデプロイされるようにする為、アリスは信頼できる compute プールを使用"" ""します。クラウド中で使用されるイメージがクラウド管理者に既知で信頼できる方法"" ""で作成されたものである事を保証するため、アリスはユーザにイメージをアップロー"" ""ドする権限を与えない事を決めました。"" msgid """" ""Finally, Alice disables instance migrations as this feature is less critical "" ""for the high performance application workloads expected to run in this "" ""cloud. This helps avoid the various security concerns related to instance "" ""migrations."" msgstr """" ""最後に、アリスはインスタンスのマイグレーションを無効化しました。この機能はこ"" ""のクラウドで実行される予定の高パフォーマンスアプリケーション負荷にはほとんど"" ""不要だからです。これにより、インスタンスマイグレーションにまつわる様々なセ"" ""キュリティ関連を避ける事ができます。"" msgid """" ""Bob is aware that entropy will be a concern for some of his customers, such "" ""as those in the financial industry. However, due to the added cost and "" ""complexity, Bob has decided to forgo integrating hardware entropy into the "" ""first iteration of his cloud. He adds hardware entropy as a fast-follow to "" ""do for a later improvement for the second generation of his cloud "" ""architecture."" msgstr """" ""ボブは、金融業界の企業ユーザの幾つかにとってエントロピーが重要となる事を理解"" ""しています。しかしながら、費用と複雑さが増える為、ボブは彼のクラウドの初回導"" ""入分にハードウェアエントロピーの導入を見送る事を決めました。彼は自分の２世代"" ""目のクラウドアーキテクチャに向けた後の改善では、早期のフォローとしてハード"" ""ウェアエントロピーを追加します。"" msgid ""Architecture"" msgstr ""アーキテクチャー"" msgid ""Hadoop"" msgstr ""Hadoop"" msgid ""Spark"" msgstr ""Spark"" msgid ""Hive"" msgstr ""Hive"" msgid ""Pig"" msgstr ""Pig"" msgid ""Privacy"" msgstr ""プライバシー"" msgid """" ""Privacy is an increasingly important element of a compliance program. "" ""Businesses are being held to a higher standard by their customers, who have "" ""increased interest in understanding how their data is treated from a privacy "" ""perspective."" msgstr """" ""プライバシーはコンプライアンスプログラムの重要な要素になりつつあります。顧客"" ""はプライバシーの観点から、データがいかに扱われているか関心を高めており、デー"" ""タを扱う企業はより高い基準を期待されています。"" msgid """" ""An OpenStack deployment will likely need to demonstrate compliance with an "" ""organization's Privacy Policy, with the U.S.-E.U. Safe Harbor framework, the "" ""ISO/IEC 29100:2011 privacy framework or with other privacy-specific "" ""guidelines. In the U.S. the AICPA has <link href=\""http://www.aicpa.org/"" ""interestareas/informationtechnology/resources/privacy/"" ""generallyacceptedprivacyprinciples/\"">defined 10 privacy areas of focus</"" ""link>, OpenStack deployments within a commercial environment may desire to "" ""attest to some or all of these principles."" msgstr """" ""OpenStack環境では、組織のプライバシーポリシー、米国 - EU間のセーフハーバーフ"" ""レームワーク、ISO/IEC 29100:2011 プライバシーフレームワークなど、プライバシー"" ""特化ガイドライン遵守の証明を求められることが多いです。米国ではAICPAが<link "" ""href=\""http://www.aicpa.org/interestareas/informationtechnology/resources/"" ""privacy/generallyacceptedprivacyprinciples/\"">重視すべき10のプライバシー項目"" ""</link>を公表しており、ビジネス用途のOpenStack環境はそのうちのいくつか、もし"" ""くは全原則の立証を期待されます。"" msgid """" ""To aid OpenStack architects in the protection of personal data, it is "" ""recommended that OpenStack architects review the NIST publication 800-122, "" ""titled \""<emphasis>Guide to Protecting the Confidentiality of Personally "" ""Identifiable Information (PII)</emphasis>.\"" This guide steps through the "" ""process of protecting:"" msgstr """" ""個人情報の保護に取り組むOpenStackアーキテクトを支援するため、OpenStackアーキ"" ""テクトには、NIST刊行 800-122 \""<emphasis>Guide to Protecting the "" ""Confidentiality of Personally Identifiable Information (PII)</emphasis>.をお"" ""すすめします。このガイドは以下を保護するプロセスについて述べています。"" msgid """" ""\""<emphasis>any information about an individual maintained by an agency, "" ""including (1) any information that can be used to distinguish or trace an "" ""individual's identity, such as name, social security number, date and place "" ""of birth, mother's maiden name, or biometric records; and (2) any other "" ""information that is linked or linkable to an individual, such as medical, "" ""educational, financial, and employment information</emphasis>\"""" msgstr """" ""\""<emphasis>政府機関が保有するあらゆる個人情報、(1)個人を特定、追跡しうるあら"" ""ゆる情報、たとえば氏名、社会保障番号、出生年月日、出生地、母の旧姓、生体情報"" ""など。および、(2)個人に結びつく、結びつけられるあらゆる情報、たとえば医療、教"" ""育、金融、雇用情報など</emphasis>\"""" msgid """" ""Comprehensive privacy management requires significant preparation, thought "" ""and investment. Additional complications are introduced when building global "" ""OpenStack clouds, for example navigating the differences between U.S. and "" ""more restrictive E.U. privacy laws. In addition, extra care needs to be "" ""taken when dealing with sensitive PII that may include information such as "" ""credit card numbers or medical records. This sensitive data is not only "" ""subject to privacy laws but also regulatory and governmental regulations. By "" ""deferring to established best practices, including those published by "" ""governments, a holistic privacy management policy may be created and "" ""practiced for OpenStack deployments."" msgstr """" ""包括的なプライバシー管理には、十分な準備、考慮と投資が必要です。また、グロー"" ""バルなOpenStackクラウドの構築時には、さらなる複雑さに気づくでしょう。米国およ"" ""び、それより厳しいEUのプライバシー法令の違いが良い例です。加えて、クレジット"" ""カード番号や医療情報など、機密性の高い個人情報を扱う場合にはさらなる注意が必"" ""要です。これら機密性の高い情報はプライバシー法令だけでなく、監視当局や政府規"" ""制にも関連します。政府によって発行されたものなど、ベストプラクティスに従うこ"" ""とで、OpenStack環境向けの総合的なプライバシー管理ポリシーが確立、実践されてい"" ""くでしょう。"" msgid ""Authentication"" msgstr ""認証"" msgid ""Invalid login attempts"" msgstr ""無効なログイン試行"" msgid """" ""Prevention is possible by using an external authentication system that "" ""blocks out an account after some configured number of failed login attempts. "" ""The account then may only be unlocked with further side-channel intervention."" msgstr """" ""ログイン試行を指定した回数だけ失敗すると、アカウントをブロックするような外部"" ""認証システムを使用することにより、防止することができます。アカウントは、別の"" ""連絡手段を介してのみ、ロック解除するようにできます。"" msgid ""Multi-factor authentication"" msgstr ""多要素認証"" msgid """" ""This recommendation provides insulation from brute force, social "" ""engineering, and both spear and mass phishing attacks that may compromise "" ""administrator passwords."" msgstr """" ""このお勧めの方式は、管理者パスワードを流出させる可能性のある、総当たり、ソー"" ""シャルエンジニアリング、標的型と無差別のフィッシング攻撃に対する防御になりま"" ""す。"" msgid """" ""OpenStack Networking enables the end-user or tenant to define, utilize, and "" ""consume networking resources. OpenStack Networking provides a tenant-facing "" ""API for defining network connectivity and IP addressing for instances in the "" ""cloud in addition to orchestrating the network configuration. With the "" ""transition to an API-centric networking service, cloud architects and "" ""administrators should take into consideration best practices to secure "" ""physical and virtual network infrastructure and services."" msgstr """" ""OpenStack Networking により、エンドユーザーまたはテナントは、ネットワークリ"" ""ソースを定義、利用、消費することが可能です。OpenStack Networking は、ネット"" ""ワーク設定のオーケストレーションに加えて、クラウド内のインスタンスを対象とし"" ""たネットワーク接続の定義と IP アドレス指定用の対テナント API を提供します。"" ""API 中心のネットワークサービスへの移行にあたっては、クラウドのアーキテクトや"" ""管理者が、物理/仮想ネットワークのインフラストラクチャーとサービスをセキュリ"" ""ティ保護するためのベストプラクティスを考慮すべきです。"" msgid """" ""OpenStack Networking was designed with a plug-in architecture that provides "" ""extensibility of the API through open source community or third-party "" ""services. As you evaluate your architectural design requirements, it is "" ""important to determine what features are available in OpenStack Networking "" ""core services, any additional services that are provided by third-party "" ""products, and what supplemental services are required to be implemented in "" ""the physical infrastructure."" msgstr """" ""OpenStack Networking は、オープンソースコミュニティやサードパーティーのサービ"" ""スによる API の拡張性を提供するプラグインアーキテクチャーで設計されました。"" ""アーキテクチャーの設計要件を評価するにあたっては、OpenStack Networking のコア"" ""サービスではどのような機能が提供されているか、サードパーティの製品によって提"" ""供される追加のサービスがあるかどうか、物理インフラストラクチャーにはどのよう"" ""な補足サービスを実装する必要があるかを判断することが重要です。"" msgid """" ""This section is a high-level overview of what processes and best practices "" ""should be considered when implementing OpenStack Networking. We will talk "" ""about the current state of services that are available, what future services "" ""will be implemented, and the current limitations in this project."" msgstr """" ""本項には、OpenStack Networking を実装する際に検討すべきプロセスとベストプラク"" ""ティスについての大まかな概要をまとめています。提供されているサービスの現在の"" ""状況 、将来実装されるサービス、本プロジェクトにおける現在の制限事項などについ"" ""て説明します。"" msgid """" ""A major business driver for Bob is to provide an advanced networking "" ""services to his customers. Bob's customers would like to deploy multi-tiered "" ""application stacks. This multi-tiered application are either existing "" ""enterprise application or newly deployed applications. Since Bob's public "" ""cloud is a multi-tenancy enterprise service, the choice to use for L2 "" ""isolation in this environment is to use overlay networking. Another aspect "" ""of Bob's cloud is the self-service aspect where the customer can provision "" ""available networking services as needed. These networking services encompass "" ""L2 networks, L3 Routing, Network <glossterm>ACL</glossterm> and NAT. It is "" ""important that per-tenant quota's be implemented in this environment."" msgstr """" ""ボブの主要なビジネス目的は彼の顧客に先進的なネットワークサービスを提供する事"" ""です。ボブの顧客はマルチタイアのアプリケーションスタックをデプロイしようとし"" ""ています。マルチタイアのアプリケーションは、既存の商用アプリケーションや新し"" ""くデプロイされるアプリケーションのいずれかです。ボブのパブリッククラウドはマ"" ""ルチテナントの商用サービスである為、この環境の L2 アイソレーションに使用する"" ""選択肢は、オーバレイネットワークです。ボブのクラウドの他の側面は、必要に応じ"" ""て顧客が利用可能なネットワークサービスをプロビジョンできるセルフサービス指向"" ""です。これらのネットワークサービスは、L2 ネットワーク、L3 ルーティング、ネッ"" ""トワーク<glossterm>ACL</glossterm>、NAT を含みます。\n"" ""\n"" ""It is important that per-tenant quota's be implemented in this environment."" msgid """" ""An added benefit with utilizing OpenStack Networking is when new advanced "" ""networking services become available, these new features can be easily "" ""provided to the end customers."" msgstr """" ""OpenStack Networking 利用の追加的な利点は、新しい先進的なネットワークサービス"" ""が利用可能になった場合、これらの新しい機能をエンドユーザに簡単に提供できる事"" ""です。"" msgid ""Networking services security best practices"" msgstr ""Networking サービス セキュリティベストプラクティス"" msgid """" ""This section discusses OpenStack Networking configuration best practices as "" ""they apply to tenant network security within your OpenStack deployment."" msgstr """" ""この章では、あなたの OpenStack デプロイの中でテナントネットワークセキュリティ"" ""を適用する為に、OpenStack Networking の設定のベストプラクティスについて議論し"" ""ます。"" msgid ""Tenant network services workflow"" msgstr ""テナントネットワークサービスのワークフロー"" msgid ""Networking resource policy engine"" msgstr ""Networking リソースポリシーエンジン"" msgid """" ""It is important to review the default networking resource policy and modify "" ""the policy appropriately for your security posture."" msgstr """" ""デフォルトの Networking リソースポリシーをレビューする事と、あなたのセキュリ"" ""ティ姿勢に向けてポリシーを適切に修正する事は重要です。"" msgid """" ""If your deployment of OpenStack provides multiple external access points "" ""into different security domains it is important that you limit the tenant's "" ""ability to attach multiple vNICs to multiple external access pointsthis "" ""would bridge these security domains and could lead to unforeseen security "" ""compromise. It is possible mitigate this risk by utilizing the host "" ""aggregates functionality provided by OpenStack Compute or through splitting "" ""the tenant VMs into multiple tenant projects with different virtual network "" ""configurations."" msgstr """" ""あなたの OpenStack のデプロイが異なるセキュリティドメインに向けて複数の外部ア"" ""クセスポイントを提供する場合、複数の外部アクセスポイントへ複数の仮想NICをア"" ""タッチするテナントの機能を制限する事は重要です。これは、これらのセキュリティ"" ""ドメインのブリッジになり、思いがけないセキュリティの妥協を導くかも知れませ"" ""ん。OpenStack Compute が提供するホストアグリゲート機能の活用や、異なる仮想"" ""ネットワーク設定を持つ複数のテナントプロジェクトにテナントVMを分割する事で、"" ""リスクを緩和する事が可能です。"" msgid """" ""When using the security group API through OpenStack Compute, security groups "" ""are applied to all virtual interface ports on an instance. The reason for "" ""this is that OpenStack Compute security group APIs are instance based and "" ""not virtual interface port based as OpenStack Networking."" msgstr """" ""OpenStack Compute のセキュリティグループ API を使用する場合、セキュリティグ"" ""ループは１インスタンス上の全仮想インターフェースポートに適用されます。この理"" ""由は、OpenStack Compute のセキュリティグループ API がインスタンスベースであ"" ""り、OpenStack Networking のような仮想インターフェースポートベースではないから"" ""です。"" msgid ""Quotas"" msgstr ""クォータ"" msgid """" ""Quotas provide the ability to limit the number of network resources "" ""available to tenants. You can enforce default quotas for all tenants. The "" ""<filename>/etc/neutron/neutron.conf</filename> includes these options for "" ""quota:"" msgstr """" ""クォータは、テナントに対して利用可能なネットワークリソース数を制限する機能を"" ""提供します。全てのテナントに対してデフォルトのクォータを強制する事が出来ま"" ""す。<filename>/etc/neutron/neutron.conf</filename> にクォータに関するこれらの"" ""オプションがあります。"" msgid """" ""OpenStack Networking also supports per-tenant quotas limit through a quota "" ""extension API. To enable per-tenant quotas, you must set the "" ""<literal>quota_driver</literal> option in <filename>neutron.conf</filename>."" msgstr """" ""OpenStack Networking はまた、クォータ拡張 API 経由で、テナント単位のクォータ"" ""をサポートしています。テナント単位クォータを有効にするためには、"" ""<filename>neutron.conf</filename> 中の <literal>quota_driver</literal> を設定"" ""する必要があります。"" msgid ""Data privacy concerns"" msgstr ""データプライバシ関連"" msgid ""Data residency"" msgstr ""データの所在"" msgid """" ""The privacy and isolation of data has consistently been cited as the primary "" ""barrier to cloud adoption over the past few years. Concerns over who owns "" ""data in the cloud and whether the cloud operator can be ultimately trusted "" ""as a custodian of this data have been significant issues in the past."" msgstr """" ""データのプライバシーと分割は、ここ数年クラウド採用の最初の障壁としてずっと言"" ""及されてきました。クラウド中でデータを所有するのは誰か、このデータの管理人と"" ""してクラウドオペレータは結局信用できるのか否かという事は、これまで重要な問題"" ""でした。"" msgid """" ""Numerous OpenStack services maintain data and metadata belonging to tenants "" ""or reference tenant information."" msgstr """" ""多数の OpenStack サービス群は、テナントやテナント情報の所在に属するデータとメ"" ""タデータを管理します。"" msgid """" ""Tenant data stored in an OpenStack cloud may include the following items:"" msgstr ""OpenStack クラウドに保存されたテナントデータは以下の項目を含まれます："" msgid ""Compute instance ephemeral filesystem storage"" msgstr ""Compute のインスタンスの一時的ファイルシステムストレージ"" msgid ""Compute instance memory"" msgstr ""Compute インスタンスのメモリ"" msgid ""Block Storage volume data"" msgstr ""ブロックストレージボリュームデータ"" msgid ""Machine snapshots"" msgstr ""マシンのスナップショット"" msgid ""Data passed to OpenStack Compute's configuration-drive extension"" msgstr ""OpenStack Compute の設定用ドライブ拡張に渡されたデータ"" msgid """" ""Metadata stored by an OpenStack cloud includes the following non-exhaustive "" ""items:"" msgstr ""以下の不完全な一覧を含む、OpenStack クラウドが保存したメタデータ:"" msgid ""Organization name"" msgstr ""組織名"" msgid ""User's \""Real Name\"""" msgstr ""ユーザの「実名」"" msgid """" ""Number or size of running instances, buckets, objects, volumes, and other "" ""quota-related items"" msgstr """" ""実行中のインスタンスのサイズ、バケット、オブジェクト、ボリューム、その他"" ""クォータ関連の項目"" msgid ""Number of hours running instances or storing data"" msgstr ""実行中のインスタンス又は保存されたデータの経過時間"" msgid ""IP addresses of users"" msgstr ""ユーザの IP アドレス"" msgid ""Internally generated private keys for compute image bundling"" msgstr ""Compute イメージ作成用に内部で生成されたプライベートキー"" msgid ""Data disposal"" msgstr ""データの処分"" msgid """" ""OpenStack operators should strive to provide a certain level of tenant data "" ""disposal assurance. Best practices suggest that the operator sanitize cloud "" ""system media (digital and non-digital) prior to disposal, release out of "" ""organization control or release for reuse. Sanitization methods should "" ""implement an appropriate level of strength and integrity given the specific "" ""security domain and sensitivity of the information."" msgstr """" ""OpenStack オペレータは、ある一定レベルのテナントデータ破棄保証が提供できるよ"" ""う努力しなければんりません。ベストプラクティスは、クラウドシステムメディア "" ""(デジタル・非デジタル) を破棄、組織コントロール外へのリリース、再利用の為の開"" ""放より前にオペレータがメディアをクリアする事を推奨しています。メディアのクリ"" ""ア方法は、特定のセキュリティドメインと情報のデリケートさが与えられた、適切な"" ""レベルの強度と完全性を実装すべきです。"" msgid """" ""General data disposal and sanitization guidelines as adopted from NIST "" ""recommended security controls. Cloud operators should:"" msgstr """" ""NIST が採用した汎用のデータ破棄とサニタイズのガイドラインは、セキュリティ制御"" ""を推奨しています。クラウドオペレータは以下のことをすべきです。"" msgid ""Track, document and verify media sanitization and disposal actions."" msgstr ""媒体サニタイズと破棄行為の追跡・文書化・検証を行うこと。"" msgid ""Test sanitation equipment and procedures to verify proper performance."" msgstr """" ""適切なパフォーマンスを検証する為、サニタイズ設備と過程の評価を行うこと。"" msgid """" ""Sanitize portable, removable storage devices prior to connecting such "" ""devices to the cloud infrastructure."" msgstr """" ""持ち運び可能なリムーバルストレージデバイスをクラウドインフラに接続する前にサ"" ""ニタイズすること。"" msgid ""Destroy cloud system media that cannot be sanitized."" msgstr ""サニタイズできないクラウドシステム媒体を破壊すること。"" msgid ""In an OpenStack deployment you will need to address the following:"" msgstr ""OpenStack デプロイでは、以下の事も実施する必要があるでしょう。"" msgid ""Secure data erasure"" msgstr ""安全なデータの消去"" msgid ""Instance memory scrubbing"" msgstr ""インスタンスメモリの消去"" msgid ""Compute instance ephemeral storage"" msgstr ""Compute インスタンスの一時ストレージ"" msgid ""Bare metal server sanitization"" msgstr ""物理サーバのサニタイズ"" msgid ""Data not securely erased"" msgstr ""安全に消去されなかったデータ"" msgid """" ""Within OpenStack some data may be deleted, but not securely erased in the "" ""context of the NIST standards outlined above. This is generally applicable "" ""to most or all of the above-defined metadata and information stored in the "" ""database. This may be remediated with database and/or system configuration "" ""for auto vacuuming and periodic free-space wiping."" msgstr """" ""OpenStack 中でいくつかのデータは削除されるかも知れませんが、上記で触れた "" ""NIST 標準の文脈における安全な消去ではありません。これは一般に、データベースに"" ""保存された上記で定義したメタデータと情報の大半又は全てに当てはまります。これ"" ""は、データベースとシステム設定のどちらか又は両方で、自動バキュームと定期的な"" ""空き領域のクリアを実施する事で解決する事ができるかも知れません。"" msgid """" ""Specific to various hypervisors is the treatment of instance memory. This "" ""behavior is not defined in OpenStack Compute, although it is generally "" ""expected of hypervisors that they will make a best effort to scrub memory "" ""either upon deletion of an instance, upon creation of an instance, or both."" msgstr """" ""様々なハイパーバイザの特色はインスタンスメモリの扱いにあります。\n"" ""\n"" ""This behavior is not defined in OpenStack Compute, although it is generally "" ""expected of hypervisors that they will make a best effort to scrub memory "" ""either upon deletion of an instance, upon creation of an instance, or both.\n"" ""\n"" ""この挙動は OpenStack Compute で定義されておらず、ハイパーバイザがインスタンス"" ""作成時または削除時、あるいはその両方において、ベストエフォートでメモリのクリ"" ""ンアップを行うだろうと一般に考えられています。"" msgid """" ""Xen explicitly assigns dedicated memory regions to instances and scrubs data "" ""upon the destruction of instances (or domains in Xen parlance). KVM depends "" ""more greatly on Linux page management; A complex set of rules related to KVM "" ""paging is defined in the <link href=\""http://www.linux-kvm.org/page/Memory"" ""\"">KVM documentation</link>."" msgstr """" ""Xen は、専用のメモリ範囲をインスタンスに明確に割り当て、インスタンス (又は "" ""Xen の用語でドメイン) 破棄時にそのデータをクリンアップします。KVM はより大い"" ""に Linux のページ管理に依存しています。 KVM のページングに関する複雑なルール"" ""セットは、<link href=\""http://www.linux-kvm.org/page/Memory\"">KVM の文書</"" ""link>で定義されています。"" msgid """" ""It is important to note that use of the Xen memory balloon feature is likely "" ""to result in information disclosure. We strongly recommended to avoid use of "" ""this feature."" msgstr """" ""Xen のメモリバルーン機能の使用は情報漏えいの結果になりかねないという事への注"" ""意は重要です。"" msgid """" ""For these and other hypervisors, we recommend referring to hypervisor-"" ""specific documentation."" msgstr """" ""これらや他のハイパーバイザでは、ハイパーバイザ毎のドキュメントを参照すると良"" ""いでしょう。"" msgid ""Cinder volume data"" msgstr ""Cinder のボリュームデータ"" msgid """" ""Finally, while not a feature of OpenStack, vendors and implementors may "" ""choose to add or support encryption of volumes. In this case, destruction of "" ""data is as simple as throwing away the key."" msgstr """" ""最後に、これは OpenStack の機能ではありませんが、ベンダーと開発者がボリューム"" ""の暗号化機能をサポートするか、あるいは追加可能であるかも知れません。この場"" ""合、データの破壊は単にキーを破棄するだけです。"" msgid """" ""The creation and destruction of ephemeral storage will be somewhat dependent "" ""on the chosen hypervisor and the OpenStack Compute plug-in."" msgstr """" ""一時ストレージの作成・削除は選択したハイパーバイザや OpenStack Compute プラグ"" ""インに依存するでしょう。"" msgid """" ""The libvirt plug-in for compute may maintain ephemeral storage directly on a "" ""filesystem, or in LVM. Filesystem storage generally will not overwrite data "" ""when it is removed, although there is a guarantee that dirty extents are not "" ""provisioned to users."" msgstr """" ""compute 用の libvirt プラグインは、ファイルシステム又は LVM 上の一時ストレー"" ""ジを直接管理出来ます。ファイルシステムストレージは一般にデータを削除する際に"" ""上書きはしませんが、ユーザに対して汚れたエクステンドが用意されないという保証"" ""があります。"" msgid """" ""When using LVM backed ephemeral storage, which is block-based, it is "" ""necessary that the OpenStack Compute software securely erases blocks to "" ""prevent information disclosure. There have in the past been information "" ""disclosure vulnerabilities related to improperly erased ephemeral block "" ""storage devices."" msgstr """" ""ブロックデバイスベースである LVM をバックエンドにした一時ストレージを使用する"" ""場合、OpenStack Compute は情報漏えいを防ぐために、安全にブロックを削除する必"" ""要があります。これらには、過去において、不適切な一時ブロックストレージデバイ"" ""スの削除に関連する情報漏洩の脆弱性がありました。"" msgid """" ""Filesystem storage is a more secure solution for ephemeral block storage "" ""devices than LVM as dirty extents cannot be provisioned to users. However, "" ""it is important to be mindful that user data is not destroyed, so it is "" ""suggested to encrypt the backing filesystem."" msgstr """" ""データが含まれたエクステンドがユーザに用意されないので、一時ブロックストレー"" ""ジデバイス用としてファイルシステムストレージは LVM より安全なソリューションで"" ""す。しかしながら、ユーザデータが破壊されない事を覚えておく事は重要であり、こ"" ""のためバックエンドのファイルシステムの暗号化が提案されています。"" msgid """" ""A bare metal server driver for Compute was under development and has since "" ""moved into a separate project called <link href=\""https://wiki.openstack.org/"" ""wiki/Ironic\"">ironic</link>. At the time of this writing, ironic does not "" ""appear to address sanitization of tenant data resident the physical hardware."" msgstr """" ""Compute の物理サーバドライバは開発中だったのですが、<link href=\""https://"" ""wiki.openstack.org/wiki/Ironic\"">ironic</link>と呼ばれる独立したプロジェクト"" ""に移管される事になりました。この文書の執筆時点では、ironic には物理ハードウェ"" ""ア上にあるテナントデータのサニタイズ機能はまだありません。"" msgid ""Run the following commands:"" msgstr ""以下のコマンドを実行します。"" msgid ""Key management"" msgstr ""キーマネージメント"" msgid ""OpenStack Security Guide"" msgstr ""OpenStack セキュリティガイド"" msgid ""OpenStack Foundation"" msgstr ""OpenStack Foundation"" msgid ""2013"" msgstr ""2013"" msgid ""2014"" msgstr ""2014"" msgid ""current"" msgstr ""カレント"" msgid ""OpenStack"" msgstr ""OpenStack"" msgid ""Copyright details are filled in by the template."" msgstr ""Copyright details are filled in by the template."" msgid """" ""This book provides best practices and conceptual information about securing "" ""an OpenStack cloud."" msgstr """" ""本書は OpenStack クラウドを安全にするためのベストプラクティスと基本的な考え方"" ""について書かれています。"" msgid ""2013-12-02"" msgstr ""2013-12-02"" msgid ""Chapter on Object Storage added."" msgstr ""Object Storage に関する章を追加しました。"" msgid ""2013-10-17"" msgstr ""2013-10-17"" msgid ""Havana release."" msgstr ""Havana リリース。"" msgid ""2013-07-02"" msgstr ""2013-07-02"" msgid ""Initial creation..."" msgstr ""初版作成..."" msgid ""Messaging security"" msgstr ""メッセージングのセキュリティ"" msgid ""Messaging transport security"" msgstr ""メッセージ通信路のセキュリティ"" msgid ""RabbitMQ server SSL configuration"" msgstr ""RabbitMQ サーバにおける SSL 設定"" msgid """" ""The following lines should be added to the system-wide RabbitMQ "" ""configuration file, typically <filename>/etc/rabbitmq/rabbitmq.config</"" ""filename>:"" msgstr """" ""下記の設定を RabbitMQ のシステム設定ファイルに追加します。通常、<filename>/"" ""etc/rabbitmq/rabbitmq.config</filename> に保存されています。"" msgid """" ""Note, the <literal>tcp_listeners</literal> option is set to <literal>[]</"" ""literal> to prevent it from listening an on non-SSL port. The "" ""<literal>ssl_listeners</literal> option should be restricted to only listen "" ""on the management network for the services."" msgstr """" ""<literal>tcp_listeners</literal> オプションを <literal>[]</literal> に指定"" ""し、非 SSL ポートの接続を受け付けない設定にしていることに注意してください。 "" ""<literal>ssl_listeners</literal> オプションはサービスの管理ネットワークのみ受"" ""け付けるよう限定すべきです。"" msgid ""For more information on RabbitMQ SSL configuration see:"" msgstr ""RabbitMQ の SSL 設定に関する詳細は、以下を参照してください。"" msgid ""RabbitMQ Configuration"" msgstr ""RabbitMQ 設定"" msgid ""RabbitMQ SSL"" msgstr ""RabbitMQ SSL"" msgid ""Qpid server SSL configuration"" msgstr ""Qpid サーバ SSL 設定"" msgid ""The Apache Foundation has a messaging security guide for Qpid. See:"" msgstr """" ""Apache Foundation が Qpid のメッセージングセキュリティガイドを発行していま"" ""す。"" msgid ""Apache Qpid SSL"" msgstr ""Apache Qpid SSL"" msgid ""Queue authentication and access control"" msgstr ""キューの認証およびアクセス制御"" msgid """" ""RabbitMQ and Qpid offer authentication and access control mechanisms for "" ""controlling access to queues. ZeroMQ offers no such mechanisms."" msgstr """" ""RabbitMQ と Qpid はキューへのアクセス制御を目的とした、認証およびアクセス制御"" ""の仕組みを持っています。ZeroMQ にはこのような仕組みは備わっていません。"" msgid ""Authentication configuration example: RabbitMQ"" msgstr ""認証設定例: RabbitMQ"" msgid """" ""On the RabbitMQ server, delete the default <literal>guest</literal> user:"" msgstr """" ""RabbitMQ サーバで、デフォルトの <literal>guest</literal> ユーザを削除します。"" msgid """" ""On the RabbitMQ server, for each OpenStack service or node that communicates "" ""with the message queue set up user accounts and privileges:"" msgstr """" ""RabbitMQ サーバにて、メッセージキューを使用する各 OpenStack サービス、また"" ""は、ノード毎にユーザアカウントと権限を設定します。"" msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" msgid """" ""Replace <replaceable>RABBIT_PASS</replaceable> with a suitable password."" msgstr """" ""<replaceable>RABBIT_PASS</replaceable> を適切なパスワードに置き換えます。"" msgid ""For additional configuration information see:"" msgstr ""追加の設定情報は以下を参照してください。"" msgid ""RabbitMQ Access Control"" msgstr ""RabbitMQ アクセス制御"" msgid ""RabbitMQ Authentication"" msgstr ""RabbitMQ 認証"" msgid ""RabbitMQ Plugins"" msgstr ""RabbitMQ プラグイン"" msgid ""RabbitMQ SASL External Auth"" msgstr ""RabbitMQ SASL 外部認証"" msgid ""OpenStack service configuration: RabbitMQ"" msgstr ""OpenStack サービス設定: RabbitMQ"" msgid ""Authentication configuration example: Qpid"" msgstr ""認証設定例: Qpid"" msgid ""For configuration information see:"" msgstr ""設定情報は以下を参照してください。"" msgid ""Apache Qpid Authentication"" msgstr ""Apache Qpid 認証"" msgid ""Apache Qpid Authorization"" msgstr ""Apache Qpid 認可"" msgid ""OpenStack service configuration: Qpid"" msgstr ""OpenStack サービス設定: Qpid"" msgid ""QPID_PASS"" msgstr ""QPID_PASS"" msgid """" ""Optionally, if using SASL with Qpid specify the SASL mechanisms in use by "" ""adding:"" msgstr """" ""オプションとして Qpid で SASL を使用する場合は、下記のように SASL メカニズム"" ""を指定します。"" msgid ""Message queue process isolation and policy"" msgstr ""メッセージキュープロセスのアイソレーションとポリシー"" msgid """" ""Each project provides a number of services which send and consume messages. "" ""Each binary which sends a message is expected to consume messages, if only "" ""replies, from the queue."" msgstr """" ""各プロジェクトは多数のサービスを提供し、それぞれがメッセージを送信、消費しま"" ""す。メッセージを送信した各バイナリは、リプライのみの場合、該当キューからメッ"" ""セージを消費するはずです。"" msgid """" ""Message queue service processes should be isolated from each other and other "" ""processes on a machine."" msgstr """" ""メッセージキューサービスのプロセスは、他のキューサービスのプロセスや、同一マ"" ""シン上の他プロセスと分離すべきです。"" msgid """" ""Network namespaces are highly recommended for all services running on "" ""OpenStack Compute Hypervisors. This will help prevent against the bridging "" ""of network traffic between VM guests and the management network."" msgstr """" ""ネットワーク名前空間の設定は、OpenStack コンピュートハイパーバイザを動作させ"" ""る全てのサービスで強く推奨します。ネットワーク名前空間を用いることで、VM ゲス"" ""トと管理ネットワークのトラフィックがブリッジングされることを防ぎます。"" msgid """" ""When using ZeroMQ messaging, each host must run at least one ZeroMQ message "" ""receiver to receive messages from the network and forward messages to local "" ""processes through IPC. It is possible and advisable to run an independent "" ""message receiver per project within an IPC namespace, along with other "" ""services within the same project."" msgstr """" ""ZeroMQ メッセージングを使用する場合、ネットワーク経由のメッセージ受信と、IPC"" ""経由によるローカルプロセスへのメッセージ送信のために、各ホストに最低 1 つの "" ""ZeroMQ メッセージレシーバーを走らせる必要があります。IPC 名前空間内にプロジェ"" ""クト毎で独立したメッセージレシーバーを構築することが可能であり望ましいです。"" ""また同様に、同一プロジェクト内でも異なるサービスごとに独立したメッセージレ"" ""シーバーを構築することが望ましいです。"" msgid """" ""Queue servers should only accept connections from the management network. "" ""This applies to all implementations. This should be implemented through "" ""configuration of services and optionally enforced through global network "" ""policy."" msgstr """" ""キューサーバーは管理ネットワークからの接続のみを受け付けるべきであり、この方"" ""針はあらゆる実装に適用されます。サービスの設定を通して実装し、任意でグローバ"" ""ルネットワークポリシーを追加で実装します。"" msgid """" ""When using ZeroMQ messaging, each project should run a separate ZeroMQ "" ""receiver process on a port dedicated to services belonging to that project. "" ""This is equivalent to the AMQP concept of control exchanges."" msgstr """" ""ZeroMQ を使用するのであれば、各プロジェクトで独立した専用のポート上で動作す"" ""る ZeroMQ レシーバープロセスを用意すべきです。これは、AMQP のコントロール "" ""exchange の概念に相当します。"" msgid """" ""Use both mandatory access controls (MACs) and discretionary access controls "" ""(DACs) to restrict the configuration for processes to only those processes. "" ""This restriction prevents these processes from being isolated from other "" ""processes that run on the same machine(s)."" msgstr """" ""強制アクセス制御と任意アクセス制御を併用して、プロセスの設定をそれらのプロセ"" ""スのみに制限します。この制限により、これらのプロセスが、同じマシンで動作して"" ""いる他のプロセスから分離されることを防ぎます。"" msgid ""Databases"" msgstr ""データベース"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/databaseusername.png'; md5=a6a5dadedbc1517069ca388c7ac5940a"" msgstr """" ""@@image: 'static/databaseusername.png'; md5=a6a5dadedbc1517069ca388c7ac5940a"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/databaseusernamessl.png'; "" ""md5=9c43242c47eb159b6f61ac41f3d8bced"" msgstr """" ""@@image: 'static/databaseusernamessl.png'; "" ""md5=9c43242c47eb159b6f61ac41f3d8bced"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/novaconductor.png'; md5=dbc1ba139bd1af333f0415bb48704843"" msgstr """" ""@@image: 'static/novaconductor.png'; md5=dbc1ba139bd1af333f0415bb48704843"" msgid ""Database access control"" msgstr ""データベースアクセス制御"" msgid ""OpenStack database access model"" msgstr ""OpenStack データベースアクセスモデル"" msgid """" ""All of the services within an OpenStack project access a single database. "" ""There are presently no reference policies for creating table or row based "" ""access restrictions to the database."" msgstr """" ""OpenStack プロジェクトの中にあるすべてのサービスは単一のデータベースにアクセ"" ""スします。データベースへのテーブルの作成や行単位のアクセス制限に関する明確な"" ""ポリシーは今のところありません。"" msgid """" ""There are no general provisions for granular control of database operations "" ""in OpenStack. Access and privileges are granted simply based on whether a "" ""node has access to the database or not. In this scenario, nodes with access "" ""to the database may have full privileges to DROP, INSERT, or UPDATE "" ""functions."" msgstr """" ""OpenStack には、データベース操作の詳細な制御に関する一般的な決まりがありませ"" ""ん。アクセス権と権限は単にノードがデータベースにアクセスするかしないかに基づ"" ""いて与えられます。このシナリオでは、データベースにアクセスするノードは、"" ""DROP、INSERT、UPDATE 関数の完全な権限を持っているでしょう。"" msgid ""Granular access control"" msgstr ""精細なアクセス制御"" msgid """" ""By default, each of the OpenStack services and their processes access the "" ""database using a shared set of credentials. This makes auditing database "" ""operations and revoking access privileges from a service and its processes "" ""to the database particularly difficult."" msgstr """" ""OpenStack の各サービスとそれらのプロセスはデフォルトで、共有クレデンシャルを"" ""使用してデータベースにアクセスします。これにより、データベース操作の監査およ"" ""び、サービスとそのプロセスからデータベースへのアクセス権の剥奪が特に難しくな"" ""ります。"" msgid ""Nova-conductor"" msgstr ""Nova-conductor"" msgid """" ""The compute nodes are the least trusted of the services in OpenStack because "" ""they host tenant instances. The <systemitem class=\""service\"">nova-"" ""conductor</systemitem> service has been introduced to serve as a database "" ""proxy, acting as an intermediary between the compute nodes and the database. "" ""We discuss its ramifications later in this chapter."" msgstr """" ""コンピュートノードは、プロジェクトのインスタンスをホストするため、OpenStack "" ""で最も信頼できないサービスです。<systemitem class=\""service\"">nova-"" ""conductor</systemitem> サービスは、コンピュートノードとデータベースの中継役と"" ""して動作する、データベースプロキシとして処理するために導入されました。その結"" ""果について本章で後ほど議論します。"" msgid ""We strongly recommend:"" msgstr ""以下の事項を強く推奨します。"" msgid ""All database communications be isolated to a management network"" msgstr ""すべてのデータベース通信の管理ネットワークへの分離"" msgid """" ""Creating unique database user accounts per OpenStack service endpoint "" ""(illustrated below)"" msgstr """" ""OpenStack サービスのエンドポイントごとに一意なデータベースユーザーアカウント"" ""の作成 (下図)"" msgid ""Database authentication and access control"" msgstr ""データベースの認証とアクセス制御"" msgid ""Privileges"" msgstr ""権限"" msgid """" ""A separate database administrator (DBA) account should be created and "" ""protected that has full privileges to create/drop databases, create user "" ""accounts, and update user privileges. This simple means of separation of "" ""responsibility helps prevent accidental misconfiguration, lowers risk and "" ""lowers scope of compromise."" msgstr """" ""データベースの作成と削除、ユーザーアカウントの作成、ユーザーの権限の更新に関"" ""する完全な権限を持つ、別々のデータベース管理者 (DBA) アカウントが作成され、保"" ""護されるべきです。これは、不注意な設定ミスを防ぎ、リスクを減らし、被害の範囲"" ""を小さくする、責任の分離を実現する簡単な方法です。"" msgid """" ""The database user accounts created for the OpenStack services and for each "" ""node should have privileges limited to just the database relevant to the "" ""service where the node is a member."" msgstr """" ""データベースユーザーアカウントは OpenStack サービスのために作成され、ノードが"" ""メンバーであるサービスに関連するデータベースだけに制限された権限を持つ各ノー"" ""ドのために作成されます。"" msgid ""Require user accounts to require SSL transport"" msgstr ""SSL 通信利用のための必須ユーザーアカウント"" msgid ""Configuration example #1: (MySQL)"" msgstr ""設定例 #1: (MySQL)"" msgid ""NOVA_DBPASS"" msgstr ""NOVA_DBPASS"" msgid ""Configuration example #2: (PostgreSQL)"" msgstr ""設定例 #2: (PostgreSQL)"" msgid ""In file <filename>pg_hba.conf</filename>:"" msgstr ""<filename>pg_hba.conf</filename> ファイル:"" msgid """" ""Note this command only adds the ability to communicate over SSL and is non-"" ""exclusive. Other access methods that may allow unencrypted transport should "" ""be disabled so that SSL is the sole access method."" msgstr """" ""このコマンドは SSL 経由で通信する機能を追加するのみであり、排他的ではないこと"" ""に注意してください。SSL を唯一のアクセス方法にするために、暗号化されていない"" ""通信を許可するかもしれない他のアクセス方法は無効化されるべきです。"" msgid """" ""The <literal>md5</literal> parameter defines the authentication method as a "" ""hashed password. We provide a secure authentication example in the section "" ""below."" msgstr """" ""<literal>md5</literal> パラメーターは認証方式をハッシュ化パスワードとして定義"" ""します。以下のセクションでセキュアな認証例を提供します。"" msgid ""OpenStack service database configuration"" msgstr ""OpenStack サービスのデータベース設定"" msgid ""Authentication with X.509 certificates"" msgstr ""X.509 証明書を用いた認証"" msgid """" ""Security may be enhanced by requiring X.509 client certificates for "" ""authentication. Authenticating to the database in this manner provides "" ""greater identity assurance of the client making the connection to the "" ""database and ensures that the communications are encrypted."" msgstr """" ""認証に X.509 クライアント証明書を要求することにより、セキュリティを向上させら"" ""れるかもしれません。この方法でデータベースに認証することにより、データベース"" ""に接続しているクライアントの ID 確認をより強力にでき、通信が確実に暗号化され"" ""ます。"" msgid """" ""OpenStack Compute offers a sub-service called <systemitem class=\""service"" ""\"">nova-conductor</systemitem> which proxies database connections, with the "" ""primary purpose of having the nova compute nodes interfacing with "" ""<systemitem class=\""service\"">nova-conductor</systemitem> to meet data "" ""persistence needs as opposed to directly communicating with the database."" msgstr """" ""OpenStack Compute は <systemitem class=\""service\"">nova-conductor</"" ""systemitem> というサブサービスを提供します。これは、<systemitem class="" ""\""service\"">nova-conductor</systemitem> と直接接する nova コンピュートノード"" ""がデータ永続性の要求を満たすことを主目的として、それらがデータベースと直接通"" ""信する代わりにデータベース接続を中継します。"" msgid """" ""Nova-conductor receives requests over RPC and performs actions on behalf of "" ""the calling service without granting granular access to the database, its "" ""tables, or data within. Nova-conductor essentially abstracts direct database "" ""access away from compute nodes."" msgstr """" ""Nova-conductor は RPC 経由でリクエストを受信します。そして、データベース、"" ""テーブル、データへの精細なアクセス権なしでサービスを呼び出す動作を実行しま"" ""す。Nova-conductor は本質的にコンピュートノードがデータベースに直接アクセスす"" ""ることを抽象化します。"" msgid """" ""This abstraction offers the advantage of restricting services to executing "" ""methods with parameters, similar to stored procedures, preventing a large "" ""number of systems from directly accessing or modifying database data. This "" ""is accomplished without having these procedures stored or executed within "" ""the context or scope of the database itself, a frequent criticism of typical "" ""stored procedures."" msgstr """" ""この抽象化は、サービスがパラメーター、ストアドプロシージャーのようなものを用"" ""いたメソッドの実行を制限し、数多くのシステムがデータベースのデータに直接アク"" ""セスしたり変更したりすることを防ぐという利点を提供します。これは、一般的なス"" ""トアドプロシージャーという頻繁に批判される、データベース自体の文脈や範囲の中"" ""で、これらの手順を保存して実行することなく実現されます。"" msgid """" ""Unfortunately, this solution complicates the task of more fine-grained "" ""access control and the ability to audit data access. Because the <systemitem "" ""class=\""service\"">nova-conductor</systemitem> service receives requests over "" ""RPC, it highlights the importance of improving the security of messaging. "" ""Any node with access to the message queue may execute these methods provided "" ""by the <systemitem class=\""service\"">nova-conductor</systemitem> and "" ""effectively modifying the database."" msgstr """" ""残念なことに、このソリューションはより詳細なアクセス制御とデータアクセスの監"" ""査機能を複雑にします。<systemitem class=\""service\"">nova-conductor</"" ""systemitem> サービスは RPC 経由でリクエストを受信するため、メッセージングのセ"" ""キュリティを改善する重要性を強調させます。メッセージキューにアクセスするすべ"" ""てのノードは、<systemitem class=\""service\"">nova-conductor</systemitem> によ"" ""り提供されるこれらの方式を実行し、データベースを効率的に変更するかもしれませ"" ""ん。"" msgid """" ""Note, as <systemitem class=\""service\"">nova-conductor</systemitem> only "" ""applies to OpenStack Compute, direct database access from compute hosts may "" ""still be necessary for the operation of other OpenStack components such as "" ""Telemetry (ceilometer), Networking, and Block Storage."" msgstr """" ""<systemitem class=\""service\"">nova-conductor</systemitem> は OpenStack "" ""Compute のみに適用されるので、Telemetry (ceilometer)、Networking、Block "" ""Storage のような他の OpenStack コンポーネントの動作のために、コンピュートホス"" ""トから直接データベースにアクセスする必要があるかもしれないことに注意してくだ"" ""さい。"" msgid """" ""To disable the <systemitem class=\""service\"">nova-conductor</systemitem>, "" ""place the following into your <filename>nova.conf</filename> file (on your "" ""compute hosts):"" msgstr """" ""<systemitem class=\""service\"">nova-conductor</systemitem> を無効化するため"" ""に、以下の事項を (コンピュートホストの) <filename>nova.conf</filename> ファイ"" ""ルに記入します。"" msgid ""Management interfaces"" msgstr ""管理インターフェース"" msgid """" ""It is necessary for administrators to perform command and control over the "" ""cloud for various operational functions. It is important these command and "" ""control facilities are understood and secured."" msgstr """" ""管理者は、様々な運用機能に対してクラウドの管理統制を行う必要があります。ま"" ""た、これらの管理統制機能を理解して、セキュリティの確保を行うことが重要です。"" msgid """" ""OpenStack provides several management interfaces for operators and tenants:"" msgstr """" ""OpenStack は、オペレーターやプロジェクト向けに複数の管理インターフェースを提"" ""供しています。"" msgid ""OpenStack dashboard (horizon)"" msgstr ""OpenStack dashboard (horizon)"" msgid ""OpenStack API"" msgstr ""OpenStack API"" msgid ""Secure shell (SSH)"" msgstr ""secure shell (SSH)"" msgid """" ""OpenStack management utilities such as <systemitem class=\""service\"">nova-"" ""manage</systemitem> and <systemitem class=\""service\"">glance-manage</"" ""systemitem>"" msgstr """" ""<systemitem class=\""service\"">nova-manage</systemitem>、<systemitem class="" ""\""service\"">glance-manage</systemitem> などの OpenStack 管理ユーティリティ"" msgid ""Out-of-band management interfaces, such as IPMI"" msgstr ""帯域外管理インターフェース (IPMI など)"" msgid """" ""The OpenStack dashboard (horizon) provides administrators and tenants with a "" ""web-based graphical interface to provision and access cloud-based resources. "" ""The dashboard communicates with the back-end services through calls to the "" ""OpenStack API."" msgstr """" ""OpenStack dashboard (horizon) は、管理者やプロジェクトに対して、クラウドベー"" ""スのリソースのプロビジョンやアクセスができるように Web ベースのグラフィカル"" ""インターフェースを提供します。ダッシュボードは、OpenStack API に呼び出しを行"" ""うことでバックエンドサービスと対話します。"" msgid """" ""As a cloud administrator, the dashboard provides an overall view of the size "" ""and state of your cloud. You can create users and tenants/projects, assign "" ""users to tenant/projects and set limits on the resources available for them."" msgstr """" ""クラウド管理者として、ダッシュボードはクラウドのサイズや状態の俯瞰図を確認で"" ""きます。また、ユーザーやプロジェクト (テナント) の作成、プロジェクトへのユー"" ""ザーの割り当て、ユーザーやプロジェクトで利用可能なリソースの制限設定が可能で"" ""す。 "" msgid """" ""The dashboard provides tenant-users a self-service portal to provision their "" ""own resources within the limits set by administrators."" msgstr """" ""ダッシュボードでは、プロジェクト/ユーザーに対して、管理者が設定した制限値内で"" ""自身のリソースをプロビジョニングするためのセルフサービスポータルを提供しま"" ""す。"" msgid """" ""The dashboard provides GUI support for routers and load-balancers. For "" ""example, the dashboard now implements all of the main Networking features."" msgstr """" ""また、ダッシュボードではルーターやロードバランサーにも GUI 対応しています。例"" ""えば、ダッシュボードは主な Networking 機能をすべて実装するようになりました。"" msgid """" ""It is an extensible <glossterm>Django</glossterm> web application that "" ""allows easy plug-in of third-party products and services, such as billing, "" ""monitoring, and additional management tools."" msgstr """" ""Hirozon は拡張可能な <glossterm>Django</glossterm> Web アプリケーションで、請"" ""求、監視、追加管理ツールなど、サードパーティーの製品やサービスを簡単にプラグ"" ""インできるようにします。"" msgid """" ""The dashboard can also be branded for service providers and other commercial "" ""vendors."" msgstr """" ""また、ダッシュボードはサービスプロバイダーや他の商業ベンダー向けにブランディ"" ""ングすることも可能です。"" msgid """" ""The dashboard requires cookies and JavaScript to be enabled in the web "" ""browser."" msgstr """" ""ダッシュボードは Web ブラウザーのクッキーと JavaScript を有効にする必要があり"" ""ます。"" msgid """" ""Create and manage security groups through dashboard. The security groups "" ""allows L3-L4 packet filtering for security policies to protect virtual "" ""machines."" msgstr """" ""ダッシュボードからセキュリティグループを作成・管理します。セキュリティグルー"" ""プにより、セキュリティポリシーに関する L3-L4 パケットをフィルダリングして仮想"" ""マシンの保護が可能になります。"" msgid ""Icehouse Release Notes"" msgstr ""Icehouse リリースノート"" msgid """" ""The OpenStack API is a RESTful web service endpoint to access, provision and "" ""automate cloud-based resources. Operators and users typically access the API "" ""through command-line utilities (for example, <placeholder-1/> or "" ""<placeholder-2/>), language-specific libraries, or third-party tools."" msgstr """" ""OpenStack API はクラウドベースのリソースのアクセス、プロビジョニング、自動化"" ""を行う RESTful Web サービスのエンドポイントです。オペレーターやユーザーは通"" ""常、コマンドラインユーティリティ (<placeholder-1/>、<placeholder-2/> など)、"" ""言語固有のライブラリ、またはサードパーティのツールで API にアクセスします。"" msgid """" ""To the cloud administrator, the API provides an overall view of the size and "" ""state of the cloud deployment and allows the creation of users, tenants/"" ""projects, assigning users to tenants/projects, and specifying resource "" ""quotas on a per tenant/project basis."" msgstr """" ""API はクラウド管理者がクラウドデプロイメントのサイズや状態の概要を把握できる"" ""ようにするだけでなく、ユーザー、プロジェクトの作成、プロジェクトへのユーザー"" ""の割り当て、プロジェクトベースのリソースクォータの指定などができるようにしま"" ""す。"" msgid """" ""The API provides a tenant interface for provisioning, managing, and "" ""accessing their resources."" msgstr """" ""API はリソースのプロビジョニング、管理、アクセスに使用するプロジェクトイン"" ""ターフェースを提供します。"" msgid """" ""As a web service, OpenStack API is susceptible to familiar web site attack "" ""vectors such as denial of service attacks."" msgstr """" ""Web サービスとして OpenStack API は、サービス妨害 (DoS) 攻撃など、よく知られ"" ""ている Web サイト攻撃ベクトルからの影響を受けます。"" msgid """" ""It has become industry practice to use secure shell (SSH) access for the "" ""management of Linux and Unix systems. SSH uses secure cryptographic "" ""primitives for communication. With the scope and importance of SSH in "" ""typical OpenStack deployments, it is important to understand best practices "" ""for deploying SSH."" msgstr """" ""Linux や Unix システムの管理にはセキュアシェル (SSH) を使用するのが業界の慣習"" ""となっています。SSH は通信にセキュアな暗号化機能を使用します。一般的な "" ""OpenStack デプロイメントでの SSH の範囲や重要性において、SSH デプロイメントの"" ""ベストプラクティスを把握することが重要です。"" msgid ""Host key fingerprints"" msgstr ""ホストキーのフィンガープリント"" msgid """" ""Often overlooked is the need for key management for SSH hosts. As most or "" ""all hosts in an OpenStack deployment will provide an SSH service, it is "" ""important to have confidence in connections to these hosts. It cannot be "" ""understated that failing to provide a reasonably secure and accessible "" ""method to verify SSH host key fingerprints is ripe for abuse and "" ""exploitation."" msgstr """" ""頻繁に見逃されるのが SSH ホストのキー管理の必要性です。OpenStack デプロイメン"" ""トホストのすべてまたは多くが SSH サービスを提供します。このようなホストへの接"" ""続の信頼性を確保することが重要です。SSH ホストキーのフィンガープリントの検証"" ""に関して比較的セキュアでアクセス可能なメソッドを提供できないと、悪用やエクス"" ""プロイトの温床となるといっても過言ではありません。"" msgid """" ""All SSH daemons have private host keys and, upon connection, offer a host "" ""key fingerprint. This host key fingerprint is the hash of an unsigned public "" ""key. It is important these host key fingerprints are known in advance of "" ""making SSH connections to those hosts. Verification of host key fingerprints "" ""is instrumental in detecting man-in-the-middle attacks."" msgstr """" ""SSH デーモンにはすべてプライベートのホストキーがあり、接続するとホストキーの"" ""フィンガープリントが提供されます。このホストキーのフィンガープリントは未署名"" ""のパブリックキーのハッシュです。これらのホストに SSH 接続する前に、ホスト"" ""キーのフィンガープリントを把握しておくことが重要です。ホストキーのフィンガー"" ""プリントの検証は中間者攻撃の検出に役立ちます。"" msgid """" ""Typically, when an SSH daemon is installed, host keys will be generated. It "" ""is necessary that the hosts have sufficient entropy during host key "" ""generation. Insufficient entropy during host key generation can result in "" ""the possibility to eavesdrop on SSH sessions."" msgstr """" ""通常、SSH デーモンがインストールされると、ホストキーが生成されます。ホスト"" ""キーの生成時に、ホストには十分なエントロピーが必要になります。ホストキーの生"" ""成時にエントロピーが十分にないと、SSH セッションの傍受が発生してしまう可能性"" ""があります。"" msgid ""Management utilities"" msgstr ""管理ユーティリティ"" msgid """" ""The OpenStack Management Utilities are open-source Python command-line "" ""clients that make API calls. There is a client for each OpenStack service "" ""(for example, <systemitem class=\""service\"">nova</systemitem>, <systemitem "" ""class=\""service\"">glance</systemitem>). In addition to the standard CLI "" ""client, most of the services have a management command-line utility which "" ""makes direct calls to the database. These dedicated management utilities are "" ""slowly being deprecated."" msgstr """" ""OpenStack 管理ユーテリティは、API 呼び出しを行う、オープンソースの Python の"" ""コマンドラインクライアントです。OpenStack サービス (<systemitem class="" ""\""service\"">nova</systemitem>、<systemitem class=\""service\"">glance</"" ""systemitem> など) 毎にクライアントがあります。標準の CLI クライアントに加え、"" ""サービスの多くには管理コマンドラインがあり、データベースへ直接呼び出しを行い"" ""ます。これらの専用の管理ユーテリティは徐々に廃止予定となっています。"" msgid """" ""The dedicated management utilities (*-manage) in some cases use the direct "" ""database connection."" msgstr """" ""場合によっては専用の管理ユーテリティ (*-manage) は直接データベースへの接続を"" ""使用することがあります。"" msgid """" ""Ensure that the .rc file which has your credential information is secured."" msgstr """" ""認証情報が含まれている .rc ファイルのセキュリティが確保されているようにしま"" ""す。"" msgid """" ""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://"" ""docs.openstack.org/user-guide/content/section_cli_overview.html\"">command-"" ""line clients overview</link>"" msgstr """" ""<citetitle>OpenStack エンドユーザーガイド</citetitle> の項: <link href="" ""\""http://docs.openstack.org/ja/user-guide/content/section_cli_overview.html"" ""\"">コマンドラインクライアントの概要</link>"" msgid """" ""<citetitle>OpenStack End User Guide</citetitle> section <link href=\""http://"" ""docs.openstack.org/user-guide/content/cli_openrc.html\"">Download and source "" ""the OpenStack RC file</link>"" msgstr """" ""<citetitle>OpenStack エンドユーザーガイド</citetitle> の項 <link href="" ""\""http://docs.openstack.org/ja/user-guide/content/cli_openrc.html"" ""\"">OpenStack RC ファイルのダウンロードと読み込み</link>"" msgid ""Out-of-band management interface"" msgstr ""帯域外管理インターフェース"" msgid """" ""OpenStack management relies on out-of-band management interfaces such as the "" ""IPMI protocol to access into nodes running OpenStack components. IPMI is a "" ""very popular specification to remotely manage, diagnose, and reboot servers "" ""whether the operating system is running or the system has crashed."" msgstr """" ""OpenStack コンポーネントを実行するノードにアクセスする場合、OpenStack の管理"" ""は IPMI プロトコルなどのアウトオブバンド管理インターフェースに依存します。"" ""IPMI は非常に有名な仕様で、オペレーティングシステムが実行中である場合やシステ"" ""ムがクラッシュした場合でもリモートでのサーバー管理、診断、リブートを行えま"" ""す。"" msgid """" ""Ensure that the network interfaces are on their own private(management or a "" ""separate) network. Segregate management domains with firewalls or other "" ""network gear."" msgstr """" ""ネットワークインターフェースはプライベート (管理または個別) ネットワークに設"" ""定されていることを確認します。管理ドメインはファイアウォールか他のネットワー"" ""ク機器で分離してください。"" msgid """" ""Monitor the traffic on the management network. The anomalies might be easier "" ""to track than on the busier compute nodes."" msgstr """" ""管理ネットワークのトラフィックを監視します。トラフィックの多いコンピュート"" ""ノードよりも例外のトラッキングが簡単になる場合があります。"" msgid """" ""Out of band management interfaces also often include graphical machine "" ""console access. It is often possible, although not necessarily default, that "" ""these interfaces are encrypted. Consult with your system software "" ""documentation for encrypting these interfaces."" msgstr """" ""また、アウトオブバンド管理インターフェースはグラフィカルのコンソールアクセス"" ""が可能な場合が多くあります。デフォルトではない可能性もありますが、これらのイ"" ""ンターフェースは暗号化されていることがあります。これらのインターフェースの暗"" ""号化については、お使いのシステムのソフトウェア文書を確認してください。"" msgid ""Hacking servers that are turned off"" msgstr ""オフ状態のサーバーのハッキング"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'static/filteringWorkflow1.png'; "" ""md5=c144af5cbdee1bd17a7bde0bea5b5fe7"" msgstr """" ""@@image: 'static/filteringWorkflow1.png'; "" ""md5=c144af5cbdee1bd17a7bde0bea5b5fe7"" msgid ""Security services for instances"" msgstr ""インスタンスのセキュリティサービス"" msgid """" ""Fortunately, a cloud architect may address these issues by providing a high "" ""quality source of entropy to the cloud instances. This can be done by having "" ""enough hardware random number generators (HRNG) in the cloud to support the "" ""instances. In this case, \""enough\"" is somewhat domain specific. For "" ""everyday operations, a modern HRNG is likely to produce enough entropy to "" ""support 50-100 compute nodes. High bandwidth HRNGs, such as the RdRand "" ""instruction available with Intel Ivy Bridge and newer processors could "" ""potentially handle more nodes. For a given cloud, an architect needs to "" ""understand the application requirements to ensure that sufficient entropy is "" ""available."" msgstr """" ""これらの課題は、クラウドアーキテクトが高品質のエントロピーをクラウドインスタ"" ""ンスに提供することで対応できます。例えば、クラウド内にインスタンス用に適量な"" ""ハードウェア乱数生成器(HRNG)があれば解決できます（適量はドメインによって異な"" ""る）。一般的なハードウェア乱数生成器なら通常運用されている50-100台のコン"" ""ピュートノード分のエントロピーを生成することが可能です。高帯域ハードウェア乱"" ""数生成器（Intel Ivy Bridgeや最新プロセッサなどと提供されるRdRand instruction"" ""など）はさらに多くのノードに対応できます。エントロピーの量が十分かどうかを判"" ""断するためには、クラウド上で運用するアプリケーションの要求を理解している必要"" ""があります。"" msgid """" ""Before an instance is created, a host for the image instantiation must be "" ""selected. This selection is performed by the <systemitem class=\""service"" ""\"">nova-scheduler</systemitem> which determines how to dispatch compute and "" ""volume requests."" msgstr """" ""インスタンスを生成する前に、イメージのインスタンス化のためのホストを選択する"" ""必要があります。この選択は<systemitem class=\""service\"">nova-scheduler</"" ""systemitem>によって行われ、さらにコンピュートとボリューム要求の伝達方法も決定"" ""します。"" msgid ""Image creation process"" msgstr ""イメージ作成プロセス"" msgid ""The first option is to obtain boot media from a trusted source."" msgstr ""最初の選択肢は、信頼された提供元からブートメディアを入手することです。"" msgid """" ""The final option is to use an automated image builder. The following example "" ""uses the Oz image builder. The OpenStack community has recently created a "" ""newer tool worth investigating: disk-image-builder. We have not evaluated "" ""this tool from a security perspective."" msgstr """" ""最後の手段として説明するのはイメージの自動生成機構の使用です。次の例では、Oz "" ""image builderを採用しています。OpenStackコミュニティでは、disk-image-builder"" ""というさらに新しいツールが公開されています。本ツールはセキュリティ観点におい"" ""て未検証です。"" msgid """" ""Example of RHEL 6 CCE-26976-1 which will help implement NIST 800-53 "" ""Section<emphasis>AC-19(d) in</emphasis> Oz."" msgstr """" ""OzでNIST 800-53 セクション<emphasis>AC-19(d)</emphasis> の実装を手助けする"" ""RHEL 6 CCE-26976-1の例"" msgid ""Image provenance and validation"" msgstr ""イメージの出所と妥当性確認"" msgid """" ""Unfortunately, it is not currently possible to force Compute to validate an "" ""image hash immediately prior to starting an instance. To understand the "" ""situation, we begin with a brief overview of how images are handled around "" ""the time of image launch."" msgstr """" ""残念ながら、現在はインスタンス起動直前にコンピュートにイメージのハッシュを検"" ""証を強制する方法がありません。状況を理解するために、イメージ起動の際にイメー"" ""ジがどのように扱われるのかを簡単に説明します。"" msgid ""Start instance on destination host"" msgstr ""目的先ホストでインスタンスを起動"" msgid ""Transfer memory"" msgstr ""メモリを転送"" msgid ""Stop the guest &amp; sync disks"" msgstr ""ゲスト&amp;syncディスクを停止"" msgid ""Transfer state"" msgstr ""転送状態となる"" msgid ""Start the guest"" msgstr ""ゲストを起動"" msgid ""Live migration risks"" msgstr ""ライブマイグレーションのリスク"" msgid """" ""At various stages of the live migration process the contents of an instances "" ""run time memory and disk are transmitted over the network in plain text. "" ""Thus there are several risks that need to be addressed when using live "" ""migration. The following in-exhaustive list details some of these risks:"" msgstr """" ""ライブマイグレーションのステージによっては、インスタンスのランタイムメモリや"" ""ディスクの今テンスが平文でネットワーク上転送されます。そのため、ライブマイグ"" ""レーション中には対処が必要なリスクがあります。次は一部のリスクの詳細を列挙し"" ""ています。"" msgid """" ""<emphasis>Denial of Service (DoS)</emphasis>: If something fails during the "" ""migration process, the instance could be lost."" msgstr """" ""<emphasis>Denial of Service (DoS)</emphasis>: マイグレーションプロセス中に何"" ""かが失敗した場合、インスタンスを失う可能性があります。"" msgid """" ""<emphasis>Data exposure</emphasis>: Memory or disk transfers must be handled "" ""securely."" msgstr """" ""<emphasis>データの公開</emphasis>: メモリやディスクの転送は安全に行う必要があ"" ""ります。"" msgid """" ""<emphasis>Data manipulation</emphasis>: If memory or disk transfers are not "" ""handled securely, then an attacker could manipulate user data during the "" ""migration."" msgstr """" ""<emphasis>データの操作</emphasis>: メモリやディスクの転送がセキュアに処理され"" ""なければ、攻撃者がマイグレーション中にユーザーデータを操作できる可能性があり"" ""ます。"" msgid """" ""<emphasis>Code injection</emphasis>: If memory or disk transfers are not "" ""handled securely, then an attacker could manipulate executables, either on "" ""disk or in memory, during the migration."" msgstr """" ""<emphasis>コードの挿入</emphasis>: メモリやディスクの転送が安全ではない場合、"" ""マイグレーション中に攻撃者によってディスクやメモリ上の実行ファイルが操作され"" ""る可能性があります。"" msgid ""Live migration mitigations"" msgstr ""ライブマイグレーションのリスクの軽減"" msgid """" ""There are several methods to mitigate some of the risk associated with live "" ""migrations, the following list details some of these:"" msgstr """" ""ライブマイグレーションに関連するリスクを軽減するためには様々な手法がありま"" ""す。次のリストで詳しく説明します。"" msgid ""Disable live migration"" msgstr ""ライブマイグレーションの無効化"" msgid ""Isolated migration network"" msgstr ""マイグレーションネットワークの分離"" msgid ""Encrypted live migration"" msgstr ""ライブマイグレーションの暗号化"" msgid """" ""At this time, live migration is enabled in OpenStack by default. Live "" ""migrations can be disabled by adding the following lines to the nova "" ""<filename>policy.json</filename> file:"" msgstr """" ""現在、OpenStackではデフォルトでライブマイグレーションを有効にしています。ライ"" ""ブマイグレーションは nova <filename>policy.json</filename> ファイルへ下記の行"" ""を追加することによって無効化できます。"" msgid ""Migration network"" msgstr ""マイグレーションネットワーク"" msgid ""Introduction to case studies"" msgstr ""ケーススタディの概要"" msgid """" ""This guide refers to two running case studies, which are introduced here and "" ""referred to at the end of each chapter."" msgstr """" ""本ガイドでは、全体を通して、2 つの運用事例を参照しています。ここでは、これら"" ""を概要を説明し、各章末で参照します。"" msgid ""Case study: Alice, the private cloud builder"" msgstr ""事例: プライベートクラウド構築者のアリス"" msgid ""Case study: Bob, the public cloud provider"" msgstr ""事例: パブリッククラウドプロバイダーのボブ"" msgid """" ""Bob is a lead architect for a company that deploys a large greenfield public "" ""cloud. This cloud provides IaaS for the masses and enables any consumer with "" ""a valid credit card access to utility computing and storage, but the primary "" ""focus is enterprise customers. Data privacy concerns are a big priority for "" ""Bob as they are seen as a major barrier to large-scale adoption of the cloud "" ""by organizations."" msgstr """" ""ボブは、新規展開の大規模なパブリッククラウドのデプロイを行う会社のリードアー"" ""キテクトです。このクラウドは、有効なクレジットカードを持つ消費者が、ユーティ"" ""リティコンピューティングやストレージに使用できる一般大衆向けの IaaS を提供し"" ""ますが、第一のターゲットは 企業顧客です。企業の間では、データプライバシー問題"" ""は、大規模なクラウド導入の大きな障害とみなされているため、ボブにとって優先課"" ""題となっています。"" msgid ""Message queuing"" msgstr ""メッセージキュー"" msgid """" ""Message queuing services facilitate inter-process communication in "" ""OpenStack. OpenStack supports these message queuing service back ends:"" msgstr """" ""メッセージキューイングサービスは、OpenStack 内におけるプロセス間通信を担いま"" ""す。OpenStack は次のキューイングサービスをサポートしています。"" msgid ""RabbitMQ"" msgstr ""RabbitMQ"" msgid ""Qpid"" msgstr ""Qpid"" msgid ""ZeroMQ or 0MQ"" msgstr ""ZeroMQ、または、0MQ"" msgid """" ""Both RabbitMQ and Qpid are Advanced Message Queuing Protocol (AMQP) "" ""frameworks, which provide message queues for peer-to-peer communication. "" ""Queue implementations are typically deployed as a centralized or "" ""decentralized pool of queue servers. ZeroMQ provides direct peer-to-peer "" ""communication through TCP sockets."" msgstr """" ""RabbitMQ と Qpid は両方とも、Advanced Message Queuing Protocol (AMQP) フレー"" ""ムワークであり、ピアツーピア通信にメッセージキューを提供する仕組みです。\n"" ""キューの実装は通常、キューサーバのプールを集中型か分散型で展開します。\n"" ""ZeroMQ はピア間の通信に直接 TCP ソケットを使うところが異なっています。"" msgid """" ""Message queues effectively facilitate command and control functions across "" ""OpenStack deployments. Once access to the queue is permitted no further "" ""authorization checks are performed. Services accessible through the queue do "" ""validate the contexts and tokens within the actual message payload. However, "" ""you must note the expiration date of the token because tokens are "" ""potentially re-playable and can authorize other services in the "" ""infrastructure."" msgstr """" ""メッセージキューは、OpenStack 内における指揮系統の機能を担います。一度キュー"" ""へのアクセスが許可されると、その後の認証チェックは行われません。キューを使用"" ""するサービスがメッセージペイロード内のコンテキストとトークンのチェックを行い"" ""ます。\n"" ""とはいえ、トークンの期限切れには注意を払う必要があります。これは、トークンが"" ""潜在的に再発行可能であり、インフラストラクチャ内の他のサービスを許可する可能"" ""性があるためです。"" msgid """" ""OpenStack does not support message-level confidence, such as message "" ""signing. Consequently, you must secure and authenticate the message "" ""transport itself. For high-availability (HA) configurations, you must "" ""perform queue-to-queue authentication and encryption."" msgstr """" ""OpenStack は、メッセージへの署名のようなメッセージレベルのコンフィデンスはサ"" ""ポートしていません。そのため、メッセージの通信路そのものがセキュア化され、か"" ""つ、キューサーバーへのアクセスの際に認証が行なわれる必要があります。\n"" ""また、HA 設定の際には、キュー間の認証と暗号化も同様に実施するべきです。"" msgid """" ""With ZeroMQ messaging, IPC sockets are used on individual machines. Because "" ""these sockets are vulnerable to attack, ensure that the cloud operator has "" ""secured them."" msgstr """" ""ZeroMQ メッセージングでは、IPC ソケットが各マシンで使用されます。これらのソ"" ""ケットは管理者がセキュア化しない限り、ローカルメッセージインジェクションやス"" ""ヌーピングの攻撃に脆弱な可能性があります。"" msgid """" ""The Compute service (nova) is one of the more complex OpenStack services. It "" ""runs in many locations throughout the cloud and interacts with a variety of "" ""internal services. For this reason, most of our recommendations regarding "" ""best practices for Compute service configuration are distributed throughout "" ""this book. We provide specific details in the sections on Management, API "" ""Endpoints, Messaging, and Database."" msgstr """" ""Compute Service (Nova) は最も複雑な OpenStack サービスの一つです。クラウドの"" ""隅々まで多くの場所で動作し、さまざまな内部サービスと通信します。この理由によ"" ""り、Compute Service 設定のベストプラクティスに関する推奨事項の多くは、本書を"" ""通して配布されます。管理、API エンドポイント、メッセージング、データベースの"" ""セクションで具体的な詳細を提供します。""",7538,7545
openstack%2Fneutron~master~Ia7fc2c3e605d92d8497d44e28054bdda613cebf2,openstack/neutron,master,Ia7fc2c3e605d92d8497d44e28054bdda613cebf2,Force order of dhcp.needs_resync_reasons dictionary elements,MERGED,2015-05-26 13:26:36.000000000,2015-05-28 06:47:43.000000000,2015-05-26 16:13:13.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-26 13:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/676614a79d2848a6fb9cb9a5e7ac5cadd76300fb', 'message': 'Support random hash seed in test_periodoc_resync_helper\n\nCurrently test_periodoc_resync_helper is not working when\nPYTHONHASHSEED=2. This change replaces a dict by an ordered dict in\norder to support random hash seeds.\n\nChange-Id: Ia7fc2c3e605d92d8497d44e28054bdda613cebf2\nPartial-Bug: #1348818\n'}, {'number': 2, 'created': '2015-05-26 13:47:57.000000000', 'files': ['neutron/tests/unit/agent/dhcp/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1d679678daa560c86bb84303aee6163296ec653', 'message': 'Force order of dhcp.needs_resync_reasons dictionary elements\n\nThis fixes the test_periodoc_resync_helper unit test that breaks with\na randomized PYTHONHASHSEED (see the bug report).\n\nThe test assumed that the dhcp.needs_resync_reasons dictionary from\nneutron.agent.dhcp.agent had elements in a particular order. Found with\nPYTHONHASHSEED=2.\n\nThe fix refactors the test case to force a sorted dhcp.needs_resync_reasons\ndictionary.\n\nPartial-bug: #1348818\n\nNote: There are several other unrelated unit tests that also break with\na randomized PYTHONHASHSEED, but they are not addressed here. They will\nbe addressed in separate patches.\n\nChange-Id: Ia7fc2c3e605d92d8497d44e28054bdda613cebf2\n'}]",0,185592,a1d679678daa560c86bb84303aee6163296ec653,41,25,2,8124,,,0,"Force order of dhcp.needs_resync_reasons dictionary elements

This fixes the test_periodoc_resync_helper unit test that breaks with
a randomized PYTHONHASHSEED (see the bug report).

The test assumed that the dhcp.needs_resync_reasons dictionary from
neutron.agent.dhcp.agent had elements in a particular order. Found with
PYTHONHASHSEED=2.

The fix refactors the test case to force a sorted dhcp.needs_resync_reasons
dictionary.

Partial-bug: #1348818

Note: There are several other unrelated unit tests that also break with
a randomized PYTHONHASHSEED, but they are not addressed here. They will
be addressed in separate patches.

Change-Id: Ia7fc2c3e605d92d8497d44e28054bdda613cebf2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/185592/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/agent/dhcp/test_agent.py'],1,676614a79d2848a6fb9cb9a5e7ac5cadd76300fb,bug/1348818,"import collections dhcp.needs_resync_reasons = collections.OrderedDict( (('a', 'reason1'), ('b', 'reason2')))"," dhcp.needs_resync_reasons = {'a': 'reason1', 'b': 'reason2'}",3,1
openstack%2Fmistral~master~I01f36e4b0080e10b9d39a6adbfe4b6cd43957fc6,openstack/mistral,master,I01f36e4b0080e10b9d39a6adbfe4b6cd43957fc6,Make mistral use of oslo-config-generator,MERGED,2015-05-26 09:55:21.000000000,2015-05-28 06:46:20.000000000,2015-05-28 06:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7613}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-26 09:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d9463962bd2345c4214538f1fc5ae76c6d09f533', 'message': 'Make mistral use of oslo-config-generator\n\nChange-Id: I01f36e4b0080e10b9d39a6adbfe4b6cd43957fc6\n'}, {'number': 2, 'created': '2015-05-26 10:06:18.000000000', 'files': ['etc/mistral.conf.sample', 'tools/config/check_uptodate.sh', 'mistral/config.py', 'tools/config/generate_sample.sh', 'tools/config/config-generator.mistral.conf', 'openstack-common.conf', 'tools/config/oslo.config.generator.rc', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral/commit/f34edb7e274e43317dedc3c4d25fcafedc75cbc5', 'message': 'Make mistral use of oslo-config-generator\n\nChange-Id: I01f36e4b0080e10b9d39a6adbfe4b6cd43957fc6\n'}]",0,185547,f34edb7e274e43317dedc3c4d25fcafedc75cbc5,9,6,2,7700,,,0,"Make mistral use of oslo-config-generator

Change-Id: I01f36e4b0080e10b9d39a6adbfe4b6cd43957fc6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/47/185547/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/mistral.conf.sample', 'tools/config/check_uptodate.sh', 'mistral/config.py', 'tools/config/config-generator.mistral.conf', 'tools/config/generate_sample.sh', 'openstack-common.conf', 'tools/config/oslo.config.generator.rc', 'setup.cfg', 'tox.ini']",9,d9463962bd2345c4214538f1fc5ae76c6d09f533,add_generate_config,[testenv:genconfig] commands = oslo-config-generator --config-file tools/config/config-generator.mistral.conf \ --output-file etc/mistral.conf.sample ,,650,641
openstack%2Fpython-keystoneclient~master~Ib20782f5b05f7097158f606c6562f92126650b89,openstack/python-keystoneclient,master,Ib20782f5b05f7097158f606c6562f92126650b89,Fixed grammatical errors in the V2 Client API doc,MERGED,2015-05-27 16:24:27.000000000,2015-05-28 06:43:35.000000000,2015-05-28 06:43:33.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 7191}, {'_account_id': 8119}, {'_account_id': 9382}, {'_account_id': 14920}]","[{'number': 1, 'created': '2015-05-27 16:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c9f1a0ed90b1c64a4dd8c5832058686b695e147c', 'message': 'Fixed grammatical errors in the V2 Client API doc\n\nIn the using-api-v2.rst document, various inconsistencies in spelling of\n""openstackDemo"" under the ""Creating Tenants"" and ""Creating Users"" sections.\n\nChange-Id: Ib20782f5b05f7097158f606c6562f92126650b89\nCloses-Bug: #1458015\n'}, {'number': 2, 'created': '2015-05-27 16:46:36.000000000', 'files': ['doc/source/using-api-v2.rst'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/519282d883233b60ce9f36f6a7ae271c4efdd166', 'message': 'Fixed grammatical errors in the V2 Client API doc\n\nIn the using-api-v2.rst document, various inconsistencies in spelling of\n""openstackDemo"", as well as the password under the ""Creating Tenants"" and\n""Creating Users"" sections.\n\nUpdated service names to adhere to the OpenStack service naming conventions.\n\nFixed capitalization of ""Client"" to ""client"".\n\nChange-Id: Ib20782f5b05f7097158f606c6562f92126650b89\nCloses-Bug: #1458015\n'}]",3,186074,519282d883233b60ce9f36f6a7ae271c4efdd166,12,6,2,14920,,,0,"Fixed grammatical errors in the V2 Client API doc

In the using-api-v2.rst document, various inconsistencies in spelling of
""openstackDemo"", as well as the password under the ""Creating Tenants"" and
""Creating Users"" sections.

Updated service names to adhere to the OpenStack service naming conventions.

Fixed capitalization of ""Client"" to ""client"".

Change-Id: Ib20782f5b05f7097158f606c6562f92126650b89
Closes-Bug: #1458015
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/74/186074/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/using-api-v2.rst'],1,c9f1a0ed90b1c64a4dd8c5832058686b695e147c,bug/1458015,This example will create a tenant named *openstackDemo*::in the openstackDemo tenant. We first need to retrieve the tenant::,This example will create a tenant named *openStackDemo*::in the opoenstackDemo tenant. We first need to retrieve the tenant::,2,2
openstack%2Fpython-keystoneclient~master~I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b,openstack/python-keystoneclient,master,I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b,Fixe example code in Using Sessions page,MERGED,2015-04-18 12:55:12.000000000,2015-05-28 06:41:13.000000000,2015-05-28 06:41:10.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6547}, {'_account_id': 7191}, {'_account_id': 8978}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-04-18 12:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e012e18bd9c4df0891249695e416a11171044abb', 'message': 'Fixes example code in Using Sessions page\n\n* Changes password object to use v2.Password\n* Changes project_id parameter to tenant_id\n\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\nCloses-bug: 1428309\n'}, {'number': 2, 'created': '2015-04-21 08:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5928f00ad2046003eff1222093efe5f59c33df04', 'message': 'Fixes example code in Using Sessions page\n\n* Changes project_id parameter to tenant_id\n\nCloses-bug: 1428309\n\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}, {'number': 3, 'created': '2015-04-21 08:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8e618a7486d5910930a2b68e2607a99dc18ccdd5', 'message': 'Fixes example code in Using Sessions page\n\n* Changes password object to use v2.Password\n* Changes project_id parameter to tenant_id\n\nCloses-bug: 1428309\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}, {'number': 4, 'created': '2015-04-21 08:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2bd2c569d1932f3cfa8c275dbc96abe9e732b6b4', 'message': 'Fixes example code in Using Sessions page\n\n* Changes project_id parameter to tenant_id\n\nCloses-bug: 1428309\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}, {'number': 5, 'created': '2015-05-19 00:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d61c52ce0a1f7506a2e24d31cb078c9a38e0aa89', 'message': 'Fixes example code in Using Sessions page\n\n* Changes project_id parameter to tenant_id\n\nCloses-bug: 1428309\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}, {'number': 6, 'created': '2015-05-22 19:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/81c8541dc9b0fe9a10f887bda0dc8b6bc5cfc925', 'message': 'Fixe example code in Using Sessions page\n\n* Adds the user_domain_id argument\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nCloses-bug: 1428309\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}, {'number': 7, 'created': '2015-05-27 16:30:13.000000000', 'files': ['doc/source/using-sessions.rst'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/416a3c1c4f0b29a2c366e90b70da3948dc9ba912', 'message': 'Fixe example code in Using Sessions page\n\n* Changes the auth_url to use /v3\n* Adds the user_domain_id argument\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nCloses-bug: 1428309\nChange-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b\n'}]",3,175135,416a3c1c4f0b29a2c366e90b70da3948dc9ba912,26,8,7,14474,,,0,"Fixe example code in Using Sessions page

* Changes the auth_url to use /v3
* Adds the user_domain_id argument

Co-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>

Closes-bug: 1428309
Change-Id: I8471d9fbbd4d14cbb60395f90e8e61b9ed9f7d3b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/35/175135/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/using-sessions.rst'],1,e012e18bd9c4df0891249695e416a11171044abb,bug/1428309," >>> auth = v2.Password(auth_url='https://my.keystone.com:5000/v2.0', ... tenant_id='proj')"," >>> auth = v3.Password(auth_url='https://my.keystone.com:5000/v2.0', ... project_id='proj')",2,2
openstack%2Fheat~master~I5d274acf17f222c493d10ded50f87e05a075b424,openstack/heat,master,I5d274acf17f222c493d10ded50f87e05a075b424,Rename OS::Heat::StructuredDeployments,MERGED,2015-05-26 13:23:43.000000000,2015-05-28 06:40:37.000000000,2015-05-26 17:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7193}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 12321}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-05-26 13:23:43.000000000', 'files': ['heat/tests/test_structured_config.py', 'heat/tests/test_engine_service.py', 'heat/engine/resources/openstack/heat/structured_config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1339f0a0b103c140be16653f5907ce7d7d44fe95', 'message': ""Rename OS::Heat::StructuredDeployments\n\nRename the StructuredDeployments resource to StructuredDeploymentGroup\nto avoid awkward situations when talking about the plural form of the\nStructuredDeployment resource. This has been agreed at the Vancouver\nsummit.\n\nThe existing 'StructuredDeployments' resource is kept for backwards\ncompatibility, but with a deprecated status and corresponding\ndeprecation message.\n\nCloses-Bug: #1458008\n\nChange-Id: I5d274acf17f222c493d10ded50f87e05a075b424\n""}]",3,185590,1339f0a0b103c140be16653f5907ce7d7d44fe95,14,8,1,7193,,,0,"Rename OS::Heat::StructuredDeployments

Rename the StructuredDeployments resource to StructuredDeploymentGroup
to avoid awkward situations when talking about the plural form of the
StructuredDeployment resource. This has been agreed at the Vancouver
summit.

The existing 'StructuredDeployments' resource is kept for backwards
compatibility, but with a deprecated status and corresponding
deprecation message.

Closes-Bug: #1458008

Change-Id: I5d274acf17f222c493d10ded50f87e05a075b424
",git fetch https://review.opendev.org/openstack/heat refs/changes/90/185590/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_structured_config.py', 'heat/tests/test_engine_service.py', 'heat/engine/resources/openstack/heat/structured_config.py']",3,1339f0a0b103c140be16653f5907ce7d7d44fe95,bug/1458008,"class StructuredDeploymentGroup(sd.SoftwareDeploymentGroup):class StructuredDeployments(StructuredDeploymentGroup): deprecation_msg = _('This resource is deprecated and use is discouraged. ' 'Please use resource ' 'OS::Heat:StructuredDeploymentGroup instead.') support_status = support.SupportStatus(status=support.DEPRECATED, message=deprecation_msg, version='2014.2') 'OS::Heat::StructuredDeploymentGroup': StructuredDeploymentGroup,",class StructuredDeployments(sd.SoftwareDeploymentGroup):,22,8
openstack%2Fheat~master~Iae38b4afcb924ba626eccadfd68712e708be2bff,openstack/heat,master,Iae38b4afcb924ba626eccadfd68712e708be2bff,Rename OS::Heat::SoftwareDeployments,MERGED,2015-05-26 13:23:43.000000000,2015-05-28 06:37:27.000000000,2015-05-26 15:39:56.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7193}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-05-26 13:23:43.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/resources/openstack/heat/software_deployment.py', 'heat/tests/test_software_deployment.py', 'heat/engine/resources/openstack/heat/structured_config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/94c2c5fc48cfd317348d84284ca9da655b531ab5', 'message': ""Rename OS::Heat::SoftwareDeployments\n\nRename the SoftwareDeployments resource to SoftwareDeploymentGroup to\navoid awkward situations when talking about the plural form of the\nSoftwareDeployment resource. This has been agreed at the Vancouver\nsummit.\n\nThe existing 'SoftwareDeployments' resource is kept for backwards\ncompatibility, but with a deprecated status and corresponding\ndeprecation message.\n\nChange-Id: Iae38b4afcb924ba626eccadfd68712e708be2bff\nPartial-Bug: #1458008\n""}]",0,185589,94c2c5fc48cfd317348d84284ca9da655b531ab5,12,6,1,7193,,,0,"Rename OS::Heat::SoftwareDeployments

Rename the SoftwareDeployments resource to SoftwareDeploymentGroup to
avoid awkward situations when talking about the plural form of the
SoftwareDeployment resource. This has been agreed at the Vancouver
summit.

The existing 'SoftwareDeployments' resource is kept for backwards
compatibility, but with a deprecated status and corresponding
deprecation message.

Change-Id: Iae38b4afcb924ba626eccadfd68712e708be2bff
Partial-Bug: #1458008
",git fetch https://review.opendev.org/openstack/heat refs/changes/89/185589/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/resources/openstack/heat/software_deployment.py', 'heat/tests/test_software_deployment.py', 'heat/engine/resources/openstack/heat/structured_config.py']",4,94c2c5fc48cfd317348d84284ca9da655b531ab5,bug/1458008,"class StructuredDeployments(sd.SoftwareDeploymentGroup): sd.SoftwareDeploymentGroup.SERVERS, sd.SoftwareDeploymentGroup.CONFIG, sd.SoftwareDeploymentGroup.INPUT_VALUES, sd.SoftwareDeploymentGroup.DEPLOY_ACTIONS, sd.SoftwareDeploymentGroup.NAME, sd.SoftwareDeploymentGroup.SIGNAL_TRANSPORT, _sds_ps = sd.SoftwareDeploymentGroup.properties_schema","class StructuredDeployments(sd.SoftwareDeployments): sd.SoftwareDeployments.SERVERS, sd.SoftwareDeployments.CONFIG, sd.SoftwareDeployments.INPUT_VALUES, sd.SoftwareDeployments.DEPLOY_ACTIONS, sd.SoftwareDeployments.NAME, sd.SoftwareDeployments.SIGNAL_TRANSPORT, _sds_ps = sd.SoftwareDeployments.properties_schema",32,19
openstack%2Fcinder~master~Ic93340eebbcfdc73c49fffb2e6a4c5760afdd951,openstack/cinder,master,Ic93340eebbcfdc73c49fffb2e6a4c5760afdd951,Unit test for cmd/manage.py get_arg_string function,ABANDONED,2015-05-27 23:40:53.000000000,2015-05-28 06:34:18.000000000,,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 14242}, {'_account_id': 15374}, {'_account_id': 16160}]","[{'number': 1, 'created': '2015-05-27 23:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d37ceee761e1a99b8cf88cfd77b6797a809faad', 'message': 'Unit test for cmd/manage.py get_arg_string function\n\nChange-Id: Ic93340eebbcfdc73c49fffb2e6a4c5760afdd951\n'}, {'number': 2, 'created': '2015-05-27 23:43:10.000000000', 'files': ['cinder/tests/unit/test_cmd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/31c7a408f46f38c04df0d156ea7b9c6717c08988', 'message': 'Unit test for cmd/manage.py get_arg_string function\n\nChange-Id: Ic93340eebbcfdc73c49fffb2e6a4c5760afdd951\nCloses-Bug: #1459453\n'}]",0,186227,31c7a408f46f38c04df0d156ea7b9c6717c08988,17,11,2,15904,,,0,"Unit test for cmd/manage.py get_arg_string function

Change-Id: Ic93340eebbcfdc73c49fffb2e6a4c5760afdd951
Closes-Bug: #1459453
",git fetch https://review.opendev.org/openstack/cinder refs/changes/27/186227/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_cmd.py'],1,7d37ceee761e1a99b8cf88cfd77b6797a809faad,cmd_manage_unit_test," def test_get_arg_string(self): args1 = ""foobar"" args2 = ""-foo bar"" args3 = ""--foo bar"" self.assertEqual(""foobar"", cinder_manage.get_arg_string(args1)) self.assertEqual(""foo bar"", cinder_manage.get_arg_string(args2)) self.assertEqual(""foo bar"", cinder_manage.get_arg_string(args3)) ",,9,0
openstack%2Ffuel-web~master~Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35,openstack/fuel-web,master,Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35,Disable ability to use certain bond modes in UI,MERGED,2015-05-27 17:17:49.000000000,2015-05-28 06:32:34.000000000,2015-05-28 05:24:14.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 7468}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-27 17:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ea00b9d4096e238ad0f8fb011a71103dbe8c4711', 'message': ""Disable ability to use certain bond modes in UI\n\nThis will hide 'broadcast', 'balance-xor', 'balance-alb', 'balance-tlb'\nlinux bond modes from UI.\n\nChange-Id: Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35\nCloses-Bug: #1458935\n""}, {'number': 2, 'created': '2015-05-27 17:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ab9d64df1af51673ef22f18031de91f539bc290f', 'message': ""Disable ability to use certain bond modes in UI\n\nThis will hide 'broadcast', 'balance-xor', 'balance-alb', 'balance-tlb'\nlinux bond modes from UI in non-experimental mode.\n\nChange-Id: Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35\nCloses-Bug: #1458935\n""}, {'number': 3, 'created': '2015-05-27 17:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b3a760c9458ff67300fb42c06275d829d9f1d7ee', 'message': ""Disable ability to use certain bond modes in UI\n\nThis will hide 'broadcast', 'balance-xor', 'balance-alb', 'balance-tlb'\nlinux bond modes from UI in non-experimental mode.\n\nChange-Id: Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35\nCloses-Bug: #1458935\n""}, {'number': 4, 'created': '2015-05-27 20:05:22.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/release.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2f5ffd9f238cd2b0428937bc31580182a5e1d2c1', 'message': ""Disable ability to use certain bond modes in UI\n\nThis will hide 'broadcast', 'balance-xor', 'balance-alb', 'balance-tlb'\nlinux bond modes from UI in non-experimental mode.\n\nChange-Id: Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35\nRelated-Bug: #1458935\n""}]",1,186088,2f5ffd9f238cd2b0428937bc31580182a5e1d2c1,34,11,4,8392,,,0,"Disable ability to use certain bond modes in UI

This will hide 'broadcast', 'balance-xor', 'balance-alb', 'balance-tlb'
linux bond modes from UI in non-experimental mode.

Change-Id: Ie290bb4fdf880b4c8fbdcc72f2e08e9086dacf35
Related-Bug: #1458935
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/88/186088/4 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,ea00b9d4096e238ad0f8fb011a71103dbe8c4711,bug/1458935," - values: [""balance-rr"", ""active-backup"", ""802.3ad""] for_modes: [""802.3ad""]"," - values: [""balance-rr"", ""balance-xor"", ""active-backup"", ""broadcast"", ""802.3ad"", ""balance-tlb"", ""balance-alb""] for_modes: [""802.3ad"", ""balance-xor"", ""balance-tlb"", ""balance-alb""]",2,2
openstack%2Fswift-specs~master~I22a0e4c12dbfa38760fae58c60fa782e530e4f77,openstack/swift-specs,master,I22a0e4c12dbfa38760fae58c60fa782e530e4f77,Increasing ring partition power,MERGED,2015-02-04 14:55:19.000000000,2015-05-28 06:24:48.000000000,2015-05-28 06:24:48.000000000,"[{'_account_id': 3}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 12193}, {'_account_id': 14967}]","[{'number': 1, 'created': '2015-02-04 14:55:19.000000000', 'files': ['specs/in_progress/increasing_partition_power.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/1e00e8564b0b2b4ff985c659b31ed7d8063b784d', 'message': 'Increasing ring partition power\n\nThis document describes a process and\nmodifications to swift code that together\nenable ring partition power to be increased\nwithout cluster downtime.\n\nChange-Id: I22a0e4c12dbfa38760fae58c60fa782e530e4f77\n'}]",1,152935,1e00e8564b0b2b4ff985c659b31ed7d8063b784d,12,6,1,7847,,,0,"Increasing ring partition power

This document describes a process and
modifications to swift code that together
enable ring partition power to be increased
without cluster downtime.

Change-Id: I22a0e4c12dbfa38760fae58c60fa782e530e4f77
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/35/152935/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/increasing_partition_power.rst'],1,1e00e8564b0b2b4ff985c659b31ed7d8063b784d,p-ring-power,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Increasing ring partition power =============================== This document describes a process and modifications to swift code that together enable ring partition power to be increased without cluster downtime. Swift operators sometimes pick a ring partition power when deploying swift and later wish to change the partition power: #. The operator chooses a partition power that proves to be too small and subsequently constrains their ability to rebalance a growing cluster. #. Perhaps more likely, in an attempt to avoid the above problem, operators choose a partition power that proves to be unnecessarily large and would subsequently like to reduce it. This proposal directly addresses the first problem by enabling partition power to be increased. Although it does not directly address the second problem (i.e. it does not enable ring power reduction), it does indirectly help to avoid that problem by removing the motivation to choose large partition power when first deploying a cluster. Problem Description =================== The ring power determines the partition to which a resource (account, container or object) is mapped. The partition is included in the path under which the resource is stored in a backend filesystem. Changing the partition power therefore requires relocating resources to new paths in backend filesystems. In a heavily populated cluster a relocation process could be time-consuming and so to avoid down-time it is desirable to relocate resources while the cluster is still operating. However, it is necessary to do so without (temporary) loss of access to data and without compromising the performance of processes such as replication and auditing. Proposed Change =============== Overview -------- The proposed solution avoids copying any file contents during a partition power change. Objects are 'moved' from their current partition to a new partition, but the current and new partitions are arranged to be on the same device, so the 'move' is achieved using filesystem links without copying data. (It may well be that the motivation for increasing partition power is to allow a rebalancing of the ring. Any rebalancing would occur after the partition power increase has completed - during partition power changes the ring balance is not changed.) To allow the cluster to continue operating during a partition power change (in particular, to avoid any disruption or incorrect behavior of the replicator and auditor processes), new partition directories are created in a separate filesystem branch from the current partition directories. When all new partition directories have been populated, the ring transitions to using the new filesystem branch. During this transition, object servers maintain links to resource files from both the current and new partition directories. However, as already discussed, no file content is duplicated or copied. The old partition directories are eventually deleted. Detailed description -------------------- The process of changing a ring's partition power comprises three phases: 1. Preparation - during this phase the current partition directories continue to be used but existing resources are also linked to new partition directories in anticipation of the new ring partition power. 2. Switchover - during this phase the ring transitions to using the new partition directories; proxy and backend servers rollover to using the new ring partition power. 3. Cleanup - once all servers are using the new ring partition power, resource files in old partition directories are removed. For simplicity, we describe the details of each phase in terms of an object ring but note that the same process can be applied to account and container rings and servers. Preparation phase ^^^^^^^^^^^^^^^^^ During the preparation phase two new attributes are set in the ring file: * the ring's `epoch`: if not already set, a new `epoch` attribute is added to the ring. The ring epoch is used to determine the parent directory for partition directories. Similar to the way in which a ring's policy index is appended to the `objects` directory name, the epoch will be prefixed to the `objects` directory name. For simplicity, the ring epoch will be a monotonically increasing integer starting at 0. A 'legacy' ring having no epoch attribute will be treated as having epoch 0. * the `next_part_power` attribute indicates the partition power that will be used in the next epoch of the ring. The `next_part_power` attribute is used during the preparation phase to determine the partition directory in which an object should be stored in the next epoch of the ring. At this point in time no other changes are made to the ring file: the current part power and the mapping of partitions to devices are unchanged. The updated ring file is distributed to all servers. During this preparation phase, proxy servers will continue to use the current ring partition mapping to determine the backend url for objects. Object servers, along with replicator and auditor processes, also continue to use the current ring parameters. However, during PUT and DELETE operations object servers will create additional links to object files in the object's future partition directory in preparation for an eventual switchover to the ring's next epoch. This does not require any additional copying or writing of object contents. The filesystem path for future partition directories is determined as follows. In general, the path to an object file on an object server's filesystem has the form:: dev/[<epoch>-]objects[-<policy>]/<partition>/<suffix>/<hash>/<ts>.<ext> where: * `epoch` is the ring's epoch, if non-zero * `policy` is the object container's policy index, if non-zero * `dev` is the device to which `partition` is mapped by the ring file * `partition` is the object's partition, calculated using `partition = F(hash) >> (32 - P)`, where `P` is the ring partition power * `suffix` is the last three digits of `hash` * `hash` is a hash of the object name * `ts` is the object timestamp * `ext` is the filename extension (`data`, `meta` or `ts`) Given `next_part_power` and `epoch` in the ring file, it is possible to calculate:: future_partition = F(hash) >> (32 - next_part_power) next_epoch = epoch + 1 The future partition directory is then:: dev/<next_epoch>-objects[-<policy>]/<next_partition>/<suffix>/<hash>/<ts>.<ext> For example, consider a ring in its first epoch, with current partition power P, containing an object currently in partition X, where 0 <= X < 2**P. If the partition power increases by a factor of 2, the object's future partition will be either 2X or 2X+1 in the ring's next epoch. During a DELETE an additional filesystem link will be created at one of:: dev/1-objects/<2X>/<suffix>/<hash>/<ts>.ts dev/1-objects/<2X+1>/<suffix>/<hash>/<ts>.ts Once object servers are known to be using the updated ring file a new relinker process is started. The relinker prepares an object server's filesystem for a partition power change by crawling the filesystem and linking existing objects to future partition directories. The relinker determines each object's future partition directory in the same way as described above for the object server. The relinker does not remove links from current partition directories. Once the relinker has successfully completed, every existing object should be linked from both a current partition directory and a future partition directory. Any subsequent object PUTs or DELETEs will be reflected in both the current and future partition directory as described above. To avoid newly created objects being 'lost', it is important that an object server is using the updated ring file before the relinker process starts in order to guarantee that either the object server or the relinker create future partition links for every object. This may require object servers to be restarted prior to the relinker process being started, or to otherwise report that they have reloaded the ring file. The relinker will report successful completion in a file `/var/cache/swift/relinker.recon` that can be queried via (modified) recon middleware. Once the relinker process has successfully completed on all object servers, the partition power change process may move on to the switchover phase. Switchover phase ^^^^^^^^^^^^^^^^ To begin the switchover to using the next partition power, the ring file is updated once more: * the current partition power is stored as `previous_part_power` * the current partition power is set to `next_partition_power` * `next_partition_power` is set to None * the ring's `epoch` is incremented * the mapping of partitions to devices is re-created so that partitions 2X and 2X+1 map to the same devices to which partition X was mapped in the previous epoch. This is a simple transformation. Since no object content is moved between devices the actual ring balance remains unchanged. The updated ring file is then distributed to all proxy and object servers. Since ring file distribution and loading is not instantaneous, there is a window of time during which a proxy server may direct object requests to either an old partition or a current partition (note that the partitions previously referred to as 'future' are now referred to as 'current'). Object servers will therefore create additional filesystem links during PUT and DELETE requests, pointing from old partition directories to files in the current partition directories. The paths to the old partition directories are determined in the same way as future partition directories were determined during the preparation phase, but now using the `previous_part_power` and decrementing the current ring `epoch`. This means that if one proxy PUTs an object using a current partition, then another proxy subsequently attempts to GET the object using the old partition, the object will be found, since both current and old partitions map to the same device. Similarly if one proxy PUTs an object using the old partition and another proxy then GETs the object using the current partition, the object will be found in the current partition on the object server. The object auditor and replicator processes are restarted to force reloading of the ring file and commence to operate using the current ring parameters. Cleanup phase ^^^^^^^^^^^^^ The cleanup phase may start once all servers are known to be using the updated ring file. Once again, this may require servers to be restarted or to report that they have reloaded the ring file during switchover. A final update is made to the ring file: the `previous_partition_power` attribute is set to `None` and the ring file is once again distributed. Once object servers have reloaded the update ring file they will cease to create object file links in old partition directories. At this point the old partition directories may be deleted - there is no need to create tombstone files when deleting objects in the old partitions since these partition directories are no longer used by any swift process. A cleanup process will crawl the filesystem and delete any partition directories that are not part of the current epoch or a future epoch. This cleanup process should repeat periodically in case any devices that were offline during the partition power change come back online - the old epoch partition directories discovered on those devices may be deleted. Normal replication may cause current epoch partition directories to be created on a resurrected disk. (The cleanup function could be added to an existing process such as the auditor). Other considerations -------------------- swift-dispersion-[populate|report] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The swift-dispersion-[populate|report] tools will need to be made epoch-aware. After increasing partition power, swift-dispersion-populate may need to be run to achieve the desired coverage. (Although initially the device coverage will remain unchanged, the percentage of partitions covered will have reduced by whatever factor the partition power has increased.) Auditing ^^^^^^^^ During preparation and switchover, the auditor may find a corrupt object. The quarantine directory is not in the epoch partition directory filesystem branch, so a quarantined object will not be lost when old partitions are deleted. The quarantining of an object in a current partition directory will not remove the object from a future partition, so after switchover the auditor will discover the object again, and quarantine it again. The diskfile quarantine renamer could optionally be made 'relinker' aware and unlink duplicate object references when quarantining an object. Alternatives ------------ Prior work ^^^^^^^^^^ The swift_ring_tool_ enables ring power increases while swift services are disabled. It takes a similar approach to this proposal in that the ring mapping is changed so that every resource remains on the same device when moved to its new partition. However, new partitions are created in the same filesystem branch as existing (hence the need for services to be suspended during the relocation). .. _swift_ring_tool: https://github.com/enovance/swift-ring-tool/ Previous proposals have been made to upstream swift: https://bugs.launchpad.net/swift/+bug/933803 suggests a 'same-device' partition re-mapping, as does this proposal, but did not provide for relocation of resources to new partition directories. https://review.openstack.org/#/c/21888/ suggests maintaining a partition power per device (so only new devices use the increase partition power) but appears to have been abandoned due to complexities with replication. Create future partitions in existing `objects[-policy]` directory ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The duplication of filesystem entries for objects and creation of (potentially duplicate) partitions during the preparation phase could have undesirable effects on other backend processes if they are not isolated in another filesystem branch. For example, the object replicator is likely to discover newly created future partition directories that appear to be 'misplaced'. The replicator will attempt to sync these to their primary nodes (according to the old ring mapping) which is unnecessary. Worse, the replicator might then delete the future partitions from their current nodes, undoing the work of the relinker process. If the replicator were to adopt the future ring mappings from the outset of the preparation phase then the same problems arise with respect to current partitions that now appear to be misplaced. Furthermore, the replication process is likely to race with the relinker process on remote nodes to populate future partitions: if relocation proceeds faster on node A than B then the replicator may start to sync objects from A to B, which is again unnecessary and expensive. The auditor will also be impacted as it will discover objects in the future partition directories and audit them, being unable to distinguish them as duplicates of the object still stored in the current partition. These issues could of course be avoided by disabling replication and auditing during the preparation phase, but instead we propose to make the future ring partition naming be mutually exclusive from current ring partition naming, and simply restrict the replicator and auditor to only process partitions that are in the current ring partition set. In other words we isolate these processes from the future partition directories that are being created by the relinker. Use mutually exclusive future partitions in existing `objects` directory ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The current algorithm for calculating the partition for an object is to calculate a 32 bit hash of the object and then use its P most significant bits, resulting in partitions in the range {0, 2**P - 1}. i.e.:: part = H(object name) >> (32 - P) A ring with partition power P+1 will re-use all the partition numbers of a ring with partition power P. To eliminate overlap of future ring partitions with current ring partitions we could change the partition number algortihm to add an offset to each partition number when a ring's partition power is increased: offset = 2**P part = (H(object name) >> (32 - P)) + offset This is backwards compatible: if `offset` is not defined in a ring file then it is set to zero. To ensure that partition numbers remain < 2**32, this change will reduce the maximum partition power from 32 to 31. Proxy servers start to use the new ring at outset of relocation phase ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ This would mean that GETs to backends would use the new rings partitions in object urls. Objects may not yet have been relocated to their new partition directory and the object servers would therefore need to fall back to looking in the old ring partition for the object. PUTs and DELETEs to the new partition would need to be made conditional upon a newer object timestamp not existing in the old location. This is more complicated than the proposed method. Enable partition power reduction ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Ring power reduction is not easily achieved with the approach presented in this proposal because there is no guarantee that partitions in the current epoch that will be merged into partitions in the next epoch are located on the same device. File contents are therefore likely to need copying between devices during a preparation phase. Implementation ============== Assignee(s) ----------- Primary assignee: alistair.coles@hp.com Work Items ---------- #. modify ring classes to support new attributes #. modify ringbuilder to manage new attributes #. modify backend servers to duplicate links to files in future epoch partition directories #. make backend servers and relinker report their status in a way that recon can report e.g. servers report when a new ring epoch has been loaded, the relinker reports when all relinking has been completed. #. make recon support reporting these states #. modify code that assumes storage-directory is objects[-policy_index] to be aware of epoch prefix #. make swift-dispersion-populate and swift-dispersion-report epoch-aware #. implement relinker daemon #. document process Repositories ------------ No new git repositories will be created. Servers ------- No new servers are created. DNS Entries ----------- No DNS entries will to be created or updated. Documentation ------------- Process will be documented in the administrator's guide. Additions will be made to the ring-builder documents. Security -------- No security issues are foreseen. Testing ------- Unit tests will be added for changes to ring-builder, ring classes and object server. Probe tests will be needed to verify the process of increasing ring power. Functional tests will be unchanged. Dependencies ============ None ",,449,0
openstack%2Fheat~master~Id9cc30fddb604a1c1d63017cd2085c1f6a4ab9a3,openstack/heat,master,Id9cc30fddb604a1c1d63017cd2085c1f6a4ab9a3,Remove deprecated nova_utils,MERGED,2015-05-22 14:50:40.000000000,2015-05-28 06:23:58.000000000,2015-05-27 02:02:29.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 13009}, {'_account_id': 13323}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-05-22 14:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb0556a11f672713903a8dead54508901f21ecbc', 'message': 'Remove deprecated nova_utils\n\nRemove unused nova_utils and test_nova_utils according to\nhttps://etherpad.openstack.org/p/YVR-heat-liberty-deprecation\n\nChange-Id: Id9cc30fddb604a1c1d63017cd2085c1f6a4ab9a3\n'}, {'number': 2, 'created': '2015-05-26 10:42:42.000000000', 'files': ['heat/tests/test_nova_client.py', 'heat/tests/test_server.py', 'heat/engine/nova_utils.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1723900f69fd6a250871e0553a38f5112c29e96c', 'message': 'Remove deprecated nova_utils\n\nRemove unused nova_utils and test_nova_utils according to\nhttps://etherpad.openstack.org/p/YVR-heat-liberty-deprecation\n\nChange-Id: Id9cc30fddb604a1c1d63017cd2085c1f6a4ab9a3\n'}]",0,185038,1723900f69fd6a250871e0553a38f5112c29e96c,23,9,2,13323,,,0,"Remove deprecated nova_utils

Remove unused nova_utils and test_nova_utils according to
https://etherpad.openstack.org/p/YVR-heat-liberty-deprecation

Change-Id: Id9cc30fddb604a1c1d63017cd2085c1f6a4ab9a3
",git fetch https://review.opendev.org/openstack/heat refs/changes/38/185038/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/nova_utils.py', 'heat/tests/test_nova_utils.py']",2,cb0556a11f672713903a8dead54508901f21ecbc,remove-nova-utils,,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Tests for :module:'heat.engine.resources.nova_utls'."""""" import uuid import mock from novaclient import exceptions as nova_exceptions import six from heat.common import exception from heat.engine import nova_utils from heat.engine import scheduler from heat.tests import common from heat.tests.nova import fakes as fakes_nova class NovaUtilsTests(common.HeatTestCase): """""" Basic tests for the helper methods in :module:'heat.engine.nova_utils'. """""" def setUp(self): super(NovaUtilsTests, self).setUp() self.nova_client = self.m.CreateMockAnything() def test_get_ip(self): my_image = self.m.CreateMockAnything() my_image.addresses = { 'public': [{'version': 4, 'addr': '4.5.6.7'}, {'version': 6, 'addr': '2401:1801:7800:0101:c058:dd33:ff18:04e6'}], 'private': [{'version': 4, 'addr': '10.13.12.13'}]} expected = '4.5.6.7' observed = nova_utils.get_ip(my_image, 'public', 4) self.assertEqual(expected, observed) expected = '10.13.12.13' observed = nova_utils.get_ip(my_image, 'private', 4) self.assertEqual(expected, observed) expected = '2401:1801:7800:0101:c058:dd33:ff18:04e6' observed = nova_utils.get_ip(my_image, 'public', 6) self.assertEqual(expected, observed) def test_get_flavor_id(self): """"""Tests the get_flavor_id function."""""" flav_id = str(uuid.uuid4()) flav_name = 'X-Large' my_flavor = self.m.CreateMockAnything() my_flavor.name = flav_name my_flavor.id = flav_id self.nova_client.flavors = self.m.CreateMockAnything() self.nova_client.flavors.list().MultipleTimes().AndReturn([my_flavor]) self.m.ReplayAll() self.assertEqual(flav_id, nova_utils.get_flavor_id(self.nova_client, flav_name)) self.assertEqual(flav_id, nova_utils.get_flavor_id(self.nova_client, flav_id)) self.assertRaises(exception.FlavorMissing, nova_utils.get_flavor_id, self.nova_client, 'noflavor') self.m.VerifyAll() def test_get_keypair(self): """"""Tests the get_keypair function."""""" my_pub_key = 'a cool public key string' my_key_name = 'mykey' my_key = self.m.CreateMockAnything() my_key.public_key = my_pub_key my_key.name = my_key_name self.nova_client.keypairs = self.m.CreateMockAnything() self.nova_client.keypairs.get( my_key_name).AndReturn(my_key) self.nova_client.keypairs.get( 'notakey').AndRaise(fakes_nova.fake_exception()) self.m.ReplayAll() self.assertEqual(my_key, nova_utils.get_keypair(self.nova_client, my_key_name)) self.assertRaises(exception.UserKeyPairMissing, nova_utils.get_keypair, self.nova_client, 'notakey') self.m.VerifyAll() def test_delete_server(self): server = mock.Mock() server.status = ""DELETED"" task = scheduler.TaskRunner(nova_utils.delete_server, server) self.assertIsNone(task()) def test_delete_server_notfound(self): server = mock.Mock() server.delete.side_effect = nova_exceptions.NotFound(404) task = scheduler.TaskRunner(nova_utils.delete_server, server) self.assertIsNone(task()) def test_delete_noserver(self): task = scheduler.TaskRunner(nova_utils.delete_server, None) self.assertIsNone(task()) def test_delete_servererror(self): server = mock.Mock() server.name = ""myserver"" server.status = ""ERROR"" server.fault = { ""message"": ""test error"", } task = scheduler.TaskRunner(nova_utils.delete_server, server) err = self.assertRaises(exception.Error, task) self.assertIn(""myserver delete failed: (None) test error"", six.text_type(err)) class NovaUtilsRefreshServerTests(common.HeatTestCase): def test_successful_refresh(self): server = self.m.CreateMockAnything() server.get().AndReturn(None) self.m.ReplayAll() self.assertIsNone(nova_utils.refresh_server(server)) self.m.VerifyAll() def test_overlimit_error(self): server = mock.Mock() server.get.side_effect = fakes_nova.fake_exception(413) self.assertIsNone(nova_utils.refresh_server(server)) def test_500_error(self): server = self.m.CreateMockAnything() server.get().AndRaise(fakes_nova.fake_exception(500)) self.m.ReplayAll() self.assertIsNone(nova_utils.refresh_server(server)) self.m.VerifyAll() def test_503_error(self): server = self.m.CreateMockAnything() server.get().AndRaise(fakes_nova.fake_exception(503)) self.m.ReplayAll() self.assertIsNone(nova_utils.refresh_server(server)) self.m.VerifyAll() def test_unhandled_exception(self): server = self.m.CreateMockAnything() server.get().AndRaise(fakes_nova.fake_exception(501)) self.m.ReplayAll() self.assertRaises(nova_exceptions.ClientException, nova_utils.refresh_server, server) self.m.VerifyAll() class NovaUtilsUserdataTests(common.HeatTestCase): def setUp(self): super(NovaUtilsUserdataTests, self).setUp() self.nova_client = self.m.CreateMockAnything() def test_build_userdata(self): """"""Tests the build_userdata function."""""" resource = self.m.CreateMockAnything() resource.metadata_get().AndReturn({}) self.m.StubOutWithMock(nova_utils.cfg, 'CONF') cnf = nova_utils.cfg.CONF cnf.heat_metadata_server_url = 'http://server.test:123' cnf.heat_watch_server_url = 'http://server.test:345' cnf.instance_connection_is_secure = False cnf.instance_connection_https_validate_certificates = False self.m.ReplayAll() data = nova_utils.build_userdata(resource) self.assertIn(""Content-Type: text/cloud-config;"", data) self.assertIn(""Content-Type: text/cloud-boothook;"", data) self.assertIn(""Content-Type: text/part-handler;"", data) self.assertIn(""Content-Type: text/x-cfninitdata;"", data) self.assertIn(""Content-Type: text/x-shellscript;"", data) self.assertIn(""http://server.test:345"", data) self.assertIn(""http://server.test:123"", data) self.assertIn(""[Boto]"", data) self.m.VerifyAll() def test_build_userdata_without_instance_user(self): """"""Don't add a custom instance user when not requested."""""" resource = self.m.CreateMockAnything() resource.metadata_get().AndReturn({}) self.m.StubOutWithMock(nova_utils.cfg, 'CONF') cnf = nova_utils.cfg.CONF cnf.instance_user = 'config_instance_user' cnf.heat_metadata_server_url = 'http://server.test:123' cnf.heat_watch_server_url = 'http://server.test:345' self.m.ReplayAll() data = nova_utils.build_userdata(resource, instance_user=None) self.assertNotIn('user: ', data) self.assertNotIn('useradd', data) self.assertNotIn('config_instance_user', data) self.m.VerifyAll() def test_build_userdata_with_instance_user(self): """"""Add the custom instance user when requested."""""" resource = self.m.CreateMockAnything() resource.metadata_get().AndReturn(None) self.m.StubOutWithMock(nova_utils.cfg, 'CONF') cnf = nova_utils.cfg.CONF cnf.instance_user = 'config_instance_user' cnf.heat_metadata_server_url = 'http://server.test:123' cnf.heat_watch_server_url = 'http://server.test:345' self.m.ReplayAll() data = nova_utils.build_userdata(resource, instance_user=""custominstanceuser"") self.assertNotIn('config_instance_user', data) self.assertIn(""custominstanceuser"", data) self.m.VerifyAll() class NovaUtilsMetadataTests(common.HeatTestCase): def test_serialize_string(self): original = {'test_key': 'simple string value'} self.assertEqual(original, nova_utils.meta_serialize(original)) def test_serialize_int(self): original = {'test_key': 123} expected = {'test_key': '123'} self.assertEqual(expected, nova_utils.meta_serialize(original)) def test_serialize_list(self): original = {'test_key': [1, 2, 3]} expected = {'test_key': '[1, 2, 3]'} self.assertEqual(expected, nova_utils.meta_serialize(original)) def test_serialize_dict(self): original = {'test_key': {'a': 'b', 'c': 'd'}} expected = {'test_key': '{""a"": ""b"", ""c"": ""d""}'} self.assertEqual(expected, nova_utils.meta_serialize(original)) def test_serialize_none(self): original = {'test_key': None} expected = {'test_key': 'null'} self.assertEqual(expected, nova_utils.meta_serialize(original)) def test_serialize_combined(self): original = { 'test_key_1': 123, 'test_key_2': 'a string', 'test_key_3': {'a': 'b'}, 'test_key_4': None, } expected = { 'test_key_1': '123', 'test_key_2': 'a string', 'test_key_3': '{""a"": ""b""}', 'test_key_4': 'null', } self.assertEqual(expected, nova_utils.meta_serialize(original)) ",0,665
openstack%2Fcinder~master~I6477164af0a60997be295587e506b37d7e019bcf,openstack/cinder,master,I6477164af0a60997be295587e506b37d7e019bcf,Brocade driver not parsing zone data correctly,MERGED,2015-05-20 11:22:15.000000000,2015-05-28 05:51:51.000000000,2015-05-26 16:48:54.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 16160}, {'_account_id': 16203}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-20 11:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a32af9885c05f1b102c3f05386fe3158354dcaf', 'message': 'Fix a bug in brocade driver\n\nBrocade driver does not handle switch data correctly.\n\nChange-Id: I6477164af0a60997be295587e506b37d7e019bcf\nCloses-Bug: 1456996\n'}, {'number': 2, 'created': '2015-05-26 04:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd64c3e563a7fe3884afd00d8a0462d4503d8df2', 'message': 'Brocade driver not parsing zone data correctly\n\nThere is an error in the parsing of zone information\nin the Brocade zone manager driver. This patch ensures\nthe zone information is correctly parsed.\n\nCloses-Bug: 1456996\nChange-Id: I6477164af0a60997be295587e506b37d7e019bcf\n'}, {'number': 3, 'created': '2015-05-26 06:43:33.000000000', 'files': ['cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b37cda69f0a73f9f565e3c45be7f5843938d3040', 'message': 'Brocade driver not parsing zone data correctly\n\nThere is an error in the parsing of zone information\nin the Brocade zone manager driver. This patch ensures\nthe zone information is correctly parsed.\n\nCloses-Bug: 1456996\nChange-Id: I6477164af0a60997be295587e506b37d7e019bcf\n'}]",9,184458,b37cda69f0a73f9f565e3c45be7f5843938d3040,63,34,3,13203,,,0,"Brocade driver not parsing zone data correctly

There is an error in the parsing of zone information
in the Brocade zone manager driver. This patch ensures
the zone information is correctly parsed.

Closes-Bug: 1456996
Change-Id: I6477164af0a60997be295587e506b37d7e019bcf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/184458/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'],1,4a32af9885c05f1b102c3f05386fe3158354dcaf,bug/1456996, zone_member = None,,1,0
openstack%2Fneutron~master~Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4,openstack/neutron,master,Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4,Add port-security extension API test cases,MERGED,2015-03-26 08:01:38.000000000,2015-05-28 05:43:00.000000000,2015-05-27 14:41:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 11114}, {'_account_id': 11343}, {'_account_id': 12040}, {'_account_id': 12378}, {'_account_id': 13063}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14743}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15637}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-03-26 08:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a443c25e76f40a714b89c32d9d4eda5ee60980f6', 'message': 'Add port-security extension API cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\n'}, {'number': 2, 'created': '2015-03-26 08:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ae426e9e6cffee72c00d06b70ed36b18a7db3e9', 'message': 'Add port-security extension API cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\n'}, {'number': 3, 'created': '2015-04-02 06:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6085ec8735c93c8e969785f803881b800d65e788', 'message': 'Add port-security extension API cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\n'}, {'number': 4, 'created': '2015-04-09 06:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7dd702db069b34611df2353ecb9d29edb93abb1', 'message': 'Add port-security extension API test cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\n'}, {'number': 5, 'created': '2015-04-09 07:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b861846a9fe72b54af2a4002b21cff997717749e', 'message': 'Add port-security extension API test cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\n'}, {'number': 6, 'created': '2015-04-12 03:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b8b812289eb223a9f5db89300325d2dc7c75f40', 'message': 'Add port-security extension API test cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\nPartially Implements: blueprint ml2-ovs-portsecurity\nDepends-On: I3035317c83d22804855517434bd8578719ce0436\n'}, {'number': 7, 'created': '2015-05-05 11:17:05.000000000', 'files': ['neutron/tests/api/test_extension_driver_port_security.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5509839e0af89467eb14ee178807e2898202101b', 'message': 'Add port-security extension API test cases\n\nNetron ml2 plugin introduces a new extension port-security from Kilo cycle,\nthis patch add the API test cases for it. It verifies the default value of the\nattribute, for network and port. And It also verifies the confict between\nsetting port-security and sec-group/address-pairs.\n\nChange-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4\nPartially Implements: blueprint ml2-ovs-portsecurity\nDepends-On: I3035317c83d22804855517434bd8578719ce0436\n'}]",18,167910,5509839e0af89467eb14ee178807e2898202101b,172,48,7,11114,,,0,"Add port-security extension API test cases

Netron ml2 plugin introduces a new extension port-security from Kilo cycle,
this patch add the API test cases for it. It verifies the default value of the
attribute, for network and port. And It also verifies the confict between
setting port-security and sec-group/address-pairs.

Change-Id: Ie0ec090e8fdce7dbdbce14ef47f38e8e57f262d4
Partially Implements: blueprint ml2-ovs-portsecurity
Depends-On: I3035317c83d22804855517434bd8578719ce0436
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/167910/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/network/test_extension_driver_port_security.py'],1,a443c25e76f40a714b89c32d9d4eda5ee60980f6,port-security-testing,"# Copyright 2015 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron.tests.tempest.api.network import base_security_groups as base from neutron.tests.tempest import config from neutron.tests.tempest import test from tempest_lib.common.utils import data_utils from tempest_lib import exceptions as lib_exc CONF = config.CONF FAKE_IP = '10.0.0.1' FAKE_MAC = '00:25:64:e8:19:dd' class PortSecTest(base.BaseSecGroupTest): _tenant_network_cidr = CONF.network.tenant_network_cidr @classmethod def resource_setup(cls): super(PortSecTest, cls).resource_setup() def _create_network(self, network_name=None, port_security_enabled=True): """"""Wrapper utility that returns a test network."""""" network_name = network_name or data_utils.rand_name('test-network-') body = self.client.create_network( name=network_name, port_security_enabled=port_security_enabled) network = body['network'] self.networks.append(network) return network @test.attr(type='smoke') @test.idempotent_id('7c338ddf-e64e-4118-bd33-e49a1f2f1495') @test.requires_ext(extension='port-security', service='network') def test_port_sec_default(self): # Default port-sec value is True, and the attr of the port will inherit # from the port-sec of the network when it not be specified in API network = self.create_network() self.create_subnet(network) self.assertTrue(network['port_security_enabled']) port = self.create_port(network) self.assertTrue(port['port_security_enabled']) @test.attr(type='smoke') @test.idempotent_id('e60eafd2-31de-4c38-8106-55447d033b57') @test.requires_ext(extension='port-security', service='network') def test_port_sec_none_default(self): network = self.create_network() self.assertTrue(network['port_security_enabled']) self.create_subnet(network) port = self.create_port(network, port_security_enabled=False) self.assertFalse(port['port_security_enabled']) # Create a network with port-sec set to False network = self._create_network(port_security_enabled=False) self.assertFalse(network['port_security_enabled']) self.create_subnet(network) port = self.create_port(network, port_security_enabled=True) self.assertTrue(port['port_security_enabled']) @test.attr(type=['negative', 'smoke']) @test.idempotent_id('05642059-1bfc-4581-9bc9-aaa5db08dd60') @test.requires_ext(extension='port-security', service='network') def test_port_sec_negative(self): network = self.create_network() self.create_subnet(network) port = self.create_port(network) # Exception when set port-sec to False with sec-group defined self.assertRaises(lib_exc.Conflict, self.update_port, port, port_security_enabled=False) updated_port = self.update_port( port, security_groups=[], port_security_enabled=False) self.assertFalse(updated_port['port_security_enabled']) allowed_address_pairs = [{'ip_address': FAKE_IP, 'mac_address': FAKE_MAC}] # Exception when set address-pairs with port-sec is False self.assertRaises(lib_exc.Conflict, self.update_port, port, allowed_address_pairs=allowed_address_pairs) ",,99,0
openstack%2Fkeystone-specs~master~Ib3cb926464c771bbf56f29f29145943b73e1ee63,openstack/keystone-specs,master,Ib3cb926464c771bbf56f29f29145943b73e1ee63,Fix assertion examples,MERGED,2015-05-27 13:38:27.000000000,2015-05-28 05:40:10.000000000,2015-05-28 05:40:08.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-05-27 13:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4920457cee26a8e76ed5d4cb878eb18331974c02', 'message': 'Fix assertion examples\n\nThe ""pure"" SAML assertion example wasn\'t a valid assertion generated\nby keystone and the ECP wrapped one was missing the two new attributes\n""openstack_user_domain"" and ""openstack_project_domain"".\n\nChange-Id: Ib3cb926464c771bbf56f29f29145943b73e1ee63\n'}, {'number': 2, 'created': '2015-05-27 14:38:27.000000000', 'files': ['api/v3/identity-api-v3-os-federation-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/25980dd19af3c5f1d21dfa3152f354d9e38946d7', 'message': 'Fix assertion examples\n\nThe ""pure"" SAML assertion example wasn\'t a valid assertion generated\nby keystone and the ECP wrapped one was missing the two new attributes\n""openstack_user_domain"" and ""openstack_project_domain"".\n\nChange-Id: Ib3cb926464c771bbf56f29f29145943b73e1ee63\nCloses-Bug: 1459279\n'}]",0,185985,25980dd19af3c5f1d21dfa3152f354d9e38946d7,10,5,2,11022,,,0,"Fix assertion examples

The ""pure"" SAML assertion example wasn't a valid assertion generated
by keystone and the ECP wrapped one was missing the two new attributes
""openstack_user_domain"" and ""openstack_project_domain"".

Change-Id: Ib3cb926464c771bbf56f29f29145943b73e1ee63
Closes-Bug: 1459279
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/85/185985/1 && git format-patch -1 --stdout FETCH_HEAD,['api/v3/identity-api-v3-os-federation-ext.rst'],1,4920457cee26a8e76ed5d4cb878eb18331974c02,," <ns0:Response xmlns:ns0=""urn:oasis:names:tc:SAML:2.0:protocol"" xmlns:saml=""urn:oasis:names:tc:SAML:2.0:assertion"" xmlns:xmldsig=""http://www.w3.org/2000/09/xmldsig#"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" Destination=""http://beta.example.com/Shibboleth.sso/POST/ECP"" ID=""818dee98a5d44a238ae3038d26cbebb6"" IssueInstant=""2015-05-27T13:23:48Z"" Version=""2.0""> <saml:Issuer Format=""urn:oasis:names:tc:SAML:2.0:nameid-format:entity"">http://keystone.idp/v3/OS-FEDERATION/saml2/idp</saml:Issuer> <ns0:Status> <ns0:StatusCode Value=""urn:oasis:names:tc:SAML:2.0:status:Success""/> </ns0:Status> <saml:Assertion ID=""68237000470e47a690bdd513bb264460"" IssueInstant=""2015-05-27T13:23:47Z"" Version=""2.0""> <saml:Issuer Format=""urn:oasis:names:tc:SAML:2.0:nameid-format:entity"">http://keystone.idp/v3/OS-FEDERATION/saml2/idp</saml:Issuer> <xmldsig:Signature> <xmldsig:SignedInfo> <xmldsig:CanonicalizationMethod Algorithm=""http://www.w3.org/2001/10/xml-exc-c14n#""/> <xmldsig:SignatureMethod Algorithm=""http://www.w3.org/2000/09/xmldsig#rsa-sha1""/> <xmldsig:Reference URI=""#68237000470e47a690bdd513bb264460""> <xmldsig:Transforms> <xmldsig:Transform Algorithm=""http://www.w3.org/2000/09/xmldsig#enveloped-signature""/> <xmldsig:Transform Algorithm=""http://www.w3.org/2001/10/xml-exc-c14n#""/> </xmldsig:Transforms> <xmldsig:DigestMethod Algorithm=""http://www.w3.org/2000/09/xmldsig#sha1""/> <xmldsig:DigestValue>IgfoWcCoBpmv64ianaK/qj63QQQ=</xmldsig:DigestValue> </xmldsig:Reference> </xmldsig:SignedInfo> <xmldsig:SignatureValue>H6GvkAcDW0BSoBaktpVTxUFtvUAcFMXRqYXLFvmse5DeOSnByvGOgW/yJMjIqzwG LjCqJXYMePIkEUYb4kqbbkN1wNFuxKtmACcC3T3/7rAavrIz3I4cT6mCipN9qFlE tzR0mD2IZhExuTzyMaON8krTWWoddx8LIYEfQ03O4eSYObi5fHmGJRGs9D5De0aK XkIeKo7HRAjZsU5fAMGlEKfazemTZMBbnpUD//oFsxf1yFcFTOyiAHddAaG7Rqv3 4SYjYo4dRKAI/yQuA+MVmHDcJUE+KVqVoJZJSVJe+Lz+X1ReRlEgvP0mhaM0yY+R w7FozqQyKSKJW9abmxJTFQ==</xmldsig:SignatureValue> <xmldsig:KeyInfo> <xmldsig:X509Data> <xmldsig:X509Certificate>...</xmldsig:X509Certificate> </xmldsig:X509Data> </xmldsig:KeyInfo> </xmldsig:Signature> <saml:Subject> <saml:NameID>admin</saml:NameID> <saml:SubjectConfirmation Method=""urn:oasis:names:tc:SAML:2.0:cm:bearer""> <saml:SubjectConfirmationData NotOnOrAfter=""2015-05-27T14:23:47.711682Z"" Recipient=""http://beta.example.com/Shibboleth.sso/POST/ECP/""> </saml:SubjectConfirmation> </saml:Subject> <saml:AuthnStatement AuthnInstant=""2015-05-27T13:23:47Z"" SessionIndex=""cd839a3ff0fc4a4aab52e55fae8094a2"" SessionNotOnOrAfter=""2015-05-27T14:23:47.711682Z""> <saml:AuthnContext> <saml:AuthnContextClassRef>urn:oasis:names:tc:SAML:2.0:ac:classes:Password</saml:AuthnContextClassRef> <saml:AuthenticatingAuthority>http://keystone.idp/v3/OS-FEDERATION/saml2/idp</saml:AuthenticatingAuthority> </saml:AuthnContext> </saml:AuthnStatement> <saml:AttributeStatement> <saml:Attribute Name=""openstack_user"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">admin</saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""openstack_user_domain"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">Default</saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""openstack_roles"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">admin</saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""openstack_project"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">admin</saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""openstack_project_domain"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">Default</saml:AttributeValue> </saml:Attribute> </saml:AttributeStatement> </ns0:Response> <saml:Attribute Name=""openstack_user_domain"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">Default</saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""openstack_project_domain"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:uri""> <saml:AttributeValue xsi:type=""xs:string"">Default</saml:AttributeValue> </saml:Attribute>"," <samlp:Response ID=""_257f9d9e9fa14962c0803903a6ccad931245264310738"" IssueInstant=""2009-06-17T18:45:10.738Z"" Version=""2.0""> <saml:Issuer Format=""urn:oasis:names:tc:SAML:2.0:nameid-format:entity""> https://www.acme.com </saml:Issuer> <samlp:Status> <samlp:StatusCode Value=""urn:oasis:names:tc:SAML:2.0:status:Success""/> </samlp:Status> <saml:Assertion ID=""_3c39bc0fe7b13769cab2f6f45eba801b1245264310738"" IssueInstant=""2009-06-17T18:45:10.738Z"" Version=""2.0""> <saml:Issuer Format=""urn:oasis:names:tc:SAML:2.0:nameid-format:entity""> https://www.acme.com </saml:Issuer> <saml:Signature> <saml:SignedInfo> <saml:CanonicalizationMethod Algorithm=""http://www.w3.org/2001/10/xml-exc-c14n#""/> <saml:SignatureMethod Algorithm=""http://www.w3.org/2000/09/xmldsig#rsa-sha1""/> <saml:Reference URI=""#_3c39bc0fe7b13769cab2f6f45eba801b1245264310738""> <saml:Transforms> <saml:Transform Algorithm=""http://www.w3.org/2000/09/xmldsig#enveloped-signature""/> <saml:Transform Algorithm=""http://www.w3.org/2001/10/xml-exc-c14n#""> <ec:InclusiveNamespaces PrefixList=""ds saml xs""/> </saml:Transform> </saml:Transforms> <saml:DigestMethod Algorithm=""http://www.w3.org/2000/09/xmldsig#sha1""/> <saml:DigestValue>vzR9Hfp8d16576tEDeq/zhpmLoo= </saml:DigestValue> </saml:Reference> </saml:SignedInfo> <saml:SignatureValue> AzID5hhJeJlG2llUDvZswNUrlrPtR7S37QYH2W+Un1n8c6kTC Xr/lihEKPcA2PZt86eBntFBVDWTRlh/W3yUgGOqQBJMFOVbhK M/CbLHbBUVT5TcxIqvsNvIFdjIGNkf1W0SBqRKZOJ6tzxCcLo 9dXqAyAUkqDpX5+AyltwrdCPNmncUM4dtRPjI05CL1rRaGeyX 3kkqOL8p0vjm0fazU5tCAJLbYuYgU1LivPSahWNcpvRSlCI4e Pn2oiVDyrcc4et12inPMTc2lGIWWWWJyHOPSiXRSkEAIwQVjf Qm5cpli44Pv8FCrdGWpEE0yXsPBvDkM9jIzwCYGG2fKaLBag== </saml:SignatureValue> <saml:KeyInfo> <saml:X509Data> <saml:X509Certificate> MIIEATCCAumgAwIBAgIBBTANBgkqhkiG9w0BAQ0FADCBgzELM </saml:X509Certificate> </saml:X509Data> </saml:KeyInfo> </saml:Signature> <saml:Subject> <saml:NameID Format=""urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified""> saml01@acme.com </saml:NameID> <saml:SubjectConfirmation Method=""urn:oasis:names:tc:SAML:2.0:cm:bearer""> <saml:SubjectConfirmationData NotOnOrAfter=""2009-06-17T18:50:10.738Z"" Recipient=""https://login.www.beta.com""/> </saml:SubjectConfirmation> </saml:Subject> <saml:Conditions NotBefore=""2009-06-17T18:45:10.738Z"" NotOnOrAfter=""2009-06-17T18:50:10.738Z""> <saml:AudienceRestriction> <saml:Audience>https://saml.acme.com</saml:Audience> </saml:AudienceRestriction> </saml:Conditions> <saml:AuthnStatement AuthnInstant=""2009-06-17T18:45:10.738Z""> <saml:AuthnContext> <saml:AuthnContextClassRef>urn:oasis:names:tc:SAML:2.0:ac:classes:unspecified </saml:AuthnContextClassRef> </saml:AuthnContext> </saml:AuthnStatement> <saml:AttributeStatement> <saml:Attribute Name=""portal_id""> <saml:AttributeValue xsi:type=""xs:anyType"">060D00000000SHZ </saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""organization_id""> <saml:AttributeValue xsi:type=""xs:anyType"">00DD0000000F7L5 </saml:AttributeValue> </saml:Attribute> <saml:Attribute Name=""ssostartpage"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:unspecified""> <saml:AttributeValue xsi:type=""xs:anyType""> http://www.acme.com/security/saml/saml20-gen.jsp </saml:AttributeValue> </saml:Attribute> </saml:AttributeStatement> </samlp:Response>",68,84
openstack%2Fheat~master~I55d45048284c4e78b9a1a94a35ef3cddc7bc3a37,openstack/heat,master,I55d45048284c4e78b9a1a94a35ef3cddc7bc3a37,Run functional tests when no ceilometer endpoint,MERGED,2015-05-26 01:37:06.000000000,2015-05-28 05:35:16.000000000,2015-05-26 10:44:00.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-05-26 01:37:06.000000000', 'files': ['heat_integrationtests/common/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d0e5cad7f305e9cdcd7c41a168a89847a08d98d6', 'message': 'Run functional tests when no ceilometer endpoint\n\nCurrently if there is no metering endpoint in the service\ncatalog then no functional/integration tests can be done.\n\nThis change tolerates missing ceilometer endpoint.\n\nChange-Id: I55d45048284c4e78b9a1a94a35ef3cddc7bc3a37\n'}]",0,185480,d0e5cad7f305e9cdcd7c41a168a89847a08d98d6,10,5,1,4571,,,0,"Run functional tests when no ceilometer endpoint

Currently if there is no metering endpoint in the service
catalog then no functional/integration tests can be done.

This change tolerates missing ceilometer endpoint.

Change-Id: I55d45048284c4e78b9a1a94a35ef3cddc7bc3a37
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/185480/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/common/clients.py'],1,d0e5cad7f305e9cdcd7c41a168a89847a08d98d6,ceilo_endpoint," try: endpoint = keystone.service_catalog.url_for( attr='region', filter_value=self.conf.region, service_type='metering', endpoint_type='publicURL') except keystoneclient.exceptions.EndpointNotFound: return None else: args = { 'username': self.conf.username, 'password': self.conf.password, 'tenant_name': self.conf.tenant_name, 'auth_url': self.conf.auth_url, 'insecure': dscv, 'region_name': self.conf.region, 'endpoint_type': 'publicURL', 'service_type': 'metering', } return ceilometerclient.client.Client(self.CEILOMETER_VERSION, endpoint, **args)"," endpoint = keystone.service_catalog.url_for( attr='region', filter_value=self.conf.region, service_type='metering', endpoint_type='publicURL') args = { 'username': self.conf.username, 'password': self.conf.password, 'tenant_name': self.conf.tenant_name, 'auth_url': self.conf.auth_url, 'insecure': dscv, 'region_name': self.conf.region, 'endpoint_type': 'publicURL', 'service_type': 'metering', } return ceilometerclient.client.Client(self.CEILOMETER_VERSION, endpoint, **args)",21,17
openstack%2Fironic~master~Ied5a1967665b19877feef610607e5f0dbbd40ef9,openstack/ironic,master,Ied5a1967665b19877feef610607e5f0dbbd40ef9,Fix sync local state periodic task for standalone mode,ABANDONED,2015-05-26 08:45:37.000000000,2015-05-28 05:31:28.000000000,,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 9751}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2015-05-26 08:45:37.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5769e6f45fab11d9bdab117fbd1eb0e7f5f0beeb', 'message': 'Fix sync local state periodic task for standalone mode\n\nIf Ironic runs as standalone service we should not use Keystone API.\nThis patch fixes periodic task for nodes take over.\n\nChange-Id: Ied5a1967665b19877feef610607e5f0dbbd40ef9\n'}]",4,185533,5769e6f45fab11d9bdab117fbd1eb0e7f5f0beeb,14,5,1,7711,,,0,"Fix sync local state periodic task for standalone mode

If Ironic runs as standalone service we should not use Keystone API.
This patch fixes periodic task for nodes take over.

Change-Id: Ied5a1967665b19877feef610607e5f0dbbd40ef9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/33/185533/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py']",2,5769e6f45fab11d9bdab117fbd1eb0e7f5f0beeb,takeover-standalone, admin_context = None if CONF.auth_strategy == 'keystone' else context, admin_context = None,21,1
openstack%2Fmanila~master~Ia400bcf08a271f1e596f33f72ee94e33d1f682ad,openstack/manila,master,Ia400bcf08a271f1e596f33f72ee94e33d1f682ad,Remove ServiceClient from share_client,MERGED,2015-05-22 21:36:23.000000000,2015-05-28 05:27:01.000000000,2015-05-28 05:27:00.000000000,"[{'_account_id': 3}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-05-22 21:36:23.000000000', 'files': ['contrib/tempest/tempest/services/share/json/shares_client.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/782291d812998371f4316f68d89437cf9bae093e', 'message': 'Remove ServiceClient from share_client\n\nServiceClient will be removed soon and there is no reason to use\nit. A client can directly be inherited from RestClient instead.\n\nChange-Id: Ia400bcf08a271f1e596f33f72ee94e33d1f682ad\nPartly-implements: bp tempest-plugin-interface\n'}]",0,185152,782291d812998371f4316f68d89437cf9bae093e,9,5,1,7872,,,0,"Remove ServiceClient from share_client

ServiceClient will be removed soon and there is no reason to use
it. A client can directly be inherited from RestClient instead.

Change-Id: Ia400bcf08a271f1e596f33f72ee94e33d1f682ad
Partly-implements: bp tempest-plugin-interface
",git fetch https://review.opendev.org/openstack/manila refs/changes/52/185152/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/services/share/json/shares_client.py'],1,782291d812998371f4316f68d89437cf9bae093e,bp/tempest-plugin-interface,from tempest_lib.common import rest_client # noqaclass SharesClient(rest_client.RestClient):,from tempest.common import service_clientclass SharesClient(service_client.ServiceClient):,2,2
openstack%2Fmanila~master~I32714af4407a77dc532dcbd18d8fce89f3863c26,openstack/manila,master,I32714af4407a77dc532dcbd18d8fce89f3863c26,Drop incubating theme from docs,MERGED,2015-05-27 22:17:24.000000000,2015-05-28 05:26:43.000000000,2015-05-28 05:26:41.000000000,"[{'_account_id': 3}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-05-27 22:17:24.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8949d64085d7f2268682339729667d1f91e361a5', 'message': 'Drop incubating theme from docs\n\nOpenStack has dropped the incubation notion, so labeling this as an\nincubated project in the docs is confusing.\n\nChange-Id: I32714af4407a77dc532dcbd18d8fce89f3863c26\n'}]",0,186196,8949d64085d7f2268682339729667d1f91e361a5,9,5,1,1849,,,0,"Drop incubating theme from docs

OpenStack has dropped the incubation notion, so labeling this as an
incubated project in the docs is confusing.

Change-Id: I32714af4407a77dc532dcbd18d8fce89f3863c26
",git fetch https://review.opendev.org/openstack/manila refs/changes/96/186196/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,8949d64085d7f2268682339729667d1f91e361a5,incubating,html_theme_options = {},html_theme_options = {'incubating': True},1,1
openstack%2Fmagnum~master~Id1b0a8bbe0bcbfdc9ada5c13930ea7e0181d5687,openstack/magnum,master,Id1b0a8bbe0bcbfdc9ada5c13930ea7e0181d5687,"Backport ""fixup! added script for dynamically registering a minion""",MERGED,2015-05-24 18:19:34.000000000,2015-05-28 05:04:58.000000000,2015-05-28 05:04:57.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 8745}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-05-24 18:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/213d3bb76ce6663435242be3b29d83cfbe201c55', 'message': 'Backport ""fixup! added script for dynamically registering a minion""\n\nheat-coe-templates: I504ce3e49acbcc469a47501d0bd90e3eceb9647e\n\nChange-Id: Id1b0a8bbe0bcbfdc9ada5c13930ea7e0181d5687\n'}, {'number': 2, 'created': '2015-05-26 10:25:28.000000000', 'files': ['magnum/templates/heat-kubernetes/fragments/configure-kubernetes-minion.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/63c1b6f4fce5b0dea20af00796dba9902face142', 'message': 'Backport ""fixup! added script for dynamically registering a minion""\n\nheat-coe-templates: I504ce3e49acbcc469a47501d0bd90e3eceb9647e\n\nChange-Id: Id1b0a8bbe0bcbfdc9ada5c13930ea7e0181d5687\n'}]",2,185277,63c1b6f4fce5b0dea20af00796dba9902face142,13,7,2,11650,,,0,"Backport ""fixup! added script for dynamically registering a minion""

heat-coe-templates: I504ce3e49acbcc469a47501d0bd90e3eceb9647e

Change-Id: Id1b0a8bbe0bcbfdc9ada5c13930ea7e0181d5687
",git fetch https://review.opendev.org/openstack/magnum refs/changes/77/185277/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/templates/heat-kubernetes/fragments/configure-kubernetes-minion.sh'],1,213d3bb76ce6663435242be3b29d83cfbe201c55,backports,"/^KUBELET_API_SERVER=/ s/=.*/=""--api_servers='""$KUBE_MASTER_IP""':8080""//usr/local/bin/kube-register","/^KUBELET_API_SERVER=/ s|=.*|=""--api_servers=http://'""$KUBE_MASTER_IP""':8080""| cpu=$(expr $(nproc) \* 1000) memory_kb=$(cat /proc/meminfo | awk '/MemTotal: /{print $2}') memory=$(expr $memory_kb \* 1024) curl -sf -X POST -H 'Content-Type: application/json' \ --data-binary ""{\""kind\"":\""Minion\"",\""id\"":\""$myip\"",\""apiVersion\"":\""v1beta1\"", \""resources\"":{\""capacity\"":{\""cpu\"":$cpu,\""memory\"":$memory}}}"" \ http://$KUBE_MASTER_IP:8080/api/v1beta1/minions",2,9
openstack%2Fpython-manilaclient~master~I9f9c70f9d6fd9156da66280183fa933f72b59d7a,openstack/python-manilaclient,master,I9f9c70f9d6fd9156da66280183fa933f72b59d7a,Drop incubating theme from docs,MERGED,2015-05-27 22:25:04.000000000,2015-05-28 04:55:04.000000000,2015-05-28 04:55:02.000000000,"[{'_account_id': 3}, {'_account_id': 11047}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-05-27 22:25:04.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/281795ef754e937cea9809e8406335454447a69c', 'message': 'Drop incubating theme from docs\n\nOpenStack has dropped the incubation notion, so labeling this as an\nincubated project in the docs is confusing.\n\nChange-Id: I9f9c70f9d6fd9156da66280183fa933f72b59d7a\n'}]",0,186199,281795ef754e937cea9809e8406335454447a69c,7,3,1,1849,,,0,"Drop incubating theme from docs

OpenStack has dropped the incubation notion, so labeling this as an
incubated project in the docs is confusing.

Change-Id: I9f9c70f9d6fd9156da66280183fa933f72b59d7a
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/99/186199/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,281795ef754e937cea9809e8406335454447a69c,incubating,html_theme_options = {},html_theme_options = {'incubating': True},1,1
openstack%2Fcinder~master~I16733643d4b92fe8134eec2549bbd679fe75fb9c,openstack/cinder,master,I16733643d4b92fe8134eec2549bbd679fe75fb9c,Don't use dict.iterkeys(),MERGED,2015-05-25 15:29:59.000000000,2015-05-28 04:52:01.000000000,2015-05-26 16:12:53.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 9107}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11343}, {'_account_id': 11600}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-25 15:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b5398bd4ae0813e9e6f6bf935bcdec84b3bb038', 'message': ""Don't use dict.iteritems()\n\nReplace list(dict.iterkeys()) with list(dict). The call to iterkeys() is\nuseless and the iterkeys() method of dictionaries was removed in\nPython 3\n\nChange-Id: I16733643d4b92fe8134eec2549bbd679fe75fb9c\n""}, {'number': 2, 'created': '2015-05-25 20:21:09.000000000', 'files': ['tools/colorizer.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/065c56de7139a9c83a1cc3d0394367d81e617454', 'message': ""Don't use dict.iterkeys()\n\nReplace list(dict.iterkeys()) with list(dict). The call to iterkeys() is\nuseless and the iterkeys() method of dictionaries was removed in\nPython 3\n\nChange-Id: I16733643d4b92fe8134eec2549bbd679fe75fb9c\n""}]",3,185411,065c56de7139a9c83a1cc3d0394367d81e617454,52,28,2,9107,,,0,"Don't use dict.iterkeys()

Replace list(dict.iterkeys()) with list(dict). The call to iterkeys() is
useless and the iterkeys() method of dictionaries was removed in
Python 3

Change-Id: I16733643d4b92fe8134eec2549bbd679fe75fb9c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/185411/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/colorizer.py'],1,0b5398bd4ae0813e9e6f6bf935bcdec84b3bb038,py3, for cls in list(self.results):, for cls in list(self.results.iterkeys()):,1,1
openstack%2Ftempest~master~I1d390d95345367a8a29ac990429619fa044563a3,openstack/tempest,master,I1d390d95345367a8a29ac990429619fa044563a3,"Replace ""hardcode"" in scenario tests",MERGED,2015-05-25 07:37:38.000000000,2015-05-28 04:49:32.000000000,2015-05-28 04:49:30.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 7227}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 11075}, {'_account_id': 13454}, {'_account_id': 14614}]","[{'number': 1, 'created': '2015-05-25 07:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/603a1a470e0c2e9d2a40762ac057469b36f07b28', 'message': 'Replace ""hardcode"" in scenario tests\n\nReplace ""harcode"" of device name for attached volume, like ""vdb"",\nby option CONF.compute.volume_device_name in all scenario tests.\n\nChange-Id: I1d390d95345367a8a29ac990429619fa044563a3\n'}, {'number': 2, 'created': '2015-05-25 07:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd6bbca7241803e3df7765073040308f7f103647', 'message': 'Replace ""hardcode"" in scenario tests\n\nReplace ""harcode"" of device name for attached volume, like ""vdb"",\nby option CONF.compute.volume_device_name in all scenario tests.\n\nChange-Id: I1d390d95345367a8a29ac990429619fa044563a3\n'}, {'number': 3, 'created': '2015-05-25 18:35:46.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_stamp_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e0634ab58732cdf42b0bd11523695a3bab3bf69c', 'message': 'Replace ""hardcode"" in scenario tests\n\nReplace ""harcode"" of device name for attached volume, like ""vdb"",\nby option CONF.compute.volume_device_name in all scenario tests.\n\nChange-Id: I1d390d95345367a8a29ac990429619fa044563a3\nCloses-Bug: 1458649\n'}]",0,185318,e0634ab58732cdf42b0bd11523695a3bab3bf69c,29,10,3,13454,,,0,"Replace ""hardcode"" in scenario tests

Replace ""harcode"" of device name for attached volume, like ""vdb"",
by option CONF.compute.volume_device_name in all scenario tests.

Change-Id: I1d390d95345367a8a29ac990429619fa044563a3
Closes-Bug: 1458649
",git fetch https://review.opendev.org/openstack/tempest refs/changes/18/185318/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_stamp_pattern.py']",2,603a1a470e0c2e9d2a40762ac057469b36f07b28,bug/1458649," server['id'], volume['id'], device='/dev/%s' % CONF.compute.volume_device_name) return CONF.compute.volume_device_name in part ssh_client.exec_command('sudo /usr/sbin/mkfs.ext4 /dev/%s' % CONF.compute.volume_device_name) ssh_client.exec_command('sudo mount /dev/%s /mnt' % CONF.compute.volume_device_name) ssh_client.exec_command('sudo mount /dev/%s /mnt' % CONF.compute.volume_device_name)"," # TODO(andreaf) we should use device from config instead if vdb server['id'], volume['id'], device='/dev/vdb') return 'vdb' in part ssh_client.exec_command('sudo /usr/sbin/mkfs.ext4 /dev/vdb') ssh_client.exec_command('sudo mount /dev/vdb /mnt') ssh_client.exec_command('sudo mount /dev/vdb /mnt')",11,8
openstack%2Fneutron~master~If91cdcd85d6fad9b9d37aea367aa11c83ff4b343,openstack/neutron,master,If91cdcd85d6fad9b9d37aea367aa11c83ff4b343,Imported Translations from Transifex,MERGED,2015-05-23 06:15:23.000000000,2015-05-28 04:48:27.000000000,2015-05-25 10:07:30.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-23 06:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dad41b7d639c3d20fa0fe2b6ca9713c90e723616', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If91cdcd85d6fad9b9d37aea367aa11c83ff4b343\n'}, {'number': 2, 'created': '2015-05-24 06:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/433f49658ff09ed77d1f4512ab1343d0d6d7e553', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If91cdcd85d6fad9b9d37aea367aa11c83ff4b343\n'}, {'number': 3, 'created': '2015-05-25 06:15:27.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron.pot', 'neutron/locale/neutron-log-warning.pot'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3425be06bf069a256dbb0fdb9528459544e9947f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If91cdcd85d6fad9b9d37aea367aa11c83ff4b343\n'}]",0,185219,3425be06bf069a256dbb0fdb9528459544e9947f,56,19,3,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If91cdcd85d6fad9b9d37aea367aa11c83ff4b343
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/185219/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron.pot', 'neutron/locale/neutron-log-warning.pot']",4,dad41b7d639c3d20fa0fe2b6ca9713c90e723616,transifex/translations,"""Project-Id-Version: neutron 2015.2.0.dev420\n""""POT-Creation-Date: 2015-05-23 06:15+0000\n""#: neutron/quota.py:227#: neutron/quota.py:241#: neutron/quota.py:341 msgid """" ""Registering resources to apply quota limits to using the quota_items "" ""option is deprecated as of Liberty.Resource REST controllers should take "" ""care of registering resources with the quota engine."" msgstr """" #: neutron/agent/linux/dhcp.py:227#: neutron/agent/linux/dhcp.py:235#: neutron/agent/linux/ebtables_manager.py:168 #, python-format msgid ""Attempted to remove chain %s which does not exist"" msgstr """" #: neutron/agent/linux/ebtables_manager.py:237 #: neutron/agent/linux/iptables_manager.py:247#: neutron/agent/linux/iptables_manager.py:696#: neutron/db/securitygroups_rpc_base.py:372#: neutron/db/migration/alembic_migrations/heal_script.py:91#: neutron/plugins/ml2/driver_context.py:191#: neutron/plugins/ml2/plugin.py:532#: neutron/plugins/ml2/plugin.py:783#: neutron/plugins/ml2/plugin.py:1391#: neutron/plugins/ml2/plugin.py:1423#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1486#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1529#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1533","""Project-Id-Version: neutron 2015.2.0.dev319\n""""POT-Creation-Date: 2015-05-10 06:14+0000\n""#: neutron/quota.py:223#: neutron/quota.py:237#: neutron/agent/linux/dhcp.py:226#: neutron/agent/linux/dhcp.py:234#: neutron/agent/linux/iptables_manager.py:239#: neutron/agent/linux/iptables_manager.py:689#: neutron/db/securitygroups_rpc_base.py:371#: neutron/db/migration/alembic_migrations/heal_script.py:90#: neutron/plugins/ml2/driver_context.py:184#: neutron/plugins/ml2/plugin.py:526#: neutron/plugins/ml2/plugin.py:776#: neutron/plugins/ml2/plugin.py:1384#: neutron/plugins/ml2/plugin.py:1416#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1484#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1527#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1531",350,244
openstack%2Fheat~master~Idad1c4bee325f5483a598cd596fe04f4d0bb8cea,openstack/heat,master,Idad1c4bee325f5483a598cd596fe04f4d0bb8cea,Do not pass rich objects in Swift Container,MERGED,2015-05-25 16:56:08.000000000,2015-05-28 04:47:15.000000000,2015-05-27 04:15:48.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6899}, {'_account_id': 7385}, {'_account_id': 8833}, {'_account_id': 9382}, {'_account_id': 9751}, {'_account_id': 12321}, {'_account_id': 13009}, {'_account_id': 16277}]","[{'number': 1, 'created': '2015-05-25 16:56:08.000000000', 'files': ['heat/engine/resources/openstack/swift/swift.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9de16459287e956b0fa08fc58fb20c07f6650bec', 'message': 'Do not pass rich objects in Swift Container\n\nfrom handle_delete to check_delete_complete, pass initial number of\nSwift objects in the container instead (or None)\n\nChange-Id: Idad1c4bee325f5483a598cd596fe04f4d0bb8cea\nPartial-Bug: #1393268\n'}]",0,185429,9de16459287e956b0fa08fc58fb20c07f6650bec,15,10,1,9542,,,0,"Do not pass rich objects in Swift Container

from handle_delete to check_delete_complete, pass initial number of
Swift objects in the container instead (or None)

Change-Id: Idad1c4bee325f5483a598cd596fe04f4d0bb8cea
Partial-Bug: #1393268
",git fetch https://review.opendev.org/openstack/heat refs/changes/29/185429/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/swift/swift.py'],1,9de16459287e956b0fa08fc58fb20c07f6650bec,bug/1393268, # objects is either None (container is gone already) or (empty) list if objects is not None: objects = len(objects) if objects: # integer >=0 from the first invocation, if objects: # an (empty) list from the first invocation,4,1
openstack%2Fproject-config~master~I2d9c91f3d1fbcf61ae21521758836793742389ed,openstack/project-config,master,I2d9c91f3d1fbcf61ae21521758836793742389ed,Sort PO files to avoid random reorder,MERGED,2015-05-27 14:46:20.000000000,2015-05-28 04:46:46.000000000,2015-05-28 04:46:44.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6786}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-27 14:46:20.000000000', 'files': ['jenkins/scripts/common_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7166dc85d8c2d6560dd5dc34941f3d47a75e0662', 'message': 'Sort PO files to avoid random reorder\n\nChanges like\nhttps://review.openstack.org/#/c/185848/1/horizon/locale/ca/LC_MESSAGES/djangojs.po\njust reordered entries with no content change. Pass --sort-output to\nmsgattrib to filter the entries in alphabetical order so that any\nrearrangements of the source files will not have an effect on the order\nof the entries.\n\nChange-Id: I2d9c91f3d1fbcf61ae21521758836793742389ed\n'}]",0,186026,7166dc85d8c2d6560dd5dc34941f3d47a75e0662,10,5,1,6547,,,0,"Sort PO files to avoid random reorder

Changes like
https://review.openstack.org/#/c/185848/1/horizon/locale/ca/LC_MESSAGES/djangojs.po
just reordered entries with no content change. Pass --sort-output to
msgattrib to filter the entries in alphabetical order so that any
rearrangements of the source files will not have an effect on the order
of the entries.

Change-Id: I2d9c91f3d1fbcf61ae21521758836793742389ed
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/186026/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/common_translation_update.sh'],1,7166dc85d8c2d6560dd5dc34941f3d47a75e0662,sort-i18n," msgattrib --translated --no-location --sort-output ""$i"" \ --output=""${i}.tmp"" msgattrib --translated --no-location --sort-output ""$i"" \ --output=""${i}.tmp"" msgattrib --translated --no-location --sort-output ""$i"" \ --output=""${i}.tmp"""," msgattrib --translated --no-location ""$i"" --output=""${i}.tmp"" msgattrib --translated --no-location ""$i"" --output=""${i}.tmp"" msgattrib --translated --no-location ""$i"" --output=""${i}.tmp""",6,3
openstack%2Fneutron~master~Ic37a18867fd88f1f3d69ca1d1ddadad0a4c4207d,openstack/neutron,master,Ic37a18867fd88f1f3d69ca1d1ddadad0a4c4207d,Drop DHCPNAK's complaining about wrong Server IDs,ABANDONED,2015-05-25 08:52:03.000000000,2015-05-28 04:46:18.000000000,,"[{'_account_id': 3}, {'_account_id': 2733}, {'_account_id': 7787}, {'_account_id': 9444}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11227}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-25 08:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1cb80d67ae5880f3dd9bfe6a895abff670191dad', 'message': ""Drop DHCPNAK's complaining about wrong Server IDs\n\nDue to issues caused by dnsmasq restarts sending DHCPNAKs,\nchange Ieff0236670c1403b5d79ad8e50d7574c1b694e34 passed the\ndhcp-authoritative option to dnsmasq. While this solved the\nrestart issue, it broke the multi-DHCP server scenario because\nthe dnsmasq instances will NAK requests to a server ID that\nisn't their own.\n\nWe could revert that change and then switch to writing leases\nto a file to persist across restarts, but then the original issue\nwon't be fixed in the case where a dhcp instance is evacuated to\nanother server that doesn't have the lease file.\n\nWe seem to be backed into a corner by dnsmasq's behavior here.\nThis patch has a light-weight iptables rule to protect the instances\nfrom the DHCPNAK messages that are generated in the multi-server\nscenario. This seems to be the only thing safe enough to back-port\nto undo the issues caused by Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nwhile maintaining its fix.\n\nCloses-Bug: #1457900\nChange-Id: Ic37a18867fd88f1f3d69ca1d1ddadad0a4c4207d\n""}, {'number': 2, 'created': '2015-05-25 09:04:14.000000000', 'files': ['neutron/agent/linux/iptables_comments.py', 'neutron/agent/linux/iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0241176d0a81577b13a7139c9b55af0e2f31f2ce', 'message': ""Drop DHCPNAK's complaining about wrong Server IDs\n\nDue to issues caused by dnsmasq restarts sending DHCPNAKs,\nchange Ieff0236670c1403b5d79ad8e50d7574c1b694e34 passed the\ndhcp-authoritative option to dnsmasq. While this solved the\nrestart issue, it broke the multi-DHCP server scenario because\nthe dnsmasq instances will NAK requests to a server ID that\nisn't their own.\n\nWe could revert that change and then switch to writing leases\nto a file to persist across restarts, but then the original issue\nwon't be fixed in the case where a dhcp instance is evacuated to\nanother server that doesn't have the lease file.\n\nWe seem to be backed into a corner by dnsmasq's behavior here.\nThis patch has a light-weight iptables rule to protect the instances\nfrom the DHCPNAK messages that are generated in the multi-server\nscenario. This seems to be the only thing safe enough to back-port\nto undo the issues caused by Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nwhile maintaining its fix.\n\nCloses-Bug: #1457900\nChange-Id: Ic37a18867fd88f1f3d69ca1d1ddadad0a4c4207d\n""}]",0,185332,0241176d0a81577b13a7139c9b55af0e2f31f2ce,37,21,2,7787,,,0,"Drop DHCPNAK's complaining about wrong Server IDs

Due to issues caused by dnsmasq restarts sending DHCPNAKs,
change Ieff0236670c1403b5d79ad8e50d7574c1b694e34 passed the
dhcp-authoritative option to dnsmasq. While this solved the
restart issue, it broke the multi-DHCP server scenario because
the dnsmasq instances will NAK requests to a server ID that
isn't their own.

We could revert that change and then switch to writing leases
to a file to persist across restarts, but then the original issue
won't be fixed in the case where a dhcp instance is evacuated to
another server that doesn't have the lease file.

We seem to be backed into a corner by dnsmasq's behavior here.
This patch has a light-weight iptables rule to protect the instances
from the DHCPNAK messages that are generated in the multi-server
scenario. This seems to be the only thing safe enough to back-port
to undo the issues caused by Ieff0236670c1403b5d79ad8e50d7574c1b694e34
while maintaining its fix.

Closes-Bug: #1457900
Change-Id: Ic37a18867fd88f1f3d69ca1d1ddadad0a4c4207d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/185332/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_comments.py', 'neutron/agent/linux/iptables_firewall.py']",2,1cb80d67ae5880f3dd9bfe6a895abff670191dad,bug/1457900," def _drop_dhcp_wrong_server_nak(self): # We need to drop a specific DHCPNAK message that gets generated when # there are multiple dnsmasq servers running since they are run with # the dhcp-authoritative option. rule = (""-p udp -m udp --sport 67 --dport 68 -m string --string "" ""'wrong server-ID' -j DROP"") return [comment_rule(rule, comment=ic.DHCP_NAK_DROP)] # NOTE(kevinbenton): we need to drop DHCPNAKs generated by dnsmasq # that will be generated when multiple dnsmasq servers are running ipv4_iptables_rules += self._drop_dhcp_wrong_server_nak()",,12,0
openstack%2Fproject-config~master~Ic6902b0254df3e601504ed40a4c319676537496a,openstack/project-config,master,Ic6902b0254df3e601504ed40a4c319676537496a,Enable Heat and Neutron for Python SDK gate,MERGED,2015-05-20 20:19:58.000000000,2015-05-28 04:42:17.000000000,2015-05-28 04:42:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-05-20 20:19:58.000000000', 'files': ['jenkins/jobs/sdk.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/941cc2f48e6f0aab582f4ba6516f0166651e9c5b', 'message': 'Enable Heat and Neutron for Python SDK gate\n\nIt would be nice if the Python SDK could test Neutron and Heat\nas well as other services.\n\nChange-Id: Ic6902b0254df3e601504ed40a4c319676537496a\n'}]",0,184611,941cc2f48e6f0aab582f4ba6516f0166651e9c5b,8,3,1,8736,,,0,"Enable Heat and Neutron for Python SDK gate

It would be nice if the Python SDK could test Neutron and Heat
as well as other services.

Change-Id: Ic6902b0254df3e601504ed40a4c319676537496a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/11/184611/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/sdk.yaml'],1,941cc2f48e6f0aab582f4ba6516f0166651e9c5b,, export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_HEAT=1,,2,0
openstack%2Fproject-config~master~Ifd7bbdcfe278e5e51aa06048713a62135d4b8baf,openstack/project-config,master,Ifd7bbdcfe278e5e51aa06048713a62135d4b8baf,Create repo for oslo.service,MERGED,2015-05-25 08:13:25.000000000,2015-05-28 04:39:08.000000000,2015-05-28 04:39:07.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2472}, {'_account_id': 4162}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 12612}]","[{'number': 1, 'created': '2015-05-25 08:13:25.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/oslo.service.config', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c4b944ad0f781e3ea87e68e023bf10f7c0227f0c', 'message': 'Create repo for oslo.service\n\nblueprint graduate-oslo-service\n\nChange-Id: Ifd7bbdcfe278e5e51aa06048713a62135d4b8baf\n'}]",0,185324,c4b944ad0f781e3ea87e68e023bf10f7c0227f0c,12,8,1,7293,,,0,"Create repo for oslo.service

blueprint graduate-oslo-service

Change-Id: Ifd7bbdcfe278e5e51aa06048713a62135d4b8baf
",git fetch https://review.opendev.org/openstack/project-config refs/changes/24/185324/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/oslo.service.config', 'zuul/layout.yaml']",5,c4b944ad0f781e3ea87e68e023bf10f7c0227f0c,new-project, - name: openstack/oslo.service template: - name: merge-check - name: python26-jobs - name: python-jobs - name: python3-jobs - name: openstack-server-publish-jobs - name: check-requirements - name: publish-to-pypi - name: lib-forward-testing ,,49,0
openstack%2Fproject-config~master~Icd6ff6cc55963ad804690fd3ad622bb3ddafbbc2,openstack/project-config,master,Icd6ff6cc55963ad804690fd3ad622bb3ddafbbc2,keystonemiddleware non-voting bandit job,MERGED,2015-05-26 01:20:52.000000000,2015-05-28 04:37:19.000000000,2015-05-28 04:37:17.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2903}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 11861}, {'_account_id': 14692}]","[{'number': 1, 'created': '2015-05-26 01:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0dad6a126cea84576aa679023df14b6506690ef5', 'message': 'keystonemiddleware non-voting bandit job\n\nkeystonemiddleware has a tox env to run bandit since 0e2c5b5.\nRun it non-voting as part of the gate on master only.\n\nChange-Id: Icd6ff6cc55963ad804690fd3ad622bb3ddafbbc2\n'}, {'number': 2, 'created': '2015-05-26 01:41:53.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7b4d44438272dc2d7c59b2d0630f5fef468a2feb', 'message': 'keystonemiddleware non-voting bandit job\n\nkeystonemiddleware has a tox env to run bandit since 0e2c5b5.\nRun it non-voting as part of the gate on master only.\n\nChange-Id: Icd6ff6cc55963ad804690fd3ad622bb3ddafbbc2\n'}]",2,185478,7b4d44438272dc2d7c59b2d0630f5fef468a2feb,16,11,2,6486,,,0,"keystonemiddleware non-voting bandit job

keystonemiddleware has a tox env to run bandit since 0e2c5b5.
Run it non-voting as part of the gate on master only.

Change-Id: Icd6ff6cc55963ad804690fd3ad622bb3ddafbbc2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/78/185478/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,0dad6a126cea84576aa679023df14b6506690ef5,bandit, - name: gate-keystonemiddleware-tox-bandit branch: ^(?!stable/(icehouse|juno|kilo)).*$ voting: false check: - name: gate-keystonemiddleware-tox-bandit,,8,0
openstack%2Fneutron~master~I2c0bc73f72840c401c578e87d8178a79f05aad82,openstack/neutron,master,I2c0bc73f72840c401c578e87d8178a79f05aad82,Skip external tables for neutron-db-manage --autogenerate,MERGED,2015-05-25 22:20:17.000000000,2015-05-28 04:21:22.000000000,2015-05-27 17:22:32.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11816}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-25 22:20:17.000000000', 'files': ['neutron/db/migration/alembic_migrations/external.py', 'neutron/db/migration/alembic_migrations/env.py', 'neutron/tests/functional/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fc7f56565925a53f2212706431af479752bb8d9', 'message': ""Skip external tables for neutron-db-manage --autogenerate\n\nDB tables that do not have models in the neutron tree cause\nneutron-db-manage --autogenerate to create commands to drop the\ntables. This fix hooks into alembic's environment with a include_object\ncallback that ignores external tables.\n\nWe already had a list of external tables for use by the migration tests,\nso re-use them for --autogenerate.\n\nPartial-bug: #1458682\n\nChange-Id: I2c0bc73f72840c401c578e87d8178a79f05aad82\n""}]",0,185465,9fc7f56565925a53f2212706431af479752bb8d9,38,30,1,6524,,,0,"Skip external tables for neutron-db-manage --autogenerate

DB tables that do not have models in the neutron tree cause
neutron-db-manage --autogenerate to create commands to drop the
tables. This fix hooks into alembic's environment with a include_object
callback that ignores external tables.

We already had a list of external tables for use by the migration tests,
so re-use them for --autogenerate.

Partial-bug: #1458682

Change-Id: I2c0bc73f72840c401c578e87d8178a79f05aad82
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/185465/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/external.py', 'neutron/db/migration/alembic_migrations/env.py', 'neutron/tests/functional/db/test_migrations.py']",3,9fc7f56565925a53f2212706431af479752bb8d9,bug/1458682,from neutron.db.migration.alembic_migrations import external or name in external.TABLES):,"# These tables are still in the neutron database, but their models have moved # to the separate advanced services repositories. We skip the migration checks # for these tables for now. The checks will be re-instated soon in the tests # for each separate repository. # TODO(akamyshnikova): delete these lists when the tables are removed from # neutron database. EXTERNAL_VPNAAS_TABLES = ['vpnservices', 'ipsecpolicies', 'ipsecpeercidrs', 'ipsec_site_connections', 'cisco_csr_identifier_map', 'ikepolicies'] EXTERNAL_LBAAS_TABLES = ['vips', 'sessionpersistences', 'pools', 'healthmonitors', 'poolstatisticss', 'members', 'poolloadbalanceragentbindings', 'embrane_pool_port', 'poolmonitorassociations'] EXTERNAL_FWAAS_TABLES = ['firewall_rules', 'firewalls', 'firewall_policies'] EXTERNAL_TABLES = (EXTERNAL_FWAAS_TABLES + EXTERNAL_LBAAS_TABLES + EXTERNAL_VPNAAS_TABLES) or name in EXTERNAL_TABLES):",40,22
openstack%2Fproject-config~master~Iac650329825c0d3eb7171a50247d276442cc35b9,openstack/project-config,master,Iac650329825c0d3eb7171a50247d276442cc35b9,"Test pecan against barbican, magnum, and gnocchi.",MERGED,2015-05-27 19:49:17.000000000,2015-05-28 04:19:57.000000000,2015-05-28 04:19:56.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1669}, {'_account_id': 2109}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 7262}, {'_account_id': 7973}, {'_account_id': 8005}, {'_account_id': 8470}]","[{'number': 1, 'created': '2015-05-27 19:49:17.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1c19406a24e7eaade31c6eab83846a7e44015783', 'message': 'Test pecan against barbican, magnum, and gnocchi.\n\nChange-Id: Iac650329825c0d3eb7171a50247d276442cc35b9\n'}]",0,186141,1c19406a24e7eaade31c6eab83846a7e44015783,14,18,1,8005,,,0,"Test pecan against barbican, magnum, and gnocchi.

Change-Id: Iac650329825c0d3eb7171a50247d276442cc35b9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/41/186141/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,1c19406a24e7eaade31c6eab83846a7e44015783,, - gate-pecan-tox-barbican-stable - gate-pecan-tox-magnum-stable - gate-pecan-tox-magnum-tip - gate-pecan-tox-gnocchi-stable - gate-pecan-tox-gnocchi-tip - gate-pecan-tox-magnum-tip - gate-pecan-tox-gnocchi-tip,,17,0
openstack%2Fproject-config~master~I2c1395ccef078f8fccc65d7cb244107473d04153,openstack/project-config,master,I2c1395ccef078f8fccc65d7cb244107473d04153,Add beaker-rspec jobs to puppet-zuul repo,MERGED,2015-05-27 12:16:28.000000000,2015-05-28 04:19:53.000000000,2015-05-28 04:19:51.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2015-05-27 12:16:28.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/eea605a07991ede86c1f782cd5b5747e6f97ca8b', 'message': 'Add beaker-rspec jobs to puppet-zuul repo\n\nChange-Id: I2c1395ccef078f8fccc65d7cb244107473d04153\n'}]",0,185952,eea605a07991ede86c1f782cd5b5747e6f97ca8b,9,4,1,6889,,,0,"Add beaker-rspec jobs to puppet-zuul repo

Change-Id: I2c1395ccef078f8fccc65d7cb244107473d04153
",git fetch https://review.opendev.org/openstack/project-config refs/changes/52/185952/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,eea605a07991ede86c1f782cd5b5747e6f97ca8b,puppet-zuul-beaker, - name: ^gate-puppet-zuul-puppet-beaker-rspec-dsvm-.*$ voting: false - name: puppet-beaker-jobs,,5,0
openstack%2Fheat~stable%2Fjuno~I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9,openstack/heat,stable/juno,I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9,Allow lists and strings for Json parameters via provider resources,MERGED,2015-03-09 10:05:43.000000000,2015-05-28 04:17:49.000000000,2015-05-27 03:07:23.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7404}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-03-09 10:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51384bf2165c88dfa474302cfb7320c62ecac4e3', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n'}, {'number': 2, 'created': '2015-05-18 10:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/697436906f3ae774de384efe220f6331c69daa0d', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChanges required for backport:\n\n* Changed import of oslo_serialization.jsonutils to\n  oslo.serialization 1.0.0 (oslo_serialization is a\n  1.2.0ism).\n* Added dependency on oslo.serialization>=1.0.0<=1.2.0\n  (this is the same version other openstack services in stable/juno,\n  such as Keystone pull in).\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n(cherry-picked from 51384bf2165c88dfa474302cfb7320c62ecac4e3)\n'}, {'number': 3, 'created': '2015-05-20 07:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db28537d9de98c08bf592c4d84a63acc4c6d3600', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChanges required for backport:\n\n* Changed import of oslo_serialization.jsonutils to\n  oslo.serialization 1.0.0 (oslo_serialization is a\n  1.2.0ism).\n* Added dependency on oslo.serialization>=1.0.0<=1.2.0\n  (this is the same version other openstack services in stable/juno,\n  such as Keystone pull in).\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n(cherry-picked from 413fde3247b804e408a9ea9fd863d85391e326aa)\n'}, {'number': 4, 'created': '2015-05-20 12:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6d78adab8150755d93a87b1283b8ef301ee06ab', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChanges required for backport:\n\n* Changed import of oslo_serialization.jsonutils to\n  oslo.serialization 1.0.0 (oslo_serialization is a\n  1.2.0ism).\n* Added dependency on oslo.serialization>=1.0.0<=1.2.0\n  (this is the same version other openstack services in stable/juno,\n  such as Keystone pull in).\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n(cherry-picked from 413fde3247b804e408a9ea9fd863d85391e326aa)\n'}, {'number': 5, 'created': '2015-05-21 07:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/40922f6d032c6cb31bafbedc2fd0554337dd7142', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChanges required for backport:\n\n* Changed import of oslo_serialization.jsonutils to\n  heat.openstack.common.jsonutils.\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n(cherry-picked from 413fde3247b804e408a9ea9fd863d85391e326aa)\n'}, {'number': 6, 'created': '2015-05-26 11:14:52.000000000', 'files': ['heat/tests/test_properties.py', 'heat/engine/properties.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/40bfa60d84aa38fef5a7c8d278641bfeefad4bb7', 'message': 'Allow lists and strings for Json parameters via provider resources\n\nCurrently we have a somewhat bogus internal equivalence between the\n""json"" parameter type and the MAP property type.  This is a problem\nwhen exposing json parameters via provider resources, because the\nschema of the exposed property does not exactly match the capabilities\nof the underlying parameter.\n\nSpecifically, json parameters can take strings (json serialized list or\nmap), and also lists and maps directly.  Currently, we can only pass\nmaps, which means some data, for example a list of maps (which is possible\nwhen interacting directly with a json parameter) is not possible when\nusing the same parameter abstracted via a TemplateResource.\n\nTo work around this add a flag which relaxes the type rules and enables\nsome coercion of map values, only when they\'re going via a schema derived\nfrom a json parameter.\n\nChanges required for backport:\n\n* Changed import of oslo_serialization.jsonutils to\n  heat.openstack.common.jsonutils.\n\nChange-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9\nCloses-Bug: #1420196\n(cherry-picked from 413fde3247b804e408a9ea9fd863d85391e326aa)\n'}]",10,162587,40bfa60d84aa38fef5a7c8d278641bfeefad4bb7,37,6,6,12542,,,0,"Allow lists and strings for Json parameters via provider resources

Currently we have a somewhat bogus internal equivalence between the
""json"" parameter type and the MAP property type.  This is a problem
when exposing json parameters via provider resources, because the
schema of the exposed property does not exactly match the capabilities
of the underlying parameter.

Specifically, json parameters can take strings (json serialized list or
map), and also lists and maps directly.  Currently, we can only pass
maps, which means some data, for example a list of maps (which is possible
when interacting directly with a json parameter) is not possible when
using the same parameter abstracted via a TemplateResource.

To work around this add a flag which relaxes the type rules and enables
some coercion of map values, only when they're going via a schema derived
from a json parameter.

Changes required for backport:

* Changed import of oslo_serialization.jsonutils to
  heat.openstack.common.jsonutils.

Change-Id: I8eff36c4343a07b644b84aa9f2f74eceeb62b4a9
Closes-Bug: #1420196
(cherry-picked from 413fde3247b804e408a9ea9fd863d85391e326aa)
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/162587/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_properties.py', 'heat/engine/properties.py']",2,51384bf2165c88dfa474302cfb7320c62ecac4e3,backport-bug/1415986,"from oslo_serialization import jsonutils support_status=support.SupportStatus(), allow_conversion=False): self.allow_conversion = allow_conversion # allow_conversion allows slightly more flexible type conversion # where property->parameter types don't align, primarily when # a json parameter value is passed via a Map property, which requires # some coercion to pass strings or lists (which are both valid for # Json parameters but not for Map properties). allow_conversion = param.type == param.MAP immutable=False, allow_conversion=allow_conversion) # This is to handle passing Lists via Json parameters exposed # via a provider resource, in particular lists-of-dicts which # cannot be handled correctly via comma_delimited_list if self.schema.allow_conversion: if isinstance(value, six.string_types): return value elif isinstance(value, collections.Sequence): return jsonutils.dumps(value)", support_status=support.SupportStatus()): immutable=False),32,2
openstack%2Fproject-config~master~I46292749d645f5f8e99c4f52c975c79bb446c6db,openstack/project-config,master,I46292749d645f5f8e99c4f52c975c79bb446c6db,Add project-team-guide,MERGED,2015-05-26 21:39:21.000000000,2015-05-28 04:08:32.000000000,2015-05-28 04:08:30.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-26 21:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/13dd18cd077f54401686029874673fcf8871f8f4', 'message': 'Add project-team-guide\n\nThe TC has a subgroup working on documentation for project teams\nas OpenStack grows to encompass more projects.  This is a repo to\nhost that documentation.  It is expected to be a sphynx repo and\ntherefore the initial commit will need to supply a buildable\nsphinx tree.\n\nChange-Id: I46292749d645f5f8e99c4f52c975c79bb446c6db\n'}, {'number': 2, 'created': '2015-05-27 14:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b3170e57bb266e546dce3fdb75f61c7d1479e525', 'message': 'Add project-team-guide\n\nThe TC has a subgroup working on documentation for project teams\nas OpenStack grows to encompass more projects.  This is a repo to\nhost that documentation.  It is expected to be a sphynx repo and\ntherefore the initial commit will need to supply a buildable\nsphinx tree.\n\nChange-Id: I46292749d645f5f8e99c4f52c975c79bb446c6db\n'}, {'number': 3, 'created': '2015-05-27 15:18:48.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/project-team-guide.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f833f5e31dddb66aecded9cf1a5386b5142437ef', 'message': 'Add project-team-guide\n\nThe TC has a subgroup working on documentation for project teams\nas OpenStack grows to encompass more projects.  This is a repo to\nhost that documentation.  It is expected to be a sphynx repo and\ntherefore the initial commit will need to supply a buildable\nsphinx tree.\n\nChange-Id: I46292749d645f5f8e99c4f52c975c79bb446c6db\n'}]",3,185746,f833f5e31dddb66aecded9cf1a5386b5142437ef,20,7,3,1,,,0,"Add project-team-guide

The TC has a subgroup working on documentation for project teams
as OpenStack grows to encompass more projects.  This is a repo to
host that documentation.  It is expected to be a sphynx repo and
therefore the initial commit will need to supply a buildable
sphinx tree.

Change-Id: I46292749d645f5f8e99c4f52c975c79bb446c6db
",git fetch https://review.opendev.org/openstack/project-config refs/changes/46/185746/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,13dd18cd077f54401686029874673fcf8871f8f4,new-project, - name: openstack/project-team-guide template: - name: merge-check check: - gate-project-team-guide-docs gate: - gate-project-team-guide-docs ,,20,0
openstack%2Fsahara~master~I02fbffe536630aa742d2a33aef78d48c22bf4124,openstack/sahara,master,I02fbffe536630aa742d2a33aef78d48c22bf4124,Adding retry ability to cinderclient calls,MERGED,2015-04-24 09:50:46.000000000,2015-05-28 04:02:31.000000000,2015-05-28 04:02:29.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7535}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 13953}, {'_account_id': 15524}]","[{'number': 1, 'created': '2015-04-24 09:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/64de2a4383cba2fcf29c9039339945c82d8786d4', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 2, 'created': '2015-04-24 14:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/76adc259268003fcb330c38d4d0d878fc5eadbb8', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 3, 'created': '2015-05-07 08:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fb96e8b4449c95badded73ecb3a37c4fed5e809f', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 4, 'created': '2015-05-07 08:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/027310ace71bc2e6b050c04dc000ff19e3609349', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 5, 'created': '2015-05-08 08:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/41fec93162b4ac9bcd59f3ce7bc4d3a5dd39f21e', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 6, 'created': '2015-05-16 13:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d9704a0553253cea747c6e6508579d25d4c1ac60', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 7, 'created': '2015-05-19 14:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/98ea43ff62700cb10c35a7f0efbfdac3154476dc', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}, {'number': 8, 'created': '2015-05-26 12:03:17.000000000', 'files': ['sahara/service/volumes.py', 'sahara/utils/openstack/cinder.py', 'sahara/service/quotas.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/981745dae866a524d5fbf6333ba12673c318b741', 'message': 'Adding retry ability to cinderclient calls\n\nAll cinderclient calls wrapped in execute_with_retry\nmethod to avoid occasional errors\n\npartially implements bp clients-calls-retry\n\nChange-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124\n'}]",8,177142,981745dae866a524d5fbf6333ba12673c318b741,56,15,8,12039,,,0,"Adding retry ability to cinderclient calls

All cinderclient calls wrapped in execute_with_retry
method to avoid occasional errors

partially implements bp clients-calls-retry

Change-Id: I02fbffe536630aa742d2a33aef78d48c22bf4124
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/177142/6 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/volumes.py', 'sahara/utils/openstack/cinder.py', 'sahara/service/quotas.py']",3,64de2a4383cba2fcf29c9039339945c82d8786d4,bp/clients-calls-retry,from sahara.utils.openstack import base as b for l in b.execute_with_retries(cinder.limits.get).absolute:, for l in cinder.limits.get().absolute:,15,11
openstack%2Ffuel-library~master~I89ff8b8d2352e75d2d3679616a20e48bb42b8eff,openstack/fuel-library,master,I89ff8b8d2352e75d2d3679616a20e48bb42b8eff,Fix apache listen for keystone and horizon,ABANDONED,2015-05-27 23:34:25.000000000,2015-05-28 04:00:26.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-27 23:34:25.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'tests/noop/spec/hosts/apache/apache_spec.rb', 'deployment/puppet/osnailyfacter/manifests/apache.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/openstack/manifests/horizon.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c5182f67697c411f02e55cdc5aa0c9bb57eeb68f', 'message': 'Fix apache listen for keystone and horizon\n\nApache should listen keystone and horizon ports only on internal\naddress, but not on 0.0.0.0. Otherwise it conflicts with haproxy\nfrontends.\n\nChange-Id: I89ff8b8d2352e75d2d3679616a20e48bb42b8eff\nCloses-bug: #1459456\n'}]",0,186225,c5182f67697c411f02e55cdc5aa0c9bb57eeb68f,19,4,1,9387,,,0,"Fix apache listen for keystone and horizon

Apache should listen keystone and horizon ports only on internal
address, but not on 0.0.0.0. Otherwise it conflicts with haproxy
frontends.

Change-Id: I89ff8b8d2352e75d2d3679616a20e48bb42b8eff
Closes-bug: #1459456
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/25/186225/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'tests/noop/spec/hosts/apache/apache_spec.rb', 'deployment/puppet/osnailyfacter/manifests/apache.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/openstack/manifests/horizon.pp']",8,c5182f67697c411f02e55cdc5aa0c9bb57eeb68f,fix-apache-ports," listen_ports => hiera_array('apache_ports', ['8888']),"," listen_ports => hiera_array('apache_ports', ['80', '8888']),",42,7
openstack%2Fsahara~stable%2Fkilo~Ib89844ced79e9ce15c8f6fd186e81b1df8c5fd94,openstack/sahara,stable/kilo,Ib89844ced79e9ce15c8f6fd186e81b1df8c5fd94,Fix management IPs usage,MERGED,2015-05-12 12:16:50.000000000,2015-05-28 03:59:41.000000000,2015-05-28 03:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 9382}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13662}, {'_account_id': 13919}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-05-12 12:16:50.000000000', 'files': ['sahara/tests/unit/plugins/mapr/test_cluster_context.py', 'sahara/plugins/mapr/services/oozie/oozie.py', 'sahara/plugins/mapr/services/mysql/mysql.py', 'sahara/plugins/mapr/domain/node_process.py', 'sahara/plugins/mapr/base/base_cluster_context.py', 'sahara/plugins/mapr/versions/v4_0_2_mrv2/context.py', 'sahara/plugins/mapr/base/base_cluster_configurer.py', 'sahara/plugins/mapr/services/spark/spark.py', 'sahara/plugins/mapr/base/base_node_manager.py', 'sahara/plugins/mapr/services/hive/hive.py', 'sahara/plugins/mapr/services/hue/hue.py', 'sahara/plugins/mapr/util/general.py', 'sahara/plugins/mapr/versions/v4_0_1_mrv2/context.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f196aaddaf77507a7811135e041fa6f7ab0e655', 'message': 'Fix management IPs usage\n\nFixed improper usage of management IPs.\nAlmost all cluster configuration relies on internal IPs\n\nCloses-Bug: #1449506\nCloses-Bug: #1439461\n\nChange-Id: Ib89844ced79e9ce15c8f6fd186e81b1df8c5fd94\n(cherry picked from commit d1d8b79abc1fec24a0f4eac190b3b2ffc210afb9)\n'}]",0,182259,9f196aaddaf77507a7811135e041fa6f7ab0e655,21,15,1,12693,,,0,"Fix management IPs usage

Fixed improper usage of management IPs.
Almost all cluster configuration relies on internal IPs

Closes-Bug: #1449506
Closes-Bug: #1439461

Change-Id: Ib89844ced79e9ce15c8f6fd186e81b1df8c5fd94
(cherry picked from commit d1d8b79abc1fec24a0f4eac190b3b2ffc210afb9)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/59/182259/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/unit/plugins/mapr/test_cluster_context.py', 'sahara/plugins/mapr/services/oozie/oozie.py', 'sahara/plugins/mapr/services/mysql/mysql.py', 'sahara/plugins/mapr/domain/node_process.py', 'sahara/plugins/mapr/base/base_cluster_context.py', 'sahara/plugins/mapr/versions/v4_0_2_mrv2/context.py', 'sahara/plugins/mapr/base/base_cluster_configurer.py', 'sahara/plugins/mapr/services/spark/spark.py', 'sahara/plugins/mapr/base/base_node_manager.py', 'sahara/plugins/mapr/services/hive/hive.py', 'sahara/plugins/mapr/services/hue/hue.py', 'sahara/plugins/mapr/util/general.py', 'sahara/plugins/mapr/versions/v4_0_1_mrv2/context.py']",13,9f196aaddaf77507a7811135e041fa6f7ab0e655,bug/1449506, ip = self.get_instance(yarn.RESOURCE_MANAGER).internal_ip, ip = self.get_instance(yarn.RESOURCE_MANAGER).management_ip,58,45
openstack%2Fsahara~master~I5eba522aac7a9db489e454ba277250470381b51a,openstack/sahara,master,I5eba522aac7a9db489e454ba277250470381b51a,Print traceback in logs for cluster operations,MERGED,2015-05-22 12:13:21.000000000,2015-05-28 03:58:54.000000000,2015-05-28 03:58:52.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13662}, {'_account_id': 13919}]","[{'number': 1, 'created': '2015-05-22 12:13:21.000000000', 'files': ['sahara/service/ops.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7dfc0888b95249b7a0f6c92e2b7c9212e64a9628', 'message': 'Print traceback in logs for cluster operations\n\nChange-Id: I5eba522aac7a9db489e454ba277250470381b51a\nCloses-bug: #1457862\n'}]",0,185004,7dfc0888b95249b7a0f6c92e2b7c9212e64a9628,13,8,1,7710,,,0,"Print traceback in logs for cluster operations

Change-Id: I5eba522aac7a9db489e454ba277250470381b51a
Closes-bug: #1457862
",git fetch https://review.opendev.org/openstack/sahara refs/changes/04/185004/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/ops.py'],1,7dfc0888b95249b7a0f6c92e2b7c9212e64a9628,bug/1457862," LOG.exception(_LE(""Error during operating on cluster (reason: "" ""{reason})"").format(reason=msg)) LOG.exception("," LOG.error(_LE(""Error during operating on cluster (reason: "" ""{reason})"").format(reason=msg)) LOG.error(",3,3
openstack%2Fsahara~stable%2Fkilo~I60913824e15add981857caef7d5bc94cae5f9512,openstack/sahara,stable/kilo,I60913824e15add981857caef7d5bc94cae5f9512,Use ThreadGroup instead of separate threads,MERGED,2015-05-07 13:48:12.000000000,2015-05-28 03:58:52.000000000,2015-05-28 03:58:50.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-05-07 13:48:12.000000000', 'files': ['sahara/plugins/hdp/ambariplugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0d0ee7a86d58fb1d4b0a03f4d16016c1c8590c04', 'message': 'Use ThreadGroup instead of separate threads\n\nThreadGroup can be used for provision_ambari execution. In that case\nwe will wait until successful execution of provision_ambari for all\nservers.\n\nCloses-bug: 1448073\n(cherry picked from commit fbcf8d979ee5f683d26d7c5faaa6bcfbb18eb442)\n\nConflicts:\n\tsahara/plugins/hdp/ambariplugin.py\n\nChange-Id: I60913824e15add981857caef7d5bc94cae5f9512\n'}]",0,180999,0d0ee7a86d58fb1d4b0a03f4d16016c1c8590c04,28,11,1,7710,,,0,"Use ThreadGroup instead of separate threads

ThreadGroup can be used for provision_ambari execution. In that case
we will wait until successful execution of provision_ambari for all
servers.

Closes-bug: 1448073
(cherry picked from commit fbcf8d979ee5f683d26d7c5faaa6bcfbb18eb442)

Conflicts:
	sahara/plugins/hdp/ambariplugin.py

Change-Id: I60913824e15add981857caef7d5bc94cae5f9512
",git fetch https://review.opendev.org/openstack/sahara refs/changes/99/180999/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/hdp/ambariplugin.py'],1,0d0ee7a86d58fb1d4b0a03f4d16016c1c8590c04,bug/1448073," with context.ThreadGroup() as tg: for server in servers: tg.spawn( ""hdp-provision-instance-%s"" % server.instance.hostname(), server.provision_ambari, ambari_info, cluster_spec) with context.ThreadGroup() as tg: for server in servers: tg.spawn('Ambari provisioning thread', server.provision_ambari, ambari_info, cluster_spec)"," def _spawn(self, description, func, *args, **kwargs): context.spawn(description, func, *args, **kwargs) for server in servers: self._spawn( ""hdp-provision-instance-%s"" % server.instance.hostname(), server.provision_ambari, ambari_info, cluster_spec) for server in servers: self._spawn('Ambari provisioning thread', server.provision_ambari, ambari_info, cluster_spec)",11,10
openstack%2Ftaskflow~master~I18bba18992b4dd90ead303b55a3f8a107a90fba5,openstack/taskflow,master,I18bba18992b4dd90ead303b55a3f8a107a90fba5,Allow for sharing the cachedproperty lock,ABANDONED,2015-05-11 19:03:41.000000000,2015-05-28 03:53:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-11 19:03:41.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/runtime.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2a88ec1eea9f1f42dd2d05474b20d0b7e514392a', 'message': 'Allow for sharing the cachedproperty lock\n\nInstead of having N locks (one for each cachedproperty\nused/specified) allow for sharing a common property lock and\nusing a common instance property to ensure that the cached\nproperties are saved in a safe manner.\n\nMaking this possible avoids creating many special (and\nhidden) locks, and allows for explicitly naming the lock that\nshould be used (which is hopefully more understandable).\n\nChange-Id: I18bba18992b4dd90ead303b55a3f8a107a90fba5\n'}]",0,182019,2a88ec1eea9f1f42dd2d05474b20d0b7e514392a,3,1,1,1297,,,0,"Allow for sharing the cachedproperty lock

Instead of having N locks (one for each cachedproperty
used/specified) allow for sharing a common property lock and
using a common instance property to ensure that the cached
properties are saved in a safe manner.

Making this possible avoids creating many special (and
hidden) locks, and allows for explicitly naming the lock that
should be used (which is hopefully more understandable).

Change-Id: I18bba18992b4dd90ead303b55a3f8a107a90fba5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/19/182019/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/runtime.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py']",4,2a88ec1eea9f1f42dd2d05474b20d0b7e514392a,," def __init__(self, fget=None, lock_attr_name=None): if lock_attr_name is None: self._lock_attr_name = None self._lock = threading.RLock() else: # Fetch it later (see __get__)... self._lock_attr_name = lock_attr_name self._lock = None # If a name is provided (as an argument) then this may be the string self._attr_name = self._generate_attr_name(fget) if isinstance(fget, six.string_types): self._attr_name = fget else: self._attr_name = None @staticmethod def _generate_attr_name(func): return ""_%s"" % (func.__name__) # If __init__ received a string (or other keyword arguments) then this # will be the function to be wrapped as a property (if __init__ got a # function then this will not be called). if self._attr_name is None: self._attr_name = self._generate_attr_name(fget) # This is safe to do multiple times (by different threads); as # all that will happen is this will be set multiple times (which # is not harmful). if self._lock is None: self._lock = getattr(instance, self._lock_attr_name)"," def __init__(self, fget): self._lock = threading.RLock() # If a name is provided (as an argument) then this will be the string self._attr_name = ""_%s"" % (fget.__name__) self._attr_name = fget # If __init__ received a string then this will be the function to be # wrapped as a property (if __init__ got a function then this will not # be called).",64,16
openstack%2Fshade~master~I736785896d6d24e18b680d07c82b9922f9d39447,openstack/shade,master,I736785896d6d24e18b680d07c82b9922f9d39447,Make ironic use the API version system,MERGED,2015-05-09 14:22:39.000000000,2015-05-28 03:49:55.000000000,2015-05-28 03:49:53.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2015-05-09 14:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0271afac4359c4877b7e642b3a8fde89785d549a', 'message': 'Make ironic use the API version system\n\nThe other services honor settings for API versions. Make Ironic comply.\n\nChange-Id: I736785896d6d24e18b680d07c82b9922f9d39447\n'}, {'number': 2, 'created': '2015-05-13 16:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4618fd7dbe31abe98c4776bf3d3a6595dee2438c', 'message': 'Make ironic use the API version system\n\nThe other services honor settings for API versions. Make Ironic comply.\n\nChange-Id: I736785896d6d24e18b680d07c82b9922f9d39447\n'}, {'number': 3, 'created': '2015-05-21 14:24:03.000000000', 'files': ['shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/88a12a98fbab037b01e95a92bc79f44a9e9cc25d', 'message': 'Make ironic use the API version system\n\nThe other services honor settings for API versions. Make Ironic comply.\n\nChange-Id: I736785896d6d24e18b680d07c82b9922f9d39447\n'}]",0,181651,88a12a98fbab037b01e95a92bc79f44a9e9cc25d,15,7,3,2,,,0,"Make ironic use the API version system

The other services honor settings for API versions. Make Ironic comply.

Change-Id: I736785896d6d24e18b680d07c82b9922f9d39447
",git fetch https://review.opendev.org/openstack/shade refs/changes/51/181651/3 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,0271afac4359c4877b7e642b3a8fde89785d549a,api-versions," def _get_ironic_api_version(self): return self.api_versions.get('baremetal', '1') self._get_ironic_api_version(), endpoint, token=token,"," '1', endpoint, token=token,",4,1
openstack%2Fsahara~master~I7ea1c91425748f71895b534d7e30af314a710f90,openstack/sahara,master,I7ea1c91425748f71895b534d7e30af314a710f90,Update the docs about how to build images for Sahara usage,MERGED,2015-05-19 14:52:04.000000000,2015-05-28 03:48:13.000000000,2015-05-28 03:48:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13662}, {'_account_id': 13919}]","[{'number': 1, 'created': '2015-05-19 14:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a9d52d72eb8e061605b9cb5f246c9fb0be784c80', 'message': 'Update the docs about how to build images for Sahara usage\n\nChange old diskimage-create.sh to tox env command.\n\nCloses-Bug: #1456251\nChange-Id: I7ea1c91425748f71895b534d7e30af314a710f90\n'}, {'number': 2, 'created': '2015-05-19 16:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dc146ed7d3e1f6550ba06e767aa5c28b14bb788b', 'message': 'Update the docs about how to build images for Sahara usage\n\nChange old diskimage-create.sh to tox env command.\n\nCloses-Bug: #1456251\nChange-Id: I7ea1c91425748f71895b534d7e30af314a710f90\n'}, {'number': 3, 'created': '2015-05-19 16:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7e086b3990e812013776177d4a9ae6f0d94369af', 'message': 'Update the docs about how to build images for Sahara usage\n\nChange old diskimage-create.sh to tox env command.\n\nCloses-Bug: #1456251\nChange-Id: I7ea1c91425748f71895b534d7e30af314a710f90\n'}, {'number': 4, 'created': '2015-05-21 06:49:03.000000000', 'files': ['doc/source/userdoc/diskimagebuilder.rst', 'doc/source/userdoc/cdh_imagebuilder.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/73a5c69cabac99a50501badfa5f0e09d01a0b718', 'message': 'Update the docs about how to build images for Sahara usage\n\nChange old diskimage-create.sh to tox env command.\n\nCloses-Bug: #1456251\nChange-Id: I7ea1c91425748f71895b534d7e30af314a710f90\n'}]",6,184262,73a5c69cabac99a50501badfa5f0e09d01a0b718,25,9,4,13662,,,0,"Update the docs about how to build images for Sahara usage

Change old diskimage-create.sh to tox env command.

Closes-Bug: #1456251
Change-Id: I7ea1c91425748f71895b534d7e30af314a710f90
",git fetch https://review.opendev.org/openstack/sahara refs/changes/62/184262/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/userdoc/diskimagebuilder.rst', 'doc/source/userdoc/cdh_imagebuilder.rst']",2,a9d52d72eb8e061605b9cb5f246c9fb0be784c80,Bug1456251,"images with Cloudera Express (now only 5.0.0, 5.3.0, and 5.4.0 versions are supported).2. Use tox to build images. You can run ""tox -e venv -- sahara-image-create"" command in sahara-image-elements directory to build images. By default this script will attempt to create cloud ""-v 5.0|5.3|5.4"" parameter to assign the version. Below is an example to create Cloudera images for both Ubuntu and CentOS with Cloudera Express 5.4.0 tox -e venv -- sahara-image-create -p cloudera -v 5.4 tox -e venv -- sahara-image-create -p cloudera -i ubuntu -v 5.4 images in the parent directory.","images with Cloudera Express (now only 5.0.0 and 5.3.0 versions are supported).2. Run the diskimage-create.sh script. You can run the script diskimage-create.sh in any directory (for example, in your home directory). By default this script will attempt to create cloud ""-v 5.0|5.3"" parameter to assign the version. Below is an example to create Cloudera images for both Ubuntu and CentOS with Cloudera Express 5.3.0 bash diskimage-create.sh -p cloudera -v 5.3 bash diskimage-create.sh -p cloudera -i ubuntu -v 5.3 images in the current directory.",17,24
openstack%2Fshade~master~I6474bf37835728f70210ad29a3757a4488dfe037,openstack/shade,master,I6474bf37835728f70210ad29a3757a4488dfe037,Handle novaclient exception in delete_server wait,MERGED,2015-05-13 21:13:36.000000000,2015-05-28 03:46:54.000000000,2015-05-28 03:46:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-13 21:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/06f500d7ac159d34760fb9fb43e4c4c41c369ea5', 'message': 'Handle novaclient exception in delete_server wait\n\nWhen a wait is requested, we poll the nova server with the ID of the\ndeleted server until it disappears. We might get an error on that poll,\nand we should wrap that exception to avoid leaking client exceptions.\n\nChange-Id: I6474bf37835728f70210ad29a3757a4488dfe037\n'}, {'number': 2, 'created': '2015-05-24 21:16:43.000000000', 'files': ['shade/tests/unit/test_delete_server.py', 'shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/1dc1d25b8e1510e910f62a7ebb981af0298e336c', 'message': 'Handle novaclient exception in delete_server wait\n\nWhen a wait is requested, we poll the nova server with the ID of the\ndeleted server until it disappears. We might get an error on that poll,\nand we should wrap that exception to avoid leaking client exceptions.\n\nChange-Id: I6474bf37835728f70210ad29a3757a4488dfe037\n'}]",1,182846,1dc1d25b8e1510e910f62a7ebb981af0298e336c,13,5,2,6488,,,0,"Handle novaclient exception in delete_server wait

When a wait is requested, we poll the nova server with the ID of the
deleted server until it disappears. We might get an error on that poll,
and we should wrap that exception to avoid leaking client exceptions.

Change-Id: I6474bf37835728f70210ad29a3757a4488dfe037
",git fetch https://review.opendev.org/openstack/shade refs/changes/46/182846/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_delete_server.py', 'shade/__init__.py']",2,06f500d7ac159d34760fb9fb43e4c4c41c369ea5,182846," except Exception as e: self.log.debug(""nova get server failed"", exc_info=True) raise OpenStackCloudException( ""Error in deleting server: {0}"".format(e))",,34,8
openstack%2Fshade~master~I0c5cf52a0315cee4a84ee4b3ff205778f461af2e,openstack/shade,master,I0c5cf52a0315cee4a84ee4b3ff205778f461af2e,Handle novaclient exceptions during delete_server,MERGED,2015-05-13 21:13:36.000000000,2015-05-28 03:46:41.000000000,2015-05-28 03:46:39.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}, {'_account_id': 6488}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-13 21:13:36.000000000', 'files': ['shade/tests/unit/test_delete_server.py', 'shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/a0a36b849af1a8706872bbf598323dc0725c9bdd', 'message': 'Handle novaclient exceptions during delete_server\n\nCurrently they are allowed to bubble up without being caught.\n\nChange-Id: I0c5cf52a0315cee4a84ee4b3ff205778f461af2e\n'}]",0,182845,a0a36b849af1a8706872bbf598323dc0725c9bdd,18,6,1,6488,,,0,"Handle novaclient exceptions during delete_server

Currently they are allowed to bubble up without being caught.

Change-Id: I0c5cf52a0315cee4a84ee4b3ff205778f461af2e
",git fetch https://review.opendev.org/openstack/shade refs/changes/45/182845/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_delete_server.py', 'shade/__init__.py']",2,a0a36b849af1a8706872bbf598323dc0725c9bdd,," try: self.manager.submitTask(_tasks.ServerDelete(server=server.id)) except nova_exceptions.NotFound: return except Exception as e: self.log.debug(""nova delete server failed"", exc_info=True) raise OpenStackCloudException( ""Error in deleting server: {0}"".format(e))", self.manager.submitTask(_tasks.ServerDelete(server=server.id)),37,1
openstack%2Fsahara-image-elements~master~I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc,openstack/sahara-image-elements,master,I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc,Add CDH5.4.0 support,MERGED,2015-04-27 06:43:54.000000000,2015-05-28 03:26:24.000000000,2015-05-28 03:26:22.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7604}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12320}, {'_account_id': 13662}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-04-27 06:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/74188b4f0741073d837fc6883f5e273380434e78', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}, {'number': 2, 'created': '2015-05-05 12:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/c3bc1df07f3ceef25037b516562fb426fbf93606', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}, {'number': 3, 'created': '2015-05-06 13:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/cf21182f6b3bf7270dede9f842a8052228c34dd0', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}, {'number': 4, 'created': '2015-05-06 17:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/7016c26e5feeecec4dc44f7259aa98d10414eca0', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}, {'number': 5, 'created': '2015-05-18 10:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/a79210f6a03d6013c39632696eba273013ec6adc', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}, {'number': 6, 'created': '2015-05-19 14:11:16.000000000', 'files': ['elements/hadoop-cloudera/pre-install.d/10-add-mirror', 'diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/c2a329c79a32b01e43b1cab7b4d2d0df05ac8c9b', 'message': 'Add CDH5.4.0 support\n\nWe add CDH5.4.0 support into current codes.\n\nPartial-implements bp: cdh-5-4-support\nChange-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc\n'}]",10,177659,c2a329c79a32b01e43b1cab7b4d2d0df05ac8c9b,73,14,6,13662,,,0,"Add CDH5.4.0 support

We add CDH5.4.0 support into current codes.

Partial-implements bp: cdh-5-4-support
Change-Id: I4e1338ef2283f41a9b37d0a55a75ff9dd1e286dc
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/59/177659/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop-cloudera/pre-install.d/10-add-mirror', 'diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera']",3,74188b4f0741073d837fc6883f5e273380434e78,bp/cdh-5-4-support,"HADOOP_OPENSTACK_5_4_0_URL=""https://repository.cloudera.com/artifactory/repo/org/apache/hadoop/hadoop-openstack/2.6.0-cdh5.4.0/hadoop-openstack-2.6.0-cdh5.4.0.jar"" 5.4) wget -O $dest $HADOOP_OPENSTACK_5_4_0_URL ;;",,90,10
openstack%2Ffuel-library~master~Id24eb49bda02efc5e9776b9441f211d96e7325e5,openstack/fuel-library,master,Id24eb49bda02efc5e9776b9441f211d96e7325e5,Allow for erlang_cookie from hiera,MERGED,2015-05-27 19:00:16.000000000,2015-05-28 03:24:35.000000000,2015-05-28 03:23:58.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14168}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-27 19:00:16.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/34e36fbf7e335d2d705896e2d5edbce1329fb7dd', 'message': 'Allow for erlang_cookie from hiera\n\nCurrently the erlang_cookie for rabbitmq was hard coded but there\nwas a hiera lookup for a erlang_cookie value. This change uses\nthe hiera lookup to allow for erlang_cookies to be specified via\nhiera but will default to the previous hardcoded value if no value\nis present in hiera.\n\nChange-Id: Id24eb49bda02efc5e9776b9441f211d96e7325e5\nCloses-Bug: 1459315\n'}]",0,186128,34e36fbf7e335d2d705896e2d5edbce1329fb7dd,25,5,1,14985,,,0,"Allow for erlang_cookie from hiera

Currently the erlang_cookie for rabbitmq was hard coded but there
was a hiera lookup for a erlang_cookie value. This change uses
the hiera lookup to allow for erlang_cookies to be specified via
hiera but will default to the previous hardcoded value if no value
is present in hiera.

Change-Id: Id24eb49bda02efc5e9776b9441f211d96e7325e5
Closes-Bug: 1459315
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/186128/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq.pp'],1,34e36fbf7e335d2d705896e2d5edbce1329fb7dd,bug/1459315," erlang_cookie => $erlang_cookie,"," #TODO(bogdando) make erlang cookie as a hiera(astute) value. erlang_cookie => 'EOKOWXQREETZSHFNTPEY',",1,2
openstack%2Fsahara-image-elements~master~I53310a1a223681170b5993b9cdefd0ebbe460424,openstack/sahara-image-elements,master,I53310a1a223681170b5993b9cdefd0ebbe460424,Do input check based on each plugin,MERGED,2015-05-13 06:33:46.000000000,2015-05-28 03:22:17.000000000,2015-05-28 03:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9382}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12320}, {'_account_id': 13919}, {'_account_id': 13953}, {'_account_id': 14778}]","[{'number': 1, 'created': '2015-05-13 06:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/4b818ace0ca87d5be574bae0c4b193098a59ed74', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 2, 'created': '2015-05-13 06:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/7663fd7ae90243b364591ace7802dcbdccd14aea', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 3, 'created': '2015-05-13 06:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/5e661c1ebda908b7a9cca30d10e303c91853634a', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 4, 'created': '2015-05-14 02:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/eec9ffd3d8049b02ca27d6f2986c73739f3395d8', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 5, 'created': '2015-05-14 02:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/afcf88d3cf02523c5271ada0fc998cddb8349fb1', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 6, 'created': '2015-05-15 01:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d216b6aca8f57abcb4d7faac8e3f68766466042c', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\nCloses-Bug: #1441583\nCloses-Bug: #1441585\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 7, 'created': '2015-05-15 01:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d03d16b7a841369766615df83c68797a8faf1625', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\nCloses-Bug: #1441583\nCloses-Bug: #1441585\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}, {'number': 8, 'created': '2015-05-19 01:08:44.000000000', 'files': ['diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/08346dc060647e246ac82438078db4a94bf1c030', 'message': 'Do input check based on each plugin\n\nEach plugin has different requirments for input values.\nWe should do input check based on plugin.\n\nCloses-Bug: #1453057\nCloses-Bug: #1441583\nCloses-Bug: #1441585\nCloses-Bug: #1441589\n\nChange-Id: I53310a1a223681170b5993b9cdefd0ebbe460424\n'}]",6,182549,08346dc060647e246ac82438078db4a94bf1c030,45,15,8,6116,,,0,"Do input check based on each plugin

Each plugin has different requirments for input values.
We should do input check based on plugin.

Closes-Bug: #1453057
Closes-Bug: #1441583
Closes-Bug: #1441585
Closes-Bug: #1441589

Change-Id: I53310a1a223681170b5993b9cdefd0ebbe460424
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/49/182549/2 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,4b818ace0ca87d5be574bae0c4b193098a59ed74,input_check,"if [ ""$PLUGIN"" = ""vanilla"" ]; then if [ ""$HADOOP_VERSION"" != ""1"" -a ""$HADOOP_VERSION"" != ""2.6""]; then echo -e ""Unknown hadoop version selected.\nAborting"" exit 1 if [ ""$PLUGIN"" = ""cloudera""]; then if [ ""$BASE_IMAGE_OS"" = ""fedora"" ]; then echo -e ""Impossible combination.\nAborting"" exit 1 fi if [ ""$HADOOP_VERSION"" != ""5.0"" -a ""$HADOOP_VERSION"" != ""5.3""]; then echo -e ""Unknown hadoop version selected.\nAborting"" exit 1 fiif [ ""$PLUGIN"" = ""spark"" ]; then if [ -n ""$BASE_IMAGE_OS"" -a ""$BASE_IMAGE_OS"" != ""ubuntu"" ]; then echo -e ""'$BASE_IMAGE_OS' image type is not supported by 'spark'.\nAborting"" exit 1 fi if [ -n ""$HADOOP_VERSION"" ]; then echo -e ""You shouldn't specify hadoop version for 'spark'.\nAborting"" exit 1 fiif [ ""$PLUGIN"" = ""hdp"" ]; then if [-n ""$BASE_IMAGE_OS"" -a ""$BASE_IMAGE_OS"" != ""centos"" ]; then echo -e ""'$BASE_IMAGE_OS' image type is not supported by 'hdp'.\nAborting"" exit 1 fi if [ ""$HADOOP_VERSION"" != ""1"" -a ""$HADOOP_VERSION"" != ""2""]; then echo -e ""Unknown hadoop version selected.\nAborting"" exit 1 fiif [ ""$PLUGIN"" = ""mapr"" ]; then if [ ""$BASE_IMAGE_OS"" = ""fedora"" ]; then echo -e ""'fedora' image type is not supported by 'mapr' plugin.\nAborting"" exit 1 fi if [ -z ""$DIB_MAPR_VERSION"" ]; then echo ""MapR version is not specified"" echo ""${DIB_DEFAULT_MAPR_VERSION} version would be used"" DIB_MAPR_VERSION=${DIB_DEFAULT_MAPR_VERSION} fi ","if [ -n ""$HADOOP_VERSION"" -a ""$HADOOP_VERSION"" != ""1"" -a ""$HADOOP_VERSION"" != ""2"" ]; then if [ ""$PLUGIN"" = ""vanilla"" -a ""$HADOOP_VERSION"" != ""1"" -a ""$HADOOP_VERSION"" != ""2.6"" ]; then if [ ""$PLUGIN"" = ""cloudera"" -a ""$HADOOP_VERSION"" != ""5.0"" -a ""$HADOOP_VERSION"" != ""5.3"" ]; then echo -e ""Unknown hadoop version selected.\nAborting"" exit 1 fiif [ ""$PLUGIN"" = ""cloudera"" -a ""$BASE_IMAGE_OS"" = ""fedora"" ]; then echo -e ""Impossible combination.\nAborting"" exit 1if [ -n ""$BASE_IMAGE_OS"" -a ""$PLUGIN"" = ""spark"" -a ""$BASE_IMAGE_OS"" != ""ubuntu"" ]; then echo -e ""'$BASE_IMAGE_OS' image type is not supported by 'spark'.\nAborting"" exit 1if [-n ""$BASE_IMAGE_OS"" -a ""$PLUGIN"" = ""hdp"" -a ""$BASE_IMAGE_OS"" != ""centos"" ]; then echo -e ""'$BASE_IMAGE_OS' image type is not supported by 'hdp'.\nAborting"" exit 1 fi if [ ""$PLUGIN"" = ""mapr"" -a ""$BASE_IMAGE_OS"" = ""fedora"" ]; then echo -e ""'fedora' image type is not supported by 'mapr' plugin.\nAborting"" exit 1if [ ""$PLUGIN"" = ""mapr"" -a -z ""$DIB_MAPR_VERSION"" ]; then echo ""MapR version is not specified"" echo ""${DIB_DEFAULT_MAPR_VERSION} version would be used"" DIB_MAPR_VERSION=${DIB_DEFAULT_MAPR_VERSION} fi if [ ""$PLUGIN"" = ""mapr"" ]; then",47,25
openstack%2Fsenlin~master~I994aae02f703186c7c15d7b86751393dc09367c4,openstack/senlin,master,I994aae02f703186c7c15d7b86751393dc09367c4,Fix catalog error when finding user_id from user_name,MERGED,2015-05-27 14:02:29.000000000,2015-05-28 03:18:44.000000000,2015-05-28 03:18:42.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-05-27 14:02:29.000000000', 'files': ['senlin/api/middleware/trust.py', 'senlin/drivers/openstack/sdk.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4c9ff23b3bf64a6d19635bb0d4bdf8fdd0d41f53', 'message': 'Fix catalog error when finding user_id from user_name\n\nFix catalog error when finding user_id from user_name\n\nChange-Id: I994aae02f703186c7c15d7b86751393dc09367c4\nCloses-Bug: #1459258\n'}]",0,186006,4c9ff23b3bf64a6d19635bb0d4bdf8fdd0d41f53,7,3,1,7404,,,0,"Fix catalog error when finding user_id from user_name

Fix catalog error when finding user_id from user_name

Change-Id: I994aae02f703186c7c15d7b86751393dc09367c4
Closes-Bug: #1459258
",git fetch https://review.opendev.org/openstack/senlin refs/changes/06/186006/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/middleware/trust.py', 'senlin/drivers/openstack/sdk.py']",2,4c9ff23b3bf64a6d19635bb0d4bdf8fdd0d41f53,bug/1459258," 'project_name': ctx.project_name,",,4,1
openstack%2Fsahara-image-elements~master~I27b681c0ecbb9e257ef46c6dd590ba55f1d4f513,openstack/sahara-image-elements,master,I27b681c0ecbb9e257ef46c6dd590ba55f1d4f513,Fix problem with set up java env variable,MERGED,2015-05-19 13:22:40.000000000,2015-05-28 03:14:36.000000000,2015-05-28 03:14:34.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-05-19 13:22:40.000000000', 'files': ['elements/java/bin/setup-java-home'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/be0757f0dd3271c905c7557c5ded39dac36d4470', 'message': 'Fix problem with set up java env variable\n\nChange-Id: I27b681c0ecbb9e257ef46c6dd590ba55f1d4f513\nCloses-bug: #1456633\n'}]",0,184244,be0757f0dd3271c905c7557c5ded39dac36d4470,14,8,1,7710,,,0,"Fix problem with set up java env variable

Change-Id: I27b681c0ecbb9e257ef46c6dd590ba55f1d4f513
Closes-bug: #1456633
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/44/184244/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/java/bin/setup-java-home'],1,be0757f0dd3271c905c7557c5ded39dac36d4470,bug/1456633,"echo ""export JAVA_HOME=$JRE_HOME"" >> $JAVA_RC","echo ""JAVA_HOME=$JRE_HOME"" >> $JAVA_RC",1,1
openstack%2Fsahara-image-elements~master~Ic066d341cad98a0b5bde0172825ca400629e0f16,openstack/sahara-image-elements,master,Ic066d341cad98a0b5bde0172825ca400629e0f16,Remove unneeded code from HDP element,MERGED,2015-05-06 10:40:04.000000000,2015-05-28 03:14:29.000000000,2015-05-28 03:14:28.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13919}]","[{'number': 1, 'created': '2015-05-06 10:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/7b5b7c842bd062021497462b60f1e41734d0d0de', 'message': ""[WIP] Remove unneeded code from HDP element\n\nThis code already have in various rhel elements like 'rpm-distro' and\netc.\n\nChange-Id: Ic066d341cad98a0b5bde0172825ca400629e0f16\n""}, {'number': 2, 'created': '2015-05-06 11:27:48.000000000', 'files': ['elements/hadoop-hdp/install.d/30-init-hdp-install', 'elements/hadoop-hdp/post-install.d/20-cleanup', 'elements/hadoop-hdp/install.d/20-nozeroconf'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/0b1c896913aa9801a1ec108d31f26756bdb36563', 'message': ""Remove unneeded code from HDP element\n\nThis code already have in various rhel elements like 'rpm-distro' and\netc.\n\nChange-Id: Ic066d341cad98a0b5bde0172825ca400629e0f16""}]",0,180478,0b1c896913aa9801a1ec108d31f26756bdb36563,18,8,2,7710,,,0,"Remove unneeded code from HDP element

This code already have in various rhel elements like 'rpm-distro' and
etc.

Change-Id: Ic066d341cad98a0b5bde0172825ca400629e0f16",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/78/180478/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop-hdp/install.d/30-init-hdp-install', 'elements/hadoop-hdp/post-install.d/20-cleanup', 'elements/hadoop-hdp/install.d/20-nozeroconf']",3,7b5b7c842bd062021497462b60f1e41734d0d0de,remove-unneeded-hdp,,"#!/bin/bash # Copyright (c) 2013 Hortonworks, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. ########################################################## # Element Script for configuring nozeroconf in HDP Install # # This setting is necessary to disable the routing rule that is otherwise injected into the image # Routing rule prevents cloud-init from contacting meta data service on quantum # See: https://bugzilla.redhat.com/show_bug.cgi?id=983611 if [ ""${DIB_DEBUG_TRACE:-0}"" -gt 0 ]; then set -x fi set -eu set -o pipefail echo ""NOZEROCONF=yes"" >> /etc/sysconfig/network ",0,110
openstack%2Fdevstack~master~I1ee90693378e83f2b0f16acdca8a04e78def410f,openstack/devstack,master,I1ee90693378e83f2b0f16acdca8a04e78def410f,Fix role list arguments error,ABANDONED,2015-05-18 03:20:23.000000000,2015-05-28 03:02:20.000000000,,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 12175}, {'_account_id': 14320}]","[{'number': 1, 'created': '2015-05-18 03:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fa91a836917b9dc450ee5c75977356a7484f8728', 'message': 'Fix role list arguments error\n\nos-identity-api-version v2 not support --group, fix it by using v3.\n\nCloses-Bug: 1456017\nChange-Id: I1ee90693378e83f2b0f16acdca8a04e78def410f\n'}, {'number': 2, 'created': '2015-05-27 09:07:39.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6f0ae50bde5f85a6cfee377ecced376cf75b5dda', 'message': 'Fix role list arguments error\n\nos-identity-api-version v2 not support --group, fix it by using v3.\n\nCloses-Bug: #1441010\nChange-Id: I1ee90693378e83f2b0f16acdca8a04e78def410f\n'}]",0,183965,6f0ae50bde5f85a6cfee377ecced376cf75b5dda,17,5,2,12175,,,0,"Fix role list arguments error

os-identity-api-version v2 not support --group, fix it by using v3.

Closes-Bug: #1441010
Change-Id: I1ee90693378e83f2b0f16acdca8a04e78def410f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/65/183965/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,fa91a836917b9dc450ee5c75977356a7484f8728,bug/1456017, local group_role_id=$(openstack --os-identity-api-version=3 role list \ group_role_id=$(openstack role --os-identity-api-version=3 add \, local group_role_id=$(openstack role list \ group_role_id=$(openstack role add \,2,2
openstack%2Fneutron-lbaas~stable%2Fkilo~I9bb16402cd08cd62a3be887d00c373a34a846652,openstack/neutron-lbaas,stable/kilo,I9bb16402cd08cd62a3be887d00c373a34a846652,Updated from global requirements,MERGED,2015-04-28 19:57:42.000000000,2015-05-28 02:58:45.000000000,2015-05-28 02:58:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11628}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-04-28 19:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/4d669aaf8f8c6c1fb3c97c23c53dd3b260abb4e7', 'message': 'Updated from global requirements\n\nChange-Id: I9bb16402cd08cd62a3be887d00c373a34a846652\n'}, {'number': 2, 'created': '2015-05-04 20:13:52.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/4ab10135f2571727689ad74000a419c00977bef8', 'message': 'Updated from global requirements\n\nChange-Id: I9bb16402cd08cd62a3be887d00c373a34a846652\n'}]",0,178373,4ab10135f2571727689ad74000a419c00977bef8,17,7,2,11131,,,0,"Updated from global requirements

Change-Id: I9bb16402cd08cd62a3be887d00c373a34a846652
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/73/178373/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,4d669aaf8f8c6c1fb3c97c23c53dd3b260abb4e7,openstack/requirements,"tempest-lib>=0.4.0,<0.5.0",tempest-lib>=0.4.0,1,1
openstack%2Fneutron~stable%2Fkilo~Id0ac9399ec39fef19ce71566670ed245c681192e,openstack/neutron,stable/kilo,Id0ac9399ec39fef19ce71566670ed245c681192e,Make sure OVS restarts when Exception occurred,MERGED,2015-05-08 07:59:44.000000000,2015-05-28 02:58:36.000000000,2015-05-28 02:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 11343}, {'_account_id': 14039}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-05-08 07:59:44.000000000', 'files': ['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/63c8ea1aced0f37cd6800ba99a416207d9c99eb2', 'message': 'Make sure OVS restarts when Exception occurred\n\nThis fix let flows in br-tun automatically recover from an Exception,\nwhich is an ideal situation.\nSimplly improve a missed flag will make sure OVS restart properly\nafter we walked out of Exception loop.\n\nCloses-Bug: #1439472\n(cherry picked from commit d72572729152e709c5f7ebae2896d5f66748b59b)\n\nConflicts:\n\tneutron/plugins/openvswitch/agent/ovs_neutron_agent.py\n\nChange-Id: Id0ac9399ec39fef19ce71566670ed245c681192e\n'}]",0,181319,63c8ea1aced0f37cd6800ba99a416207d9c99eb2,25,21,1,14039,,,0,"Make sure OVS restarts when Exception occurred

This fix let flows in br-tun automatically recover from an Exception,
which is an ideal situation.
Simplly improve a missed flag will make sure OVS restart properly
after we walked out of Exception loop.

Closes-Bug: #1439472
(cherry picked from commit d72572729152e709c5f7ebae2896d5f66748b59b)

Conflicts:
	neutron/plugins/openvswitch/agent/ovs_neutron_agent.py

Change-Id: Id0ac9399ec39fef19ce71566670ed245c681192e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/181319/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",2,63c8ea1aced0f37cd6800ba99a416207d9c99eb2,bug/1439472," ovs_restarted = False ovs_restarted |= (ovs_status == constants.OVS_RESTARTED) # Keep this flag in the last line of ""try"" block, # so we can sure that no other Exception occurred. if not sync: ovs_restarted = False", ovs_restarted = (ovs_status == constants.OVS_RESTARTED),20,15
openstack%2Fmanila~master~Ib0e53befbd48e5cbfea98a52876f381384beb268,openstack/manila,master,Ib0e53befbd48e5cbfea98a52876f381384beb268,glusterfs: Edit doc and comments,MERGED,2015-05-25 06:14:50.000000000,2015-05-28 02:35:16.000000000,2015-05-28 02:35:14.000000000,"[{'_account_id': 3}, {'_account_id': 7102}, {'_account_id': 8056}, {'_account_id': 8851}, {'_account_id': 9521}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-05-25 06:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cc4dabd9ad305331cd1df1f7ebc1e43544cf200d', 'message': 'glusterfs: Edit doc and comments\n\nEdit doc and comments to mention that the driver\n- can work with NFS-Ganesha, used by the GlusterFS backend to serve\n  NFS shares.\n- does not provide read-only access level for shares.\n\nAnd add some minor cosmetic fixes to the doc.\n\nChange-Id: Ib0e53befbd48e5cbfea98a52876f381384beb268\n'}, {'number': 2, 'created': '2015-05-27 06:49:41.000000000', 'files': ['manila/share/drivers/glusterfs.py', 'doc/source/devref/glusterfs_driver.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/4dbe4294083ba941521f7c4eb4998a84d112c006', 'message': 'glusterfs: Edit doc and comments\n\nEdit doc and comments to mention that the driver\n- can work with NFS-Ganesha, used by the GlusterFS backend to serve\n  NFS shares.\n- does not provide read-only access level for shares.\n\nAnd add some minor cosmetic fixes to the doc.\n\nChange-Id: Ib0e53befbd48e5cbfea98a52876f381384beb268\n'}]",2,185309,4dbe4294083ba941521f7c4eb4998a84d112c006,14,8,2,8056,,,0,"glusterfs: Edit doc and comments

Edit doc and comments to mention that the driver
- can work with NFS-Ganesha, used by the GlusterFS backend to serve
  NFS shares.
- does not provide read-only access level for shares.

And add some minor cosmetic fixes to the doc.

Change-Id: Ib0e53befbd48e5cbfea98a52876f381384beb268
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/185309/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/glusterfs.py', 'doc/source/devref/glusterfs_driver.rst']",2,cc4dabd9ad305331cd1df1f7ebc1e43544cf200d,glusterfs-doc-comments-fixes," * only 'rw' access - Install NFS-Ganesha, version >=2.1, if using NFS-Ganesha as the NFS server for the GlusterFS backend. * `glusterfs_target` = <glustervolserver>:/<glustervolid> * `glusterfs_target` = <username>@<glustervolserver>:/<glustervolid>- `glusterfs_nfs_server_type` = <NFS server type used by the GlusterFS backend, `Gluster` or `Ganesha`. `Gluster` is the default type>- The driver does not support network segmented multi-tenancy model, but instead works over a flat network, where the tenants share a network. - If NFS Ganesha is the NFS server used by the GlusterFS backend, then the shares can be accessed by NFSv3 and v4 protocols. However, if Gluster NFS is used by the GlusterFS backend, then the shares can only be accessed by NFSv3 protocol.- The driver does not provide read-only access level for shares."," - `glusterfs_target` = <glustervolserver>:/<glustervolid> - `glusterfs_target` = <username>@<glustervolserver>:/<glustervolid>- The driver does not support network segmented multi-tenancy model instead works over a flat network, where the tenants share a network. - NFSv3 is the only protocol that can be used to access the shares. This is because the shares are mediated in the backend GlusterFS by the Gluster-NFS server that supports only NFSv3 protocol.",24,11
openstack%2Fmanila~master~Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97,openstack/manila,master,Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97,Make devstack install manila-ui if horizon is enabled,MERGED,2015-05-21 13:15:36.000000000,2015-05-28 02:27:24.000000000,2015-05-28 02:27:22.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 9366}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-21 13:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/34dad689ab61a60b1074a8ea9bc15bb673fec208', 'message': 'Update devstack plugin to pull in manila-ui if horizon is enabled\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 2, 'created': '2015-05-21 13:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/39653ecad5c671060213bc671f93e0d46d6313e1', 'message': 'Update devstack plugin to pull in manila-ui if horizon is enabled\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 3, 'created': '2015-05-21 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/adde93115956727c6977975cbd9922a6cc70186f', 'message': 'Update devstack plugin to pull in manila-ui if horizon is enabled\n\nDepends-On: 184788\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 4, 'created': '2015-05-21 13:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/188ac3bf4e9cd4e3bcae2e1bf76748252951932c', 'message': 'Update devstack plugin to pull in manila-ui if horizon is enabled\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 5, 'created': '2015-05-21 15:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/21ab6920b62b7969459372cb624c316baa45dc91', 'message': 'Update devstack plugin to pull in manila-ui if horizon is enabled\n\nMake devstack install manila-ui if horizon is enabled\nFor the moment our devstack plugin can not install manila-ui plugin\nto horizon. But it would be really useful thing to do.\nInstalling devstack with enabled manila we will have manila-ui plugin\ninstalled into horizon by default.\n\nUse env var ""MANILA_UI_ENABLED"" (default=True) to enable/disable its\ninstallation.\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 6, 'created': '2015-05-21 15:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0bcc257bbc9ba23ea0bd5369175d4952296488dc', 'message': 'Make devstack install manila-ui if horizon is enabled\n\nFor the moment, our devstack plugin can not install manila-ui plugin\nto horizon. But it would be really useful thing to do.\nInstalling devstack with enabled manila we will have manila-ui plugin\ninstalled into horizon by default.\n\nUse env var ""MANILA_UI_ENABLED"" (default=True) to enable/disable its\ninstallation.\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 7, 'created': '2015-05-26 12:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e3a33859a814871dcc6fe6c9eeb6d14be8c4f0dd', 'message': 'Make devstack install manila-ui if horizon is enabled\n\nFor the moment, our devstack plugin can not install manila-ui plugin\nto horizon. But it would be really useful thing to do.\nInstalling devstack with enabled manila we will have manila-ui plugin\ninstalled into horizon by default.\n\nUse env var ""MANILA_UI_ENABLED"" (default=True) to enable/disable its\ninstallation.\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}, {'number': 8, 'created': '2015-05-27 09:59:05.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/770c272b672d3cd18c35102ed1945b4e67327035', 'message': 'Make devstack install manila-ui if horizon is enabled\n\nFor the moment, our devstack plugin can not install manila-ui plugin\nto horizon. But it would be really useful thing to do.\nInstalling devstack with enabled manila we will have manila-ui plugin\ninstalled into horizon by default.\n\nUse env var ""MANILA_UI_ENABLED"" (default=True) to enable/disable its\ninstallation.\n\nDepends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n\nChange-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\n'}]",3,184778,770c272b672d3cd18c35102ed1945b4e67327035,38,9,8,14232,,,0,"Make devstack install manila-ui if horizon is enabled

For the moment, our devstack plugin can not install manila-ui plugin
to horizon. But it would be really useful thing to do.
Installing devstack with enabled manila we will have manila-ui plugin
installed into horizon by default.

Use env var ""MANILA_UI_ENABLED"" (default=True) to enable/disable its
installation.

Depends-On: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354

Change-Id: Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97
",git fetch https://review.opendev.org/openstack/manila refs/changes/78/184778/6 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,34dad689ab61a60b1074a8ea9bc15bb673fec208,devstack_manila_ui,"MANILA_UI_REPO=${MANILA_GIT_BASE}/${MANILA_REPO_ROOT}/manila-ui.git MANILA_UI_BRANCH=${MANILA_UI_BRANCH:-master} MANILA_UI_DIR=${MANILA_UI_DIR:=$DEST/manila-ui} if is_service_enabled horizon; then configure_manila_ui fi } function configure_manila_ui { setup_develop $MANILA_UI_DIR local local_settings=$HORIZON_DIR/openstack_dashboard/local/local_settings.py _horizon_config_set $local_settings ""HORIZON_CONFIG"" customization_module ""'manila_ui.overrides'"" cp $MANILA_UI_DIR/manila_ui/enabled/_90_manila_*.py $HORIZON_DIR/openstack_dashboard/local/enabled } # install manila-ui if horizon is enabled if is_service_enabled horizon; then git_clone $MANILA_UI_REPO $MANILA_UI_DIR $MANILA_UI_BRANCH fi",} ,23,0
openstack%2Fneutron-specs~master~I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271,openstack/neutron-specs,master,I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271,Shorten the spec template greatly.,MERGED,2015-05-14 00:47:19.000000000,2015-05-28 01:57:22.000000000,2015-05-28 01:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 11753}, {'_account_id': 12525}]","[{'number': 1, 'created': '2015-05-14 00:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e3ede3855790cc25ac8b06e82185de407f956c31', 'message': 'An abbreviated spec template for simpler changes\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n'}, {'number': 2, 'created': '2015-05-22 17:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0131e5abc2c84420fba069295829538a47e07076', 'message': 'An abbreviated spec template for simpler changes\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n'}, {'number': 3, 'created': '2015-05-22 17:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9083ba8a1a24cb360ea8173c3d0d78717c20dcb4', 'message': 'An abbreviated spec template for simpler changes\n\nVerbiage shamelessly borrowed from Nova (thanks, Nova!)\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n'}, {'number': 4, 'created': '2015-05-22 17:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cba9a7641745e43a5c4df2d7c7ec4f9f54e6c8f6', 'message': 'An abbreviated spec template for simpler changes\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n'}, {'number': 5, 'created': '2015-05-27 00:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5586446553e7fdb599b1331313fe773b49f6d5d4', 'message': 'Shorten the spec template greatly.\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n'}, {'number': 6, 'created': '2015-05-27 03:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c866ddacedc50d33632c77c46fd58fcb283abeeb', 'message': ""Shorten the spec template greatly.\n\nSince neutron is moving to using RFE's for features, only the larger\nor contentious features will require specs. This change removes many\nof the spec sections that will become redundant with the information\nincluded in the RFE itself and the devref developer docs that are now\nexpected with the code.\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n""}, {'number': 7, 'created': '2015-05-27 16:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6f5b2fcc938175edd6d6a336986e3cf92185fc66', 'message': ""Shorten the spec template greatly.\n\nSince neutron is moving to using RFE's for features, only the larger\nor contentious features will require specs. This change removes many\nof the spec sections that will become redundant with the information\nincluded in the RFE itself and the devref developer docs that are now\nexpected with the code.\n\nAlso, comment out the rigid section checking test, which now bombs on\nolder specs, and is likely unnecessary with so few sections.\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n""}, {'number': 8, 'created': '2015-05-27 23:39:54.000000000', 'files': ['tests/test_titles.py', 'specs/template.rst', 'specs/skeleton.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/81ceb74eb516884f875c506b63695eae5922a897', 'message': ""Shorten the spec template greatly.\n\nSince neutron is moving to using RFE's for features, only the larger\nor contentious features will require specs. This change removes many\nof the spec sections that will become redundant with the information\nincluded in the RFE itself and the devref developer docs that are now\nexpected with the code.\n\nAlso, tweak the py27 test to accept both old and new spec formats\n\nChange-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271\n""}]",30,182905,81ceb74eb516884f875c506b63695eae5922a897,41,12,8,10980,,,0,"Shorten the spec template greatly.

Since neutron is moving to using RFE's for features, only the larger
or contentious features will require specs. This change removes many
of the spec sections that will become redundant with the information
included in the RFE itself and the devref developer docs that are now
expected with the code.

Also, tweak the py27 test to accept both old and new spec formats

Change-Id: I5aeb2cb39740ac85e0485f4e26d6fb380bd4d271
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/05/182905/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/template-short.rst'],1,e3ede3855790cc25ac8b06e82185de407f956c31,short-spec-template,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/example Introduction paragraph -- why are we doing anything? A single paragraph of prose that **operators, deployers, and developers** can understand. This abbreviated template can be used for smaller or obvious features, or as an initial placeholder for a later design. If it's smaller than a breadbox, you can try submitting this, though the drivers team may ask for the longer version to be submitted. Certain assumptions are made for anything filed with an abbreviated spec: * Any data model or REST interface changes are obvious from the description. * There is no security, performance, IPv6, or strange deployer impact. * The change is simple enough that a list of work items would be redundant. * There are no serious dependencies on other blueprints. * Full unit, api, and functional tests will be part of the change. * Any documentation changes will be automatic or part of the change. Problem Description =================== A detailed description of the problem: * For a new feature this should be use cases. Ensure you are clear about the actors in each use case: End User vs Deployer * For a major reworking of something existing it would describe the problems in that feature that are being addressed. Proposed Change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the API, discussion of how other plugins would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. link any vendor documentation) * Anything else you feel it is worthwhile to refer to ",,95,0
openstack%2Fstevedore~master~I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b,openstack/stevedore,master,I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b,Add sphinx integration,MERGED,2015-05-16 17:57:55.000000000,2015-05-28 01:54:58.000000000,2015-05-28 01:54:56.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 9162}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-05-16 17:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/20db35bd2f1ec197d4b381c3c03b853cd8543b30', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 2, 'created': '2015-05-16 18:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/ec5169ca6618a52e6b7f89ace379104c22dbd368', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 3, 'created': '2015-05-16 19:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/458667094aa46d1d802ee35ed65b4cc3238b67f6', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 4, 'created': '2015-05-16 19:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/fb711e7ecca97d174a728d40f9dbc9eb11b0a1a9', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 5, 'created': '2015-05-16 20:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/ac35e40f8331fd0e3e06062cf00a3f15495b42e3', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 6, 'created': '2015-05-23 14:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/6dc831a11b8ad1af2378debaa2b60fd6d63f98f9', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 7, 'created': '2015-05-23 14:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/b6163b6dd9e1fe163fb3ba85cfcf2c3a94c9541b', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}, {'number': 8, 'created': '2015-05-27 23:36:10.000000000', 'files': ['doc/source/index.rst', 'stevedore/tests/test_sphinxext.py', 'doc/source/sphinxext.rst', 'stevedore/sphinxext.py', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/7295f785f055d1551f4d61b7d1d500bac04dfa9f', 'message': 'Add sphinx integration\n\nAdd a restructuredtext directive for documenting a set of plugins with\nthe needed hooks to make it available is sphinx.\n\nChange-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b\n'}]",16,183820,7295f785f055d1551f4d61b7d1d500bac04dfa9f,25,7,8,2472,,,0,"Add sphinx integration

Add a restructuredtext directive for documenting a set of plugins with
the needed hooks to make it available is sphinx.

Change-Id: I1a24f9326b4e54174d9dc0ae366315fe29c3ac1b
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/20/183820/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'stevedore/tests/test_sphinxext.py', 'doc/source/sphinxext.rst', 'stevedore/sphinxext.py', 'doc/source/conf.py']",5,20db35bd2f1ec197d4b381c3c03b853cd8543b30,sphinx-autodoc-plugins," 'stevedore.sphinxext',",,207,0
openstack%2Fnova~master~Id4034e9e50b04f17f68b555074fc5b4ffb3a82d7,openstack/nova,master,Id4034e9e50b04f17f68b555074fc5b4ffb3a82d7,improve speed of some ec2 keypair tests,MERGED,2015-05-22 08:00:05.000000000,2015-05-28 01:42:03.000000000,2015-05-27 22:14:34.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8119}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-22 08:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af1d5121782de731bb3871f50ef7107b4f254116', 'message': ""improve speed of ec2 keypair quota test\n\ntest_create_key_pair_quota_limit is one of nova's slowest tests,\nbecause it creates 11 cryptographic keypairs.\n\nThis test doesn't actually care that the keypairs are cryptographically\nsecure, so mock out the actual generation of the keypairs.\n\nChange-Id: Id4034e9e50b04f17f68b555074fc5b4ffb3a82d7\n""}, {'number': 2, 'created': '2015-05-23 06:21:11.000000000', 'files': ['nova/tests/unit/api/ec2/test_cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/70ba3314cff3896dcf183a2c5c9eca28268cc54f', 'message': ""improve speed of some ec2 keypair tests\n\ntest_create_key_pair_quota_limit is one of nova's slowest tests,\nbecause it creates 11 cryptographic keypairs.\n\nSimilarly, test_create_key_pair is slow because it creates 7 keypairs.\n\nNeither test actually cares that the keypairs are cryptographically\nsecure, so mock out the actual generation of the keypairs.\n\nChange-Id: Id4034e9e50b04f17f68b555074fc5b4ffb3a82d7\n""}]",3,184968,70ba3314cff3896dcf183a2c5c9eca28268cc54f,45,19,2,8768,,,0,"improve speed of some ec2 keypair tests

test_create_key_pair_quota_limit is one of nova's slowest tests,
because it creates 11 cryptographic keypairs.

Similarly, test_create_key_pair is slow because it creates 7 keypairs.

Neither test actually cares that the keypairs are cryptographically
secure, so mock out the actual generation of the keypairs.

Change-Id: Id4034e9e50b04f17f68b555074fc5b4ffb3a82d7
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/184968/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/ec2/test_cloud.py'],1,af1d5121782de731bb3871f50ef7107b4f254116,speed_up_testcase," with mock.patch.object(self.cloud.keypair_api, '_generate_key_pair') as mock_generate_key_pair: mock_generate_key_pair.return_value = ( ""private_key"", ""public_key"", ""fingerprint"") self.flags(quota_key_pairs=10) for i in range(0, 10): key_name = 'key_%i' % i result = self.cloud.create_key_pair(self.context, self.assertEqual(result['keyName'], key_name) # 11'th group should fail self.assertRaises(exception.KeypairLimitExceeded,"," self.flags(quota_key_pairs=10) for i in range(0, 10): key_name = 'key_%i' % i result = self.cloud.create_key_pair(self.context, self.assertEqual(result['keyName'], key_name) # 11'th group should fail self.assertRaises(exception.KeypairLimitExceeded,",11,7
openstack%2Ftempest~master~Ie5de68e4c98c9925bd562a28a78351dc21388a17,openstack/tempest,master,Ie5de68e4c98c9925bd562a28a78351dc21388a17,Apply a list_images rule of GET to image client,MERGED,2015-05-22 01:23:40.000000000,2015-05-28 01:33:44.000000000,2015-05-28 01:33:42.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7020}, {'_account_id': 7872}, {'_account_id': 8556}]","[{'number': 1, 'created': '2015-05-22 01:23:40.000000000', 'files': ['tempest/cmd/javelin.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/api/image/v2/test_images.py', 'tempest/api/image/base.py', 'tempest/api/image/v1/test_images.py', 'tempest/services/image/v1/json/image_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3acc12f619bbb88457e9f56acdaca5d9c2ff414', 'message': 'Apply a list_images rule of GET to image client\n\n[GET /resources] methods should be ""list_<resource name>s""\nor ""show_<resource name>"", so this patch applies the part\nof the rule to image client.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Ie5de68e4c98c9925bd562a28a78351dc21388a17\n'}]",16,184927,e3acc12f619bbb88457e9f56acdaca5d9c2ff414,19,5,1,6167,,,0,"Apply a list_images rule of GET to image client

[GET /resources] methods should be ""list_<resource name>s""
or ""show_<resource name>"", so this patch applies the part
of the rule to image client.

Partially implements blueprint consistent-service-method-names

Change-Id: Ie5de68e4c98c9925bd562a28a78351dc21388a17
",git fetch https://review.opendev.org/openstack/tempest refs/changes/27/184927/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/javelin.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/api/image/v2/test_images.py', 'tempest/api/image/base.py', 'tempest/api/image/v1/test_images.py', 'tempest/services/image/v1/json/image_client.py']",6,e3acc12f619bbb88457e9f56acdaca5d9c2ff414,bp/consistent-service-method-names," def list_images(self, **kwargs):"," def image_list(self, **kwargs):",14,14
openstack%2Fdevstack~master~I3dcf8df130efc0c2ea35695018bedba31bf0570c,openstack/devstack,master,I3dcf8df130efc0c2ea35695018bedba31bf0570c,Ironic: Remove deprecated parameters,MERGED,2015-05-27 11:05:57.000000000,2015-05-28 01:23:23.000000000,2015-05-28 01:23:22.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7118}, {'_account_id': 7711}, {'_account_id': 7715}]","[{'number': 1, 'created': '2015-05-27 11:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ae3ba9235fcf8bfff129cdc51fd0501b6331c9fc', 'message': 'Ironic: Remove deprecated parameters\n\nIronic have updated some parameters to have a consistent name\nacross drivers. This patch is updating devstack to stop using the\npxe_deploy_{kernel, ramdisk} parameters which have been deprecated since\nearly Kilo eliminating the deprecation warnings in the logs.\n\nWARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_kernel"" parameter\nis deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109\nto use ""deploy_kernel"" instead.\n\nWARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_ramdisk"" parameter\nis deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109\nto use ""deploy_ramdisk"" instead.\n\nChange-Id: I3dcf8df130efc0c2ea35695018bedba31bf0570c\n'}, {'number': 2, 'created': '2015-05-27 11:22:27.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/73d24b2c1c1795a1d8b7f6dcdd608ad387d125b9', 'message': 'Ironic: Remove deprecated parameters\n\nIronic have updated some parameters to have a consistent name\nacross drivers. This patch is updating devstack to stop using the\npxe_deploy_{kernel, ramdisk} parameters which have been deprecated since\nearly Kilo eliminating the deprecation warnings in the logs.\n\nWARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_kernel"" parameter\nis deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109\nto use ""deploy_kernel"" instead.\n\nWARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_ramdisk"" parameter\nis deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109\nto use ""deploy_ramdisk"" instead.\n\nChange-Id: I3dcf8df130efc0c2ea35695018bedba31bf0570c\n'}]",2,185933,73d24b2c1c1795a1d8b7f6dcdd608ad387d125b9,10,5,2,6773,,,0,"Ironic: Remove deprecated parameters

Ironic have updated some parameters to have a consistent name
across drivers. This patch is updating devstack to stop using the
pxe_deploy_{kernel, ramdisk} parameters which have been deprecated since
early Kilo eliminating the deprecation warnings in the logs.

WARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_kernel"" parameter
is deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109
to use ""deploy_kernel"" instead.

WARNING ironic.drivers.modules.pxe [-] The ""pxe_deploy_ramdisk"" parameter
is deprecated. Please update the node 267e42c8-df07-49f5-bc7f-48b566acb109
to use ""deploy_ramdisk"" instead.

Change-Id: I3dcf8df130efc0c2ea35695018bedba31bf0570c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/185933/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,ae3ba9235fcf8bfff129cdc51fd0501b6331c9fc,remove-deprecated-parameters, local _IRONIC_DEPLOY_KERNEL_KEY=deploy_kernel local _IRONIC_DEPLOY_RAMDISK_KEY=deploy_ramdisk," if [[ ""$IRONIC_DEPLOY_DRIVER"" == ""pxe_ssh"" ]] ; then local _IRONIC_DEPLOY_KERNEL_KEY=pxe_deploy_kernel local _IRONIC_DEPLOY_RAMDISK_KEY=pxe_deploy_ramdisk elif is_deployed_by_agent; then local _IRONIC_DEPLOY_KERNEL_KEY=deploy_kernel local _IRONIC_DEPLOY_RAMDISK_KEY=deploy_ramdisk fi",2,8
openstack%2Fopenstack-ansible~kilo~I4e433e82499f5cfa0b5dde44a6aa7bab113d9e0e,openstack/openstack-ansible,kilo,I4e433e82499f5cfa0b5dde44a6aa7bab113d9e0e,Avoid keeping re-downloading container caches,MERGED,2015-05-27 09:56:41.000000000,2015-05-28 01:19:26.000000000,2015-05-28 01:19:24.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 15823}]","[{'number': 1, 'created': '2015-05-27 09:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2355e416774b54b33ed813f161e2a5d4fcaf5744', 'message': ""Avoid keeping re-downloading container caches\n\nWhen the cache tarball gets deleted at the end the task set in\nplaybooks/roles/lxc_hosts/tasks/lxc_cache.yml\nthen it will be downloaded again at subsequent runs, which makes the\ndownload task not idempotent, and needlessly slow.\n\nThe unarchive task also needs to only be executed if the download task\nperformed a change.\n\nEnsure that the location the download is placed and the directory it's extracted\nto are different.\n\nChange-Id: I4e433e82499f5cfa0b5dde44a6aa7bab113d9e0e\n(cherry picked from commit 2449ccb64076cf2b273ed0c3116c43be58b8c61e)\n""}, {'number': 2, 'created': '2015-05-27 10:58:08.000000000', 'files': ['playbooks/roles/lxc_hosts/tasks/lxc_cache.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/001b2b931a2fb3fda60cde174ee459f64416d34d', 'message': ""Avoid keeping re-downloading container caches\n\nWhen the cache tarball gets deleted at the end the task set in\nplaybooks/roles/lxc_hosts/tasks/lxc_cache.yml\nthen it will be downloaded again at subsequent runs, which makes the\ndownload task not idempotent, and needlessly slow.\n\nThe unarchive task also needs to only be executed if the download task\nperformed a change.\n\nEnsure that the location the download is placed and the directory it's extracted\nto are different.\n\nCloses-Bug: #1459191\nChange-Id: I4e433e82499f5cfa0b5dde44a6aa7bab113d9e0e\n(cherry picked from commit 2449ccb64076cf2b273ed0c3116c43be58b8c61e)""}]",0,185911,001b2b931a2fb3fda60cde174ee459f64416d34d,19,6,2,6816,,,0,"Avoid keeping re-downloading container caches

When the cache tarball gets deleted at the end the task set in
playbooks/roles/lxc_hosts/tasks/lxc_cache.yml
then it will be downloaded again at subsequent runs, which makes the
download task not idempotent, and needlessly slow.

The unarchive task also needs to only be executed if the download task
performed a change.

Ensure that the location the download is placed and the directory it's extracted
to are different.

Closes-Bug: #1459191
Change-Id: I4e433e82499f5cfa0b5dde44a6aa7bab113d9e0e
(cherry picked from commit 2449ccb64076cf2b273ed0c3116c43be58b8c61e)",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/11/185911/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/lxc_hosts/tasks/lxc_cache.yml'],1,2355e416774b54b33ed813f161e2a5d4fcaf5744,," dest: ""/var/cache/lxc_{{ item.name }}"" force: no src: ""/var/cache/lxc_{{ item.name }}"" when: cache_download|changed"," dest: ""/var/cache/lxc/{{ item.name }}"" src: ""/var/cache/lxc/{{ item.name }}""- name: Remove cache tarball file: path: ""/var/cache/lxc/{{ item.name }}"" state: absent with_items: lxc_container_caches tags: - lxc-cache - lxc-cache-remove",4,10
openstack%2Fpython-keystoneclient~feature%2Fkeystoneauth_integration~Ia471aaedc51f3e868ca788fa9a189f991f32fac7,openstack/python-keystoneclient,feature/keystoneauth_integration,Ia471aaedc51f3e868ca788fa9a189f991f32fac7,Update .gitreview for feature/keystoneauth_integration,MERGED,2015-05-27 23:13:03.000000000,2015-05-28 01:00:50.000000000,2015-05-28 01:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 7191}]","[{'number': 1, 'created': '2015-05-27 23:13:03.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/4326260e2f5f6260e039cefe2354781e197aa8ac', 'message': 'Update .gitreview for feature/keystoneauth_integration\n\nChange-Id: Ia471aaedc51f3e868ca788fa9a189f991f32fac7\n'}]",0,186220,4326260e2f5f6260e039cefe2354781e197aa8ac,7,3,1,2472,,,0,"Update .gitreview for feature/keystoneauth_integration

Change-Id: Ia471aaedc51f3e868ca788fa9a189f991f32fac7
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/20/186220/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,4326260e2f5f6260e039cefe2354781e197aa8ac,,defaultbranch=feature/keystoneauth_integration,,1,0
openstack%2Fopenstack-manuals~master~Ied22d160d8cb91d8dda84b935d117e9dcd9da3ed,openstack/openstack-manuals,master,Ied22d160d8cb91d8dda84b935d117e9dcd9da3ed,Updated create MongoDB user command in the installation guide,ABANDONED,2015-05-22 06:03:01.000000000,2015-05-28 00:54:05.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6772}, {'_account_id': 7923}, {'_account_id': 10705}, {'_account_id': 14643}]","[{'number': 1, 'created': '2015-05-22 06:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3535a4e35ecd2e0149cb63a149751c3b354b5798', 'message': 'Updated create MongoDB user command in the installation guide\n\nUpdated create MongoDb user commmand for MongoDB 3.0. The db.addUser commmand is deprecated.\n\nChange-Id: Ied22d160d8cb91d8dda84b935d117e9dcd9da3ed\nbackport: Kilo\nCloses-Bug: #1449399\n'}, {'number': 2, 'created': '2015-05-25 00:41:45.000000000', 'files': ['doc/install-guide/section_ceilometer-controller.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4b7910908eeaa52fd44fc159fe8ace63ddd59ed6', 'message': 'Updated create MongoDB user command in the installation guide\n\nUpdated create MongoDb user commmand for MongoDB 3.0. The db.addUser commmand is deprecated.\n\nChange-Id: Ied22d160d8cb91d8dda84b935d117e9dcd9da3ed\nbackport: Kilo\nCloses-Bug: #1449399\n'}]",3,184950,4b7910908eeaa52fd44fc159fe8ace63ddd59ed6,21,6,2,10705,,,0,"Updated create MongoDB user command in the installation guide

Updated create MongoDb user commmand for MongoDB 3.0. The db.addUser commmand is deprecated.

Change-Id: Ied22d160d8cb91d8dda84b935d117e9dcd9da3ed
backport: Kilo
Closes-Bug: #1449399
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/184950/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_ceilometer-controller.xml'],1,3535a4e35ecd2e0149cb63a149751c3b354b5798,MondoDB_adduser/dc," db.createUser({user: ""ceilometer"","," db.addUser({user: ""ceilometer"",",1,1
openstack%2Fnova~stable%2Fkilo~I090d2ba5774031a5b36ce51a6b6b91b823319bf1,openstack/nova,stable/kilo,I090d2ba5774031a5b36ce51a6b6b91b823319bf1,Ironic: pass injected files through to configdrive,MERGED,2015-04-22 16:49:18.000000000,2015-05-28 00:36:11.000000000,2015-05-28 00:36:08.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-04-22 16:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/103f2863f051dca3bd98f0ca1aa9de2c3b8a58f6', 'message': ""Ironic: pass injected files through to configdrive\n\nWhen building the configdrive, we weren't passing the injected_files\nparameter from spawn() through to the configdrive generator. Fix it.\n\nCloses-Bug: #1447249\nChange-Id: I090d2ba5774031a5b36ce51a6b6b91b823319bf1\n""}, {'number': 2, 'created': '2015-05-07 18:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f39b14023d24a53438fe73f074383b08554b3f86', 'message': ""Ironic: pass injected files through to configdrive\n\nWhen building the configdrive, we weren't passing the injected_files\nparameter from spawn() through to the configdrive generator. Fix it.\n\nCloses-Bug: #1447249\nChange-Id: I090d2ba5774031a5b36ce51a6b6b91b823319bf1\n(cherry picked from commit 7471b5a0924c8cb90b94ea122967b422d35d9c69)\n""}, {'number': 3, 'created': '2015-05-27 21:34:56.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d55ee5a55e228a57e326fca1e9412cbb828556e6', 'message': ""Ironic: pass injected files through to configdrive\n\nWhen building the configdrive, we weren't passing the injected_files\nparameter from spawn() through to the configdrive generator. Fix it.\n\nCloses-Bug: #1447249\nChange-Id: I090d2ba5774031a5b36ce51a6b6b91b823319bf1\n(cherry picked from commit 7471b5a0924c8cb90b94ea122967b422d35d9c69)\n""}]",0,176396,d55ee5a55e228a57e326fca1e9412cbb828556e6,22,6,3,10343,,,0,"Ironic: pass injected files through to configdrive

When building the configdrive, we weren't passing the injected_files
parameter from spawn() through to the configdrive generator. Fix it.

Closes-Bug: #1447249
Change-Id: I090d2ba5774031a5b36ce51a6b6b91b823319bf1
(cherry picked from commit 7471b5a0924c8cb90b94ea122967b422d35d9c69)
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/176396/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py']",2,103f2863f051dca3bd98f0ca1aa9de2c3b8a58f6,bug/1447249," extra_md={}, files=[])", extra_md={}),3,2
openstack%2Fos-brick~master~I08b6560a5f4dfd221c4211ab35a784c4605150dc,openstack/os-brick,master,I08b6560a5f4dfd221c4211ab35a784c4605150dc,Assign the platform after declaration,MERGED,2015-05-08 17:31:05.000000000,2015-05-28 00:23:52.000000000,2015-05-28 00:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-05-08 17:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/595cd42102b11ba9f8e91d37b4735350ae685d78', 'message': 'Assign the platform after declaration\n\nThis simple patch changes when the arch value is\nassigned in the connector factory until after the\nfunction defintion.  kwarg values assigned in\nfunction declarations are assigned at file import\ntime and not at call time.\n\nChange-Id: I08b6560a5f4dfd221c4211ab35a784c4605150dc\n'}, {'number': 2, 'created': '2015-05-20 16:31:11.000000000', 'files': ['os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/49c2bdf64162fb00dd01815b6e180efff538594f', 'message': 'Assign the platform after declaration\n\nThis simple patch changes when the arch value is\nassigned in the connector factory until after the\nfunction defintion.  kwarg values assigned in\nfunction declarations are assigned at file import\ntime and not at call time.\n\nChange-Id: I08b6560a5f4dfd221c4211ab35a784c4605150dc\n'}]",1,181475,49c2bdf64162fb00dd01815b6e180efff538594f,11,4,2,5997,,,0,"Assign the platform after declaration

This simple patch changes when the arch value is
assigned in the connector factory until after the
function defintion.  kwarg values assigned in
function declarations are assigned at file import
time and not at call time.

Change-Id: I08b6560a5f4dfd221c4211ab35a784c4605150dc
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/75/181475/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/initiator/connector.py'],1,595cd42102b11ba9f8e91d37b4735350ae685d78,mock-factory," arch=None, # We do this instead of assigning it in the definition # to help mocking for unit tests if arch is None: arch = platform.machine() "," arch=platform.machine(),",7,1
openstack%2Fhorizon~stable%2Fkilo~Ibc5233028507c66de459e84e91f65c9557940ea5,openstack/horizon,stable/kilo,Ibc5233028507c66de459e84e91f65c9557940ea5,LBaas v1 Associate Monitor to Pool Fails,MERGED,2015-05-14 21:47:16.000000000,2015-05-28 00:23:29.000000000,2015-05-28 00:23:27.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6650}, {'_account_id': 6873}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9981}, {'_account_id': 14064}]","[{'number': 1, 'created': '2015-05-14 21:47:16.000000000', 'files': ['openstack_dashboard/test/api_tests/lbaas_tests.py', 'openstack_dashboard/api/lbaas.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/baf55ce43c1ac14358caa3cbe603476fa05f91e1', 'message': 'LBaas v1 Associate Monitor to Pool Fails\n\nThe associate monitor fails to show monitors to choose from\nwithin horizon.  The monitor list code has changed where\nyou can no longer list monitors with a filter criteria.\nThis change switches to grab needed monitors one at a time.\n\nChange-Id: Ibc5233028507c66de459e84e91f65c9557940ea5\nCloses-bug: #1398754\n(cherry picked from commit 0dde489a81ea8599e75d45ac0be34048a5c366d0)\n'}]",0,183321,baf55ce43c1ac14358caa3cbe603476fa05f91e1,19,10,1,9981,,,0,"LBaas v1 Associate Monitor to Pool Fails

The associate monitor fails to show monitors to choose from
within horizon.  The monitor list code has changed where
you can no longer list monitors with a filter criteria.
This change switches to grab needed monitors one at a time.

Change-Id: Ibc5233028507c66de459e84e91f65c9557940ea5
Closes-bug: #1398754
(cherry picked from commit 0dde489a81ea8599e75d45ac0be34048a5c366d0)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/21/183321/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/api_tests/lbaas_tests.py', 'openstack_dashboard/api/lbaas.py']",2,baf55ce43c1ac14358caa3cbe603476fa05f91e1,," monitors = [] for monitor_id in pool['health_monitors']: try: monitors.append(_pool_health_monitor_get(request, monitor_id, False)) except Exception: messages.warning(request, _(""Unable to get health monitor "" ""%(monitor_id)s for pool %(pool)s."") % {""pool"": pool_id, ""monitor_id"": monitor_id}) pool['health_monitors'] = monitors"," try: pool['health_monitors'] = pool_health_monitor_list( request, id=pool['health_monitors']) except Exception: messages.warning(request, _(""Unable to get health monitors "" ""for pool %(pool)s."") % {""pool"": pool_id})",19,11
openstack%2Fos-brick~master~I63ec4f291d9990e8911b696a4030d3ffe377bd6e,openstack/os-brick,master,I63ec4f291d9990e8911b696a4030d3ffe377bd6e,Allow overriding the host field,MERGED,2015-05-21 16:13:27.000000000,2015-05-28 00:22:26.000000000,2015-05-28 00:22:26.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-05-21 16:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/75ace984c569b9ab22188e26c73a8651986011aa', 'message': ""Allow overriding the host field\n\nThis patch adds the ability to override the host\nthat is populated into the connector when collecting\ninformation about the initiator.  Nova sometimes overrides\nthe host depending on it's CONF.host value, so we need to\nsupport that instead of always using the socket.gethostname()\n\nChange-Id: I63ec4f291d9990e8911b696a4030d3ffe377bd6e\n""}, {'number': 2, 'created': '2015-05-21 17:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8d4c9ecd5f3cca5c8250693cfc6dd20d12f4d7b0', 'message': ""Allow overriding the host field\n\nThis patch adds the ability to override the host\nthat is populated into the connector when collecting\ninformation about the initiator.  Nova sometimes overrides\nthe host depending on it's CONF.host value, so we need to\nsupport that instead of always using the socket.gethostname()\n\nChange-Id: I63ec4f291d9990e8911b696a4030d3ffe377bd6e\n""}, {'number': 3, 'created': '2015-05-21 17:18:22.000000000', 'files': ['os_brick/tests/initiator/test_connector.py', 'os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/3433f5d5830dd32708a3879b59c9cabaf8ba8ddc', 'message': ""Allow overriding the host field\n\nThis patch adds the ability to override the host\nthat is populated into the connector when collecting\ninformation about the initiator.  Nova sometimes overrides\nthe host depending on it's CONF.host value, so we need to\nsupport that instead of always using the socket.gethostname()\n\nChange-Id: I63ec4f291d9990e8911b696a4030d3ffe377bd6e\n""}]",4,184811,3433f5d5830dd32708a3879b59c9cabaf8ba8ddc,16,5,3,5997,,,0,"Allow overriding the host field

This patch adds the ability to override the host
that is populated into the connector when collecting
information about the initiator.  Nova sometimes overrides
the host depending on it's CONF.host value, so we need to
support that instead of always using the socket.gethostname()

Change-Id: I63ec4f291d9990e8911b696a4030d3ffe377bd6e
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/11/184811/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/test_connector.py', 'os_brick/initiator/connector.py']",2,75ace984c569b9ab22188e26c73a8651986011aa,override-host,"def get_connector_properties(root_helper, my_ip, multipath, enforce_multipath, host=None): props['host'] = host if host else socket.gethostname()","def get_connector_properties(root_helper, my_ip, multipath, enforce_multipath): props['host'] = socket.gethostname()",23,5
openstack%2Fhorizon~stable%2Fkilo~I4821eacb0bb274befab7995f3a8f87c82d3997f5,openstack/horizon,stable/kilo,I4821eacb0bb274befab7995f3a8f87c82d3997f5,Sanitation of metadata passed from Django,MERGED,2015-05-15 19:11:24.000000000,2015-05-28 00:14:15.000000000,2015-05-28 00:14:12.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 6914}, {'_account_id': 7976}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 15209}]","[{'number': 1, 'created': '2015-05-15 19:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/81e1fa13177c8e259c90183409696305f55cdd75', 'message': 'Sanitation of metadata passed from Django\n\nWe need to escape HTML in metadata passed from Django, which\ncan lead to security issues. Refer to the bug for more details.\n\nCo-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>\nChange-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5\nCloses-bug: #1449260\n(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)\n'}, {'number': 2, 'created': '2015-05-22 22:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ee73ebeb07d289e098601059c92cf70025e49547', 'message': 'Sanitation of metadata passed from Django\n\nWe need to escape HTML in metadata passed from Django, which\ncan lead to security issues. Refer to the bug for more details.\n\nCo-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>\nChange-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5\nCloses-bug: #1449260\n(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)\n'}, {'number': 3, 'created': '2015-05-22 23:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0101fe34abcb95012d215d4ba8f908632ba9876', 'message': 'Sanitation of metadata passed from Django\n\nWe need to escape HTML in metadata passed from Django, which\ncan lead to security issues. Refer to the bug for more details.\n\nCo-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>\nChange-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5\nCloses-bug: #1449260\n(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)\n'}, {'number': 4, 'created': '2015-05-26 22:32:11.000000000', 'files': ['horizon/templates/horizon/common/_modal_form_update_metadata.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/30dde700701040d0d405e7e759a3d73e3b97bf71', 'message': 'Sanitation of metadata passed from Django\n\nWe need to escape HTML in metadata passed from Django, which\ncan lead to security issues. Refer to the bug for more details.\n\nCo-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>\nChange-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5\nCloses-bug: #1449260\n(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)\n'}]",0,183656,30dde700701040d0d405e7e759a3d73e3b97bf71,39,12,4,6486,,,0,"Sanitation of metadata passed from Django

We need to escape HTML in metadata passed from Django, which
can lead to security issues. Refer to the bug for more details.

Co-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>
Change-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5
Closes-bug: #1449260
(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/183656/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_modal_form_update_metadata.html'],1,81e1fa13177c8e259c90183409696305f55cdd75,183656, var existing_metadata = JSON.parse('{{ existing_metadata|escapejs }}'); var available_metadata = JSON.parse('{{ available_metadata|escapejs }}');, var existing_metadata = {{ existing_metadata|safe }}; var available_metadata = {{ available_metadata|safe }};,2,2
openstack%2Frally~master~Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee,openstack/rally,master,Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee,Add Cinder create_and_restore_volume_backup scenario,MERGED,2015-04-14 16:23:28.000000000,2015-05-28 00:04:52.000000000,2015-05-28 00:04:51.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 13555}, {'_account_id': 13609}, {'_account_id': 14305}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-04-14 16:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6c5d4f0062ff40c69bd65bd60f15352e338578b2', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 2, 'created': '2015-04-15 08:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6fba550520b94c560c7484ee16e071a025185f87', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 3, 'created': '2015-04-15 15:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aa381da7bb29d63554760652468982d2602bca83', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 4, 'created': '2015-04-15 16:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4855bbab29194e87c9bc79125df1303755e36eaa', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 5, 'created': '2015-04-15 16:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5a92d6775c1f27f23e647861d6e9e2f883b8c969', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 6, 'created': '2015-05-15 13:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3cfc037677c038d21390a4a6dcdaae4427380bc6', 'message': 'Add Cinder restore_volume_backup scenario\n\nImplemented restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 7, 'created': '2015-05-18 08:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/41d7302d7d432d5f59cf467c3404c176938fe393', 'message': 'Add Cinder create_and_restore_volume_backup scenario\n\nImplemented crete_and_restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 8, 'created': '2015-05-18 13:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/65efb0917a421f49490d774b0ec85c7789d27caa', 'message': 'Add Cinder create_and_restore_volume_backup scenario\n\nImplement crete_and_restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 9, 'created': '2015-05-21 08:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9df1ca753bb7f2c1be3fe7093457aaf9ea448c9c', 'message': 'Add Cinder create_and_restore_volume_backup scenario\n\nImplement crete_and_restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}, {'number': 10, 'created': '2015-05-21 13:18:53.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'samples/tasks/scenarios/cinder/create-and-restore-volume-backup.yaml', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'rally-jobs/rally-mos_neutron.yaml', 'samples/tasks/scenarios/cinder/create-and-restore-volume-backup.json', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'rally-jobs/rally-neutron.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/b0c9eb1f864616b8a4052f60e33dba9a726bbce0', 'message': 'Add Cinder create_and_restore_volume_backup scenario\n\nImplement crete_and_restore_volume_backup scenario for Cinder.\n\nChange-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee\n'}]",25,173412,b0c9eb1f864616b8a4052f60e33dba9a726bbce0,76,10,10,14305,,,0,"Add Cinder create_and_restore_volume_backup scenario

Implement crete_and_restore_volume_backup scenario for Cinder.

Change-Id: Ieeaf36e14454b18497c1b8730c5d3b5e167d98ee
",git fetch https://review.opendev.org/openstack/rally refs/changes/12/173412/9 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/cinder/utils.py', 'samples/tasks/scenarios/cinder/restore-volume-backup.json', 'rally/benchmark/scenarios/cinder/volumes.py', 'tests/unit/benchmark/scenarios/cinder/test_volumes.py', 'rally-jobs/rally-mos_neutron.yaml', 'tests/unit/benchmark/scenarios/cinder/test_utils.py', 'rally-jobs/rally-neutron.yaml', 'samples/tasks/scenarios/cinder/restore-volume-backup.yaml']",8,6c5d4f0062ff40c69bd65bd60f15352e338578b2,create-backup,"--- CinderVolumes.restore_volume_backup: - args: size: 1 runner: type: ""constant"" times: 2 concurrency: 1 context: users: tenants: 1 users_per_tenant: 1 roles: - ""Member"" ",,156,2
openstack%2Fdevstack~master~I2575a516244b848e5ed461e7f488c59edc41068d,openstack/devstack,master,I2575a516244b848e5ed461e7f488c59edc41068d,Honor the flag for Identity v3 API only jobs,MERGED,2015-05-03 18:15:03.000000000,2015-05-28 00:04:49.000000000,2015-05-28 00:04:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1921}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7191}, {'_account_id': 7715}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-05-03 18:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4111a69134469b77ed3531204a0c4f55c81284b6', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 2, 'created': '2015-05-06 04:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/884f06ef0447cb38516714e9c4bf98ab75050162', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 3, 'created': '2015-05-06 11:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/44b6dc85206216e25a88653aadc5129644491c9b', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 4, 'created': '2015-05-08 03:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/302bf6cb10ecac9d2ad91216fea470065d46357e', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 5, 'created': '2015-05-08 04:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fa9008639a86f25e6fe6fe625680141d25b3e710', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 6, 'created': '2015-05-13 11:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c4f6a0a181fb8a6ae0cfacc8b10a006937c54c36', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property IDENTITY_V3_ONLY is set to\nTrue in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 7, 'created': '2015-05-13 17:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d6bc2f683bde86836a9b868417eeca487a8c4ab3', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property ENABLE_IDENTITY_V2 is set to\nFalse in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens;\n* Register the Identity endpoint as v3.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 8, 'created': '2015-05-13 20:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7f19506eb34017849e36d37a241d8266bf190258', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property ENABLE_IDENTITY_V2 is set to\nFalse in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens;\n* Register the Identity endpoint as v3.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 9, 'created': '2015-05-26 21:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc632849f0e98281a91fe05a64b668d144428e41', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property ENABLE_IDENTITY_V2 is set to\nFalse in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens;\n* Register the Identity endpoint as v3.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}, {'number': 10, 'created': '2015-05-27 17:26:35.000000000', 'files': ['lib/keystone', 'lib/tempest', 'stackrc', 'lib/horizon'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3fd71d68933f2c4e38ff7fa58416ec0263325a9f', 'message': 'Honor the flag for Identity v3 API only jobs\n\nWhen the property ENABLE_IDENTITY_V2 is set to\nFalse in the local.conf file, devstack will:\n\n* Disable the v2 API in Keystone paste config;\n* Set Tempest to skip Identity v2 tests and use\n  v3 auth tokens to run all the other tests;\n* Set Horizon to use v3 API and v3 auth tokens;\n* Register the Identity endpoint as v3.\n\nChange-Id: I2575a516244b848e5ed461e7f488c59edc41068d\n'}]",15,179663,3fd71d68933f2c4e38ff7fa58416ec0263325a9f,54,11,10,9142,,,0,"Honor the flag for Identity v3 API only jobs

When the property ENABLE_IDENTITY_V2 is set to
False in the local.conf file, devstack will:

* Disable the v2 API in Keystone paste config;
* Set Tempest to skip Identity v2 tests and use
  v3 auth tokens to run all the other tests;
* Set Horizon to use v3 API and v3 auth tokens;
* Register the Identity endpoint as v3.

Change-Id: I2575a516244b848e5ed461e7f488c59edc41068d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/63/179663/5 && git format-patch -1 --stdout FETCH_HEAD,"['lib/keystone', 'lib/tempest', 'lib/horizon']",3,4111a69134469b77ed3531204a0c4f55c81284b6,identity-v3-only-jobs," if [ ""$IDENTITY_V3_ONLY"" == ""True"" ]; then # Only Identity v3 API is available; then use it with v3 auth tokens _horizon_config_set $local_settings """" OPENSTACK_API_VERSIONS {\""identity\"":\""v3\""} _horizon_config_set $local_settings """" OPENSTACK_KEYSTONE_URL ""\""${KEYSTONE_SERVICE_PROTOCOL}://${KEYSTONE_SERVICE_HOST}:${KEYSTONE_SERVICE_PORT}/v3\"""" else _horizon_config_set $local_settings """" OPENSTACK_KEYSTONE_URL ""\""${KEYSTONE_SERVICE_PROTOCOL}://${KEYSTONE_SERVICE_HOST}:${KEYSTONE_SERVICE_PORT}/v2.0\"""" fi"," _horizon_config_set $local_settings """" OPENSTACK_KEYSTONE_URL ""\""${KEYSTONE_SERVICE_PROTOCOL}://${KEYSTONE_SERVICE_HOST}:${KEYSTONE_SERVICE_PORT}/v2.0\""""",23,2
openstack%2Fheat~stable%2Fkilo~Ibf80e95e69a2f27ed29754a2e0f1125e8eed0775,openstack/heat,stable/kilo,Ibf80e95e69a2f27ed29754a2e0f1125e8eed0775,Get rid of circular references in Resource and Function,MERGED,2015-05-15 22:28:35.000000000,2015-05-28 00:03:53.000000000,2015-05-28 00:03:52.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-05-15 22:28:35.000000000', 'files': ['heat/tests/test_os_database.py', 'heat/tests/test_nested_stack.py', 'contrib/heat_gnocchi/heat_gnocchi/tests/test_gnocchi_alarm.py', 'heat/tests/test_sahara_cluster.py', 'heat/tests/neutron/test_neutron_firewall.py', 'heat/tests/neutron/test_neutron_loadbalancer.py', 'heat/engine/service.py', 'heat/tests/test_engine_service.py', 'heat/tests/neutron/test_neutron_network_gateway.py', 'heat/tests/test_template.py', 'heat/tests/test_sahara_templates.py', 'heat/engine/stack.py', 'heat/tests/test_stack_user.py', 'heat/engine/function.py', 'heat/tests/neutron/test_neutron_metering.py', 'heat/tests/autoscaling/test_heat_scaling_group.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'heat/tests/autoscaling/test_scaling_policy.py', 'heat/tests/test_instance.py', 'heat/tests/test_restarter.py', 'heat/tests/test_swift.py', 'heat/tests/test_properties.py', 'heat/tests/test_provider_template.py', 'heat/tests/autoscaling/test_heat_scaling_policy.py', 'heat/tests/autoscaling/test_scaling_group.py', 'contrib/rackspace/rackspace/tests/test_rackspace_dns.py', 'heat/tests/test_hot.py', 'heat/tests/test_instance_group.py', 'heat/tests/test_nova_floatingip.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/tests/neutron/test_neutron_provider_net.py', 'contrib/heat_docker/heat_docker/tests/test_docker_container.py', 'heat/tests/aws/test_waitcondition.py', 'heat/tests/test_stack.py', 'heat/tests/test_nova_servergroup.py', 'heat/tests/test_server.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py', 'heat/engine/resource.py', 'heat/tests/test_ceilometer_alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a5297fec8a470d2aef8e41c1c4bee16f986aff74', 'message': 'Get rid of circular references in Resource and Function\n\nCircular references cause practically every bit of data that Heat uses to\nremain in memory until the completion of an operation, and even then to\nonly be freed once the loop is detected by the garbage collector. By\nbreaking all of the loops using weak references, we can ensure that things\nwill get freed when they are no longer referenced without the need to wait\nfor garbage collection (which should also take a lot less time). This\nchange removes the loops from Resource and Function objects back to the\nStack.\n\nChange-Id: Ibf80e95e69a2f27ed29754a2e0f1125e8eed0775\nCloses-Bug: #1454873\n(cherry-picked from commits 2032548c4e501ebf90604bf60a69fdf9f64b981d,\n                            203b8e8ecf91ad7c75dd7072c85930de4f8c1c42,\n                            d29bb1927489d5590f17d2f3ef2904b6f5edd0d4,\n                            60300b014952f5b2fa4c2a9010876f5b871f0f66)\n'}]",0,183723,a5297fec8a470d2aef8e41c1c4bee16f986aff74,16,7,1,4257,,,0,"Get rid of circular references in Resource and Function

Circular references cause practically every bit of data that Heat uses to
remain in memory until the completion of an operation, and even then to
only be freed once the loop is detected by the garbage collector. By
breaking all of the loops using weak references, we can ensure that things
will get freed when they are no longer referenced without the need to wait
for garbage collection (which should also take a lot less time). This
change removes the loops from Resource and Function objects back to the
Stack.

Change-Id: Ibf80e95e69a2f27ed29754a2e0f1125e8eed0775
Closes-Bug: #1454873
(cherry-picked from commits 2032548c4e501ebf90604bf60a69fdf9f64b981d,
                            203b8e8ecf91ad7c75dd7072c85930de4f8c1c42,
                            d29bb1927489d5590f17d2f3ef2904b6f5edd0d4,
                            60300b014952f5b2fa4c2a9010876f5b871f0f66)
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/183723/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_database.py', 'heat/tests/test_nested_stack.py', 'contrib/heat_gnocchi/heat_gnocchi/tests/test_gnocchi_alarm.py', 'heat/tests/test_sahara_cluster.py', 'heat/tests/neutron/test_neutron_firewall.py', 'heat/tests/neutron/test_neutron_loadbalancer.py', 'heat/engine/service.py', 'heat/tests/test_engine_service.py', 'heat/tests/neutron/test_neutron_network_gateway.py', 'heat/tests/test_template.py', 'heat/tests/test_sahara_templates.py', 'heat/engine/stack.py', 'heat/tests/test_stack_user.py', 'heat/engine/function.py', 'heat/tests/neutron/test_neutron_metering.py', 'heat/tests/autoscaling/test_heat_scaling_group.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'heat/tests/autoscaling/test_scaling_policy.py', 'heat/tests/test_instance.py', 'heat/tests/test_restarter.py', 'heat/tests/test_swift.py', 'heat/tests/test_properties.py', 'heat/tests/test_provider_template.py', 'heat/tests/autoscaling/test_heat_scaling_policy.py', 'heat/tests/autoscaling/test_scaling_group.py', 'contrib/rackspace/rackspace/tests/test_rackspace_dns.py', 'heat/tests/test_hot.py', 'heat/tests/test_instance_group.py', 'heat/tests/test_nova_floatingip.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/tests/neutron/test_neutron_provider_net.py', 'contrib/heat_docker/heat_docker/tests/test_docker_container.py', 'heat/tests/aws/test_waitcondition.py', 'heat/tests/test_stack.py', 'heat/tests/test_nova_servergroup.py', 'heat/tests/test_server.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py', 'heat/engine/resource.py', 'heat/tests/test_ceilometer_alarm.py']",42,a5297fec8a470d2aef8e41c1c4bee16f986aff74,bug/1454873," self.stack = utils.parse_stack(snippet) res = self.stack['MEMAlarmHigh'] self.stack = utils.parse_stack(snippet) resource_defns = self.stack.t.resource_definitions(self.stack) 'CombinAlarm', resource_defns['CombinAlarm'], self.stack) self.stack = utils.parse_stack(snippet) res = self.stack['CombinAlarm']"," stack = utils.parse_stack(snippet) res = stack['MEMAlarmHigh'] stack = utils.parse_stack(snippet) resource_defns = stack.t.resource_definitions(stack) 'CombinAlarm', resource_defns['CombinAlarm'], stack) stack = utils.parse_stack(snippet) res = stack['CombinAlarm']",308,272
openstack%2Fnova~stable%2Fkilo~I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd,openstack/nova,stable/kilo,I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd,libvirt: handle NotSupportedError in compareCPU,MERGED,2015-05-19 12:54:43.000000000,2015-05-27 23:57:25.000000000,2015-05-27 23:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11303}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-19 12:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/530b7be09facd026c7225b625db570811a41e288', 'message': 'libvirt: handle NotSupportedError in compareCPU\n\nIn case of a NotSupportedError during the CPU comparison, the live\nmigration was aborted and rolled back because all libvirt errors were\ntreated equally.\nIf the target host has the same CPU architecture like the source host,\nthe live migration gets triggered now, despite no CPU comparison was\ndone.\n\nCloses-Bug: 1434429\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd\n(cherry picked from commit da9301fbc7877529bc2b099ffeb622e02ef54f0e)'}, {'number': 2, 'created': '2015-05-22 08:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f20b6f74e3ed0684604a11e03e0577c403f8d042', 'message': 'libvirt: handle NotSupportedError in compareCPU\n\nIn case of a NotSupportedError during the CPU comparison, the live\nmigration was aborted and rolled back because all libvirt errors were\ntreated equally.\nIf the target host has the same CPU architecture like the source host,\nthe live migration gets triggered now, despite no CPU comparison was\ndone.\nThis also includes the fix from Nikola Dipanov from commit b3d4c1b\n\nCo-Authored-By: Nikola Dipanov <ndipanov@redhat.com> \n\nCloses-Bug: 1434429\n\nConflicts:\n    nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd\n(cherry picked from commit da9301fbc7877529bc2b099ffeb622e02ef54f0e)\n(cherry-picked from commit b3d4c1b6efdf7eb7a7293c069f453e05ffa9f338)\n'}, {'number': 3, 'created': '2015-05-22 13:14:25.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d18058e8d7c6b3e66ca496a8c112c477bcb73851', 'message': 'libvirt: handle NotSupportedError in compareCPU\n\nIn case of a NotSupportedError during the CPU comparison, the live\nmigration was aborted and rolled back because all libvirt errors were\ntreated equally.\nIf the target host has the same CPU architecture like the source host,\nthe live migration gets triggered now, despite no CPU comparison was\ndone.\n\nCloses-Bug: 1434429\n\nConflicts:\n    nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd\n(cherry picked from commit da9301fbc7877529bc2b099ffeb622e02ef54f0e)\n'}]",3,184240,d18058e8d7c6b3e66ca496a8c112c477bcb73851,43,10,3,11303,,,0,"libvirt: handle NotSupportedError in compareCPU

In case of a NotSupportedError during the CPU comparison, the live
migration was aborted and rolled back because all libvirt errors were
treated equally.
If the target host has the same CPU architecture like the source host,
the live migration gets triggered now, despite no CPU comparison was
done.

Closes-Bug: 1434429

Conflicts:
    nova/tests/unit/virt/libvirt/test_driver.py

Change-Id: I9276f0a7ce9a9b58943e1ed9b9c7d8855482d9cd
(cherry picked from commit da9301fbc7877529bc2b099ffeb622e02ef54f0e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/184240/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,530b7be09facd026c7225b625db570811a41e288,," @mock.patch.object(nova.virt.libvirt, 'config') def test_compare_cpu_handles_not_supported_error_gracefully(self, mock_vconfig, mock_conn): not_supported_exc = fakelibvirt.make_libvirtError( fakelibvirt.libvirtError, 'this function is not supported by the connection driver:' ' virCompareCPU', error_code=fakelibvirt.VIR_ERR_NO_SUPPORT) mock_conn.compareCPU.side_effect = not_supported_exc conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) ret = conn._compare_cpu(None, jsonutils.dumps(_fake_cpu_info)) self.assertIsNone(ret) @mock.patch('nova.virt.libvirt.LibvirtDriver._conn')",,25,3
openstack%2Fgrenade~master~I2d81f25522ad982657d7f4239bfe66bfb5538295,openstack/grenade,master,I2d81f25522ad982657d7f4239bfe66bfb5538295,Allow ceilometer in grenade to use mod_wsgi,MERGED,2015-05-12 10:51:12.000000000,2015-05-27 23:44:31.000000000,2015-05-27 23:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-05-12 10:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/4e09fa188514c04bbd051062a9159d6c2382c57e', 'message': 'Source lib/apache for ceilometer shutdown and upgrade\n\nCeilometer can use mod_wsgi when configured to do so but these\nceilometer project scripts were not sourcing lib/apache to get\nfunctions such enable_apache_site. Without these starting and\nstopping a stack will fail.\n\nChange-Id: I2d81f25522ad982657d7f4239bfe66bfb5538295\n'}, {'number': 2, 'created': '2015-05-12 12:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/438768b08fd51b6eff1849767e11ad35a2a61efc', 'message': 'Default ceilometer to using mod_wsgi\n\nUsing mod_wsgi is the recommended mode of deployment in modern\nceilometer.\n\nSource lib/apache for ceilometer shutdown and upgrade.\n\nCeilometer can use mod_wsgi when configured to do so but the\nceilometer project scripts were not sourcing lib/apache to get\nfunctions such enable_apache_site. Without these starting and\nstopping a stack will fail.\n\nChange-Id: I2d81f25522ad982657d7f4239bfe66bfb5538295\n'}, {'number': 3, 'created': '2015-05-12 19:27:39.000000000', 'files': ['projects/20_ceilometer/upgrade.sh', 'projects/20_ceilometer/shutdown.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/bf4b8ab2d1811b1678338124c28b275c6c4b29a1', 'message': 'Allow ceilometer in grenade to use mod_wsgi\n\nIf the base or target stack is configured for ceilometer to use\nmod wsgi we need to source lib/apache for ceilometer shutdown and\nupgrade, otherwise functions such as enable_apache_site are not in\nscope and starting and/or stopping a stack will fail.\n\nChange-Id: I2d81f25522ad982657d7f4239bfe66bfb5538295\n'}]",3,182233,bf4b8ab2d1811b1678338124c28b275c6c4b29a1,16,5,3,11564,,,0,"Allow ceilometer in grenade to use mod_wsgi

If the base or target stack is configured for ceilometer to use
mod wsgi we need to source lib/apache for ceilometer shutdown and
upgrade, otherwise functions such as enable_apache_site are not in
scope and starting and/or stopping a stack will fail.

Change-Id: I2d81f25522ad982657d7f4239bfe66bfb5538295
",git fetch https://review.opendev.org/openstack/grenade refs/changes/33/182233/1 && git format-patch -1 --stdout FETCH_HEAD,"['projects/20_ceilometer/upgrade.sh', 'projects/20_ceilometer/shutdown.sh']",2,4e09fa188514c04bbd051062a9159d6c2382c57e,cd/ceilometer-mod-wsgi,source $BASE_DEVSTACK_DIR/lib/apache,,2,0
openstack%2Ftaskflow~master~I421e1ab33508c25baf78bd76df158bb6116d6fb0,openstack/taskflow,master,I421e1ab33508c25baf78bd76df158bb6116d6fb0,Allow same deps for requires and provides in task,MERGED,2015-05-06 08:00:21.000000000,2015-05-27 23:37:48.000000000,2015-05-27 23:37:46.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-05-06 08:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6170fff8de6c9f809067661302a928888cb8d1f6', 'message': 'Allow same deps for requires and provides in task\n\nThis change removes the DependencyFailure that is raised when a task\nrequires the same dependency as it provides. Taskflow returns a\nfrozenset([]) instead of a frozenset() when more than one value with the\nsame name is in the store.\n\nChange-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0\n'}, {'number': 2, 'created': '2015-05-22 14:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a7eab741157d3fb56769cbe0f915aa0d43a76abf', 'message': ""Allow same deps for requires and provides in task\n\nThis change removes the DependencyFailure that is raised when a task\nrequires the same dependency as it provides. Taskflow returns a\nfrozenset([]) instead of a frozenset() when more than one value with the\nsame name is in the store.\n\nThis prevents the need for an inconvenient rename function when you want\nto update a store variable with a new value.\n\nExample case:\n```\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nclass AwkwardRename(task.Task):\n    def execute(self, b):\n        return b\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t1',\n        provides='b',\n        requires='a',\n        ),\n    AwkwardRename('t2',\n                  provides='a',\n                  requires='b'))\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n```\n\nNow with ability to have the same provides as requires:\n```\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t3',\n        provides='a',\n        requires='a'),\n)\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n```\n\nChange-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0\n""}, {'number': 3, 'created': '2015-05-24 10:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/79fb1be029fdac5a40ad6f2080d0ec8e49406e01', 'message': ""Allow same deps for requires and provides in task\n\nThis change removes the DependencyFailure that is raised when a task\nrequires the same dependency as it provides. Taskflow returns a\nfrozenset([]) instead of a frozenset() when more than one value with the\nsame name is in the store.\n\nThis prevents the need for an inconvenient rename function when you want\nto update a store variable with a new value.\n\nExample case:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nclass AwkwardRename(task.Task):\n    def execute(self, b):\n        return b\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t1',\n        provides='b',\n        requires='a',\n        ),\n    AwkwardRename('t2',\n                  provides='a',\n                  requires='b'))\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nNow with ability to have the same provides as requires:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t3',\n        provides='a',\n        requires='a'),\n)\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nChange-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0\n""}, {'number': 4, 'created': '2015-05-24 11:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4113e6b151933714dcdb8470f44716802f7a1ba6', 'message': ""Allow same deps for requires and provides in task\n\nThis change removes the DependencyFailure that is raised when a task\nrequires the same dependency as it provides. Taskflow returns a\nfrozenset([]) instead of a frozenset() when more than one value with the\nsame name is in the store.\n\nThis prevents the need for an inconvenient rename function when you want\nto update a store variable with a new value.\n\nExample case:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nclass AwkwardRename(task.Task):\n    def execute(self, b):\n        return b\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t1',\n        provides='b',\n        requires='a',\n        ),\n    AwkwardRename('t2',\n                  provides='a',\n                  requires='b'))\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nNow with ability to have the same provides as requires:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t3',\n        provides='a',\n        requires='a'),\n)\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nChange-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0\n""}, {'number': 5, 'created': '2015-05-25 12:57:26.000000000', 'files': ['taskflow/tests/unit/test_engines.py', 'taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/atom.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c7e8c868cd85c878ab9896c868f9989adc7dfc09', 'message': ""Allow same deps for requires and provides in task\n\nThis change removes the DependencyFailure that is raised when a task\nrequires the same dependency as it provides. Taskflow returns a\nfrozenset([]) instead of a frozenset() when more than one value with the\nsame name is in the store.\n\nThis prevents the need for an inconvenient rename function when you want\nto update a store variable with a new value.\n\nExample case:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nclass AwkwardRename(task.Task):\n    def execute(self, b):\n        return b\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t1',\n        provides='b',\n        requires='a',\n        ),\n    AwkwardRename('t2',\n                  provides='a',\n                  requires='b'))\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nNow with ability to have the same provides as requires:\nclass Inc(task.Task):\n    def execute(self, a):\n        return a + 1\n\nstore = {\n    'a': 1\n}\nf = linear_flow.Flow('inc-flow')\nf.add(\n    Inc('t3',\n        provides='a',\n        requires='a'),\n)\n\ne = engines.load(f, store=store)\ne.run()\nprint e.storage.fetch('a', many_handler=lambda x: x[-1])\n\nChange-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0\n""}]",0,180431,c7e8c868cd85c878ab9896c868f9989adc7dfc09,21,3,5,15808,,,0,"Allow same deps for requires and provides in task

This change removes the DependencyFailure that is raised when a task
requires the same dependency as it provides. Taskflow returns a
frozenset([]) instead of a frozenset() when more than one value with the
same name is in the store.

This prevents the need for an inconvenient rename function when you want
to update a store variable with a new value.

Example case:
class Inc(task.Task):
    def execute(self, a):
        return a + 1

class AwkwardRename(task.Task):
    def execute(self, b):
        return b

store = {
    'a': 1
}
f = linear_flow.Flow('inc-flow')
f.add(
    Inc('t1',
        provides='b',
        requires='a',
        ),
    AwkwardRename('t2',
                  provides='a',
                  requires='b'))

e = engines.load(f, store=store)
e.run()
print e.storage.fetch('a', many_handler=lambda x: x[-1])

Now with ability to have the same provides as requires:
class Inc(task.Task):
    def execute(self, a):
        return a + 1

store = {
    'a': 1
}
f = linear_flow.Flow('inc-flow')
f.add(
    Inc('t3',
        provides='a',
        requires='a'),
)

e = engines.load(f, store=store)
e.run()
print e.storage.fetch('a', many_handler=lambda x: x[-1])

Change-Id: I421e1ab33508c25baf78bd76df158bb6116d6fb0
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/31/180431/3 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/test_flow_dependencies.py', 'taskflow/atom.py']",2,6170fff8de6c9f809067661302a928888cb8d1f6,allow-same-provides-as-requires,,"from taskflow import exceptions NOTE(harlowja): there can be no intersection between what this atom requires and what it produces (since this would be an impossible dependency to satisfy). out_of_order = self.provides.intersection(self.requires) if out_of_order: raise exceptions.DependencyFailure( ""Atom %(item)s provides %(oo)s that are required "" ""by this atom"" % dict(item=self.name, oo=sorted(out_of_order)))",9,18
openstack%2Frequirements~stable%2Fjuno~Ib591187857699a909be29e27696af07c0700bfff,openstack/requirements,stable/juno,Ib591187857699a909be29e27696af07c0700bfff,Add tooz to projects.txt,ABANDONED,2015-05-27 17:21:04.000000000,2015-05-27 23:32:16.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-27 17:21:04.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1f093340560c69168a0b35135b5c1c527b04ef6e', 'message': ""Add tooz to projects.txt\n\nNow that tooz has a stable/juno branch we want to keep it in sync with\nglobal-requirements.\n\nThat's being done manually in change\nIb6f79cfcd18a758ce4b2a86f3ff323d533db4640 for now.\n\nRelated-Bug: #1459322\n\nChange-Id: Ib591187857699a909be29e27696af07c0700bfff\n""}]",0,186090,1f093340560c69168a0b35135b5c1c527b04ef6e,9,6,1,6873,,,0,"Add tooz to projects.txt

Now that tooz has a stable/juno branch we want to keep it in sync with
global-requirements.

That's being done manually in change
Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640 for now.

Related-Bug: #1459322

Change-Id: Ib591187857699a909be29e27696af07c0700bfff
",git fetch https://review.opendev.org/openstack/requirements refs/changes/90/186090/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,1f093340560c69168a0b35135b5c1c527b04ef6e,bug/1459322,openstack/tooz,,1,0
openstack%2Fkeystone~master~I6215b7df497c142a5e73b62543e0d76458c85f64,openstack/keystone,master,I6215b7df497c142a5e73b62543e0d76458c85f64,Move endpoint policy into keystone core,MERGED,2015-04-08 00:51:38.000000000,2015-05-27 23:07:34.000000000,2015-05-27 23:07:32.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 8978}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-04-08 00:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/588b50eb5160fafca5a5668ee2e5304861c073bb', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace_extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 2, 'created': '2015-04-09 04:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5210c9d689c006830ea9403ad0baa974284a2a81', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace_extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 3, 'created': '2015-04-13 04:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4638249f1d41ae8c3f2888a4a32e5b493e3b5abe', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace_extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 4, 'created': '2015-04-17 01:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5d6512c712c0a21d5c46e34571e402b5e7c863e5', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace_extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 5, 'created': '2015-04-28 06:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f106e97e58e763c4a29829533e48e18611a60f77', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace_extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 6, 'created': '2015-05-04 02:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3af07fd4725ed8a0f3e8f811c7ac268fc18535a6', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace-extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 7, 'created': '2015-05-11 23:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/66f0c4db5c8c3ca052ec6998a415078169cc3ac1', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nImplements: bp replace-extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 8, 'created': '2015-05-19 18:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4443b77f1eaef3c81b4069712fb4fc2ef032a408', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nDocImpact: You should no longer run the migrations for this extension.\nImplements: bp replace-extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}, {'number': 9, 'created': '2015-05-25 07:30:42.000000000', 'files': ['keystone/endpoint_policy/core.py', 'keystone/backends.py', 'keystone/common/config.py', 'keystone/contrib/endpoint_policy/routers.py', 'keystone/endpoint_policy/backends/sql.py', 'keystone/endpoint_policy/backends/__init__.py', 'keystone/contrib/endpoint_policy/backends/sql.py', 'keystone/endpoint_policy/__init__.py', 'keystone/endpoint_policy/controllers.py', 'keystone/service.py', 'keystone/endpoint_policy/routers.py', 'setup.cfg', 'keystone/contrib/endpoint_policy/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/696c1569e8c2d2f9e3aa490b5d2bbcb037539006', 'message': 'Move endpoint policy into keystone core\n\nRemove endpoint_policy as an extension and move it to a core resource.\nFor now we leave the database migrations in the extension directory\nuntil we have a general policy for merging these into core.\n\nDocImpact: You should no longer run the migrations for this extension.\nImplements: bp replace-extensions\nChange-Id: I6215b7df497c142a5e73b62543e0d76458c85f64\n'}]",10,171448,696c1569e8c2d2f9e3aa490b5d2bbcb037539006,39,16,9,7191,,,0,"Move endpoint policy into keystone core

Remove endpoint_policy as an extension and move it to a core resource.
For now we leave the database migrations in the extension directory
until we have a general policy for merging these into core.

DocImpact: You should no longer run the migrations for this extension.
Implements: bp replace-extensions
Change-Id: I6215b7df497c142a5e73b62543e0d76458c85f64
",git fetch https://review.opendev.org/openstack/keystone refs/changes/48/171448/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/endpoint_policy/core.py', 'keystone/backends.py', 'keystone/common/config.py', 'keystone/contrib/endpoint_policy/routers.py', 'keystone/endpoint_policy/backends/sql.py', 'keystone/endpoint_policy/backends/__init__.py', 'keystone/contrib/endpoint_policy/backends/sql.py', 'keystone/endpoint_policy/__init__.py', 'keystone/endpoint_policy/controllers.py', 'keystone/service.py', 'keystone/endpoint_policy/routers.py', 'keystone/contrib/endpoint_policy/__init__.py']",12,588b50eb5160fafca5a5668ee2e5304861c073bb,bp/replace_extensions,,"# Copyright 2014 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystone.contrib.endpoint_policy.core import * # noqa ",279,207
openstack%2Fceilometer~stable%2Fjuno~Iba92aa656c6490ad43589bf6ae42bf2aac2ca613,openstack/ceilometer,stable/juno,Iba92aa656c6490ad43589bf6ae42bf2aac2ca613,Updated from global requirements,MERGED,2015-04-13 23:30:44.000000000,2015-05-27 23:03:47.000000000,2015-05-27 22:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5196}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6873}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-04-13 23:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1cd560fee7ea400f19d8cd4fbb00c747b2cb9487', 'message': 'Updated from global requirements\n\nChange-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613\n'}, {'number': 2, 'created': '2015-04-22 12:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/662b6e9010047fc0bbabedd50bec1272488ded24', 'message': 'Updated from global requirements\n\nChange-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613\n'}, {'number': 3, 'created': '2015-04-24 12:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2178358ecc0cafa8576c3ae1d0b28f84a21b2aca', 'message': 'Updated from global requirements\n\nChange-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613\n'}, {'number': 4, 'created': '2015-05-14 22:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/71af3e5ff45806e9aee5ae432d79dbaf10744835', 'message': 'Updated from global requirements\n\nChange-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613\n'}, {'number': 5, 'created': '2015-05-27 21:14:37.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ff882bebf20deb04880c7aef37a8565a10f742c2', 'message': 'Updated from global requirements\n\nChange-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613\n'}]",0,173117,ff882bebf20deb04880c7aef37a8565a10f742c2,32,10,5,11131,,,0,"Updated from global requirements

Change-Id: Iba92aa656c6490ad43589bf6ae42bf2aac2ca613
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/17/173117/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,1cd560fee7ea400f19d8cd4fbb00c747b2cb9487,openstack/requirements,"python-keystoneclient>=0.10.0,<1.2.0","python-keystoneclient>=0.10.0,<=1.1.0",2,2
openstack%2Ftooz~stable%2Fjuno~I211e2d17d6df5dc4f2eaa5b77c2653f9574f16eb,openstack/tooz,stable/juno,I211e2d17d6df5dc4f2eaa5b77c2653f9574f16eb,Update .gitreview for stable/juno,ABANDONED,2015-05-27 16:22:46.000000000,2015-05-27 22:57:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-05-27 16:22:46.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/tooz/commit/2a04a3a9a17531e0ee1b9bcd466856da50fa8334', 'message': 'Update .gitreview for stable/juno\n\nChange-Id: I211e2d17d6df5dc4f2eaa5b77c2653f9574f16eb\n'}]",0,186070,2a04a3a9a17531e0ee1b9bcd466856da50fa8334,9,3,1,2472,,,0,"Update .gitreview for stable/juno

Change-Id: I211e2d17d6df5dc4f2eaa5b77c2653f9574f16eb
",git fetch https://review.opendev.org/openstack/tooz refs/changes/70/186070/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,2a04a3a9a17531e0ee1b9bcd466856da50fa8334,,defaultbranch=stable/juno,,1,0
openstack%2Fpuppet-cinder~master~Idb91dd3d3599a4bea9a106d09be2f41052fb3cca,openstack/puppet-cinder,master,Idb91dd3d3599a4bea9a106d09be2f41052fb3cca,Bring Redhat support to acceptance tests,MERGED,2015-05-13 13:33:47.000000000,2015-05-27 22:57:46.000000000,2015-05-27 22:57:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-05-13 13:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9a79c37799bcab86f8a39d1220844ceb3fca945c', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* basic_keystone_spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source and on RH, install erlang before rabbitmq-server.\n\nChange-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca\nCloses-bug: #1444736\n'}, {'number': 2, 'created': '2015-05-13 16:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9344a2562448468496df66e0c641dcab77bc2d57', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* basic_keystone_spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source\n\nChange-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca\nCloses-bug: #1444736\n'}, {'number': 3, 'created': '2015-05-14 12:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/4ac43264e6e3aabd63422ffe47eb34b15bde4061', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* basic_keystone_spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source\n* apt: pin the module\n\nChange-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca\nCloses-bug: #1444736\n'}, {'number': 4, 'created': '2015-05-14 14:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/c97bface8f8ccd6e504cfe0a0a6720a4e5a1ab9c', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source\n* apt: pin the module\n\nChange-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca\nCloses-bug: #1444736'}, {'number': 5, 'created': '2015-05-14 15:50:46.000000000', 'files': ['spec/acceptance/nodesets/nodepool-trusty.yml', 'Gemfile', 'spec/acceptance/basic_cinder_spec.rb', 'spec/spec_helper_acceptance.rb', 'spec/acceptance/nodesets/nodepool-centos7.yml'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/4b95903f0962a560325958ca3dd7a6297bbbc063', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* basic_keystone_spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source\n* apt: pin the module\n\nChange-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca\nCloses-bug: #1444736\n'}]",0,182668,4b95903f0962a560325958ca3dd7a6297bbbc063,28,5,5,3153,,,0,"Bring Redhat support to acceptance tests

OpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.

* Add minitest to Gemfile (dependency to run beaker on centos - see
  http://projects.theforeman.org/issues/2650 for details)
* separate nodepool files to have trusty & centos7 support in OS infra
* basic_keystone_spec: add case for repo configuration and support
  RH systems.
* rabbitmq: install module from source
* apt: pin the module

Change-Id: Idb91dd3d3599a4bea9a106d09be2f41052fb3cca
Closes-bug: #1444736
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/68/182668/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/nodesets/nodepool-trusty.yml', 'Gemfile', 'spec/acceptance/basic_cinder_spec.rb', 'spec/spec_helper_acceptance.rb', 'spec/acceptance/nodesets/nodepool-centos7.yml']",5,9a79c37799bcab86f8a39d1220844ceb3fca945c,bug/1444736,HOSTS: centos-70-x64: roles: - master platform: el-7-x86_64 hypervisor : none ip: 127.0.0.1 CONFIG: type: foss ,,41,5
openstack%2Fpuppet-cinder~master~I35aeb3a14c1048b3453b290c368703e859767727,openstack/puppet-cinder,master,I35aeb3a14c1048b3453b290c368703e859767727,Beaker: install APT repo with openstack_extras,MERGED,2015-05-11 19:49:45.000000000,2015-05-27 22:57:33.000000000,2015-05-27 22:57:31.000000000,"[{'_account_id': 3}, {'_account_id': 5241}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-05-11 19:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9d7681b1d5db2abbcc8957b2132e63f1c67dec21', 'message': 'Beaker: install APT repo with openstack_extras\n\nUse openstack_extras module to manage Ubuntu Cloud Archive repository.\n\nChange-Id: I35aeb3a14c1048b3453b290c368703e859767727\n'}, {'number': 2, 'created': '2015-05-12 04:06:04.000000000', 'files': ['spec/acceptance/basic_cinder_spec.rb', 'spec/spec_helper_acceptance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/0dd2d78bd3b0e664a38c6984bca69eaf2635535f', 'message': 'Beaker: install APT repo with openstack_extras\n\nUse openstack_extras module to manage Ubuntu Cloud Archive repository.\n\nChange-Id: I35aeb3a14c1048b3453b290c368703e859767727\n'}]",0,182046,0dd2d78bd3b0e664a38c6984bca69eaf2635535f,12,4,2,3153,,,0,"Beaker: install APT repo with openstack_extras

Use openstack_extras module to manage Ubuntu Cloud Archive repository.

Change-Id: I35aeb3a14c1048b3453b290c368703e859767727
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/46/182046/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/basic_cinder_spec.rb', 'spec/spec_helper_acceptance.rb']",2,9d7681b1d5db2abbcc8957b2132e63f1c67dec21,bug/1444736, shell('git clone https://git.openstack.org/stackforge/puppet-openstack_extras /etc/puppet/modules/openstack_extras'),,3,13
openstack%2Fhorizon~stable%2Fkilo~I6a8d1460cbd3a5b954a357b46ca9239614290e49,openstack/horizon,stable/kilo,I6a8d1460cbd3a5b954a357b46ca9239614290e49,General specs enclosure cleanup,ABANDONED,2015-05-21 20:58:01.000000000,2015-05-27 22:48:14.000000000,,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9981}]","[{'number': 1, 'created': '2015-05-21 20:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/666727d374fa849b3fb396f3eb1fd7959114aeff', 'message': 'Jshint fix for stable/kilo\n\nChange-Id: I6a8d1460cbd3a5b954a357b46ca9239614290e49\n'}, {'number': 2, 'created': '2015-05-22 05:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fbbd6b02fcc5c798512eeab5cde766dd3972aa67', 'message': 'Jshint fix for stable/kilo\n\nEnclosed jasmine tests inside a function and removed the irrelevant\nglobalstrict jshint comment.\n\nCloses-bug: #1441299\nCherry-picked from Idefbe2290e88bd3be62043e9601c1a909dc86620\nChange-Id: I6a8d1460cbd3a5b954a357b46ca9239614290e49\n'}, {'number': 3, 'created': '2015-05-26 13:47:34.000000000', 'files': ['horizon/static/angular/login/login.spec.js', 'horizon/static/angular/help-panel/help-panel.spec.js', 'horizon/static/angular/wizard/wizard.spec.js', 'horizon/static/angular/form/form.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.model.spec.js', 'horizon/static/angular/charts/pie-chart.spec.js', 'horizon/static/angular/metadata-tree/metadata-tree.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.spec.js', 'horizon/static/angular/table/table.js', 'openstack_dashboard/static/dashboard/launch-instance/flavor/flavor.spec.js', 'horizon/static/angular/metadata-display/metadata-display.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b6043434540eff94c4d10aabe431acfe70a480e', 'message': 'General specs enclosure cleanup\n\nEnclosed jasmine tests inside a function and removed the irrelevant\nglobalstrict jshint comment.\n\nCloses-bug: #1441299\n(cherry picked from commit cc6f1ebf384de4660b19719ad980304ced8acde2)\n\nResolution Notes:\nKept broader set of tests.\n\nConflicts:\n\thorizon/static/angular/login/login.spec.js\n\nChange-Id: I6a8d1460cbd3a5b954a357b46ca9239614290e49\n'}]",0,184865,3b6043434540eff94c4d10aabe431acfe70a480e,15,6,3,9576,,,0,"General specs enclosure cleanup

Enclosed jasmine tests inside a function and removed the irrelevant
globalstrict jshint comment.

Closes-bug: #1441299
(cherry picked from commit cc6f1ebf384de4660b19719ad980304ced8acde2)

Resolution Notes:
Kept broader set of tests.

Conflicts:
	horizon/static/angular/login/login.spec.js

Change-Id: I6a8d1460cbd3a5b954a357b46ca9239614290e49
",git fetch https://review.opendev.org/openstack/horizon refs/changes/65/184865/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/angular/charts/pie-chart.spec.js', 'horizon/static/angular/login/login.spec.js', 'horizon/static/angular/help-panel/help-panel.spec.js', 'horizon/static/angular/metadata-tree/metadata-tree.spec.js', 'horizon/static/angular/wizard/wizard.spec.js', 'horizon/static/angular/form/form.spec.js', 'horizon/static/angular/metadata-display/metadata-display.spec.js']",7,666727d374fa849b3fb396f3eb1fd7959114aeff,jshint-fix,"(function(){ 'use strict'; describe('hz.widget.metadata-display module', function() { it('should have been defined', function () { expect(angular.module('hz.widget.metadata-display')).toBeDefined(); }); var namespaces = [ { ""display_name"": ""Test Namespace A"", ""description"": ""Test namespace description"", ""properties"": { ""test:A:1"": { ""title"": ""Test A.1 - string"", ""default"": ""foo"", ""option-1"", ""option-2"", ""option-3"" }, ""test:A:2"": { ""title"": ""Test A.2 - integer"", ""type"": ""integer"", ""default"": ""1"", ""minimum"": 0, ""maximum"": 10 }, ""test:A:3"": { ""title"": ""Test A.3 - number"", ""type"": ""number"", ""default"": ""1.1"", ""minimum"": 0, ""maximum"": 10 }, ""test:A:4"": { ""title"": ""Test A.4 - boolean"", ""type"": ""boolean"", ""default"": ""True"" }, ""test:A:5"": { ""title"": ""Test A.5 - boolean"", ""type"": ""boolean"", ""default"": ""false"" }, ""test:A:6"": { ""title"": ""Test A.6 - array"", ""type"": ""array"", ""items"": { ""type"": ""string"", ""enum"": [ ""val-1"", ""val-2"", ""val-3"" ] } } } }, { ""display_name"": ""Test Namespace B"", ""description"": ""Test namespace description"", ""objects"": [ { ""name"": ""Test Object A"", ""description"": ""Test object description"", ""properties"": { ""test:B:A:1"": { ""title"": ""Test B.A.1"", ""description"": ""Test description"" }, ""test:B:A:2"": {} } }, { ""name"": ""Test Object B"", ""description"": ""Test object description"", ""properties"": { ""test:B:B:1"": {}, ""test:B:B:2"": {} } } ] } ]; var existing = { 'test:A:1': 'option-2', 'test:A:2': '5', 'test:B:A:1': 'foo', 'test:B:B:1': 'bar' }; describe('hzMetadataDisplay directive', function () { var $scope, $element; beforeEach(module('templates')); beforeEach(module('hz')); beforeEach(module('hz.widgets')); beforeEach(module('hz.widget.metadata-tree')); beforeEach(module('hz.widget.metadata-display')); beforeEach(inject(function ($injector) { var $compile = $injector.get('$compile'); $scope = $injector.get('$rootScope').$new(); $scope.available = namespaces; $scope.existing = existing; var markup = '<hz-metadata-display available=""available"" existing=""existing""></hz-metadata-display>'; $element = angular.element(markup); $compile($element)($scope); $scope.$digest(); })); it('should have 3 rows in selector list', function() { expect($element.find('.selector .selector-item').length).toBe(3); }); it('should have 2 items in first group', function() { expect($element.find('div[ng-repeat] div.auto-width').length).toBe(2); }); it('should have 1 item in second group', function() { $element.find('.selector .selector-item:nth-child(2)').trigger('click'); expect($element.find('div[ng-repeat] div.auto-width').length).toBe(1); }); it('should have proper description', function() { expect($element.find('span[ng-bind=""selected.description""]').text()).toBe(namespaces[0].description); $element.find('.selector .selector-item:nth-child(2)').trigger('click'); expect($element.find('span[ng-bind=""selected.description""]').text()).toBe(namespaces[1].objects[0].description); });})();","/* jshint globalstrict: true */ 'use strict'; describe('hz.widget.metadata-display module', function() { it('should have been defined', function () { expect(angular.module('hz.widget.metadata-display')).toBeDefined(); }); var namespaces = [ { ""display_name"": ""Test Namespace A"", ""description"": ""Test namespace description"", ""properties"": { ""test:A:1"": { ""title"": ""Test A.1 - string"", ""type"": ""string"", ""default"": ""foo"", ""enum"": [ ""option-1"", ""option-2"", ""option-3"" ] }, ""test:A:2"": { ""title"": ""Test A.2 - integer"", ""type"": ""integer"", ""default"": ""1"", ""minimum"": 0, ""maximum"": 10 }, ""test:A:3"": { ""title"": ""Test A.3 - number"", ""type"": ""number"", ""default"": ""1.1"", ""minimum"": 0, ""maximum"": 10 }, ""test:A:4"": { ""title"": ""Test A.4 - boolean"", ""type"": ""boolean"", ""default"": ""True"" }, ""test:A:5"": { ""title"": ""Test A.5 - boolean"", ""type"": ""boolean"", ""default"": ""false"" }, ""test:A:6"": { ""title"": ""Test A.6 - array"", ""type"": ""array"", ""items"": { ""val-1"", ""val-2"", ""val-3"" } } } }, { ""display_name"": ""Test Namespace B"", ""description"": ""Test namespace description"", ""objects"": [ { ""name"": ""Test Object A"", ""description"": ""Test object description"", ""properties"": { ""test:B:A:1"": { ""title"": ""Test B.A.1"", ""description"": ""Test description"" }, ""test:B:A:2"": {} } }, { ""name"": ""Test Object B"", ""description"": ""Test object description"", ""properties"": { ""test:B:B:1"": {}, ""test:B:B:2"": {} } } ] } ]; var existing = { 'test:A:1': 'option-2', 'test:A:2': '5', 'test:B:A:1': 'foo', 'test:B:B:1': 'bar' }; describe('hzMetadataDisplay directive', function () { var $scope, $element; beforeEach(module('templates')); beforeEach(module('hz')); beforeEach(module('hz.widgets')); beforeEach(module('hz.widget.metadata-tree')); beforeEach(module('hz.widget.metadata-display')); beforeEach(inject(function ($injector) { var $compile = $injector.get('$compile'); $scope = $injector.get('$rootScope').$new(); $scope.available = namespaces; $scope.existing = existing; var markup = '<hz-metadata-display available=""available"" existing=""existing""></hz-metadata-display>'; $element = angular.element(markup); $compile($element)($scope); $scope.$digest(); })); it('should have 3 rows in selector list', function() { expect($element.find('.selector .selector-item').length).toBe(3); it('should have 2 items in first group', function() { expect($element.find('div[ng-repeat] div.auto-width').length).toBe(2); }); it('should have 1 item in second group', function() { $element.find('.selector .selector-item:nth-child(2)').trigger('click'); expect($element.find('div[ng-repeat] div.auto-width').length).toBe(1); }); it('should have proper description', function() { expect($element.find('span[ng-bind=""selected.description""]').text()).toBe(namespaces[0].description); $element.find('.selector .selector-item:nth-child(2)').trigger('click'); expect($element.find('span[ng-bind=""selected.description""]').text()).toBe(namespaces[1].objects[0].description); }); });",782,775
openstack%2Fopenstack-ansible~master~Ie4adf625d85f84a0d89a108ef0438622ab763b9d,openstack/openstack-ansible,master,Ie4adf625d85f84a0d89a108ef0438622ab763b9d,add option to use dd for swapfile creation,MERGED,2015-05-26 11:28:05.000000000,2015-05-27 22:44:53.000000000,2015-05-27 22:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 2556}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-05-26 11:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d980377eb3f9d7ccc1cd59db3c6e597c36c8ca15', 'message': 'add option to use dd for swapfile creation\n\nfallocate is faster than using dd to create a thick swapfile with\nzeros, but it is not supported on all filesystems (specifically ext3).\n\nThis commit adds the ability to override the default use of fallocate\nand fall back to using dd.\n\nChange-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d\n'}, {'number': 2, 'created': '2015-05-26 12:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f7782092727c13c00bb57cf9fb346da10e011ac9', 'message': 'add option to use dd for swapfile creation\n\nfallocate is faster than using dd to create a thick swapfile with\nzeros, but it is not supported on all filesystems (specifically ext3).\n\nThis commit adds the ability to override the default use of fallocate\nand fall back to using dd.\n\nChange-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d\n'}, {'number': 3, 'created': '2015-05-27 09:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b63509e31672992725bf1a5ded0473d70cc64b34', 'message': 'add option to use dd for swapfile creation\n\nfallocate is faster than using dd to create a thick swapfile with\nzeros, but it is not supported on all filesystems (specifically ext3).\n\nThis commit adds a fallback to using dd if fallocate fails\n\nChange-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d\n'}, {'number': 4, 'created': '2015-05-27 10:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/30f026b8317d14daf9cc9a178402fca2902ffe5b', 'message': 'add option to use dd for swapfile creation\n\nfallocate is faster than using dd to create a thick swapfile with\nzeros, but it is not supported on all filesystems (specifically ext3).\n\nThis commit adds a fallback to using dd if fallocate fails\n\nCloses-Bug: #1458841\n\nChange-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d\n'}, {'number': 5, 'created': '2015-05-27 16:02:44.000000000', 'files': ['scripts/bootstrap-aio.sh', 'scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ccb16763234a13fc204b91943e3d0c197545f2e9', 'message': 'add option to use dd for swapfile creation\n\nfallocate is faster than using dd to create a thick swapfile with\nzeros, but it is not supported on all filesystems (specifically ext3).\n\nThis commit adds a fallback to using dd if fallocate fails\n\nCloses-Bug: #1458841\n\nChange-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d\n'}]",2,185565,ccb16763234a13fc204b91943e3d0c197545f2e9,30,6,5,425,,,0,"add option to use dd for swapfile creation

fallocate is faster than using dd to create a thick swapfile with
zeros, but it is not supported on all filesystems (specifically ext3).

This commit adds a fallback to using dd if fallocate fails

Closes-Bug: #1458841

Change-Id: Ie4adf625d85f84a0d89a108ef0438622ab763b9d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/65/185565/4 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/bootstrap-aio.sh', 'scripts/scripts-library.sh']",2,d980377eb3f9d7ccc1cd59db3c6e597c36c8ca15,bug/1458841,"SWAPFILE_USE_DD=""${SWAPFILE_USE_DD:-false}"" if [ ${SWAPFILE_USE_DD} ]; then dd if=/dev/zero of=${LOOP_FILENAME} bs=1M count=$(( ${LOOP_FILESIZE} / 1024 / 1024 )) else fallocate -l ${LOOP_FILESIZE} ${LOOP_FILENAME} fi", fallocate -l ${LOOP_FILESIZE} ${LOOP_FILENAME},8,3
openstack%2Fgovernance~master~I406c7b8d2b192a7d0463881ab1aebce83895d4f6,openstack/governance,master,I406c7b8d2b192a7d0463881ab1aebce83895d4f6,Add tc-approved-release tag for trademarkable projects,ABANDONED,2015-05-04 14:48:56.000000000,2015-05-27 22:40:49.000000000,,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2889}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-05-04 14:48:56.000000000', 'files': ['reference/tags/index.rst', 'reference/tags/tc-approved-release.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/94984e29bac3117e3c871368203777d43cba01f6', 'message': 'Add tc-approved-release tag for trademarkable projects\n\nChange-Id: I406c7b8d2b192a7d0463881ab1aebce83895d4f6\n'}]",32,179799,94984e29bac3117e3c871368203777d43cba01f6,25,12,1,2472,,,0,"Add tc-approved-release tag for trademarkable projects

Change-Id: I406c7b8d2b192a7d0463881ab1aebce83895d4f6
",git fetch https://review.opendev.org/openstack/governance refs/changes/99/179799/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/tags/index.rst', 'reference/tags/tc-approved-release.rst']",2,94984e29bac3117e3c871368203777d43cba01f6,add-trademark-candidate-tag,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== tc-approved-release ===================== .. NOTE(dhellmann): I don't especially like the name of this tag, but I decided its use would be more easily communicated if we stuck with the designation from the bylaws rather than making up a different name. This tag is used to indicate the projects the TC recommends to the OpenStack Foundation Board as candidates for trademark use under the OpenStack Foundation trademark policy. Rationale ========= This tag is applied to projects the TC considers suitable to be included in the set of ""Trademark Designated OpenStack Software"" as defined in the Foundation bylaws. Applying the tag is an indication that the TC is including the project in the ""OpenStack TC Approved Release"", following the guidelines laid out in sections 4.1 and 4.13 of `the OpenStack Foundation Bylaws`_. .. _the OpenStack Foundation Bylaws: http://www.openstack.org/legal/bylaws-of-the-openstack-foundation Requirements ============ #. The project is already an official OpenStack project in good standing. #. The project team is managed in a way that improves its chances of being healthy over a long period of time and has the :ref:`tag-team:diverse-affiliation` tag. .. NOTE(dhellmann): Some of the below are copied or modified versions of the incubation/integration policies, which seemed like a good starting point for criteria. #. The project leverages existing functionality in other OpenStack projects as much as possible. #. The project uses the OpenStack continuous integration facilities for automated functional testing, including integration with any other OpenStack projects on which it depends. #. The project team fulfills its commitment to users. #. The project team commits to maintaining API compatibility over a sustained period of time. #. The project team actively manages and responds to incoming bug reports. #. The project team has a proven history of providing user support (on the openstack@ mailing list and on Ask OpenStack). #. The project supports upgrading from one stable release to the next (for consumers of stable releases) and between commits on the master branch (for consumers of the development release). #. The project follows OpenStack licensing conventions. #. The project must be licensed under the Apache License v2. #. All contributors to the project must have signed the CLA. #. The TC considers the project suitable for consideration for trademark use. Tag application process ======================= Anyone may propose adding or removing this tag to a set of projects by proposing a change to the openstack/governance repository. The change is reviewed by the Technical Committee and approved using standard resolution approval rules, including discussion at at least one Technical Committee public IRC meeting. Deprecation =========== Deprecation of the use of this tag is governed by the bylaws, the trademark policy set out by the board, and the procedures the Board and TC have agreed to follow for communicating changes to the ""Trademark Designated OpenStack Software"". .. note:: We need a reference to that agreement, when we have it. We also need a reference to the deprecation policy the Board adopts, since that will influence our policy by at least setting a minimum. Attributes ========== None Application to current projects =============================== Initially, all projects that have the :ref:`tag-integrated-release` tag should be updated to also include this tag. .. tagged-projects:: tc-approved-release ",,113,0
openstack%2Frally~master~Ie38f46e1e191b0dba0689e86b8504f4be24aec10,openstack/rally,master,Ie38f46e1e191b0dba0689e86b8504f4be24aec10,Add checks for SuSE based systems,MERGED,2015-05-27 09:10:10.000000000,2015-05-27 22:25:58.000000000,2015-05-27 22:25:57.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 14168}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-27 09:10:10.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/b63c1b8380ddd1e13b353b03ea83dfe37b8318fe', 'message': ""Add checks for SuSE based systems\n\nAdd support for systems that have OpenSuSE platforms.\nThe package manager in suse is 'zypper' and works just like\nyum, where package availability can simply be checked by 'rpm -q'\njust like for rhel based sys. Some packages differ by name like\n'libffi48' and 'postgresql93'.\nCloses-bug: 1455672\n\nChange-Id: Ie38f46e1e191b0dba0689e86b8504f4be24aec10\n""}]",0,185893,b63c1b8380ddd1e13b353b03ea83dfe37b8318fe,9,9,1,12609,,,0,"Add checks for SuSE based systems

Add support for systems that have OpenSuSE platforms.
The package manager in suse is 'zypper' and works just like
yum, where package availability can simply be checked by 'rpm -q'
just like for rhel based sys. Some packages differ by name like
'libffi48' and 'postgresql93'.
Closes-bug: 1455672

Change-Id: Ie38f46e1e191b0dba0689e86b8504f4be24aec10
",git fetch https://review.opendev.org/openstack/rally refs/changes/93/185893/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,b63c1b8380ddd1e13b353b03ea83dfe37b8318fe,bug/1455672," missing=$(which_missing_packages gcc libffi48-devel python-devel openssl-devel gmp-devel libxml2-devel libxslt-devel postgresql93-devel git) if [ ""$ASKCONFIRMATION"" -eq 0 ]; then pkg_manager=""zypper -n --no-gpg-checks --non-interactive install --auto-agree-with-licenses"" else pkg_manager=""zypper install"" fi"," warn ""Cannot check if requisite software is installed: SuSE and compatible Linux distributions are not yet supported. I'm proceeding anyway, but you may run into errors later.""",7,1
openstack%2Fcinder~master~I68c607df90a3dfeae7a841a1dddee5416fa42d13,openstack/cinder,master,I68c607df90a3dfeae7a841a1dddee5416fa42d13,Validate name and description for volume type,MERGED,2015-05-14 10:23:03.000000000,2015-05-27 22:24:07.000000000,2015-05-26 13:34:23.000000000,"[{'_account_id': 3}, {'_account_id': 1011}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 7219}, {'_account_id': 8119}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9096}, {'_account_id': 9751}, {'_account_id': 10300}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14907}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 15882}, {'_account_id': 16160}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-14 10:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f35af445d76e51f2863d541038d793d00e44d45', 'message': ""Cinder type create and update api returns 500\n\nIf you pass name parameter with long string of more than\n255 characters to type-create and type-update api, then\nit returns 500 error code.\n\nAdded a check in _create() and _update() methods of 'types_manage'\nextension to validate string limit and returned 400 if limit exceeds.\nAlso removed leading and trailing white spaces before add/update\ndb record.\n\nCloses-Bug: 1450388\nChange-Id: I68c607df90a3dfeae7a841a1dddee5416fa42d13\n""}, {'number': 2, 'created': '2015-05-18 13:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dfa8d16a3ec0ee36e9ed6518b3c71e848781f2c8', 'message': ""Validate name and description for volume type\n\nIf you pass name parameter with long string of more than\n255 characters to type-create and type-update api, then\nit returns 500 error code.\n\nAdded a check in _create() and _update() methods of 'types_manage'\nextension to validate string limit and returned 400 if limit exceeds.\n\nCloses-Bug: 1450388\nChange-Id: I68c607df90a3dfeae7a841a1dddee5416fa42d13\n""}, {'number': 3, 'created': '2015-05-20 13:34:04.000000000', 'files': ['cinder/api/contrib/types_manage.py', 'cinder/tests/unit/api/contrib/test_types_manage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/aeed2a788608b7b93bcdd70826ff0a3102c15027', 'message': ""Validate name and description for volume type\n\nIf you pass name parameter with long string of more than\n255 characters to type-create and type-update api, then\nit returns 500 error code.\n\nAdded a check in _create() and _update() methods of 'types_manage'\nextension to validate string limit and returned 400 if limit exceeds.\n\nCloses-Bug: 1450388\nChange-Id: I68c607df90a3dfeae7a841a1dddee5416fa42d13\n""}]",9,183000,aeed2a788608b7b93bcdd70826ff0a3102c15027,107,39,3,10300,,,0,"Validate name and description for volume type

If you pass name parameter with long string of more than
255 characters to type-create and type-update api, then
it returns 500 error code.

Added a check in _create() and _update() methods of 'types_manage'
extension to validate string limit and returned 400 if limit exceeds.

Closes-Bug: 1450388
Change-Id: I68c607df90a3dfeae7a841a1dddee5416fa42d13
",git fetch https://review.opendev.org/openstack/cinder refs/changes/00/183000/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/contrib/types_manage.py', 'cinder/tests/unit/api/contrib/test_types_manage.py']",2,1f35af445d76e51f2863d541038d793d00e44d45,bug/1450388," def test_create_type_with_name_too_long(self): type_name = 'a' * 256 body = {""volume_type"": {""name"": type_name, ""extra_specs"": {""key1"": ""value1""}}} req = fakes.HTTPRequest.blank('/v2/fake/types') self.assertRaises(exception.InvalidInput, self.controller._create, req, body) def test_create_type_with_description_too_long(self): type_description = 'a' * 256 body = {""volume_type"": {""name"": ""vol_type_1"", ""description"": type_description, ""extra_specs"": {""key1"": ""value1""}}} req = fakes.HTTPRequest.blank('/v2/fake/types') self.assertRaises(exception.InvalidInput, self.controller._create, req, body) def test_create_type_with_name_as_integer(self): type_name = 1234 body = {""volume_type"": {""name"": type_name, ""extra_specs"": {""key1"": ""value1""}}} req = fakes.HTTPRequest.blank('/v2/fake/types') self.assertRaises(exception.InvalidInput, self.controller._create, req, body) def test_create_type_with_description_as_integer(self): type_description = 1234 body = {""volume_type"": {""name"": ""vol_type_1"", ""description"": type_description, ""extra_specs"": {""key1"": ""value1""}}} req = fakes.HTTPRequest.blank('/v2/fake/types') self.assertRaises(exception.InvalidInput, self.controller._create, req, body) def test_update_type_with_name_too_long(self): type_name = 'a' * 256 body = {""volume_type"": {""name"": type_name, ""description"": """"}} req = fakes.HTTPRequest.blank('/v2/fake/types/1') req.method = 'PUT' self.assertRaises(exception.InvalidInput, self.controller._update, req, '1', body) def test_update_type_with_description_too_long(self): type_description = 'a' * 256 body = {""volume_type"": {""description"": type_description}} req = fakes.HTTPRequest.blank('/v2/fake/types/1') req.method = 'PUT' self.assertRaises(exception.InvalidInput, self.controller._update, req, '1', body) def test_update_type_with_name_as_integer(self): type_name = 1234 body = {""volume_type"": {""name"": type_name, ""description"": """"}} req = fakes.HTTPRequest.blank('/v2/fake/types/1') req.method = 'PUT' self.assertRaises(exception.InvalidInput, self.controller._update, req, '1', body) def test_update_type_with_description_as_integer(self): type_description = 1234 body = {""volume_type"": {""description"": type_description}} req = fakes.HTTPRequest.blank('/v2/fake/types/1') req.method = 'PUT' self.assertRaises(exception.InvalidInput, self.controller._update, req, '1', body) self.assertRaises(exception.InvalidInput,"," self.assertRaises(webob.exc.HTTPBadRequest,",100,6
openstack%2Fswift~feature%2Fhummingbird~I69c00c0cf4bba552ad73176fdd75874ff25f0a94,openstack/swift,feature/hummingbird,I69c00c0cf4bba552ad73176fdd75874ff25f0a94,go: check error returns part 1,MERGED,2015-05-15 16:51:34.000000000,2015-05-27 22:16:21.000000000,2015-05-27 22:16:19.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 2828}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-05-15 16:51:34.000000000', 'files': ['go/objectserver/replicator_test.go', 'go/hummingbird/utils.go', 'go/objectserver/replicator.go', 'go/objectserver/backend.go', 'go/hummingbird/unpickle.go', 'go/probe/base.go', 'go/hummingbird/ring.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/b9d0e885dc5cc1800a7746cf2e915d7bbcd20565', 'message': ""go: check error returns part 1\n\nCheck error returns for a few places we'd ignored them.\n\nThere will be a few of these - I think it's better to clean up in small\nincrements rather than one giant commit that's hard to get merged.\n\nChange-Id: I69c00c0cf4bba552ad73176fdd75874ff25f0a94\n""}]",0,183605,b9d0e885dc5cc1800a7746cf2e915d7bbcd20565,11,5,1,2828,,,0,"go: check error returns part 1

Check error returns for a few places we'd ignored them.

There will be a few of these - I think it's better to clean up in small
increments rather than one giant commit that's hard to get merged.

Change-Id: I69c00c0cf4bba552ad73176fdd75874ff25f0a94
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/183605/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/objectserver/replicator_test.go', 'go/hummingbird/utils.go', 'go/objectserver/replicator.go', 'go/objectserver/backend.go', 'go/hummingbird/unpickle.go', 'go/probe/base.go', 'go/hummingbird/ring.go']",7,b9d0e885dc5cc1800a7746cf2e915d7bbcd20565,handleerrors," LocalDevices(localPort int) (devs []*Device, err error)func (r *hashRing) LocalDevices(localPort int) (devs []*Device, err error) { localAddrs, err := net.InterfaceAddrs() if err != nil { return nil, err } return devs, nil gz, err := gzip.NewReader(fp) if err != nil { return nil, err }"," LocalDevices(localPort int) (devs []*Device)func (r *hashRing) LocalDevices(localPort int) (devs []*Device) { localAddrs, _ := net.InterfaceAddrs() return devs gz, _ := gzip.NewReader(fp)",59,28
openstack%2Fcookbook-openstack-network~master~I8896af89f1b5fef39776a8aa1289cb9ee7645a08,openstack/cookbook-openstack-network,master,I8896af89f1b5fef39776a8aa1289cb9ee7645a08,Refactor nova section to enable auth strategy,MERGED,2015-04-28 02:12:32.000000000,2015-05-27 22:14:55.000000000,2015-05-27 22:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 7148}, {'_account_id': 8112}, {'_account_id': 8172}, {'_account_id': 9488}, {'_account_id': 12323}, {'_account_id': 13667}]","[{'number': 1, 'created': '2015-04-28 02:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/cb4919e84289e931bdbe5dcce0ed03ce18c52baf', 'message': ""Partially revert the updates on nova section attributes\n\nNow in neutron code, it is still adoption as below.\nInstead of using [nova] section 'admin_auth_url' or 'admin_username' etc.\n\n  CONF.nova_admin_auth_url\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n""}, {'number': 2, 'created': '2015-05-11 07:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/c783320ac9a3687a9ec6406bd03f39704ee6beb2', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 3, 'created': '2015-05-11 08:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/48453b2bda76dfee984935688b8cbd2dd6c02ed9', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 4, 'created': '2015-05-11 09:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/fc71701555a51945bd6dd451648134656f8b906c', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 5, 'created': '2015-05-12 02:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/a60e0861f3e820286495947cd1088f74b90fc1c1', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 6, 'created': '2015-05-13 05:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/27c0a322d45b6fa6eb8c884c3dc8b873bee15167', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 7, 'created': '2015-05-14 03:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/70cb78dd5dedb82e7d971bb1d48a6d0aaaee8785', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 8, 'created': '2015-05-18 02:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/cf4b3e854adee1f401f733fef626e6d238ec57ad', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_ur\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}, {'number': 9, 'created': '2015-05-27 02:52:26.000000000', 'files': ['attributes/default.rb', 'spec/default_spec.rb', 'templates/default/neutron.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/38758fbb145751847e975873ce60c28e46bf6db0', 'message': 'Refactor nova section to enable auth strategy\n\nAuthenticating to nova using nova_admin_* options is deprecated.\n\n  CONF.nova_admin_auth_url\n  CONF.nova_admin_username\n  CONF.nova_admin_password\n  CONF.nova_admin_tenant_id\n  CONF.nova_admin_tenant_name\n\nThis should be done using an auth plugin, like password:\n\n  [nova]\n  region_name = RegionOne\n  project_domain_id = default\n  project_name = service\n  user_domain_id = default\n  password = passw0rd\n  username = nova\n  auth_url = http://127.0.0.1:35357\n  auth_plugin = password\n\nReference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90\n\nChange-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08\nCloses-bug: #1449058\n'}]",26,178028,38758fbb145751847e975873ce60c28e46bf6db0,47,8,9,8112,,,0,"Refactor nova section to enable auth strategy

Authenticating to nova using nova_admin_* options is deprecated.

  CONF.nova_admin_auth_url
  CONF.nova_admin_username
  CONF.nova_admin_password
  CONF.nova_admin_tenant_id
  CONF.nova_admin_tenant_name

This should be done using an auth plugin, like password:

  [nova]
  region_name = RegionOne
  project_domain_id = default
  project_name = service
  user_domain_id = default
  password = passw0rd
  username = nova
  auth_url = http://127.0.0.1:35357
  auth_plugin = password

Reference: https://github.com/openstack/neutron/blob/master/neutron/notifiers/nova.py#L85-90

Change-Id: I8896af89f1b5fef39776a8aa1289cb9ee7645a08
Closes-bug: #1449058
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/28/178028/7 && git format-patch -1 --stdout FETCH_HEAD,"['spec/default_spec.rb', 'templates/default/neutron.conf.erb']",2,cb4919e84289e931bdbe5dcce0ed03ce18c52baf,wencheng,"# URL for connection to nova (Only supports one nova region currently). nova_url = <%= @nova_endpoint %> # Username for connection to nova in admin context nova_admin_username = <%= node[""openstack""][""network""][""nova""][""admin_username""] %> <% if node['openstack']['network']['nova']['admin_tenant_id'] -%> # The uuid of the admin nova tenant nova_admin_tenant_id = <%= node[""openstack""][""network""][""nova""][""admin_tenant_id""] %> <% end -%> # The name of the admin nova tenant. If the uuid of the admin nova tenant # is set, this is optional. nova_admin_tenant_name = <%= node[""openstack""][""network""][""nova""][""admin_tenant_name""] %> # Password for connection to nova in admin context. nova_admin_password = <%= @nova_admin_pass %> # Authorization URL for connection to nova in admin context. nova_admin_auth_url = <%= @identity_admin_endpoint.to_s %> ","# URL for connection to nova (Only supports one nova region currently). url = <%= @nova_endpoint %> # Username for connection to nova in admin context admin_username = <%= node[""openstack""][""network""][""nova""][""admin_username""] %> <% if node['openstack']['network']['nova']['admin_tenant_id'] -%> # The uuid of the admin nova tenant admin_tenant_id = <%= node[""openstack""][""network""][""nova""][""admin_tenant_id""] %> <% end -%> # The name of the admin nova tenant. If the uuid of the admin nova tenant # is set, this is optional. admin_tenant_name = <%= node[""openstack""][""network""][""nova""][""admin_tenant_name""] %> # Password for connection to nova in admin context. admin_password = <%= @nova_admin_pass %> # Authorization URL for connection to nova in admin context. admin_auth_url = <%= @identity_admin_endpoint.to_s %> ",34,30
openstack%2Ftempest~master~Id40310712ecda13d65cfd68bdaf4ea91dc7687fe,openstack/tempest,master,Id40310712ecda13d65cfd68bdaf4ea91dc7687fe,Fix sample conf file based on new oslo.log release,MERGED,2015-05-27 20:55:08.000000000,2015-05-27 22:12:45.000000000,2015-05-27 22:12:42.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5638}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-05-27 20:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/243058010f7ad96df34542a362cb19ef3b5b29eb', 'message': 'Fix sample conf file based on new oslo.log release\n\nChange-Id: Id40310712ecda13d65cfd68bdaf4ea91dc7687fe\n'}, {'number': 2, 'created': '2015-05-27 20:58:34.000000000', 'files': ['etc/tempest.conf.sample'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7068d88a65a374e82cf982bd7add4044f3567e40', 'message': 'Fix sample conf file based on new oslo.log release\n\nThis commit updates the tempest sample config file to\ninclude changes in the latest oslo.log release, 1.2.0.\nThis is needed to unblock the sample config generation\njob which is failing because the in-tree tempest sample\nconfig file differs from what is generated with a fresh\nvenv.\n\nChange-Id: Id40310712ecda13d65cfd68bdaf4ea91dc7687fe\n'}]",0,186162,7068d88a65a374e82cf982bd7add4044f3567e40,11,4,2,1192,,,0,"Fix sample conf file based on new oslo.log release

This commit updates the tempest sample config file to
include changes in the latest oslo.log release, 1.2.0.
This is needed to unblock the sample config generation
job which is failing because the in-tree tempest sample
config file differs from what is generated with a fresh
venv.

Change-Id: Id40310712ecda13d65cfd68bdaf4ea91dc7687fe
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/186162/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/tempest.conf.sample'],1,243058010f7ad96df34542a362cb19ef3b5b29eb,fix-config,"# I, and changed in J to honor RFC5424. (boolean value)# will be removed in M, along with this option. (boolean value) # This option is deprecated for removal. # Its value may be silently ignored in the future.#logging_exception_prefix = %(asctime)s.%(msecs)03d %(process)d ERROR %(name)s %(instance)s# Enables or disables fatal status of deprecations. (boolean value) #fatal_deprecations = false ","# I, and will change in J to honor RFC5424. (boolean value)# will be removed in L, along with this option. (boolean value)#logging_exception_prefix = %(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s",8,3
openstack%2Frequirements~master~Ib41b0c482edf39017f26e483cd3661ca5b540133,openstack/requirements,master,Ib41b0c482edf39017f26e483cd3661ca5b540133,Add glance_store to projects.txt,MERGED,2015-05-13 13:40:50.000000000,2015-05-27 22:12:38.000000000,2015-05-27 22:12:35.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 6159}, {'_account_id': 8119}, {'_account_id': 9656}]","[{'number': 1, 'created': '2015-05-13 13:40:50.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/64091866112ac6b3590de8b6d3c036cc03dcd6e0', 'message': ""Add glance_store to projects.txt\n\nglance requires glance_store but the requirements in glance_store on\nmaster and stable/kilo don't line up with what's in\nglobal-requirements.txt so add glance_store to projects.txt to sync\nthose up.\n\nCloses-Bug: #1454695\nRelated-Bug: #1454467\n\nChange-Id: Ib41b0c482edf39017f26e483cd3661ca5b540133\n""}]",0,182674,64091866112ac6b3590de8b6d3c036cc03dcd6e0,10,6,1,6873,,,0,"Add glance_store to projects.txt

glance requires glance_store but the requirements in glance_store on
master and stable/kilo don't line up with what's in
global-requirements.txt so add glance_store to projects.txt to sync
those up.

Closes-Bug: #1454695
Related-Bug: #1454467

Change-Id: Ib41b0c482edf39017f26e483cd3661ca5b540133
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/182674/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,64091866112ac6b3590de8b6d3c036cc03dcd6e0,bug/1454695,openstack/glance_store,,1,0
openstack%2Foslo.log~master~I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc,openstack/oslo.log,master,I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc,Do not fail if syslog is not available,MERGED,2015-05-27 15:24:10.000000000,2015-05-27 22:00:09.000000000,2015-05-27 22:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8543}]","[{'number': 1, 'created': '2015-05-27 15:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/249eddd9cce84c201746335e3cbd0954a41387d7', 'message': 'Do not fail if syslog is not available\n\nSome platforms (e.g. Windows) do not have the syslog module and\ntherefore fails when importing it. Handle that case\n\nChange-Id: I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc\nCloses-Bug: #1459187\n'}, {'number': 2, 'created': '2015-05-27 15:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/71e6c5f032b324722d7eae77604bff5f890f23e0', 'message': 'Do not fail if syslog is not available\n\nSome platforms (e.g. Windows) do not have the syslog module and\ntherefore fails when importing it. Handle that case\n\nChange-Id: I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc\nCloses-Bug: #1459187\n'}, {'number': 3, 'created': '2015-05-27 15:57:17.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/handlers.py', 'oslo_log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/1d64c9184214f3a7f2888d85acee93247278a0ec', 'message': 'Do not fail if syslog is not available\n\nSome platforms (e.g. Windows) do not have the syslog module and\ntherefore fails when importing it. Handle that case\n\nChange-Id: I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc\nCloses-Bug: #1459187\n'}]",2,186037,1d64c9184214f3a7f2888d85acee93247278a0ec,14,6,3,1669,,,0,"Do not fail if syslog is not available

Some platforms (e.g. Windows) do not have the syslog module and
therefore fails when importing it. Handle that case

Change-Id: I86ca0ff2bb3fbfbcaf4a04692ff7871654add5bc
Closes-Bug: #1459187
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/37/186037/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/tests/unit/test_log.py', 'oslo_log/handlers.py', 'oslo_log/log.py']",3,249eddd9cce84c201746335e3cbd0954a41387d7,bug/1459187,"try: import syslog except ImportError: syslog = None if syslog is None: raise RuntimeError(""syslog is not available on this platform"")",import syslog,40,26
openstack%2Fmonasca-agent~master~I07f3185268d7fdf8938c2fce1ffe8b6a9da4d18a,openstack/monasca-agent,master,I07f3185268d7fdf8938c2fce1ffe8b6a9da4d18a,mysql plugin fix,MERGED,2015-05-27 17:37:01.000000000,2015-05-27 21:38:13.000000000,2015-05-27 21:38:13.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 10068}, {'_account_id': 11094}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-05-27 17:37:01.000000000', 'files': ['monasca_setup/detection/plugins/mysql.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/1fb256267a773226dd0cdad64aaac9b8059958c9', 'message': 'mysql plugin fix\n\nChange-Id: I07f3185268d7fdf8938c2fce1ffe8b6a9da4d18a\n'}]",0,186097,1fb256267a773226dd0cdad64aaac9b8059958c9,9,5,1,16557,,,0,"mysql plugin fix

Change-Id: I07f3185268d7fdf8938c2fce1ffe8b6a9da4d18a
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/97/186097/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_setup/detection/plugins/mysql.py'],1,1fb256267a773226dd0cdad64aaac9b8059958c9,fixmysql," # If there are any spaces in confFile, remove them row = row.replace("" "", """")",,2,0
openstack%2Fpython-openstackclient~master~I1bd91490487b4c5eb6de7ea2aa09848b063071f1,openstack/python-openstackclient,master,I1bd91490487b4c5eb6de7ea2aa09848b063071f1,Create 1.3.0 release notes,MERGED,2015-05-27 19:30:18.000000000,2015-05-27 21:20:50.000000000,2015-05-27 21:20:48.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 19:30:18.000000000', 'files': ['doc/source/releases.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a15d8f681a19e8f247328c2748b06cf6a383c672', 'message': 'Create 1.3.0 release notes\n\nChange-Id: I1bd91490487b4c5eb6de7ea2aa09848b063071f1\n'}]",0,186138,a15d8f681a19e8f247328c2748b06cf6a383c672,7,3,1,970,,,0,"Create 1.3.0 release notes

Change-Id: I1bd91490487b4c5eb6de7ea2aa09848b063071f1
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/38/186138/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/releases.rst'],1,a15d8f681a19e8f247328c2748b06cf6a383c672,rel-1.3.0,"1.3.0 (27 May 2015) =================== * Need to specify domain with role list Bug `1421328 <https://bugs.launchpad.net/bugs/1421328>`_ * Add support for keystone service providers Bug `1435962 <https://bugs.launchpad.net/bugs/1435962>`_ * Can't update disk_format and container_format of image Bug `1446362 <https://bugs.launchpad.net/bugs/1446362>`_ * Openstack --os-image-api-version 2 image show <image_id> fails Bug `1450829 <https://bugs.launchpad.net/bugs/1450829>`_ * The insecure option is ignored for command line options and OCC Bug `1450855 <https://bugs.launchpad.net/bugs/1450855>`_ * Delete security group rule broken Bug `1450872 <https://bugs.launchpad.net/bugs/1450872>`_ * Quota set sends invalid messages Bug `1451640 <https://bugs.launchpad.net/bugs/1451640>`_ * Keystone Access Log logs ""python-keystoneclient"" as User-Agent even when request is made by openstack client Bug `1453995 <https://bugs.launchpad.net/bugs/1453995>`_ * Client error while rescuing an instance Bug `1457983 <https://bugs.launchpad.net/bugs/1457983>`_ ",,31,0
openstack%2Fsolum~master~I7e6bc61d8e004e22bb6df0400e78cb21b98b868f,openstack/solum,master,I7e6bc61d8e004e22bb6df0400e78cb21b98b868f,Separate the storage of image loc and tag,MERGED,2015-04-02 23:08:29.000000000,2015-05-27 21:20:05.000000000,2015-05-27 21:20:05.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-04-02 23:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7c39a08c7dfac87ac088aeb935715bf938eddda2', 'message': '(WIP) Separate the storage of image loc and tag\n\ndeployer changes are not yet\n\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 2, 'created': '2015-04-06 04:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2ad4215b8aff86fb12bcfe78b56c889b5b0885e7', 'message': '(WIP) Separate the storage of image loc and tag\n\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 3, 'created': '2015-05-01 22:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/94dac7fac9f60291acfe27d7fd97841a592140a9', 'message': 'Separate the storage of image loc and tag\n\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 4, 'created': '2015-05-03 04:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f53f91758cffc9607f9d9d20ae2aa3387ae173e9', 'message': 'Separate the storage of image loc and tag\n\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 5, 'created': '2015-05-05 22:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/09659354427b70a0fb9d35f7c3a7502b2093b9b9', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 6, 'created': '2015-05-20 17:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7280088ca3f36b94046db777714ce91c213c98f5', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 7, 'created': '2015-05-21 16:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2f71f647cc71878d42802d5745015cd07d96386f', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 8, 'created': '2015-05-26 21:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e97baf74c8113c4740c231f9626e21150104d4bc', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nPartially-fix: #1458979\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 9, 'created': '2015-05-26 21:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8885b1ac6b0f26a790875f7dd1dd00594070ab96', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nPartially-fixes-bug: #1458979\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}, {'number': 10, 'created': '2015-05-26 22:06:27.000000000', 'files': ['solum/deployer/api.py', 'solum/tests/deployer/handlers/test_heat.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/452f34e8ea3_add_docker_image_name_to_image_table.py', 'contrib/lp-cedarish/docker/build-lp', 'solum/tests/fakes.py', 'solum/deployer/handlers/heat.py', 'solum/conductor/api.py', 'solum/worker/handlers/shell.py', 'tools/migration/migrate_rev_452f34e8ea3.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/conductor/handlers/default.py', 'solum/objects/sqlalchemy/image.py', 'contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/36aac12a854624161751b37827508afec3ff71c4', 'message': 'Separate the storage of image loc and tag\n\nCloses-bug: #1452047\nPartially-fixes-bug: #1458979\nChange-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f\n'}]",22,170313,36aac12a854624161751b37827508afec3ff71c4,46,6,10,6662,,,0,"Separate the storage of image loc and tag

Closes-bug: #1452047
Partially-fixes-bug: #1458979
Change-Id: I7e6bc61d8e004e22bb6df0400e78cb21b98b868f
",git fetch https://review.opendev.org/openstack/solum refs/changes/13/170313/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/conductor/api.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/452f34e8ea3_add_docker_repo_name_to_image_table.py', 'solum/worker/handlers/shell.py', 'contrib/lp-cedarish/docker/build-lp', 'solum/conductor/handlers/default.py', 'contrib/lp-cedarish/docker/build-app']",6,7c39a08c7dfac87ac088aeb935715bf938eddda2,state_status, image_id=$(app_glance_id $STORAGE_OBJ_NAME) image_id=${APP_NAME} image_id=${TEMP_URL}TLOG docker_repo_name=$DU_IMG_TAGecho docker_repo_name=$DU_IMG_TAG," image_id=""$(app_glance_id $STORAGE_OBJ_NAME)DOCKER_IMAGE_TAG=${DU_IMG_TAG}"" image_id=""${APP_NAME}DOCKER_IMAGE_TAG=${DU_IMG_TAG}"" image_id=""${TEMP_URL}DOCKER_IMAGE_TAG=${DU_IMG_TAG}""",92,37
openstack%2Fzaqar~master~I820ac017ee44b806dead9bc484664228d4022f81,openstack/zaqar,master,I820ac017ee44b806dead9bc484664228d4022f81,Enable pooling in devstack,MERGED,2015-04-28 09:10:20.000000000,2015-05-27 21:12:03.000000000,2015-05-27 21:12:01.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 7385}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-04-28 09:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/59f64250be97bb17e88bf4a3b5e7d9863616e5cc', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 2, 'created': '2015-04-30 07:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2ca745dc348132bdd26204dbc80231b31dce7d26', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 3, 'created': '2015-05-04 16:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/031387aa74533c1006e0581e455dcee0d9be4010', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 4, 'created': '2015-05-04 17:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/305074c6af592b2ef9ce73fea0f38f544a26b2f3', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 5, 'created': '2015-05-05 21:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/287d455e8744123136f0a952c4f8e64cb0df1cd4', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 6, 'created': '2015-05-06 06:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fc1acd7363d9bbb9160581aabf3672bcc76d5f37', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 7, 'created': '2015-05-06 06:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cd9a267e487223069b0aab153b7b9ddf6b2cdb0b', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 8, 'created': '2015-05-07 07:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c3ef93a948d768378bdf5711d71cc897ae2c7cbe', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 9, 'created': '2015-05-07 15:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8494c01748a6b4f1469fd8eb49191b59da18cd79', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 10, 'created': '2015-05-07 16:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8a0f820b63a22c0547a9b4b76b4a153c8d9ec7cc', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 11, 'created': '2015-05-07 17:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/785f035a4f152e997b224f06e878615018f41779', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 12, 'created': '2015-05-21 23:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a3559aada586c8347def15c4cf9599ae373ad89c', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}, {'number': 13, 'created': '2015-05-27 12:25:42.000000000', 'files': ['devstack/plugin.sh', 'zaqar/storage/pooling.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9352bb600ff61f09d348fcb4bebe6b46c179d2e6', 'message': 'Enable pooling in devstack\n\nThis patch enables pooling by default. Pooling has become a central\npiece for Zaqar, therefore, we ought to test on it always.\n\nThe patch also changes the behavior for pools in Zaqar. That is,\nwhenever a default pool is not found and a `message_store` section has\nbeen configured, such section will be used as the default store. No\npools will be created out of this configurations so that users can still\nconfigure their default store using zaqarclient.\n\nChange-Id: I820ac017ee44b806dead9bc484664228d4022f81\nDepends-On: If5c91ebe136017cea2eeecf62a580d050e49617d\n'}]",1,178100,9352bb600ff61f09d348fcb4bebe6b46c179d2e6,37,6,13,6159,,,0,"Enable pooling in devstack

This patch enables pooling by default. Pooling has become a central
piece for Zaqar, therefore, we ought to test on it always.

The patch also changes the behavior for pools in Zaqar. That is,
whenever a default pool is not found and a `message_store` section has
been configured, such section will be used as the default store. No
pools will be created out of this configurations so that users can still
configure their default store using zaqarclient.

Change-Id: I820ac017ee44b806dead9bc484664228d4022f81
Depends-On: If5c91ebe136017cea2eeecf62a580d050e49617d
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/00/178100/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,59f64250be97bb17e88bf4a3b5e7d9863616e5cc,devstack, # Enable pooling by default for now iniset $ZAQAR_CONF DEFAULT pooling True iniset $ZAQAR_CONF DEFAULT admin_mode True iniset $ZAQAR_CONF 'drivers:management_store:mongodb' uri mongodb://localhost:27017/zaqar_mgmt iniset $ZAQAR_CONF 'drivers:management_store:mongodb' database zaqar_mgmt iniset $ZAQAR_CONF 'drivers:management_store:redis' uri redis://localhost:6379 iniset $ZAQAR_CONF 'drivers:management_store:redis' database zaqar_mgmt,,8,0
openstack%2Fos-client-config~master~Iaad73898daf6b00839be5a134558d53b95f0dd65,openstack/os-client-config,master,Iaad73898daf6b00839be5a134558d53b95f0dd65,Add tests for cloud config comparison,MERGED,2015-05-27 20:10:21.000000000,2015-05-27 21:11:37.000000000,2015-05-27 21:11:36.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 20:10:21.000000000', 'files': ['os_client_config/tests/test_cloud_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/2580c0aa0112d94606879c8f8864e34602ddaab8', 'message': 'Add tests for cloud config comparison\n\nUnit tests are good.\n\nChange-Id: Iaad73898daf6b00839be5a134558d53b95f0dd65\n'}]",0,186148,2580c0aa0112d94606879c8f8864e34602ddaab8,8,3,1,3099,,,0,"Add tests for cloud config comparison

Unit tests are good.

Change-Id: Iaad73898daf6b00839be5a134558d53b95f0dd65
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/48/186148/1 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/tests/test_cloud_config.py'],1,2580c0aa0112d94606879c8f8864e34602ddaab8,186145," def test_equality(self): cc1 = cloud_config.CloudConfig(""test1"", ""region-al"", fake_config_dict) cc2 = cloud_config.CloudConfig(""test1"", ""region-al"", fake_config_dict) self.assertEqual(cc1, cc2) def test_inequality(self): cc1 = cloud_config.CloudConfig(""test1"", ""region-al"", fake_config_dict) cc2 = cloud_config.CloudConfig(""test2"", ""region-al"", fake_config_dict) self.assertNotEqual(cc1, cc2) cc2 = cloud_config.CloudConfig(""test1"", ""region-xx"", fake_config_dict) self.assertNotEqual(cc1, cc2) cc2 = cloud_config.CloudConfig(""test1"", ""region-al"", {}) self.assertNotEqual(cc1, cc2)",,17,0
openstack%2Fos-client-config~master~Ifcd39ee188d88d9490f67b5644a941d4d1c6ec38,openstack/os-client-config,master,Ifcd39ee188d88d9490f67b5644a941d4d1c6ec38,Add inequality method,MERGED,2015-05-27 19:53:06.000000000,2015-05-27 21:11:31.000000000,2015-05-27 21:11:30.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 19:53:06.000000000', 'files': ['os_client_config/cloud_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/9b98ee0e098cc33eb976a9d5e917d10a0ad7968c', 'message': 'Add inequality method\n\nOne method does not imply the other.\n\nChange-Id: Ifcd39ee188d88d9490f67b5644a941d4d1c6ec38\n'}]",0,186145,9b98ee0e098cc33eb976a9d5e917d10a0ad7968c,8,4,1,2,,,0,"Add inequality method

One method does not imply the other.

Change-Id: Ifcd39ee188d88d9490f67b5644a941d4d1c6ec38
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/45/186145/1 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/cloud_config.py'],1,9b98ee0e098cc33eb976a9d5e917d10a0ad7968c,," def __ne__(self, other): return not self == other",,3,0
openstack%2Fmagnum~master~Idc97bbb2a8ac01d6933da5288854f034befb5748,openstack/magnum,master,Idc97bbb2a8ac01d6933da5288854f034befb5748,Improve dev-quickstart documentation,MERGED,2015-05-27 12:55:42.000000000,2015-05-27 21:09:58.000000000,2015-05-27 21:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 6698}, {'_account_id': 11650}, {'_account_id': 14352}, {'_account_id': 16051}]","[{'number': 1, 'created': '2015-05-27 12:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f253e485d6c6ce9d56d9b19fc41a872c990ef49a', 'message': 'Improve dev-quickstart documentation\n\nAdded clarifying information regarding the default installed image\nand provided a validation check and example response.\nImproved SSH key generation step to enable automated usage.\n\nChange-Id: Idc97bbb2a8ac01d6933da5288854f034befb5748\n'}, {'number': 2, 'created': '2015-05-27 13:38:07.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/80db1d846ba8712938923138903cfea50f9fc436', 'message': 'Improve dev-quickstart documentation\n\nAdded clarifying information regarding the default installed image\nand provided a validation check and example response.\nImproved SSH key generation step to enable automated usage.\n\nChange-Id: Idc97bbb2a8ac01d6933da5288854f034befb5748\n'}]",3,185964,80db1d846ba8712938923138903cfea50f9fc436,15,7,2,16051,,,0,"Improve dev-quickstart documentation

Added clarifying information regarding the default installed image
and provided a validation check and example response.
Improved SSH key generation step to enable automated usage.

Change-Id: Idc97bbb2a8ac01d6933da5288854f034befb5748
",git fetch https://review.opendev.org/openstack/magnum refs/changes/64/185964/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,f253e485d6c6ce9d56d9b19fc41a872c990ef49a,improve-dev-quickstart-docs,"Prepare your session to be able to use the various openstack clients including magnum, neutron and glance. Create a new shell, and source the devstack openrc script::The fedora-21-atomic-3 image will automatically be added to glance. You can add additional images to use manually through glance. To verify the image was created when installing DevStack:: glance image-list +--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+ | ID | Name | Disk Format | Container Format | Size | Status | +--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+ | 7f5b6a15-f2fd-4552-aec5-952c6f6d4bc7 | cirros-0.3.4-x86_64-uec | ami | ami | 25165824 | active | | bd3c0f92-669a-4390-a97d-b3e0a2043362 | cirros-0.3.4-x86_64-uec-kernel | aki | aki | 4979632 | active | | 843ce0f7-ae51-4db3-8e74-bcb860d06c55 | cirros-0.3.4-x86_64-uec-ramdisk | ari | ari | 3740163 | active | | 02c312e3-2d30-43fd-ab2d-1d25622c0eaa | fedora-21-atomic-3 | qcow2 | bare | 770179072 | active | +--------------------------------------+---------------------------------+-------------+------------------+-----------+--------+ You need to define and register a keypair for use when creating baymodel's:: test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N """" -f ~/.ssh/id_rsaBays will have an initial status of CREATE_IN_PROGRESS. Magnum reports CREATE_COMPLETE when it is done creating the bay. Do not create","The fedora-21-atomic-3 image will automatically be added to glance. You can still add your own images to use manually through glance. Prepare to use the magnum client. Create a new shell, and source the devstack openrc script:: test -f ~/.ssh/id_rsa.pub || ssh-keygenMagnum reports CREATE_COMPLETE when it is done creating the bay. Do not create",22,7
openstack%2Fpuppet-neutron~master~I233fa640e601f180c57c991e9e0a4f3bb8867709,openstack/puppet-neutron,master,I233fa640e601f180c57c991e9e0a4f3bb8867709,Beaker: install APT repo with openstack_extras,MERGED,2015-05-15 16:58:47.000000000,2015-05-27 21:05:59.000000000,2015-05-27 21:05:58.000000000,"[{'_account_id': 3}, {'_account_id': 5241}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-05-15 16:58:47.000000000', 'files': ['spec/acceptance/basic_neutron_spec.rb', 'spec/spec_helper_acceptance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3f2ec9002a0d66859794d50d5af7a5c49ae33581', 'message': 'Beaker: install APT repo with openstack_extras\n\nUse openstack_extras module to manage Ubuntu Cloud Archive repository.\n\nChange-Id: I233fa640e601f180c57c991e9e0a4f3bb8867709\n'}]",0,183609,3f2ec9002a0d66859794d50d5af7a5c49ae33581,10,4,1,3153,,,0,"Beaker: install APT repo with openstack_extras

Use openstack_extras module to manage Ubuntu Cloud Archive repository.

Change-Id: I233fa640e601f180c57c991e9e0a4f3bb8867709
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/09/183609/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/basic_neutron_spec.rb', 'spec/spec_helper_acceptance.rb']",2,3f2ec9002a0d66859794d50d5af7a5c49ae33581,bug/1444736, shell('git clone https://git.openstack.org/stackforge/puppet-openstack_extras /etc/puppet/modules/openstack_extras'),,4,10
openstack%2Foslosphinx~master~Ib95bb403d51ed3c7b682dd695713f43432cf8a4e,openstack/oslosphinx,master,Ib95bb403d51ed3c7b682dd695713f43432cf8a4e,Drop incubating theme option,MERGED,2015-05-27 19:19:36.000000000,2015-05-27 21:05:07.000000000,2015-05-27 21:05:05.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-27 19:19:36.000000000', 'files': ['oslosphinx/theme/openstack/layout.html'], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/46832a8942c5f56f2cc8d1689304c57ab5c38c7e', 'message': 'Drop incubating theme option\n\nOpenStack has dropped the incubation concept, so drop this label as a\ndocs option.\n\nChange-Id: Ib95bb403d51ed3c7b682dd695713f43432cf8a4e\n'}]",0,186134,46832a8942c5f56f2cc8d1689304c57ab5c38c7e,7,3,1,1849,,,0,"Drop incubating theme option

OpenStack has dropped the incubation concept, so drop this label as a
docs option.

Change-Id: Ib95bb403d51ed3c7b682dd695713f43432cf8a4e
",git fetch https://review.opendev.org/openstack/oslosphinx refs/changes/34/186134/1 && git format-patch -1 --stdout FETCH_HEAD,['oslosphinx/theme/openstack/layout.html'],1,46832a8942c5f56f2cc8d1689304c57ab5c38c7e,incubated,," {%- if theme_incubating|tobool %} <h3 class=""highlighted""><a href=""https://wiki.openstack.org/wiki/Governance/NewProjects"">{{ _('Incubated Project') }}</a></h3> {%- endif %}",0,3
openstack%2Fswift~master~I78f21e5794e8ba7a095f03d279247516a241f555,openstack/swift,master,I78f21e5794e8ba7a095f03d279247516a241f555,drop Python 2.6 testing support,MERGED,2015-05-27 19:29:07.000000000,2015-05-27 20:58:59.000000000,2015-05-27 20:58:58.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 12279}, {'_account_id': 14967}]","[{'number': 1, 'created': '2015-05-27 19:29:07.000000000', 'files': ['doc/source/getting_started.rst', 'doc/source/development_guidelines.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/5374ba3a80a5b895542196502eac4d9300ba53d2', 'message': 'drop Python 2.6 testing support\n\nChange-Id: I78f21e5794e8ba7a095f03d279247516a241f555\n'}]",0,186137,5374ba3a80a5b895542196502eac4d9300ba53d2,10,6,1,330,,,0,"drop Python 2.6 testing support

Change-Id: I78f21e5794e8ba7a095f03d279247516a241f555
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/186137/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/getting_started.rst', 'doc/source/development_guidelines.rst', 'tox.ini']",3,5374ba3a80a5b895542196502eac4d9300ba53d2,nopy26,"envlist = py27,pep8","envlist = py26,py27,pep8",3,4
openstack%2Ftripleo-heat-templates~master~Ie0aa46b4a3c00d3826866796b4ec3b14f71f987c,openstack/tripleo-heat-templates,master,Ie0aa46b4a3c00d3826866796b4ec3b14f71f987c,"Map Horizon, Redis, Rabbit, memcached to isolated nets",MERGED,2015-05-27 08:50:52.000000000,2015-05-27 20:51:21.000000000,2015-05-27 20:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-27 08:50:52.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2dfa94657e2970a373d63e082fb439558e97e6f5', 'message': ""Map Horizon, Redis, Rabbit, memcached to isolated nets\n\nThis change adds parameters to select the networks for Horizon,\nRedis, Rabbit MQ, and memcached services. Horizon is often used for\nadministration from outside the cloud, so if the external network\nexists, Horizon will bind to that IP, otherwise it will default to\nthe Undercloud 'ctlplane' network. Redis, Rabbit MQ, and memcached\nwill bind to IPs on the internal_api network if it exists, else\nthey will default to the 'ctlplane' network as well. Any of these\nnetwork assignments can be overridden with an environment file.\n\nChange-Id: Ie0aa46b4a3c00d3826866796b4ec3b14f71f987c\n""}]",0,185888,2dfa94657e2970a373d63e082fb439558e97e6f5,13,4,1,12398,,,0,"Map Horizon, Redis, Rabbit, memcached to isolated nets

This change adds parameters to select the networks for Horizon,
Redis, Rabbit MQ, and memcached services. Horizon is often used for
administration from outside the cloud, so if the external network
exists, Horizon will bind to that IP, otherwise it will default to
the Undercloud 'ctlplane' network. Redis, Rabbit MQ, and memcached
will bind to IPs on the internal_api network if it exists, else
they will default to the 'ctlplane' network as well. Any of these
network assignments can be overridden with an environment file.

Change-Id: Ie0aa46b4a3c00d3826866796b4ec3b14f71f987c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/185888/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,2dfa94657e2970a373d63e082fb439558e97e6f5,service_map_misc," horizon::bind_address: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HorizonNetwork]}]} rabbitmq::node_ip_address: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, RabbitMqNetwork]}]} redis::bind: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, RedisNetwork]}]} memcached::listen_ip: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, MemcachedNetwork]}]}", horizon::bind_address: {get_input: controller_host} rabbitmq::node_ip_address: {get_input: controller_host} redis::bind: {get_input: controller_host} memcached::listen_ip: {get_input: controller_host},8,4
openstack%2Frequirements~stable%2Fjuno~I4e720c734f51b9e8375108b00d3f3a91ede3c77e,openstack/requirements,stable/juno,I4e720c734f51b9e8375108b00d3f3a91ede3c77e,Raise cap on tooz to <0.13,MERGED,2015-05-27 16:16:37.000000000,2015-05-27 20:51:20.000000000,2015-05-27 20:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-27 16:16:37.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b5dd58baa0d0b151c4d0a9702593416c16aee98d', 'message': ""Raise cap on tooz to <0.13\n\ntooz does not have a stable/juno branch yet and tooz 0.12 has uncapped\nrequirements on zake and kazoo which is breaking with zake 0.2.2 which\nblocks kazoo 2.1 - which is what gets pulled in.\n\nSo we're going to create a stable/juno branch for tooz from the 0.12\ntag, sync it's requirements with g-r and then release tooz 0.12.1 so we\nneed to raise the cap here to allow for 0.12.1.\n\nOnce this is in, it'll sync to ceilometer on stable/juno and we'll need\nto merge that also to fix stable/juno and stable/kilo changes.\n\nPartial-Bug: #1459322\n\nChange-Id: I4e720c734f51b9e8375108b00d3f3a91ede3c77e\n""}]",0,186065,b5dd58baa0d0b151c4d0a9702593416c16aee98d,12,6,1,6873,,,0,"Raise cap on tooz to <0.13

tooz does not have a stable/juno branch yet and tooz 0.12 has uncapped
requirements on zake and kazoo which is breaking with zake 0.2.2 which
blocks kazoo 2.1 - which is what gets pulled in.

So we're going to create a stable/juno branch for tooz from the 0.12
tag, sync it's requirements with g-r and then release tooz 0.12.1 so we
need to raise the cap here to allow for 0.12.1.

Once this is in, it'll sync to ceilometer on stable/juno and we'll need
to merge that also to fix stable/juno and stable/kilo changes.

Partial-Bug: #1459322

Change-Id: I4e720c734f51b9e8375108b00d3f3a91ede3c77e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/186065/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,b5dd58baa0d0b151c4d0a9702593416c16aee98d,bug/1459322,"tooz>=0.3,<0.13 # Apache-2.0","tooz>=0.3,<=0.12 # Apache-2.0",1,1
openstack%2Ftripleo-heat-templates~master~I1d5e966a16416c52935c22efe2d4783cd2192c32,openstack/tripleo-heat-templates,master,I1d5e966a16416c52935c22efe2d4783cd2192c32,Map Swift services to isolated networks,MERGED,2015-05-27 08:36:05.000000000,2015-05-27 20:51:03.000000000,2015-05-27 20:01:53.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-27 08:36:05.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4e891510e0c42d1cdda430d53ab34b72b903a208', 'message': ""Map Swift services to isolated networks\n\nThis change adds paramters to specify which networks the Swift API\nservices will use. If the storage network exists, it will be used\nfor the Swift API, otherwise the Undercloud 'ctlplane' network will\nbe used. If the storage_mgmt network exists, it will be used for\nthe back-end storage services, otherwise the 'ctlplane' will be\nused by default.\n\nChange-Id: I1d5e966a16416c52935c22efe2d4783cd2192c32\n""}]",0,185878,4e891510e0c42d1cdda430d53ab34b72b903a208,13,4,1,12398,,,0,"Map Swift services to isolated networks

This change adds paramters to specify which networks the Swift API
services will use. If the storage network exists, it will be used
for the Swift API, otherwise the Undercloud 'ctlplane' network will
be used. If the storage_mgmt network exists, it will be used for
the back-end storage services, otherwise the 'ctlplane' will be
used by default.

Change-Id: I1d5e966a16416c52935c22efe2d4783cd2192c32
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/185878/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,4e891510e0c42d1cdda430d53ab34b72b903a208,service_map_swift," swift::proxy::proxy_local_net_ip: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, SwiftProxyNetwork]}]} swift::storage::all::storage_local_net_ip: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, SwiftMgmtNetwork]}]}", swift::proxy::proxy_local_net_ip: {get_input: controller_host} swift::storage::all::storage_local_net_ip: {get_input: controller_host},4,2
openstack%2Ffuel-library~master~I2eb1f28dd9db520a1a40b82aa8d87489ff366920,openstack/fuel-library,master,I2eb1f28dd9db520a1a40b82aa8d87489ff366920,Add glance::api dependancy to glance cache crons,MERGED,2015-05-27 18:24:27.000000000,2015-05-27 20:38:39.000000000,2015-05-27 20:38:05.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14168}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-27 18:24:27.000000000', 'files': ['deployment/puppet/openstack/manifests/glance.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ca9dc7589b9a1f7db945df0fb7c6bd21b60f0280', 'message': 'Add glance::api dependancy to glance cache crons\n\nThe glance cleanup crons cannot be processed before the glance api\npackage gets installed because the user may not exist.  This change\nadds an explicit dependency on the glance::api class for the\nglance::cache::pruner and cleaner classes.  With out this, puppet\nwould sometimes attempt to create these crons for the glance user\nwhich had not been created yet and this would result in an error.\n\nChange-Id: I2eb1f28dd9db520a1a40b82aa8d87489ff366920\nCloses-Bug: 1459227\n'}]",0,186118,ca9dc7589b9a1f7db945df0fb7c6bd21b60f0280,25,5,1,14985,,,0,"Add glance::api dependancy to glance cache crons

The glance cleanup crons cannot be processed before the glance api
package gets installed because the user may not exist.  This change
adds an explicit dependency on the glance::api class for the
glance::cache::pruner and cleaner classes.  With out this, puppet
would sometimes attempt to create these crons for the glance user
which had not been created yet and this would result in an error.

Change-Id: I2eb1f28dd9db520a1a40b82aa8d87489ff366920
Closes-Bug: 1459227
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/18/186118/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/glance.pp'],1,ca9dc7589b9a1f7db945df0fb7c6bd21b60f0280,bug/1459227, Class['glance::api'] -> class { 'glance::cache::pruner': } ->, class { 'glance::cache::pruner': },2,1
openstack%2Fpython-openstackclient~master~Ie30802d720a247748c45099c38450cc6c76bbc2a,openstack/python-openstackclient,master,Ie30802d720a247748c45099c38450cc6c76bbc2a,Add support for v2 image set command,MERGED,2015-05-13 00:02:14.000000000,2015-05-27 20:38:02.000000000,2015-05-27 20:38:00.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 13664}]","[{'number': 1, 'created': '2015-05-13 00:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e247210b857ce8a02545cb8a83c7094bf25a4884', 'message': 'WIP: Add support for v2 image create/update commands\n\nChange-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a\n'}, {'number': 2, 'created': '2015-05-13 00:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c0944f06ac95cb9bd6ccba470636df7ef53464cc', 'message': 'WIP: Add support for v2 image create/update commands\n\nCloses-Bug: #1405562\nChange-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a\n'}, {'number': 3, 'created': '2015-05-14 22:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/79c26cafbfad3a3ce4096e0b6ec3f6cf49533496', 'message': 'Add support for v2 image update commands\n\nPartial-Bug: #1405562\nChange-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a\n'}, {'number': 4, 'created': '2015-05-27 06:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/495cf3f9d4076a705f6d416fb950b36c8dc71221', 'message': 'Add support for v2 image set command\n\nPartial-Bug: #1405562\nChange-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a\n'}, {'number': 5, 'created': '2015-05-27 18:53:09.000000000', 'files': ['openstackclient/tests/image/v2/test_image.py', 'setup.cfg', 'openstackclient/image/v2/image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ce05822a3a328bffa8ec62ec72da946c0d187c2c', 'message': 'Add support for v2 image set command\n\nPartial-Bug: #1405562\nChange-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a\n'}]",24,182504,ce05822a3a328bffa8ec62ec72da946c0d187c2c,17,5,5,13664,,,0,"Add support for v2 image set command

Partial-Bug: #1405562
Change-Id: Ie30802d720a247748c45099c38450cc6c76bbc2a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/04/182504/4 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'openstackclient/image/v2/image.py']",2,e247210b857ce8a02545cb8a83c7094bf25a4884,1405562_set,"class CreateImage(show.ShowOne): """"""Create/upload an image"""""" log = logging.getLogger(__name__ + "".CreateImage"") def get_parser(self, prog_name): parser = super(CreateImage, self).get_parser(prog_name) parser.add_argument( ""name"", metavar=""<image-name>"", help=""New Image Name"" ) parser.add_argument( ""--id"", metavar=""<id>"", help=""Image ID to reserve"" ) parser.add_argument( ""--architecture"", metavar=""<architecture>"", help=""Operating System Architecture"" ) parser.add_argument( ""--instance-uuid"", metavar=""<instance-uuid>"", help=""ID of instance used to create this image"" ) parser.add_argument( ""--min-disk"", metavar=""<min-disk>"", help=""Amount of disk space (in GB) required to boot image"" ) parser.add_argument( ""--visibility"", metavar=""<visibility>"", help=""Scope of image accessibility. Valid values: public, private"" ) help_msg = (""ID of image in Glance taht should be used as the kernel"" "" when booting an AMI-style image"") parser.add_argument( ""--kernel-id"", metavar=""<kernel-id>"", help=help_msg ) #TODO parser.add_argument( ""--tags"", metavar=""<tags>"", help=""List of strings related to the image"" ) parser.add_argument( ""--os-version"", metavar=""<os-version>"", help=""Operating system version as specified by the distributor"" ) parser.add_argument( ""--disk-format"", metavar=""<disk-format>"", help=""Format of the disk"" ) parser.add_argument( ""--os-distro"", metavar=""<os-distro>"", help=""Common name of operating system distribution"" ) parser.add_argument( ""--owner"", metavar=""<owner>"", help=""Owner of the image"" ) parser.add_argument( ""--locations"", metavar=""<locations>"", help=""Set of URLs to access the image file kept in external store"" ) msg = (""ID of image stored in Glance that should be used as the "" ""ramdisk when booting an AMI-style image"") parser.add_argument( ""--ramdisk-id"", metavar=""<ramdisk-id>"", help=msg ) parser.add_argument( ""--min-ram"", metavar=""<min-ram>"", help=""Amount of RAM (in MB) required to boot image"" ) parser.add_argument( ""--container-format"", metavar=""<container-format>"", help=""Format of the container"" ) parser.add_argument( ""--property"", dest=""properties"", metavar=""<key=value>"", action=parseractions.KeyValueAction, help=""Arbitrary property to associate with image. May be used "" ""multiple times"" ) parser.add_argument( ""--file"", metavar=""<file>"", help=""Local file that contains disk image to be uploaded during "" ""creation. Alternatively, images can be passed to the client "" ""via stdin"" ) parser.add_argument( ""--progress"", help=""Show upload progress bar"", action='store_true', default=False ) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"", parsed_args) image_client = self.app.client_manager.image print(""XXX: %s"" % parsed_args) ",,122,0
openstack%2Fzaqar~master~I1d8280cef8e260576550cab85574b663266ae314,openstack/zaqar,master,I1d8280cef8e260576550cab85574b663266ae314,Drop incubating theme from docs,MERGED,2015-05-27 19:17:40.000000000,2015-05-27 20:19:28.000000000,2015-05-27 20:19:27.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-05-27 19:17:40.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8bcb20de88a4cc7783b588b78a44ef7bcd710a50', 'message': 'Drop incubating theme from docs\n\nOpenStack has dropped the incubation notion, so labeling this as an\nincubated project in the docs is confusing.\n\nChange-Id: I1d8280cef8e260576550cab85574b663266ae314\n'}]",0,186133,8bcb20de88a4cc7783b588b78a44ef7bcd710a50,7,3,1,1849,,,0,"Drop incubating theme from docs

OpenStack has dropped the incubation notion, so labeling this as an
incubated project in the docs is confusing.

Change-Id: I1d8280cef8e260576550cab85574b663266ae314
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/33/186133/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,8bcb20de88a4cc7783b588b78a44ef7bcd710a50,incubating,html_theme_options = {},html_theme_options = {'incubating': True},1,1
openstack%2Fopenstacksdk~master~I16bfea56b14d37d99aac15efe7e162d03dfc3b23,openstack/openstacksdk,master,I16bfea56b14d37d99aac15efe7e162d03dfc3b23,Metric resource docs framework,MERGED,2015-05-23 02:24:58.000000000,2015-05-27 20:15:21.000000000,2015-05-27 20:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-23 02:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2e6a827140d2223484c2c2c27626a0cb9ec85dd5', 'message': 'Metric resource docs framework\n\nChange-Id: I16bfea56b14d37d99aac15efe7e162d03dfc3b23\n'}, {'number': 2, 'created': '2015-05-27 20:05:08.000000000', 'files': ['doc/source/users/resources/metric/index.rst', 'doc/source/users/resources/metric/v1/capabilities.rst', 'doc/source/users/resources/metric/v1/metric.rst', 'doc/source/users/resources/metric/v1/archive_policy.rst', 'doc/source/users/index.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/94b90e50ca76df34717b24a8a48b4316842691a8', 'message': 'Metric resource docs framework\n\nChange-Id: I16bfea56b14d37d99aac15efe7e162d03dfc3b23\n'}]",0,185208,94b90e50ca76df34717b24a8a48b4316842691a8,9,2,2,8736,,,0,"Metric resource docs framework

Change-Id: I16bfea56b14d37d99aac15efe7e162d03dfc3b23
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/08/185208/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/resources/metric/index.rst', 'doc/source/users/resources/metric/v1/capabilities.rst', 'doc/source/users/resources/metric/v1/metric.rst', 'doc/source/users/resources/metric/v1/archive_policy.rst', 'doc/source/users/index.rst']",5,2e6a827140d2223484c2c2c27626a0cb9ec85dd5,docsmetric, Metric <resources/metric/index>,,46,0
openstack%2Fopenstacksdk~master~Ieff2b5119bca079c8ecf4aae14f9ab7e773501d8,openstack/openstacksdk,master,Ieff2b5119bca079c8ecf4aae14f9ab7e773501d8,Keystore resource docs framework,MERGED,2015-05-23 02:24:14.000000000,2015-05-27 20:14:23.000000000,2015-05-27 20:14:21.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-23 02:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/aa284ea88f8640d63013db22af841628095c21c0', 'message': 'Keystore resource docs framework\n\nChange-Id: Ieff2b5119bca079c8ecf4aae14f9ab7e773501d8\n'}, {'number': 2, 'created': '2015-05-27 20:03:53.000000000', 'files': ['doc/source/users/resources/keystore/v1/secret.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/keystore/index.rst', 'doc/source/users/resources/keystore/v1/container.rst', 'doc/source/users/resources/keystore/v1/order.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e8782465bba8806344817a1a62a37026b2a5cb0b', 'message': 'Keystore resource docs framework\n\nChange-Id: Ieff2b5119bca079c8ecf4aae14f9ab7e773501d8\n'}]",0,185207,e8782465bba8806344817a1a62a37026b2a5cb0b,9,2,2,8736,,,0,"Keystore resource docs framework

Change-Id: Ieff2b5119bca079c8ecf4aae14f9ab7e773501d8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/07/185207/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/resources/keystore/v1/secret.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/keystore/index.rst', 'doc/source/users/resources/keystore/v1/container.rst', 'doc/source/users/resources/keystore/v1/order.rst']",5,aa284ea88f8640d63013db22af841628095c21c0,docskeystore,openstack.keystore.v1.order =========================== .. automodule:: openstack.keystore.v1.order The Order Class --------------- The ``Order`` class inherits from :class:`~openstack.resource.Resource`. .. autoclass:: openstack.keystore.v1.order.Order :members: ,,46,0
openstack%2Fopenstacksdk~master~I476605070fa94b410f47fd6ff66a645217332e60,openstack/openstacksdk,master,I476605070fa94b410f47fd6ff66a645217332e60,Image resource docs framework,MERGED,2015-05-23 02:23:50.000000000,2015-05-27 20:11:24.000000000,2015-05-27 20:11:23.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-23 02:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/145f2b3fc780dfc9f2822511d1420485e3d45f08', 'message': 'Image resource docs framework\n\nChange-Id: I476605070fa94b410f47fd6ff66a645217332e60\n'}, {'number': 2, 'created': '2015-05-27 20:02:38.000000000', 'files': ['doc/source/users/resources/image/v2/member.rst', 'doc/source/users/resources/image/v2/tag.rst', 'doc/source/users/resources/image/v2/image.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/image/index.rst', 'doc/source/users/resources/image/v1/image.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/79dfd5fa9e4857b60d7fa96ab6e8c60af8f26e7e', 'message': 'Image resource docs framework\n\nChange-Id: I476605070fa94b410f47fd6ff66a645217332e60\n'}]",0,185206,79dfd5fa9e4857b60d7fa96ab6e8c60af8f26e7e,9,2,2,8736,,,0,"Image resource docs framework

Change-Id: I476605070fa94b410f47fd6ff66a645217332e60
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/06/185206/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/resources/image/v2/member.rst', 'doc/source/users/resources/image/v2/tag.rst', 'doc/source/users/resources/image/v2/image.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/image/index.rst', 'doc/source/users/resources/image/v1/image.rst']",6,145f2b3fc780dfc9f2822511d1420485e3d45f08,docsimage,openstack.image.v1.image ======================== .. automodule:: openstack.image.v1.image The Image Class --------------- The ``Image`` class inherits from :class:`~openstack.resource.Resource`. .. autoclass:: openstack.image.v1.image.Image :members: ,,66,0
openstack%2Fpython-monascaclient~master~I7a200084075d0358e9619401fe8aa61a024fcbd5,openstack/python-monascaclient,master,I7a200084075d0358e9619401fe8aa61a024fcbd5,Fixed README for Python API - about re-athenticate,MERGED,2015-05-27 20:02:32.000000000,2015-05-27 20:09:43.000000000,2015-05-27 20:09:43.000000000,"[{'_account_id': 3}, {'_account_id': 11094}]","[{'number': 1, 'created': '2015-05-27 20:02:32.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/ef9b654c1de1dca83a2a38c013965da76665149f', 'message': 'Fixed README for Python API - about re-athenticate\n\nChange-Id: I7a200084075d0358e9619401fe8aa61a024fcbd5\n'}]",0,186146,ef9b654c1de1dca83a2a38c013965da76665149f,6,2,1,12133,,,0,"Fixed README for Python API - about re-athenticate

Change-Id: I7a200084075d0358e9619401fe8aa61a024fcbd5
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/46/186146/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ef9b654c1de1dca83a2a38c013965da76665149f,fix-readme,"In order to use the python api directly, you must pass in a valid auth token and monasca api endpoint, or you can pass in the credentials required by the keystone client and let the Python API do the authentication. The user can obtain the token and endpoint using the keystone client api:Long running users of the Client will recieve an indicationinto the client.Client.replace_token(token) method. If you constructed the Client with all the keystone credentials needed to authenticate, then the API will automatically try one time to re-authenticate with keystone whenever the token expires.Refer to the example in python-monascaclient/client_api_example.py for more detail::","In order to use the python api directly, you must first obtain an auth token and identify the monasca api endpoint. The user can obtain the token and endpoint using the keystone client api:Long running users of Client will recieve an indicationinto the client.Client.replace_token(token) method.Refer to this example in python-monascaclient/client_api_example.py::",10,6
openstack%2Fzaqar-specs~master~Ib28ab536f88c63019ab435697382533d584acb84,openstack/zaqar-specs,master,Ib28ab536f88c63019ab435697382533d584acb84,Drop incubating theme from docs,MERGED,2015-05-27 19:23:54.000000000,2015-05-27 20:07:04.000000000,2015-05-27 20:07:03.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-05-27 19:23:54.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/883377c9013ec01c6af7642e0dc652b4a0ca30f4', 'message': 'Drop incubating theme from docs\n\nOpenStack has dropped the incubation notion, so labeling this as an\nincubated project in the docs is confusing.\n\nChange-Id: Ib28ab536f88c63019ab435697382533d584acb84\n'}]",0,186136,883377c9013ec01c6af7642e0dc652b4a0ca30f4,7,3,1,1849,,,0,"Drop incubating theme from docs

OpenStack has dropped the incubation notion, so labeling this as an
incubated project in the docs is confusing.

Change-Id: Ib28ab536f88c63019ab435697382533d584acb84
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/36/186136/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,883377c9013ec01c6af7642e0dc652b4a0ca30f4,incubating,html_theme_options = {},html_theme_options = {'incubating': True},1,1
openstack%2Fpython-zaqarclient~master~I1893fa76affb5e712abef6765e373077b2fc6832,openstack/python-zaqarclient,master,I1893fa76affb5e712abef6765e373077b2fc6832,Drop incubating theme from docs,MERGED,2015-05-27 19:21:56.000000000,2015-05-27 20:05:36.000000000,2015-05-27 20:05:35.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-05-27 19:21:56.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/6707d411166f515023031d30371b6ba01796275f', 'message': 'Drop incubating theme from docs\n\nOpenStack has dropped the incubation notion, so labeling this as an\nincubated project in the docs is confusing.\n\nChange-Id: I1893fa76affb5e712abef6765e373077b2fc6832\n'}]",0,186135,6707d411166f515023031d30371b6ba01796275f,7,3,1,1849,,,0,"Drop incubating theme from docs

OpenStack has dropped the incubation notion, so labeling this as an
incubated project in the docs is confusing.

Change-Id: I1893fa76affb5e712abef6765e373077b2fc6832
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/35/186135/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,6707d411166f515023031d30371b6ba01796275f,incubating,html_theme_options = {},html_theme_options = {'incubating': True},1,1
openstack%2Fpython-openstackclient~master~I1eb73e5f38904ee6c74f6c7e27fc66cfe198619d,openstack/python-openstackclient,master,I1eb73e5f38904ee6c74f6c7e27fc66cfe198619d,Remove checks for None dates in keypair functional tests,MERGED,2015-05-22 20:01:42.000000000,2015-05-27 20:03:51.000000000,2015-05-27 20:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-05-22 20:01:42.000000000', 'files': ['functional/tests/compute/v2/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9186885553ed8ad32c5a863c9efb63dd570a99bb', 'message': ""Remove checks for None dates in keypair functional tests\n\nSteve made a comment about this and I agree, we should try and\nkeep these tests and simple as possible and this kind of thing\ndoesn't add much value.\n\nChange-Id: I1eb73e5f38904ee6c74f6c7e27fc66cfe198619d\n""}]",1,185127,9186885553ed8ad32c5a863c9efb63dd570a99bb,7,2,1,8736,,,0,"Remove checks for None dates in keypair functional tests

Steve made a comment about this and I agree, we should try and
keep these tests and simple as possible and this kind of thing
doesn't add much value.

Change-Id: I1eb73e5f38904ee6c74f6c7e27fc66cfe198619d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/27/185127/1 && git format-patch -1 --stdout FETCH_HEAD,['functional/tests/compute/v2/test_keypair.py'],1,9186885553ed8ad32c5a863c9efb63dd570a99bb,keypair," FIELDS = ['name'] self.assertEqual(self.NAME + ""\n"", raw_output)"," FIELDS = ['deleted_at', 'name', 'updated_at'] expected = ""None\n"" + self.NAME + ""\nNone\n"" self.assertEqual(expected, raw_output)",2,3
openstack%2Fpython-openstackclient~master~I41957c1449f8278f23ec07bce920524caea01280,openstack/python-openstackclient,master,I41957c1449f8278f23ec07bce920524caea01280,Remove oslo incubator config,MERGED,2015-05-26 20:52:53.000000000,2015-05-27 20:03:11.000000000,2015-05-27 20:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8041}]","[{'number': 1, 'created': '2015-05-26 20:52:53.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cae03c6834baedd45d3962025a6168a70322df64', 'message': ""Remove oslo incubator config\n\nI don't think we are using oslo incubator right now, if it is\nneeded, this file can be added back.  This will make tab\ncomplete more pleasant as well.\n\nChange-Id: I41957c1449f8278f23ec07bce920524caea01280\n""}]",0,185738,cae03c6834baedd45d3962025a6168a70322df64,8,4,1,8736,,,0,"Remove oslo incubator config

I don't think we are using oslo incubator right now, if it is
needed, this file can be added back.  This will make tab
complete more pleasant as well.

Change-Id: I41957c1449f8278f23ec07bce920524caea01280
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/38/185738/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,cae03c6834baedd45d3962025a6168a70322df64,osloconfig,,[DEFAULT] # The list of modules to copy from openstack-common # The base module to hold the copy of openstack.common base=openstackclient ,0,7
openstack%2Fpython-openstackclient~master~I0f8d939d6fca7608eaa3eea7ea4ca93296aaab3a,openstack/python-openstackclient,master,I0f8d939d6fca7608eaa3eea7ea4ca93296aaab3a,Remove oslo serialization requirement,MERGED,2015-05-26 21:41:21.000000000,2015-05-27 20:03:08.000000000,2015-05-27 20:03:06.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8041}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-26 21:41:21.000000000', 'files': ['requirements.txt', 'openstackclient/tests/common/test_clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/575dcdfc8ef6d24ecb75663eb94d549a8beb30fe', 'message': ""Remove oslo serialization requirement\n\nRecently oslo serialization has started to also include\npython-msgpack. Since we were only using it for json support, we\nshould just use python's json support. Especially since it's only\nused by our tests.\n\nChange-Id: I0f8d939d6fca7608eaa3eea7ea4ca93296aaab3a\n""}]",0,185749,575dcdfc8ef6d24ecb75663eb94d549a8beb30fe,8,4,1,6482,,,0,"Remove oslo serialization requirement

Recently oslo serialization has started to also include
python-msgpack. Since we were only using it for json support, we
should just use python's json support. Especially since it's only
used by our tests.

Change-Id: I0f8d939d6fca7608eaa3eea7ea4ca93296aaab3a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/49/185749/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'openstackclient/tests/common/test_clientmanager.py']",2,575dcdfc8ef6d24ecb75663eb94d549a8beb30fe,rm_oslo_ser, import json as jsonutils,from oslo_serialization import jsonutils,2,2
openstack%2Ftripleo-heat-templates~master~Ie420274c7fba80abf9cf2b599431acc47e28fc7a,openstack/tripleo-heat-templates,master,Ie420274c7fba80abf9cf2b599431acc47e28fc7a,Map Nova services to isolated networks,MERGED,2015-05-27 02:00:21.000000000,2015-05-27 20:01:47.000000000,2015-05-27 20:01:46.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-27 02:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ddf25acc9bcd072c0687738ade2385763e4cc335', 'message': ""Map Nova services to isolated networks\n\nThis change adds parameters to specify which networks the Nova API and\nmetadata services will use. If the internal_api network exists, it will be\nused for the bind IP for Nova API and metadata servers, otherwise the\nUndercloud 'ctlplane' IP will be used by default.\n\nChange-Id: Ie420274c7fba80abf9cf2b599431acc47e28fc7a\n""}, {'number': 2, 'created': '2015-05-27 07:46:14.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d358351f4af4bd962b5c2b83afdc70838949b6ff', 'message': ""Map Nova services to isolated networks\n\nThis change adds parameters to specify which networks the Nova API and\nmetadata services will use. If the internal_api network exists, it will be\nused for the bind IP for Nova API and metadata servers, otherwise the\nUndercloud 'ctlplane' IP will be used by default.\n\nChange-Id: Ie420274c7fba80abf9cf2b599431acc47e28fc7a\n""}]",3,185816,d358351f4af4bd962b5c2b83afdc70838949b6ff,13,5,2,12398,,,0,"Map Nova services to isolated networks

This change adds parameters to specify which networks the Nova API and
metadata services will use. If the internal_api network exists, it will be
used for the bind IP for Nova API and metadata servers, otherwise the
Undercloud 'ctlplane' IP will be used by default.

Change-Id: Ie420274c7fba80abf9cf2b599431acc47e28fc7a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/16/185816/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,ddf25acc9bcd072c0687738ade2385763e4cc335,service_map_nova," nova::api::api_bind_address: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, NovaApiNetwork]}]} nova::api::metadata_listen: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, NovaMetadataNetwork]}]}", nova::api::api_bind_address: {get_input: controller_host} nova::api::metadata_listen: {get_input: controller_host},4,2
openstack%2Ftripleo-heat-templates~master~I5febe1b9071600b43fa76c6cf415db83cad472ab,openstack/tripleo-heat-templates,master,I5febe1b9071600b43fa76c6cf415db83cad472ab,Map Heat services to isolated networks,MERGED,2015-05-27 01:50:04.000000000,2015-05-27 20:01:40.000000000,2015-05-27 20:01:40.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-27 01:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ea46288c03452af67c443374cdf02308617bfb4', 'message': ""Map Heat services to isolated networks\n\nThis change adds parameters to specify which networks the Heat services\nwill use. If the internal_api network exists, the Heat API, Heat Cloud\nFormations, and Heat Cloudwatch services will bind to the IP address on\nthat network, otherwise the services will default to the IP on the\nUndercloud 'ctlplane' network.\n\nChange-Id: I5febe1b9071600b43fa76c6cf415db83cad472ab\n""}, {'number': 2, 'created': '2015-05-27 07:45:16.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/41f0b76907416b8e6ea0f7a7b9de9985b77e79e7', 'message': ""Map Heat services to isolated networks\n\nThis change adds parameters to specify which networks the Heat services\nwill use. If the internal_api network exists, the Heat API, Heat Cloud\nFormations, and Heat Cloudwatch services will bind to the IP address on\nthat network, otherwise the services will default to the IP on the\nUndercloud 'ctlplane' network.\n\nChange-Id: I5febe1b9071600b43fa76c6cf415db83cad472ab\n""}]",0,185815,41f0b76907416b8e6ea0f7a7b9de9985b77e79e7,11,6,2,12398,,,0,"Map Heat services to isolated networks

This change adds parameters to specify which networks the Heat services
will use. If the internal_api network exists, the Heat API, Heat Cloud
Formations, and Heat Cloudwatch services will bind to the IP address on
that network, otherwise the services will default to the IP on the
Undercloud 'ctlplane' network.

Change-Id: I5febe1b9071600b43fa76c6cf415db83cad472ab
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/185815/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,8ea46288c03452af67c443374cdf02308617bfb4,service_map_heat," heat::api::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiNetwork]}]} heat::api_cloudwatch::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiCloudwatchNetwork]}]} heat::api_cfn::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiCfnNetwork]}]}", heat::api::bind_host: {get_input: controller_host} heat::api_cloudwatch::bind_host: {get_input: controller_host} heat::api_cfn::bind_host: {get_input: controller_host},6,3
openstack%2Ftripleo-heat-templates~master~I11bcebba3a22e8850095250a2ddfaf972339476b,openstack/tripleo-heat-templates,master,I11bcebba3a22e8850095250a2ddfaf972339476b,Map Neutron services to isolated networks,MERGED,2015-05-27 01:46:40.000000000,2015-05-27 20:01:34.000000000,2015-05-27 20:01:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-27 01:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/62d24cb26664d5242b5b968904619c285cadbf31', 'message': ""Map Neutron services to isolated networks\n\nThis change adds parameters to specify which network the Neutron API should\nuse. If the internal_api network exists, Neutron will bind to the IP on that\nnetwork, otherwise the Undercloud 'ctlplane' network will be used. The\nnetwork that the Neutron API is bound to can be overridden in an environment\nfile.\n\nChange-Id: I11bcebba3a22e8850095250a2ddfaf972339476b\n""}, {'number': 2, 'created': '2015-05-27 06:41:24.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80b30983386466f08f11c285627c99f7d16d3448', 'message': ""Map Neutron services to isolated networks\n\nThis change adds parameters to specify which network the Neutron API should\nuse. If the internal_api network exists, Neutron will bind to the IP on that\nnetwork, otherwise the Undercloud 'ctlplane' network will be used. The\nnetwork that the Neutron API is bound to can be overridden in an environment\nfile.\n\nChange-Id: I11bcebba3a22e8850095250a2ddfaf972339476b\n""}]",0,185812,80b30983386466f08f11c285627c99f7d16d3448,11,5,2,12398,,,0,"Map Neutron services to isolated networks

This change adds parameters to specify which network the Neutron API should
use. If the internal_api network exists, Neutron will bind to the IP on that
network, otherwise the Undercloud 'ctlplane' network will be used. The
network that the Neutron API is bound to can be overridden in an environment
file.

Change-Id: I11bcebba3a22e8850095250a2ddfaf972339476b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/185812/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,62d24cb26664d5242b5b968904619c285cadbf31,service_map_neutron," neutron::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, NeutronApiNetwork]}]}", neutron::bind_host: {get_input: controller_host},2,1
openstack%2Ftripleo-heat-templates~master~I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20,openstack/tripleo-heat-templates,master,I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20,Map Keystone services to isolated networks,MERGED,2015-05-27 01:00:41.000000000,2015-05-27 20:01:27.000000000,2015-05-27 20:01:27.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-27 01:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6bc60cba48a58478f87b9d77c1ed4851c1570551', 'message': ""Map Keystone services to isolated networks\n\nThis change adds parameters to specify which networks the Keystone API\nservices will use. If the public network exists, Keystone will bind to\nthe IP on that network for the public API, otherwise it will default to\nthe IP on the Undercloud 'ctlplane' network. If the internal_api network\nexists it will be used for the Keystone Admin API, otherwise it will\ndefault to the 'ctlplane' IP. The networks these APIs are bound to can\nbe overridden in an environment file.\n\nChange-Id: I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20\n""}, {'number': 2, 'created': '2015-05-27 01:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b09e38b46ad758ed7bb4352e267a628c8617efe', 'message': ""Map Keystone services to isolated networks\n\nThis change adds parameters to specify which networks the Keystone API\nservices will use. If the external network exists, Keystone will bind to\nthe IP on that network for the public API, otherwise it will default to\nthe IP on the Undercloud 'ctlplane' network. If the internal_api network\nexists it will be used for the Keystone Admin API, otherwise it will\ndefault to the 'ctlplane' IP. The networks these APIs are bound to can\nbe overridden in an environment file.\n\nChange-Id: I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20\n""}, {'number': 3, 'created': '2015-05-27 06:35:56.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8072ae85082dd060d1cb8e3bcba76da8372ed593', 'message': ""Map Keystone services to isolated networks\n\nThis change adds parameters to specify which networks the Keystone API\nservices will use. If the external network exists, Keystone will bind to\nthe IP on that network for the public API, otherwise it will default to\nthe IP on the Undercloud 'ctlplane' network. If the internal_api network\nexists it will be used for the Keystone Admin API, otherwise it will\ndefault to the 'ctlplane' IP. The networks these APIs are bound to can\nbe overridden in an environment file.\n\nChange-Id: I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20\n""}]",0,185797,8072ae85082dd060d1cb8e3bcba76da8372ed593,15,5,3,12398,,,0,"Map Keystone services to isolated networks

This change adds parameters to specify which networks the Keystone API
services will use. If the external network exists, Keystone will bind to
the IP on that network for the public API, otherwise it will default to
the IP on the Undercloud 'ctlplane' network. If the internal_api network
exists it will be used for the Keystone Admin API, otherwise it will
default to the 'ctlplane' IP. The networks these APIs are bound to can
be overridden in an environment file.

Change-Id: I6694ef6ca3b9b7afbde5d4f9d173723b9ce71b20
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/185797/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,6bc60cba48a58478f87b9d77c1ed4851c1570551,service_map_keystone," keystone::public_bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, KeystonePublicApiNetwork]}]} keystone::admin_bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, KeystoneAdminApiNetwork]}]}", keystone::public_bind_host: {get_input: controller_host} keystone::admin_bind_host: {get_input: controller_host},4,2
openstack%2Ftripleo-heat-templates~master~I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99,openstack/tripleo-heat-templates,master,I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99,Map Glance services to isolated networks,MERGED,2015-05-26 22:55:45.000000000,2015-05-27 20:01:20.000000000,2015-05-27 20:01:19.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-26 22:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7415fcb38d5cebc9b67a0ad92be1acc2c8a237f0', 'message': ""Map Heat services to isolated networks\n\nThis change adds parameters to specify which networks the Heat services\nwill use. If the internal_api network exists, the Heat API, Heat Cloud\nFormations, and Heat Cloudwatch services will bind to the IP address on\nthat network, otherwise the services will default to the IP on the\nUndercloud 'ctlplane' network.\n\nChange-Id: I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99\n""}, {'number': 2, 'created': '2015-05-27 01:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a83df269ebae7b55056fc3871d6c08148abd6102', 'message': ""Map Glance services to isolated networks\n\nThis change adds parameters to specify which networks the Glance services\nwill use. If the internal_api network exists, Glance Registry will bind\nto the IP on that network, otherwise it will default to the Undercloud\n'ctlplane' network. If the storage network exists, Glance API will bind\nto the IP on that network, otherwise it will default to 'ctlplane'. The\nnetworks that these services use can be overridden with an environment\nfile.\n\nChange-Id: I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99\n""}, {'number': 3, 'created': '2015-05-27 02:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1534011cd2ec64af39695f8c782e92962ae2fe8', 'message': ""Map Heat services to isolated networks\n\nThis change adds parameters to specify which networks the Heat services\nwill use. If the internal_api network exists, the Heat API, Heat Cloud\nFormations, and Heat Cloudwatch services will bind to the IP address on\nthat network, otherwise the services will default to the IP on the\nUndercloud 'ctlplane' network.\n\nChange-Id: I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99\n""}, {'number': 4, 'created': '2015-05-27 02:04:21.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/93c488e50591d0b4994b52d4cc91e9bcc954fef4', 'message': ""Map Glance services to isolated networks\n\nThis change adds parameters to specify which networks the Glance services\nwill use. If the internal_api network exists, Glance Registry will bind\nto the IP on that network, otherwise it will default to the Undercloud\n'ctlplane' network. If the storage network exists, Glance API will bind\nto the IP on that network, otherwise it will default to 'ctlplane'. The\nnetworks that these services use can be overridden with an environment\nfile.\n\nChange-Id: I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99\n""}]",8,185775,93c488e50591d0b4994b52d4cc91e9bcc954fef4,25,6,4,12398,,,0,"Map Glance services to isolated networks

This change adds parameters to specify which networks the Glance services
will use. If the internal_api network exists, Glance Registry will bind
to the IP on that network, otherwise it will default to the Undercloud
'ctlplane' network. If the storage network exists, Glance API will bind
to the IP on that network, otherwise it will default to 'ctlplane'. The
networks that these services use can be overridden with an environment
file.

Change-Id: I6114b2d898c5a0ba4cdb26a3da2dbf669666ba99
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/185775/3 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,7415fcb38d5cebc9b67a0ad92be1acc2c8a237f0,service_map_glance," glance::api::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, GlanceApiNetwork]}]} glance::registry::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, GlanceRegistryNetwork]}]}", glance::api::bind_host: {get_input: controller_host} glance::registry::bind_host: {get_input: controller_host},4,2
openstack%2Fpython-openstackclient~master~Ida9ac9956c611fec783ff98a01628c3d38e7b58f,openstack/python-openstackclient,master,Ida9ac9956c611fec783ff98a01628c3d38e7b58f,Add some comments about current plugin support,MERGED,2015-05-22 21:11:19.000000000,2015-05-27 19:57:49.000000000,2015-05-27 19:20:03.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8041}, {'_account_id': 8736}, {'_account_id': 10239}, {'_account_id': 14805}]","[{'number': 1, 'created': '2015-05-22 21:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3ef5f5f3226bc0bd1939a593b7cb6a3028565b85', 'message': 'Add some comments about current plugin support\n\nChange-Id: Ida9ac9956c611fec783ff98a01628c3d38e7b58f\n'}, {'number': 2, 'created': '2015-05-22 21:41:55.000000000', 'files': ['doc/source/plugins.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ab5a89493f376cb561e25d19da0a37617e09e6e0', 'message': 'Add some comments about current plugin support\n\nChange-Id: Ida9ac9956c611fec783ff98a01628c3d38e7b58f\n'}]",12,185144,ab5a89493f376cb561e25d19da0a37617e09e6e0,15,7,2,6482,,,0,"Add some comments about current plugin support

Change-Id: Ida9ac9956c611fec783ff98a01628c3d38e7b58f
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/44/185144/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugins.rst'],1,3ef5f5f3226bc0bd1939a593b7cb6a3028565b85,plugins,"Adoption ======== OpenStackClient promises to support first class support for the following OpenStack services: Compute, Identity, Image, Storage, Volume and Network. These services are considered essential to any OpenStack deployment. Other OpenStack services, such as Orchestration or Telemetry may use OpenStackClient as a plugin. The source code will not be hosted by OpenStackClient. The following is a list of projects and their status as an OpenStackClient plugin. ============================= ====================================== project notes ============================= ====================================== python-barbicanclient n/a python-ceilometerclient n/a python-congressclient n/a python-designateclient n/a python-heatclient n/a python-ironicclient patch in progress (https://review.openstack.org/#/c/171672/) python-magnumclient n/a python-manilaclient n/a python-mistralclient n/a python-muranoclient n/a python-saharaclient n/a python-troveclient n/a python-zaqarclient n/a ============================= ====================================== ==============",--------------,33,1
openstack%2Fos-net-config~master~Iac94a94ba8970a08984e646abd385565e8765c9c,openstack/os-net-config,master,Iac94a94ba8970a08984e646abd385565e8765c9c,Add static IP assignment via template tokens in config.yaml,ABANDONED,2015-04-01 22:29:49.000000000,2015-05-27 19:50:29.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 8399}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-04-01 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/950121e5f1f7589e2cb1254a3672de64b9f744c6', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the ip_index. The ip_index is specified on the\ncommand line or read from a yaml file, and this change modifies the\ncli to search a directory (defaults to /etc/puppet/hieradata/ for\ncompatibility with tripleo) for the os_net_config_ip_index element\nin the tripleo files. Note that since tripleo produces a different\nhieradata for each family (control, compute, ceph, cinder, etc.)\nos-net-config must search the directory for known file names.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nindex (an os_net_config_ip_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 2, 'created': '2015-04-01 22:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/ea48baac3bf1c16bee4046e5dab5e3f1ceb50364', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the ip_index. The ip_index is specified on the\ncommand line or read from a yaml file, and this change modifies the\ncli to search a directory (defaults to /etc/puppet/hieradata/ for\ncompatibility with tripleo) for the os_net_config_ip_index element\nin the tripleo files. Note that since tripleo produces a different\nhieradata for each family (control, compute, ceph, cinder, etc.)\nos-net-config must search the directory for known file names.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nindex (an os_net_config_ip_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 3, 'created': '2015-04-02 15:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/8f46ad4f1631840258dcc1a397ceb4d129b514b3', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the ip_index. The ip_index is specified on the\ncommand line or read from a yaml file, and this change modifies the\ncli to search a directory (defaults to /etc/puppet/hieradata/ for\ncompatibility with tripleo) for the os_net_config_ip_index element\nin the tripleo files. Note that since tripleo produces a different\nhieradata for each family (control, compute, ceph, cinder, etc.)\nos-net-config must search the directory for known file names.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nindex (an os_net_config_ip_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 4, 'created': '2015-04-02 16:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/6a86669fbf8bd6d0f3c09517468b7bce103014df', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the ip_index. The ip_index is specified on the\ncommand line or read from a yaml file, and this change modifies the\ncli to search a directory (defaults to /etc/puppet/hieradata/ for\ncompatibility with tripleo) for the os_net_config_ip_index element\nin the tripleo files. Note that since tripleo produces a different\nhieradata for each family (control, compute, ceph, cinder, etc.)\nos-net-config must search the directory for known file names.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nindex (an os_net_config_ip_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 5, 'created': '2015-04-02 17:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/808e5e1b64ac8e5268b7f9f8d429c7abef43074a', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the ip_index. The ip_index is specified on the\ncommand line or read from a yaml file, and this change modifies the\ncli to search a directory (defaults to /etc/puppet/hieradata/ for\ncompatibility with tripleo) for the os_net_config_ip_index element\nin the tripleo files. Note that since tripleo produces a different\nhieradata for each family (control, compute, ceph, cinder, etc.)\nos-net-config must search the directory for known file names.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nindex (an os_net_config_ip_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 6, 'created': '2015-04-08 00:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/21022a0e953136c0f60d914ea4aa7a89ace4a0f7', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the node_index. The node_index is specified on the\ncommand line or read from the config file, and this change modifies\nthe cli to search the config file for a node_index element.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nnode_index (a node_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory. Note that\nthe node_index in the sample files is for demonstration, in an\nactual deployment the node_index would be written by Heat and\nwould be unique for each member of a ResourceGroup, such as\nController or Compute. Each group would also have a unique\nhost_ip_range. This ensures that each member of a group\nhas a unique static IP address, and that the groups do not have\noverlapping IP addresses.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 7, 'created': '2015-04-08 01:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/8853693d191eb0437bde41f9b506ff59159be13d', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the node_index. Subnets can also be referred to by\nsubnet, e.g. ${192_0_2_0_24_address}, The node_index is specified on\nthe command line or read from the config file, and this change\nmodifies the cli to search the config file for a node_index element.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nnode_index (a node_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory. Note that\nthe node_index in the sample files is for demonstration, in an\nactual deployment the node_index would be written by Heat and\nwould be unique for each member of a ResourceGroup, such as\nController or Compute. Each group would also have a unique\nhost_ip_range. This ensures that each member of a group\nhas a unique static IP address, and that the groups do not have\noverlapping IP addresses.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 8, 'created': '2015-04-09 23:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/260b36dbda2307882b8468f2265451b346845374', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the node_index. Subnets can also be referred to by\nIP/mask, e.g. ${192_0_2_0_24_address}, The node_index is specified\non the command line or read from the config file, and this change\nmodifies the cli to search the config file for a node_index element.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nnode_index (a node_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory. Note that\nthe node_index in the sample files is for demonstration, in an\nactual deployment the node_index would be written by Heat and\nwould be unique for each member of a ResourceGroup, such as\nController or Compute. Each group would also have a unique\nhost_ip_range. This ensures that each member of a group\nhas a unique static IP address, and that the groups do not have\noverlapping IP addresses.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}, {'number': 9, 'created': '2015-04-10 00:57:29.000000000', 'files': ['etc/os-net-config/samples/static_interface.json', 'etc/os-net-config/samples/static_vlan.yaml', 'os_net_config/utils.py', 'os_net_config/tests/test_objects.py', 'os_net_config/tests/test_utils.py', 'README.rst', 'etc/os-net-config/samples/static_interface.yaml', 'etc/os-net-config/samples/static_vlan.json', 'os_net_config/objects.py', 'os_net_config/cli.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/a847fe3ba2e9c30b1701adac840e6304ac47b04c', 'message': 'Add static IP assignment via template tokens in config.yaml\n\nThis change adds support for assigning static IP addresses to any\ninterface. In order for this to work, os-net-config needs to have\nsome knowledge of the subnet characteristics, so this change adds\nthe Subnet object (and associated unit test). The subnets are\ndefined in config.yaml/json in the subnets array (on the same level\nas the network_config).\n\nA name is used to identify the subnet when matching tokens. A token\nof ${tenant_address} will assign a static IP address in the ""tenant""\nsubnet, based on the node_index. Subnets can also be referred to by\nIP/mask, e.g. ${192_0_2_0_24_address}, The node_index is specified\non the command line or read from the config file, and this change\nmodifies the cli to search the config file for a node_index element.\nIPs are assigned out of the subnet\'s host_ip_range based on the\nnode_index (a node_index of 0 would return the first IP in\nhost_ip_range). This allows for scale deployments.\n\nExample config files for static IPs on interfaces and VLANs were\nalso added to the etc/os-net-config/samples directory. Note that\nthe node_index in the sample files is for demonstration, in an\nactual deployment the node_index would be written by Heat and\nwould be unique for each member of a ResourceGroup, such as\nController or Compute. Each group would also have a unique\nhost_ip_range. This ensures that each member of a group\nhas a unique static IP address, and that the groups do not have\noverlapping IP addresses. The README.rst has been updated with\nexamples for using the new subnet and static IP assignment\nmethods.\n\nChange-Id: Iac94a94ba8970a08984e646abd385565e8765c9c\n'}]",22,169937,a847fe3ba2e9c30b1701adac840e6304ac47b04c,34,5,9,12398,,,0,"Add static IP assignment via template tokens in config.yaml

This change adds support for assigning static IP addresses to any
interface. In order for this to work, os-net-config needs to have
some knowledge of the subnet characteristics, so this change adds
the Subnet object (and associated unit test). The subnets are
defined in config.yaml/json in the subnets array (on the same level
as the network_config).

A name is used to identify the subnet when matching tokens. A token
of ${tenant_address} will assign a static IP address in the ""tenant""
subnet, based on the node_index. Subnets can also be referred to by
IP/mask, e.g. ${192_0_2_0_24_address}, The node_index is specified
on the command line or read from the config file, and this change
modifies the cli to search the config file for a node_index element.
IPs are assigned out of the subnet's host_ip_range based on the
node_index (a node_index of 0 would return the first IP in
host_ip_range). This allows for scale deployments.

Example config files for static IPs on interfaces and VLANs were
also added to the etc/os-net-config/samples directory. Note that
the node_index in the sample files is for demonstration, in an
actual deployment the node_index would be written by Heat and
would be unique for each member of a ResourceGroup, such as
Controller or Compute. Each group would also have a unique
host_ip_range. This ensures that each member of a group
has a unique static IP address, and that the groups do not have
overlapping IP addresses. The README.rst has been updated with
examples for using the new subnet and static IP assignment
methods.

Change-Id: Iac94a94ba8970a08984e646abd385565e8765c9c
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/37/169937/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/os-net-config/samples/static_interface.json', 'etc/os-net-config/samples/static_vlan.yaml', 'os_net_config/utils.py', 'os_net_config/tests/test_objects.py', 'os_net_config/tests/test_utils.py', 'etc/os-net-config/samples/static_interface.yaml', 'etc/os-net-config/samples/static_vlan.json', 'os_net_config/objects.py', 'os_net_config/cli.py']",9,950121e5f1f7589e2cb1254a3672de64b9f744c6,static_ip_assignment,"from os_net_config import utils parser.add_argument('-t', '--tripleo-dir', metavar='TRIPLEO_DIR', help=""directory with yaml containing "" + ""os_net_config_ip_index."", default='/etc/puppet/hieradata/') parser.add_argument('-i', '--ip-index', metavar='IP_INDEX', help=""""""Override ip_index for static IP assignment."""""", default='None') subnets_array = [] ooo_data_files = ['controller.yaml', 'compute.yaml', 'ceph.yaml', 'object.yaml', 'volume.yaml'] ip_index = opts.ip_index if opts.ip_index == 'None': # Read the known puppet hieradata files looking for IP index info for filename in ooo_data_files: path = opts.tripleo_dir + filename if os.path.isfile(path): with open(path) as yf: fc = yf.read() ip_index = yaml.load(fc).get('os_net_config_ip_index') if ip_index: logger.debug(""ip_index: %s:"" % ip_index) break config_raw = cf.read() config_processed = utils.replace_tokens(config_raw, ip_index) iface_array = yaml.load(config_processed).get(""network_config"") if not isinstance(subnets_array, list): logger.warning('No subnets defined in config: %s' % opts.config_file) subnets_array = [] logger.debug(""iface_json: %s"" % iface_json)"," iface_array = yaml.load(cf.read()).get(""network_config"")",473,1
openstack%2Fswift~feature%2Fhummingbird~I9d6fbf4a10cb7b876c142d8d6320a2974d239e00,openstack/swift,feature/hummingbird,I9d6fbf4a10cb7b876c142d8d6320a2974d239e00,go: log 499 on client early disconnect,MERGED,2015-05-15 15:43:48.000000000,2015-05-27 19:32:41.000000000,2015-05-27 19:32:39.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 2828}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-05-15 15:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fb052dc8a80b64ef375122405b392ca2e7687853', 'message': 'go: log 499 on client early disconnect\n\nIf a client disconnects early, hummingbird currently returns a 500 status\nwhile python-swift returns 499.\n\nThis really only affects what gets logged.\n\nChange-Id: I9d6fbf4a10cb7b876c142d8d6320a2974d239e00\n'}, {'number': 2, 'created': '2015-05-26 19:16:16.000000000', 'files': ['go/objectserver/main.go', 'go/objectserver/main_test.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/e734427bbb7ddc0d1ed980ebf297e974007e43cf', 'message': 'go: log 499 on client early disconnect\n\nIf a client disconnects early, hummingbird currently returns a 500 status\nwhile python-swift returns 499.\n\nThis really only affects what gets logged.\n\nChange-Id: I9d6fbf4a10cb7b876c142d8d6320a2974d239e00\n'}]",0,183577,e734427bbb7ddc0d1ed980ebf297e974007e43cf,16,5,2,2828,,,0,"go: log 499 on client early disconnect

If a client disconnects early, hummingbird currently returns a 500 status
while python-swift returns 499.

This really only affects what gets logged.

Change-Id: I9d6fbf4a10cb7b876c142d8d6320a2974d239e00
",git fetch https://review.opendev.org/openstack/swift refs/changes/77/183577/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/objectserver/main.go', 'go/objectserver/main_test.go']",2,fb052dc8a80b64ef375122405b392ca2e7687853,logdisconnect," host string port int root string handler *ObjectHandler return &TestServer{Server: ts, host: host, port: port, root: driveRoot, handler: handler.(*ObjectHandler)}, nil type shortReader struct{} func (s *shortReader) Read(p []byte) (n int, err error) { return 0, io.ErrUnexpectedEOF } type fakeResponse struct { status int } func (*fakeResponse) Header() http.Header { return make(http.Header) } func (*fakeResponse) Write(p []byte) (int, error) { return len(p), nil } func (f *fakeResponse) WriteHeader(s int) { f.status = s } func TestDisconnectOnPut(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() timestamp := hummingbird.GetTimestamp() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a/c/o"", ts.host, ts.port), &shortReader{}) assert.Nil(t, err) req.Header.Set(""Content-Type"", ""application/octet-stream"") req.Header.Set(""Content-Length"", ""10"") req.Header.Set(""X-Timestamp"", timestamp) resp := &fakeResponse{} ts.handler.ServeHTTP(resp, req) assert.Equal(t, resp.status, 499) }"," host string port int root string return &TestServer{Server: ts, host: host, port: port, root: driveRoot}, nil",49,5
openstack%2Fnova-specs~master~I51a8cb0c7ca08bb1a01dcf32829b5536f4d15427,openstack/nova-specs,master,I51a8cb0c7ca08bb1a01dcf32829b5536f4d15427,Remove the use of require_admin_context in the API,ABANDONED,2015-04-27 13:25:12.000000000,2015-05-27 19:27:54.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 13637}]","[{'number': 1, 'created': '2015-04-27 13:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/23e714a170b5842dabc887c5d729f3a4120bc0bb', 'message': ""Remove the use of require_admin_context in the API\n\nThe spec was mentioning that v2 API methods were still using the require_admin_ccontext() method by calling it explicitely in order to remove the DB decorators.\n\nThat's just something wrong : if the operator explicitely wants to free up a specific API endpoint, he shouldn't still face an Unauthorized error and that blueprint is exactly there to clean that mess up.\n\nAll the discussion is backed by a ML thread http://lists.openstack.org/pipermail/openstack-dev/2015-April/062282.html\n\nChange-Id: I51a8cb0c7ca08bb1a01dcf32829b5536f4d15427\n""}, {'number': 2, 'created': '2015-04-27 13:31:14.000000000', 'files': ['specs/liberty/approved/nova-api-policy.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d1c6b88081e83cf11201a2aa8be6409b6a7713fb', 'message': ""Remove the use of require_admin_context in the API\n\nThe spec was mentioning that v2 API methods were still using the require_admin_context() \nmethod by calling it explicitely in order to remove the DB decorators.\n\nThat's just something wrong : if the operator explicitely wants to free\nup a specific API endpoint, he shouldn't still face an Unauthorized\nerror and that blueprint is exactly there to clean that mess up.\n\nAll the discussion is backed by a ML thread :\nhttp://lists.openstack.org/pipermail/openstack-dev/2015-April/062282.html\n\nChange-Id: I51a8cb0c7ca08bb1a01dcf32829b5536f4d15427""}]",0,177764,d1c6b88081e83cf11201a2aa8be6409b6a7713fb,7,5,2,7166,,,0,"Remove the use of require_admin_context in the API

The spec was mentioning that v2 API methods were still using the require_admin_context() 
method by calling it explicitely in order to remove the DB decorators.

That's just something wrong : if the operator explicitely wants to free
up a specific API endpoint, he shouldn't still face an Unauthorized
error and that blueprint is exactly there to clean that mess up.

All the discussion is backed by a ML thread :
http://lists.openstack.org/pipermail/openstack-dev/2015-April/062282.html

Change-Id: I51a8cb0c7ca08bb1a01dcf32829b5536f4d15427",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/64/177764/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/nova-api-policy.rst'],1,23e714a170b5842dabc887c5d729f3a4120bc0bb,bp/is," layer, and we will ensure that API methods calling the DB API methods decorated by the context check are having a default policy enforced to ""rule:admin_api"". V2 API will removed once V2.1 ready, this can reduce the risk we break something existed."," layer, and move the hard-code permission checks into REST API layer to keep back-compatibility. V2 API will removed once V2.1 ready, this can reduce the risk we break something existed.",4,3
openstack%2Fos-client-config~master~Icdd9acede81bc5fba60d877194048e24a62c9e5d,openstack/os-client-config,master,Icdd9acede81bc5fba60d877194048e24a62c9e5d,Add an equality method for CloudConfig,MERGED,2015-05-27 12:58:05.000000000,2015-05-27 19:23:48.000000000,2015-05-27 19:23:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/2d9efa972bc4b182f077cd8f0af3e8c2de2b0ac7', 'message': 'Add an equality method for CloudConfig\n\nIn order to track if a config has changed, we need to be able to compare\nthe CloudConfig objects for equality.\n\nChange-Id: Icdd9acede81bc5fba60d877194048e24a62c9e5d\n'}, {'number': 2, 'created': '2015-05-27 13:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/0bc3ddbcfa6e892e0666f8f2df8925220cc880ca', 'message': 'Add an equality method for CloudConfig\n\nIn order to track if a config has changed, we need to be able to compare\nthe CloudConfig objects for equality.\n\nChange-Id: Icdd9acede81bc5fba60d877194048e24a62c9e5d\n'}, {'number': 3, 'created': '2015-05-27 16:11:39.000000000', 'files': ['os_client_config/cloud_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/5c60aad725b0b98008ee467c5130931339c12d48', 'message': 'Add an equality method for CloudConfig\n\nIn order to track if a config has changed, we need to be able to compare\nthe CloudConfig objects for equality.\n\nChange-Id: Icdd9acede81bc5fba60d877194048e24a62c9e5d\n'}]",0,185969,5c60aad725b0b98008ee467c5130931339c12d48,12,4,3,2,,,0,"Add an equality method for CloudConfig

In order to track if a config has changed, we need to be able to compare
the CloudConfig objects for equality.

Change-Id: Icdd9acede81bc5fba60d877194048e24a62c9e5d
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/69/185969/1 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/cloud_config.py'],1,2d9efa972bc4b182f077cd8f0af3e8c2de2b0ac7,," def __eq__(self, other): return (self.name == other.name and self.region == other.region and self.config == other.config)",,4,0
openstack%2Fpython-monascaclient~master~I9380e868850b59b46d2fcc90e2e5fb1b1429bc1d,openstack/python-monascaclient,master,I9380e868850b59b46d2fcc90e2e5fb1b1429bc1d,replace v2.0 auth_url with v3,MERGED,2015-05-27 16:10:44.000000000,2015-05-27 19:23:33.000000000,2015-05-27 19:23:30.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 12133}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-05-27 16:10:44.000000000', 'files': ['monascaclient/v2_0/client.py', 'monascaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/f9f7f2b62d2beb31310808023f9c16304e3ec3b6', 'message': 'replace v2.0 auth_url with v3\n\nChange-Id: I9380e868850b59b46d2fcc90e2e5fb1b1429bc1d\n'}]",0,186061,f9f7f2b62d2beb31310808023f9c16304e3ec3b6,8,4,1,12133,,,0,"replace v2.0 auth_url with v3

Change-Id: I9380e868850b59b46d2fcc90e2e5fb1b1429bc1d
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/61/186061/1 && git format-patch -1 --stdout FETCH_HEAD,"['monascaclient/v2_0/client.py', 'monascaclient/shell.py']",2,f9f7f2b62d2beb31310808023f9c16304e3ec3b6,auth-url-version,"import string if args.os_auth_url and 'v2.0' in args.os_auth_url: args.os_auth_url = string.replace(args.os_auth_url, 'v2.0', 'v3') ",,10,2
openstack%2Fpython-openstackclient~master~Ie3468d14186f69ec9203f11302b8a07dc93dcc5a,openstack/python-openstackclient,master,Ie3468d14186f69ec9203f11302b8a07dc93dcc5a,Adds python-tuskarclient to list of plugins,MERGED,2015-05-27 14:31:58.000000000,2015-05-27 19:20:06.000000000,2015-05-27 19:20:06.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 14:31:58.000000000', 'files': ['doc/source/plugins.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/af9275178ba994a81ad38e3446579c5d783c1d10', 'message': 'Adds python-tuskarclient to list of plugins\n\nChange-Id: Ie3468d14186f69ec9203f11302b8a07dc93dcc5a\n'}]",0,186020,af9275178ba994a81ad38e3446579c5d783c1d10,7,3,1,8041,,,0,"Adds python-tuskarclient to list of plugins

Change-Id: Ie3468d14186f69ec9203f11302b8a07dc93dcc5a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/20/186020/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugins.rst'],1,af9275178ba994a81ad38e3446579c5d783c1d10,add-tuskarclient-to-list-of-plugins,python-tuskarclient using OpenStackClient,,1,0
openstack%2Fcinder~master~I646602624af7fbece277fe2305a3a541a456ed85,openstack/cinder,master,I646602624af7fbece277fe2305a3a541a456ed85,Replace suds test dependency with suds-jurko,MERGED,2015-05-05 12:51:27.000000000,2015-05-27 19:18:43.000000000,2015-05-14 02:24:53.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5638}, {'_account_id': 9107}, {'_account_id': 9171}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11751}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-05 12:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5f6f0ca737954cb2d2215e07708a47b16998365', 'message': 'Replace suds test dependency with suds-jurko\n\nsuds-jurko is actively maintained (latest commit in december 2014) and supports\nPython 3, whereas suds doesn\'t seem to be maintained anymore (last release in\n2010).\n\nsuds-jurko is a drop-in replacement for suds, both packages provide the same\nPython module.\n\nThis change depends on the same change for oslo.vmware:\n""Use suds-jurko on Python 2"".\n\nChange-Id: I646602624af7fbece277fe2305a3a541a456ed85\nDepends-On: I699c65e4abd607ea6f377d86c45fd609569f3c2b\n'}, {'number': 2, 'created': '2015-05-12 10:15:03.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/befc9da96e24ad9ec16a623f65df1d0a7de36555', 'message': ""Replace suds test dependency with suds-jurko\n\nsuds-jurko is actively maintained (latest commit in december 2014) and supports\nPython 3, whereas suds doesn't seem to be maintained anymore (last release in\n2010).\n\nsuds-jurko is a drop-in replacement for suds, both packages provide the same\nPython module.\n\nsuds-jurko is already in global requirements.\n\nChange-Id: I646602624af7fbece277fe2305a3a541a456ed85\n""}]",5,180130,befc9da96e24ad9ec16a623f65df1d0a7de36555,77,30,2,9107,,,0,"Replace suds test dependency with suds-jurko

suds-jurko is actively maintained (latest commit in december 2014) and supports
Python 3, whereas suds doesn't seem to be maintained anymore (last release in
2010).

suds-jurko is a drop-in replacement for suds, both packages provide the same
Python module.

suds-jurko is already in global requirements.

Change-Id: I646602624af7fbece277fe2305a3a541a456ed85
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/180130/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e5f6f0ca737954cb2d2215e07708a47b16998365,py3_suds,suds-jurko>=0.6,suds>=0.4,1,1
openstack%2Fpython-manilaclient~master~I1fadd514de4d9ae000cf0921262edd2bb111f5c5,openstack/python-manilaclient,master,I1fadd514de4d9ae000cf0921262edd2bb111f5c5,Add share extend API,MERGED,2015-05-13 10:05:28.000000000,2015-05-27 19:11:46.000000000,2015-05-27 19:11:44.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-13 10:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/c424b43bb1a840260c1691c7cf90d65d56b14790', 'message': 'Add share extend API\n\nImplement API method and shell command for extending\nshares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\nChange-Id: I1fadd514de4d9ae000cf0921262edd2bb111f5c5\n'}, {'number': 2, 'created': '2015-05-15 08:29:55.000000000', 'files': ['manilaclient/v1/shares.py', 'manilaclient/tests/unit/v1/fakes.py', 'manilaclient/tests/unit/v1/test_shell.py', 'manilaclient/tests/unit/v1/test_shares.py', 'manilaclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/916ae8cb632043b46a67e43467f3b8c2ee4f6f54', 'message': 'Add share extend API\n\nImplement API method and shell command for extending\nshares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\nChange-Id: I1fadd514de4d9ae000cf0921262edd2bb111f5c5\n'}]",2,182606,916ae8cb632043b46a67e43467f3b8c2ee4f6f54,17,8,2,14232,,,0,"Add share extend API

Implement API method and shell command for extending
shares similar to Cinder:
""manila extend <share-id> <new-size>""

Change-Id: I1fadd514de4d9ae000cf0921262edd2bb111f5c5
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/06/182606/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/v1/shares.py', 'manilaclient/tests/unit/v1/fakes.py', 'manilaclient/tests/unit/v1/test_shell.py', 'manilaclient/tests/unit/v1/test_shares.py', 'manilaclient/v1/shell.py']",5,c424b43bb1a840260c1691c7cf90d65d56b14790,bp/share-extend-api," @cliutils.arg('share', metavar='<share>', help='Name or ID of share to extend.') @cliutils.arg('new_size', metavar='<new_size>', type=int, help='New size of share, in GBs.') @cliutils.service_type('share') def do_extend(cs, args): """"""Attempts to extend size of an existing share."""""" share = _find_share(cs, args.share) cs.shares.extend(share, args.new_size)",,43,0
openstack%2Fmanila~stable%2Fkilo~I719c8ece9fcaf9dcc484fb6c522997d2856cc4a3,openstack/manila,stable/kilo,I719c8ece9fcaf9dcc484fb6c522997d2856cc4a3,Release Neutron ports after share server deletion using generic driver,MERGED,2015-05-19 12:06:40.000000000,2015-05-27 19:07:43.000000000,2015-05-27 19:07:40.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-19 12:06:40.000000000', 'files': ['manila/share/drivers/service_instance.py', 'manila/tests/share/drivers/test_service_instance.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b27132d8b4e17b739d49802e231ce352c705dc43', 'message': 'Release Neutron ports after share server deletion using generic driver\n\nGeneric driver creates ports in Neutron for each share server but does not\ndelete it with deletion of share servers. It leads to orphaning of ports and\nfixed ip leak. So, write their IDs to share server details and release ports\nafter share server deletion.\n\nChange-Id: I719c8ece9fcaf9dcc484fb6c522997d2856cc4a3\nCloses-Bug: #1453191\n(cherry picked from commit c75db095a25b7e649a5f26fb16cd8855cff1fae9)\n'}]",2,184231,b27132d8b4e17b739d49802e231ce352c705dc43,9,7,1,8851,,,0,"Release Neutron ports after share server deletion using generic driver

Generic driver creates ports in Neutron for each share server but does not
delete it with deletion of share servers. It leads to orphaning of ports and
fixed ip leak. So, write their IDs to share server details and release ports
after share server deletion.

Change-Id: I719c8ece9fcaf9dcc484fb6c522997d2856cc4a3
Closes-Bug: #1453191
(cherry picked from commit c75db095a25b7e649a5f26fb16cd8855cff1fae9)
",git fetch https://review.opendev.org/openstack/manila refs/changes/31/184231/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/service_instance.py', 'manila/tests/share/drivers/test_service_instance.py']",2,b27132d8b4e17b739d49802e231ce352c705dc43,," @ddt.data( dict(), dict(service_port_id='fake_service_port_id'), dict(public_port_id='fake_public_port_id'), dict(service_port_id='fake_service_port_id', public_port_id='fake_public_port_id'), ) def test_set_up_service_instance(self, update_data): fake_server.update(update_data) public_port=dict(id='fake_public_port', fixed_ips=[dict(ip_address=ip_address)]), service_port=dict(id='fake_service_port', fixed_ips=[dict(ip_address=ip_address)]))) id=server_get['id'], status=server_get['status'], pk_path=key_data[1], public_address=ip_address, router_id=network_data.get('router_id'), subnet_id=network_data.get('subnet_id'), instance_id=server_get['id'], ip=ip_address, networks=server_get['networks']) expected['public_port_id'] = 'fake_public_port' expected['service_port_id'] = 'fake_service_port' @ddt.data( *[dict(server_details=sd, fail=f) for f in (True, False) for sd in (dict(service_port_id='fake_service_port_id'), dict(public_port_id='fake_public_port_id'), dict(service_port_id='fake_service_port_id', public_port_id='fake_public_port_id'))] ) @ddt.unpack def test_teardown_network_with_ports(self, server_details, fail): instance = self._init_neutron_network_plugin() self.mock_object( service_instance.neutron.API, 'router_remove_interface') if fail: delete_port_mock = mock.Mock( side_effect=exception.NetworkException(code=404)) else: delete_port_mock = mock.Mock() self.mock_object(instance.neutron_api, 'delete_port', delete_port_mock) self.mock_object(service_instance.LOG, 'debug') instance.teardown_network(server_details) self.assertFalse(instance.neutron_api.router_remove_interface.called) self.assertEqual( len(server_details), len(instance.neutron_api.delete_port.mock_calls)) for k, v in server_details.items(): self.assertIn( mock.call(v), instance.neutron_api.delete_port.mock_calls) if fail: service_instance.LOG.debug.assert_has_calls([ mock.call(mock.ANY, mock.ANY) for sd in server_details ]) else: service_instance.LOG.debug.assert_has_calls([]) @ddt.data( dict(service_port_id='fake_service_port_id'), dict(public_port_id='fake_public_port_id'), dict(service_port_id='fake_service_port_id', public_port_id='fake_public_port_id'), ) def test_teardown_network_with_ports_unhandled_exception(self, server_details): instance = self._init_neutron_network_plugin() self.mock_object( service_instance.neutron.API, 'router_remove_interface') delete_port_mock = mock.Mock( side_effect=exception.NetworkException(code=500)) self.mock_object( service_instance.neutron.API, 'delete_port', delete_port_mock) self.mock_object(service_instance.LOG, 'debug') self.assertRaises( exception.NetworkException, instance.teardown_network, server_details, ) self.assertFalse( service_instance.neutron.API.router_remove_interface.called) service_instance.neutron.API.delete_port.assert_called_once(mock.ANY) service_instance.LOG.debug.assert_has_calls([]) def test_teardown_network_with_wrong_ports(self): instance = self._init_neutron_network_plugin() self.mock_object( service_instance.neutron.API, 'router_remove_interface') self.mock_object( service_instance.neutron.API, 'delete_port') self.mock_object(service_instance.LOG, 'debug') instance.teardown_network(dict(foo_id='fake_service_port_id')) service_instance.neutron.API.router_remove_interface.assert_has_calls( []) service_instance.neutron.API.delete_port.assert_has_calls([]) service_instance.LOG.debug.assert_has_calls([]) "," def test_set_up_service_instance(self): public_port=dict(fixed_ips=[dict(ip_address=ip_address)]), service_port=dict(fixed_ips=[dict(ip_address=ip_address)]))) id=server_get['id'], status=server_get['status'], pk_path=key_data[1], public_address=ip_address, ip=ip_address, networks=server_get['networks'])",128,6
openstack%2Fbandit~master~I81f570a6ac5c9c97f9fbedfc3fd34ebfe61c6e15,openstack/bandit,master,I81f570a6ac5c9c97f9fbedfc3fd34ebfe61c6e15,Refactor BanditResultStore.report,MERGED,2015-05-26 22:44:43.000000000,2015-05-27 19:07:32.000000000,2015-05-27 19:07:31.000000000,"[{'_account_id': 3}, {'_account_id': 7473}, {'_account_id': 11716}, {'_account_id': 11861}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-26 22:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/ee5f45d408a1ab7e4f43b606afa6dde7f0ef31a6', 'message': 'Refactor BanditResultStore.report\n\nInstead of adding a new elif branch inside that try-except block, it\nmakes more sense to move the actual writing of results to a private\nmethod. That keeps the try portion of the try-except block small and\nallows for new additions to the if/elif/else tree to be localized to\none, well-named method.\n\nChange-Id: I81f570a6ac5c9c97f9fbedfc3fd34ebfe61c6e15\n'}, {'number': 2, 'created': '2015-05-27 16:54:12.000000000', 'files': ['bandit/core/result_store.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/de9de9bb5794ff4446e030b9c160b4b91e672438', 'message': 'Refactor BanditResultStore.report\n\nInstead of adding a new elif branch inside that try-except block, it\nmakes more sense to move the actual writing of results to a private\nmethod. That keeps the try portion of the try-except block small and\nallows for new additions to the if/elif/else tree to be localized to\none, well-named method.\n\nChange-Id: I81f570a6ac5c9c97f9fbedfc3fd34ebfe61c6e15\n'}]",10,185769,de9de9bb5794ff4446e030b9c160b4b91e672438,15,5,2,12000,,,0,"Refactor BanditResultStore.report

Instead of adding a new elif branch inside that try-except block, it
makes more sense to move the actual writing of results to a private
method. That keeps the try portion of the try-except block small and
allows for new additions to the if/elif/else tree to be localized to
one, well-named method.

Change-Id: I81f570a6ac5c9c97f9fbedfc3fd34ebfe61c6e15
",git fetch https://review.opendev.org/openstack/bandit refs/changes/69/185769/1 && git format-patch -1 --stdout FETCH_HEAD,['bandit/core/result_store.py'],1,ee5f45d408a1ab7e4f43b606afa6dde7f0ef31a6,format-refactor," def _write_report(self, files_list, scores, excluded_files): if self.format == 'json': format_func = self._report_json elif self.format == 'csv': self.max_lines = 1 format_func = self._report_csv elif self.format == 'xml': format_func = self._report_xml else: format_func = self._report_text # format is the default ""txt"" if self.out_file: # output to file, specify plain text self.format = 'plain' format_func(files_list, scores, excluded_files=excluded_files) self._write_report(files_list, scores, excluded_files)"," if self.format == 'json': self._report_json(files_list, scores, excluded_files=excluded_files) elif self.format == 'csv': self.max_lines = 1 self._report_csv(files_list, scores, excluded_files=excluded_files) elif self.format == 'xml': self._report_xml(files_list, scores, excluded_files=excluded_files) else: # format is the default ""txt"" if self.out_file: # output to file, specify plain text self.format = 'plain' self._report_text(files_list, scores, excluded_files=excluded_files) ",18,20
openstack%2Fbandit~master~Ie4de1ea174fb9fff644285b2198d20dc5b0893e6,openstack/bandit,master,Ie4de1ea174fb9fff644285b2198d20dc5b0893e6,Add XML output format support,MERGED,2015-05-21 18:52:00.000000000,2015-05-27 19:07:25.000000000,2015-05-27 19:07:25.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 11861}, {'_account_id': 12000}, {'_account_id': 14692}, {'_account_id': 15173}, {'_account_id': 16195}]","[{'number': 1, 'created': '2015-05-21 18:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/33c06848ff9f51be7ee5f7cceaa491c2a4d691fb', 'message': 'Add junit output format\n\nChange-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6\n'}, {'number': 2, 'created': '2015-05-23 14:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/6851ce4a7230b10c46953aa68ad9c25aaa20c3f2', 'message': 'Add XML output format support, generates an xml file which contains a\n<testsuite> element with <testcase> per bandit warning which contains an\n<error> element describing the exact warning message, severity, file and line\nnumber.\n\nThe XML output can be used to integrate bandit in Jenkins with either the Junit or Xunit test result report plugin.\n\nChange-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6\n'}, {'number': 3, 'created': '2015-05-25 12:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/57f120e5a057ef93af44b06d185470306578c3a1', 'message': 'Add XML output format support, generates an xml file which contains a\n<testsuite> element with <testcase> per bandit warning which contains an\n<error> element describing the exact warning message, severity, file and line\nnumber.\n\nThe XML output can be used to integrate bandit in Jenkins with either the Junit or Xunit test result report plugin.\n\nChange-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6\n'}, {'number': 4, 'created': '2015-05-26 19:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/b76d71ed72be35b764c9c4064d64784882bf6bba', 'message': 'Add XML output format support\n\nThis allows bandit to generates an xml file which contains a\n<testsuite> element with <testcase> per bandit warning which contains an\n<error> element describing the exact warning message, severity, file\nand line number. The XML output can be used to integrate bandit in\nJenkins with either the Junit or Xunit test result report plugin.\n\nChange-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6\n'}, {'number': 5, 'created': '2015-05-26 20:38:20.000000000', 'files': ['bandit/core/result_store.py', 'bandit/bandit.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/99e4d98201e3235f55aa39165e4c3bca8f9d1cd8', 'message': 'Add XML output format support\n\nThis allows bandit to generates an xml file which contains a\n<testsuite> element with <testcase> per bandit warning which contains an\n<error> element describing the exact warning message, severity, file\nand line number. The XML output can be used to integrate bandit in\nJenkins with either the Junit or Xunit test result report plugin.\n\nChange-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6\n'}]",22,184848,99e4d98201e3235f55aa39165e4c3bca8f9d1cd8,38,10,5,16195,,,0,"Add XML output format support

This allows bandit to generates an xml file which contains a
<testsuite> element with <testcase> per bandit warning which contains an
<error> element describing the exact warning message, severity, file
and line number. The XML output can be used to integrate bandit in
Jenkins with either the Junit or Xunit test result report plugin.

Change-Id: Ie4de1ea174fb9fff644285b2198d20dc5b0893e6
",git fetch https://review.opendev.org/openstack/bandit refs/changes/48/184848/5 && git format-patch -1 --stdout FETCH_HEAD,"['bandit/core/result_store.py', 'bandit/bandit.py']",2,33c06848ff9f51be7ee5f7cceaa491c2a4d691fb,junit_output," choices=['txt', 'json', 'csv', 'junit']"," choices=['txt', 'json', 'csv']",34,1
openstack%2Ftripleo-ci~master~Ic49eabe12999e50c3624f7739ec85f5b56bbeb0f,openstack/tripleo-ci,master,Ic49eabe12999e50c3624f7739ec85f5b56bbeb0f,Pin puppetlabs-mysql,ABANDONED,2015-05-27 14:25:59.000000000,2015-05-27 19:02:27.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-27 14:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/862eab2ff6f168ab80204fe6a56dcdf0bdde519d', 'message': 'Pin puppetlabs-mysql\n\nPin puppetlabs-mysql so we are not impacted by a commit that breaks CI[1]\n\nChange-Id: Ic49eabe12999e50c3624f7739ec85f5b56bbeb0f\nRelated-Bug: #1459266\n'}, {'number': 2, 'created': '2015-05-27 15:22:43.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/009b76635ecb7342885bd9745b7b6ebf717cf867', 'message': 'Pin puppetlabs-mysql\n\nPin puppetlabs-mysql so we are not impacted by a commit that breaks CI[1]\n\n[1]\nhttps://github.com/puppetlabs/puppetlabs-mysql/commit/4bab65edcb98f82f87a4414840fe90ab81b6cea3\n\nChange-Id: Ic49eabe12999e50c3624f7739ec85f5b56bbeb0f\nRelated-Bug: #1459266\n'}]",1,186016,009b76635ecb7342885bd9745b7b6ebf717cf867,11,4,2,9410,,,0,"Pin puppetlabs-mysql

Pin puppetlabs-mysql so we are not impacted by a commit that breaks CI[1]

[1]
https://github.com/puppetlabs/puppetlabs-mysql/commit/4bab65edcb98f82f87a4414840fe90ab81b6cea3

Change-Id: Ic49eabe12999e50c3624f7739ec85f5b56bbeb0f
Related-Bug: #1459266
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/16/186016/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,862eab2ff6f168ab80204fe6a56dcdf0bdde519d,mysql_pin,# https://bugs.launchpad.net/tripleo/+bug/1459266 export DIB_REPOREF_puppetlabs_mysql=18e45a0d8f75d187cd64829e38429fac4fffd404,,2,0
openstack%2Frally~master~Iff9daf4a412a27011bb21b2860558fda6574db34,openstack/rally,master,Iff9daf4a412a27011bb21b2860558fda6574db34,Set Python2.7 as basepython for testenv,MERGED,2015-05-26 06:00:04.000000000,2015-05-27 18:45:55.000000000,2015-05-27 18:45:51.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-26 06:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/144deb76726d65a17f6f569b31aa683914feff80', 'message': 'Set Python2.7 as basepython for testenv\n\nBased on:\n * default python can be different at different operation systems;\n * test environment should not depend on system in which it created;\n * Python2.7 is used by default in gates\n\nit would be nice to set Python2.7 as python interpreter for testenvs in\ntox configuration file.\n\nChange-Id: Iff9daf4a412a27011bb21b2860558fda6574db34\n'}, {'number': 2, 'created': '2015-05-26 17:25:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/rally/commit/95a5fd3c42f2b61cbf1baf7af09f9ea4dd1e730a', 'message': 'Set Python2.7 as basepython for testenv\n\nBased on:\n * default python can be different at different operation systems;\n * test environment should not depend on system in which it created;\n * Python2.7 is used by default in gates\n\nit would be nice to set Python2.7 as python interpreter for testenvs in\ntox configuration file.\n\nChange-Id: Iff9daf4a412a27011bb21b2860558fda6574db34\n'}]",0,185500,95a5fd3c42f2b61cbf1baf7af09f9ea4dd1e730a,19,5,2,9545,,,0,"Set Python2.7 as basepython for testenv

Based on:
 * default python can be different at different operation systems;
 * test environment should not depend on system in which it created;
 * Python2.7 is used by default in gates

it would be nice to set Python2.7 as python interpreter for testenvs in
tox configuration file.

Change-Id: Iff9daf4a412a27011bb21b2860558fda6574db34
",git fetch https://review.opendev.org/openstack/rally refs/changes/00/185500/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,144deb76726d65a17f6f569b31aa683914feff80,testr,basepython = python2.7,,1,0
openstack%2Ftooz~stable%2Fjuno~Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640,openstack/tooz,stable/juno,Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640,Cap kazoo and zake from stable/juno global-requirements,MERGED,2015-05-27 17:04:28.000000000,2015-05-27 18:39:14.000000000,2015-05-27 18:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5638}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-05-27 17:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/74d239963951c82a486511e200b150f49cde2a79', 'message': 'Manually sync global-requirements for stable/juno\n\nNow that we have a stable/juno branch from the 0.12 git tag, sync the\nglobal-requirements versions from stable/juno.\n\nNote that pymemcache, PyMySQL and sysv_ipc are not in\nglobal-requirements.txt in stable/juno so those versions are left\nintact.\n\nPartial-RTC: #1459322\n\nChange-Id: Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640\n'}, {'number': 2, 'created': '2015-05-27 17:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/347d246dcaf9400b631de2be8ac857d0b334885e', 'message': 'Cap kazoo and zake from stable/juno global-requirements\n\nThe latest version of zake blocks kazoo 2.1 which causes version\nconflicts in stable/juno jobs.\n\nCap kazoo and zake using the values from global-requirements in\nstable/juno so that we can unblock stable/juno and stable/kilo (due to\ngrenade jobs on kilo).\n\nPartial-RTC: #1459322\n\nChange-Id: Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640'}, {'number': 3, 'created': '2015-05-27 18:21:08.000000000', 'files': ['requirements.txt', '.gitreview', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/tooz/commit/bd86d31d6ecda984e2f5863ce26f4d2b19a81665', 'message': 'Cap kazoo and zake from stable/juno global-requirements\n\nThe latest version of zake blocks kazoo 2.1 which causes version\nconflicts in stable/juno jobs.\n\nCap kazoo and zake using the values from global-requirements in\nstable/juno so that we can unblock stable/juno and stable/kilo (due to\ngrenade jobs on kilo).\n\nAlso updates .gitreview for stable/juno since this is the first\ncommit to stable/juno for tooz.\n\nPartial-RTC: #1459322\n\nChange-Id: Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640\n'}]",0,186084,bd86d31d6ecda984e2f5863ce26f4d2b19a81665,13,6,3,6873,,,0,"Cap kazoo and zake from stable/juno global-requirements

The latest version of zake blocks kazoo 2.1 which causes version
conflicts in stable/juno jobs.

Cap kazoo and zake using the values from global-requirements in
stable/juno so that we can unblock stable/juno and stable/kilo (due to
grenade jobs on kilo).

Also updates .gitreview for stable/juno since this is the first
commit to stable/juno for tooz.

Partial-RTC: #1459322

Change-Id: Ib6f79cfcd18a758ce4b2a86f3ff323d533db4640
",git fetch https://review.opendev.org/openstack/tooz refs/changes/84/186084/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py', 'requirements-py3.txt']",4,74d239963951c82a486511e200b150f49cde2a79,bug/1459322,"# The order of packages is significant, because pip processes them in the order # of appearance. Changing the order has an impact on the overall integration # process, which may cause wedges in the gate later.Babel>=1.3,<=1.3 stevedore>=1.0.0,<=1.3.0 # Apache-2.0 six>=1.7.0,<=1.9.0 iso8601>=0.1.9,<=0.1.10 kazoo>=1.3.1,<=2.0zake>=0.1,<=0.1.7 # Apache-2.0 msgpack-python>=0.4.0,<=0.4.5 retrying>=1.2.2,!=1.3.0,<=1.3.3 # Apache-2.0 oslo.utils>=1.4.0,<1.5.0 # Apache-2.0 redis<=2.10.3","Babel>=1.3 stevedore>=1.1.0 six>=1.7.0 iso8601 kazoo>=1.3.1zake>=0.1.6 msgpack-python>=0.4.0 retrying>=1.2.3,!=1.3.0 oslo.utils>=1.0.0 redis",48,33
openstack%2Fmanila~master~Ib00958feff7b0ed9abe2ddde82a78c88e5325a44,openstack/manila,master,Ib00958feff7b0ed9abe2ddde82a78c88e5325a44,Simplify generic driver with private data storage API,MERGED,2015-04-27 08:33:22.000000000,2015-05-27 18:36:57.000000000,2015-05-27 18:36:55.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7652}, {'_account_id': 8851}, {'_account_id': 9382}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}, {'_account_id': 14567}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-04-27 08:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/44cf822bfb7de935f2a07fe09d1addd2306397e7', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 2, 'created': '2015-04-27 13:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8dc259bef166b7d2ad9c18291ff8b40a91a476ce', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 3, 'created': '2015-04-29 13:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1b2f9787e8a6134086d251c94a92e44f6fd6ad87', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 4, 'created': '2015-04-30 09:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b1b9bc8cd612e338bb23ae609a521228aa1ac075', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 5, 'created': '2015-05-05 10:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/30ce452ec5b97d70b5a23896d1a82c882f287e5b', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 6, 'created': '2015-05-05 10:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/06039dea0bbdf693ffe66141ec2724b334d6061e', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 7, 'created': '2015-05-07 13:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cd71c5ccad0a0c75cdbb320bcd5ec6f9a9a02bfe', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 8, 'created': '2015-05-08 09:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/da45b664cf2601da6da8410662dd566066aacb2f', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 9, 'created': '2015-05-08 11:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c1b80fd5330becb809120cd5a37a91f63ae1452f', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 10, 'created': '2015-05-26 14:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9a1f048cd9782f4e631ceed3565479d46b9dfb58', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}, {'number': 11, 'created': '2015-05-26 14:58:23.000000000', 'files': ['manila/tests/share/drivers/test_generic.py', 'manila/share/drivers/generic.py', 'manila/tests/fake_volume.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/7ea33170924a85d8206fe5011436f47a726fbccb', 'message': 'Simplify generic driver with private data storage API\n\n- Save volume_id in private data storage (PDS)\n- Save volume_snapshot_id in PDS\n- Simplify manage_existing() method\n- Add appropriate unit tests\n\nPartially Implements bp private-data-storage-api-for-drivers\n\nChange-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44\n'}]",12,177679,7ea33170924a85d8206fe5011436f47a726fbccb,51,12,11,14232,,,0,"Simplify generic driver with private data storage API

- Save volume_id in private data storage (PDS)
- Save volume_snapshot_id in PDS
- Simplify manage_existing() method
- Add appropriate unit tests

Partially Implements bp private-data-storage-api-for-drivers

Change-Id: Ib00958feff7b0ed9abe2ddde82a78c88e5325a44
",git fetch https://review.opendev.org/openstack/manila refs/changes/79/177679/11 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/test_generic.py', 'manila/share/drivers/generic.py']",2,44cf822bfb7de935f2a07fe09d1addd2306397e7,bp/private-data-storage-api-for-drivers," def __init__(self, private_storage, *args, **kwargs): self.private_storage = private_storage volume_id = self.private_storage.get(share_id, 'volume_id') if volume_id is not None: return self.volume_api.get(context, volume_id) else: # Fallback to legacy method return self._get_volume_legacy(context, share_id) def _get_volume_legacy(self, context, share_id): # NOTE(u_glide): this method should be deprecated and removed in # feature versions volume_snapshot_id = self.private_storage.get( snapshot_id, 'volume_snapshot_id') if volume_snapshot_id is not None: return self.volume_api.get_snapshot(context, volume_snapshot_id) else: # Fallback to legacy method return self._get_volume_snapshot_legacy(context, snapshot_id) def _get_volume_snapshot_legacy(self, context, snapshot_id): # NOTE(u_glide): this method should be deprecated and removed in # feature versions self.private_storage.update( share['id'], {'volume_id': volume['id']}) self.private_storage.delete(share['id']) self.private_storage.update( snapshot['id'], {'volume_snapshot_id': volume_snapshot['id']}) self.private_storage.delete(snapshot['id']) self.private_storage.update( share['id'], {'volume_id': share_volume['id']})"," def __init__(self, *args, **kwargs): linked_volume_name = self._get_volume_name(share['id']) if share_volume['name'] != linked_volume_name: LOG.debug('Manage: volume_id = %s' % share_volume['id']) self.volume_api.update(self.admin_context, share_volume['id'], {'name': linked_volume_name})",74,12
openstack%2Fmanila~master~I61b3cc41f545b540101819feb603e45d0a057a4e,openstack/manila,master,I61b3cc41f545b540101819feb603e45d0a057a4e,Provide private data storage API for drivers,MERGED,2015-04-23 15:56:51.000000000,2015-05-27 18:35:12.000000000,2015-05-27 18:35:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 7652}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}, {'_account_id': 14567}]","[{'number': 1, 'created': '2015-04-23 15:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9d49aae71fb51ababd3c802c674c424208b26a52', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage (PDS) API\n- Simplify generic driver with PDS API\n- Add appropriate unit tests\n\nImplements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 2, 'created': '2015-04-24 13:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e1ac11d900040cd5f513343d8cfc6c07ca425e36', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage (PDS) API\n- Simplify generic driver with PDS API\n- Add appropriate unit tests\n\nImplements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 3, 'created': '2015-04-27 08:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/66080504f1456df5b71216d1847cd291f227c97d', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 4, 'created': '2015-04-27 13:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/936dfce16d14e3aee24d5d99403eb97afd65d219', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 5, 'created': '2015-04-29 12:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f46d53868dd9af8f771743e83c04f36db2d682d2', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 6, 'created': '2015-04-29 13:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ebbe50505e46a100abb32adea170d98829729127', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 7, 'created': '2015-04-30 09:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6a2911851dd6be0955f8341724ab9a0f6caff8fe', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 8, 'created': '2015-05-05 10:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d37a9726caaba821e55e5a260f3554d986a3dcff', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 9, 'created': '2015-05-07 12:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ff38a3de7ef228305a7ab647a5efadbfc5df64d7', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 10, 'created': '2015-05-08 09:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b7bbc648facb9ffcb45a7cb395e1ec92639e7ea9', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 11, 'created': '2015-05-08 09:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f2bd6d27d29520a61841424cc1edac6dae3bf41d', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 12, 'created': '2015-05-08 11:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d894ab165b054813175f08bb4ce0531f319c461d', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 13, 'created': '2015-05-12 12:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/63953878a4c6d39eab8d4f7200a889b5722f3b30', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}, {'number': 14, 'created': '2015-05-26 14:53:17.000000000', 'files': ['manila/tests/share/test_drivers_private_data.py', 'manila/db/api.py', 'manila/db/sqlalchemy/models.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/migrations/alembic/versions/3a482171410f_add_drivers_private_data_table.py', 'manila/db/sqlalchemy/api.py', 'manila/share/manager.py', 'manila/opts.py', 'manila/tests/share/test_manager.py', 'manila/share/drivers_private_data.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8953627967c49e38490c0a0dce82b51560177b3b', 'message': 'Provide private data storage API for drivers\n\n- Add implementation of private data storage API\n- Add appropriate unit tests\n\nPartially implements bp private-data-storage-api-for-drivers\n\nChange-Id: I61b3cc41f545b540101819feb603e45d0a057a4e\n'}]",137,176877,8953627967c49e38490c0a0dce82b51560177b3b,93,11,14,14232,,,0,"Provide private data storage API for drivers

- Add implementation of private data storage API
- Add appropriate unit tests

Partially implements bp private-data-storage-api-for-drivers

Change-Id: I61b3cc41f545b540101819feb603e45d0a057a4e
",git fetch https://review.opendev.org/openstack/manila refs/changes/77/176877/14 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/api.py', 'manila/db/sqlalchemy/models.py', 'manila/db/sqlalchemy/api.py', 'manila/share/drivers/private_driver_data.py', 'manila/share/manager.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/share/drivers/test_private_driver_data.py', 'manila/tests/test_db.py', 'manila/share/drivers/generic.py', 'manila/tests/fake_volume.py', 'manila/db/migrations/alembic/versions/3a482171410f_add_private_driver_data_table.py']",11,9d49aae71fb51ababd3c802c674c424208b26a52,bp/private-data-storage-api-for-drivers,"# Copyright 2015 Mirantis inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""add_private_driver_data_table Revision ID: 3a482171410f Revises: 56cdbe267881 Create Date: 2015-04-21 14:47:38.201658 """""" # revision identifiers, used by Alembic. revision = '3a482171410f' down_revision = '56cdbe267881' from alembic import op from oslo_log import log import sqlalchemy as sql from manila.i18n import _LE LOG = log.getLogger(__name__) def upgrade(): try: op.create_table( 'private_drivers_data', sql.Column('created_at', sql.DateTime), sql.Column('updated_at', sql.DateTime), sql.Column('deleted_at', sql.DateTime), sql.Column('deleted', sql.Integer, default=0), sql.Column('host', sql.String(255), nullable=False, primary_key=True), sql.Column('entity_uuid', sql.String(36), nullable=False, primary_key=True), sql.Column('key', sql.String(255), nullable=False, primary_key=True), sql.Column('value', sql.String(1023), nullable=False), sql.UniqueConstraint('host', 'entity_uuid', 'key', 'deleted', name=""pdd_id_uc""), mysql_engine='InnoDB', ) except Exception: LOG.error(_LE(""Table |%s| not created!""), 'private_drivers_data') raise def downgrade(): try: op.drop_table('private_drivers_data') except Exception: LOG.error(_LE(""private_drivers_data table not dropped"")) raise ",,601,14
openstack%2Ftripleo-ci~master~Ie11b8d29728dd46d7b246589f4e0872b378d7383,openstack/tripleo-ci,master,Ie11b8d29728dd46d7b246589f4e0872b378d7383,Remove nova temprevert,MERGED,2015-05-13 14:25:00.000000000,2015-05-27 18:27:58.000000000,2015-05-27 18:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 7144}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-13 14:25:00.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c39a66b8cde8d7485336f6fa5aaa09657dc551ad', 'message': 'Remove nova temprevert\n\nNow that we are no longer using the removed ironic option of linking\nramdisk/kernel to flavors we no longer need this temprevert.\n\nChange-Id: Ie11b8d29728dd46d7b246589f4e0872b378d7383\nDepends-On: I494e3579c3daad7bf13a8127cf83cc61f82f913a\n'}]",0,182695,c39a66b8cde8d7485336f6fa5aaa09657dc551ad,15,4,1,1926,,,0,"Remove nova temprevert

Now that we are no longer using the removed ironic option of linking
ramdisk/kernel to flavors we no longer need this temprevert.

Change-Id: Ie11b8d29728dd46d7b246589f4e0872b378d7383
Depends-On: I494e3579c3daad7bf13a8127cf83cc61f82f913a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/95/182695/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,c39a66b8cde8d7485336f6fa5aaa09657dc551ad,,,# https://review.openstack.org/#/c/167341/ temprevert nova a50163be49922013652047823e5922eda998d68c 1453076,0,2
openstack%2Fproject-config~master~Ib522d39627adf3042c78017f7a575adcc37b79c7,openstack/project-config,master,Ib522d39627adf3042c78017f7a575adcc37b79c7,Upload ical output to log server,MERGED,2015-05-27 16:54:05.000000000,2015-05-27 18:26:48.000000000,2015-05-27 18:26:46.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-27 16:54:05.000000000', 'files': ['jenkins/jobs/infra.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2a75012dc3ee3ffbdf408a6e5a4cb5f5fba197aa', 'message': 'Upload ical output to log server\n\nThe output location for these files has changed.  Update the job\nto correctly include them again.\n\nChange-Id: Ib522d39627adf3042c78017f7a575adcc37b79c7\n'}]",0,186081,2a75012dc3ee3ffbdf408a6e5a4cb5f5fba197aa,8,4,1,1,,,0,"Upload ical output to log server

The output location for these files has changed.  Update the job
to correctly include them again.

Change-Id: Ib522d39627adf3042c78017f7a575adcc37b79c7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/186081/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/infra.yaml'],1,2a75012dc3ee3ffbdf408a6e5a4cb5f5fba197aa,, upload_source: 'output/*', upload_source: 'output.ical output.html',1,1
openstack%2Fkeystone~master~I48cfa5d524338e046b9049280a142702fa961b3d,openstack/keystone,master,I48cfa5d524338e046b9049280a142702fa961b3d,Update dev setup requirements for Python 3.4,MERGED,2015-04-19 15:15:56.000000000,2015-05-27 18:24:13.000000000,2015-05-27 18:24:11.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8119}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-04-19 15:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d91979cbe35601a2231da511c2fe9b8c89fbe41b', 'message': 'Update dev setup requirements for py3\n\nThe functional tests use py3, so add the package for Ubuntu setup.\n\nChange-Id: I48cfa5d524338e046b9049280a142702fa961b3d\n'}, {'number': 2, 'created': '2015-05-10 16:36:05.000000000', 'files': ['doc/source/setup.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6e9c4ec8ddbb8ab9a0aacebaed78d66c22efb9d', 'message': 'Update dev setup requirements for Python 3.4\n\nThe functional tests use Python 3.4 so document that both Python\n2.7 and Python 3.4 are required for development and add\npython3-dev to the required packages for Ubuntu.\n\nChange-Id: I48cfa5d524338e046b9049280a142702fa961b3d\n'}]",6,175216,f6e9c4ec8ddbb8ab9a0aacebaed78d66c22efb9d,16,6,2,6486,,,0,"Update dev setup requirements for Python 3.4

The functional tests use Python 3.4 so document that both Python
2.7 and Python 3.4 are required for development and add
python3-dev to the required packages for Ubuntu.

Change-Id: I48cfa5d524338e046b9049280a142702fa961b3d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/16/175216/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/setup.rst'],1,d91979cbe35601a2231da511c2fe9b8c89fbe41b,doc_setup, $ sudo apt-get install python-dev python3-dev libxml2-dev libxslt1-dev \ libsasl2-dev libsqlite3-dev libssl-dev libldap2-dev libffi-dev, $ sudo apt-get install python-dev libxml2-dev libxslt1-dev libsasl2-dev libsqlite3-dev libssl-dev libldap2-dev libffi-dev,2,1
openstack%2Fos-client-config~master~I66c59c6acdbb930f013d4742d5b3cc7e35a922d4,openstack/os-client-config,master,I66c59c6acdbb930f013d4742d5b3cc7e35a922d4,Capture the filename used for config,MERGED,2015-05-27 12:58:05.000000000,2015-05-27 18:24:01.000000000,2015-05-27 18:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/fabdd4f890a3eadbbf2e9f03ecf48b9554d87785', 'message': 'Capture the filename used for config\n\nConsumers who may want to watch for config file changes would find such\na thing interesting information.\n\nChange-Id: I66c59c6acdbb930f013d4742d5b3cc7e35a922d4\n'}, {'number': 2, 'created': '2015-05-27 13:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/f67169f1b12c79efd221fe674a35728db26c1866', 'message': 'Capture the filename used for config\n\nConsumers who may want to watch for config file changes would find such\na thing interesting information.\n\nChange-Id: I66c59c6acdbb930f013d4742d5b3cc7e35a922d4\n'}, {'number': 3, 'created': '2015-05-27 16:11:39.000000000', 'files': ['os_client_config/config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/5a4f809caf2223121803debab2e6ac52bc943116', 'message': 'Capture the filename used for config\n\nConsumers who may want to watch for config file changes would find such\na thing interesting information.\n\nChange-Id: I66c59c6acdbb930f013d4742d5b3cc7e35a922d4\n'}]",0,185968,5a4f809caf2223121803debab2e6ac52bc943116,12,4,3,2,,,0,"Capture the filename used for config

Consumers who may want to watch for config file changes would find such
a thing interesting information.

Change-Id: I66c59c6acdbb930f013d4742d5b3cc7e35a922d4
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/68/185968/2 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/config.py'],1,fabdd4f890a3eadbbf2e9f03ecf48b9554d87785,," self.config_filename, self.cloud_config = self._load_config_file() return path, self._normalize_keys(yaml.safe_load(f)) return (None, None) vendor_filename, vendor_file = self._load_vendor_file()", self.cloud_config = self._load_config_file() return self._normalize_keys(yaml.safe_load(f)) vendor_file = self._load_vendor_file(),4,3
openstack%2Fos-client-config~master~Ibd834f7a70cf2285619b5499492858b21635ba57,openstack/os-client-config,master,Ibd834f7a70cf2285619b5499492858b21635ba57,Normalize all keys down to _ instead of -,MERGED,2015-05-27 12:58:05.000000000,2015-05-27 18:23:55.000000000,2015-05-27 18:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 5263}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/3a72926a029a7b7730089cadd00b01b9a597de90', 'message': ""Normalize all keys down to _ instead of -\n\nIt's really common to use the config dict in a **kwargs context.\nTherefore, normalize every key with a - to use _ instead.\n\nTesting for this is done by changing one of the base region_name args\nto be region-name.\n\nChange-Id: Ibd834f7a70cf2285619b5499492858b21635ba57\n""}, {'number': 2, 'created': '2015-05-27 13:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/e7195ac4614fc19fee8c7eedc77f293b599bae05', 'message': ""Normalize all keys down to _ instead of -\n\nIt's really common to use the config dict in a **kwargs context.\nTherefore, normalize every key with a - to use _ instead.\n\nTesting for this is done by changing one of the base region_name args\nto be region-name.\n\nChange-Id: Ibd834f7a70cf2285619b5499492858b21635ba57\n""}, {'number': 3, 'created': '2015-05-27 16:11:39.000000000', 'files': ['os_client_config/config.py', 'os_client_config/tests/base.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/f3eb3d47bc51c5c4dbf8a609c27e99cf9abaca53', 'message': ""Normalize all keys down to _ instead of -\n\nIt's really common to use the config dict in a **kwargs context.\nTherefore, normalize every key with a - to use _ instead.\n\nTesting for this is done by changing one of the base region_name args\nto be region-name.\n\nChange-Id: Ibd834f7a70cf2285619b5499492858b21635ba57\n""}]",0,185967,f3eb3d47bc51c5c4dbf8a609c27e99cf9abaca53,14,5,3,2,,,0,"Normalize all keys down to _ instead of -

It's really common to use the config dict in a **kwargs context.
Therefore, normalize every key with a - to use _ instead.

Testing for this is done by changing one of the base region_name args
to be region-name.

Change-Id: Ibd834f7a70cf2285619b5499492858b21635ba57
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/67/185967/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_client_config/config.py', 'os_client_config/tests/base.py']",2,3a72926a029a7b7730089cadd00b01b9a597de90,," 'region-name': 'test-region',"," 'region_name': 'test-region',",14,4
openstack%2Fos-client-config~master~I77ab133634236d2a7a59ea805a6d650854165030,openstack/os-client-config,master,I77ab133634236d2a7a59ea805a6d650854165030,Expose method for getting a list of cloud names,MERGED,2015-05-27 12:58:05.000000000,2015-05-27 18:23:38.000000000,2015-05-27 18:23:37.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 5263}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/9184a9e141fbf0e5c068f96957226e02caed8ef6', 'message': 'Add method to get available cloud names\n\nKnowing what cloud names os-client-config found can be useful for\nintrospection or investigation.\n\nChange-Id: I77ab133634236d2a7a59ea805a6d650854165030\n'}, {'number': 2, 'created': '2015-05-27 13:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/c0f79b784e20ed1abf00a9e435e7b6f3c0fa85da', 'message': 'Add method to get available cloud names\n\nKnowing what cloud names os-client-config found can be useful for\nintrospection or investigation.\n\nChange-Id: I77ab133634236d2a7a59ea805a6d650854165030\n'}, {'number': 3, 'created': '2015-05-27 16:11:39.000000000', 'files': ['os_client_config/config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/a5dd46af2ede29580450ffad46ad1888cca4a9ac', 'message': 'Expose method for getting a list of cloud names\n\nKnowing what cloud names os-client-config found can be useful for\nintrospection or investigation.\n\nChange-Id: I77ab133634236d2a7a59ea805a6d650854165030\n'}]",0,185966,a5dd46af2ede29580450ffad46ad1888cca4a9ac,18,5,3,2,,,0,"Expose method for getting a list of cloud names

Knowing what cloud names os-client-config found can be useful for
introspection or investigation.

Change-Id: I77ab133634236d2a7a59ea805a6d650854165030
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/66/185966/2 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/config.py'],1,9184a9e141fbf0e5c068f96957226e02caed8ef6,, def get_cloud_names(self): return self.cloud_config['clouds'].keys() ,,3,0
openstack%2Fopenstacksdk~master~Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f,openstack/openstacksdk,master,Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f,metric: add support for generic resources,MERGED,2015-03-09 12:18:14.000000000,2015-05-27 18:21:01.000000000,2015-05-27 18:21:00.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-03-09 12:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c32d3573616a8ff01ef7ecdcfca32e2c8f9a7af8', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 2, 'created': '2015-03-09 13:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/584c45eae13a11bd0efccf51b22839e527f7756b', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 3, 'created': '2015-03-09 13:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/58273f1bd8c4ccf829766678cba4ca3ddd61b26c', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 4, 'created': '2015-03-09 14:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/dc7d93f32436cdf0ee960c2fdbb48e10c1c068b8', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 5, 'created': '2015-03-09 14:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ebeca0a525753abd03f940b4ee8ab6f9fa945f81', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 6, 'created': '2015-03-09 15:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eb92c8436b1e062d26457705235d95eb3fbb49fa', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 7, 'created': '2015-03-09 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/506f319a02f9bee6bd2c1a8bf0bf34f648567d21', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 8, 'created': '2015-03-09 17:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7ac096a47cc81deda6fc42f759b2d1840f9bd076', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 9, 'created': '2015-03-24 10:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e57ca39a330a2428406b73629c47f1ab59f95b59', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 10, 'created': '2015-03-24 13:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/43a69c8fbedc8b9fe6ff3831cb1c71209ceab73f', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}, {'number': 11, 'created': '2015-03-24 14:11:39.000000000', 'files': ['openstack/metric/v1/resource.py', 'openstack/resource_types.py', 'openstack/tests/metric/v1/test_resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4f25972de91f06ee1018cd6ec0ea65e700c80813', 'message': 'metric: add support for generic resources\n\nChange-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f\n'}]",7,162620,4f25972de91f06ee1018cd6ec0ea65e700c80813,34,4,11,1669,,,0,"metric: add support for generic resources

Change-Id: Iafe6235998a1787c3c165bf3d59513b7cf6b4e7f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/162620/11 && git format-patch -1 --stdout FETCH_HEAD,['openstack/metric/v1/resource.py'],1,c32d3573616a8ff01ef7ecdcfca32e2c8f9a7af8,jd/gnocchi,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from openstack.metric import metric_service from openstack import resource class Generic(resource.Resource): base_path = '/resource/generic' service = metric_service.MetricService() # Supported Operations allow_create = True allow_retrieve = True allow_delete = True allow_list = True put_create = False # Properties id = resource.prop('id', alias=""resource_id"") created_by_user_id = resource.prop('created_by_user_id') created_by_project_id = resource.prop('created_by_project_id') user_id = resource.prop('user_id') project_id = resource.prop('project_id') started_at = resource.prop('started_at', type=datetime.datetime) ended_at = resource.prop('ended_at', type=datetime.datetime) metrics = resource.prop('ended_at', type=dict) ",,38,0
openstack%2Fopenstack-manuals~master~Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c,openstack/openstack-manuals,master,Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c,Network guide: add ethernet and arp,MERGED,2015-05-27 03:01:32.000000000,2015-05-27 18:19:24.000000000,2015-05-27 18:19:21.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-05-27 03:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fefd9d8498b05e5704e513b6f0c25eeb9c473da3', 'message': 'Network guide: add ethernet and arp\n\nChange-Id: Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c\n'}, {'number': 2, 'created': '2015-05-27 03:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/260a3fb7134fe38e02e6cdd73517060ead4a6671', 'message': 'Network guide: add ethernet and arp\n\nChange-Id: Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c\n'}, {'number': 3, 'created': '2015-05-27 13:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1cce4baad3f5155c08fb46cdf566cfdcc32b3620', 'message': 'Network guide: add ethernet and arp\n\nChange-Id: Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c\n'}, {'number': 4, 'created': '2015-05-27 15:09:46.000000000', 'files': ['doc/networking-guide/source/intro_basic_networking.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/209ef2f79ffccfd11feaa6c11db73823c65b8974', 'message': 'Network guide: add ethernet and arp\n\nChange-Id: Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c\n'}]",6,185829,209ef2f79ffccfd11feaa6c11db73823c65b8974,15,4,4,321,,,0,"Network guide: add ethernet and arp

Change-Id: Ia5bc6bd3fbd21862d8ef23a18018f88058bb332c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/29/185829/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/intro_basic_networking.rst'],1,fefd9d8498b05e5704e513b6f0c25eeb9c473da3,ethernet,"Ethernet is a networking protocol, specified by the IEEE 802.3 standard. Most wired network interface cards (NICs) communicate using Ethernet. In the `OSI model`_ of networking protocols, Ethernet occupies the second layer, which is known as the data link layer. When discussing Ethernet, you'll often hear terms such as *local network*, *layer 2*, *L2*, *link layer* and *data link layer*. In an Ethernet network, the hosts connected to the network communicate by exchanging *frames*, which is the Ethernet terminology for packets. Every host on an Ethernet network is uniquely identified by an address called the media access control (MAC) address. In particular, in an OpenStack environment, every virtual machine instance will have a unique MAC address, which is different from the MAC address of the compute host. A MAC address has 48 bits and is typically represented as a hexadecimal string, such as ``08:00:27:b9:88:74``. The MAC address is hard-coded into the NIC by the manufacturer, although modern NICs allow you to change the MAC address programatically. In Linux, you can retrieve the MAC address of a NIC using the ``ip`` command:: $ ip link show eth0 2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 08:00:27:b9:88:74 brd ff:ff:ff:ff:ff:ff Conceptually, you can think of an Ethernet network is a single bus that each of the networked hosts connects to. In early implementations, an Ethernet network consisted of a single coaxial cable that hosts would tap into to connect to the network. Modern Ethernet networks do not use this approach, and instead each network host connects directly to a network device called a *switch*. Still, this conceptual model is useful, and in network diagrams (including those generated by the OpenStack dashboard) an Ethernet network is often depicted as if it was a single bus. You'll sometimes hear an Ethernet netowrk referred to as a *layer 2 segment*. In an Ethernet network, every host on the network can send a frame directly to every other host. An Ethernet network also supports broadcasts, so that one host can send a frame to every host on the network by sending to the special MAC address ``ff:ff:ff:ff:ff:ff``. ARP_ and DHCP_ are two notable protocols that use Ethernet broadcasts. Because Ethernet networks support broadcasts, you will sometimes hear an Ethernet network referred to as a *broadcast domain*. When a NIC receives an Ethernet frame, by default the NIC will check to see if the destination MAC address matches the address of the NIC (or the broadcast address), and the Ethernet frame will be discarded if the MAC address does not match. For a compute host, this behavior is undesirable because the frame may be intended for one of the instances. NICs can be configured for *promiscuous mode*, where they will pass all Ethernet frames to the operating system, even if the MAC address does not match. Compute hosts should always have the appropriate NICs configured for promiscuous mode. As mentioned earlier, modern Ethernet networks uses switches to interconnect the networked hosts. A switch is a box of networking hardware with a large number of ports, that forwards Ethernet frames from one connected host to another. When hosts first send frames over the switch, the switch doesn’t know which MAC address is associated with which port. If an Ethernet frame is destined for an unknown MAC address, the switch broadcasts the frame to all ports. The port learns which MAC addresses are at which ports by observing the traffic. Once it knows which MAC address is associated with a port, it can send Ethernet frames to the correct port instead of broadcasting. The switch maintains the mappings of MAC addresses to switch ports in a table called a *forwarding table* or *forwarding information base* (FIB). Switches can be dasiy-chained together, and the resulting connection of switches and hosts behaves like a single network. .. _OSI model: http://en.wikipedia.org/wiki/OSI_model .. _ARP: Subnets and ARP ~~~~~~~~~~~~~~~ While NICs use MAC addresses to address network hosts, TCP/IP applications use IP addresses. The Address Resolution Protocol (ARP) bridges the gap between Ethernet and IP by translating IP addresses into MAC addresses. IP addresses are broken up into two parts: a *network number* and a *host identifier*. Two hosts are on the same *subnet* if they have the same network number. Recall that two hosts can only commnunicate directly over Ethernet if they are on the same local network. ARP assumes that all machines that are in the same subnet are on the same local network. Network administrators must take care when assigning IP addresses and netmasks to hosts so that any two hosts that are in the same subnet are on the same local network, otherwise ARP will not work properly. To calculate the network number of an IP address, you must know the *netmask* associated with the address. A netmask indicates how many of the bits in the 32-bit IP address make up the network number. There are two syntaxes for expressing a netmask: * dotted quad * classless inter-domain routing (CIDR) Consider an IP address of 192.168.1.5, where the first 24 bits of the address are the network number. In dotted quad notation, the netmask would be written as ``255.255.255.0``. CIDR notation includes both the IP address and netmask, and this exmaple would be written as ``192.168.1.5/24``. Sometimes we want to refer to a subnet, but not any particular IP address on the subnet. A common convention is to set the host identifer to all zeros to make reference to a subnet. For example, if a host's IP address is ``10.10.53.24/16``, then we would say the subnet is ``10.10.0.0/16``. To understand how ARP translates IP addresses to MAC addresses, consider the following example. Assume host *A* has an IP address of ``192.168.1.5/24`` and a MAC address of ``fc:99:47:49:d4:a0``, and wants to send a packet to host *B* with an IP address of ``192.168.1.7``. Note that the network number is the same for both hosts, so host *A* is able to send frames directly to host *B*. The first time host *A* attempts to communicate with host *B*, the destination MAC address is not known. Host *A* will make an ARP request to the local network. The request is a broadcast with a message like this: *To: everybody (ff:ff:ff:ff:ff:ff). I am looking for the computer who has IP address 192.168.1.7. Signed: MAC address fc:99:47:49:d4:a0*. Host *B* would respond with a response like this: *To: fc:99:47:49:d4:a0. I have IP address 192.168.1.7. Signed: MAC address 54:78:1a:86:00:a5.* Host *A* would then send Ethernet frames to host *B*. You can initiate an ARP request manually using the *arping* command. For example, to send an ARP request to IP address ``10.30.0.132``:: $ arping 10.30.0.132 ARPING 10.30.0.132 from 10.30.0.131 eth0 Unicast reply from 10.30.0.132 [54:78:1A:86:1C:0B] 0.670ms Unicast reply from 10.30.0.132 [54:78:1A:86:1C:0B] 0.722ms Unicast reply from 10.30.0.132 [54:78:1A:86:1C:0B] 0.723ms Sent 3 probes (1 broadcast(s)) Received 3 response(s) To reduce the number of ARP requests, operating systems maintain an ARP cache that contains the mappings of IP addresses to MAC address. On a Linux machine, you can view the contents of the ARP cache by using the *arp* command:: $ arp -n Address HWtype HWaddress Flags Mask Iface 10.0.2.3 ether 52:54:00:12:35:03 C eth0 10.0.2.2 ether 52:54:00:12:35:02 C eth0 .. _DHCP: DHCP ~~~~",ARP ~~~,144,2
openstack%2Fopenstacksdk~master~I4639f3b95eac0bfc34472502e54aba48b89d778a,openstack/openstacksdk,master,I4639f3b95eac0bfc34472502e54aba48b89d778a,Add telemetry resource docs,MERGED,2015-05-23 02:27:01.000000000,2015-05-27 18:17:05.000000000,2015-05-27 18:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-23 02:27:01.000000000', 'files': ['doc/source/users/resources/telemetry/v2/alarm_change.rst', 'doc/source/users/resources/telemetry/v2/meter.rst', 'doc/source/users/resources/telemetry/v2/alarm.rst', 'doc/source/users/resources/telemetry/v2/sample.rst', 'doc/source/users/resources/telemetry/index.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/telemetry/v2/resource.rst', 'doc/source/users/resources/telemetry/v2/capability.rst', 'doc/source/users/resources/telemetry/v2/statistics.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/977bf3320f3f9b9e295d6b24da982ed1fc62685f', 'message': 'Add telemetry resource docs\n\nChange-Id: I4639f3b95eac0bfc34472502e54aba48b89d778a\n'}]",0,185211,977bf3320f3f9b9e295d6b24da982ed1fc62685f,6,2,1,8736,,,0,"Add telemetry resource docs

Change-Id: I4639f3b95eac0bfc34472502e54aba48b89d778a
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/11/185211/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/resources/telemetry/v2/alarm_change.rst', 'doc/source/users/resources/telemetry/v2/meter.rst', 'doc/source/users/resources/telemetry/index.rst', 'doc/source/users/resources/telemetry/v2/alarm.rst', 'doc/source/users/resources/telemetry/v2/sample.rst', 'doc/source/users/index.rst', 'doc/source/users/resources/telemetry/v2/capability.rst', 'doc/source/users/resources/telemetry/v2/resource.rst', 'doc/source/users/resources/telemetry/v2/statistics.rst']",9,977bf3320f3f9b9e295d6b24da982ed1fc62685f,doctelemetry,openstack.telemetry.v2.statistics ================================= .. automodule:: openstack.telemetry.v2.statistics The Statistics Class -------------------- The ``Statistics`` class inherits from :class:`~openstack.resource.Resource`. .. autoclass:: openstack.telemetry.v2.statistics.Statistics :members: ,,98,0
openstack%2Fopenstacksdk~master~I564426a7abadbb59f15a7f8c73c4656c77d89667,openstack/openstacksdk,master,I564426a7abadbb59f15a7f8c73c4656c77d89667,Remove oslo incubator config file,MERGED,2015-05-26 20:48:42.000000000,2015-05-27 18:16:03.000000000,2015-05-27 18:16:02.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-26 20:48:42.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/00666418f68cf5044968f9262c605517b46779b0', 'message': ""Remove oslo incubator config file\n\nI don't think we will be pulling in oslo incubator stuff here.\nIf for some reason we decide to do it, we can add this file\nback.\n\nChange-Id: I564426a7abadbb59f15a7f8c73c4656c77d89667\n""}]",0,185736,00666418f68cf5044968f9262c605517b46779b0,7,3,1,8736,,,0,"Remove oslo incubator config file

I don't think we will be pulling in oslo incubator stuff here.
If for some reason we decide to do it, we can add this file
back.

Change-Id: I564426a7abadbb59f15a7f8c73c4656c77d89667
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/36/185736/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,00666418f68cf5044968f9262c605517b46779b0,osloconfig,,[DEFAULT] # The list of modules to copy from oslo-incubator.git module=install_venv_common # The base module to hold the copy of openstack.common base=openstack ,0,7
openstack%2Ffuel-docs~master~Ic4a58135c546fc8867a838aab9e366be41886095,openstack/fuel-docs,master,Ic4a58135c546fc8867a838aab9e366be41886095,Update commands for removing OSDs,MERGED,2015-05-19 22:30:34.000000000,2015-05-27 18:12:16.000000000,2015-05-27 18:12:16.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 13343}, {'_account_id': 14708}]","[{'number': 1, 'created': '2015-05-19 22:30:34.000000000', 'files': ['pages/operations/2500-delete-ceph-osd.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f902ae99dd7af93c91e10cb74da8684dcaa18320', 'message': 'Update commands for removing OSDs\n\nAdded OS-specific commands for stopping OSD processes.\nAlso added commands to remove the OSDs and host from\nthe CRUSH map.\n\nChange-Id: Ic4a58135c546fc8867a838aab9e366be41886095\nRelated-bug: #1446089\n'}]",0,184347,f902ae99dd7af93c91e10cb74da8684dcaa18320,12,6,1,8829,,,0,"Update commands for removing OSDs

Added OS-specific commands for stopping OSD processes.
Also added commands to remove the OSDs and host from
the CRUSH map.

Change-Id: Ic4a58135c546fc8867a838aab9e366be41886095
Related-bug: #1446089
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/47/184347/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/2500-delete-ceph-osd.rst'],1,f902ae99dd7af93c91e10cb74da8684dcaa18320,bug/1446089, .. code-block:: none When the cluster is in state HEALTH_OK the OSD(s) can be removed from the CRUSH map: On CentOS hosts: # service ceph stop osd.0 On Ubuntu hosts: # stop ceph-osd id=0 # ceph osd rm osd.0 After all OSDs have been deleted the host can be removed from the CRUSH map: .. code-block:: none # ceph osd crush remove node-35 , :: When the cluster is in state HEALTH_OK the OSD can be removed from the crush map: # service ceph stop osd.0,18,4
openstack%2Frequirements~master~Icf1ce8dbb4b2c0b6b627d5d8be0b85a42e99c784,openstack/requirements,master,Icf1ce8dbb4b2c0b6b627d5d8be0b85a42e99c784,Block oslo.vmware 0.13.0 due to a backwards incompatible change,MERGED,2015-05-26 21:40:00.000000000,2015-05-27 18:10:49.000000000,2015-05-27 18:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 8574}, {'_account_id': 8688}, {'_account_id': 9171}]","[{'number': 1, 'created': '2015-05-26 21:40:00.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/988e241d97ad10ed24c24d783f31fd2805d0e071', 'message': ""Block oslo.vmware 0.13.0 due to a backwards incompatible change\n\nThe nova vmware unit tests are failing after 5/26 when oslo.vmware\n0.13.0 was releaed due to change\nI34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd which breaks backwards\ncompatibility by raising a different exception type than before.\n\nThe change should have gone through a deprecation cycle before making\nthat a new hard error cutover so clients have time to change.\n\nThere is a revert proposed: I0f8042c6e47f6eb9802e770ffb7d09bdbe57013b\n\nSince this is a library release, we have to block the version so nova\ndoesn't pick it up and then put out a new release (0.13.1?) with the\nrevert to move forward.\n\nCloses-Bug: #1459021\n\nChange-Id: Icf1ce8dbb4b2c0b6b627d5d8be0b85a42e99c784\n""}]",0,185748,988e241d97ad10ed24c24d783f31fd2805d0e071,14,9,1,6873,,,0,"Block oslo.vmware 0.13.0 due to a backwards incompatible change

The nova vmware unit tests are failing after 5/26 when oslo.vmware
0.13.0 was releaed due to change
I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd which breaks backwards
compatibility by raising a different exception type than before.

The change should have gone through a deprecation cycle before making
that a new hard error cutover so clients have time to change.

There is a revert proposed: I0f8042c6e47f6eb9802e770ffb7d09bdbe57013b

Since this is a library release, we have to block the version so nova
doesn't pick it up and then put out a new release (0.13.1?) with the
revert to move forward.

Closes-Bug: #1459021

Change-Id: Icf1ce8dbb4b2c0b6b627d5d8be0b85a42e99c784
",git fetch https://review.opendev.org/openstack/requirements refs/changes/48/185748/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,988e241d97ad10ed24c24d783f31fd2805d0e071,bug/1459021,"oslo.vmware>=0.11.1,!=0.13.0 # Apache-2.0",oslo.vmware>=0.11.1 # Apache-2.0,1,1
openstack%2Fkeystoneauth~master~Icc3efeb41ff8c03d1e36e3eca372d2206b6077bf,openstack/keystoneauth,master,Icc3efeb41ff8c03d1e36e3eca372d2206b6077bf,Remove some cruft from the service catalog,MERGED,2015-05-27 01:35:10.000000000,2015-05-27 17:44:49.000000000,2015-05-27 17:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-27 01:35:10.000000000', 'files': ['keystoneauth/service_catalog.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/32bd7a5d74ba9cbb6678635da81bca2561c46f24', 'message': 'Remove some cruft from the service catalog\n\nRemove filtering by arbitrary attr/filter_value combination.\nRemove defaulting the service_type to identity.\n\nI expect that more will need to be done to the service catalog before\n1.0.\n\nChange-Id: Icc3efeb41ff8c03d1e36e3eca372d2206b6077bf\n'}]",0,185805,32bd7a5d74ba9cbb6678635da81bca2561c46f24,7,3,1,7191,,,0,"Remove some cruft from the service catalog

Remove filtering by arbitrary attr/filter_value combination.
Remove defaulting the service_type to identity.

I expect that more will need to be done to the service catalog before
1.0.

Change-Id: Icc3efeb41ff8c03d1e36e3eca372d2206b6077bf
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/05/185805/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth/service_catalog.py'],1,32bd7a5d74ba9cbb6678635da81bca2561c46f24,catalog2," def _get_service_endpoints(self, service_type, endpoint_type, region_name, service_name): @utils.positional() def get_urls(self, service_type=None, endpoint_type='public', @utils.positional() def url_for(self, service_type=None, endpoint_type='public', urls = self.get_urls(service_type=service_type, @utils.positional() def get_urls(self, service_type=None, endpoint_type='publicURL', endpoints = self._get_service_endpoints(service_type=service_type, @utils.positional() def get_urls(self, service_type=None, endpoint_type='publicURL', region_name=None, service_name=None): endpoints = self._get_service_endpoints(service_type=service_type,"," def _get_service_endpoints(self, attr, filter_value, service_type, endpoint_type, region_name, service_name): # TODO(jamielennox): at least swiftclient is known to set attr and not # filter_value and expects that to mean that filtering is ignored, so # we can't check for the presence of attr. This behaviour should be # deprecated and an appropriate warning provided. if filter_value: return [endpoint for endpoint in endpoints if endpoint.get(attr) == filter_value] @utils.positional(enforcement=utils.positional.WARN) def get_urls(self, attr=None, filter_value=None, service_type='identity', endpoint_type='publicURL', :param string attr: Endpoint attribute name. :param string filter_value: Endpoint attribute value. @utils.positional(3, enforcement=utils.positional.WARN) def url_for(self, attr=None, filter_value=None, service_type='identity', endpoint_type='publicURL', :param string attr: Endpoint attribute name. :param string filter_value: Endpoint attribute value. urls = self.get_urls(attr=attr, filter_value=filter_value, service_type=service_type, @utils.positional(enforcement=utils.positional.WARN) def get_urls(self, attr=None, filter_value=None, service_type='identity', endpoint_type='publicURL', endpoints = self._get_service_endpoints(attr=attr, filter_value=filter_value, service_type=service_type, @utils.positional(enforcement=utils.positional.WARN) def get_urls(self, attr=None, filter_value=None, service_type='identity', endpoint_type='public', region_name=None, service_name=None): endpoints = self._get_service_endpoints(attr=attr, filter_value=filter_value, service_type=service_type,",13,35
openstack%2Fdesignate~master~Ib4c65743f59295cc94926c54d294c945e06872bf,openstack/designate,master,Ib4c65743f59295cc94926c54d294c945e06872bf,Update Dashboard requirements,MERGED,2015-05-15 15:04:36.000000000,2015-05-27 17:42:32.000000000,2015-05-27 17:42:28.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-15 15:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/1a6849d3e5555ed224f0de45541ad8b358b300d1', 'message': 'Update Dashboard requirements\n\nChange-Id: Ib4c65743f59295cc94926c54d294c945e06872bf\n'}, {'number': 2, 'created': '2015-05-26 13:56:44.000000000', 'files': ['contrib/designate-dashboard/setup.py', 'contrib/designate-dashboard/requirements.txt', 'contrib/designate-dashboard/test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/34019d2bf57fd519adce11d763e4f4c3033311ae', 'message': 'Update Dashboard requirements\n\nChange-Id: Ib4c65743f59295cc94926c54d294c945e06872bf\n'}]",0,183557,34019d2bf57fd519adce11d763e4f4c3033311ae,15,5,2,741,,,0,"Update Dashboard requirements

Change-Id: Ib4c65743f59295cc94926c54d294c945e06872bf
",git fetch https://review.opendev.org/openstack/designate refs/changes/57/183557/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/designate-dashboard/requirements.txt', 'contrib/designate-dashboard/test-requirements.txt']",2,1a6849d3e5555ed224f0de45541ad8b358b300d1,183557,"hacking>=0.10.0,<0.11oslo.config>=1.11.0 # Apache-2.0 pylint==1.4.1 # GNU GPL v2testtools>=0.9.36,!=1.2.0","hacking>=0.9.2,<0.10oslo.config>=1.2.1 pylint==0.25.2testtools>=0.9.34",10,10
openstack%2Frequirements~master~I880cffbe003a27e9caba3695e39e39e3bd9b1fcc,openstack/requirements,master,I880cffbe003a27e9caba3695e39e39e3bd9b1fcc,Pin pyngus version as python-qpid-proton is not in pypi,MERGED,2015-05-16 00:52:09.000000000,2015-05-27 17:40:23.000000000,2015-05-16 16:55:20.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 8770}]","[{'number': 1, 'created': '2015-05-16 00:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e662674ef1ae072c28f707db57908738571fa35a', 'message': 'Pin pyngus version\n\ncheck-requirements-integration-dsvm is failing with\nthe following error:\n\nCould not find a version that satisfies the requirement python-qpid-proton<0.10,>=0.9\n\nthe latest released version of python-qpid-proton is 0.8.1 at the moment.\n\nChange-Id: I880cffbe003a27e9caba3695e39e39e3bd9b1fcc\n'}, {'number': 2, 'created': '2015-05-16 01:47:42.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6aa6ddb129b521e1ddbdc203fef557174f1f3b63', 'message': 'Pin pyngus version as python-qpid-proton is not in pypi\n\ncheck-requirements-integration-dsvm is failing with\nthe following error:\n\nCould not find a version that satisfies the requirement python-qpid-proton<0.10,>=0.9\n\nthe latest released version of python-qpid-proton is 0.8.1 at the moment.\n\nChange-Id: I880cffbe003a27e9caba3695e39e39e3bd9b1fcc\n'}]",0,183756,6aa6ddb129b521e1ddbdc203fef557174f1f3b63,12,5,2,5638,,,0,"Pin pyngus version as python-qpid-proton is not in pypi

check-requirements-integration-dsvm is failing with
the following error:

Could not find a version that satisfies the requirement python-qpid-proton<0.10,>=0.9

the latest released version of python-qpid-proton is 0.8.1 at the moment.

Change-Id: I880cffbe003a27e9caba3695e39e39e3bd9b1fcc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/56/183756/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e662674ef1ae072c28f707db57908738571fa35a,," # NOTE(dims): pyngus 1.3.0 depends on an unreleased python-qpid-proton # version, so we should unpin this once this problem is fixed. pyngus==1.2.0 # Apache 2.0 License ",pyngus>=1.2.0 # Apache 2.0 License,5,1
openstack%2Ffuel-library~master~Ia52fc5f2ab7adb36252a7194f9209ab87ce487de,openstack/fuel-library,master,Ia52fc5f2ab7adb36252a7194f9209ab87ce487de,Check if the rabbitmqctl command is responding,MERGED,2015-05-27 13:57:18.000000000,2015-05-27 17:38:17.000000000,2015-05-27 17:37:35.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-27 13:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/11a36a20bd0dc6204e1c3862895f0cb33e254a3a', 'message': 'Check if the rabbitmqctl command is responding\n\nW/o this fix, rabbitmqctl sometimes may hang failing\nmany commands. This is a problem as it brings the rabbit node\nto unresponsive and broken state. This also may affect\nentire cluster operations, for example, when the failed command is\nthe forget_cluster_node.\n\nThe solution is to check for the cases when the command rabbitmqctl\nlist_channels timed out and killed or termintated with exit codes\n137 or 124 and return generic error.\nThere is also related confusing error message ""get_status() returns generic\nerror"" may be logged when the rabbit node is running out of the cluster\nand fixed as well.\n\nCloses-bug: #1459152\n\nChange-Id: Ia52fc5f2ab7adb36252a7194f9209ab87ce487de\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2015-05-27 14:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0420663c178e1f1bb98a9c973b57e8eade7debc0', 'message': 'Check if the rabbitmqctl command is responding\n\nW/o this fix, rabbitmqctl sometimes may hang failing\nmany commands. This is a problem as it brings the rabbit node\nto unresponsive and broken state. This also may affect\nentire cluster operations, for example, when the failed command is\nthe forget_cluster_node.\n\nThe solution is to check for the cases when the command rabbitmqctl\nlist_channels timed out and killed or termintated with exit codes\n137 or 124 and return generic error.\nThere is also related confusing error message ""get_status() returns generic\nerror"" may be logged when the rabbit node is running out of the cluster\nand fixed as well.\n\nCloses-bug: #1459152\n\nChange-Id: Ia52fc5f2ab7adb36252a7194f9209ab87ce487de\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2015-05-27 14:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ad731a2c1559ad4d75a31cde835e604b00345c71', 'message': 'Check if the rabbitmqctl command is responding\n\nW/o this fix, rabbitmqctl sometimes may hang failing\nmany commands. This is a problem as it brings the rabbit node\nto unresponsive and broken state. This also may affect\nentire cluster operations, for example, when the failed command is\nthe forget_cluster_node.\n\nThe solution is to check for the cases when the command rabbitmqctl\nlist_channels timed out and killed or termintated with exit codes\n137 or 124 and return generic error.\nThere is also related confusing error message ""get_status() returns generic\nerror"" may be logged when the rabbit node is running out of the cluster\nand fixed as well.\n\nCloses-bug: #1459173\n\nChange-Id: Ia52fc5f2ab7adb36252a7194f9209ab87ce487de\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2015-05-27 14:21:53.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e8e777a55b6d31e197c97cc6380c2c0e49927b0a', 'message': 'Check if the rabbitmqctl command is responding\n\nW/o this fix, rabbitmqctl sometimes may hang failing\nmany commands. This is a problem as it brings the rabbit node\nto unresponsive and broken state. This also may affect\nentire cluster operations, for example, when the failed command is\nthe forget_cluster_node.\n\nThe solution is to check for the cases when the command rabbitmqctl\nlist_channels timed out and killed or termintated with exit codes\n137 or 124 and return generic error.\nThere is also related confusing error message ""get_status() returns generic\nerror"" may be logged when the rabbit node is running out of the cluster\nand fixed as well.\n\nCloses-bug: #1459173\n\nChange-Id: Ia52fc5f2ab7adb36252a7194f9209ab87ce487de\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,186002,e8e777a55b6d31e197c97cc6380c2c0e49927b0a,77,5,4,6926,,,0,"Check if the rabbitmqctl command is responding

W/o this fix, rabbitmqctl sometimes may hang failing
many commands. This is a problem as it brings the rabbit node
to unresponsive and broken state. This also may affect
entire cluster operations, for example, when the failed command is
the forget_cluster_node.

The solution is to check for the cases when the command rabbitmqctl
list_channels timed out and killed or termintated with exit codes
137 or 124 and return generic error.
There is also related confusing error message ""get_status() returns generic
error"" may be logged when the rabbit node is running out of the cluster
and fixed as well.

Closes-bug: #1459173

Change-Id: Ia52fc5f2ab7adb36252a7194f9209ab87ce487de
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/02/186002/3 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,11a36a20bd0dc6204e1c3862895f0cb33e254a3a,fix1459152," local rc2=$OCF_SUCCESS rc2=$OCF_ERR_GENERIC [ $rc2 -ne $OCF_ERR_GENERIC ] || ocf_log err ""${LH} rabbit app is running out of the cluster"" ocf_log err ""${LH} get_status() returns generic error ${rc}"" # Check if the rabbitmqctl control plane is alive. # The rabbit app may be not running and the command # will return > 0, so we only check if the command execution # has timed out (which is a code 137) su_rabbit_cmd ""${OCF_RESKEY_ctl} list_channels 2>&1 > /dev/null"" rc2=$? if [ $rc2 -eq 137 -o $rc2 -eq 124 ]; then ocf_log err ""${LH} rabbitmqctl is not responding. The resource is failed."" return $OCF_ERR_GENERIC "," local prev_rc prev_rc=$rc rc=$OCF_ERR_GENERIC rc=$prev_rc ocf_log info ""${LH} get_status() returns generic error ${rc}""",15,5
openstack%2Fproject-config~master~I2b47ad8cfcd7d1a6dd9a86fe8dc8c682c433ab63,openstack/project-config,master,I2b47ad8cfcd7d1a6dd9a86fe8dc8c682c433ab63,Clean up run-tox.sh to make it easier to reuse,MERGED,2015-03-04 20:50:28.000000000,2015-05-27 17:30:29.000000000,2015-05-27 17:30:28.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6524}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-03-04 20:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/06836b0b82cbb5c5e7cddca3b5189dbc2f649f4c', 'message': 'Clean up run-tox.sh to make it easier to reuse\n\nThis change is the first pass of making run-tox.sh usable by\nfunctional jobs.  It moves potentially optional checks into functions\nto make it easier for subsequent changes to be able to conditionally\nexecute them.\n\nChange-Id: I2b47ad8cfcd7d1a6dd9a86fe8dc8c682c433ab63\n'}, {'number': 2, 'created': '2015-05-12 23:17:23.000000000', 'files': ['jenkins/scripts/run-tox.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2a47ba1fce00d18a6355f23218e469cb9dcda41d', 'message': 'Clean up run-tox.sh to make it easier to reuse\n\nThis change is the first pass of making run-tox.sh usable by\nfunctional jobs.  It moves potentially optional checks into functions\nto make it easier for subsequent changes to be able to conditionally\nexecute them.\n\nChange-Id: I2b47ad8cfcd7d1a6dd9a86fe8dc8c682c433ab63\n'}]",0,161414,2a47ba1fce00d18a6355f23218e469cb9dcda41d,14,11,2,2035,,,0,"Clean up run-tox.sh to make it easier to reuse

This change is the first pass of making run-tox.sh usable by
functional jobs.  It moves potentially optional checks into functions
to make it easier for subsequent changes to be able to conditionally
execute them.

Change-Id: I2b47ad8cfcd7d1a6dd9a86fe8dc8c682c433ab63
",git fetch https://review.opendev.org/openstack/project-config refs/changes/14/161414/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/run-tox.sh'],1,06836b0b82cbb5c5e7cddca3b5189dbc2f649f4c,refactor-run-tox,"function freeze_venv { [ -e $bin_path/pbr ] && freezecmd=pbr || freezecmd=pip echo ""Begin $freezecmd freeze output from test virtualenv:"" echo ""======================================================================"" ${bin_path}/${freezecmd} freeze echo ""======================================================================"" } function process_testr_artifacts { if [ ! -d "".testrepository"" ] ; then return fi $bin_path/subunit-1to2 < .testrepository/0 > ./subunit_log.txt $PYTHON $script_path/subunit2html.py ./subunit_log.txt testr_results.html rancount=$($bin_path/testr last | sed -ne 's/Ran \([0-9]\+\).*tests in.*/\1/p')} function check_sudo_usage { sudo $script_path/jenkins-sudo-grep.sh post sudoresult=$? if [ $sudoresult -ne ""0"" ]; then echo ""This test has failed because it attempted to execute commands"" echo ""with sudo. See above for the exact commands used.""} function check_oom { $script_path/jenkins-oom-grep.sh post oomresult=$? if [ $oomresult -ne ""0"" ]; then echo echo ""This test has failed because it attempted to exceed configured"" echo ""memory limits and was killed prior to completion. See above"" echo ""for related kernel messages."" echo exit 1 fi } function check_nose_html { htmlreport=$(find . -name $NOSE_HTML_OUT_FILE) if [ -f ""$htmlreport"" ]; then passcount=$(grep -c 'tr class=.passClass' $htmlreport) if [ $passcount -eq ""0"" ]; then echo echo ""Zero tests passed, which probably means there was an error"" echo ""parsing one of the python files, or that some other failure"" echo ""during test setup prevented a sane run."" echo exit 1 fi else echo echo ""WARNING: Unable to find $NOSE_HTML_OUT_FILE to confirm results!"" echo fi } local script_path=/usr/local/jenkins/slave_scripts local bin_path=.tox/$venv/bin export PYTHON=$bin_path/python export NOSE_WITH_XUNIT=1 export NOSE_WITH_HTML_OUTPUT=1 export NOSE_HTML_OUT_FILE='nose_results.html' export TMPDIR=`/bin/mktemp -d` trap ""rm -rf $TMPDIR"" EXIT cat /etc/image-hostname.txt $script_path/jenkins-oom-grep.sh pre sudo $script_path/jenkins-sudo-grep.sh pre tox -v -e$venv result=$? freeze_venv process_testr_artifacts check_sudo_usage check_oom check_nose_html","export NOSE_WITH_XUNIT=1 export NOSE_WITH_HTML_OUTPUT=1 export NOSE_HTML_OUT_FILE='nose_results.html' export TMPDIR=`/bin/mktemp -d` trap ""rm -rf $TMPDIR"" EXIT cat /etc/image-hostname.txt /usr/local/jenkins/slave_scripts/jenkins-oom-grep.sh pre sudo /usr/local/jenkins/slave_scripts/jenkins-sudo-grep.sh pre tox -v -e$venv result=$? [ -e .tox/$venv/bin/pbr ] && freezecmd=pbr || freezecmd=pip echo ""Begin $freezecmd freeze output from test virtualenv:"" echo ""======================================================================"" .tox/${venv}/bin/${freezecmd} freeze echo ""======================================================================"" if [ -d "".testrepository"" ] ; then .tox/$venv/bin/subunit-1to2 < .testrepository/0 > ./subunit_log.txt .tox/$venv/bin/python /usr/local/jenkins/slave_scripts/subunit2html.py ./subunit_log.txt testr_results.html export PYTHON=.tox/$venv/bin/python rancount=$(.tox/$venv/bin/testr last | sed -ne 's/Ran \([0-9]\+\).*tests in.*/\1/p')fi sudo /usr/local/jenkins/slave_scripts/jenkins-sudo-grep.sh post sudoresult=$? if [ $sudoresult -ne ""0"" ]; then echo echo ""This test has failed because it attempted to execute commands"" echo ""with sudo. See above for the exact commands used."" echo exit 1 fi /usr/local/jenkins/slave_scripts/jenkins-oom-grep.sh post oomresult=$? if [ $oomresult -ne ""0"" ]; then echo echo ""This test has failed because it attempted to exceed configured"" echo ""memory limits and was killed prior to completion. See above"" echo ""for related kernel messages."" echo exit 1 fi htmlreport=$(find . -name $NOSE_HTML_OUT_FILE) if [ -f ""$htmlreport"" ]; then passcount=$(grep -c 'tr class=.passClass' $htmlreport) if [ $passcount -eq ""0"" ]; then echo ""Zero tests passed, which probably means there was an error"" echo ""parsing one of the python files, or that some other failure"" echo ""during test setup prevented a sane run.""else echo echo ""WARNING: Unable to find $NOSE_HTML_OUT_FILE to confirm results!"" echo fi",80,58
openstack%2Fdesignate~stable%2Fkilo~I02d22212511246f0c1b8138fa3413770cd5810a1,openstack/designate,stable/kilo,I02d22212511246f0c1b8138fa3413770cd5810a1,Fix check+set race condition in APIv1/Sink,MERGED,2015-05-13 15:47:05.000000000,2015-05-27 17:27:25.000000000,2015-05-27 17:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 4894}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-05-13 15:47:05.000000000', 'files': ['designate/notification_handler/base.py', 'designate/api/v1/records.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/219aa4bee5af92ac29e0a1ff0e90b6dd38cbbc90', 'message': 'Fix check+set race condition in APIv1/Sink\n\nChange-Id: I02d22212511246f0c1b8138fa3413770cd5810a1\nCloses-Bug: 1454262\n(cherry picked from commit ef769bf960c9e24f571b80935e03dcd3d8e61c34)\n'}]",0,182731,219aa4bee5af92ac29e0a1ff0e90b6dd38cbbc90,7,4,1,741,,,0,"Fix check+set race condition in APIv1/Sink

Change-Id: I02d22212511246f0c1b8138fa3413770cd5810a1
Closes-Bug: 1454262
(cherry picked from commit ef769bf960c9e24f571b80935e03dcd3d8e61c34)
",git fetch https://review.opendev.org/openstack/designate refs/changes/31/182731/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/notification_handler/base.py', 'designate/api/v1/records.py']",2,219aa4bee5af92ac29e0a1ff0e90b6dd38cbbc90,," # Attempt to create an empty recordset except exceptions.DuplicateRecordSet: # Fetch the existing recordset recordset = _find_recordset(context, domain_id, name, type) "," recordset = _find_recordset(context, domain_id, name, type) except exceptions.RecordSetNotFound: # Create an empty recordset",14,9
openstack%2Fastara-horizon~master~I7231c25080bb877364439cd5bfacee6ba23c1be7,openstack/astara-horizon,master,I7231c25080bb877364439cd5bfacee6ba23c1be7,prep for next stable,ABANDONED,2015-05-16 23:10:48.000000000,2015-05-27 17:27:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-05-16 23:10:48.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-horizon/commit/2a028f013de897257c76c39e1790a99088a50150', 'message': 'prep for next stable\n\nupdate package configuration\n\nChange-Id: I7231c25080bb877364439cd5bfacee6ba23c1be7\n'}]",0,183845,2a028f013de897257c76c39e1790a99088a50150,8,3,1,6923,,,0,"prep for next stable

update package configuration

Change-Id: I7231c25080bb877364439cd5bfacee6ba23c1be7
",git fetch https://review.opendev.org/openstack/astara-horizon refs/changes/45/183845/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2a028f013de897257c76c39e1790a99088a50150,prepare-for-next-stable,version = 2015.1.1,version = 2015.1,1,1
openstack%2Fopenstack-ansible~master~Id316ee54e4e5ab90bd5cf8fb5d4a655c05b50090,openstack/openstack-ansible,master,Id316ee54e4e5ab90bd5cf8fb5d4a655c05b50090,fix bash/curl command in development-stack.rst,MERGED,2015-05-27 10:22:21.000000000,2015-05-27 17:23:47.000000000,2015-05-27 14:10:48.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-05-27 10:22:21.000000000', 'files': ['development-stack.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/21575644b188c2d7a1af10fe8a72cb2b76363a42', 'message': 'fix bash/curl command in development-stack.rst\n\nmake the curl/bash command work properly\n\nChange-Id: Id316ee54e4e5ab90bd5cf8fb5d4a655c05b50090\nCloses-Bug: #1459182\n'}]",0,185919,21575644b188c2d7a1af10fe8a72cb2b76363a42,8,3,1,425,,,0,"fix bash/curl command in development-stack.rst

make the curl/bash command work properly

Change-Id: Id316ee54e4e5ab90bd5cf8fb5d4a655c05b50090
Closes-Bug: #1459182
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/19/185919/1 && git format-patch -1 --stdout FETCH_HEAD,['development-stack.rst'],1,21575644b188c2d7a1af10fe8a72cb2b76363a42,bug/1459182, bash <(curl -s http://git.openstack.org/cgit/stackforge/os-ansible-deployment/plain/scripts/run-aio-build.sh), curl http://git.openstack.org/cgit/stackforge/os-ansible-deployment/plain/scripts/run-aio-build.sh | bash,1,1
openstack%2Fneutron~stable%2Ficehouse~Iaeab9ec664820de651bda563b530c88411deb8e7,openstack/neutron,stable/icehouse,Iaeab9ec664820de651bda563b530c88411deb8e7,Updated from global requirements,MERGED,2015-04-20 19:04:06.000000000,2015-05-27 17:22:45.000000000,2015-05-27 17:22:43.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-20 19:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a53450efc17c33a5d8dcc995a18dc82c4bd0795d', 'message': 'Updated from global requirements\n\nChange-Id: Iaeab9ec664820de651bda563b530c88411deb8e7\n'}, {'number': 2, 'created': '2015-04-22 12:34:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/69693436fcd24c7ae052754e7578bf885c95f5a7', 'message': 'Updated from global requirements\n\nChange-Id: Iaeab9ec664820de651bda563b530c88411deb8e7\n'}]",0,175543,69693436fcd24c7ae052754e7578bf885c95f5a7,32,19,2,11131,,,0,"Updated from global requirements

Change-Id: Iaeab9ec664820de651bda563b530c88411deb8e7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/175543/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a53450efc17c33a5d8dcc995a18dc82c4bd0795d,openstack/requirements,"python-keystoneclient>=0.7.0,<0.12.0","python-keystoneclient>=0.7.0,<=0.11.2",1,1
openstack%2Ffuel-library~master~I82d8669240beaa40a427c71c4b6d653224da660a,openstack/fuel-library,master,I82d8669240beaa40a427c71c4b6d653224da660a,Move bridge sleep out of the loop,MERGED,2015-05-27 05:35:47.000000000,2015-05-27 17:13:33.000000000,2015-05-27 17:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14168}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-27 05:35:47.000000000', 'files': ['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/adb93d236dc29744150a95915c0a72aab662b0ea', 'message': 'Move bridge sleep out of the loop\n\nRemove excessive sleep introduced by\n\nhttps://review.openstack.org/#q,I6dd5f62df103f6839b802aaf1b7643b6ba440caa,n,z\n\nChange-Id: I82d8669240beaa40a427c71c4b6d653224da660a\nRelated-bug: #1458625\n'}]",0,185845,adb93d236dc29744150a95915c0a72aab662b0ea,26,6,1,8786,,,0,"Move bridge sleep out of the loop

Remove excessive sleep introduced by

https://review.openstack.org/#q,I6dd5f62df103f6839b802aaf1b7643b6ba440caa,n,z

Change-Id: I82d8669240beaa40a427c71c4b6d653224da660a
Related-bug: #1458625
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/45/185845/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb'],1,adb93d236dc29744150a95915c0a72aab662b0ea,bug/1458625, #Add sleep before checking for repos #as Ubuntu waits 32 seconds for the #bridge to become ready sleep 32, #Add sleep before checking for repos #as Ubuntu waits 32 seconds for the #bridge to become ready sleep 32,4,4
openstack%2Fnetworking-hyperv~master~I215393977e9b81f013738c66d371440c6d704727,openstack/networking-hyperv,master,I215393977e9b81f013738c66d371440c6d704727,Bump version to 2015.2.0,MERGED,2015-05-27 16:08:24.000000000,2015-05-27 17:00:32.000000000,2015-05-27 17:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-05-27 16:08:24.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/6eaf418741a8126d1399e009997af47ec6fec003', 'message': 'Bump version to 2015.2.0\n\nBump version for the Liberty release cycle.\n\nChange-Id: I215393977e9b81f013738c66d371440c6d704727\n'}]",0,186058,6eaf418741a8126d1399e009997af47ec6fec003,6,2,1,8213,,,0,"Bump version to 2015.2.0

Bump version for the Liberty release cycle.

Change-Id: I215393977e9b81f013738c66d371440c6d704727
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/58/186058/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6eaf418741a8126d1399e009997af47ec6fec003,,version = 2015.1.1,version = 2015.1.0,1,1
openstack%2Fheat~master~Ia777c25cc58be16d7185d60315457981f15e885f,openstack/heat,master,Ia777c25cc58be16d7185d60315457981f15e885f,made few small changes to heat dev docs,ABANDONED,2015-04-27 18:53:08.000000000,2015-05-27 16:56:27.000000000,,"[{'_account_id': 3}, {'_account_id': 7193}, {'_account_id': 9382}, {'_account_id': 9563}, {'_account_id': 15804}]","[{'number': 1, 'created': '2015-04-27 18:53:08.000000000', 'files': ['doc/source/getting_started/on_ubuntu.rst', 'doc/source/schedulerhints.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/642aab8d3ec935ccad47d361fc44a263144cc28d', 'message': 'made few small changes to heat dev docs\n\nremoved unneccessary capitalization in docs\nfollowed doc conventions for heat capitalization\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: Ia777c25cc58be16d7185d60315457981f15e885f\n'}]",1,177928,642aab8d3ec935ccad47d361fc44a263144cc28d,14,5,1,9382,,,0,"made few small changes to heat dev docs

removed unneccessary capitalization in docs
followed doc conventions for heat capitalization
https://wiki.openstack.org/wiki/Documentation/Conventions

Change-Id: Ia777c25cc58be16d7185d60315457981f15e885f
",git fetch https://review.opendev.org/openstack/heat refs/changes/28/177928/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/getting_started/on_ubuntu.rst', 'doc/source/schedulerhints.rst']",2,642aab8d3ec935ccad47d361fc44a263144cc28d,on_ubuntu_rst,"Heat stack lifecycle scheduler hintsThis is a mechanism whereby when heat processes a stack server resource, the","Heat Stack Lifecycle Scheduler HintsThis is a mechanism whereby when heat processes a stack Server resource, the",3,3
openstack%2Fheat~master~I254156ba9bdaa1b754ab21886a23e802755afdb0,openstack/heat,master,I254156ba9bdaa1b754ab21886a23e802755afdb0,changed heat dev docs to comply with conventions,ABANDONED,2015-04-25 04:53:16.000000000,2015-05-27 16:56:18.000000000,,"[{'_account_id': 3}, {'_account_id': 9382}, {'_account_id': 9563}, {'_account_id': 12606}, {'_account_id': 13009}, {'_account_id': 14920}, {'_account_id': 15804}]","[{'number': 1, 'created': '2015-04-25 04:53:16.000000000', 'files': ['doc/source/getting_started/on_devstack.rst', 'doc/source/getting_started/jeos_building.rst', 'doc/source/getting_started/on_fedora.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/3a8a6b4af147602842ad9d76dd8cbc393c75a303', 'message': ""changed heat dev docs to comply with conventions\n\nWith the incorporation of many projects within OpenStack, it's very important to\nuse standards in the documentation This is important for formalization as well\nas consistency\nthe proper usage is: heat or Orchestration or Orchestration module\nheat should not be capitalized\nOpenstack should be OpenStack\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: I254156ba9bdaa1b754ab21886a23e802755afdb0\n""}]",1,177520,3a8a6b4af147602842ad9d76dd8cbc393c75a303,15,7,1,9382,,,0,"changed heat dev docs to comply with conventions

With the incorporation of many projects within OpenStack, it's very important to
use standards in the documentation This is important for formalization as well
as consistency
the proper usage is: heat or Orchestration or Orchestration module
heat should not be capitalized
Openstack should be OpenStack
https://wiki.openstack.org/wiki/Documentation/Conventions

Change-Id: I254156ba9bdaa1b754ab21886a23e802755afdb0
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/177520/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/getting_started/on_devstack.rst', 'doc/source/getting_started/jeos_building.rst', 'doc/source/getting_started/on_fedora.rst']",3,3a8a6b4af147602842ad9d76dd8cbc393c75a303,on_devstack,"Getting started With heat on FedoraInstalling OpenStack and heat on FedoraHeat requires an OpenStack release of Grizzly or newer, but bear in mind that Grizzly is EOL. The current stable release_ is, of course, recommended.Instructions for installing heat on RDO are also available at ``http://openstack.redhat.com/Docs``Example templates","Getting Started With Heat on FedoraInstalling OpenStack and Heat on FedoraHeat requires an Openstack release of Grizzly or newer, but bear in mind that Grizzly is EOL. The current stable release_ is, of course, recommended.Instructions for installing Heat on RDO are also available at ``http://openstack.redhat.com/Docs``Example Templates",13,13
openstack%2Fheat~master~I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc,openstack/heat,master,I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc,changed heat dev docs to comply with conventions,ABANDONED,2015-04-25 01:26:48.000000000,2015-05-27 16:56:13.000000000,,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 7193}, {'_account_id': 9563}, {'_account_id': 10487}, {'_account_id': 12259}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-04-25 01:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9f913ee36a1b22767230e4c88ae3c546a9a9279e', 'message': ""changed heat dev docs to comply with conventions\n\nWith the incorporation of many projects within OpenStack, it's very important to\nuse standards in the documentation This is important for formalization as well\nas consistency\nPer formal doc conventions, the word plugin should\nnot be used. It should be plug-in with a hyphen\nservice names should not be capitalized\nthe proper usage is: heat: Orchestration or Orchestration module\nalso made some sentence changes, added “the” before Juno\nOpenStack was also spelled wrong (Openstack)\nremoved capitalization from titles per standards\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc\n""}, {'number': 2, 'created': '2015-04-27 16:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bc0c29bd2ac9de9b834e6ac6afecba2468dc3f75', 'message': ""changed heat dev docs to comply with conventions\n\nIt's very important to use standards in the documentation\nThis is important for formalization as well as consistency\nPer formal doc conventions, the word plugin should not be used\nIt should be plug-in with a hyphen service names should\nnot be capitalized the proper usage is: heat: Orchestration\nor Orchestration module. Also made some sentence changes, added\n“the” before Juno OpenStack was also spelled wrong (Openstack)\nremoved capitalization from titles per standards\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc\n""}, {'number': 3, 'created': '2015-04-27 17:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10bef70e4db06e1dc33587ad75515fdcad5b676d', 'message': ""changed heat dev docs to comply with conventions\n\nIt's very important to use standards in the documentation\nThis is important for formalization as well as consistency\nPer formal doc conventions, the word plugin should not be used.\nIt should be plug-in with a hyphen service names should not\nbe capitalized the proper usage is: heat: Orchestration or\nOrchestration module. Also made some sentence changes, removed\ncapitalization from titles per standards\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc\n""}, {'number': 4, 'created': '2015-04-28 20:52:44.000000000', 'files': ['doc/source/index.rst', 'doc/source/template_guide/hot_spec.rst', 'doc/source/pluginguide.rst', 'doc/source/template_guide/contrib.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/981b01ef79b7749ffd7db9f18983e9a2bc6c54d8', 'message': ""changed heat dev docs to comply with conventions\n\nIt's very important to use standards in the documentation\nThis is important for formalization as well as consistency\nPer formal doc conventions, the word plugin should not be used.\nIt should be plug-in with a hyphen service names should not\nbe capitalized the proper usage is: heat: Orchestration or\nOrchestration module. Also made some sentence changes, removed\ncapitalization from titles per standards\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc\n""}]",5,177510,981b01ef79b7749ffd7db9f18983e9a2bc6c54d8,25,8,4,9382,,,0,"changed heat dev docs to comply with conventions

It's very important to use standards in the documentation
This is important for formalization as well as consistency
Per formal doc conventions, the word plugin should not be used.
It should be plug-in with a hyphen service names should not
be capitalized the proper usage is: heat: Orchestration or
Orchestration module. Also made some sentence changes, removed
capitalization from titles per standards
https://wiki.openstack.org/wiki/Documentation/Conventions

Change-Id: I6d8f44fcde3ed2ab8ee41e279969f08809ee60cc
",git fetch https://review.opendev.org/openstack/heat refs/changes/10/177510/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/template_guide/hot_spec.rst', 'doc/source/pluginguide.rst', 'doc/source/template_guide/contrib.rst']",4,9f913ee36a1b22767230e4c88ae3c546a9a9279e,heat-cor,Contributed heat resource typesThe resources in this module are for using heat with the Rackspacea generic OpenStack deployment and the Rackspace Cloud.This plug-in enables the use of Docker containers in a heat template and,Contributed Heat Resource TypesThe resources in this module are for using Heat with the Rackspacea generic Openstack deployment and the Rackspace Cloud.This plugin enables the use of Docker containers in a Heat template and,53,53
openstack%2Fsecurity-doc~master~I77d6ec363ecaa8990295c098dd4389621f2e854c,openstack/security-doc,master,I77d6ec363ecaa8990295c098dd4389621f2e854c,"Update “tenant"" to “project"" in security guide",ABANDONED,2015-05-27 02:49:07.000000000,2015-05-27 16:55:24.000000000,,"[{'_account_id': 3}, {'_account_id': 12325}]","[{'number': 1, 'created': '2015-05-27 02:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/46be743a8fae0784065494d2974f093115157201', 'message': 'few changes in security guide\n\nadded projects for tenant information\n\nChange-Id: I77d6ec363ecaa8990295c098dd4389621f2e854c\n'}, {'number': 2, 'created': '2015-05-27 15:54:32.000000000', 'files': ['security-guide/ch_instance-management.xml', 'security-guide/section_system-documentation-requirements.xml', 'security-guide/ch_tenant-data.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/7359b31066eced29304d3f72537b7e860e49b3c8', 'message': 'Update “tenant"" to “project"" in security guide\n\nchanged tenant to project and added tenant in parenthesis\n\nChange-Id: I77d6ec363ecaa8990295c098dd4389621f2e854c\n'}]",0,185827,7359b31066eced29304d3f72537b7e860e49b3c8,7,2,2,9382,,,0,"Update “tenant"" to “project"" in security guide

changed tenant to project and added tenant in parenthesis

Change-Id: I77d6ec363ecaa8990295c098dd4389621f2e854c
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/27/185827/2 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/ch_instance-management.xml', 'security-guide/section_system-documentation-requirements.xml', 'security-guide/ch_tenant-data.xml']",3,46be743a8fae0784065494d2974f093115157201,tenpr, <title>Project (tenant) data privacy</title> OpenStack is designed to support multi-tenancy and those projects will, <title>Tenant data privacy</title> OpenStack is designed to support multitenancy and those tenants will,4,4
openstack%2Fhorizon~master~Id6b4ddd3779e3be32e5b35508449437b114179a5,openstack/horizon,master,Id6b4ddd3779e3be32e5b35508449437b114179a5,made changes per doc conventions to policy.rst,ABANDONED,2015-04-17 19:58:47.000000000,2015-05-27 16:54:23.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6914}, {'_account_id': 9563}, {'_account_id': 12525}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-04-17 19:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/58124441e22ab3d80d7d392f1e3ad4655d490775', 'message': 'made changes per doc conventions to policy.rst\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\ndocumentation conventions for OpenStack\n\nChange-Id: Id6b4ddd3779e3be32e5b35508449437b114179a5\n'}, {'number': 2, 'created': '2015-04-18 20:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dddd8c6ef09ece99c500f2e33e01d5cf3f8db4df', 'message': 'made changes per doc conventions to policy.rst\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\ndocumentation conventions for OpenStack\n\nChange-Id: Id6b4ddd3779e3be32e5b35508449437b114179a5\n'}, {'number': 3, 'created': '2015-04-20 14:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/357adb8984e28e24443d6d8a735d977be59c57fc', 'message': 'made changes per doc conventions to policy.rst\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\ndocumentation conventions for OpenStack\nPartial-Bug: #1446253\n\nChange-Id: Id6b4ddd3779e3be32e5b35508449437b114179a5\n'}, {'number': 4, 'created': '2015-04-21 14:08:34.000000000', 'files': ['doc/source/topics/policy.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1265cef69c1a5d8fff5e89943940dbd3388bb5c8', 'message': 'made changes per doc conventions to policy.rst\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\ndocumentation conventions for OpenStack\nalso changed to address using active voice\nPartial-Bug: #1446253\n\nChange-Id: Id6b4ddd3779e3be32e5b35508449437b114179a5\n'}]",1,175032,1265cef69c1a5d8fff5e89943940dbd3388bb5c8,18,6,4,9382,,,0,"made changes per doc conventions to policy.rst

changed file to comply with official doc conventions
horizon should be lowercase per the official name
and capitalization section in the wiki
documentation conventions for OpenStack
also changed to address using active voice
Partial-Bug: #1446253

Change-Id: Id6b4ddd3779e3be32e5b35508449437b114179a5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/175032/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/policy.rst'],1,58124441e22ab3d80d7d392f1e3ad4655d490775,pol_rst,Horizon policy enforcement (RBAC: Role Based Access Control)horizon is based on copies of policy.json files found in the service'sfiles in horizon.Horizon settingsThere are a few settings that must be in place for the horizon policyHow to utilize RBAC will return false and the action will not be allowed.Rule targets,Horizon Policy Enforcement (RBAC: Role Based Access Control)Horizon is based on copies of policy.json files found in the service'sfiles in Horizon.Horizon SettingsThere are a few settings that must be in place for the Horizon policyHow to Utilize RBAC will return False and the action will not be allowed.Rule Targets,8,8
openstack%2Fhorizon~master~I94dfd662c6df0b56cc84b2b8c7b54dbabeb217cc,openstack/horizon,master,I94dfd662c6df0b56cc84b2b8c7b54dbabeb217cc,made changes per doc conventions to tables.rst,ABANDONED,2015-04-17 19:33:25.000000000,2015-05-27 16:54:14.000000000,,"[{'_account_id': 3}, {'_account_id': 9563}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-04-17 19:33:25.000000000', 'files': ['doc/source/topics/tables.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/591a460fd5df02a792ae3064d17b0f268c9f3a42', 'message': 'made changes per doc conventions to tables.rst\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\n\nChange-Id: I94dfd662c6df0b56cc84b2b8c7b54dbabeb217cc\n'}]",0,175018,591a460fd5df02a792ae3064d17b0f268c9f3a42,5,3,1,9382,,,0,"made changes per doc conventions to tables.rst

changed file to comply with official doc conventions
horizon should be lowercase per the official name
and capitalization section in the wiki

Change-Id: I94dfd662c6df0b56cc84b2b8c7b54dbabeb217cc
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/175018/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/tables.rst'],1,591a460fd5df02a792ae3064d17b0f268c9f3a42,tablesrst,wire it up to a view. To make this as easy as possible horizon provides theThere are several common tasks for which horizon provides pre-built shortcut,wire it up to a view. To make this as easy as possible Horizon provides theThere are several common tasks for which Horizon provides pre-built shortcut,2,2
openstack%2Fhorizon~master~I8c7f24feb16b98339011d33903467c26b79ee39a,openstack/horizon,master,I8c7f24feb16b98339011d33903467c26b79ee39a,Changes to testing.rst per doc convention,ABANDONED,2015-04-17 17:28:42.000000000,2015-05-27 16:54:06.000000000,,"[{'_account_id': 3}, {'_account_id': 9382}, {'_account_id': 9383}, {'_account_id': 9563}, {'_account_id': 12826}, {'_account_id': 15804}]","[{'number': 1, 'created': '2015-04-17 17:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f7212b829eddc4dbeabe00074d2fb43d563b6a4', 'message': 'Changes to contributing.rst per doc convention\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\nremoved “damn” from doc, unprofessional - changed to certain\n\nChange-Id: I8c7f24feb16b98339011d33903467c26b79ee39a\n'}, {'number': 2, 'created': '2015-04-17 19:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c5bc3b041d5ed49debe92eed79bf631c7bf2a0e8', 'message': 'Changes to testing.rst per doc convention\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\nremoved “damn” from doc, unprofessional - changed to certain\n\nChange-Id: I8c7f24feb16b98339011d33903467c26b79ee39a\n'}, {'number': 3, 'created': '2015-04-21 14:13:23.000000000', 'files': ['doc/source/topics/testing.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e249e884b9d607f29d70e2348e8b26251f216516', 'message': 'Changes to testing.rst per doc convention\n\nchanged file to comply with official doc conventions\nhorizon should be lowercase per the official name\nand capitalization section in the wiki\nremoved “damn” from doc, unprofessional - changed to certain\nPartial-Bug: #1446253\n\nChange-Id: I8c7f24feb16b98339011d33903467c26b79ee39a\n'}]",0,174972,e249e884b9d607f29d70e2348e8b26251f216516,16,6,3,9382,,,0,"Changes to testing.rst per doc convention

changed file to comply with official doc conventions
horizon should be lowercase per the official name
and capitalization section in the wiki
removed “damn” from doc, unprofessional - changed to certain
Partial-Bug: #1446253

Change-Id: I8c7f24feb16b98339011d33903467c26b79ee39a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/174972/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/testing.rst'],1,6f7212b829eddc4dbeabe00074d2fb43d563b6a4,top_testing,"to it, be certain you verify that it came out right.To that end, horizon includes several custom assertions to make these tasks","to it, be damn sure you verify that came out right.To that end, Horizon includes several custom assertions to make these tasks",2,2
openstack%2Fdevstack~master~Ie48ae4151bd6ad5bf5338228c300107621b700d3,openstack/devstack,master,Ie48ae4151bd6ad5bf5338228c300107621b700d3,doc change to plugins.rst,ABANDONED,2015-04-16 18:05:18.000000000,2015-05-27 16:53:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 9382}, {'_account_id': 9563}, {'_account_id': 10385}, {'_account_id': 12403}]","[{'number': 1, 'created': '2015-04-16 18:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/467f70d8b3b2d132f08bb5e368be1befef7c7ad3', 'message': 'doc change to plugins.rst\n\nplugging should be plug-in also spelled wrong\nchanged to plug-in throughout to comply with doc\nconventions\n\nChange-Id: Ie48ae4151bd6ad5bf5338228c300107621b700d3\n'}, {'number': 2, 'created': '2015-04-18 21:13:38.000000000', 'files': ['doc/source/plugins.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0748f0738f4c5b3481a113ae4d70fec6c4a9e059', 'message': 'doc change to plugins.rst\n\nplugging should be plug-in also spelled wrong\nchanged to plug-in throughout to comply with doc\nconventions\n\nChange-Id: Ie48ae4151bd6ad5bf5338228c300107621b700d3\n'}]",0,174511,0748f0738f4c5b3481a113ae4d70fec6c4a9e059,15,8,2,9382,,,0,"doc change to plugins.rst

plugging should be plug-in also spelled wrong
changed to plug-in throughout to comply with doc
conventions

Change-Id: Ie48ae4151bd6ad5bf5338228c300107621b700d3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/11/174511/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugins.rst'],1,467f70d8b3b2d132f08bb5e368be1befef7c7ad3,plugins_rs,"Plug-insDevStack has a couple of plug-in mechanisms to allow easily addingExternally Hosted Plug-ins ==========================for including plug-ins from external repositories. The plug-in interface sourced very early in the process. This is helpful if other plug-ins by your plug-in. This is especially important if you are kicking off- ``plugin.sh`` - the actual plug-in. It will be executed by devstack order for these plug-ins, and will occur immediately after all inPlug-ins are registered by adding the following to the localrc sectionPlug-ins for gate jobs ----------------------- All OpenStack plug-ins that wish to be used as gate jobs need to existnamespace are fine. This allows testing of the plug-in as well asIdeally plug-ins will be implemented as ``devstack`` directory insideproject has it's plug-in support in it's tree.``stackforge/devstack-plugin-FOO`` project to house the plug-in.Hypervisor plug-ins are fairly new and condense most hypervisorThe initial plug-in implemented was for Docker support and is a useful template for the required support. Plug-ins are placed inthe value of ``VIRT_DRIVER``. Plug-ins must define the followingphase of its execution. This packages may be defined in a plug-in as files that contain new-line separated lists of packages required by the plug-inTo enable a plug-in to hook into this and install package dependencies, packages may be listed at the following locations in the top-level of the plug-in","PluginsDevStack has a couple of plugin mechanisms to allow easily addingExternally Hosted Plugins =========================for including plugins from external repositories. The plugin interface sourced very early in the process. This is helpful if other plugins by your plugin. This is especially important if you are kicking off- ``plugin.sh`` - the actual plugin. It will be executed by devstack order for these plugins, and will occur immediately after all inPlugins are registered by adding the following to the localrc sectionPlugins for gate jobs --------------------- All OpenStack plugins that wish to be used as gate jobs need to existnamespace are fine. This allows testing of the plugin as well asIdeally plugins will be implemented as ``devstack`` directory insideproject has it's pluggin support in it's tree.``stackforge/devstack-plugin-FOO`` project to house the plugin.Hypervisor plugins are fairly new and condense most hypervisorThe initial plugin implemented was for Docker support and is a useful template for the required support. Plugins are placed inthe value of ``VIRT_DRIVER``. Plugins must define the followingphase of its execution. This packages may be defined in a plugin as files that contain new-line separated lists of packages required by the pluginTo enable a plugin to hook into this and install package dependencies, packages may be listed at the following locations in the top-level of the plugin",25,25
openstack%2Fpython-monascaclient~master~I95e078125c54789893f5056d746f86127c5e1738,openstack/python-monascaclient,master,I95e078125c54789893f5056d746f86127c5e1738,Add lifecycle fields to CLI,MERGED,2015-05-13 22:02:01.000000000,2015-05-27 16:52:09.000000000,2015-05-27 16:52:08.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-05-13 22:02:01.000000000', 'files': ['monascaclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/ceaf9d248e735cad628def3d3f722a870dd25497', 'message': 'Add lifecycle fields to CLI\n\nAdded two fields to alarms, lifecycle state and link.\n\nChange-Id: I95e078125c54789893f5056d746f86127c5e1738\n'}]",0,182869,ceaf9d248e735cad628def3d3f722a870dd25497,9,4,1,14517,,,0,"Add lifecycle fields to CLI

Added two fields to alarms, lifecycle state and link.

Change-Id: I95e078125c54789893f5056d746f86127c5e1738
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/69/182869/1 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/v2_0/shell.py'],1,ceaf9d248e735cad628def3d3f722a870dd25497,jah1553,"@utils.arg('--lifecycle-state', metavar='<LIFECYCLE_STATE>', help='The lifecycle state of the alarm') @utils.arg('--link', metavar='<LINK>', help='The link to external data associated with the alarm') if args.lifecycle_state: fields['lifecycle_state'] = args.lifecycle_state if args.link: fields['link'] = args.link 'lifecycle_state', 'link', 'state_updated_timestamp', 'updated_timestamp', ""created_timestamp""] 'lifecycle_state': lambda x: x['lifecycle_state'], 'link': lambda x: x['link'], 'updated_timestamp': lambda x: x['updated_timestamp'],@utils.arg('lifecycle_state', metavar='<LIFECYCLE_STATE>', help='The lifecycle state of the alarm') @utils.arg('link', metavar='<LINK>', help='A link to an external resource with information about the alarm') fields['lifecycle_state'] = args.lifecycle_state fields['link'] = args.link@utils.arg('--state', metavar='<ALARM_STATE>',@utils.arg('--lifecycle-state', metavar='<LIFECYCLE_STATE>', help='The lifecycle state of the alarm') @utils.arg('--link', metavar='<LINK>', help='A link to an external resource with information about the alarm') if args.state: if args.state.upper() not in state_types: fields['state'] = args.state if args.lifecycle_state: fields['lifecycle_state'] = args.lifecycle_state if args.link: fields['link'] = args.link"," 'state_updated_timestamp', ""created_timestamp""]@utils.arg('state', metavar='<ALARM_STATE>', if args.state.upper() not in state_types: fields['state'] = args.state",30,4
openstack%2Fcinder~stable%2Fkilo~I1368b74f79eb8c8560cf86df27f9af9541963a87,openstack/cinder,stable/kilo,I1368b74f79eb8c8560cf86df27f9af9541963a87,Enable use of filter_function in PureISCIDriver,ABANDONED,2015-04-22 23:21:29.000000000,2015-05-27 16:49:44.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 11611}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13394}, {'_account_id': 13868}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15374}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-04-22 23:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/84d2fb0c6b1140c2e723ffc0052733915c228bdb', 'message': 'Enable use of filter_function in PureISCIDriver\n\nAdding filter_function to capabilities of PureISCIDriver.  Return\ntotal_volumes as well for use with filter_function.\n\nChange-Id: I1368b74f79eb8c8560cf86df27f9af9541963a87\nCloses-Bug: 1437082'}, {'number': 2, 'created': '2015-04-22 23:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0ce93b6d1cb9f706e64a2adf3c3f71fcc398fea', 'message': 'Enable use of filter_function in PureISCIDriver\n\nAdding filter_function to capabilities of PureISCIDriver.  Return\ntotal_volumes as well for use with filter_function.\n\nChange-Id: I1368b74f79eb8c8560cf86df27f9af9541963a87\nCloses-Bug: 1437082\n(cherry picked from commit 1708dffe14b6ff6565e49d397939016f4fa59db4)\n'}, {'number': 3, 'created': '2015-05-13 18:10:47.000000000', 'files': ['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6c88057330adcc3fb76b2df9639140e541a0f718', 'message': 'Enable use of filter_function in PureISCIDriver\n\nAdding filter_function to capabilities of PureISCIDriver.  Return\ntotal_volumes as well for use with filter_function.\n\nThis will open a way for admins to prevent Cinder from scheduling\nvolumes on a Pure backend once it has reached the array’s limits. The\nprimary use case for this is volume limits. An example of a\nfilter_function that will prevent this issue would be:\n\nfilter_function=""capabilities.total_volumes < 500”\n\nThis will prevent any issues with Purity versions that are limited to\n500 volumes.\n\nWithout that filter_function the scheduler will continue to try and\nschedule volume creation if space is available instead of selecting\nanother backend. The end result would be volume creation fails and the\nvolume is in an error state even though there are backends available\nthat could have handled it.\n\nDocImpact: This means the PureISCSIDriver will now respect the\nfilter_function config option. Special Pure specific fields to filter\noff of need to be added to the driver config manual.\n\nChange-Id: I1368b74f79eb8c8560cf86df27f9af9541963a87\nCloses-Bug: 1437082\n(cherry picked from commit 27a1f66773755456a1bb135a940ba2a835c121a3)\n'}]",0,176542,6c88057330adcc3fb76b2df9639140e541a0f718,52,20,3,12924,,,0,"Enable use of filter_function in PureISCIDriver

Adding filter_function to capabilities of PureISCIDriver.  Return
total_volumes as well for use with filter_function.

This will open a way for admins to prevent Cinder from scheduling
volumes on a Pure backend once it has reached the array’s limits. The
primary use case for this is volume limits. An example of a
filter_function that will prevent this issue would be:

filter_function=""capabilities.total_volumes < 500”

This will prevent any issues with Purity versions that are limited to
500 volumes.

Without that filter_function the scheduler will continue to try and
schedule volume creation if space is available instead of selecting
another backend. The end result would be volume creation fails and the
volume is in an error state even though there are backends available
that could have handled it.

DocImpact: This means the PureISCSIDriver will now respect the
filter_function config option. Special Pure specific fields to filter
off of need to be added to the driver config manual.

Change-Id: I1368b74f79eb8c8560cf86df27f9af9541963a87
Closes-Bug: 1437082
(cherry picked from commit 27a1f66773755456a1bb135a940ba2a835c121a3)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/42/176542/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py']",2,84d2fb0c6b1140c2e723ffc0052733915c228bdb,bug/1437082," @mock.patch(DRIVER_OBJ + "".get_filter_function"", autospec=True) def test_get_volume_stats(self, mock_space, mock_filter): filter_function = ""capabilities.total_volumes < 10"" mock_space.return_value = (PROVISIONED_CAPACITY * units.Gi, 100) mock_filter.return_value = filter_function USED_SPACE), ""total_volumes"": 100, ""filter_function"": filter_function @mock.patch(DRIVER_OBJ + "".get_filter_function"", autospec=True) def test_get_volume_stats_empty_array(self, mock_space, mock_filter): filter_function = ""capabilities.total_volumes < 10"" mock_space.return_value = (PROVISIONED_CAPACITY * units.Gi, 100) mock_filter.return_value = filter_function ""max_over_subscription_ratio"": DEFAULT_OVER_SUBSCRIPTION, ""total_volumes"": 100, ""filter_function"": filter_function @mock.patch(DRIVER_OBJ + "".get_filter_function"", autospec=True) def test_get_volume_stats_nothing_provisioned(self, mock_space, mock_filter): filter_function = ""capabilities.total_volumes < 10"" mock_space.return_value = (0, 0) mock_filter.return_value = filter_function ""max_over_subscription_ratio"": DEFAULT_OVER_SUBSCRIPTION, ""total_volumes"": 0, ""filter_function"": filter_function"," def test_get_volume_stats(self, mock_space): mock_space.return_value = PROVISIONED_CAPACITY * units.Gi USED_SPACE) def test_get_volume_stats_empty_array(self, mock_space): mock_space.return_value = PROVISIONED_CAPACITY * units.Gi ""max_over_subscription_ratio"": DEFAULT_OVER_SUBSCRIPTION def test_get_volume_stats_nothing_provisioned(self, mock_space): mock_space.return_value = 0 ""max_over_subscription_ratio"": DEFAULT_OVER_SUBSCRIPTION",31,12
openstack%2Fec2-api~master~Iccc886c3a899f65cad2a097712b312ac18143e4c,openstack/ec2-api,master,Iccc886c3a899f65cad2a097712b312ac18143e4c,Move dict to xml conversion to ec2utils,MERGED,2015-05-27 13:43:35.000000000,2015-05-27 16:46:03.000000000,2015-05-27 15:26:54.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-27 13:43:35.000000000', 'files': ['ec2api/api/apirequest.py', 'ec2api/api/ec2utils.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/76c7d45442ff9978e3dd2d612f2872ed66ba084f', 'message': 'Move dict to xml conversion to ec2utils\n\nThis allows to use the conversion from other code\n\nChange-Id: Iccc886c3a899f65cad2a097712b312ac18143e4c\n'}]",0,185991,76c7d45442ff9978e3dd2d612f2872ed66ba084f,7,3,1,10224,,,0,"Move dict to xml conversion to ec2utils

This allows to use the conversion from other code

Change-Id: Iccc886c3a899f65cad2a097712b312ac18143e4c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/91/185991/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/apirequest.py', 'ec2api/api/ec2utils.py']",2,76c7d45442ff9978e3dd2d612f2872ed66ba084f,vpn,"import datetime# TODO(termie): replace minidom with etree from xml.dom import minidomfrom lxml import etreefrom oslo_utils import encodeutilsimport sixdef _render_dict(xml, el, data): try: for key in data.keys(): val = data[key] el.appendChild(_render_data(xml, key, val)) except Exception: LOG.debug(data) raise def _render_data(xml, el_name, data): data_el = xml.createElement(el_name) if isinstance(data, list): for item in data: data_el.appendChild(_render_data(xml, 'item', item)) elif isinstance(data, dict): _render_dict(xml, data_el, data) elif hasattr(data, '__dict__'): _render_dict(xml, data_el, data.__dict__) elif isinstance(data, bool): data_el.appendChild(xml.createTextNode(str(data).lower())) elif isinstance(data, datetime.datetime): data_el.appendChild( xml.createTextNode(_database_to_isoformat(data))) elif data is not None: data_el.appendChild(xml.createTextNode( encodeutils.safe_encode(six.text_type(data)))) return data_el def _database_to_isoformat(datetimeobj): """"""Return a xs:dateTime parsable string from datatime."""""" return datetimeobj.strftime(""%Y-%m-%dT%H:%M:%S.%f"")[:-3] + 'Z' def dict_to_lxml(data_dict, root_tag): xml = minidom.Document() response_el = xml.createElement(root_tag) _render_dict(xml, response_el, data_dict) xml.appendChild(response_el) response = xml.toxml() root = etree.fromstring(response) xml.unlink() return root ",,68,56
openstack%2Fkeystoneauth~master~Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3,openstack/keystoneauth,master,Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3,Remove oslo.utils dependency from keystoneauth,ABANDONED,2015-05-27 00:11:34.000000000,2015-05-27 16:45:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-27 00:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/dc391b669ae5489b5388d5a458bd7afc9f3cd584', 'message': 'Remove oslo.utils dependency from keystoneauth\n\nThe dependency on oslo.utils was due to timeutils. The specific isoformatting\nand parsing mostly was to capture errors and/or testing only. This has been\nmoved into the keystoneauth utils module. The minor duplication of code\nis intended to limit the dependencies of keystoneauth library.\n\nChange-Id: Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3\n'}, {'number': 2, 'created': '2015-05-27 00:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/c188b9c04352ba3ea302670a916df41c887923e4', 'message': 'Remove oslo.utils dependency from keystoneauth\n\nThe dependency on oslo.utils was due to timeutils. The specific isoformatting\nand parsing mostly was to capture errors and/or testing only. This has been\nmoved into the keystoneauth utils module. The minor duplication of code\nis intended to limit the dependencies of keystoneauth library.\n\nChange-Id: Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3\n'}, {'number': 3, 'created': '2015-05-27 00:43:38.000000000', 'files': ['keystoneauth/utils.py', 'keystoneauth/access.py', 'keystoneauth/session.py', 'requirements.txt', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/fixture/discovery.py', 'keystoneauth/fixture/v2.py', 'keystoneauth/fixture/v3.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/4c7afc152153c20979840af76db2edb8a50bbca6', 'message': 'Remove oslo.utils dependency from keystoneauth\n\nThe dependency on oslo.utils was due to timeutils. The specific isoformatting\nand parsing mostly was to capture errors and/or testing only. This has been\nmoved into the keystoneauth utils module. The minor duplication of code\nis intended to limit the dependencies of keystoneauth library.\n\nChange-Id: Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3\n'}]",0,185789,4c7afc152153c20979840af76db2edb8a50bbca6,7,3,3,2903,,,0,"Remove oslo.utils dependency from keystoneauth

The dependency on oslo.utils was due to timeutils. The specific isoformatting
and parsing mostly was to capture errors and/or testing only. This has been
moved into the keystoneauth utils module. The minor duplication of code
is intended to limit the dependencies of keystoneauth library.

Change-Id: Ibe9958a7737dd3dbd1a2cffb984e9d215e8d58c3
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/89/185789/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth/access.py', 'keystoneauth/utils.py', 'requirements.txt', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/fixture/discovery.py', 'keystoneauth/fixture/v2.py', 'keystoneauth/fixture/v3.py']",7,dc391b669ae5489b5388d5a458bd7afc9f3cd584,jsonutils,"from keystoneauth import utils issued = datetime.datetime.utcnow() - datetime.timedelta(minutes=2) return utils.parse_date(self.expires_str) self.expires_str = utils.isotime(value, subsecond=True) return utils.parse_date(self.issued_str) self.issued_str = utils.isotime(value, subsecond=True)","from oslo_utils import timeutils issued = timeutils.utcnow() - datetime.timedelta(minutes=2) return timeutils.parse_isotime(self.expires_str) self.expires_str = timeutils.isotime(value, subsecond=True) return timeutils.parse_isotime(self.issued_str) self.issued_str = timeutils.isotime(value, subsecond=True)",65,31
openstack%2Fshade~master~Ic4f5ddddfc403f21eba5972b24a3968ae3ce0a58,openstack/shade,master,Ic4f5ddddfc403f21eba5972b24a3968ae3ce0a58,Set metadata headers on object create,MERGED,2015-05-27 15:49:21.000000000,2015-05-27 16:43:30.000000000,2015-05-27 16:43:29.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-05-27 15:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/8d000ed7a6d6b1f17c4843301800d8b6661454d4', 'message': ""Set metadata headers on object create\n\nIt's a common swift deployment pattern for an update to be a server-side\nobject copy, which is quite expensive. Rather than doing a second update\nstep, just set the headers when we upload the image.\n\nChange-Id: Ic4f5ddddfc403f21eba5972b24a3968ae3ce0a58\n""}, {'number': 2, 'created': '2015-05-27 15:55:45.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/353875b55e1c527a19a23e9e52a7514e84f6e9c8', 'message': ""Set metadata headers on object create\n\nIt's a common swift deployment pattern for an update to be a server-side\nobject copy, which is quite expensive. Rather than doing a second update\nstep, just set the headers when we upload the image.\n\nChange-Id: Ic4f5ddddfc403f21eba5972b24a3968ae3ce0a58\n""}]",0,186048,353875b55e1c527a19a23e9e52a7514e84f6e9c8,9,4,2,2,,,0,"Set metadata headers on object create

It's a common swift deployment pattern for an update to be a server-side
object copy, which is quite expensive. Rather than doing a second update
step, just set the headers when we upload the image.

Change-Id: Ic4f5ddddfc403f21eba5972b24a3968ae3ce0a58
",git fetch https://review.opendev.org/openstack/shade refs/changes/48/186048/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,8d000ed7a6d6b1f17c4843301800d8b6661454d4,," if not md5 or not sha256: (md5, sha256) = self._get_file_hashes(filename) headers[OBJECT_MD5_KEY] = md5 headers[OBJECT_SHA256_KEY] = sha256 container=container, obj=name, contents=fileobj, headers=headers))"," container=container, obj=name, contents=fileobj)) (md5, sha256) = self._get_file_hashes(filename) headers[OBJECT_MD5_KEY] = md5 headers[OBJECT_SHA256_KEY] = sha256 self.manager.submitTask(_tasks.ObjectUpdate( container=container, obj=name, headers=headers))",7,7
openstack%2Fmonasca-api~master~If903267a36e5925d7fef01417fecad925e85da3e,openstack/monasca-api,master,If903267a36e5925d7fef01417fecad925e85da3e,Add lifecyclefields to alarms,MERGED,2015-05-13 21:52:06.000000000,2015-05-27 16:36:23.000000000,2015-05-27 16:36:20.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-05-13 21:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e5ec157cefa3d4c275caef6fd0a274e888c39823', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 2, 'created': '2015-05-14 18:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/838a9e5a456a5f1a7693d71cb7d1d3730e61dca2', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 3, 'created': '2015-05-14 22:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/b03023ead4b3d2b1c831f2c94c97bbc42a2cce31', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 4, 'created': '2015-05-19 17:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/1c786948138dbf4f81f135c23b0a65a2891f8d95', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 5, 'created': '2015-05-19 17:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/4271afe49eb2d2390a51a3decb3520e4337831c4', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nClosesBug: #1449705\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 6, 'created': '2015-05-19 21:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/a2940f50edf8c2cd2ada7fdf79f5bf954d0f741d', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nClosesBug: #1449705\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}, {'number': 7, 'created': '2015-05-20 16:50:52.000000000', 'files': ['java/src/main/java/monasca/api/infrastructure/persistence/mysql/AlarmMySqlRepoImpl.java', 'java/src/main/java/monasca/api/app/AlarmService.java', 'java/src/test/java/monasca/api/resource/LinksTest.java', 'java/src/main/java/monasca/api/app/validation/Validation.java', 'java/src/main/java/monasca/api/app/command/UpdateAlarmCommand.java', 'java/src/main/java/monasca/api/app/AlarmDefinitionService.java', 'java/src/main/java/monasca/api/resource/AlarmResource.java', 'java/src/test/java/monasca/api/infrastructure/persistence/mysql/AlarmMySqlRepositoryImplTest.java', 'java/src/main/java/monasca/api/domain/model/alarm/Alarm.java', 'java/src/main/java/monasca/api/domain/model/alarm/AlarmRepo.java', 'docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/70eec3f9937ffc7f72488282476bb18d73f354c9', 'message': 'Add lifecyclefields to alarms\n\nAdd lifecycle state and link to the alarm resources\n\nClosesBug: #1449705\n\nChange-Id: If903267a36e5925d7fef01417fecad925e85da3e\n'}]",24,182865,70eec3f9937ffc7f72488282476bb18d73f354c9,28,5,7,14517,,,0,"Add lifecyclefields to alarms

Add lifecycle state and link to the alarm resources

ClosesBug: #1449705

Change-Id: If903267a36e5925d7fef01417fecad925e85da3e
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/65/182865/1 && git format-patch -1 --stdout FETCH_HEAD,"['java/src/main/java/monasca/api/infrastructure/persistence/mysql/AlarmMySqlRepoImpl.java', 'java/src/main/java/monasca/api/app/AlarmService.java', 'java/src/test/java/monasca/api/resource/LinksTest.java', 'java/src/main/java/monasca/api/app/validation/Validation.java', 'java/src/main/java/monasca/api/app/command/UpdateAlarmCommand.java', 'java/src/main/java/monasca/api/app/AlarmDefinitionService.java', 'java/src/main/java/monasca/api/resource/AlarmResource.java', 'java/src/test/java/monasca/api/infrastructure/persistence/mysql/AlarmMySqlRepositoryImplTest.java', 'java/src/main/java/monasca/api/domain/model/alarm/Alarm.java', 'java/src/main/java/monasca/api/domain/model/alarm/AlarmRepo.java', 'docs/monasca-api-spec.md']",11,e5ec157cefa3d4c275caef6fd0a274e888c39823,jah1553,"Alarms have a state that is set by the Threshold Engine based on the incoming metrics. * UNDETERMINED - No metrics for at least one of the subexpressions has been received in (period + 2) times periods (see below for definition of period and periods * OK - Metrics have been received and the Alarm Definition Expression evaluates to false for the given metrics * ALARM - Metrics have been received and the Alarm Definition Expression evaluates to true for the given metricsAlarms contain three fields that may be edited via the API. These are the alarm state, lifecycle state, and the link. The alarm state is updated by Monasca as metrics are evaluated, and can be changed manually as necessary. The lifecycle state and link fields are not maintained or updated by Monasca, instead these are provided for storing information related to external tools. Returns a JSON alarm definition object with the following fields:Returns a JSON alarm definition object with the following parameters:* lifecycle_state (string(50), optional) - Lifecycle state to filter by. * link (string(512), optional) - Link to filter by.* lifecycle_state (string) - Lifecycle state of alarm. * link (string) - Link to an external resource related to the alarm. * state_updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the state was last updated. * updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when any field was last updated. * created_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the alarm was created. ""state"": ""OK"", ""lifecycle_state"":""OPEN"", ""link"":""http://somesite.com/this-alarm-info"", ""updated_timestamp"":""2015-03-20T21:04:49.000Z"",* lifecycle_state (string) - Lifecycle state of alarm. * link (string) - Link to an external resource related to the alarm. * state_updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the state was last updated. * updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when any field was last updated. * created_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the alarm was created. ""state"":""OK"", ""lifecycle_state"":""OPEN"", ""link"":""http://somesite.com/this-alarm-info"", ""updated_timestamp"": ""2015-03-20T21:04:49.000Z"",* lifecycle_state (string(50)) - Lifecycle state of alarm. * link (string(512)) - Url of an external resource related to the alarm. ""lifecycle_state"":""OPEN"" ""link"":""http://pagerduty.com/""* lifecycle_state (string) - Lifecycle state of alarm. * link (string) - Link to an external resource related to the alarm. * state_updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the state was last updated. * updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when any field was last updated. * created_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the alarm was created. ""lifecycle_state"":""OPEN"", ""link"":""http://somesite.com/this-alarm-info"", ""updated_timestamp"": ""2015-03-20T21:04:49.000Z"",* state (string, optional) - State of alarm, either `OK`, `ALARM` or `UNDETERMINED`. * lifecycle_state (string(50), optional) - Lifecycle state of alarm. * link (string(512), optional) - Link to external resource related to the alarm. ""state"":""OK"", ""lifecycle_state"":""OPEN"", ""link"":""http://somesite.com/this-alarm-info""* lifecycle_state (string) - Lifecycle state of the alarm. * link (string) - Link to an external resource related to the alarm. * state_updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the state was last updated. * updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when any field was last updated. * created_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the alarm was created. ""lifecycle_state"":""OPEN"", ""link"":""http://somesite.com/this-alarm-info"", ""updated_timestamp"": ""2015-03-20T21:04:49.000Z"",","Alarms have a state that is set by the Threshold Engine based on the incoming metrics. The states are: UNDETERMINED - No metrics for at least one of the subexpressions has been received in (period + 2) times periods (see below for definition of period and periods OK - Metrics have been received and the Alarm Definition Expression evaluates to false for the given metrics ALARM - Metrics have been received and the Alarm Definition Expression evaluates to true for the given metricsReturns a JSON alarm object with the following fields:Returns a JSON alarm object with the following parameters:* state_updated_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the state was last updated * created_timestamp - Timestamp in ISO 8601 combined date and time format in UTC when the alarm was created ""state"": ""OK"" ""state"":""OK""* state (string) - State of alarm, either `OK`, `ALARM` or `UNDETERMINED`. ""state"":""OK""",253,72
openstack%2Foslo.messaging~master~Ief3bf02f952882ecadf742cdd0bac8edd7812473,openstack/oslo.messaging,master,Ief3bf02f952882ecadf742cdd0bac8edd7812473,consumer connections not closed properly,MERGED,2015-05-26 18:38:42.000000000,2015-05-27 16:20:35.000000000,2015-05-27 16:20:33.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 7729}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-05-26 18:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/329f94bcb3efd76fd67ad1fdab8c5973584cec72', 'message': 'consumer connections not closed properly\n\nheartbeat_thread is not set for listeners. when closing connection,\nit blindly checks heartbeat_thread and will throw an error causing\nconnection to remain open. this patch explicitly sets\nheartbeat_thread to None.\n\nChange-Id: Ief3bf02f952882ecadf742cdd0bac8edd7812473\nCloses-Bug: #1458917\n'}, {'number': 2, 'created': '2015-05-26 20:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/10b4ceddeab6b55d006fff14dea43c70d55e1287', 'message': 'consumer connections not closed properly\n\nheartbeat_thread is not set for listeners. when closing connection,\nit blindly checks heartbeat_thread and will throw an error causing\nconnection to remain open. this patch explicitly sets\nheartbeat_thread to None.\n\nChange-Id: Ief3bf02f952882ecadf742cdd0bac8edd7812473\nCloses-Bug: #1458917\n'}, {'number': 3, 'created': '2015-05-27 01:22:22.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a45084126452c7ce2a7da43e09a2654f2ee9ec2d', 'message': 'consumer connections not closed properly\n\nheartbeat_thread is not set for listeners. when closing connection,\nit blindly checks heartbeat_thread and will throw an error causing\nconnection to remain open. this patch explicitly sets\nheartbeat_thread to None.\n\nChange-Id: Ief3bf02f952882ecadf742cdd0bac8edd7812473\nCloses-Bug: #1458917\n'}]",0,185693,a45084126452c7ce2a7da43e09a2654f2ee9ec2d,17,5,3,6537,,,0,"consumer connections not closed properly

heartbeat_thread is not set for listeners. when closing connection,
it blindly checks heartbeat_thread and will throw an error causing
connection to remain open. this patch explicitly sets
heartbeat_thread to None.

Change-Id: Ief3bf02f952882ecadf742cdd0bac8edd7812473
Closes-Bug: #1458917
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/93/185693/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,329f94bcb3efd76fd67ad1fdab8c5973584cec72,bug/1458917, self._heartbeat_thread = None,,1,0
openstack%2Ffuel-web~master~Iee80c67c6e1ea81c03f3df506f9868df368e6a3e,openstack/fuel-web,master,Iee80c67c6e1ea81c03f3df506f9868df368e6a3e,Support none action for settings,MERGED,2015-05-27 15:50:51.000000000,2015-05-27 16:19:51.000000000,2015-05-27 16:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-05-27 15:50:51.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ac8668cc06368fe22330e293c9ce8655d46846bd', 'message': 'Support none action for settings\n\nCloses-Bug: #1459317\n\nChange-Id: Iee80c67c6e1ea81c03f3df506f9868df368e6a3e\n'}]",0,186049,ac8668cc06368fe22330e293c9ce8655d46846bd,11,3,1,8766,,,0,"Support none action for settings

Closes-Bug: #1459317

Change-Id: Iee80c67c6e1ea81c03f3df506f9868df368e6a3e
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/49/186049/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx'],1,ac8668cc06368fe22330e293c9ce8655d46846bd,bug/1459317," path = this.props.makePath(groupName, settingName), var restrictionsCheck = this.checkRestrictions('disable', path), dependentSettings = this.checkDependentSettings(groupName, settingName), messagesCheck = this.checkRestrictions('none', path); if (messagesCheck.message) messages.push(messagesCheck.message);"," var restrictionsCheck = this.checkRestrictions('disable', this.props.makePath(groupName, settingName)), dependentSettings = this.checkDependentSettings(groupName, settingName);",5,2
openstack%2Fopenstacksdk~master~I7f7d8c982d0f48de3687a6697e7a8632f1f3064e,openstack/openstacksdk,master,I7f7d8c982d0f48de3687a6697e7a8632f1f3064e,Initial commit for the Messaging service (Zaqar),MERGED,2015-05-09 04:33:24.000000000,2015-05-27 16:14:02.000000000,2015-05-27 16:14:02.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-09 04:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/550cc3dc347b1b75212409056550414afda39e3b', 'message': 'Initial commit for the Messaging service (Zaqar)\n\nStart the Messaging service off with one call to create a queue.\n\nChange-Id: I7f7d8c982d0f48de3687a6697e7a8632f1f3064e\n'}, {'number': 2, 'created': '2015-05-11 17:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e5ab00747d8652968f5b08b9aa928028e8f972ab', 'message': 'Initial commit for the Messaging service (Zaqar)\n\nStart the Messaging service off with one call to create a queue.\n\nChange-Id: I7f7d8c982d0f48de3687a6697e7a8632f1f3064e\n'}, {'number': 3, 'created': '2015-05-13 16:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7ff12dbcfab1403673eeeaaa72c22e835ba2b026', 'message': 'Initial commit for the Messaging service (Zaqar)\n\nStart the Messaging service off with one call to create a queue.\n\nChange-Id: I7f7d8c982d0f48de3687a6697e7a8632f1f3064e\n'}, {'number': 4, 'created': '2015-05-27 04:53:37.000000000', 'files': ['openstack/messaging/v1/queue.py', 'openstack/tests/unit/messaging/test_messaging_service.py', 'openstack/tests/unit/messaging/__init__.py', 'doc/source/contributors/local.conf', 'openstack/tests/unit/messaging/v1/test_queue.py', 'openstack/messaging/v1/_proxy.py', 'openstack/tests/unit/messaging/test_version.py', 'openstack/messaging/version.py', 'openstack/tests/unit/test_profile.py', 'openstack/profile.py', 'openstack/tests/unit/messaging/v1/test_proxy.py', 'openstack/tests/unit/messaging/v1/__init__.py', 'openstack/messaging/messaging_service.py', 'openstack/messaging/__init__.py', 'openstack/messaging/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0894d9f9ac0464d19d5cb057035a856663064972', 'message': 'Initial commit for the Messaging service (Zaqar)\n\nStart the Messaging service off with one call to create a queue.\n\nChange-Id: I7f7d8c982d0f48de3687a6697e7a8632f1f3064e\n'}]",13,181607,0894d9f9ac0464d19d5cb057035a856663064972,24,4,4,1112,,,0,"Initial commit for the Messaging service (Zaqar)

Start the Messaging service off with one call to create a queue.

Change-Id: I7f7d8c982d0f48de3687a6697e7a8632f1f3064e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/07/181607/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/messaging/v1/queue.py', 'openstack/tests/functional/messaging/__init__.py', 'openstack/tests/unit/messaging/test_messaging_service.py', 'openstack/tests/unit/messaging/__init__.py', 'openstack/tests/functional/messaging/v1/__init__.py', 'doc/source/contributors/local.conf', 'openstack/tests/unit/test_user_preference.py', 'openstack/tests/unit/messaging/v1/test_queue.py', 'openstack/messaging/v1/_proxy.py', 'openstack/tests/unit/messaging/test_version.py', 'openstack/messaging/version.py', 'openstack/user_preference.py', 'openstack/tests/unit/messaging/v1/test_proxy.py', 'openstack/tests/unit/messaging/v1/__init__.py', 'openstack/messaging/messaging_service.py', 'openstack/messaging/__init__.py', 'openstack/messaging/v1/__init__.py', 'openstack/tests/functional/messaging/v1/test_queue.py']",18,550cc3dc347b1b75212409056550414afda39e3b,messaging,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import unittest import os_client_config from openstack import connection from openstack import user_preference class TestQueue(unittest.TestCase): def setUp(self): test_cloud = os_client_config.OpenStackConfig().get_one_cloud( 'test_cloud') pref = user_preference.UserPreference() pref.set_region(pref.ALL, test_cloud.region) self.conn = connection.Connection( preference=pref, auth_url=test_cloud.config['auth']['auth_url'], project_name=test_cloud.config['auth']['project_name'], username=test_cloud.config['auth']['username'], password=test_cloud.config['auth']['password']) def test_create_queue(self): self.conn.messaging.create_queue(name='test_queue') ",,304,0
openstack%2Fshade~master~I6011e9822a52428dbe7d9aaf4d130e655b16253d,openstack/shade,master,I6011e9822a52428dbe7d9aaf4d130e655b16253d,Turn server object to dict so we can pop things,ABANDONED,2015-05-27 13:13:39.000000000,2015-05-27 16:11:51.000000000,,"[{'_account_id': 3}, {'_account_id': 3099}]","[{'number': 1, 'created': '2015-05-27 13:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/663fbe42e83e466fc1f62cd10f4632084d0e82da', 'message': ""Turn server object to dict so we can pop things\n\nWe're transforming data from a server object to a dict of metadata -\nexcept we forgot to turn it into a dict first.\n\nChange-Id: I6011e9822a52428dbe7d9aaf4d130e655b16253d\n""}, {'number': 2, 'created': '2015-05-27 13:29:22.000000000', 'files': ['shade/meta.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/9260d271dd2f38766255bf2ad87d1e854443ce92', 'message': ""Turn server object to dict so we can pop things\n\nThere are consumers out in the wild who are wanting to pass server\nobjects and not dicts. That's a little sad, but it's easy to deal with.\n\nChange-Id: I6011e9822a52428dbe7d9aaf4d130e655b16253d\n""}]",0,185976,9260d271dd2f38766255bf2ad87d1e854443ce92,5,2,2,2,,,0,"Turn server object to dict so we can pop things

There are consumers out in the wild who are wanting to pass server
objects and not dicts. That's a little sad, but it's easy to deal with.

Change-Id: I6011e9822a52428dbe7d9aaf4d130e655b16253d
",git fetch https://review.opendev.org/openstack/shade refs/changes/76/185976/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/meta.py'],1,663fbe42e83e466fc1f62cd10f4632084d0e82da,, server_vars = obj_to_dict(server), server_vars = server,1,1
openstack%2Fpython-heatclient~master~Ib172834f5fc0d60521161c82d0c4793e920646de,openstack/python-heatclient,master,Ib172834f5fc0d60521161c82d0c4793e920646de,Add stack tag filtering options to stack-list,MERGED,2015-05-15 19:50:30.000000000,2015-05-27 16:07:49.000000000,2015-05-27 16:07:20.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11714}, {'_account_id': 12259}, {'_account_id': 12321}, {'_account_id': 12606}]","[{'number': 1, 'created': '2015-05-15 19:50:30.000000000', 'files': ['heatclient/tests/unit/test_shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7ff6ddba90f1be7a51607a82536755e7cb73a083', 'message': 'Add stack tag filtering options to stack-list\n\nAdd four new stack-list options to support filtering by stack tags:\n""--tags"", ""--tags-any"", ""--not-tags"", and ""--not-tags-any"".\n\nExamples:\n  heat stack-list --tags=tag1,tag2\n  heat stack-list --tags-any=tag3,tag4\n  heat stack-list --not-tags=tag5,tag6\n  heat stack-list --not-tags-any=tag7,tag8\n\nblueprint stack-tags\n\nChange-Id: Ib172834f5fc0d60521161c82d0c4793e920646de\n'}]",0,183679,7ff6ddba90f1be7a51607a82536755e7cb73a083,23,10,1,7253,,,0,"Add stack tag filtering options to stack-list

Add four new stack-list options to support filtering by stack tags:
""--tags"", ""--tags-any"", ""--not-tags"", and ""--not-tags-any"".

Examples:
  heat stack-list --tags=tag1,tag2
  heat stack-list --tags-any=tag3,tag4
  heat stack-list --not-tags=tag5,tag6
  heat stack-list --not-tags-any=tag7,tag8

blueprint stack-tags

Change-Id: Ib172834f5fc0d60521161c82d0c4793e920646de
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/79/183679/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/test_shell.py', 'heatclient/v1/shell.py']",2,7ff6ddba90f1be7a51607a82536755e7cb73a083,bp/stack-tags,"@utils.arg('-t', '--tags', metavar='<TAG1,TAG2...>', help=_('Show stacks containing these tags, combine multiple tags ' 'using the boolean AND expression')) @utils.arg('--tags-any', metavar='<TAG1,TAG2...>', help=_('Show stacks containing these tags, combine multiple tags ' 'using the boolean OR expression')) @utils.arg('--not-tags', metavar='<TAG1,TAG2...>', help=_('Show stacks not containing these tags, combine multiple ' 'tags using the boolean AND expression')) @utils.arg('--not-tags-any', metavar='<TAG1,TAG2...>', help=_('Show stacks not containing these tags, combine multiple ' 'tags using the boolean OR expression')) 'tags': args.tags, 'tags_any': args.tags_any, 'not_tags': args.not_tags, 'not_tags_any': args.not_tags_any,",,24,0
openstack%2Fswift~master~I2c4e585221387dd02a8679a50398d6b614407b12,openstack/swift,master,I2c4e585221387dd02a8679a50398d6b614407b12,Allow SLO PUTs to forgo per-segment integrity checks,MERGED,2015-05-20 13:09:52.000000000,2015-05-27 16:07:31.000000000,2015-05-27 16:07:29.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 12279}, {'_account_id': 15343}]","[{'number': 1, 'created': '2015-05-20 13:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ecedf14fbd8ea0365a442596c7e03a68b927e1a4', 'message': ""Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require 'etag' and 'size_bytes' fields for each\nsegment (to catch user errors like 'etaf' or 'size_btyes'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\n""}, {'number': 2, 'created': '2015-05-20 21:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/40a4260d7fd51aff018a55e54846943effbcfe05', 'message': 'Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require \'etag\' and \'size_bytes\' fields for each\nsegment (to catch user errors like \'etaf\' or \'size_btyes\'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment. So, if a user\nuploads a manifest like:\n\n    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},\n     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},\n     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]\n\nthen the etag will only be verified for the /con/obj_seg_2 segment,\nand the segment size will only be verified for the /con/obj_seg_3\nsegment. However, the manifest that\'s ultimately stored (and can be\nretrieved with a ?multipart-manifest=get query-string) will still look\nlike:\n\n    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]\n\nThis allows the middleware to continue performing integrity checks on\nobject GET.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\n'}, {'number': 3, 'created': '2015-05-20 22:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/17e382902a459b7142f16ad3f05a755c4e5dc03a', 'message': 'Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require \'etag\' and \'size_bytes\' fields for each\nsegment (to catch user errors like \'etaf\' or \'size_btyes\'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment. So, if a user\nuploads a manifest like:\n\n    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},\n     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},\n     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]\n\nthen the etag will only be verified for the /con/obj_seg_2 segment,\nand the segment size will only be verified for the /con/obj_seg_3\nsegment. However, the manifest that\'s ultimately stored (and can be\nretrieved with a ?multipart-manifest=get query-string) will still look\nlike:\n\n    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]\n\nThis allows the middleware to continue performing integrity checks on\nobject GET.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\nDocImpact\n'}, {'number': 4, 'created': '2015-05-20 23:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/66af061de7f43805685847aabd7ddeda543ab15b', 'message': 'Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require \'etag\' and \'size_bytes\' fields for each\nsegment (to catch user errors like \'etaf\' or \'size_btyes\'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment. So, if a user\nuploads a manifest like:\n\n    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},\n     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},\n     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]\n\nthen the etag will only be verified for the /con/obj_seg_2 segment,\nand the segment size will only be verified for the /con/obj_seg_3\nsegment. However, the manifest that\'s ultimately stored (and can be\nretrieved with a ?multipart-manifest=get query-string) will still look\nlike:\n\n    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]\n\nThis allows the middleware to continue performing integrity checks on\nobject GET.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\nDocImpact\n'}, {'number': 5, 'created': '2015-05-21 18:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8bbb0b320d4ff6c8434878b73389499e771e6ad4', 'message': 'Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require \'etag\' and \'size_bytes\' fields for each\nsegment (to catch user errors like \'etaf\' or \'size_btyes\'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment. So, if a user\nuploads a manifest like:\n\n    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},\n     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},\n     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]\n\nthen the etag will only be verified for the /con/obj_seg_2 segment,\nand the segment size will only be verified for the /con/obj_seg_3\nsegment. However, the manifest that\'s ultimately stored (and can be\nretrieved with a ?multipart-manifest=get query-string) will still look\nlike:\n\n    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]\n\nThis allows the middleware to continue performing integrity checks on\nobject GET.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\nDocImpact\n'}, {'number': 6, 'created': '2015-05-27 13:38:45.000000000', 'files': ['swift/common/middleware/slo.py', 'test/unit/common/middleware/test_slo.py', 'test/functional/tests.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bb716573ab5c8455348ec013feb894421e0e1f1c', 'message': 'Allow SLO PUTs to forgo per-segment integrity checks\n\nWhile manifests still require \'etag\' and \'size_bytes\' fields for each\nsegment (to catch user errors like \'etaf\' or \'size_btyes\'), an explicit\nnull for either will skip that particular integrity check and instead\nuse whatever value is retrieved when HEADing the segment. So, if a user\nuploads a manifest like:\n\n    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},\n     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},\n     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]\n\nthen the etag will only be verified for the /con/obj_seg_2 segment,\nand the segment size will only be verified for the /con/obj_seg_1\nsegment. However, the manifest that\'s ultimately stored (and can be\nretrieved with a ?multipart-manifest=get query-string) will still look\nlike:\n\n    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},\n     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]\n\nThis allows the middleware to continue performing integrity checks on\nobject GET.\n\nChange-Id: I2c4e585221387dd02a8679a50398d6b614407b12\nDocImpact\n'}]",3,184479,bb716573ab5c8455348ec013feb894421e0e1f1c,27,8,6,15343,,,0,"Allow SLO PUTs to forgo per-segment integrity checks

While manifests still require 'etag' and 'size_bytes' fields for each
segment (to catch user errors like 'etaf' or 'size_btyes'), an explicit
null for either will skip that particular integrity check and instead
use whatever value is retrieved when HEADing the segment. So, if a user
uploads a manifest like:

    [{""path"": ""/con/obj_seg_1"", ""etag"": null, ""size_bytes"": 1048576},
     {""path"": ""/con/obj_seg_2"", ""etag"": ""etag2"", ""size_bytes"": null},
     {""path"": ""/con/obj_seg_3"", ""etag"": null, ""size_bytes"": null}]

then the etag will only be verified for the /con/obj_seg_2 segment,
and the segment size will only be verified for the /con/obj_seg_1
segment. However, the manifest that's ultimately stored (and can be
retrieved with a ?multipart-manifest=get query-string) will still look
like:

    [{""name"": ""/con/obj_seg_1"", ""hash"": ""etag1"", ""bytes"": 1048576, ...},
     {""name"": ""/con/obj_seg_2"", ""hash"": ""etag2"", ""bytes"": 1048576, ...},
     {""name"": ""/con/obj_seg_3"", ""hash"": ""etag3"", ""bytes"": 1234, ...}]

This allows the middleware to continue performing integrity checks on
object GET.

Change-Id: I2c4e585221387dd02a8679a50398d6b614407b12
DocImpact
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/184479/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/slo.py', 'test/unit/common/middleware/test_slo.py']",2,ecedf14fbd8ea0365a442596c7e03a68b927e1a4,184479," def test_handle_multipart_put_skip_size_check(self): good_data = json.dumps( [{'path': '/checktest/a_1', 'etag': 'a', 'size_bytes': None}, {'path': '/checktest/b_2', 'etag': 'b', 'size_bytes': None}]) req = Request.blank( '/v1/AUTH_test/checktest/man_3?multipart-manifest=put', environ={'REQUEST_METHOD': 'PUT'}, body=good_data) status, headers, body = self.call_slo(req) self.assertEquals(self.app.call_count, 3) # Check that we still populated the manifest properly from our HEADs req = Request.blank( # this string looks weird, but it's just an artifact # of FakeSwift '/v1/AUTH_test/checktest/man_3?multipart-manifest=put', environ={'REQUEST_METHOD': 'GET'}) status, headers, body = self.call_app(req) manifest_data = json.loads(body) self.assertEquals(1, manifest_data[0]['bytes']) self.assertEquals(2, manifest_data[1]['bytes']) def test_handle_multipart_put_skip_size_check_still_uses_min_size(self): with patch.object(self.slo, 'min_segment_size', 50): test_json_data = json.dumps([{'path': '/cont/small_object', 'etag': 'etagoftheobjectsegment', 'size_bytes': None}, {'path': '/cont/small_object', 'etag': 'etagoftheobjectsegment', 'size_bytes': 100}]) req = Request.blank('/v1/AUTH_test/c/o', body=test_json_data) try: self.slo.handle_multipart_put(req, fake_start_response) except HTTPException as e: pass self.assertEquals(e.status_int, 400) def test_handle_multipart_put_skip_etag_check(self): good_data = json.dumps( [{'path': '/checktest/a_1', 'etag': None, 'size_bytes': 1}, {'path': '/checktest/b_2', 'etag': None, 'size_bytes': 2}]) req = Request.blank( '/v1/AUTH_test/checktest/man_3?multipart-manifest=put', environ={'REQUEST_METHOD': 'PUT'}, body=good_data) status, headers, body = self.call_slo(req) self.assertEquals(self.app.call_count, 3) # Check that we still populated the manifest properly from our HEADs req = Request.blank( # this string looks weird, but it's just an artifact # of FakeSwift '/v1/AUTH_test/checktest/man_3?multipart-manifest=put', environ={'REQUEST_METHOD': 'GET'}) status, headers, body = self.call_app(req) manifest_data = json.loads(body) self.assertEquals('a', manifest_data[0]['hash']) self.assertEquals('b', manifest_data[1]['hash']) ",,75,8
openstack%2Fdragonflow~master~Ib7a8fadf3a6349f7554f32527a79cbda14bb56b1,openstack/dragonflow,master,Ib7a8fadf3a6349f7554f32527a79cbda14bb56b1,"Fix README 1) Fix documentation link, move doc title  up 2) Added link to the project blueprints",MERGED,2015-05-27 09:47:47.000000000,2015-05-27 16:02:08.000000000,2015-05-27 16:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-27 09:47:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b80db889e6fb8b9ffddf988274c8df570948a63f', 'message': 'Fix README\n1) Fix documentation link, move doc title  up\n2) Added link to the project blueprints\n\nChange-Id: Ib7a8fadf3a6349f7554f32527a79cbda14bb56b1\n'}]",1,185907,b80db889e6fb8b9ffddf988274c8df570948a63f,8,4,1,13070,,,0,"Fix README
1) Fix documentation link, move doc title  up
2) Added link to the project blueprints

Change-Id: Ib7a8fadf3a6349f7554f32527a79cbda14bb56b1
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/07/185907/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b80db889e6fb8b9ffddf988274c8df570948a63f,bp/s,Documentation: -------------- * `Solution Overview Presentation <http://www.slideshare.net/gampel/dragonflow-sdn-based-distributed-virtual-router-for-openstack-neutron>`_ * `Solution Overview Blog Post <http://blog.gampel.net/2015/01/neutron-dvr-sdn-way.html>`_ * `Deep-Dive Introduction 1 Blog Post <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/05/09/dragonflow-1/>`_ * `Deep-Dive Introduction 2 Blog Post <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/05/11/dragonflow-2/>`_ * `Kilo-Release Blog Post <http://blog.gampel.net/2015/01/dragonflow-sdn-based-distributed.html>`_ Full description can be found in the project `Blueprints <https://blueprints.launchpad.net/dragonflow>`_ ,* Documentation: `Documentation <#Documentation>`_ Documentation: -------------- * `Solution Overview Presentation <http://www.slideshare.net/gampel/dragonflow-sdn-based-distributed-virtual-router-for-openstack-neutron>`_ * `Solution Overview Blog Post <http://blog.gampel.net/2015/01/neutron-dvr-sdn-way.html>`_ * `Deep-Dive Introduction 1 Blog Post <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/05/09/dragonflow-1/>`_ * `Deep-Dive Introduction 2 Blog Post <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/05/11/dragonflow-2/>`_ * `Kilo-Release Blog Post <http://blog.gampel.net/2015/01/dragonflow-sdn-based-distributed.html>`_ * Remove change impact on Neutron L2 Agent by switching to OVSDB command for bootstrap sequence (set-controller and install ARP responder),15,15
openstack%2Fdragonflow~master~I24b25edd254f9c301a6e0f80a0f73f1bdb7ae263,openstack/dragonflow,master,I24b25edd254f9c301a6e0f80a0f73f1bdb7ae263,Supress port sync up exception,MERGED,2015-05-27 08:30:40.000000000,2015-05-27 16:02:00.000000000,2015-05-27 16:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-27 08:30:40.000000000', 'files': ['dragonflow/neutron/agent/l3/l3_controller_agent.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/51579ff197ffb23d80dd10d76c6d507155871a6b', 'message': 'Supress port sync up exception\n\nContinue the L3 Agent boot process even if the sync\nprocess failed (can happen on ./stack)\n\nChange-Id: I24b25edd254f9c301a6e0f80a0f73f1bdb7ae263\n'}]",0,185877,51579ff197ffb23d80dd10d76c6d507155871a6b,8,5,1,11343,,,0,"Supress port sync up exception

Continue the L3 Agent boot process even if the sync
process failed (can happen on ./stack)

Change-Id: I24b25edd254f9c301a6e0f80a0f73f1bdb7ae263
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/77/185877/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/agent/l3/l3_controller_agent.py'],1,51579ff197ffb23d80dd10d76c6d507155871a6b,supress_rpc_exception, return, raise,1,1
openstack%2Fdragonflow~master~I2aa959c39f9923883bc2000d9cd09ae2ec294b14,openstack/dragonflow,master,I2aa959c39f9923883bc2000d9cd09ae2ec294b14,"Set int-br fail mode to ""standalone""",MERGED,2015-05-27 07:42:54.000000000,2015-05-27 16:01:12.000000000,2015-05-27 16:01:11.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-27 07:42:54.000000000', 'files': ['dragonflow/neutron/agent/l2/ovs_dragonflow_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e02217d349441628c1343302a7d7e1bbf435e580', 'message': 'Set int-br fail mode to ""standalone""\n\nIf  the  value  is  standalone, or if neither of these settings is set,\novs-vswitchd will take over responsibility for setting up flows when no\nmessage has been received from the controller for three times the inactivity\nprobe interval.  In this mode, ovs-vswitchd causes the  datapath\nto act like an ordinary MAC-learning switch.  ovs-vswitchd will continue\nto retry connecting to the controller in the background and, when\nthe connection succeeds, it discontinues its standalone behavior.\n\nIf this option is set to secure, ovs-vswitchd will not set up flows on\nits own when the controller connection fails.\n\nChange-Id: I2aa959c39f9923883bc2000d9cd09ae2ec294b14\n'}]",0,185864,e02217d349441628c1343302a7d7e1bbf435e580,8,5,1,11343,,,0,"Set int-br fail mode to ""standalone""

If  the  value  is  standalone, or if neither of these settings is set,
ovs-vswitchd will take over responsibility for setting up flows when no
message has been received from the controller for three times the inactivity
probe interval.  In this mode, ovs-vswitchd causes the  datapath
to act like an ordinary MAC-learning switch.  ovs-vswitchd will continue
to retry connecting to the controller in the background and, when
the connection succeeds, it discontinues its standalone behavior.

If this option is set to secure, ovs-vswitchd will not set up flows on
its own when the controller connection fails.

Change-Id: I2aa959c39f9923883bc2000d9cd09ae2ec294b14
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/64/185864/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/agent/l2/ovs_dragonflow_neutron_agent.py'],1,e02217d349441628c1343302a7d7e1bbf435e580,," # TODO(gsagie) change this to the API call when # https://review.openstack.org/#/c/185659/ gets merged bridge.ovsdb.set_fail_mode(bridge.br_name, ""standalone"").execute(check_error=True)",,5,0
openstack%2Frequirements~master~I4e2190434247f428ceb7482df7e9c7222ed9c4dc,openstack/requirements,master,I4e2190434247f428ceb7482df7e9c7222ed9c4dc,Kazoo 2.1 has a bug which is breaking tooz gate,MERGED,2015-05-22 17:52:22.000000000,2015-05-27 15:55:28.000000000,2015-05-27 01:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-05-22 17:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ac5a4021cac9ce85060c3880ff226036fac1cdd3', 'message': 'Kazoo 2.1 has a bug which is breaking tooz gate\n\nThis bug is opened at https://github.com/python-zk/kazoo/issues/315\n\nThe PR fix is at https://github.com/python-zk/kazoo/pull/316\n\nUntil that merges and is released reduce the required version to a\nknown set that is known to work (vs one that is not).\n\nChange-Id: I4e2190434247f428ceb7482df7e9c7222ed9c4dc\n'}, {'number': 2, 'created': '2015-05-26 20:10:54.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e562a7f4c0eafca7ba5c300dd5999c12b9b4fc52', 'message': 'Kazoo 2.1 has a bug which is breaking tooz gate\n\nThis bug is opened at https://github.com/python-zk/kazoo/issues/315\n\nThe PR fix is at https://github.com/python-zk/kazoo/pull/316\n\nUntil that merges and is released reduce the required version to a\nknown set that is known to work (vs one that is not).\n\nChange-Id: I4e2190434247f428ceb7482df7e9c7222ed9c4dc\n'}]",0,185095,e562a7f4c0eafca7ba5c300dd5999c12b9b4fc52,11,7,2,1297,,,0,"Kazoo 2.1 has a bug which is breaking tooz gate

This bug is opened at https://github.com/python-zk/kazoo/issues/315

The PR fix is at https://github.com/python-zk/kazoo/pull/316

Until that merges and is released reduce the required version to a
known set that is known to work (vs one that is not).

Change-Id: I4e2190434247f428ceb7482df7e9c7222ed9c4dc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/95/185095/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,ac5a4021cac9ce85060c3880ff226036fac1cdd3,,"kazoo>=1.3.1,<2.1",kazoo>=1.3.1,1,1
openstack%2Fastara~master~I7db92bc7fd3743d89d73ab2a0b8da14685c30c69,openstack/astara,master,I7db92bc7fd3743d89d73ab2a0b8da14685c30c69,Remove appliance's hard-coded password in favor of ssh pub key,MERGED,2015-05-23 00:10:30.000000000,2015-05-27 15:55:27.000000000,2015-05-27 15:55:26.000000000,"[{'_account_id': 3}, {'_account_id': 986}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 3208}, {'_account_id': 6287}, {'_account_id': 6923}, {'_account_id': 8005}, {'_account_id': 14473}]","[{'number': 1, 'created': '2015-05-23 00:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d2fc59144ce6495e9824c0a391f2b209696a2b56', 'message': ""Remove appliance's hard-coded password in favor of ssh pub key\n\nThis removes the hard-coded password from the appliance VM's user-data\nand replaces it with a SSH public key, which is read from a file whos\npath is configured in rug.ini.\n\nIt also disables password logins for the user.  Another patch to\nakanda-appliance-builder will allow developers to include a specified\ndebug user to allow debugging in dev environments.\n\nChange-Id: I7db92bc7fd3743d89d73ab2a0b8da14685c30c69\n""}, {'number': 2, 'created': '2015-05-23 00:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/999335b096f8ccf9916e6b147fbdb709036cb5ba', 'message': ""Remove appliance's hard-coded password in favor of ssh pub key\n\nThis removes the hard-coded password from the appliance VM's user-data\nand replaces it with a SSH public key, which is read from a file whos\npath is configured in rug.ini.\n\nIt also disables password logins for the user.  Another patch to\nakanda-appliance-builder will allow developers to include a specified\ndebug user to allow debugging in dev environments.\n\nChange-Id: I7db92bc7fd3743d89d73ab2a0b8da14685c30c69\n""}, {'number': 3, 'created': '2015-05-23 00:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/f3a760ee4ae73b7bc13be19cb8045ee85faba534', 'message': ""Remove appliance's hard-coded password in favor of ssh pub key\n\nThis removes the hard-coded password from the appliance VM's user-data\nand replaces it with a SSH public key, which is read from a file whos\npath is configured in rug.ini.\n\nIt also disables password logins for the user.  Another patch to\nakanda-appliance-builder will allow developers to include a specified\ndebug user to allow debugging in dev environments.\n\nChange-Id: I7db92bc7fd3743d89d73ab2a0b8da14685c30c69\n""}, {'number': 4, 'created': '2015-05-26 19:15:41.000000000', 'files': ['akanda/rug/test/unit/api/test_nova_wrapper.py', 'etc/rug.ini', 'akanda/rug/api/nova.py', 'test-requirements.txt', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/astara/commit/a06dbe7ab3d579c0c4cb84642ed1708d1442dc0b', 'message': ""Remove appliance's hard-coded password in favor of ssh pub key\n\nThis removes the hard-coded password from the appliance VM's user-data\nand replaces it with a SSH public key, which is read from a file whos\npath is configured in rug.ini.\n\nIt also disables password logins for the user.  Another patch to\nakanda-appliance-builder will allow developers to include a specified\ndebug user to allow debugging in dev environments.\n\nChange-Id: I7db92bc7fd3743d89d73ab2a0b8da14685c30c69\n""}]",0,185195,a06dbe7ab3d579c0c4cb84642ed1708d1442dc0b,14,9,4,1420,,,0,"Remove appliance's hard-coded password in favor of ssh pub key

This removes the hard-coded password from the appliance VM's user-data
and replaces it with a SSH public key, which is read from a file whos
path is configured in rug.ini.

It also disables password logins for the user.  Another patch to
akanda-appliance-builder will allow developers to include a specified
debug user to allow debugging in dev environments.

Change-Id: I7db92bc7fd3743d89d73ab2a0b8da14685c30c69
",git fetch https://review.opendev.org/openstack/astara refs/changes/95/185195/2 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/api/nova.py', 'akanda/rug/test/unit/api/test_nova_wrapper.py', 'etc/rug.ini', 'test-requirements.txt', 'devstack/plugin.sh']",5,d2fc59144ce6495e9824c0a391f2b209696a2b56,185195, if [ ! -e $STACK_USER/.ssh/id_rsa.pub ]; then mkdir -p $STACK_USER/.ssh echo -e 'n\n' | ssh-keygen -q -t rsa -P '' -f $STACK_USER/.ssh/id_rsa fi ln -s $STACK_USER/.ssh/id_rsa.pub /etc/akanda-rug/akanda.pub iniset $AKANDA_RUG_CONF DEFAULT router_ssh_public_key /etc/akanda-rug/akanda.pub DIB_AKANDA_APPLIANCE_DEBUG_USER=$ADMIN_USERNAME \ DIB_AKANDA_APPLIANCE_DEBUG_PASSWORD=$ADMIN_PASSWORD \ DIB_RELEASE=wheezy DIB_EXTLINUX=1 disk-image-create debian vm akanda debug-user \, DIB_RELEASE=wheezy DIB_EXTLINUX=1 disk-image-create debian vm akanda \,100,6
openstack%2Fzuul-packaging~debian%2Fsid~I73024af09fe4435b0a06d73ff97b918876477d4e,openstack/zuul-packaging,debian/sid,I73024af09fe4435b0a06d73ff97b918876477d4e,Support voluptuous 7.0+,ABANDONED,2013-12-03 01:54:11.000000000,2015-05-27 15:50:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2475}, {'_account_id': 6987}]","[{'number': 1, 'created': '2013-12-03 01:54:11.000000000', 'files': ['debian/patches/0001-test-support-voluptuous-7.0.patch', 'debian/patches/series', 'debian/control'], 'web_link': 'https://opendev.org/openstack/zuul-packaging/commit/634239e85a38d54ce1189c8fb464bdeb2c4fe0e9', 'message': 'Support voluptuous 7.0+\n\nDebian sid now include support for python-voluptuous 7.0 as such we need\nto backport an upstream patch[1].\n\n[1] https://github.com/openstack-infra/zuul/commit/b36f8658d8979c545ad798bb1ea9489180ad6250\n\nChange-Id: I73024af09fe4435b0a06d73ff97b918876477d4e\nSigned-off-by: Paul Belanger <paul.belanger@polybeacon.com>\n'}]",0,59592,634239e85a38d54ce1189c8fb464bdeb2c4fe0e9,15,3,1,4162,,,0,"Support voluptuous 7.0+

Debian sid now include support for python-voluptuous 7.0 as such we need
to backport an upstream patch[1].

[1] https://github.com/openstack-infra/zuul/commit/b36f8658d8979c545ad798bb1ea9489180ad6250

Change-Id: I73024af09fe4435b0a06d73ff97b918876477d4e
Signed-off-by: Paul Belanger <paul.belanger@polybeacon.com>
",git fetch https://review.opendev.org/openstack/zuul-packaging refs/changes/92/59592/1 && git format-patch -1 --stdout FETCH_HEAD,"['debian/patches/0001-test-support-voluptuous-7.0.patch', 'debian/patches/series', 'debian/control']",3,634239e85a38d54ce1189c8fb464bdeb2c4fe0e9,temp/openstack," python-voluptuous (>= 0.7), python-voluptuous (>= 0.7),"," python-voluptuous (<< 0.7), python-voluptuous (<< 0.7),",63,2
openstack%2Fbarbican~master~Ib598cab8c36728f8ad91c940680e0cdfcfca5c2e,openstack/barbican,master,Ib598cab8c36728f8ad91c940680e0cdfcfca5c2e,Add more users/roles to secret/container RBAC tests,MERGED,2015-05-22 20:36:02.000000000,2015-05-27 15:49:26.000000000,2015-05-27 15:49:23.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 9234}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-22 20:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/794dff55008f69ad4caf1b24d7721819d41e09dd', 'message': 'Add more users/roles to secret/container RBAC tests\n\nCompleted the set of RBAC users by adding audit and\ncreator users for group b, then add those users to the\ntests for secret and container GET tests.  This completes\nthe matrix of tests for secret and container GET.\n\nChange-Id: Ib598cab8c36728f8ad91c940680e0cdfcfca5c2e\n'}, {'number': 2, 'created': '2015-05-22 21:08:01.000000000', 'files': ['functionaltests/common/client.py', 'etc/barbican/barbican-functional.conf', 'bin/keystone_data.sh', 'contrib/devstack/lib/barbican', 'functionaltests/common/config.py', 'functionaltests/api/v1/functional/test_rbac.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/5e82cbeaecf34524d20e62113e3276d091f8761a', 'message': 'Add more users/roles to secret/container RBAC tests\n\nCompleted the set of RBAC users by adding audit and\ncreator users for group b, then add those users to the\ntests for secret and container GET tests.  This completes\nthe matrix of tests for secret and container GET.\n\nUpdated the scripts to ensure the users get setup\ncorrectly in devstack and via keystone_data.sh.\n\nChange-Id: Ib598cab8c36728f8ad91c940680e0cdfcfca5c2e\n'}]",2,185135,5e82cbeaecf34524d20e62113e3276d091f8761a,11,5,2,9234,,,0,"Add more users/roles to secret/container RBAC tests

Completed the set of RBAC users by adding audit and
creator users for group b, then add those users to the
tests for secret and container GET tests.  This completes
the matrix of tests for secret and container GET.

Updated the scripts to ensure the users get setup
correctly in devstack and via keystone_data.sh.

Change-Id: Ib598cab8c36728f8ad91c940680e0cdfcfca5c2e
",git fetch https://review.opendev.org/openstack/barbican refs/changes/35/185135/1 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/common/client.py', 'bin/keystone_data.sh', 'etc/barbican/barbican-functional.conf', 'functionaltests/common/config.py', 'functionaltests/api/v1/functional/test_rbac.py']",5,794dff55008f69ad4caf1b24d7721819d41e09dd,rbac-get,"creator_b = CONF.rbac_users.creator_bauditor_b = CONF.rbac_users.auditor_b 'with_creator_b': {'user': creator_b, 'expected_return': 403}, 'with_auditor_b': {'user': auditor_b, 'expected_return': 403}, 'with_creator_b': {'user': creator_b, 'expected_return': 403}, 'with_auditor_b': {'user': auditor_b, 'expected_return': 403},",,58,1
openstack%2Fopenstack-ansible~juno~Ia340057060c41bb609532872991c7cd4b43c5bfa,openstack/openstack-ansible,juno,Ia340057060c41bb609532872991c7cd4b43c5bfa,Updates maas fs thresholds,ABANDONED,2015-05-24 15:55:41.000000000,2015-05-27 15:47:18.000000000,,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 14552}]","[{'number': 1, 'created': '2015-05-24 15:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/db01e92513c137e96a9d4e18868fd6070270e341', 'message': 'Closes-Bug: 1455999\nAdding default thresholds for maas_filesystem_warning and critical threshold\n\nChange-Id: Ia340057060c41bb609532872991c7cd4b43c5bfa\n'}, {'number': 2, 'created': '2015-05-25 15:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/00a61eaf415a13bb5f0e4c0ec876fad1e29b22aa', 'message': 'Closes-Bug: 1455999\nAdding default thresholds for maas_filesystem_warning and critical threshold\n\nChange-Id: Ia340057060c41bb609532872991c7cd4b43c5bfa\n'}, {'number': 3, 'created': '2015-05-25 15:54:18.000000000', 'files': ['rpc_deployment/roles/maas_cdm/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/794b8a8c50c9111aac507f790981f5ac1d452f64', 'message': 'Updates maas fs thresholds\n\nAdding default thresholds for maas_filesystem_warning and critical \nthreshold.\n\nCloses-Bug: 1455999\nChange-Id: Ia340057060c41bb609532872991c7cd4b43c5bfa\n'}]",0,185270,794b8a8c50c9111aac507f790981f5ac1d452f64,9,3,3,14552,,,0,"Updates maas fs thresholds

Adding default thresholds for maas_filesystem_warning and critical 
threshold.

Closes-Bug: 1455999
Change-Id: Ia340057060c41bb609532872991c7cd4b43c5bfa
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/70/185270/2 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/maas_cdm/tasks/main.yml'],1,db01e92513c137e96a9d4e18868fd6070270e341,bug/1455999," warning_threshold: ""{{ maas_filesystem_warning_threshold | default (80.0) }}"" critical_threshold: ""{{ maas_filesystem_critical_threshold | default (90.0) }}"" warning_threshold: ""{{ maas_filesystem_warning_threshold | default (80.0) }}"" critical_threshold: ""{{ maas_filesystem_critical_threshold | default (90.0) }}"""," warning_threshold: ""{{ maas_filesystem_warning_threshold }}"" critical_threshold: ""{{ maas_filesystem_critical_threshold }}"" warning_threshold: ""{{ maas_filesystem_warning_threshold }}"" critical_threshold: ""{{ maas_filesystem_critical_threshold }}""",4,4
openstack%2Fopenstacksdk~master~I4f48643097dc841312d6f048a9cceeb6e6d1ea76,openstack/openstacksdk,master,I4f48643097dc841312d6f048a9cceeb6e6d1ea76,Fix catalog error,MERGED,2015-05-27 14:10:54.000000000,2015-05-27 15:46:21.000000000,2015-05-27 15:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 14:10:54.000000000', 'files': ['openstack/auth/access.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/84bd54f66ef56035ab8e118f15af9c3d98f32cdb', 'message': ""Fix catalog error\n\nUse get() function to get 'catalog'\n\nChange-Id: I4f48643097dc841312d6f048a9cceeb6e6d1ea76\n""}]",3,186010,84bd54f66ef56035ab8e118f15af9c3d98f32cdb,10,4,1,7404,,,0,"Fix catalog error

Use get() function to get 'catalog'

Change-Id: I4f48643097dc841312d6f048a9cceeb6e6d1ea76
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/10/186010/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/auth/access.py'],1,84bd54f66ef56035ab8e118f15af9c3d98f32cdb,catalog, self.service_catalog = catalog.ServiceCatalog( self._info.get('catalog')), self.service_catalog = catalog.ServiceCatalog(self._info['catalog']),2,1
openstack%2Fdevstack~master~Ib317ad1e9dd2a5d2232b9c64541fe4a601a2b8da,openstack/devstack,master,Ib317ad1e9dd2a5d2232b9c64541fe4a601a2b8da,Fix msg argument to assert_equal,MERGED,2015-05-25 01:54:46.000000000,2015-05-27 15:43:23.000000000,2015-05-27 15:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 8119}]","[{'number': 1, 'created': '2015-05-25 01:54:46.000000000', 'files': ['tests/test_truefalse.sh', 'tests/unittest.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/165afa2377ee8eb6bad1b6cfb454a7de525a4498', 'message': 'Fix msg argument to assert_equal\n\nI noticed this was taking an argument but not dealing with it.  In\ngeneral the functions were undocumented, so I added some terse usage.\n\nAlso, the intent of the test-case was to expand the values before\nusing them as the message; make sure this happens by using a temp\nvariable.\n\nChange-Id: Ib317ad1e9dd2a5d2232b9c64541fe4a601a2b8da\n'}]",0,185292,165afa2377ee8eb6bad1b6cfb454a7de525a4498,10,6,1,7118,,,0,"Fix msg argument to assert_equal

I noticed this was taking an argument but not dealing with it.  In
general the functions were undocumented, so I added some terse usage.

Also, the intent of the test-case was to expand the values before
using them as the message; make sure this happens by using a temp
variable.

Change-Id: Ib317ad1e9dd2a5d2232b9c64541fe4a601a2b8da
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/185292/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_truefalse.sh', 'tests/unittest.sh']",2,165afa2377ee8eb6bad1b6cfb454a7de525a4498,bug/1457989,"# pass a test, printing out MSG # usage: passed message echo ""PASS: $function:L$lineno $msg"" } # fail a test, printing out MSG # usage: failed message# assert string comparision of val1 equal val2, printing out msg # usage: assert_equal val1 val2 msg if [ -z ""$msg"" ]; then msg=""OK"" fi echo ""PASS: $function:L$lineno - $msg""# print a summary of passing and failing tests, exiting # with an error if we have failed tests # usage: report_results"," echo $function:L$lineno $msg } echo ""$function:L$lineno - ok""",19,4
openstack%2Fkeystone~stable%2Ficehouse~I55663db4cf2df84a66de8f64fba4b4f129ae827d,openstack/keystone,stable/icehouse,I55663db4cf2df84a66de8f64fba4b4f129ae827d,backend_argument should be marked secret,MERGED,2015-04-20 18:03:08.000000000,2015-05-27 15:41:34.000000000,2015-05-27 15:41:32.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1941}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 8119}, {'_account_id': 9311}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-04-20 18:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a5fab6c7a5752c5702532087248b5d010b0758a0', 'message': 'backend_argument should be marked secret\n\nSince the backend_argument can potentially contain a password,\nit should be marked secret to avoid leakage into the logs.\n\nCloses-Bug: #1443598\n\nChange-Id: I55663db4cf2df84a66de8f64fba4b4f129ae827d\n(cherry picked from commit f9db1a65bd4d83d12c572ba4d5807845996ef410)\n'}, {'number': 2, 'created': '2015-05-26 19:34:01.000000000', 'files': ['keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a1548eb670d74cac7ff9bb8c4b4228059e6b9e4a', 'message': 'backend_argument should be marked secret\n\nSince the backend_argument can potentially contain a password,\nit should be marked secret to avoid leakage into the logs.\n\nCloses-Bug: #1443598\n\nChange-Id: I55663db4cf2df84a66de8f64fba4b4f129ae827d\n(cherry picked from commit f9db1a65bd4d83d12c572ba4d5807845996ef410)\n'}]",1,175519,a1548eb670d74cac7ff9bb8c4b4228059e6b9e4a,19,9,2,9311,,,0,"backend_argument should be marked secret

Since the backend_argument can potentially contain a password,
it should be marked secret to avoid leakage into the logs.

Closes-Bug: #1443598

Change-Id: I55663db4cf2df84a66de8f64fba4b4f129ae827d
(cherry picked from commit f9db1a65bd4d83d12c572ba4d5807845996ef410)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/175519/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/config.py'],1,a5fab6c7a5752c5702532087248b5d010b0758a0,," cfg.MultiStrOpt('backend_argument', default=[], secret=True,"," cfg.MultiStrOpt('backend_argument', default=[],",1,1
openstack%2Ffuel-qa~master~I01ab9d34f369f3ebe9295f47c455f85aa406a0d1,openstack/fuel-qa,master,I01ab9d34f369f3ebe9295f47c455f85aa406a0d1,Increase count of VMs and timeout in vcenter_multiple_cluster.,MERGED,2015-05-27 12:35:12.000000000,2015-05-27 15:35:40.000000000,2015-05-27 15:35:38.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 11427}, {'_account_id': 12141}, {'_account_id': 12199}, {'_account_id': 13306}, {'_account_id': 14946}, {'_account_id': 15005}, {'_account_id': 15921}]","[{'number': 1, 'created': '2015-05-27 12:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/4455a5969a07e79946f0bf881a4865d06fa05c72', 'message': 'Increase count of VMs and timeout in vcenter_multiple_cluster.\n\n-increase count of VMs\n-increase timeout\n\nChange-Id: I01ab9d34f369f3ebe9295f47c455f85aa406a0d1\nCloses-Bug: #1459220\n'}, {'number': 2, 'created': '2015-05-27 12:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/59d4f78f75e155a27afbc94a2833dbf90fbba2c2', 'message': 'Increase count of VMs and timeout in vcenter_multiple_cluster.\n\n-increase count of VMs\n-increase timeout\n\nChange-Id: I01ab9d34f369f3ebe9295f47c455f85aa406a0d1\nCloses-Bug: #1459220\n'}, {'number': 3, 'created': '2015-05-27 12:48:47.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6f26b7faa2d2c991003727e04ff0dfc2b7f03ca0', 'message': 'Increase count of VMs and timeout in vcenter_multiple_cluster.\n\n-increase count of VMs from 4 to 6 and add exception\n-increase timeout to ssh to VM from 10 to 100 \n\nChange-Id: I01ab9d34f369f3ebe9295f47c455f85aa406a0d1\nCloses-Bug: #1459220\n'}]",0,185956,6f26b7faa2d2c991003727e04ff0dfc2b7f03ca0,20,10,3,15660,,,0,"Increase count of VMs and timeout in vcenter_multiple_cluster.

-increase count of VMs from 4 to 6 and add exception
-increase timeout to ssh to VM from 10 to 100 

Change-Id: I01ab9d34f369f3ebe9295f47c455f85aa406a0d1
Closes-Bug: #1459220
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/56/185956/3 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,4455a5969a07e79946f0bf881a4865d06fa05c72,fix_multiple_cluster,"from proboscis import test from proboscis.asserts import assert_truefrom devops.error import TimeoutError from fuelweb_test.helpers.decorators import log_snapshot_after_test def create_vm(self, os_conn=None, vm_count=None): # Get list of available images,flavors and hipervisors images_list = os_conn.nova.images.list() flavors_list = os_conn.nova.flavors.list() hypervisors_list = os_conn.get_hypervisors() # Create VMs on each of hypervisor for image in images_list: for i in range(0, vm_count): os_conn.nova.servers.create( flavor=flavors_list[0], name='test_{0}_{1}'.format(image.name, i), image=image) # Wait for launch VMs for hypervisor in hypervisors_list: wait( lambda: os_conn.get_hypervisor_vms_count(hypervisor) != 0, timeout=300) try: self.create_vm(os_conn=os_conn, vm_count=6) except TimeoutError: logger.info(""Tests failed from first probe,"" "" to create Vm on each hypervisors"" "" try one more time"" "" and if it fails again - test will fails "") self.create_vm(os_conn=os_conn, vm_count=4) interval=10, timeout=100 4. Add 1 node with cinder role 5. Add 1 node with cinder-vmvare role 6. Set Nova-Network VlanManager as a network backend. 7. Deploy the cluster 9. Remove 1 node with controller role and redeploy cluster. 10. Run OSTF.","from proboscis import testfrom fuelweb_test.helpers.decorators import log_snapshot_after_testfrom proboscis.asserts import assert_true # Get list of available images,flavors and hipervisors images_list = os_conn.nova.images.list() flavors_list = os_conn.nova.flavors.list() hypervisors_list = os_conn.get_hypervisors() # Create VMs on each of hypervisor for image in images_list: for i in range(0, len(images_list)): os_conn.nova.servers.create( flavor=flavors_list[0], name='test_{0}_{1}'.format(image.name, i), image=image) # Wait for launch VMs for hypervisor in hypervisors_list: t1 = time.time() while time.time() < t1 + 300: if os_conn.get_hypervisor_vms_count(hypervisor) != 0: break interval=10, timeout=10 4. Set Nova-Network VlanManager as a network backend. 5. Deploy the cluster 6. Run OSTF. 7. Remove 1 node with controller role and redeploy cluster.",38,27
openstack%2Fswift~master~I9b8367dcee7b9d6aebaa294c7fae61b5fadd402a,openstack/swift,master,I9b8367dcee7b9d6aebaa294c7fae61b5fadd402a,Replace StringIO.StringIO with six.BytesIO,ABANDONED,2015-05-27 15:32:45.000000000,2015-05-27 15:33:51.000000000,,[],"[{'number': 1, 'created': '2015-05-27 15:32:45.000000000', 'files': ['test/unit/cli/test_recon.py', 'test/unit/common/test_storage_policy.py', 'test/unit/cli/test_info.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_xprofile.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py', 'test/unit/cli/test_form_signature.py', 'bin/swift-dispersion-populate', 'swift/common/middleware/slo.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py', 'test/unit/obj/test_ssync_receiver.py', 'test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/proxy/test_server.py', 'swift/obj/mem_diskfile.py', 'test/unit/obj/test_server.py', 'test/unit/cli/test_ringbuilder.py', 'test/functional/swift_test_client.py', 'test/unit/common/test_internal_client.py', 'swift/common/swob.py', 'test/unit/common/test_daemon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b83db4a2d0491fe993ba364c77f00e9782fa5b9b', 'message': ""Replace StringIO.StringIO with six.BytesIO\n\n* Replace 'import StringIO' + StringIO.StringIO with six.BytesIO or\n  six.StringIO\n* Replace 'from StringIO import StringIO'\n  with 'from six import StringIO'\n\nUse BytesIO (bytes) for:\n\n* compute MD5 checksum\n* file\n* WSGI input, output and errors\n* sender response for ssync sender and ssync receiver tests\n* HTTP content in direct client tests\n\nUse StringIO (unicode) for:\n\n* mocking stdout and stderr\n* inject config into a configuration parser\n\nWhen BytesIO is used, mark strings with the b'...' prefix to convert\nthem to bytes strings on Python 3.\n\ntest/unit/common/middleware/test_formpost.py: encode WSGI input to UTF-8\non Python 3.\n\nInitial patch generated by the cstring and stringio operations of the\nsixer tool:\nhttps://pypi.python.org/pypi/sixer\n\nChange-Id: I9b8367dcee7b9d6aebaa294c7fae61b5fadd402a\n""}]",0,186042,b83db4a2d0491fe993ba364c77f00e9782fa5b9b,2,0,1,9107,,,0,"Replace StringIO.StringIO with six.BytesIO

* Replace 'import StringIO' + StringIO.StringIO with six.BytesIO or
  six.StringIO
* Replace 'from StringIO import StringIO'
  with 'from six import StringIO'

Use BytesIO (bytes) for:

* compute MD5 checksum
* file
* WSGI input, output and errors
* sender response for ssync sender and ssync receiver tests
* HTTP content in direct client tests

Use StringIO (unicode) for:

* mocking stdout and stderr
* inject config into a configuration parser

When BytesIO is used, mark strings with the b'...' prefix to convert
them to bytes strings on Python 3.

test/unit/common/middleware/test_formpost.py: encode WSGI input to UTF-8
on Python 3.

Initial patch generated by the cstring and stringio operations of the
sixer tool:
https://pypi.python.org/pypi/sixer

Change-Id: I9b8367dcee7b9d6aebaa294c7fae61b5fadd402a
",git fetch https://review.opendev.org/openstack/swift refs/changes/42/186042/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/cli/test_recon.py', 'test/unit/common/test_storage_policy.py', 'test/unit/cli/test_info.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_xprofile.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py', 'test/unit/cli/test_form_signature.py', 'bin/swift-dispersion-populate', 'swift/common/middleware/slo.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py', 'test/unit/obj/test_ssync_receiver.py', 'test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/proxy/test_server.py', 'swift/obj/mem_diskfile.py', 'test/unit/obj/test_server.py', 'test/unit/cli/test_ringbuilder.py', 'test/functional/swift_test_client.py', 'test/unit/common/test_internal_client.py', 'swift/common/swob.py', 'test/unit/common/test_daemon.py']",28,b83db4a2d0491fe993ba364c77f00e9782fa5b9b,py3,from six import StringIO,from StringIO import StringIO,300,258
openstack%2Fceilometer~master~Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd,openstack/ceilometer,master,Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd,Enable test_swift_middleware on Python 3,MERGED,2015-05-25 13:55:06.000000000,2015-05-27 15:31:04.000000000,2015-05-27 15:31:02.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 9107}, {'_account_id': 10987}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-25 13:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3da32008edbb9e2c7c7808ec9245c3eb868ca309', 'message': 'Enable test_swift_middleware on Python 3\n\nEnable also event_pipeline test.\n\nChange-Id: Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd\n'}, {'number': 2, 'created': '2015-05-25 14:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/73859f38b011026b0448ef95d7dac1a7250fb06b', 'message': 'Enable test_swift_middleware on Python 3\n\nEnable also event_pipeline test.\n\nChange-Id: Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd\n'}, {'number': 3, 'created': '2015-05-26 13:20:01.000000000', 'files': ['tox.ini', 'ceilometer/tests/objectstore/test_swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ab2a1bc7adfbf26a718be815872d5c00fe92e1f8', 'message': 'Enable test_swift_middleware on Python 3\n\nEnable also event_pipeline test.\n\nChange-Id: Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd\n'}]",0,185386,ab2a1bc7adfbf26a718be815872d5c00fe92e1f8,18,6,3,9107,,,0,"Enable test_swift_middleware on Python 3

Enable also event_pipeline test.

Change-Id: Iffdbc770bb167f49243d7799bb50dc7c4c65a0dd
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/185386/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'ceilometer/tests/objectstore/test_swift_middleware.py']",2,3da32008edbb9e2c7c7808ec9245c3eb868ca309,py3," self.assertEqual(b'value1', self.assertEqual(b'value2', self.assertEqual(b'token', self.assertFalse(b'http_header_x_var3' in data.resource_metadata)"," self.assertEqual('value1', self.assertEqual('value2', self.assertEqual('token', self.assertFalse('http_header_x_var3' in data.resource_metadata)",5,4
openstack%2Fceilometer~master~Ibf1354018a8140901ba44e74f5cc5d88b2578339,openstack/ceilometer,master,Ibf1354018a8140901ba44e74f5cc5d88b2578339,Clear useless exclude from flake8 ignore in tox,MERGED,2015-05-26 13:19:14.000000000,2015-05-27 15:30:55.000000000,2015-05-27 15:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-26 13:19:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/10c0be3e80397c8584011f93aead33ea4c5e86c4', 'message': 'Clear useless exclude from flake8 ignore in tox\n\nChange-Id: Ibf1354018a8140901ba44e74f5cc5d88b2578339\n'}]",0,185587,10c0be3e80397c8584011f93aead33ea4c5e86c4,9,5,1,1669,,,0,"Clear useless exclude from flake8 ignore in tox

Change-Id: Ibf1354018a8140901ba44e74f5cc5d88b2578339
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/87/185587/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,10c0be3e80397c8584011f93aead33ea4c5e86c4,jd/clean-tox,"exclude=.venv,.git,.tox,dist,doc,./ceilometer/openstack/common,*lib/python*,*egg,build","exclude=.venv,.git,.tox,dist,doc,./ceilometer/openstack/common,*lib/python*,*egg,nova_tests,build,tools/lintstack.head.py",1,1
openstack%2Fastara~stable%2Fkilo~I824fde35835e0b1a9141079a975f726e26698b30,openstack/astara,stable/kilo,I824fde35835e0b1a9141079a975f726e26698b30,prep for next stable,MERGED,2015-05-16 07:55:04.000000000,2015-05-27 15:24:18.000000000,2015-05-27 15:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-05-16 07:55:04.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara/commit/aad3802b53323b5f2d17a034a1995881d920159a', 'message': 'prep for next stable\n\nupdate package configuration\n\nChange-Id: I824fde35835e0b1a9141079a975f726e26698b30\n'}]",0,183774,aad3802b53323b5f2d17a034a1995881d920159a,7,3,1,6923,,,0,"prep for next stable

update package configuration

Change-Id: I824fde35835e0b1a9141079a975f726e26698b30
",git fetch https://review.opendev.org/openstack/astara refs/changes/74/183774/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,aad3802b53323b5f2d17a034a1995881d920159a,prepare-for-next-stable,version = 2015.1.1,version = 2015.1,1,1
openstack%2Fmagnum~master~I49652dd9fca471d3f48f8c6145a2642dea4f3d77,openstack/magnum,master,I49652dd9fca471d3f48f8c6145a2642dea4f3d77,"Backport ""minor updates to README""",MERGED,2015-05-24 18:19:34.000000000,2015-05-27 15:21:31.000000000,2015-05-27 15:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-05-24 18:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9626096c079099fe639a30225a6e407e14e3f561', 'message': 'Backport ""minor updates to README""\n\nheat-coe-templates: I0cd9f1f435b8befb6d91d1676b7b0cf8f62a4f2e\n\nChange-Id: I49652dd9fca471d3f48f8c6145a2642dea4f3d77\n'}, {'number': 2, 'created': '2015-05-26 10:25:28.000000000', 'files': ['magnum/templates/heat-kubernetes/README.md'], 'web_link': 'https://opendev.org/openstack/magnum/commit/2b1204720d5aa8aa5efd5c4925c6483860359f5a', 'message': 'Backport ""minor updates to README""\n\nheat-coe-templates: I0cd9f1f435b8befb6d91d1676b7b0cf8f62a4f2e\n\nChange-Id: I49652dd9fca471d3f48f8c6145a2642dea4f3d77\n'}]",0,185275,2b1204720d5aa8aa5efd5c4925c6483860359f5a,10,4,2,11650,,,0,"Backport ""minor updates to README""

heat-coe-templates: I0cd9f1f435b8befb6d91d1676b7b0cf8f62a4f2e

Change-Id: I49652dd9fca471d3f48f8c6145a2642dea4f3d77
",git fetch https://review.opendev.org/openstack/magnum refs/changes/75/185275/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/templates/heat-kubernetes/README.md'],1,9626096c079099fe639a30225a6e407e14e3f561,backports,Atomic.## Contributing Please submit bugs and pull requests via the [GitHub repository][] at https://github.com/larsks/heat-kubernetes/. When submitting pull requests: - Please ensure that each pull request contains a single commit and contains only related changes. Put unrelated changes in multiple pull requests. - Please avoid conflating new features with stylistic/formatting/cleanup changes. [github repository]: https://github.com/larsks/heat-kubernetes/,Atomic. You will need an image dated later than 2015-01-20 in order to have both the `flannel` package installed and the appropriately configured `docker.service` unit.## Contact Please report bugs using the [GitHub issue tracker][] at https://github.com/larsks/heat-kubernetes/issues. [github issue tracker]: https://github.com/larsks/heat-kubernetes/issues,14,7
openstack%2Fdjango_openstack_auth~master~Ia1c9f116ce731b80fb66a191d937a5ef509c81e9,openstack/django_openstack_auth,master,Ia1c9f116ce731b80fb66a191d937a5ef509c81e9,Support removal of last_activity session flag,MERGED,2015-05-04 14:48:57.000000000,2015-05-27 15:17:42.000000000,2015-05-27 15:17:41.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6650}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-05-04 14:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/d65d80ed3d79f108382f05495b3fa817fc1e50ea', 'message': 'Support removal of last_activity session flag\n\nThis is a simple change that will support removal of the last activiy\nsession field within the horizon middleware.  Whith this change, a bunch\nof horizon code can be removed.\n\nChange-Id: Ia1c9f116ce731b80fb66a191d937a5ef509c81e9\nPartialy-Closes: #1450914\n'}, {'number': 2, 'created': '2015-05-14 15:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/144edcc5786a4337ab1eca8b5ff80c70a31e8c17', 'message': 'Support removal of last_activity session flag\n\nThis is a simple change that will support removal of the last activiy\nsession field within the horizon middleware.  Whith this change, a bunch\nof horizon code can be removed.\n\nChange-Id: Ia1c9f116ce731b80fb66a191d937a5ef509c81e9\nPartialy-Closes: #1450914\n'}, {'number': 3, 'created': '2015-05-26 21:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/953dc2e0566fbc57b3c18f83b695befd2db6b2ee', 'message': 'Support removal of last_activity session flag\n\nThis is a simple change that will support removal of the last activiy\nsession field within the horizon middleware.  Whith this change, a bunch\nof horizon code can be removed.\n\nChange-Id: Ia1c9f116ce731b80fb66a191d937a5ef509c81e9\nPartialy-Closes: #1450914\n'}, {'number': 4, 'created': '2015-05-26 21:27:18.000000000', 'files': ['openstack_auth/views.py', 'openstack_auth/backend.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/2e804b0fa3bb3b81b1fe4c6becf91998c6fd0a39', 'message': 'Support removal of last_activity session flag\n\nThis is a simple change that will support removal of the last activiy\nsession field within the horizon middleware.  Whith this change, a bunch\nof horizon code can be removed.\n\nChange-Id: Ia1c9f116ce731b80fb66a191d937a5ef509c81e9\nPartialy-Closes: #1450914\n'}]",6,179800,2e804b0fa3bb3b81b1fe4c6becf91998c6fd0a39,26,6,4,6650,,,0,"Support removal of last_activity session flag

This is a simple change that will support removal of the last activiy
session field within the horizon middleware.  Whith this change, a bunch
of horizon code can be removed.

Change-Id: Ia1c9f116ce731b80fb66a191d937a5ef509c81e9
Partialy-Closes: #1450914
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/00/179800/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/user.py'],1,d65d80ed3d79f108382f05495b3fa817fc1e50ea,bug-1450914, request.session.set_expiry(user.token.expires),,1,0
openstack%2Fastara~master~I3343106d4da59dede7ca32e66c8ec7ed1abb4ebb,openstack/astara,master,I3343106d4da59dede7ca32e66c8ec7ed1abb4ebb,Migrate to oslo.context,MERGED,2015-05-14 19:13:15.000000000,2015-05-27 15:16:36.000000000,2015-05-27 15:16:34.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-05-14 19:13:15.000000000', 'files': ['requirements.txt', 'akanda/rug/notifications.py', 'akanda/rug/api/neutron.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/8a34d72c60be7d41461e91f14b0946a4cc72dd1c', 'message': ""Migrate to oslo.context\n\nThis removes akanda.rug's usage of openstack.common.context\nand instead uses the equivalent oslo_context.context.\n\nNote the old module is still left in place as its used by other old\noslo-incubator things.\n\nChange-Id: I3343106d4da59dede7ca32e66c8ec7ed1abb4ebb\n""}]",0,183180,8a34d72c60be7d41461e91f14b0946a4cc72dd1c,10,4,1,1420,,,0,"Migrate to oslo.context

This removes akanda.rug's usage of openstack.common.context
and instead uses the equivalent oslo_context.context.

Note the old module is still left in place as its used by other old
oslo-incubator things.

Change-Id: I3343106d4da59dede7ca32e66c8ec7ed1abb4ebb
",git fetch https://review.opendev.org/openstack/astara refs/changes/80/183180/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'akanda/rug/notifications.py', 'akanda/rug/api/neutron.py']",3,8a34d72c60be7d41461e91f14b0946a4cc72dd1c,akanda/oslo_migration,from oslo_context import context,from akanda.rug.openstack.common import context,3,2
openstack%2Fos-client-config~master~Idf3d089703985ecc60f23a3c780ddcab914aa678,openstack/os-client-config,master,Idf3d089703985ecc60f23a3c780ddcab914aa678,Rename cloud to profile,MERGED,2015-05-27 12:58:05.000000000,2015-05-27 15:16:15.000000000,2015-05-27 15:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 5263}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-27 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/a052d1a415b192f09ae43600dcff1cb6d710214a', 'message': 'Rename cloud to profile\n\nThe cloud parameter was confusing people, especially since it was\ninside of a dict that was named ""clouds"". profile was suggested as less\nconfusing, which seems fine.\n\nContinue processing cloud as a parameter so that we don\'t break\nanyway, but change the docs to only mention profile.\n\nChange-Id: Idf3d089703985ecc60f23a3c780ddcab914aa678\n'}, {'number': 2, 'created': '2015-05-27 13:42:56.000000000', 'files': ['os_client_config/config.py', 'os_client_config/tests/base.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/b51f9f841651710ed088867b9047a7311e39cdea', 'message': 'Rename cloud to profile\n\nThe cloud parameter was confusing people, especially since it was\ninside of a dict that was named ""clouds"". profile was suggested as less\nconfusing, which seems fine.\n\nContinue processing cloud as a parameter so that we don\'t break\nanyway, but change the docs to only mention profile.\n\nChange-Id: Idf3d089703985ecc60f23a3c780ddcab914aa678\n'}]",0,185965,b51f9f841651710ed088867b9047a7311e39cdea,11,5,2,2,,,0,"Rename cloud to profile

The cloud parameter was confusing people, especially since it was
inside of a dict that was named ""clouds"". profile was suggested as less
confusing, which seems fine.

Continue processing cloud as a parameter so that we don't break
anyway, but change the docs to only mention profile.

Change-Id: Idf3d089703985ecc60f23a3c780ddcab914aa678
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/65/185965/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_client_config/config.py', 'os_client_config/tests/base.py', 'README.rst']",3,a052d1a415b192f09ae43600dcff1cb6d710214a,," profile: hp profile: rackspaceand embarrasingly ugly, known cloud vendor profile information is included and may be referrenced by name. One of the benefits of that is that auth_url isn't the only thing the vendor defaults contain. For instance, since Rackspace lists `rax:database` as the service type for trove, os-client-config knows that so that you don't have to. profile: hp"," cloud: hp cloud: rackspaceand embarrasingly ugly, known cloud vendors are included and may be referrenced by name. One of the benefits of that is that auth_url isn't the only thing the vendor defaults contain. For instance, since Rackspace lists `rax:database` as the service type for trove, os-client-config knows that so that you don't have to. cloud: hp",17,16
openstack%2Fheat-translator~master~I6626e5baaa0ebc369d8e4ab74720e880d52926a7,openstack/heat-translator,master,I6626e5baaa0ebc369d8e4ab74720e880d52926a7,TOSCA: interfaces for relationship templates,MERGED,2015-05-15 05:37:05.000000000,2015-05-27 15:15:17.000000000,2015-05-27 15:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 10856}]","[{'number': 1, 'created': '2015-05-15 05:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0f29c14fd34d9280cce68ac4491eaa306a885869', 'message': 'TOSCA: interfaces for relationship templates\n\nTOSCA relationship interfaces are provided for various configurations to run on the\nhost or target machine for pre, post configuration operations. Make such interfaces\navailable via relationship templates.\n\nChange-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7\n'}, {'number': 2, 'created': '2015-05-15 05:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4648ff2fa31f5daad90a9ddd6b844273b3003788', 'message': 'TOSCA: interfaces for relationship templates\n\nTOSCA relationship interfaces are provided for various configurations to run on the\nhost or target machine for pre, post configuration operations. Make such interfaces\navailable via relationship templates.\n\nChange-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7\n'}, {'number': 3, 'created': '2015-05-15 05:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/03ed3e0bcb399645f1ac273281fc4f5c0df1b6ee', 'message': 'TOSCA: interfaces for relationship templates\n\nTOSCA relationship interfaces are provided for various configurations to run\non the host or target machine for pre, post configuration operations. Make\nsuch interfaces available via relationship templates.\n\nChange-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7\n'}, {'number': 4, 'created': '2015-05-15 22:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4ee8ea9f9b4b47506850dd8d28d1830e6d57213b', 'message': 'TOSCA: interfaces for relationship templates\n\nTOSCA relationship interfaces are provided for various configurations to run\non the host or target machine for pre, post configuration operations. Make\nsuch interfaces available via relationship templates.\n\nChange-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7\n'}, {'number': 5, 'created': '2015-05-26 19:56:13.000000000', 'files': ['translator/toscalib/elements/interfaces.py', 'translator/toscalib/entity_template.py', 'translator/toscalib/topology_template.py', 'translator/toscalib/tests/test_toscatpl.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e2143adbf88576b86b18e0674d291911da62a92e', 'message': 'TOSCA: interfaces for relationship templates\n\nTOSCA relationship interfaces are provided for various configurations to run\non the host or target machine for pre, post configuration operations. Make\nsuch interfaces available via relationship templates.\n\nChange-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7\n'}]",0,183394,e2143adbf88576b86b18e0674d291911da62a92e,19,3,5,6456,,,0,"TOSCA: interfaces for relationship templates

TOSCA relationship interfaces are provided for various configurations to run
on the host or target machine for pre, post configuration operations. Make
such interfaces available via relationship templates.

Change-Id: I6626e5baaa0ebc369d8e4ab74720e880d52926a7
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/94/183394/4 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/elements/interfaces.py', 'translator/toscalib/entity_template.py', 'translator/toscalib/topology_template.py', 'translator/toscalib/tests/test_toscatpl.py']",4,0f29c14fd34d9280cce68ac4491eaa306a885869,i3," if node_tpl.name == 'logstash': config_interface = 'Configure' if rel_tpl: interfaces = rel_tpl[0].interfaces for interface in interfaces: self.assertEqual(config_interface, interface.type) self.assertEqual('pre_configure_source', interface.name) self.assertEqual('logstash/configure_elasticsearch.py', interface.implementation)"," if node_tpl.name == 'nodejs': config_interface = 'tosca.interfaces.relationship.Configure' interfaces = rel_tpl[0].interfaces for interface in interfaces: self.assertEqual(config_interface, interface.type) self.assertEqual('pre_configure_source', interface.name) self.assertEqual('nodejs/pre_configure_source.sh', interface.implementation)",39,14
openstack%2Fastara-neutron~master~I21cb6da6aeeb6fcf55a81cd07c4ca88a6285e682,openstack/astara-neutron,master,I21cb6da6aeeb6fcf55a81cd07c4ca88a6285e682,Update get_ports_from_devices for liberty,MERGED,2015-05-26 20:49:45.000000000,2015-05-27 15:14:56.000000000,2015-05-27 15:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-05-26 20:49:45.000000000', 'files': ['akanda/neutron/plugins/ml2_neutron_plugin.py'], 'web_link': 'https://opendev.org/openstack/astara-neutron/commit/432cf9ff5764f027b1b82b904b833eea58a66ce9', 'message': 'Update get_ports_from_devices for liberty\n\nThe API here changed in liberty as of https://review.openstack.org/#/c/173320/\nThis updates call signature accordingly and allows the ML2 plugin to function\nontop of liberty / trunk neutron.\n\nChange-Id: I21cb6da6aeeb6fcf55a81cd07c4ca88a6285e682\n'}]",0,185737,432cf9ff5764f027b1b82b904b833eea58a66ce9,7,3,1,1420,,,0,"Update get_ports_from_devices for liberty

The API here changed in liberty as of https://review.openstack.org/#/c/173320/
This updates call signature accordingly and allows the ML2 plugin to function
ontop of liberty / trunk neutron.

Change-Id: I21cb6da6aeeb6fcf55a81cd07c4ca88a6285e682
",git fetch https://review.opendev.org/openstack/astara-neutron refs/changes/37/185737/1 && git format-patch -1 --stdout FETCH_HEAD,['akanda/neutron/plugins/ml2_neutron_plugin.py'],1,432cf9ff5764f027b1b82b904b833eea58a66ce9,," def get_ports_from_devices(self, context, devices): ports = super(Ml2Plugin, self).get_ports_from_devices(context, devices) for port in ports"," def get_ports_from_devices(self, devices): for port in super(Ml2Plugin, self).get_ports_from_devices(devices)",3,3
openstack-attic%2Fakanda~master~I3ae46d30806f549b3f6d17e8fb0f6337fe53d4af,openstack-attic/akanda,master,I3ae46d30806f549b3f6d17e8fb0f6337fe53d4af,Document building an appliance image from source,MERGED,2015-05-13 21:31:45.000000000,2015-05-27 15:12:48.000000000,2015-05-27 15:12:47.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-05-13 21:31:45.000000000', 'files': ['doc/source/appliance.rst'], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/a92e721b6c65f27d931844666c3599b552807e71', 'message': 'Document building an appliance image from source\n\nThis adds docs for building the appliance image from source using\nDIB.\n\nChange-Id: I3ae46d30806f549b3f6d17e8fb0f6337fe53d4af\n'}]",0,182857,a92e721b6c65f27d931844666c3599b552807e71,7,3,1,1420,,,0,"Document building an appliance image from source

This adds docs for building the appliance image from source using
DIB.

Change-Id: I3ae46d30806f549b3f6d17e8fb0f6337fe53d4af
",git fetch https://review.opendev.org/openstack-attic/akanda refs/changes/57/182857/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/appliance.rst'],1,a92e721b6c65f27d931844666c3599b552807e71,image_build,".. _appliance_build: Building a Service VM image from source --------------------------------------- The router code that runs within the appliance is hosted in the ``akanda-appliance`` repository at ``https://github.com/stackforge/akanda-appliance``. Additional tooling for actually building a VM image to run the appliance is stored in the ``akanda-appliance-builder`` repository at ``https://github.com/stackforge/akanda-appliance-builder`` in the form of build elements to be used with ``diskimage-builder``. The following instructions will walk through building the Debian-based appliance locally, publishing to Glance and configuring the RUG to use said image. These instructions are for building the image on an Ubuntu 14.04+ system. Install Prerequisites +++++++++++++++++++++ First, install ``diskimage-builder`` and required packages: :: sudo apt-get -y install debootstrap qemu-utils sudo pip install ""diskimage-builder<0.1.43"" Next, clone the ``akanda-appliance-builder`` repository: :: git clone https://github.com/akanda-appliance-builder Build the image +++++++++++++++ Kick off an image build using diskimage-builder: :: cd akanda-appliance-builder ELEMENTS_PATH=diskimage-builder/elements DIB_RELEASE=wheezy DIB_EXTLINUX=1 \ disk-image-create debian vm akanda -o akanda Publish the image +++++++++++++++++ The previous step should produce a qcow2 image called ``akanda.qcow`` that can be published into Glance for use by the system: :: # We assume you have the required OpenStack credentials set as an environment # variables glance image-create --name akanda --disk-format qcow2 --container-format bare \ --file akanda.qcow2 +------------------+--------------------------------------+ | Property | Value | +------------------+--------------------------------------+ | checksum | cfc24b67e262719199c2c4dfccb6c808 | | container_format | bare | | created_at | 2015-05-13T21:27:02.000000 | | deleted | False | | deleted_at | None | | disk_format | qcow2 | | id | e2caf7fa-9b51-4f42-9fb9-8cfce96aad5a | | is_public | False | | min_disk | 0 | | min_ram | 0 | | name | akanda | | owner | df8eaa19c1d44365911902e738c2b10a | | protected | False | | size | 450573824 | | status | active | | updated_at | 2015-05-13T21:27:03.000000 | | virtual_size | None | +------------------+--------------------------------------+ Configure the RUG +++++++++++++++++ Take the above image id and set the corresponding value in the RUG's config file, to instruct the service to use that image for software router instances it manages: :: vi /etc/akanda/rug.ini ... router_image_uuid=e2caf7fa-9b51-4f42-9fb9-8cfce96aad5a Making local changes to the appliance service +++++++++++++++++++++++++++++++++++++++++++++ By default, building an image in this way pulls the ``akanda-appliance`` code directly from the upstream tip of trunk. If you'd like to make modifications to this code locally and build an image containing those changes, set DIB_REPOLOCATION_akanda and DIB_REPOREF_akanda in your enviornment accordingly during the image build, ie: :: export DIB_REPOLOCATION_akanda=~/src/akanda-appliance # Location of the local repository checkout export DIB_REPOREF_akanda=my-new-feature # The branch name or SHA-1 hash of the git ref to build from. ",,99,0
openstack%2Fec2-api~master~I548c0be14c83be85eb06b84ae6f224b2b3477bf7,openstack/ec2-api,master,I548c0be14c83be85eb06b84ae6f224b2b3477bf7,Remove underscore to camelCase conversion for XML output,MERGED,2015-05-27 12:45:43.000000000,2015-05-27 15:12:19.000000000,2015-05-27 15:12:18.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-27 12:45:43.000000000', 'files': ['ec2api/api/instance.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/apirequest.py', 'ec2api/api/vpn_connection.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/711f7ec17447cafaf7b4f22e81a024b898d3b913', 'message': 'Remove underscore to camelCase conversion for XML output\n\nSince we use camelCase in operation result formatting, this conversion\nis unecessary.\n\nChange-Id: I548c0be14c83be85eb06b84ae6f224b2b3477bf7\n'}]",0,185959,711f7ec17447cafaf7b4f22e81a024b898d3b913,6,3,1,10224,,,0,"Remove underscore to camelCase conversion for XML output

Since we use camelCase in operation result formatting, this conversion
is unecessary.

Change-Id: I548c0be14c83be85eb06b84ae6f224b2b3477bf7
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/59/185959/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/instance.py', 'ec2api/api/apirequest.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/vpn_connection.py']",4,711f7ec17447cafaf7b4f22e81a024b898d3b913,vpn," 'destinationCidrBlock'], 'routes': [{'destinationCidrBlock': cidr,"," 'destination_cidr_block'], 'routes': [{'destination_cidr_block': cidr,",4,10
openstack%2Ffuel-library~master~Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e,openstack/fuel-library,master,Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e,Ensure irqbalance is installed and running,MERGED,2015-05-27 11:27:48.000000000,2015-05-27 15:09:30.000000000,2015-05-27 15:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13948}, {'_account_id': 14168}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-27 11:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/30f408cbe9f3ae2a3372bce0cda696cbc7a42ffb', 'message': 'Ensure irqbalance is installed and running\n\nChange-Id: Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e\nCloses-Bug: 1401925\n'}, {'number': 2, 'created': '2015-05-27 12:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/04625b26003f0898984f1dd1328c4cb3a10c1a58', 'message': 'Ensure irqbalance is installed and running\n\nChange-Id: Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e\nCloses-Bug: 1401925\n'}, {'number': 3, 'created': '2015-05-27 13:12:13.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/netconfig/netconfig.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f9345282609de1d387bbf3178b400d08159d1f96', 'message': 'Ensure irqbalance is installed and running\n\nChange-Id: Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e\nCloses-Bug: 1401925\n'}]",5,185938,f9345282609de1d387bbf3178b400d08159d1f96,68,9,3,13948,,,0,"Ensure irqbalance is installed and running

Change-Id: Ifd2dfa17fe95d3ca77614e0f1e0e3c51372eb90e
Closes-Bug: 1401925
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/38/185938/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/tools/tools.pp'],1,30f408cbe9f3ae2a3372bce0cda696cbc7a42ffb,bug/1401925," ensure => 'purged', } if !defined(Package['irqbalance']) { package { 'irqbalance': ensure => installed, } } if !defined(Service['irqbalance']) { service { 'irqbalance': ensure => running, }"," ensure => 'purged',",13,1
openstack%2Fos-client-config~master~I4fa5bb8ac03baf464cfa00b451627f63ff847fdf,openstack/os-client-config,master,I4fa5bb8ac03baf464cfa00b451627f63ff847fdf,Don't pass None as the cloud name,MERGED,2015-05-26 18:51:18.000000000,2015-05-27 15:03:39.000000000,2015-05-27 15:03:38.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 3099}, {'_account_id': 5263}, {'_account_id': 6488}, {'_account_id': 8736}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-26 18:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/b61d115ef63acca44d1957e9a996a8092d865249', 'message': ""Don't pass None as the cloud name\n\ncloud names want to be strings. If there is no cloud name, stringify\nNone.\n\nChange-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf\n""}, {'number': 2, 'created': '2015-05-26 18:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/17507c33fad8f2d6d3e7af30cbdd7607936471e7', 'message': ""Don't pass None as the cloud name\n\ncloud names want to be strings. If there is no cloud name, stringify\nNone.\n\nChange-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf\n""}, {'number': 3, 'created': '2015-05-26 18:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/2c6c1a91a8387c8b99ffbf8b093a6c1536dfca91', 'message': ""Don't pass None as the cloud name\n\ncloud names want to be strings. If there is no cloud name, stringify\nNone.\n\nChange-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf\n""}, {'number': 4, 'created': '2015-05-27 13:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/b13957a64f88ccf3ad742df460a793ab34f250cf', 'message': ""Don't pass None as the cloud name\n\ncloud names want to be strings. If there is no cloud name, stringify\nNone.\n\nChange-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf\n""}, {'number': 5, 'created': '2015-05-27 13:42:56.000000000', 'files': ['os_client_config/config.py', 'os_client_config/tests/test_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/434d51aac292609162f738eea4611e2a52df8a0f', 'message': ""Don't pass None as the cloud name\n\ncloud names want to be strings. If there is no cloud name, stringify\nNone.\n\nChange-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf\n""}]",0,185701,434d51aac292609162f738eea4611e2a52df8a0f,25,7,5,2,,,0,"Don't pass None as the cloud name

cloud names want to be strings. If there is no cloud name, stringify
None.

Change-Id: I4fa5bb8ac03baf464cfa00b451627f63ff847fdf
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/01/185701/3 && git format-patch -1 --stdout FETCH_HEAD,['os_client_config/config.py'],1,b61d115ef63acca44d1957e9a996a8092d865249,," cloud_name=str(cloud) name=cloud_name, region=config['region_name'], config=config)"," name=cloud, region=config['region_name'], config=config)",2,1
openstack%2Ffuel-library~master~Ib8d1f605b5aa254547ef5b88bc6fec591926b051,openstack/fuel-library,master,Ib8d1f605b5aa254547ef5b88bc6fec591926b051,Fix fuel-logrotate file installation,MERGED,2015-05-27 12:53:30.000000000,2015-05-27 14:46:58.000000000,2015-05-27 14:46:23.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-27 12:53:30.000000000', 'files': ['debian/rules', 'debian/fuel-misc.install'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/afa71661f3194a674123bbc1034d0b014d8ca4f2', 'message': 'Fix fuel-logrotate file installation\n\nChange-Id: Ib8d1f605b5aa254547ef5b88bc6fec591926b051\nCloses-bug: #1459222\n'}]",0,185963,afa71661f3194a674123bbc1034d0b014d8ca4f2,27,7,1,8786,,,0,"Fix fuel-logrotate file installation

Change-Id: Ib8d1f605b5aa254547ef5b88bc6fec591926b051
Closes-bug: #1459222
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/63/185963/1 && git format-patch -1 --stdout FETCH_HEAD,"['debian/rules', 'debian/fuel-misc.install']",2,afa71661f3194a674123bbc1034d0b014d8ca4f2,bug/1459222,files/fuel-misc/logrotate-ubuntu /usr/bin,files/fuel-misc/logrotate-ubuntu /usr/bin/fuel-logrotate ,2,2
openstack%2Fmurano~master~I476e4fcbe4812d766d81c5ff4787a42bdd6637a3,openstack/murano,master,I476e4fcbe4812d766d81c5ff4787a42bdd6637a3,Update docs about Require section,MERGED,2015-05-27 12:06:58.000000000,2015-05-27 14:44:13.000000000,2015-05-27 14:44:11.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2015-05-27 12:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/3f5110c95d8886a1f7c8ca27520111c9c6d23cfe', 'message': 'Update docs a bout Require section\n\nInclude example with no version information.\nInclude information, that version is optional in Require dict.\n\nChange-Id: I476e4fcbe4812d766d81c5ff4787a42bdd6637a3\n'}, {'number': 2, 'created': '2015-05-27 13:18:05.000000000', 'files': ['doc/source/articles/app_pkg.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/63ab297bd2cf26fc811bb4d81c4a48f9232d0571', 'message': 'Update docs about Require section\n\nInclude example with no version information.\nInclude information, that version is optional in Require dict.\n\nChange-Id: I476e4fcbe4812d766d81c5ff4787a42bdd6637a3\n'}]",0,185945,63ab297bd2cf26fc811bb4d81c4a48f9232d0571,14,5,2,15168,,,0,"Update docs about Require section

Include example with no version information.
Include information, that version is optional in Require dict.

Change-Id: I476e4fcbe4812d766d81c5ff4787a42bdd6637a3
",git fetch https://review.opendev.org/openstack/murano refs/changes/45/185945/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/articles/app_pkg.rst'],1,3f5110c95d8886a1f7c8ca27520111c9c6d23cfe,185945,"* **Require** - a dict of application names with versions, required by this application. Currently only used by repository importing mechanism. Versions can be omitted, in that case package with no version would be imported. *Optional* parameter io.murano.apps.TelnetDoc:","* **Require** - list of applications with versions, required by this application. Currently only used by repository importing mechanism. *Optional* parameter",2,1
openstack%2Ffuel-main~master~Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9,openstack/fuel-main,master,Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9,Fix directory creation on running make with docker target,MERGED,2015-05-21 10:59:01.000000000,2015-05-27 14:42:49.000000000,2015-05-27 14:42:48.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 12817}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-05-21 10:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8f2b60ec334aedffaab23d2206bc82069c5c0f1c', 'message': 'Fix directory creation on running make with docker target\n\nSince target $(ISOROOT)/openstack_version can be used\nfrom several places, we need to be sure that $(ISOROOT)\ndirectory exists\n\nSince we can use target $(ISOROOT)/openstack_version\n\nChange-Id: Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9\n'}, {'number': 2, 'created': '2015-05-21 11:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a77bc76095dab7fa5b169081f7368a57d33f9d59', 'message': 'Fix directory creation on running make with docker target\n\nOn running ""make docker"" we have other targets \nworkflow then on ""make iso"", so for building target\n$(ISOROOT)/openstack_version we must be sure that $(ISOROOT)\ndirectory exists.\n\nChange-Id: Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9\n'}, {'number': 3, 'created': '2015-05-21 11:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1f67a88862f82a3feb540ea26ff05e11ce7e9c31', 'message': 'Fix directory creation on running make with docker target\n\nOn running ""make docker"" we have other targets\nworkflow then on ""make iso"", so for building target\n$(ISOROOT)/openstack_version we must be sure that $(ISOROOT)\ndirectory exists.\n\nCloses-bug: #1457435\nChange-Id: Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9\n'}, {'number': 4, 'created': '2015-05-25 07:57:15.000000000', 'files': ['iso/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/456ed4f329b613417152ae71ea3b13114f884ba6', 'message': 'Fix directory creation on running make with docker target\n\nOn running ""make docker"" we have other targets\nworkflow then on ""make iso"", so for building target\n$(ISOROOT)/openstack_version we must be sure that $(ISOROOT)\ndirectory exists.\n\nCloses-bug: #1457435\nChange-Id: Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9\n'}]",2,184759,456ed4f329b613417152ae71ea3b13114f884ba6,23,7,4,12817,,,0,"Fix directory creation on running make with docker target

On running ""make docker"" we have other targets
workflow then on ""make iso"", so for building target
$(ISOROOT)/openstack_version we must be sure that $(ISOROOT)
directory exists.

Closes-bug: #1457435
Change-Id: Ifa0ca2f81074d1be040cebb99f3632bcc7270dd9
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/59/184759/2 && git format-patch -1 --stdout FETCH_HEAD,['iso/module.mk'],1,8f2b60ec334aedffaab23d2206bc82069c5c0f1c,184759, mkdir -p $(@D), mkdir -p $(@D),1,1
openstack%2Fdevstack~master~I3035317c83d22804855517434bd8578719ce0436,openstack/devstack,master,I3035317c83d22804855517434bd8578719ce0436,add the port_sec as default neutron/ml2 extension driver,MERGED,2015-03-06 09:24:57.000000000,2015-05-27 14:41:43.000000000,2015-05-27 14:41:41.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 970}, {'_account_id': 1269}, {'_account_id': 1689}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 10385}, {'_account_id': 11114}, {'_account_id': 15637}]","[{'number': 1, 'created': '2015-03-06 09:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/95304355b76701e22dffd3b44698b14222c94c60', 'message': 'add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nDepends-On: I2da53168e2529db7a8094ce90ef3a8a93fe55727\n'}, {'number': 2, 'created': '2015-03-09 04:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7b311d2283ce0f98881b13d18aee49c3cf583568', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nDepends-On: I2da53168e2529db7a8094ce90ef3a8a93fe55727\n""}, {'number': 3, 'created': '2015-03-09 05:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/32baca0d20781f1a30eb27578fecc8fe26bc0d68', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nDepends-On: I2da53168e2529db7a8094ce90ef3a8a93fe55727\n""}, {'number': 4, 'created': '2015-03-11 06:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/251d2c5f47c38cf54417b07e1be5ee8c7a4561a6', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nNote: If we comment the extension_drivers in ml2_conf.ini, port_security will\nbe loaded. If we set the extension_drivers to NULL, none extension driver will\nbe loaded.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nDepends-On: I2da53168e2529db7a8094ce90ef3a8a93fe55727\n""}, {'number': 5, 'created': '2015-03-24 10:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/35886f334ad96083ff616b28189fe9945f293fa6', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nDepends-On: I2da53168e2529db7a8094ce90ef3a8a93fe55727\n""}, {'number': 6, 'created': '2015-04-12 03:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ed0e24def9bf87d80e26df71db924e9c276a91f9', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}, {'number': 7, 'created': '2015-04-16 09:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/01bcde3cac2f7a5f7786bb012c13d9289d2e9682', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}, {'number': 8, 'created': '2015-04-30 17:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1dcc8d7a9e8abf107f7bd02a19db746e1b100619', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}, {'number': 9, 'created': '2015-05-13 04:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/876cb1aacbbf87242b27eed5a4dbe04206bc38ac', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}, {'number': 10, 'created': '2015-05-18 03:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e704217cdd7474c6cc9ee58d6d8418d4ae1d7647', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}, {'number': 11, 'created': '2015-05-18 06:44:10.000000000', 'files': ['doc/source/guides/neutron.rst', 'lib/neutron_plugins/ml2'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a48e5dc4bd3514cc24cd75c72ea998ad9afe5321', 'message': ""add the port_sec as default neutron/ml2 extension driver\n\nNeutron ML2 plugin introduces the first extension driver port_security, this\npatch add it to be a default extension driver as a example. And also, if not\nset it by default, networks like public/private which are created after the\nneutron-db-manage's update, will not include the port-sec value.\n\nChange-Id: I3035317c83d22804855517434bd8578719ce0436\nPartially Implements: blueprint ml2-ovs-portsecurity\n""}]",26,162063,a48e5dc4bd3514cc24cd75c72ea998ad9afe5321,80,12,11,11114,,,0,"add the port_sec as default neutron/ml2 extension driver

Neutron ML2 plugin introduces the first extension driver port_security, this
patch add it to be a default extension driver as a example. And also, if not
set it by default, networks like public/private which are created after the
neutron-db-manage's update, will not include the port-sec value.

Change-Id: I3035317c83d22804855517434bd8578719ce0436
Partially Implements: blueprint ml2-ovs-portsecurity
",git fetch https://review.opendev.org/openstack/devstack refs/changes/63/162063/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ml2'],1,95304355b76701e22dffd3b44698b14222c94c60,bp/ml2-ovs-portsecurity,# List of extension drivers to load Q_ML2_PLUGIN_EXT_DRIVERS=${Q_ML2_PLUGIN_EXT_DRIVERS:-port_security} populate_ml2_config /$Q_PLUGIN_CONF_FILE ml2 extension_drivers=$Q_ML2_PLUGIN_EXT_DRIVERS ,,4,0
openstack%2Fpython-muranoclient~master~I678554b223fac982d97c8196fe661ff861b40474,openstack/python-muranoclient,master,I678554b223fac982d97c8196fe661ff861b40474,Point default MURANO_REPO_URL to http://storage.apps.openstack.org,MERGED,2015-05-21 13:03:01.000000000,2015-05-27 14:34:18.000000000,2015-05-27 14:34:15.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-05-21 13:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/57b647029fc13db82925874b21b12733a71350be', 'message': 'Point default MURANO_REPO_URL to http://storage.apps.openstack.org\n\nChange-Id: I678554b223fac982d97c8196fe661ff861b40474\n'}, {'number': 2, 'created': '2015-05-21 14:03:56.000000000', 'files': ['muranoclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/d2182e1b92c6c0f7e0b6af501bcf0a988b5174ef', 'message': 'Point default MURANO_REPO_URL to http://storage.apps.openstack.org\n\nChange-Id: I678554b223fac982d97c8196fe661ff861b40474\n'}]",0,184773,d2182e1b92c6c0f7e0b6af501bcf0a988b5174ef,17,6,2,15168,,,0,"Point default MURANO_REPO_URL to http://storage.apps.openstack.org

Change-Id: I678554b223fac982d97c8196fe661ff861b40474
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/73/184773/2 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/shell.py'],1,57b647029fc13db82925874b21b12733a71350be,apps_os_org," default=utils.env( 'MURANO_REPO_URL', default='http://storage.apps.openstack.org'),"," default=utils.env('MURANO_REPO_URL', default='http://127.0.0.1'),",3,2
openstack%2Fproject-config~master~I749539f387f163e829fdc8390b6bd16cf23c663b,openstack/project-config,master,I749539f387f163e829fdc8390b6bd16cf23c663b,Add barbican-dogtag flag,MERGED,2015-05-22 22:52:08.000000000,2015-05-27 14:30:39.000000000,2015-05-27 14:30:36.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10035}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-22 22:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/de54fd6389388a93c8637f74511ec87258af0e97', 'message': 'Add barbican-dogtag flag\n\nChange-Id: I749539f387f163e829fdc8390b6bd16cf23c663b\nDepends-on: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 2, 'created': '2015-05-22 23:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1bd56907435a18f7ad38c0fde6f830891e2c9130', 'message': 'Add barbican-dogtag flag\n\nChange-Id: I749539f387f163e829fdc8390b6bd16cf23c663b\n'}, {'number': 3, 'created': '2015-05-26 15:16:21.000000000', 'files': ['jenkins/jobs/barbican.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a6955f52d8a2e7d911ab5cfc444fc4e2a67a732c', 'message': 'Add barbican-dogtag flag\n\nChange-Id: I749539f387f163e829fdc8390b6bd16cf23c663b\n'}]",2,185183,a6955f52d8a2e7d911ab5cfc444fc4e2a67a732c,18,14,3,10873,,,0,"Add barbican-dogtag flag

Change-Id: I749539f387f163e829fdc8390b6bd16cf23c663b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/83/185183/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/barbican.yaml'],1,de54fd6389388a93c8637f74511ec87258af0e97,dogtag_stuff," export ENABLED_SERVICES=barbican,barbican-dogtag,tempest,keystone"," export ENABLED_SERVICES=barbican,tempest,keystone",1,1
openstack%2Fopenstack-manuals~master~Ifa6bdb909a703a29657505cba35059052c56d113,openstack/openstack-manuals,master,Ifa6bdb909a703a29657505cba35059052c56d113,Remove unnessesary label in End User Guide,MERGED,2015-05-27 09:45:02.000000000,2015-05-27 14:28:09.000000000,2015-05-27 14:28:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-27 09:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3b0b095db9ac3f3e5724924f16b3c67b4fee202a', 'message': 'Fix typo in End User Guide\n\nChange-Id: Ifa6bdb909a703a29657505cba35059052c56d113\nCloses-Bug: 1459171\n'}, {'number': 2, 'created': '2015-05-27 13:43:09.000000000', 'files': ['doc/user-guide/source/dashboard_manage_containers.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a112a0b5bc263e32038858288f35bbb4708acde7', 'message': 'Remove unnessesary label in End User Guide\n\nChange-Id: Ifa6bdb909a703a29657505cba35059052c56d113\nCloses-Bug: 1459171\n'}]",1,185905,a112a0b5bc263e32038858288f35bbb4708acde7,11,4,2,10497,,,0,"Remove unnessesary label in End User Guide

Change-Id: Ifa6bdb909a703a29657505cba35059052c56d113
Closes-Bug: 1459171
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/05/185905/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/source/dashboard_manage_containers.rst'],1,3b0b095db9ac3f3e5724924f16b3c67b4fee202a,bug/1459171,**Procedure: To edit an object****Procedure: To copy an object from one container to another**,**To edit an object****Procedure To copy an object from one container to another**,2,2
openstack%2Fmurano~master~Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a,openstack/murano,master,Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a,Improve exception handling during enviroment editing,MERGED,2015-05-19 11:51:02.000000000,2015-05-27 14:25:54.000000000,2015-05-27 14:25:53.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-19 11:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/37003dae65e717a359bbe1d94a80d5791b817ce0', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 2, 'created': '2015-05-19 11:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7e14175202ec08440d3d7dbd1395f2fb88fcaf1d', 'message': 'Improve error handling during environment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142'}, {'number': 3, 'created': '2015-05-19 11:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6d7363f22187edd99ea152be72ebe1d3b82a3efe', 'message': 'Improve error handling during environment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142'}, {'number': 4, 'created': '2015-05-25 07:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/91d7240173479000e2b5e253cf30b0ea349e8dcf', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 5, 'created': '2015-05-25 09:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/47a9050f0d9170a6680212b3d08aa0ce20603e71', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 6, 'created': '2015-05-25 09:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/43a174fbaf3b06560de38d9f51d7b8c8ae6ad325', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 7, 'created': '2015-05-25 16:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/eacc990a9a0db4eb4c6437b70e1d07fd9bb400ed', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 8, 'created': '2015-05-25 16:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/259e04f252a87c79206b31fd507dae09de3a8451', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}, {'number': 9, 'created': '2015-05-26 08:40:49.000000000', 'files': ['murano/api/v1/environments.py', 'doc/source/specification/murano-api.rst', 'murano/tests/unit/api/v1/test_environments.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/2eaedf2d797de86a299ec9e00990a1ae460524d7', 'message': 'Improve exception handling during enviroment editing\n\nChange-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a\nPartial-Bug: #1455142\n'}]",4,184228,2eaedf2d797de86a299ec9e00990a1ae460524d7,46,7,9,13149,,,0,"Improve exception handling during enviroment editing

Change-Id: Ie40cc99bb9b69caf4fe552a95c55c31a4d191f5a
Partial-Bug: #1455142
",git fetch https://review.opendev.org/openstack/murano refs/changes/28/184228/8 && git format-patch -1 --stdout FETCH_HEAD,['murano/api/v1/environments.py'],1,37003dae65e717a359bbe1d94a80d5791b817ce0,bug/1455142, try: environment.update(body) environment.save(session) except db_exc.DBDuplicateEntry: msg = _('Environment with specified name already exists') LOG.exception(msg) raise exc.HTTPConflict(explanation=msg), environment.update(body) environment.save(session),7,2
openstack%2Fmurano~master~Ia491c957ebd29fb27614623e6f8ef6bd327e9449,openstack/murano,master,Ia491c957ebd29fb27614623e6f8ef6bd327e9449,Add unique constraint to environment table,MERGED,2015-05-25 16:40:51.000000000,2015-05-27 14:25:51.000000000,2015-05-27 14:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-25 16:40:51.000000000', 'files': ['murano/db/models.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/1a84e6f7296d532875bae07510826629aaba4566', 'message': 'Add unique constraint to environment table\n\nChange-Id: Ia491c957ebd29fb27614623e6f8ef6bd327e9449\nPartial-Bug: #1415436\n'}]",0,185426,1a84e6f7296d532875bae07510826629aaba4566,16,8,1,13149,,,0,"Add unique constraint to environment table

Change-Id: Ia491c957ebd29fb27614623e6f8ef6bd327e9449
Partial-Bug: #1415436
",git fetch https://review.opendev.org/openstack/murano refs/changes/26/185426/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/db/models.py'],1,1a84e6f7296d532875bae07510826629aaba4566,bug/1415436," __table_args__ = (sa.Index( 'ix_name_tenant_id', 'name', 'tenant_id', unique=True),)",,2,0
openstack%2Fmurano~master~Idc0b6c4f6043366e7bb95bb57b88fa7e6d304001,openstack/murano,master,Idc0b6c4f6043366e7bb95bb57b88fa7e6d304001,corrected typos throughout murano source articles,MERGED,2015-05-26 22:28:15.000000000,2015-05-27 14:19:27.000000000,2015-05-27 14:19:25.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-26 22:28:15.000000000', 'files': ['doc/source/articles/policy_enf_setup.rst', 'doc/source/articles/client.rst', 'doc/source/articles/dynamic_ui.rst', 'doc/source/articles/policy_enf_dev.rst', 'doc/source/articles/app_migrating.rst', 'doc/source/articles/heat_support.rst', 'doc/source/articles/repository.rst', 'doc/source/articles/test_docs.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/f4a280f8a321044705004792fbf275a3273cd39b', 'message': 'corrected typos throughout murano source articles\n\nsuported should be supported\nspecfying should be specifying\nregistered should be registered\narhive should be archive\nenvironmet should be environment\nremoved title capitals where not required\nsplitted is not a word changed to split\npakcage should be package\nscenarious should be scenarios\n\nChange-Id: Idc0b6c4f6043366e7bb95bb57b88fa7e6d304001\n'}]",0,185760,f4a280f8a321044705004792fbf275a3273cd39b,11,6,1,9382,,,0,"corrected typos throughout murano source articles

suported should be supported
specfying should be specifying
registered should be registered
arhive should be archive
environmet should be environment
removed title capitals where not required
splitted is not a word changed to split
pakcage should be package
scenarious should be scenarios

Change-Id: Idc0b6c4f6043366e7bb95bb57b88fa7e6d304001
",git fetch https://review.opendev.org/openstack/murano refs/changes/60/185760/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/articles/policy_enf_setup.rst', 'doc/source/articles/client.rst', 'doc/source/articles/dynamic_ui.rst', 'doc/source/articles/policy_enf_dev.rst', 'doc/source/articles/app_migrating.rst', 'doc/source/articles/heat_support.rst', 'doc/source/articles/repository.rst', 'doc/source/articles/test_docs.rst']",8,f4a280f8a321044705004792fbf275a3273cd39b,murano,"Murano automated tests descriptionMurano continuous integration serviceMurano automated tests: UI testsThe murano project has a web user interface and all possible user scenarios should be tested.All Murano services have tempest-based automated tests, which allow to verify API interfaces and deployment scenarios.","Murano Automated Tests DescriptionMurano Continuous Integration ServiceMurano Automated Tests: UI TestsMurano project has a Web User Interface and all possible user scenarios should be tested.All Murano services have tempest-based automated tests, which allow to verify API interfaces and deployment scenarious.",19,19
openstack%2Fdevstack-gate~master~Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354,openstack/devstack-gate,master,Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354,Add manila-ui to cloned projects,MERGED,2015-05-21 13:44:48.000000000,2015-05-27 14:14:06.000000000,2015-05-27 14:14:04.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8851}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-21 13:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f5b57aba808078416b641baa0dc17d4378147711', 'message': 'Add manila-ui to cloned projects\n\nChange-Id: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n'}, {'number': 2, 'created': '2015-05-21 13:57:48.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3527b4d3710e2b0f76dd045735b09198915c3678', 'message': 'Add manila-ui to cloned projects\n\nThis change is required by Manila devstack plugin to\nsetup manila-ui in gate jobs.\n\nSee change Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97\nfor more details.\n\nChange-Id: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354\n'}]",2,184788,3527b4d3710e2b0f76dd045735b09198915c3678,11,10,2,14232,,,0,"Add manila-ui to cloned projects

This change is required by Manila devstack plugin to
setup manila-ui in gate jobs.

See change Ia64ab7b88c2c1df4d3bf4771c4ea4a9353ed8c97
for more details.

Change-Id: Iaa46955d3e3cc3f96ee21fcabe2c47fd6ab22354
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/88/184788/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,f5b57aba808078416b641baa0dc17d4378147711,,"PROJECTS=""openstack/manila-ui $PROJECTS""",,1,0
openstack%2Fmurano~master~I960473916e70f9e17e5b5b1c228b7efd1deb98b5,openstack/murano,master,I960473916e70f9e17e5b5b1c228b7efd1deb98b5,Add support for 'boolean' HOT parameter,MERGED,2015-05-26 21:44:07.000000000,2015-05-27 14:13:13.000000000,2015-05-27 14:13:11.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-26 21:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/29221d250b9a5d780835db540d8e153a473a0df6', 'message': ""Add support for 'boolean' HOT parameter\n\nThe HOT-to-MuranoPL converter did not support 'boolean' type as Heat\nTemplate input parameter. This lead to a\n400 'Unsupported parameter type boolean', during package uploads.\n\nThis patch adds support for boolean type, adds .bool() to boolean field\ncontracts and adds 'boolean' UI type during UI translation.\n\nChange-Id: I960473916e70f9e17e5b5b1c228b7efd1deb98b5\nCloses-Bug: #1450536\n""}, {'number': 2, 'created': '2015-05-27 11:27:41.000000000', 'files': ['murano/packages/hot_package.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/e89f3f4c3d7d39fe10fd8399a351e88f0a88bc8f', 'message': ""Add support for 'boolean' HOT parameter\n\nThe HOT-to-MuranoPL converter did not support 'boolean' type as Heat\nTemplate input parameter. This lead to a\n400 'Unsupported parameter type boolean', during package uploads.\n\nThis patch adds support for boolean type, adds .bool() to boolean field\ncontracts and adds 'boolean' UI type during UI translation.\n\nChange-Id: I960473916e70f9e17e5b5b1c228b7efd1deb98b5\nCloses-Bug: #1450536\n""}]",2,185750,e89f3f4c3d7d39fe10fd8399a351e88f0a88bc8f,15,5,2,15168,,,0,"Add support for 'boolean' HOT parameter

The HOT-to-MuranoPL converter did not support 'boolean' type as Heat
Template input parameter. This lead to a
400 'Unsupported parameter type boolean', during package uploads.

This patch adds support for boolean type, adds .bool() to boolean field
contracts and adds 'boolean' UI type during UI translation.

Change-Id: I960473916e70f9e17e5b5b1c228b7efd1deb98b5
Closes-Bug: #1450536
",git fetch https://review.opendev.org/openstack/murano refs/changes/50/185750/2 && git format-patch -1 --stdout FETCH_HEAD,['murano/packages/hot_package.py'],1,29221d250b9a5d780835db540d8e153a473a0df6,bug/1450536," elif parameter_type == 'boolean': contract += '.bool()' if parameter_type == 'number': elif parameter_type == 'boolean': translated['type'] = 'boolean' else: # ('string', 'json', 'comma_delimited_list') translated['type'] = 'string'"," if parameter_type in ('string', 'json', 'comma_delimited_list'): translated['type'] = 'string' elif parameter_type == 'number':",7,3
openstack%2Fmurano-apps~master~I869ac19705437faf99c77b3c87f9cf590f9eaae4,openstack/murano-apps,master,I869ac19705437faf99c77b3c87f9cf590f9eaae4,Add elements for puppet/chef,MERGED,2015-05-06 16:12:56.000000000,2015-05-27 14:06:07.000000000,2015-05-27 14:06:07.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 13149}, {'_account_id': 13752}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-06 16:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/9c05fc99323a0c5e1ec6266c7d4da3d70328623c', 'message': 'Added elements for puppet/chef\n\nChange-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4\n'}, {'number': 2, 'created': '2015-05-22 16:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/da8e509d7ebc871e997fd1e5c9d5ed0c4727e4a9', 'message': 'Added elements for puppet/chef\n\nChange-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4\n'}, {'number': 3, 'created': '2015-05-24 12:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/2e4e65b6cab38425dc3fbb514e455c41eea55fb8', 'message': 'Add elements for puppet/chef\n\nChange-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4\n'}, {'number': 4, 'created': '2015-05-24 12:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/a5957049d504fa0da11d55350a3d6183e4a6474f', 'message': 'Add elements for puppet/chef\n\nChange-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4\n'}, {'number': 5, 'created': '2015-05-26 11:24:48.000000000', 'files': ['Examples/PuppetExample/elements/readme.rst', 'Examples/ChefExample/elements/readme.rst', 'Examples/PuppetExample/elements/puppet/install.d/60-puppet', 'Examples/ChefExample/elements/chef/install.d/60-chef'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/14c042c05d008bf195744a070d4004c1f3391418', 'message': 'Add elements for puppet/chef\n\nChange-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4\n'}]",3,180608,14c042c05d008bf195744a070d4004c1f3391418,21,6,5,13752,,,0,"Add elements for puppet/chef

Change-Id: I869ac19705437faf99c77b3c87f9cf590f9eaae4
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/08/180608/3 && git format-patch -1 --stdout FETCH_HEAD,"['Examples/PuppetExample/elements/puppet/install.d/60-puppet', 'Examples/ChefExample/elements/chef/install.d/60-chef']",2,9c05fc99323a0c5e1ec6266c7d4da3d70328623c,,#!/bin/bash install-packages chef,,4,0
openstack%2Ftripleo-image-elements~master~I06bb225bd349f96c2d52d68657925f1417656cdc,openstack/tripleo-image-elements,master,I06bb225bd349f96c2d52d68657925f1417656cdc,Include yum update extra files,MERGED,2015-05-12 08:55:42.000000000,2015-05-27 14:04:44.000000000,2015-05-27 14:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-12 08:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dd12fc2baf41b39ddcffe8a8e813307e91237ed2', 'message': 'Include yum update extra files\n\nI56bbf944ecd6cbdbf116021b8a53f9f9111c134f adds extra files for yum\nupdates. These files should be loaded into tuskar too.\n\nChange-Id: I06bb225bd349f96c2d52d68657925f1417656cdc\nRelated-to: I56bbf944ecd6cbdbf116021b8a53f9f9111c134f\n'}, {'number': 2, 'created': '2015-05-14 12:54:30.000000000', 'files': ['elements/tuskar/os-refresh-config/configure.d/90-tuskar-db-sync'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8f8b0c17862b98be64c37a498a5628d50fe5db76', 'message': 'Include yum update extra files\n\nI56bbf944ecd6cbdbf116021b8a53f9f9111c134f adds extra files for yum\nupdates. These files should be loaded into tuskar too.\n\nChange-Id: I06bb225bd349f96c2d52d68657925f1417656cdc\nRelated-to: I56bbf944ecd6cbdbf116021b8a53f9f9111c134f\n'}]",2,182198,8f8b0c17862b98be64c37a498a5628d50fe5db76,17,5,2,7582,,,0,"Include yum update extra files

I56bbf944ecd6cbdbf116021b8a53f9f9111c134f adds extra files for yum
updates. These files should be loaded into tuskar too.

Change-Id: I06bb225bd349f96c2d52d68657925f1417656cdc
Related-to: I56bbf944ecd6cbdbf116021b8a53f9f9111c134f
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/98/182198/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/tuskar/os-refresh-config/configure.d/90-tuskar-db-sync'],1,dd12fc2baf41b39ddcffe8a8e813307e91237ed2,extraconfig," # include yum update extra files for i in extraconfig/tasks/yum_update.yaml extraconfig/tasks/yum_update.sh; do file=""$TUSKAR_ROLE_DIRECTORY/$i"" if [ -e $file ];then ROLE_EXTRA_DATA=""$ROLE_EXTRA_DATA --extra-data $file "" fi done ",,8,0
openstack%2Fmagnum~master~Ie1f379f79cb94753767fcb0a2a3e31d5a135d0e9,openstack/magnum,master,Ie1f379f79cb94753767fcb0a2a3e31d5a135d0e9,remove allow_logical_names check,MERGED,2015-05-22 09:02:40.000000000,2015-05-27 14:03:58.000000000,2015-05-27 14:03:56.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-05-22 09:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/203106f8cfd13f021db91f4aaf711c5a182a3efb', 'message': 'remove allow_logical_names check\n\nFor now we have not support microversion yet, but allow_logical_names\ncheckes the microversion.\n\nThis logic can be implemented after microversion is there.\n\nChange-Id: Ie1f379f79cb94753767fcb0a2a3e31d5a135d0e9\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\n'}, {'number': 2, 'created': '2015-05-26 06:10:20.000000000', 'files': ['magnum/common/utils.py', 'magnum/api/controllers/v1/utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9bd60157aa97672d4f146e70ce9a0b2cd3ef6cb2', 'message': 'remove allow_logical_names check\n\nFor now we have not support microversion yet, but allow_logical_names\ncheckes the microversion.\n\nThis logic can be implemented after microversion is there.\n\nChange-Id: Ie1f379f79cb94753767fcb0a2a3e31d5a135d0e9\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\n'}]",0,184974,9bd60157aa97672d4f146e70ce9a0b2cd3ef6cb2,11,5,2,11189,,,0,"remove allow_logical_names check

For now we have not support microversion yet, but allow_logical_names
checkes the microversion.

This logic can be implemented after microversion is there.

Change-Id: Ie1f379f79cb94753767fcb0a2a3e31d5a135d0e9
Co-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/74/184974/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/common/utils.py', 'magnum/api/controllers/v1/utils.py']",2,203106f8cfd13f021db91f4aaf711c5a182a3efb,bp/api-microversions," return resource.get_by_name(pecan.request.context, resource_ident)"," if utils.allow_logical_names(): return resource.get_by_name(pecan.request.context, resource_ident)",1,14
openstack%2Fmagnum~master~I8448bf9ea050513dfb271cdce7f61d37f89fd186,openstack/magnum,master,I8448bf9ea050513dfb271cdce7f61d37f89fd186,Improving Unit Test coverage of k8s_manifest,MERGED,2015-05-25 21:29:15.000000000,2015-05-27 13:59:33.000000000,2015-05-27 13:59:32.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 16051}]","[{'number': 1, 'created': '2015-05-25 21:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8ac9410f8e88ebd975b6004c35b3732b4b4c8c14', 'message': 'Examples of improving Unit Test coverage for new contributors.\n\nChange-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186\nImplements: blueprint integrate-ci-metrics\n'}, {'number': 2, 'created': '2015-05-26 03:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/da663007e41b1aba01f81f32da03e29bb732b01d', 'message': 'Improving Unit Test coverage and using these tests to provide a\ndocumented example to demonstrate writing unit tests for new\ncontributors for increasing project code coverage.\n\nChange-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186\nImplements: blueprint integrate-ci-metrics\n'}, {'number': 3, 'created': '2015-05-26 13:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0fdfa7ce0b47ec0a5a1c7e00ea11564b944339af', 'message': 'Improving Unit Test coverage of k8s_manifest\n\nIn addition these tests are used to provide a documented example\nto demonstrate writing unit tests for new contributors for\nincreasing project code coverage.\n\nChange-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186\nCloses-Bug: #1458879\nImplements: blueprint integrate-ci-metrics\n'}, {'number': 4, 'created': '2015-05-26 14:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f74cd8b17e08b3543e459d5abc446732cfbccb33', 'message': 'Improving Unit Test coverage of k8s_manifest\n\nIn addition these tests are used to provide a documented example\nto demonstrate writing unit tests for new contributors for\nincreasing project code coverage.\n\nChange-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186\nCloses-Bug: #1458879\nImplements: blueprint integrate-ci-metrics\n'}, {'number': 5, 'created': '2015-05-27 11:47:28.000000000', 'files': ['magnum/common/k8s_manifest.py', 'magnum/tests/unit/common/test_k8s_manifest.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d3e041b785f9e4a2bd2bd2714d938c7afb8ab3c5', 'message': 'Improving Unit Test coverage of k8s_manifest\n\nIn addition these tests are used to provide a documented example\nto demonstrate writing unit tests for new contributors for\nincreasing project code coverage.\n\nChange-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186\nCloses-Bug: #1458879\nPartially-Implements: blueprint integrate-ci-metrics\n'}]",9,185454,d3e041b785f9e4a2bd2bd2714d938c7afb8ab3c5,26,7,5,16051,,,0,"Improving Unit Test coverage of k8s_manifest

In addition these tests are used to provide a documented example
to demonstrate writing unit tests for new contributors for
increasing project code coverage.

Change-Id: I8448bf9ea050513dfb271cdce7f61d37f89fd186
Closes-Bug: #1458879
Partially-Implements: blueprint integrate-ci-metrics
",git fetch https://review.opendev.org/openstack/magnum refs/changes/54/185454/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/unit/common/test_k8s_manifest.py'],1,8ac9410f8e88ebd975b6004c35b3732b4b4c8c14,bp/integrate-ci-metrics," port = 6379 ""port"": ''' + str(port) + ''', ""containerPort"": ''' + str(port) + ''', self.assertEqual(port, manifest['port']) self.assertEqual(port, manifest['containerPort']) port = 6389 port: ''' + str(port) + ''' containerPort: ''' + str(port) + ''' self.assertEqual(port, manifest['port']) self.assertEqual(port, manifest['containerPort']) def test_parse_empty_value(self): empty_str = '' self.assertRaises(ValueError, k8s_manifest.parse, empty_str) def test_parse_empty_dict_response(self): blank_str = ' ' manifest = k8s_manifest.parse(blank_str) self.assertIsInstance(manifest, dict) self.assertEqual({}, manifest) def test_parse_yaml_error(self): invalid_str = ""}invalid: y'm'l3!"" self.assertRaises(ValueError, k8s_manifest.parse, invalid_str) "," ""port"": 6379, ""containerPort"": 6379, port: 6379 containerPort: 6379",28,4
openstack%2Fneutron~master~Ieff0236670c1403b5d79ad8e50d7574c1b694e34,openstack/neutron,master,Ieff0236670c1403b5d79ad8e50d7574c1b694e34,Pass '--dhcp-authoritative' option to dnsmasq,MERGED,2015-02-02 10:46:17.000000000,2015-05-27 13:58:58.000000000,2015-02-05 07:19:09.000000000,"[{'_account_id': 3}, {'_account_id': 161}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 7634}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11061}, {'_account_id': 11762}, {'_account_id': 12040}, {'_account_id': 12524}, {'_account_id': 12860}, {'_account_id': 14212}, {'_account_id': 14562}]","[{'number': 1, 'created': '2015-02-02 10:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b5a4de91e5accde4f73ec98f2495bef73e1770e', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1417057\n'}, {'number': 2, 'created': '2015-02-04 09:45:43.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1345947\n'}]",3,152080,74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70,63,28,2,11061,,,0,"Pass '--dhcp-authoritative' option to dnsmasq

When dnsmasq is restarted, it forgets about all leases (since it runs
with leasefile-ro option). When client tries to renew its lease, dnsmasq
sends DHCPNAK reply with message ""lease not found"". Then client shuts
down the network and re-request lease from DHCP server (and gets exactly
same IP address). There's a small network downtime which affects
services, like zookeeper, running in VMs.

Change-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34
Closes-Bug: #1345947
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/152080/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,2b5a4de91e5accde4f73ec98f2495bef73e1770e,bug/1345947," '--leasefile-ro', '--dhcp-authoritative']", '--leasefile-ro'],3,1
openstack%2Fneutron~stable%2Fjuno~Ieff0236670c1403b5d79ad8e50d7574c1b694e34,openstack/neutron,stable/juno,Ieff0236670c1403b5d79ad8e50d7574c1b694e34,Pass '--dhcp-authoritative' option to dnsmasq,MERGED,2015-02-05 10:23:01.000000000,2015-05-27 13:55:16.000000000,2015-02-12 14:23:20.000000000,"[{'_account_id': 3}, {'_account_id': 161}, {'_account_id': 704}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9380}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 11061}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-02-05 10:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92caee907006c341f951a06f8bfe0c224c63a6b4', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1345947\n(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)\n'}, {'number': 2, 'created': '2015-02-05 15:00:03.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed799e38fe740621776aab51c95ec1db248af997', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1345947\nCo-Authored-By: Kevin Bringard <kevinbri@cisco.com>\n(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)\n'}]",0,153182,ed799e38fe740621776aab51c95ec1db248af997,46,23,2,9656,,,0,"Pass '--dhcp-authoritative' option to dnsmasq

When dnsmasq is restarted, it forgets about all leases (since it runs
with leasefile-ro option). When client tries to renew its lease, dnsmasq
sends DHCPNAK reply with message ""lease not found"". Then client shuts
down the network and re-request lease from DHCP server (and gets exactly
same IP address). There's a small network downtime which affects
services, like zookeeper, running in VMs.

Change-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34
Closes-Bug: #1345947
Co-Authored-By: Kevin Bringard <kevinbri@cisco.com>
(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/153182/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,92caee907006c341f951a06f8bfe0c224c63a6b4,bug/1345947," '--leasefile-ro', '--dhcp-authoritative']", '--leasefile-ro'],3,1
openstack%2Fmurano-deployment~master~I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b,openstack/murano-deployment,master,I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b,Set MURANO_REPO_URL for murano-dashboard tests,MERGED,2015-05-26 14:14:47.000000000,2015-05-27 13:51:20.000000000,2015-05-27 13:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 13149}, {'_account_id': 13752}]","[{'number': 1, 'created': '2015-05-26 14:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/e0c1f414cc107d922b94494696da5900a75e46ba', 'message': 'Set MURANO_REPO_URL for murano-dashboard tests\n\nChange-Id: I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b\n'}, {'number': 2, 'created': '2015-05-26 15:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/9a666eab77439c67559e708023ac44910be1365e', 'message': 'Set MURANO_REPO_URL for murano-dashboard tests\n\nChange-Id: I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b\n'}, {'number': 3, 'created': '2015-05-26 16:01:16.000000000', 'files': ['murano-ci/scripts/murano-integration-tests-devstack.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/05fe6dc4a75d6ff341cb48d5f6915bc105abb4df', 'message': 'Set MURANO_REPO_URL for murano-dashboard tests\n\nSet MURANO_REPO_URL var during devstack configuration for dashboard and\nallow inbound traffic on 8099 port.\n\nDepends-On: I9ca36d1f5fb1ec9206465542a8af42522465735b\nChange-Id: I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b\n'}]",1,185618,05fe6dc4a75d6ff341cb48d5f6915bc105abb4df,15,5,3,15168,,,0,"Set MURANO_REPO_URL for murano-dashboard tests

Set MURANO_REPO_URL var during devstack configuration for dashboard and
allow inbound traffic on 8099 port.

Depends-On: I9ca36d1f5fb1ec9206465542a8af42522465735b
Change-Id: I00b9e561ebc0c36f1a21e27d86179ffe9d41c97b
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/18/185618/1 && git format-patch -1 --stdout FETCH_HEAD,['murano-ci/scripts/murano-integration-tests-devstack.sh'],1,e0c1f414cc107d922b94494696da5900a75e46ba,," echo ""MURANO_REPO_URL='http://${floating_ip_address}:8099'"" >> /usr/share/openstack-dashboard/openstack_dashboard/settings.py",,1,0
openstack%2Ffuel-astute~master~I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6,openstack/fuel-astute,master,I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6,Improve shell task error message,MERGED,2015-05-22 12:28:18.000000000,2015-05-27 13:50:18.000000000,2015-05-27 13:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-05-22 12:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/8847ea1dd01841e019ec639312f0297343bbb2ac', 'message': 'Improve shell task error message\n\nThe shell command which has failed is included in the\nerror message along with the task timeout.\n\nChange-Id: I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6\nRelated-bug: #1435603\n'}, {'number': 2, 'created': '2015-05-22 15:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/3932159d3478a79bc5642e57d6d8cbe56dd78202', 'message': 'Improve shell task error message\n\nThe shell command which has failed is included in the\nerror message along with the task timeout.\n\nChange-Id: I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6\nRelated-bug: #1435603\n'}, {'number': 3, 'created': '2015-05-26 15:57:15.000000000', 'files': ['lib/astute/nailgun_hooks.rb', 'spec/unit/nailgun_hooks_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/7e07b873b607e8b91845c465c2884af19cca56a1', 'message': 'Improve shell task error message\n\nThe shell command which has failed is included in the\nerror message along with the task timeout.\n\nChange-Id: I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6\nRelated-bug: #1435603\n'}]",1,185008,7e07b873b607e8b91845c465c2884af19cca56a1,21,5,3,8829,,,0,"Improve shell task error message

The shell command which has failed is included in the
error message along with the task timeout.

Change-Id: I0ea474a899ba86d32b6b4f1a96de4baee17ecdc6
Related-bug: #1435603
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/08/185008/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/nailgun_hooks.rb'],1,8847ea1dd01841e019ec639312f0297343bbb2ac,bug/1435603," error_message += hook_return['error'] ret['error'] += ""\n\nTask: #{@ctx.task_id}: "" \ ""shell timeout error: #{e.message}\n"" \ ""Task timeout: #{timeout}, Retries: "" \ ""Retries: #{hook['parameters']['retries']}"""," ret['error'] = ""#{@ctx.task_id}: shell timeout error: #{e.message}""",5,1
openstack%2Fkolla~master~I83f3cdb1dabf0dfface589c581cb22c155467acc,openstack/kolla,master,I83f3cdb1dabf0dfface589c581cb22c155467acc,Clean up the image functional test,MERGED,2015-05-15 07:20:50.000000000,2015-05-27 13:49:58.000000000,2015-05-27 13:49:54.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 9488}, {'_account_id': 10419}, {'_account_id': 13039}]","[{'number': 1, 'created': '2015-05-15 07:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6fe7511f9784d55101b4b386bab5b402773f580d', 'message': 'Move setup_docker.sh to tools directory\n\nCreate a dummy setup_docker.sh in tests directory that returns 0\nto unbreak the gate.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 2, 'created': '2015-05-15 07:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b2d111f9381a4b824be634ada8bae4a30bb41a30', 'message': 'Move setup_docker.sh to tools directory\n\nCreate a dummy setup_docker.sh in tests directory that returns 0\nto unbreak the gate.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 3, 'created': '2015-05-15 07:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/39be9d1c0e114d9cf964bf9cbdf4c3ffbe2e4087', 'message': 'Move setup_docker.sh to tools directory\n\nCreate a dummy setup_docker.sh in tests directory that returns 0\nto unbreak the gate.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 4, 'created': '2015-05-15 07:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d846c9816587bbab6d409cc0766e507db75a760c', 'message': 'Move setup_docker.sh to tools directory\n\nCreate a dummy setup_docker.sh in tests directory that returns 0\nto unbreak the gate.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 5, 'created': '2015-05-15 07:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/53281cad87e31e5b7a8367109784d4b7f42b470b', 'message': 'Move setup_docker.sh to tools directory\n\nCreate a dummy setup_docker.sh in tests directory that returns 0\nto unbreak the gate.\n\nAdd pull option back into build scripts.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 6, 'created': '2015-05-15 08:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/59e452318904bf37c7d9c840d6adbdc96ea04b37', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 7, 'created': '2015-05-17 16:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7eb3ce8ee0f3c86a60d59439fc7cb72789e34650', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Make build-all-docker-images only print out the parsable summary in\n   test mode.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 8, 'created': '2015-05-17 17:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/af7d94d936a2e93c20984add799442da604e1d08', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Make build-all-docker-images only print out the parsable summary in\n   test mode.\n\n5. add some debug output.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 9, 'created': '2015-05-17 18:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/438bca2022334999d4038659d62a37f575d8ba31', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Make build-all-docker-images only print out the parsable summary in\n   test mode.\n\n5. add some debug output.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 10, 'created': '2015-05-18 02:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c96a3117a409ed0ba7a8ed91d80f6d8722d17910', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging (not useful yet) and debug output.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 11, 'created': '2015-05-18 03:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/af78d51e9be302c3c2d752765507e5e0cdc94eb1', 'message': 'Fix the voting functional gate\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging (not useful yet) and debug output.\n\nThis patch has to be one commit to fix the gate in one go.\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 12, 'created': '2015-05-19 22:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8d430791ea9e7a8e8f7c34544f31c248d272741f', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 13, 'created': '2015-05-20 15:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/23efa63d2ba5acf1658aaa47e74a776b5e21f7fe', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 14, 'created': '2015-05-20 17:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ea0cb5bfa2293b1a44d157e52eea767a688e3a1c', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 15, 'created': '2015-05-21 02:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/62de0c08d2fb5fdcf2a6d3c2a80de708b449a330', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 16, 'created': '2015-05-21 02:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3942bb845e32631edefbfb5d94d4af2cc3a6fe0a', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_docker.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 17, 'created': '2015-05-22 20:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/590bb680fff63d109d0509543553caccfbbe4ee3', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 18, 'created': '2015-05-22 20:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fa2eb89dbd89d30bc208d5d6885af148a4aab0a3', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Jeff Peeler\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 19, 'created': '2015-05-24 17:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/21542f6fa1fdba20d90f221e5f1d5a3214c4651f', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 20, 'created': '2015-05-24 17:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/828fb02a9aa7a51ccbfe8a1944763f01ff4d9787', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 21, 'created': '2015-05-24 19:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fb42607dc2e8cb2c945308e5f98b56f3a144d181', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 22, 'created': '2015-05-24 20:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f32f60ac540755da6c65e942e34331108bbd5250', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 23, 'created': '2015-05-24 21:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c479cf386c4e81b776c8a33667b75bc0934f75dc', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 24, 'created': '2015-05-24 21:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/14fb46a24e2a1702abf19076a3d966994eaaa1ee', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 25, 'created': '2015-05-24 21:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/54d126a42a99af31fd93539d2e190e84f021a4f1', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 26, 'created': '2015-05-25 15:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3dae614b009945b179ad3df7b3aba53bd6ebf798', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 27, 'created': '2015-05-25 15:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9998e4d99ca4191136fea1bfe365ff394a1fc8d3', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 28, 'created': '2015-05-25 15:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ae45a46bbeaa83ca771ed63f6fdca29266db4c6e', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 29, 'created': '2015-05-25 16:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/deb9941af794b4b2474f2b524919d5e500240968', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 30, 'created': '2015-05-25 16:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1fe78d2a4104d5bd1e9c496852a03bb32b25098c', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 31, 'created': '2015-05-25 16:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/28d850be898668c43587b3a2bfbc8668819bb9dd', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 32, 'created': '2015-05-25 16:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c79cc65e6aa456d0520535ae0ad492cd1cb1fc8f', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 33, 'created': '2015-05-25 16:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/06d91a19fa8ae3297009d7d28d5f4194a80ed458', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 34, 'created': '2015-05-25 16:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8479d5667efa053d510a16f0fc26d6c2ca3fd190', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 35, 'created': '2015-05-25 16:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e0bb317c326efccf7d80ced5404f4c0fcccd5c9f', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 36, 'created': '2015-05-25 16:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3a0416f5e63eac2adee220ea90079d9936fbe23e', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 37, 'created': '2015-05-25 17:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/44e5994e9d45d71998e729527ec420dace9c3921', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 38, 'created': '2015-05-25 17:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fc68dd5e6fc8bf199a5cd1a18154dd416c01ec58', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 39, 'created': '2015-05-25 17:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/90cc80d5450967aeb0fe8bfcdefe5cc505bbb299', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 40, 'created': '2015-05-25 17:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b52146fbb2c80d87aff4ba7439fbe7194789ad7c', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 41, 'created': '2015-05-25 17:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/37d5dc8f3c8f99e55c578bc86f78c0e608834daf', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 42, 'created': '2015-05-25 17:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/26199d586e989b500bba99d390412fbcd079fedd', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 43, 'created': '2015-05-25 17:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4400a550dfeb8106c0879474d892df1be10e63ba', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 44, 'created': '2015-05-25 17:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/51b19a266f0e2dc40f55184ff9df6397cb5a5c90', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add pull option back into build scripts.\n\n4. Add logging output.\n\n5. Add default test timeout of 2 hours.\n\n6. Add user to the docker group before running test cases\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 45, 'created': '2015-05-25 18:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/628615fc26ee1633abc60ebd53941a3608358f5a', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 46, 'created': '2015-05-25 19:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e16f5f2f1e2de8f429d20a97978799134c2bee37', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 47, 'created': '2015-05-26 16:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4dfafcab26947138f372b9374859e726c985de1d', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 48, 'created': '2015-05-26 16:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/262cebeb17bcd87d5c717cc930c2d647a34f5bde', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 49, 'created': '2015-05-26 17:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/964b5084d787720a471381cc1df84a7dcc672684', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 50, 'created': '2015-05-26 17:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6b794d60137aceaf499aed0c91f8c0dcd43134d3', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}, {'number': 51, 'created': '2015-05-26 19:01:35.000000000', 'files': ['tools/build-docker-image', 'tools/setup_docker.sh', 'tests/test_images.py', 'test-requirements.txt', 'tests/setup_gate.sh', '.testr.conf', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/78b27e3e6017ceda4e15c5b2c87516ec3750fd98', 'message': 'Clean up the image functional test\n\n1. Move setup_docker.sh to tools directory\n\n2. Make a setup_gate.sh that installs necessary packages including\n   docker and starts docker.\n\n3. Add logging output.\n\n4. Add default test timeout of 2 hours.\n\n5. Add user to the docker group before running test cases.\n\n6. Run image build as dockerroot group.\n\nThis patch has to be one commit to fix the gate in one go.\n\nCo-Authored-By: Steven Dake <stdake@cisco.com>\n\nChange-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc\n'}]",15,183417,78b27e3e6017ceda4e15c5b2c87516ec3750fd98,123,6,51,2834,,,0,"Clean up the image functional test

1. Move setup_docker.sh to tools directory

2. Make a setup_gate.sh that installs necessary packages including
   docker and starts docker.

3. Add logging output.

4. Add default test timeout of 2 hours.

5. Add user to the docker group before running test cases.

6. Run image build as dockerroot group.

This patch has to be one commit to fix the gate in one go.

Co-Authored-By: Steven Dake <stdake@cisco.com>

Change-Id: I83f3cdb1dabf0dfface589c581cb22c155467acc
",git fetch https://review.opendev.org/openstack/kolla refs/changes/17/183417/34 && git format-patch -1 --stdout FETCH_HEAD,"['tools/setup_docker.sh', 'tests/setup_docker.sh']",2,6fe7511f9784d55101b4b386bab5b402773f580d,newfailures,return 0,"# # This script is used to setup Kolla Docker environment, # after running this script, you can run Kolla functional test. # NOTE: This script was only tested on redhat/debian/suse platform families. # set -xu DOCKER_MIN_VERSION=1.6.0 function check_prerequisites() { if [[ $EUID -ne 0 ]]; then echo ""You must execute this script as root."" 1>&2 exit 1 fi if [ ""$OSTYPE"" != ""linux-gnu"" ]; then echo Platform not supported exit 255 fi if [ ""$HOSTTYPE"" != ""x86_64"" ]; then echo Machine type not supported exit 255 fi } function check_docker_version() { local docker_version local result if type docker &>/dev/null; then docker_version=$(docker --version 2>/dev/null | awk -F""[ ,]"" '{print $3}') result=$(awk 'BEGIN{print '$docker_version' >= '$DOCKER_MIN_VERSION'}') if [ $result = 1 ]; then return 0 fi fi return 1 } function start_docker() { pkill -x -9 docker if check_docker_version; then docker -d &>/dev/null & else curl -sSL https://get.docker.com/builds/Linux/x86_64/docker-$DOCKER_MIN_VERSION -o /usr/local/bin/docker chmod +x /usr/local/bin/docker /usr/local/bin/docker -d &>/dev/null & fi } function create_group() { getent group docker result=$? if [ $result -eq 0 ]; then # 0: key already exists, nothing to do return elif [ $result -eq 2 ]; then # 2: key could not be found in database groupadd docker chown root:docker /var/run/docker.sock usermod -a -G docker ${SUDO_USER:-$USER} else echo Unexpected failure: $result exit fi } # Check for root privileges and correct platform check_prerequisites # Start Docker service start_docker # Ensure executing user is placed in the docker group create_group",74,72
openstack%2Fnova-powervm~master~I7b200fb20481c69c3cb2d5eb96a6ab1596b8ef2b,openstack/nova-powervm,master,I7b200fb20481c69c3cb2d5eb96a6ab1596b8ef2b,Disk Driver: instance_disk_iter,MERGED,2015-05-19 22:10:29.000000000,2015-05-27 13:46:44.000000000,2015-05-27 13:46:42.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 14806}]","[{'number': 1, 'created': '2015-05-19 22:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/583c9f98dfd311cc2f62c1b7b13d8778716f74a9', 'message': ""Disk Driver: instance_disk_iter\n\nAdd a method to the disk.driver API which can find the backing (usually\nboot) disk associated with an instance.\n\nThis is in anticipation of the snapshot functionality, which will need\nto find an instance's disk in order to map it to the management\npartition.\n\nChange-Id: I7b200fb20481c69c3cb2d5eb96a6ab1596b8ef2b\n""}, {'number': 2, 'created': '2015-05-20 17:21:29.000000000', 'files': ['nova_powervm/tests/virt/powervm/disk/test_ssp.py', 'nova_powervm/virt/powervm/disk/ssp.py', 'nova_powervm/tests/virt/powervm/disk/test_localdisk.py', 'nova_powervm/virt/powervm/disk/localdisk.py', 'nova_powervm/virt/powervm/disk/driver.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/dda2bb9fb6d07cfa5219e64477502dc255b47e1f', 'message': ""Disk Driver: instance_disk_iter\n\nAdd a method to the disk.driver API which can find the backing (usually\nboot) disk associated with an instance.\n\nThis is in anticipation of the snapshot functionality, which will need\nto find an instance's disk in order to map it to the management\npartition.\n\nChange-Id: I7b200fb20481c69c3cb2d5eb96a6ab1596b8ef2b\n""}]",3,184342,dda2bb9fb6d07cfa5219e64477502dc255b47e1f,16,6,2,14070,,,0,"Disk Driver: instance_disk_iter

Add a method to the disk.driver API which can find the backing (usually
boot) disk associated with an instance.

This is in anticipation of the snapshot functionality, which will need
to find an instance's disk in order to map it to the management
partition.

Change-Id: I7b200fb20481c69c3cb2d5eb96a6ab1596b8ef2b
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/42/184342/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/disk/localdisk.py', 'nova_powervm/virt/powervm/disk/driver.py']",2,583c9f98dfd311cc2f62c1b7b13d8778716f74a9,instance_disk_iter,"import pypowervm.tasks.scsi_mapper as tsk_mapimport pypowervm.wrappers.virtual_io_server as pvm_vios from nova_powervm.virt.powervm import vm def vios_uuids(self): """"""List the UUIDs of the Virtual I/O Servers hosting the storage."""""" raise NotImplementedError() def disk_match_func(self, disk_type, instance): """"""Return a matching function to locate the disk for an instance. :param disk_type: One of the DiskType enum values. :param instance: The instance whose disk is to be found. :return: Callable suitable for the match_func parameter of the pypowervm.tasks.scsi_mapper.find_maps method, with the following specification: def match_func(storage_elem) param storage_elem: A backing storage element wrapper (VOpt, VDisk, PV, or LU) to be analyzed. return: True if the storage_elem's mapping should be included; False otherwise. """""" raise NotImplementedError() def instance_disk_iter(self, instance, disk_type=DiskType.BOOT, lpar_wrap=None): """"""Return the instance's storage element wrapper of the specified type. :param instance: nova.objects.instance.Instance object owning the requested disk. :param disk_type: The type of disk to find, one of the DiskType enum values. :param lpar_wrap: pypowervm.wrappers.logical_partition.LPAR corresponding to the instance. If not specified, it will be retrieved; i.e. specify this parameter to save on REST calls. :return: Iterator of tuples of (storage_elem, VIOS), where storage_elem is a storage element wrapper (pypowervm.wrappers.storage.VOpt, VDisk, PV, or LU) associated with the instance; and VIOS is the wrapper of the Virtual I/O Server owning that storage element. """""" if lpar_wrap is None: lpar_wrap = vm.get_instance_wrapper(self.adapter, instance, self.host_uuid) match_func = self.disk_match_func(disk_type, instance) for vios_uuid in self.vios_uuids: vios_wrap = pvm_vios.VIOS.wrap(self.adapter.read( pvm_vios.VIOS.schema_type, root_id=vios_uuid, xag=pvm_vios.VIOS.xags.SCSI_MAPPING)) for scsi_map in tsk_map.find_maps( vios_wrap.scsi_mappings, lpar_wrap.id, match_func): yield scsi_map.backing_storage, vios_wrap @property",,85,5
openstack%2Ffreezer~master~I6e70e60797742054e0e5e10b7b2398bc42354e3b,openstack/freezer,master,I6e70e60797742054e0e5e10b7b2398bc42354e3b,Consistent opt args and variable to dentify that same opt arg,MERGED,2015-05-27 13:27:49.000000000,2015-05-27 13:45:06.000000000,2015-05-27 13:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 12211}]","[{'number': 1, 'created': '2015-05-27 13:27:49.000000000', 'files': ['freezer/swift.py', 'freezer/arguments.py', 'freezer/utils.py', 'tests/test_utils.py', 'tests/commons.py', 'freezer/lvm.py', 'tests/test_tar.py', 'tests/test_backup.py', 'tests/scenario/backup_scenario.py', 'freezer/job.py', 'tests/test_job.py', 'freezer/backup.py', 'freezer/tar.py', 'tests/test_swift.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/c7f71ff70bdcc68efc2c88e736a6c39443e33ab6', 'message': 'Consistent opt args and variable to dentify that same opt arg\n\nThe freezerc was using an inconsistent naming convenstion\nbetween option arguments and variable to the same opt argument\n\ni.e,:\n--path-to-backup -> (backup_opt_dict.src_file)\n\nChange-Id: I6e70e60797742054e0e5e10b7b2398bc42354e3b\nImplements: blueprint consistent-args\n'}]",0,185980,c7f71ff70bdcc68efc2c88e736a6c39443e33ab6,6,2,1,11151,,,0,"Consistent opt args and variable to dentify that same opt arg

The freezerc was using an inconsistent naming convenstion
between option arguments and variable to the same opt argument

i.e,:
--path-to-backup -> (backup_opt_dict.src_file)

Change-Id: I6e70e60797742054e0e5e10b7b2398bc42354e3b
Implements: blueprint consistent-args
",git fetch https://review.opendev.org/openstack/freezer refs/changes/80/185980/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/swift.py', 'freezer/arguments.py', 'freezer/utils.py', 'tests/test_utils.py', 'tests/commons.py', 'freezer/lvm.py', 'tests/test_tar.py', 'tests/test_backup.py', 'tests/scenario/backup_scenario.py', 'freezer/job.py', 'tests/test_job.py', 'freezer/backup.py', 'freezer/tar.py', 'tests/test_swift.py']",14,c7f71ff70bdcc68efc2c88e736a6c39443e33ab6,bp/consistent-args, backup_opt.__dict__['list_containers'] = True backup_opt.__dict__['list_containers'] = False, backup_opt.__dict__['list_container'] = True backup_opt.__dict__['list_container'] = False,99,97
openstack%2Fproject-config~master~I63d0b7fe37b92aa807499ee2c7971d47ee86b420,openstack/project-config,master,I63d0b7fe37b92aa807499ee2c7971d47ee86b420,Stop running non-voting docker job on nova,MERGED,2015-01-28 18:22:51.000000000,2015-05-27 13:43:48.000000000,2015-01-28 19:05:30.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-28 18:22:51.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1da1ca091a9eba0809d30fcc946962446d0c5ecd', 'message': 'Stop running non-voting docker job on nova\n\nnova-docker has been broken for a while and no one is maintaining it,\nso stop running it on nova repo. When this is working again we can bring\nit back etc.\n\nChange-Id: I63d0b7fe37b92aa807499ee2c7971d47ee86b420\n'}]",0,150887,1da1ca091a9eba0809d30fcc946962446d0c5ecd,10,5,1,1849,,,0,"Stop running non-voting docker job on nova

nova-docker has been broken for a while and no one is maintaining it,
so stop running it on nova repo. When this is working again we can bring
it back etc.

Change-Id: I63d0b7fe37b92aa807499ee2c7971d47ee86b420
",git fetch https://review.opendev.org/openstack/project-config refs/changes/87/150887/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1da1ca091a9eba0809d30fcc946962446d0c5ecd,,, - check-tempest-dsvm-docker,0,1
openstack%2Ftooz~master~Ic6ec2d573bc1bf79c7aa6796f7a53b04251a610f,openstack/tooz,master,Ic6ec2d573bc1bf79c7aa6796f7a53b04251a610f,Updated from global requirements,MERGED,2015-05-27 01:14:19.000000000,2015-05-27 13:39:18.000000000,2015-05-27 13:39:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-27 01:14:19.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tooz/commit/f16972d4237df86aae6e85af92ee444b6afd9fd4', 'message': 'Updated from global requirements\n\nChange-Id: Ic6ec2d573bc1bf79c7aa6796f7a53b04251a610f\n'}]",0,185801,f16972d4237df86aae6e85af92ee444b6afd9fd4,12,4,1,11131,,,0,"Updated from global requirements

Change-Id: Ic6ec2d573bc1bf79c7aa6796f7a53b04251a610f
",git fetch https://review.opendev.org/openstack/tooz refs/changes/01/185801/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f16972d4237df86aae6e85af92ee444b6afd9fd4,openstack/requirements,"kazoo>=1.3.1,!=2.1",kazoo>=1.3.1,1,1
openstack%2Ftripleo-incubator~master~I066a5d0022871804479c1ee325881381b08020c6,openstack/tripleo-incubator,master,I066a5d0022871804479c1ee325881381b08020c6,Rename brbm.xml template to net.xml,MERGED,2015-05-15 14:23:16.000000000,2015-05-27 13:33:13.000000000,2015-05-27 13:33:13.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-05-15 14:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f45b7b267ac37bb559db6ddc6297131168b3e4a5', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}, {'number': 2, 'created': '2015-05-15 16:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/a44ae1d0e17678308de19d637065bbc889dc190a', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}, {'number': 3, 'created': '2015-05-21 17:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f1df564448b336fabeb95fb1bcc65f4eebb92fae', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}, {'number': 4, 'created': '2015-05-22 18:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/cc716de5bcacc5ea1cbe5164517af970022067d8', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}, {'number': 5, 'created': '2015-05-26 12:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bce28d68f46a8abc33bd75ec9b6c6937a3afdf4f', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}, {'number': 6, 'created': '2015-05-26 16:59:06.000000000', 'files': ['templates/net.xml', 'templates/brbm.xml', 'scripts/setup-network'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/044463ad5c2444fb80f16c942e2cdeae94103c60', 'message': 'Rename brbm.xml template to net.xml\n\nThe brbm.xml template is not used for multiple networks.\nAdditionally libvirt calls these net (or networks) so\nrenaming the template makes it less confusing.\n\nUsing a more explicit %NETWORK_NAME% tag in the template so\nthat it is more clear what is being replaced by a variable.\n\nChange-Id: I066a5d0022871804479c1ee325881381b08020c6\n'}]",0,183539,044463ad5c2444fb80f16c942e2cdeae94103c60,28,4,6,360,,,0,"Rename brbm.xml template to net.xml

The brbm.xml template is not used for multiple networks.
Additionally libvirt calls these net (or networks) so
renaming the template makes it less confusing.

Using a more explicit %NETWORK_NAME% tag in the template so
that it is more clear what is being replaced by a variable.

Change-Id: I066a5d0022871804479c1ee325881381b08020c6
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/39/183539/6 && git format-patch -1 --stdout FETCH_HEAD,"['templates/net.xml', 'templates/brbm.xml', 'scripts/setup-network']",3,f45b7b267ac37bb559db6ddc6297131168b3e4a5,baremetal_network_config, virsh net-define <(sed s/%NETWORK_NAME%/$BRIDGE_NAME/ $BASE/templates/net.xml), virsh net-define <(sed s/brbm/$BRIDGE_NAME/ $BASE/templates/brbm.xml),7,7
openstack%2Fglance~stable%2Fkilo~I0a7e1260259f2c7c7b1307e4022ccee9dbb49869,openstack/glance,stable/kilo,I0a7e1260259f2c7c7b1307e4022ccee9dbb49869,Make sure the converted image is imported,ABANDONED,2015-05-27 13:31:43.000000000,2015-05-27 13:32:36.000000000,,[],"[{'number': 1, 'created': '2015-05-27 13:31:43.000000000', 'files': ['glance/tests/unit/async/flows/test_import.py', 'glance/async/flows/convert.py', 'glance/async/flows/base_import.py', 'glance/tests/unit/async/flows/test_convert.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1b41bd5fc24149eb6576cc55eb96c6ee48c1b77d', 'message': ""Make sure the converted image is imported\n\nTurns out the converted image is being completely ignored. This is\nbecause the `file_path` provided by the ImportToFS task cannot be\noverriden by other tasks. In order to fix this, I've dropped all the\nextra suffixes that we've been using in favor of working on the actual\n`file_path` directly.\n\nResolves: rhbz#1065603\nUpstream-Closes-bug: #1452750\nUpstream-Change-Id: Ifbd2308057f33c1f712fa06f9bb3e57f90068fdc\nUpstream-Cherry-Pick: d77fd685ea4d552eb4cf6c5c4a1049ed7964ff05\nUpstream-Kilo: https://review.openstack.org/#/c/181815/\nUpstream-Liberty: https://review.openstack.org/#/c/181024/\n(cherry picked from commit 724f17ac065652bdcf42379f55da3f903ad18f37)\n\nChange-Id: I0a7e1260259f2c7c7b1307e4022ccee9dbb49869\n""}]",0,185982,1b41bd5fc24149eb6576cc55eb96c6ee48c1b77d,2,0,1,6159,,,0,"Make sure the converted image is imported

Turns out the converted image is being completely ignored. This is
because the `file_path` provided by the ImportToFS task cannot be
overriden by other tasks. In order to fix this, I've dropped all the
extra suffixes that we've been using in favor of working on the actual
`file_path` directly.

Resolves: rhbz#1065603
Upstream-Closes-bug: #1452750
Upstream-Change-Id: Ifbd2308057f33c1f712fa06f9bb3e57f90068fdc
Upstream-Cherry-Pick: d77fd685ea4d552eb4cf6c5c4a1049ed7964ff05
Upstream-Kilo: https://review.openstack.org/#/c/181815/
Upstream-Liberty: https://review.openstack.org/#/c/181024/
(cherry picked from commit 724f17ac065652bdcf42379f55da3f903ad18f37)

Change-Id: I0a7e1260259f2c7c7b1307e4022ccee9dbb49869
",git fetch https://review.opendev.org/openstack/glance refs/changes/82/185982/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async/flows/test_import.py', 'glance/async/flows/convert.py', 'glance/async/flows/base_import.py', 'glance/tests/unit/async/flows/test_convert.py']",4,1b41bd5fc24149eb6576cc55eb96c6ee48c1b77d,bug/1453068," with mock.patch.object(os, 'rename') as rm_mock: rm_mock.return_value = None image_convert.execute(image, 'file:///test/path.raw') image_path = os.path.join(self.work_dir, image.image_id) def fake_execute(*args, **kwargs): if 'info' in args: # NOTE(flaper87): Make sure the file actually # exists. Extra check to verify previous tasks did # what they were supposed to do. assert os.path.exists(args[3].split(""file://"")[-1]) return (json.dumps({ }), None) open(""%s.converted"" % image_path, 'a').close() return ("""", None) with mock.patch.object(script_utils, 'get_image_data_iter') as dmock: dmock.return_value = StringIO.StringIO(""TEST_IMAGE"") with mock.patch.object(processutils, 'execute') as exc_mock: exc_mock.side_effect = fake_execute # NOTE(flaper87): DeleteFromFS should've deleted this # file. Make sure it doesn't exist. self.assertFalse(os.path.exists(image_path)) # NOTE(flaper87): Workdir should be empty after all # the tasks have been executed. self.assertEqual([], os.listdir(self.work_dir))"," image_convert.execute(image, '/test/path.raw') with mock.patch.object(script_utils, 'get_image_data_iter') as dmock: dmock.return_value = StringIO.StringIO(""TEST_IMAGE"") with mock.patch.object(processutils, 'execute') as exc_mock: result = json.dumps({ }) # NOTE(flaper87): First result for the conversion step and # the second one for the introspection one. The later *must* # come after the former. If not, the current builtin flow # process will be unsound. # Follow-up work will fix this by having a better way to handle # task's dependencies and activation. exc_mock.side_effect = [("""", None), (result, None)] image_path = os.path.join(self.test_dir, image.image_id) tmp_image_path = ""%s.tasks_import"" % image_path self.assertFalse(os.path.exists(tmp_image_path)) self.assertTrue(os.path.exists(image_path))",47,24
openstack%2Fglance~stable%2Fkilo~If07a7441acd1927695312b183442f0642b310a80,openstack/glance,stable/kilo,If07a7441acd1927695312b183442f0642b310a80,Save image data after setting the data,ABANDONED,2015-05-27 13:31:43.000000000,2015-05-27 13:32:06.000000000,,[],"[{'number': 1, 'created': '2015-05-27 13:31:43.000000000', 'files': ['glance/tests/unit/async/flows/test_import.py', 'glance/async/flows/base_import.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/cdbdf6469cfb8d6b270c83e3b3afd727cf05f38f', 'message': ""Save image data after setting the data\n\nThe image's locations are missing when image's are imported using tasks\nbecause the ImportToStore task is not saving the image metadata after\nthe import. This patch fixes that.\n\nResolves: rhbz#1065603\nUpstream-Closes-bug: #1453068\nUpstream-Change-Id: I43dec450d5fc4bee2131d78dbe3c2b2373c3f739\nUpstream-Cherry-Pick: 4efb56aae9288952bdb0d368a7c307e8524b80d8\nUpstream-Kilo: https://review.openstack.org/#/c/181816/\nUpstream-Liberty: https://review.openstack.org/#/c/181345/\n(cherry picked from commit 8b8384d65c4ea090dc0d04c5bb3a283debc00cde)\n\nChange-Id: If07a7441acd1927695312b183442f0642b310a80\n""}]",0,185983,cdbdf6469cfb8d6b270c83e3b3afd727cf05f38f,2,0,1,6159,,,0,"Save image data after setting the data

The image's locations are missing when image's are imported using tasks
because the ImportToStore task is not saving the image metadata after
the import. This patch fixes that.

Resolves: rhbz#1065603
Upstream-Closes-bug: #1453068
Upstream-Change-Id: I43dec450d5fc4bee2131d78dbe3c2b2373c3f739
Upstream-Cherry-Pick: 4efb56aae9288952bdb0d368a7c307e8524b80d8
Upstream-Kilo: https://review.openstack.org/#/c/181816/
Upstream-Liberty: https://review.openstack.org/#/c/181345/
(cherry picked from commit 8b8384d65c4ea090dc0d04c5bb3a283debc00cde)

Change-Id: If07a7441acd1927695312b183442f0642b310a80
",git fetch https://review.opendev.org/openstack/glance refs/changes/83/185983/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async/flows/test_import.py', 'glance/async/flows/base_import.py']",2,cdbdf6469cfb8d6b270c83e3b3afd727cf05f38f,bug/1453068, # NOTE(flaper87): We need to save the image again after the locations # have been set in the image. self.image_repo.save(image) ,,8,0
openstack%2Ftripleo-image-elements~master~Ief5255fed9505c4965cbb04de7d43266a4541acb,openstack/tripleo-image-elements,master,Ief5255fed9505c4965cbb04de7d43266a4541acb,Add roles to plan during Tuskar install,MERGED,2015-05-21 09:09:37.000000000,2015-05-27 13:31:23.000000000,2015-05-27 13:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7509}, {'_account_id': 8399}, {'_account_id': 11997}, {'_account_id': 15192}]","[{'number': 1, 'created': '2015-05-21 09:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/757978ee758ceebd9b8b6a7a5cd1092688c78070', 'message': 'Add roles to plan during Tuskar install\n\nChange-Id: Ief5255fed9505c4965cbb04de7d43266a4541acb\n'}, {'number': 2, 'created': '2015-05-21 09:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2b9bafce8cb7cd644269a539837c225ade11f5c7', 'message': 'Add roles to plan during Tuskar install\n\nChange-Id: Ief5255fed9505c4965cbb04de7d43266a4541acb\n'}, {'number': 3, 'created': '2015-05-21 10:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bf60df3a388026d06a246d93711aafca42a404db', 'message': 'Add roles to plan during Tuskar install\n\nChange-Id: Ief5255fed9505c4965cbb04de7d43266a4541acb\n'}, {'number': 4, 'created': '2015-05-21 12:56:27.000000000', 'files': ['elements/tuskar/os-refresh-config/post-configure.d/101-plan-add-roles'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c93c26a1cac60f091a88fb12b02f547eef37eae8', 'message': 'Add roles to plan during Tuskar install\n\nChange-Id: Ief5255fed9505c4965cbb04de7d43266a4541acb\n'}]",2,184743,c93c26a1cac60f091a88fb12b02f547eef37eae8,18,6,4,11997,,,0,"Add roles to plan during Tuskar install

Change-Id: Ief5255fed9505c4965cbb04de7d43266a4541acb
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/43/184743/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/tuskar/os-refresh-config/post-configure.d/100-tuskar-api', 'elements/tuskar/os-refresh-config/post-configure.d/101-plan-add-roles']",2,757978ee758ceebd9b8b6a7a5cd1092688c78070,regebro/plan-add-roles,"#!/bin/bash source /root/stackrc i=""0"" while tuskar plan-list 2>&1 | grep ""Max retries""; do i=$[$i+1] if [ ""$i"" -gt ""10"" ]; then echo ""Could not connect to tuskar-api service"" 1>&2 exit 1 fi done PLAN_ID=$(tuskar plan-show overcloud | awk '$2==""uuid"" {print $4}') if [ -z ""$PLAN_ID"" ]; then exit 1 fi for ROLE_NAME in ""Controller"" ""Compute"" ""Swift-Storage"" ""Cinder-Storage"" ""Ceph-Storage"" ; do ROLE_ID=$(tuskar role-list | awk '$4==VAR {print $2}' VAR=""$ROLE_NAME"") ROLE_EXISTS=$(tuskar plan-show $PLAN_ID | grep $ROLE_ID) if [ -z ""$ROLE_EXISTS"" ]; then tuskar plan-add-role $PLAN_ID -r $ROLE_ID fi done ",,29,0
openstack%2Foslo.messaging~master~Ic09fe619694c300c4502acb7157d7ecdd47c5fd7,openstack/oslo.messaging,master,Ic09fe619694c300c4502acb7157d7ecdd47c5fd7,Refactor processing reply in ReplyWaiter,MERGED,2015-05-06 15:36:01.000000000,2015-05-27 13:17:15.000000000,2015-05-27 13:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 7491}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-05-06 15:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2a537582b9d60b4698ca415df29c837ccab42080', 'message': ""Send a single reply to call message\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so this change\nremove the second AMQP message sending and pass 'ending' parameter to\nthe first message for backward compatibility.\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}, {'number': 2, 'created': '2015-05-07 10:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b2c43a1dd141ae2d2d19f4dd680f0367d4aa4ef8', 'message': ""Refactor processing reply in ReplyWaiter\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so we are going\nto remove this the second AMQP message sending. This patch allows\nreceiver side to proceed correctly old case - two AMQP messages (first\nwith data and second with 'ending' parameter) same as the new one (a\nsingle message with data 'ending' parameter)\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}, {'number': 3, 'created': '2015-05-22 09:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7b1eee63f1fbc8144b1a606d8e376f6535543142', 'message': ""Refactor processing reply in ReplyWaiter\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so we are going\nto remove this the second AMQP message sending. This patch allows\nreceiver side to proceed correctly old case - two AMQP messages (first\nwith data and second with 'ending' parameter) same as the new one (a\nsingle message with data 'ending' parameter)\n\nBlueprint: remove-double-reply\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}, {'number': 4, 'created': '2015-05-22 13:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c61437d5830b8a66f8b9ee543a53e8007977911e', 'message': ""Refactor processing reply in ReplyWaiter\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so we are going\nto remove this the second AMQP message sending. This patch allows\nreceiver side to proceed correctly old case - two AMQP messages (first\nwith data and second with 'ending' parameter) same as the new one (a\nsingle message with data 'ending' parameter)\n\nBlueprint: remove-double-reply\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}, {'number': 5, 'created': '2015-05-27 06:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9c48ace6055f6ac5112c44ca9528c9fce8e0359f', 'message': ""Refactor processing reply in ReplyWaiter\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so we are going\nto remove this the second AMQP message sending. This patch allows\nreceiver side to proceed correctly old case - two AMQP messages (first\nwith data and second with 'ending' parameter) same as the new one (a\nsingle message with data 'ending' parameter)\n\nBlueprint: remove-double-reply\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}, {'number': 6, 'created': '2015-05-27 08:21:12.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/75cba16d15b720e7a2ca769ef799a3c26326590d', 'message': ""Refactor processing reply in ReplyWaiter\n\nAt the moment for each msg_id we receive two amqp message - first one\nwith the payload, a second one to ensure the other have finish to send\nthe payload. This was made, because a long time ago 'reply' allowed\ngenerator as payload to send multiple messages on one 'rpc.call' - [1]\n\nIt's a bad idea - to double RPC messages for each call, so we are going\nto remove this the second AMQP message sending. This patch allows\nreceiver side to proceed correctly old case - two AMQP messages (first\nwith data and second with 'ending' parameter) same as the new one (a\nsingle message with data 'ending' parameter)\n\nBlueprint: remove-double-reply\n\n[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464\n\nChange-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7\n""}]",2,180583,75cba16d15b720e7a2ca769ef799a3c26326590d,26,7,6,7491,,,0,"Refactor processing reply in ReplyWaiter

At the moment for each msg_id we receive two amqp message - first one
with the payload, a second one to ensure the other have finish to send
the payload. This was made, because a long time ago 'reply' allowed
generator as payload to send multiple messages on one 'rpc.call' - [1]

It's a bad idea - to double RPC messages for each call, so we are going
to remove this the second AMQP message sending. This patch allows
receiver side to proceed correctly old case - two AMQP messages (first
with data and second with 'ending' parameter) same as the new one (a
single message with data 'ending' parameter)

Blueprint: remove-double-reply

[1] - https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464

Change-Id: Ic09fe619694c300c4502acb7157d7ecdd47c5fd7
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/83/180583/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/amqpdriver.py'],1,2a537582b9d60b4698ca415df29c837ccab42080,bp/remove-double-reply," # TODO(viktors): Remove `ending` parameter usage in M release msg = {'result': reply, 'failure': failure, 'ending': ending} # TODO(viktors): Remove `ending` parameter usage in M release self._send_reply(conn, reply, failure, log_failure=log_failure, ending=True) # TODO(viktors): Remove `ending` parameter usage in M release return result, data['ending'] timeout = timer.check_return(self._raise_timeout_exception, msg_id) try: message = self.waiters.get(msg_id, timeout=timeout) except moves.queue.Empty: self._raise_timeout_exception(msg_id) # TODO(viktors): Remove `ending` parameter usage in M release reply, ending = self._process_reply(message) return reply"," msg = {'result': reply, 'failure': failure} if ending: msg['ending'] = True self._send_reply(conn, reply, failure, log_failure=log_failure) self._send_reply(conn, ending=True) result = None ending = False elif data.get('ending', False): ending = True return result, ending # NOTE(sileht): for each msg_id we receive two amqp message # first one with the payload, a second one to ensure the other # have finish to send the payload final_reply = None ending = False while not ending: timeout = timer.check_return(self._raise_timeout_exception, msg_id) try: message = self.waiters.get(msg_id, timeout=timeout) except moves.queue.Empty: self._raise_timeout_exception(msg_id) reply, ending = self._process_reply(message) if not ending: final_reply = reply return final_reply",15,26
openstack%2Fswift~master~Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f,openstack/swift,master,Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f,"fixup!Patch of ""parse_content_disposition"" method to meet RFC2183",MERGED,2015-05-25 14:07:43.000000000,2015-05-27 13:15:18.000000000,2015-05-27 13:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 10068}, {'_account_id': 12193}, {'_account_id': 16233}, {'_account_id': 16517}]","[{'number': 1, 'created': '2015-05-25 14:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7ff1c0354ab133b5fd895ffd3772afff0b3e093c', 'message': 'fixup! Patch of ""parse_content_disposition"" method to meet RFC 2183\n\nThe spec of Content-Disposition does not require a space character after\ncomma: http://www.ietf.org/rfc/rfc2183.txt\n\nChange-Id: Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f\nRelated-Bug: 1458497\n'}, {'number': 2, 'created': '2015-05-26 08:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cc399c4d772869582abbc2b998891908aef57b83', 'message': 'fixup! Patch of ""parse_content_disposition"" method to meet RFC 2183\n\nThe spec of Content-Disposition does not require a space character after\ncomma: http://www.ietf.org/rfc/rfc2183.txt\n\nChange-Id: Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f\nRelated-Bug: 1458497\n'}, {'number': 3, 'created': '2015-05-26 09:24:36.000000000', 'files': ['swift/common/utils.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e7c8c578d9e5b0aa7e56b02bd9c39baa99d2d6ae', 'message': 'fixup!Patch of ""parse_content_disposition"" method to meet RFC2183\n\nThe spec of Content-Disposition does not require a space character after\ncomma: http://www.ietf.org/rfc/rfc2183.txt\n\nChange-Id: Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f\nCloses-Bug: #1458497\n'}]",2,185389,e7c8c578d9e5b0aa7e56b02bd9c39baa99d2d6ae,21,7,3,16517,,,0,"fixup!Patch of ""parse_content_disposition"" method to meet RFC2183

The spec of Content-Disposition does not require a space character after
comma: http://www.ietf.org/rfc/rfc2183.txt

Change-Id: Iff438dc36ce78c6a79bb66ab3d889a8dae7c0e1f
Closes-Bug: #1458497
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/185389/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/common/test_utils.py']",2,7ff1c0354ab133b5fd895ffd3772afff0b3e093c,bug/bug-1458497," 'form-data; name=""somefile""; filename=""test.ehtml""') self.assertEquals(name, 'form-data') self.assertEquals(attrs, {'name': 'somefile', 'filename': 'test.html'}) def test_content_disposition_without_white_space(self): name, attrs = utils.parse_content_disposition( 'form-data;name=""somefile"";filename=""test.html""')"," 'form-data; name=""somefile""; filename=""test.html""')",9,3
openstack%2Frally~master~I967dc258a0fbccf750bec48e56b20d4b67a1764f,openstack/rally,master,I967dc258a0fbccf750bec48e56b20d4b67a1764f,[Fuel] Add Fuel scenario `list_environments',MERGED,2015-04-29 15:33:12.000000000,2015-05-27 13:03:52.000000000,2015-05-27 13:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 13609}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-04-29 15:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8e1febc0c4d3bd5be28f08e20e5a0abb895dd0f4', 'message': '[Context] [WIP] Add context for fuelclient.\n\nNote:\n  This patch requires discussion.\n\nChanges:\n  New context `fuel\' registers fuelclient in osclients.\n  This is not done by extending osclient.Clients in regular way,\n  because fuelclient setup works different - it actually does not\n  need endpoint, in opposite to other clients.\n  It requires Fuel master node address, and (optionally)\n  its TCP port.\n\nTask input file example:\n  {\n      ""FooScenario.foo_benchmark"": [\n          {\n              ""runner"": {\n                  ""type"": ""constant"",\n                  ""times"": 2,\n                  ""concurrency"": 2\n              },\n              ""context"": {\n                  ""fuel"": {\n                      ""server_address"": ""10.20.0.2""\n                  }\n              }\n          }\n      ]\n  }\n\nTODO:\n\n  * unit tests\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n'}, {'number': 2, 'created': '2015-04-29 15:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bc8965b8ba58df738297a61e8244039e435fed19', 'message': '[Context] [WIP] Add context for fuelclient\n\nNote:\n  This patch requires discussion.\n\nChanges:\n  New context `fuel\' registers fuelclient in osclients.\n  This is not done by extending osclients.Clients in regular way,\n  because fuelclient setup works different - it actually does not\n  need endpoint, in opposite to other clients.\n  It requires Fuel master node address, and (optionally)\n  its TCP port.\n\nTask input file example:\n  {\n      ""FooScenario.foo_benchmark"": [\n          {\n              ""runner"": {\n                  ""type"": ""constant"",\n                  ""times"": 2,\n                  ""concurrency"": 2\n              },\n              ""context"": {\n                  ""fuel"": {\n                      ""server_address"": ""10.20.0.2""\n                  }\n              }\n          }\n      ]\n  }\n\nTODO:\n\n  * unit tests\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n'}, {'number': 3, 'created': '2015-04-30 11:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7e232935894f8c88858fba6af26c865114d6b3e9', 'message': '[Context][Fuel] (WIP) Add context for fuelclient\n\nNote:\n  This patch requires discussion.\n\nChanges:\n  New context `fuel\' registers fuelclient in osclients.\n  This is not done by extending osclients.Clients in regular way,\n  because fuelclient setup works different - it actually does not\n  need endpoint from deployment and deployment at all, in\n  opposite to other clients.\n  But it requires Fuel master access parameters (address, port,\n  username and password).\n\nTask input file example:\n  {\n      ""FooScenario.foo_benchmark"": [\n          {\n              ""runner"": {\n                  ""type"": ""constant"",\n                  ""times"": 2,\n                  ""concurrency"": 2\n              },\n              ""context"": {\n                  ""fuel"": {\n                      ""host"": ""10.20.0.2"",\n                      ""port"": ""8000"",\n                      ""username: ""admin"",\n                      ""password"": ""secret""\n                  }\n              }\n          }\n      ]\n  }\n\nTODO:\n\n  * unit tests\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n'}, {'number': 4, 'created': '2015-05-05 12:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6528d58ea95d15da038f7fb94dfe579bbe6f5bdd', 'message': ""[Fuel] (WIP) Add Fuel scenario `list_environments'\n\nChanges:\n  * module rally.benchmark.scenarios.fuel registers\n    fuelclient in osclients.\n  * scenario FuelEnvironments.list_environments is added\n\nWIP:\n  * unit tests\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 5, 'created': '2015-05-05 15:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/82fb6ef04b0efb19b3214202490b60d78ecbc62a', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * module rally.benchmark.scenarios.fuel registers\n    fuelclient in osclients.\n  * scenario FuelEnvironments.list_environments is added\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 6, 'created': '2015-05-06 10:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a4117a7549df9aa991d826932ebfac914ec51f4c', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * register fuelclient in module rally.benchmark.scenarios.fuel.utils\n  * scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 7, 'created': '2015-05-08 01:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8f9aa9f2ee164c8b484bfc53fe8f031bc1dd1a3e', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * register fuelclient in module rally.benchmark.scenarios.fuel.utils\n  * scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 8, 'created': '2015-05-08 13:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d9b6be5121f1e901abad5d6d095f25057ed6e276', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * register fuelclient in module rally.benchmark.scenarios.fuel.utils\n  * scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 9, 'created': '2015-05-08 15:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dd1af84a096023fed67c242b223c0d2b3bc8c6d6', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * rework osclients.Clients.register into decorator\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 10, 'created': '2015-05-08 15:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/48d15bc40a87f24eaee4e28b211caf69a4512982', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 11, 'created': '2015-05-12 14:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/74cb131da8862ee7e8af5fd0f7be2bf1c9c2168d', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 12, 'created': '2015-05-12 16:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/84730bf3b7409f69466cdc9f3143bae1cb590f08', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 13, 'created': '2015-05-14 10:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dc85da543b172c4481eaba38125bb690a05d6c46', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n  * changes in validation.required_clients to allow this\n    decorator to check admin clients\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 14, 'created': '2015-05-15 16:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2f41209adacc66ec58914ecda74a1fd7ef7f243d', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n  * changes in validation.required_clients to allow this\n    decorator to check admin clients\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 15, 'created': '2015-05-15 16:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/754cd5c1e74003317661043e23b2efd82f565347', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 16, 'created': '2015-05-18 09:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/868d4612827329a314e86c7b5c9cac9bdf85d1de', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 17, 'created': '2015-05-20 10:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c0a3865f788f4fb8d3a63e444d13514a943ba9c7', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 18, 'created': '2015-05-21 14:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e824908a716c8d89aba5be06ecb93c283fa2a495', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 19, 'created': '2015-05-25 15:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a44b49494d643c8388dbb751538b6ed68b1fab2', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 20, 'created': '2015-05-25 15:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d54afc64ea2f4dd8519a5d7399e1563696bb5c8c', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 21, 'created': '2015-05-26 09:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f5868744e19e5056a580ddfe3e8a4a3278e6b1a', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}, {'number': 22, 'created': '2015-05-27 09:28:21.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/fuel/test_utils.py', 'tests/unit/plugins/openstack/scenarios/fuel/__init__.py', 'rally/plugins/openstack/scenarios/fuel/environments.py', 'samples/tasks/scenarios/fuel/list-environments.yaml', 'rally/plugins/openstack/scenarios/fuel/__init__.py', 'tests/unit/plugins/openstack/scenarios/fuel/test_environments.py', 'samples/tasks/scenarios/fuel/list-environments.json', 'optional-requirements.txt', 'rally/plugins/openstack/scenarios/fuel/utils.py', 'rally-jobs/fuel.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/91f82490db0f71c2d91378c8331cee5db92c60ba', 'message': ""[Fuel] Add Fuel scenario `list_environments'\n\nThis patch adds simple scenario `list_environments' for Fuel node.\n\nChanges:\n  * register scenarios.fuel.utils.fuel for osclients\n  * add scenario FuelEnvironments.list_environments\n\nChange-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f\n""}]",66,178731,91f82490db0f71c2d91378c8331cee5db92c60ba,154,10,22,10475,,,0,"[Fuel] Add Fuel scenario `list_environments'

This patch adds simple scenario `list_environments' for Fuel node.

Changes:
  * register scenarios.fuel.utils.fuel for osclients
  * add scenario FuelEnvironments.list_environments

Change-Id: I967dc258a0fbccf750bec48e56b20d4b67a1764f
",git fetch https://review.opendev.org/openstack/rally refs/changes/31/178731/19 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/context/fuel.py'],1,8e1febc0c4d3bd5be28f08e20e5a0abb895dd0f4,list-fuel-environments,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os from rally.benchmark.context import base from rally.common.i18n import _ from rally.common import log as logging from rally.common import utils as rutils from rally import consts from rally import exceptions from rally import osclients LOG = logging.getLogger(__name__) class FuelClient(object): """"""Leightweight facade over fuelclient.get_client."""""" def __init__(self, client, version=""v1""): self.client = client self.version = version @property def environment(self): return self.client(""environment"", version=self.version) @property def node(self): return self.client(""node"", version=self.version) @property def task(self): return self.client(""task"", version=self.version) def fuel(self): """"""Fuelclient factory for osclients."""""" try: import fuelclient except ImportError: raise exceptions.RallyException( _(""Package is not installed: %s"") % ""fuelclient"") return FuelClient(fuelclient.get_client) @base.context(name=""fuel"", order=700) class FuelClientSetup(base.Context): """"""Make fuelclient available via osclients."""""" CONFIG_SCHEMA = { ""type"": ""object"", ""$schema"": consts.JSON_SCHEMA, ""properties"": { ""server_address"": { ""type"": ""string"", }, ""server_port"": { ""type"": ""string"", } }, ""required"": [""server_address""], ""additionalProperties"": False } @rutils.log_task_wrapper(LOG.info, _(""Enter context: `fuel`"")) def setup(self): """"""Add fuel client to osclients. Example for further client usage in some scenario: class FooScenario(base.Scenario): def foo_benchmark(self): all_envs = self.clients(""fuel"").environment.get_all() """""" os.environ[""SERVER_ADDRESS""] = self.config[""server_address""] os.environ[""LISTEN_PORT""] = self.config.get(""server_port"", ""8000"") osclients.register(""fuel"", fuel) @rutils.log_task_wrapper(LOG.info, _(""Exit context: `fuel`"")) def cleanup(self): """"""Nothing to cleanup."""""" ",,95,0
openstack%2Fswift~master~I4d1c047106c242bca85c94b569d98fd59bb255f4,openstack/swift,master,I4d1c047106c242bca85c94b569d98fd59bb255f4,Exclude local_dev from sync partners on failure,MERGED,2015-04-18 00:06:13.000000000,2015-05-27 12:59:23.000000000,2015-05-27 12:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 6968}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 14619}, {'_account_id': 14966}, {'_account_id': 14967}, {'_account_id': 15090}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-04-18 00:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b8b4d3499bb83d8c0cd296728141ba555dc0fe9f', 'message': ""Use the right nodes and frag_index on failures\n\nOn a revert:\n\nIf the primary node for a fragment index is unavailable, the next best place\nfor it is on one of the current handoff nodes in the ring (so the proxy can\nfind it!).  However, when we ssync to handoff node we need to make sure the\nFrag-Index header is correct for the fragments we want to send in the job.\n\nWhile generally the node's index is correct (espeically for sync jobs where\nthe job's frag_index is acctually different from the partners node index which\nwe acctually want to sync with) - on a handoff node there is no node index, so\nwe need to fill it in with the frag_index.  This fixes a KeyError when trying\nto ssync to a handoff node.\n\nOn a sync:\n\nIf the primary left or right hand partners are down, the next best thing is to\nvalidate the rest of the primary nodes.  Where the rest should exclude not\njust the left and right hand partners - but ourself as well.\n\nThis fixes a accidental noop when partner node is unavailable and another node\nis missing data.\n\nValidation:\n\nAdd two more probetests to cover ssync failures for the primary sync_to nodes\non both revert and sync jobs.\n\nDrive-by:\n\nMake additional plumbing for the check_mount and check_dir constraints into\nthe remaining daemons.\n\nChange-Id: I4d1c047106c242bca85c94b569d98fd59bb255f4\n""}, {'number': 2, 'created': '2015-04-20 20:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2325d4536b7e45dae77204220869855931d65d02', 'message': 'Exclude local_dev from sync partners on failure\n\nIf the primary left or right hand partners are down, the next best thing\nis to validate the rest of the primary nodes.  Where the rest should\nexclude not just the left and right hand partners - but ourself as well.\n\nThis fixes a accidental noop when partner node is unavailable and\nanother node is missing data.\n\nValidation:\n\nAdd probetests to cover ssync failures for the primary sync_to nodes for\nsync jobs.\n\nDrive-by:\n\nMake additional plumbing for the check_mount and check_dir constraints into\nthe remaining daemons.\n\nChange-Id: I4d1c047106c242bca85c94b569d98fd59bb255f4\n'}, {'number': 3, 'created': '2015-04-22 17:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4983b0621cd1b7396204a882bb2cf5791265d254', 'message': 'Exclude local_dev from sync partners on failure\n\nIf the primary left or right hand partners are down, the next best thing\nis to validate the rest of the primary nodes.  Where the rest should\nexclude not just the left and right hand partners - but ourself as well.\n\nThis fixes a accidental noop when partner node is unavailable and\nanother node is missing data.\n\nValidation:\n\nAdd probetests to cover ssync failures for the primary sync_to nodes for\nsync jobs.\n\nDrive-by:\n\nMake additional plumbing for the check_mount and check_dir constraints into\nthe remaining daemons.\n\nChange-Id: I4d1c047106c242bca85c94b569d98fd59bb255f4\n'}, {'number': 4, 'created': '2015-05-26 19:52:38.000000000', 'files': ['test/probe/common.py', 'test/probe/test_reconstructor_rebuild.py', 'test/probe/test_reconstructor_revert.py', 'swift/obj/reconstructor.py', 'test/unit/obj/test_reconstructor.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a3559edc2342e2cf92a5188336ab263ffd038554', 'message': 'Exclude local_dev from sync partners on failure\n\nIf the primary left or right hand partners are down, the next best thing\nis to validate the rest of the primary nodes.  Where the rest should\nexclude not just the left and right hand partners - but ourself as well.\n\nThis fixes a accidental noop when partner node is unavailable and\nanother node is missing data.\n\nValidation:\n\nAdd probetests to cover ssync failures for the primary sync_to nodes for\nsync jobs.\n\nDrive-by:\n\nMake additional plumbing for the check_mount and check_dir constraints into\nthe remaining daemons.\n\nChange-Id: I4d1c047106c242bca85c94b569d98fd59bb255f4\n'}]",17,175076,a3559edc2342e2cf92a5188336ab263ffd038554,39,12,4,1179,,,0,"Exclude local_dev from sync partners on failure

If the primary left or right hand partners are down, the next best thing
is to validate the rest of the primary nodes.  Where the rest should
exclude not just the left and right hand partners - but ourself as well.

This fixes a accidental noop when partner node is unavailable and
another node is missing data.

Validation:

Add probetests to cover ssync failures for the primary sync_to nodes for
sync jobs.

Drive-by:

Make additional plumbing for the check_mount and check_dir constraints into
the remaining daemons.

Change-Id: I4d1c047106c242bca85c94b569d98fd59bb255f4
",git fetch https://review.opendev.org/openstack/swift refs/changes/76/175076/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/common.py', 'test/probe/test_reconstructor_rebuild.py', 'test/probe/test_reconstructor_revert.py', 'swift/obj/reconstructor.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_reconstructor.py', 'test/unit/obj/test_ssync_receiver.py']",7,b8b4d3499bb83d8c0cd296728141ba555dc0fe9f,(detached," utils.mkdirs(os.path.join(self.testdir, 'device', 'partition')) mock.patch('swift.obj.diskfile.check_mount', return_value=False)) as ( mock.patch('swift.obj.diskfile.check_mount', return_value=False)) as (","from swift.common import constraints mock.patch.object( constraints, 'check_mount', return_value=False)) as ( mock.patch.object( constraints, 'check_mount', return_value=False)) as (",246,51
openstack%2Fneutron~stable%2Ficehouse~Ieff0236670c1403b5d79ad8e50d7574c1b694e34,openstack/neutron,stable/icehouse,Ieff0236670c1403b5d79ad8e50d7574c1b694e34,Pass '--dhcp-authoritative' option to dnsmasq,MERGED,2015-02-09 14:13:23.000000000,2015-05-27 12:59:17.000000000,2015-03-08 08:54:20.000000000,"[{'_account_id': 3}, {'_account_id': 161}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11061}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14967}]","[{'number': 1, 'created': '2015-02-09 14:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c10bf69cb83366bd55ec1fd455cdccd367007f93', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1345947\nCo-Authored-By: Kevin Bringard <kevinbri@cisco.com>\n(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)\n'}, {'number': 2, 'created': '2015-03-06 19:43:01.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3a88a578f3e484b5dc2a227a46e8546e581f8a3', 'message': 'Pass \'--dhcp-authoritative\' option to dnsmasq\n\nWhen dnsmasq is restarted, it forgets about all leases (since it runs\nwith leasefile-ro option). When client tries to renew its lease, dnsmasq\nsends DHCPNAK reply with message ""lease not found"". Then client shuts\ndown the network and re-request lease from DHCP server (and gets exactly\nsame IP address). There\'s a small network downtime which affects\nservices, like zookeeper, running in VMs.\n\nChange-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34\nCloses-Bug: #1345947\n(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)\n'}]",1,154052,c3a88a578f3e484b5dc2a227a46e8546e581f8a3,43,26,2,161,,,0,"Pass '--dhcp-authoritative' option to dnsmasq

When dnsmasq is restarted, it forgets about all leases (since it runs
with leasefile-ro option). When client tries to renew its lease, dnsmasq
sends DHCPNAK reply with message ""lease not found"". Then client shuts
down the network and re-request lease from DHCP server (and gets exactly
same IP address). There's a small network downtime which affects
services, like zookeeper, running in VMs.

Change-Id: Ieff0236670c1403b5d79ad8e50d7574c1b694e34
Closes-Bug: #1345947
(cherry picked from commit 74a16fde1c9972dc3c5d07215ca9d5e8f2e23d70)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/154052/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,c10bf69cb83366bd55ec1fd455cdccd367007f93,bug/1345947," '--leasefile-ro', '--dhcp-authoritative']", '--leasefile-ro'],3,1
openstack%2Fmagnum~master~Ie8a6deca7e7c238b8076a8bbbe9598a025222aa1,openstack/magnum,master,Ie8a6deca7e7c238b8076a8bbbe9598a025222aa1,Only define RequestContextSerializer once,MERGED,2015-05-27 04:44:18.000000000,2015-05-27 12:58:52.000000000,2015-05-27 12:58:50.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 10206}, {'_account_id': 11650}, {'_account_id': 12927}]","[{'number': 1, 'created': '2015-05-27 04:44:18.000000000', 'files': ['magnum/common/rpc.py', 'magnum/common/rpc_service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/58a13e38a41e026840255ddcb5c382003832f3c5', 'message': 'Only define RequestContextSerializer once\n\nrpc_service.py is already importing rpc.py so it should reuse\nRequestContextSerializer rather than redefining it.\n\nChange-Id: Ie8a6deca7e7c238b8076a8bbbe9598a025222aa1\nCloses-Bug: #1459090\n'}]",0,185837,58a13e38a41e026840255ddcb5c382003832f3c5,9,5,1,6638,,,0,"Only define RequestContextSerializer once

rpc_service.py is already importing rpc.py so it should reuse
RequestContextSerializer rather than redefining it.

Change-Id: Ie8a6deca7e7c238b8076a8bbbe9598a025222aa1
Closes-Bug: #1459090
",git fetch https://review.opendev.org/openstack/magnum refs/changes/37/185837/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/common/rpc.py', 'magnum/common/rpc_service.py']",2,58a13e38a41e026840255ddcb5c382003832f3c5,bug/1459090, serializer = rpc.RequestContextSerializer( serializer = rpc.RequestContextSerializer(,"from magnum.common import context as magnum_contextclass RequestContextSerializer(messaging.Serializer): def __init__(self, base): self._base = base def serialize_entity(self, context, entity): if not self._base: return entity return self._base.serialize_entity(context, entity) def deserialize_entity(self, context, entity): if not self._base: return entity return self._base.deserialize_entity(context, entity) def serialize_context(self, context): return context.to_dict() def deserialize_context(self, context): return magnum_context.RequestContext.from_dict(context) serializer = RequestContextSerializer( serializer = RequestContextSerializer(",3,26
openstack%2Fmagnum~master~I9975ad54588aa0363547ede3778b0d84dd263811,openstack/magnum,master,I9975ad54588aa0363547ede3778b0d84dd263811,"Backport ""added some output descriptions""",MERGED,2015-05-24 18:19:34.000000000,2015-05-27 12:56:10.000000000,2015-05-27 12:56:08.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 10206}, {'_account_id': 11189}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-05-24 18:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f16ebb898dac46cba17df1690290bc7d5dcfb9ac', 'message': 'Backport ""added some output descriptions""\n\nheat-coe-templates: I6701f2cd4c3f4c82e423f6ffae03c04673106705\n\nChange-Id: I9975ad54588aa0363547ede3778b0d84dd263811\n'}, {'number': 2, 'created': '2015-05-26 10:25:28.000000000', 'files': ['magnum/templates/heat-kubernetes/kubecluster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7d4015a57f981e00144433ad30471d3b23649fb7', 'message': 'Backport ""added some output descriptions""\n\nheat-coe-templates: I6701f2cd4c3f4c82e423f6ffae03c04673106705\n\nChange-Id: I9975ad54588aa0363547ede3778b0d84dd263811\n'}]",8,185274,7d4015a57f981e00144433ad30471d3b23649fb7,15,7,2,11650,,,0,"Backport ""added some output descriptions""

heat-coe-templates: I6701f2cd4c3f4c82e423f6ffae03c04673106705

Change-Id: I9975ad54588aa0363547ede3778b0d84dd263811
",git fetch https://review.opendev.org/openstack/magnum refs/changes/74/185274/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/templates/heat-kubernetes/kubecluster.yaml'],1,f16ebb898dac46cba17df1690290bc7d5dcfb9ac,backports," description: > This is the ""public"" ip address of the Kubernetes master server. Use this address to log in to the Kubernetes master via ssh or to access the Kubernetes API from outside the cluster. description: > This is a list of of the ""private"" addresses of all the Kubernetes minions. description: > This is a list of of the ""public"" addresses of all the Kubernetes minions. Use these addresses to, e.g., log into the minions.",,9,1
openstack%2Frally~master~If0f0a091af3b3451b81123434cafea57318b589f,openstack/rally,master,If0f0a091af3b3451b81123434cafea57318b589f,Rename sla.base module to sla,MERGED,2015-05-22 23:03:40.000000000,2015-05-27 12:53:24.000000000,2015-05-27 12:53:23.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-22 23:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e1a1fbc6351341e0d5957c3c6a4ab39add5c6940', 'message': 'Rename sla.base module to sla\n\nSince rally/benchmark/sla dir contains only one module, we can easaly remove\nit and move rally.benchmark.sla.base to rally.benchmark.sla\n\nChange-Id: If0f0a091af3b3451b81123434cafea57318b589f\n'}, {'number': 2, 'created': '2015-05-27 02:08:46.000000000', 'files': ['doc/source/plugins.rst', 'rally/benchmark/sla/__init__.py', 'rally/plugins/common/sla/failure_rate.py', 'rally/benchmark/sla.py', 'rally/plugins/common/sla/iteraion_time.py', 'tests/unit/test_docstrings.py', 'rally/benchmark/engine.py', 'tests/unit/cli/commands/test_info.py', 'samples/plugins/sla/sla_plugin.py', 'rally/cli/commands/info.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/benchmark/test_sla.py', 'rally/plugins/common/sla/max_average_duration.py', 'tests/unit/plugins/common/sla/test_failure_rate.py', 'rally/plugins/common/sla/outliers.py', 'tests/unit/benchmark/sla/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b4508d49b66957e3fcedf0ea0cc8d1d963747585', 'message': 'Rename sla.base module to sla\n\nSince rally/benchmark/sla dir contains only one module, we can easaly remove\nit and move rally.benchmark.sla.base to rally.benchmark.sla\n\nChange-Id: If0f0a091af3b3451b81123434cafea57318b589f\n'}]",0,185185,b4508d49b66957e3fcedf0ea0cc8d1d963747585,21,8,2,9545,,,0,"Rename sla.base module to sla

Since rally/benchmark/sla dir contains only one module, we can easaly remove
it and move rally.benchmark.sla.base to rally.benchmark.sla

Change-Id: If0f0a091af3b3451b81123434cafea57318b589f
",git fetch https://review.opendev.org/openstack/rally refs/changes/85/185185/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/plugins.rst', 'rally/benchmark/sla/__init__.py', 'rally/plugins/common/sla/failure_rate.py', 'rally/benchmark/sla.py', 'rally/plugins/common/sla/iteraion_time.py', 'tests/unit/test_docstrings.py', 'rally/benchmark/engine.py', 'tests/unit/cli/commands/test_info.py', 'samples/plugins/sla/sla_plugin.py', 'rally/cli/commands/info.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/benchmark/test_sla.py', 'rally/plugins/common/sla/max_average_duration.py', 'tests/unit/plugins/common/sla/test_failure_rate.py', 'rally/plugins/common/sla/outliers.py', 'tests/unit/benchmark/sla/__init__.py']",16,e1a1fbc6351341e0d5957c3c6a4ab39add5c6940,cover,,,45,46
openstack%2Frally~master~Ica22a3cd1a26d27c01f314a48a7cd49a529552eb,openstack/rally,master,Ica22a3cd1a26d27c01f314a48a7cd49a529552eb,Improvement of cover script,MERGED,2015-05-27 02:06:49.000000000,2015-05-27 12:53:22.000000000,2015-05-27 12:53:19.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-27 02:06:49.000000000', 'files': ['tests/ci/cover.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/35f179c9bc9dc4c3def3f40da9509992b9dd5007', 'message': 'Improvement of cover script\n\n*.pyc files break cover-script for situations like:\n     some/module.py -> some.py\n\nSo we should remove all *.pyc files before launching `testr --coverage`\n\nChange-Id: Ica22a3cd1a26d27c01f314a48a7cd49a529552eb\n'}]",0,185819,35f179c9bc9dc4c3def3f40da9509992b9dd5007,8,4,1,9545,,,0,"Improvement of cover script

*.pyc files break cover-script for situations like:
     some/module.py -> some.py

So we should remove all *.pyc files before launching `testr --coverage`

Change-Id: Ica22a3cd1a26d27c01f314a48a7cd49a529552eb
",git fetch https://review.opendev.org/openstack/rally refs/changes/19/185819/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/ci/cover.sh'],1,35f179c9bc9dc4c3def3f40da9509992b9dd5007,cover,"find . -type f -name ""*.pyc"" -delete && python setup.py testr --coverage --testr-args=""$*""find . -type f -name ""*.pyc"" -delete && python setup.py testr --coverage --testr-args=""$*""","python setup.py testr --coverage --testr-args=""$*""python setup.py testr --coverage --testr-args=""$*""",2,2
openstack%2Ffuel-docs~master~I0ab6ad2d009d8f244ee9782ab47cb19a06563dc9,openstack/fuel-docs,master,I0ab6ad2d009d8f244ee9782ab47cb19a06563dc9,Remove dhcrelay use,MERGED,2015-05-12 12:37:03.000000000,2015-05-27 12:53:06.000000000,2015-05-27 12:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-05-12 12:37:03.000000000', 'files': ['pages/operations/docker-on-master.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/980320d51079cbe921bb56caddad10e7b05d47b1', 'message': 'Remove dhcrelay use\n\nRemove dhcrelay starting\nin Fuel 6.1\n\nChange-Id: I0ab6ad2d009d8f244ee9782ab47cb19a06563dc9\n'}]",0,182264,980320d51079cbe921bb56caddad10e7b05d47b1,9,4,1,14342,,,0,"Remove dhcrelay use

Remove dhcrelay starting
in Fuel 6.1

Change-Id: I0ab6ad2d009d8f244ee9782ab47cb19a06563dc9
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/64/182264/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/docker-on-master.rst'],1,980320d51079cbe921bb56caddad10e7b05d47b1,docker6.1,"* Starting with Fuel 6.1, Docker containers with host networking are used. This means that dhcrelay is not used anymore because cobbler/dnsmasq are bound to the host system.",* Cobbler operates inside LXC with the help of dhcrelay running on the host.,3,1
openstack%2Ffuel-web~master~I4908968f247337ed01711f6c69dda82918e34f68,openstack/fuel-web,master,I4908968f247337ed01711f6c69dda82918e34f68,Support 'select' attribute type in attributes schema validator,MERGED,2015-05-27 10:54:11.000000000,2015-05-27 12:40:38.000000000,2015-05-27 12:28:55.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-05-27 10:54:11.000000000', 'files': ['nailgun/nailgun/test/unit/test_attributes_validator.py', 'nailgun/nailgun/api/v1/validators/json_schema/cluster.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2eb15f92402c300e24ee40552995ed2168e05b9a', 'message': ""Support 'select' attribute type in attributes schema validator\n\nChange-Id: I4908968f247337ed01711f6c69dda82918e34f68\nCloses-Bug: #1458940\n""}]",0,185929,2eb15f92402c300e24ee40552995ed2168e05b9a,13,7,1,8735,,,0,"Support 'select' attribute type in attributes schema validator

Change-Id: I4908968f247337ed01711f6c69dda82918e34f68
Closes-Bug: #1458940
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/29/185929/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_attributes_validator.py', 'nailgun/nailgun/api/v1/validators/json_schema/cluster.py']",2,2eb15f92402c300e24ee40552995ed2168e05b9a,bug/1458940," 'select',# Schema with allowed values for 'radio' and 'select' attribute types allowed_values_schema = { 'value': { 'type': 'string', }, 'values': { 'type': 'array', 'minItems': 1, 'items': [ { 'type': 'object', 'properties': { 'data': {'type': 'string'}, 'label': {'type': 'string'}, 'description': {'type': 'string'}, 'restrictions': role.RESTRICTIONS, }, 'required': ['data', 'label'], }, ], }, } 'radio': allowed_values_schema, 'select': allowed_values_schema,","# (note that for example 'radio' can have 'value' and 'values' # properties) 'radio': { 'value': { 'type': 'string', }, 'values': { 'type': 'array', 'minItems': 1, 'items': [ { 'type': 'object', 'properties': { 'data': {'type': 'string'}, 'label': {'type': 'string'}, 'description': {'type': 'string'}, 'restrictions': role.RESTRICTIONS, }, 'required': ['data', 'label'], }, ], }, },",47,23
openstack%2Ffuel-main~master~I32a71181b16bb3897b9743efdb083057daf7bb96,openstack/fuel-main,master,I32a71181b16bb3897b9743efdb083057daf7bb96,Add mellanox package to target centos image,ABANDONED,2015-02-24 13:13:57.000000000,2015-05-27 12:39:20.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 12177}]","[{'number': 1, 'created': '2015-02-24 13:13:57.000000000', 'files': ['image/centos/centos.ks'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/188a85a3aa1a162de6578f8ea7b7baee69606d89', 'message': 'Add mellanox package to target centos image\n\nAdd mlnx-ofed-light to the list of packages installed during target\ncentos image building.\n\nChange-Id: I32a71181b16bb3897b9743efdb083057daf7bb96\nRelated-Bug: #1405661\n'}]",0,158685,188a85a3aa1a162de6578f8ea7b7baee69606d89,7,5,1,8003,,,0,"Add mellanox package to target centos image

Add mlnx-ofed-light to the list of packages installed during target
centos image building.

Change-Id: I32a71181b16bb3897b9743efdb083057daf7bb96
Related-Bug: #1405661
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/85/158685/1 && git format-patch -1 --stdout FETCH_HEAD,['image/centos/centos.ks'],1,188a85a3aa1a162de6578f8ea7b7baee69606d89,bug/1405661,mlnx-ofed-light,,1,0
openstack%2Fglance~master~Ie3426cee8cd3f6f1222529160d39b281af5ce317,openstack/glance,master,Ie3426cee8cd3f6f1222529160d39b281af5ce317,Register oslo.log's config options in tests,MERGED,2015-03-19 12:56:21.000000000,2015-05-27 12:36:25.000000000,2015-05-27 12:36:23.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 7575}, {'_account_id': 9303}, {'_account_id': 11356}, {'_account_id': 11428}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-03-19 12:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/473594b3c3a72827a20a07171e09985e5f9d4fda', 'message': ""Register oslo.log's config options in tests\n\nWhen running tests with testr oslo.log's config options are always\nregistered even if you're only running one test. When you wish to debug\ninto your tests and use python -m testtools.run these options will not\nbe registered.\n\nChange-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317\n""}, {'number': 2, 'created': '2015-03-19 15:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b5bfddd223675b326b324d20878ea2348f17c21e', 'message': ""Register oslo.log's config options in tests\n\nWhen running tests with testr oslo.log's config options are always\nregistered even if you're only running one test. When you wish to debug\ninto your tests and use python -m testtools.run these options will not\nbe registered.\n\nCloses-bug: 1433785\nChange-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317\n""}, {'number': 3, 'created': '2015-03-19 22:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/85d6fcdeb00a2aa8fc8da1e070032309d84c46d8', 'message': ""Register oslo.log's config options in tests\n\nWhen running tests with testr oslo.log's config options are always\nregistered even if you're only running one test. When you wish to debug\ninto your tests and use python -m testtools.run these options will not\nbe registered.\n\nCloses-bug: 1433785\nChange-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317\n""}, {'number': 4, 'created': '2015-03-27 15:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a15cc1bc1640488980461887bd4b05531d5b04ce', 'message': ""Register oslo.log's config options in tests\n\nWhen running tests with testr oslo.log's config options are always\nregistered even if you're only running one test. When you wish to debug\ninto your tests and use python -m testtools.run these options will not\nbe registered.\n\nCloses-bug: 1433785\nChange-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317\n""}, {'number': 5, 'created': '2015-05-01 21:29:57.000000000', 'files': ['glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/7c419a60b197e1dde9548bbd78b2754323e45eac', 'message': ""Register oslo.log's config options in tests\n\nWhen running tests with testr oslo.log's config options are always\nregistered even if you're only running one test. When you wish to debug\ninto your tests and use python -m testtools.run these options will not\nbe registered.\n\nCloses-bug: 1433785\nChange-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317\n""}]",14,165812,7c419a60b197e1dde9548bbd78b2754323e45eac,40,9,5,12000,,,0,"Register oslo.log's config options in tests

When running tests with testr oslo.log's config options are always
registered even if you're only running one test. When you wish to debug
into your tests and use python -m testtools.run these options will not
be registered.

Closes-bug: 1433785
Change-Id: Ie3426cee8cd3f6f1222529160d39b281af5ce317
",git fetch https://review.opendev.org/openstack/glance refs/changes/12/165812/5 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/utils.py'],1,473594b3c3a72827a20a07171e09985e5f9d4fda,bug/1433785,"from oslo_log import logtry: debug = CONF.debug except cfg.NoSuchOptError: # When running a test in isolation, this is necessary when using a test # case class that inherits from BaseTestCase and uses the config method to # set the debug level. # See bug 1433785 for more details. log.register_opts(CONF) else: del debug",,11,0
openstack%2Fcinder~master~I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4,openstack/cinder,master,I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4,Fix missing translations for log messages,MERGED,2015-03-16 13:37:36.000000000,2015-05-27 12:35:24.000000000,2015-05-13 10:59:17.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 7350}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10263}, {'_account_id': 10485}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13900}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14271}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14863}, {'_account_id': 14969}, {'_account_id': 15165}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15556}, {'_account_id': 15764}, {'_account_id': 15882}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-03-16 13:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/54b5141436554f8e9c6fd934d30421b9617e7695', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages according to the standards.\n\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 2, 'created': '2015-03-18 12:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c745706293af810ae1fd26b9874d1743cf38c9e', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nmarker function standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html#choosing-a-marker-function\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 3, 'created': '2015-03-18 17:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/494191fb4798d0456c82d03a6f3abc2437f65433', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nmarker function standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html#choosing-a-marker-function\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 4, 'created': '2015-03-19 07:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f834905211c03c3d34f6316157ea04bbaba5a74', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nmarker function standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html#choosing-a-marker-function\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 5, 'created': '2015-03-22 20:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/60b35331a3f4f215fe0fc0dd7d9ccf9517ee7ce1', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nlogging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 6, 'created': '2015-03-23 10:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d09a27c1a07b4988ad03258e583ae06f7a096ef', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nlogging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 7, 'created': '2015-03-24 03:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a6ba0d25dcc816e2c8378b268d4c40cda152202b', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nlogging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 8, 'created': '2015-03-24 09:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2337fd8224e324e23f53855470639dd379bdf1a', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nlogging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 9, 'created': '2015-03-30 06:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b46eedc8a120fd9b91814cd49dbdc892d931971b', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers module for error, info and\nwarning messages with appropriate marker function according to the\nlogging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 10, 'created': '2015-04-02 15:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a36d05c275a76e55e2ac6594d30e655a498fcee3', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers and volume.manager modules\nfor error, info and warning messages with appropriate marker function\naccording to the logging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 11, 'created': '2015-04-08 09:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b71cf377d93da1be740d568cc9e7e359e5a3e19', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers and volume.manager modules\nfor error, info and warning messages with appropriate marker function\naccording to the logging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nNote: Any new occurrences added in master during the review can be\nhandled separately if they are not caught by hacking checks.\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 12, 'created': '2015-04-08 13:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d7e5cd4b089573ba280361487f6cfff9c71748d', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers and volume.manager modules\nfor error, info and warning messages with appropriate marker function\naccording to the logging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nNote: Any new occurrences added in master during the review can be\nhandled separately if they are not caught by hacking checks.\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 13, 'created': '2015-04-12 09:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4f6ef8ff8469781ba1599dfecc881eba0ba3d02', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers and volume.manager modules\nfor error, info and warning messages with appropriate marker function\naccording to the logging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nNote: Any new occurrences added in master during the review can be\nhandled separately if they are not caught by hacking checks.\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}, {'number': 14, 'created': '2015-05-11 21:37:26.000000000', 'files': ['cinder/volume/manager.py', 'cinder/volume/drivers/vmware/datastore.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/nimble.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'cinder/volume/drivers/hitachi/hbsd_horcm.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/tests/unit/test_quobyte.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/unit/test_nfs.py', 'cinder/volume/drivers/netapp/dataontap/block_cmode.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/volume/drivers/hitachi/hbsd_basiclib.py', 'cinder/volume/drivers/netapp/dataontap/client/api.py', 'cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/netapp/dataontap/client/client_base.py', 'cinder/volume/drivers/netapp/dataontap/nfs_7mode.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/pure.py', 'cinder/volume/drivers/solidfire.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/volume/drivers/netapp/dataontap/block_7mode.py', 'cinder/volume/drivers/openvstorage.py', 'cinder/volume/drivers/zfssa/restclient.py', 'cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/tests/unit/test_glusterfs.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/ibm/storwize_svc/replication.py', 'cinder/volume/drivers/xio.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/volume/drivers/emc/emc_cli_fc.py', 'cinder/volume/drivers/violin/v6000_common.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/volume/drivers/windows/remotefs.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/volume/drivers/block_device.py', 'cinder/volume/drivers/ibm/flashsystem.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/san/san.py', 'cinder/volume/drivers/srb.py', 'cinder/volume/drivers/prophetstor/dpl_fc.py', 'cinder/volume/drivers/zfssa/webdavclient.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/volume/drivers/hds/hus_backend.py', 'cinder/volume/drivers/netapp/dataontap/client/client_7mode.py', 'cinder/volume/drivers/hitachi/hbsd_common.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/volume/drivers/hitachi/hbsd_snm2.py', 'cinder/volume/drivers/lvm.py', 'cinder/volume/drivers/windows/smbfs.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/datera.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/eqlx.py', 'cinder/hacking/checks.py', 'cinder/volume/drivers/violin/v6000_iscsi.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/zfssa/zfssarest.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/emc/emc_vmax_fc.py', 'cinder/volume/drivers/hitachi/hbsd_iscsi.py', 'cinder/tests/unit/test_netapp_nfs.py', 'cinder/volume/drivers/violin/v6000_fcp.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/volume/drivers/netapp/dataontap/ssc_cmode.py', 'cinder/volume/drivers/netapp/eseries/host_mapper.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/volume/drivers/huawei/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a09c4e1747ba4027c90debdbbe698406c3096188', 'message': 'Fix missing translations for log messages\n\nFixed log translations in volume.drivers and volume.manager modules\nfor error, info and warning messages with appropriate marker function\naccording to the logging standards [1].\n\nAs LOG.warn has deprecated [2] so I have changed LOG.warn to\nLOG.warning.\n\n[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html\n[2] http://bugs.python.org/issue13235\n\nNote: Any new occurrences added in master during the review can be\nhandled separately if they are not caught by hacking checks.\n\nPartial-Bug: 1431256\nChange-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4\n'}]",265,164697,a09c4e1747ba4027c90debdbbe698406c3096188,426,55,14,10485,,,0,"Fix missing translations for log messages

Fixed log translations in volume.drivers and volume.manager modules
for error, info and warning messages with appropriate marker function
according to the logging standards [1].

As LOG.warn has deprecated [2] so I have changed LOG.warn to
LOG.warning.

[1] http://docs.openstack.org/developer/oslo.i18n/guidelines.html
[2] http://bugs.python.org/issue13235

Note: Any new occurrences added in master during the review can be
handled separately if they are not caught by hacking checks.

Partial-Bug: 1431256
Change-Id: I9b7b89097b296ea62b43f1d948dcf59e2e5a40c4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/164697/7 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/volume/drivers/windows/smbfs.py', 'cinder/volume/drivers/block_device.py', 'cinder/volume/drivers/datera.py', 'cinder/volume/drivers/fujitsu/eternus_dx_common.py', 'cinder/volume/drivers/zfssa/zfssarest.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/zfssa/webdavclient.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/ibm/storwize_svc/replication.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/volume/drivers/zfssa/zfssaiscsi.py', 'cinder/volume/drivers/zadara.py']",18,54b5141436554f8e9c6fd934d30421b9617e7695,bug/1431256,"from cinder.i18n import _LE, _LW msg = _LW('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name} msg = _LE('Volume %(name)s not found') % {'name': volume_name} msg = _LE('Volume %(name)s not found') % {'name': volume_name} msg = _LE('Snapshot %(name)s not found') % { 'name': snapshot['name']} msg = _LE('Volume %(name)s not found') % {'name': volume_name} msg = _LE('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name}","from cinder.i18n import _, _LW msg = _('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name} msg = _('Volume %(name)s not found') % {'name': volume_name} msg = _('Volume %(name)s not found') % {'name': volume_name} msg = _('Snapshot %(name)s not found') % {'name': snapshot['name']} msg = _('Volume %(name)s not found') % {'name': volume_name} msg = _('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name}",109,105
openstack%2Fheat~master~I48cad912b35d845b858852dd26364f645a53d40f,openstack/heat,master,I48cad912b35d845b858852dd26364f645a53d40f,Add a periodic task to clean up engine threads,ABANDONED,2015-05-08 21:14:44.000000000,2015-05-27 12:32:27.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 9751}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-05-08 21:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e44e8fce423b623b98f49c10023c4eb0c47a6c20', 'message': 'Add a periodic task to clean up engine threads\n\nPreviously, finished stacks continued to have threads allocated.\n\nChange-Id: I48cad912b35d845b858852dd26364f645a53d40f\n'}, {'number': 2, 'created': '2015-05-12 12:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5725bf4673dcadea4d235becc8b1e1c9e20ca78e', 'message': 'Add a periodic task to clean up engine threads\n\nPreviously, finished stacks continued to have threads allocated.\n\nChange-Id: I48cad912b35d845b858852dd26364f645a53d40f\n'}, {'number': 3, 'created': '2015-05-12 13:02:08.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d34552f7bba2d9faaf39ba5fea8e2b5e34d2e995', 'message': 'Add a periodic task to clean up engine threads\n\nPreviously, finished stacks continued to have threads allocated.\n\nChange-Id: I48cad912b35d845b858852dd26364f645a53d40f\n'}]",5,181559,d34552f7bba2d9faaf39ba5fea8e2b5e34d2e995,13,5,3,12321,,,0,"Add a periodic task to clean up engine threads

Previously, finished stacks continued to have threads allocated.

Change-Id: I48cad912b35d845b858852dd26364f645a53d40f
",git fetch https://review.opendev.org/openstack/heat refs/changes/59/181559/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,e44e8fce423b623b98f49c10023c4eb0c47a6c20,threadManage," for stack in self.groups.keys(): if stack == cfg.CONF.periodic_interval: continue self.stop(stack, graceful=True) LOG.debug(""XXX Cleaned up stray threads"") if stack_id not in self.groups: return self.events.pop(stack_id, None) threadgroup = self.groups.pop(stack_id) threads = threadgroup.threads[:] threadgroup.stop(graceful) threadgroup.wait() # Wait for link()ed functions (i.e. lock release) links_done = dict((th, False) for th in threads) def mark_done(gt, th): links_done[th] = True"," pass if stack_id in self.groups: self.events.pop(stack_id, None) threadgroup = self.groups.pop(stack_id) threads = threadgroup.threads[:] threadgroup.stop(graceful) threadgroup.wait() # Wait for link()ed functions (i.e. lock release) links_done = dict((th, False) for th in threads) def mark_done(gt, th): links_done[th] = True",17,11
openstack%2Foslo-incubator~stable%2Ficehouse~I5abec64f44b59c8040aea8f066101db9c9bcb56b,openstack/oslo-incubator,stable/icehouse,I5abec64f44b59c8040aea8f066101db9c9bcb56b,Updated from global requirements,ABANDONED,2015-04-22 12:38:49.000000000,2015-05-27 12:26:56.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-04-22 12:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/505811c66403485fd8c4684d485be053490970d1', 'message': 'Updated from global requirements\n\nChange-Id: I5abec64f44b59c8040aea8f066101db9c9bcb56b\n'}, {'number': 2, 'created': '2015-05-07 15:16:16.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d7616302758d3987c6aa6fc06fd01c2ab93bf2ab', 'message': 'Updated from global requirements\n\nChange-Id: I5abec64f44b59c8040aea8f066101db9c9bcb56b\n'}]",0,176274,d7616302758d3987c6aa6fc06fd01c2ab93bf2ab,5,1,2,11131,,,0,"Updated from global requirements

Change-Id: I5abec64f44b59c8040aea8f066101db9c9bcb56b
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/74/176274/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,505811c66403485fd8c4684d485be053490970d1,openstack/requirements,stevedore>=0.14,"stevedore>=0.14,<1.2",2,2
openstack%2Fpython-mistralclient~master~I06a63c5735b85750dd0d828ebcdff0ebfa6bcf9e,openstack/python-mistralclient,master,I06a63c5735b85750dd0d828ebcdff0ebfa6bcf9e,fix: Extra fields in the env definition are allowed,ABANDONED,2015-05-11 14:03:16.000000000,2015-05-27 12:16:09.000000000,,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-11 14:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/80d45ec63a88896a772bf98c6d4531cbc6e450e4', 'message': 'fix: Extra fields in the env definition are allowed\n\n   * add verification of fields for create\n\nChange-Id: I06a63c5735b85750dd0d828ebcdff0ebfa6bcf9e\nCloses-Bug: #1418912\n'}, {'number': 2, 'created': '2015-05-11 15:09:51.000000000', 'files': ['mistralclient/api/v2/environments.py', 'mistralclient/tests/unit/v2/test_environments.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/3847105abde93268503d8bcc854acaca470ed497', 'message': 'fix: Extra fields in the env definition are allowed\n\n   * add verification of fields for create\n\nChange-Id: I06a63c5735b85750dd0d828ebcdff0ebfa6bcf9e\nCloses-Bug: #1418912\n'}]",5,181899,3847105abde93268503d8bcc854acaca470ed497,10,5,2,15881,,,0,"fix: Extra fields in the env definition are allowed

   * add verification of fields for create

Change-Id: I06a63c5735b85750dd0d828ebcdff0ebfa6bcf9e
Closes-Bug: #1418912
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/99/181899/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/api/v2/environments.py', 'mistralclient/tests/unit/v2/test_environments.py']",2,80d45ec63a88896a772bf98c6d4531cbc6e450e4,bug/1418912,"ENVIRONMENT_FOR_CREATE = { 'name': 'env1', 'description': 'Test Environment #1', 'variables': { 'server': 'localhost' } } data = copy.deepcopy(ENVIRONMENT_FOR_CREATE) def test_create_invalid_field(self): data = copy.deepcopy(ENVIRONMENT) def create_env(data, params=""""): return self.environments.create(**data) self.assertRaises( ValueError, create_env, data, params=""{0}"".format(URL_TEMPLATE) ) ", data = copy.deepcopy(ENVIRONMENT),32,1
openstack%2Ffuel-astute~master~I81cc57564089dfbe937dd7e447b65fe645c8bae9,openstack/fuel-astute,master,I81cc57564089dfbe937dd7e447b65fe645c8bae9,Wait some time before checking puppet state,MERGED,2015-05-27 10:11:59.000000000,2015-05-27 12:11:48.000000000,2015-05-27 12:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 12200}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-05-27 10:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/f5d1e078487075ca1141e4705e8511ea5c8ac707', 'message': 'Wait some time before checking puppet state\n\nThis tries to fix really strange bug. Puppet finished\nits run without any error but for some reason last_run_summary.yaml\nwas not updated immediately.\nIf puppet finishes and last_run_summary.yaml is not updated we assume\nthat puppet crushed.\n\nChange-Id: I81cc57564089dfbe937dd7e447b65fe645c8bae9\nCloses-bug: #1458780\n'}, {'number': 2, 'created': '2015-05-27 10:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9fe78449cfcfdfd5d3831409fd9022ad2d46c6fc', 'message': 'Wait some time before checking puppet state\n\nThis tries to fix really strange bug. Puppet finished\nits run without any error but for some reason last_run_summary.yaml\nwas not updated immediately.\nIf puppet finishes and last_run_summary.yaml is not updated we assume\nthat puppet crushed.\n\nChange-Id: I81cc57564089dfbe937dd7e447b65fe645c8bae9\nCloses-bug: #1458780\n'}, {'number': 3, 'created': '2015-05-27 10:52:16.000000000', 'files': ['spec/unit/puppetd_spec.rb', 'lib/astute/puppetd.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/d579d95dbfda3ccc19dd52387417bbadd8cf48b9', 'message': 'Wait some time before checking puppet state\n\nThis tries to fix really strange bug. Puppet finished\nits run without any error but for some reason last_run_summary.yaml\nwas not updated immediately.\nIf puppet finishes and last_run_summary.yaml is not updated we assume\nthat puppet crushed.\n\nChange-Id: I81cc57564089dfbe937dd7e447b65fe645c8bae9\nCloses-bug: #1458780\n'}]",0,185915,d579d95dbfda3ccc19dd52387417bbadd8cf48b9,21,7,3,8954,,,0,"Wait some time before checking puppet state

This tries to fix really strange bug. Puppet finished
its run without any error but for some reason last_run_summary.yaml
was not updated immediately.
If puppet finishes and last_run_summary.yaml is not updated we assume
that puppet crushed.

Change-Id: I81cc57564089dfbe937dd7e447b65fe645c8bae9
Closes-bug: #1458780
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/15/185915/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/puppetd.rb'],1,f5d1e078487075ca1141e4705e8511ea5c8ac707,bug/1458780, loop do break if puppet_tasks.any? { |t| t.status == 'deploying' }, while puppet_tasks.any? { |t| t.status == 'deploying' },2,1
openstack%2Ffuel-web~master~I1ec2caa674466c54534025d867be91fc19d078e4,openstack/fuel-web,master,I1ec2caa674466c54534025d867be91fc19d078e4,Add forgotten mellanox support for image-based-provisioning,ABANDONED,2014-11-28 17:04:01.000000000,2015-05-27 12:11:00.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 11968}, {'_account_id': 12171}, {'_account_id': 12177}]","[{'number': 1, 'created': '2014-11-28 17:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b4697747de144657d3e309cb0f242c224c7ab6c4', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nAccidentally missing part\n\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 2, 'created': '2014-12-25 17:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/780e93402f105dcb86cb3704f6946f145d1b60e4', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nAccidentally missing part\n\nRelated-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 3, 'created': '2014-12-25 17:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f275a77040b787acf7bf90d9242dc6e913048317', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nAccidentally missing part\n\nRelated-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 4, 'created': '2015-01-12 15:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dcbe36e48335722d23b6dc559e034b001c8d4884', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nThe patchset adds section to boothook which configures kernel module\noptions and loads it. Also adds support to fuel-agent to deal with it.\n\nCloses-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 5, 'created': '2015-01-22 12:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0b20aff56de3f138481d150c62031428115d6543', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nThe patchset adds section to boothook which configures kernel module\noptions and loads it. Also adds support to fuel-agent to deal with it.\n\nCloses-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 6, 'created': '2015-02-24 13:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c6f61a7f1d5439b11d92542f095c4ab50d1a4f9f', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nThe patchset adds section to boothook which configures kernel module\noptions and loads it. Also adds support to fuel-agent to deal with it.\n\nCloses-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}, {'number': 7, 'created': '2015-02-24 13:26:55.000000000', 'files': ['fuel_agent/fuel_agent/tests/test_nailgun.py', 'fuel_agent/cloud-init-templates/boothook_ubuntu.jinja2', 'fuel_agent/fuel_agent/tests/test_configdrive.py', 'fuel_agent/fuel_agent/objects/configdrive.py', 'fuel_agent/fuel_agent/drivers/nailgun.py', 'fuel_agent/cloud-init-templates/boothook_centos.jinja2'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cd6c18df131b6871dd6432a17d35032b4f49f146', 'message': 'Add forgotten mellanox support for image-based-provisioning\n\nThe patchset adds section to boothook which configures kernel module\noptions and loads it. Also adds support to fuel-agent to deal with it.\n\nCloses-Bug: #1405661\nChange-Id: I1ec2caa674466c54534025d867be91fc19d078e4\n'}]",0,137835,cd6c18df131b6871dd6432a17d35032b4f49f146,40,10,7,8003,,,0,"Add forgotten mellanox support for image-based-provisioning

The patchset adds section to boothook which configures kernel module
options and loads it. Also adds support to fuel-agent to deal with it.

Closes-Bug: #1405661
Change-Id: I1ec2caa674466c54534025d867be91fc19d078e4
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/35/137835/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/fuel_agent/tests/test_nailgun.py', 'fuel_agent/cloud-init-templates/boothook_ubuntu.jinja2', 'fuel_agent/fuel_agent/objects/configdrive.py', 'fuel_agent/fuel_agent/tests/test_configdrive.py', 'fuel_agent/cloud-init-templates/boothook_centos.jinja2', 'fuel_agent/fuel_agent/drivers/nailgun.py']",6,b4697747de144657d3e309cb0f242c224c7ab6c4,bug/1405661," gw=data['ks_meta']['gw'], mlnx_plugin_mode=data['ks_meta'].get('mlnx_plugin_mode', 'disabled'), mlnx_iser_enabled=data['ks_meta'].get('mlnx_iser_enabled', False), mlnx_vf_num=data['ks_meta'].get('mlnx_vf_num', '1')", gw=data['ks_meta']['gw'],40,3
openstack%2Fswift~master~Ic6658db827be80bb7d496443fed4ec8284d5fa54,openstack/swift,master,Ic6658db827be80bb7d496443fed4ec8284d5fa54,Uncomment [filter: keystoneauth] and [filter: authtoken] sessions,ABANDONED,2015-05-26 22:00:39.000000000,2015-05-27 12:10:19.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2696}, {'_account_id': 12193}, {'_account_id': 12332}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-26 22:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/04daedfbe045365450d37436ef86fe58764dec0e', 'message': 'Uncomment [filter: keystoneauth] and [filter: authtoken] sessions\n\nThe sessions [filter: keystoneauth] and [filter: authtoken]\nwere uncommented to avoid errors.\n\nCloses-Bug: #1459022\nChange-Id: Ic6658db827be80bb7d496443fed4ec8284d5fa54\n'}, {'number': 2, 'created': '2015-05-27 01:43:32.000000000', 'files': ['etc/proxy-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/ef3e8403cd417bf4d40bdb4ee615fd44bf2acff4', 'message': 'Uncomment [filter: keystoneauth] and [filter: authtoken] sessions\n\nThe sessions [filter: keystoneauth] and [filter: authtoken]\nwere uncommented to avoid errors.\n\nCloses-Bug: #1459022\nChange-Id: Ic6658db827be80bb7d496443fed4ec8284d5fa54\n'}]",0,185755,ef3e8403cd417bf4d40bdb4ee615fd44bf2acff4,13,6,2,16233,,,0,"Uncomment [filter: keystoneauth] and [filter: authtoken] sessions

The sessions [filter: keystoneauth] and [filter: authtoken]
were uncommented to avoid errors.

Closes-Bug: #1459022
Change-Id: Ic6658db827be80bb7d496443fed4ec8284d5fa54
",git fetch https://review.opendev.org/openstack/swift refs/changes/55/185755/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/proxy-server.conf-sample'],1,04daedfbe045365450d37436ef86fe58764dec0e,bug/1459022,[filter:authtoken][filter:keystoneauth],# [filter:authtoken]# [filter:keystoneauth],2,2
openstack%2Ffuel-plugins~master~I14ff32c72f0131edcd168a5bb8c60df73d04b5dc,openstack/fuel-plugins,master,I14ff32c72f0131edcd168a5bb8c60df73d04b5dc,Rename dropdown to select in 1st version of plugin example,MERGED,2015-05-27 11:55:35.000000000,2015-05-27 12:09:53.000000000,2015-05-27 12:08:45.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-27 11:55:35.000000000', 'files': ['fuel_plugin_example_v1/environment_config.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/44cdd270ded5d2b8ed24f9439c6009c4e7441377', 'message': 'Rename dropdown to select in 1st version of plugin example\n\nDuring the development of 6.0 release dropdown was renamed\nto select, so this field never worked for plugins.\n\nDocImpact\nRelated-bug: #1458940\n\nChange-Id: I14ff32c72f0131edcd168a5bb8c60df73d04b5dc\n'}]",0,185943,44cdd270ded5d2b8ed24f9439c6009c4e7441377,13,7,1,8749,,,0,"Rename dropdown to select in 1st version of plugin example

During the development of 6.0 release dropdown was renamed
to select, so this field never worked for plugins.

DocImpact
Related-bug: #1458940

Change-Id: I14ff32c72f0131edcd168a5bb8c60df73d04b5dc
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/43/185943/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_plugin_example_v1/environment_config.yaml'],1,44cdd270ded5d2b8ed24f9439c6009c4e7441377,bug/1458940," fuel_plugin_example_select: type: ""select"" label: ""Select label"" description: ""Select description"""," fuel_plugin_example_dropdown: type: ""dropdown"" label: ""Dropdown label"" description: ""Dropdown description""",4,4
openstack%2Ffuel-web~master~I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e,openstack/fuel-web,master,I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e,Increase timeout for apt-get update task,MERGED,2015-05-22 22:35:43.000000000,2015-05-27 12:00:14.000000000,2015-05-27 11:48:14.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 3009}, {'_account_id': 8749}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-22 22:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0deab03181942b6e37dd060915d0104a413df076', 'message': 'Increase timeout for apt-get update task\n\nOn slow connections 3 minutes is not always sufficient\nfor the update to complete.\n\nChange-Id: I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e\n'}, {'number': 2, 'created': '2015-05-26 21:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/547add303081c114e649e800fe9d426bd9726120', 'message': 'Increase timeout for apt-get update task\n\nOn slow connections 3 minutes is not always sufficient\nfor the update to complete.\n\nChange-Id: I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e\n'}, {'number': 3, 'created': '2015-05-27 04:21:57.000000000', 'files': ['nailgun/nailgun/orchestrator/tasks_templates.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/88069f98fb52384b932f42f6d066621d0b53d665', 'message': 'Increase timeout for apt-get update task\n\nOn slow connections 3 minutes is not always sufficient\nfor the update to complete.\n\nChange-Id: I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e\nCloses-bug: #1459089\n'}]",5,185176,88069f98fb52384b932f42f6d066621d0b53d665,28,9,3,8829,,,0,"Increase timeout for apt-get update task

On slow connections 3 minutes is not always sufficient
for the update to complete.

Change-Id: I8b7ca2fd5ef35bfc67d73c5ead6f85a01bfcf05e
Closes-bug: #1459089
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/76/185176/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/orchestrator/tasks_templates.py'],1,0deab03181942b6e37dd060915d0104a413df076,bug/1459089, 'timeout': 1800}}, 'timeout': 180}},1,1
openstack%2Ffuel-web~master~Iafc745cc53768f5de1765a07e8c5d333f4849c51,openstack/fuel-web,master,Iafc745cc53768f5de1765a07e8c5d333f4849c51,Add warning about customized ubuntu mirrors,MERGED,2015-05-26 18:18:32.000000000,2015-05-27 11:59:28.000000000,2015-05-27 11:47:41.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10474}]","[{'number': 1, 'created': '2015-05-26 18:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a86702a9e6174cfe4ac5afb353d70c16d8361d87', 'message': 'Add warning about customized ubuntu mirrors\n\nIf a user adds custom ubuntu upstream mirrors to their environment, the\n--clear-upstream-repos option does not automatically remove them from\nthe environment. This commit adds a warning to indicate that user\nintervention may be required.\n\nChange-Id: Iafc745cc53768f5de1765a07e8c5d333f4849c51\nPartial-Bug: 1458597\n'}, {'number': 2, 'created': '2015-05-26 19:01:03.000000000', 'files': ['fuel_upgrade_system/fuel_package_updates/fuel_package_updates/fuel_package_updates.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b8ce1824aecaa60be186e26e0c61e4cdb97edbde', 'message': 'Add warning about customized ubuntu mirrors\n\nIf a user adds custom ubuntu upstream mirrors to their environment, the\n--clear-upstream-repos option does not automatically remove them from\nthe environment. This commit adds a warning to indicate that user\nintervention may be required.\n\nChange-Id: Iafc745cc53768f5de1765a07e8c5d333f4849c51\nPartial-Bug: 1458597\n'}]",0,185689,b8ce1824aecaa60be186e26e0c61e4cdb97edbde,19,5,2,14985,,,0,"Add warning about customized ubuntu mirrors

If a user adds custom ubuntu upstream mirrors to their environment, the
--clear-upstream-repos option does not automatically remove them from
the environment. This commit adds a warning to indicate that user
intervention may be required.

Change-Id: Iafc745cc53768f5de1765a07e8c5d333f4849c51
Partial-Bug: 1458597
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/89/185689/2 && git format-patch -1 --stdout FETCH_HEAD,['fuel_upgrade_system/fuel_package_updates/fuel_package_updates/fuel_package_updates.py'],1,a86702a9e6174cfe4ac5afb353d70c16d8361d87,bug/1458597," if options.clear_upstream_repos: logger.warning('*IMPORTANT* If there are any custom Ubuntu mirrors ' 'that have been configured manually, please remove ' 'them manually as they will not be removed with the ' '--clear-upstream-repos option.')",,5,0
openstack%2Fmistral~master~Ia106ce2bd2994c494a6c25039d92358eeb0abdb9,openstack/mistral,master,Ia106ce2bd2994c494a6c25039d92358eeb0abdb9,Fix command line arguments has lower priority than config file,MERGED,2015-05-26 12:48:54.000000000,2015-05-27 11:39:14.000000000,2015-05-27 11:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-26 12:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9e3d71e94757d0574b57bf923eda8dbb41c09bf3', 'message': 'Fix command line arguments has lower priority than config file\n\n  *This bug happened because of how oslo is handling the order of command line\n\n  *Make sure the command line parameter will always send last\n\nChange-Id: Ia106ce2bd2994c494a6c25039d92358eeb0abdb9\nCloses-Bug: #1454111\n'}, {'number': 2, 'created': '2015-05-26 12:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8716f1faf93d02219c49e37257a982d32eea620d', 'message': 'Fix command line arguments has lower priority than config file\n\n  *This bug happened because of how oslo is handling the order of command line\n\n  *Make sure the command line parameter will always send last\n\nChange-Id: Ia106ce2bd2994c494a6c25039d92358eeb0abdb9\nCloses-Bug: #1454111\n'}, {'number': 3, 'created': '2015-05-26 15:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fbefd5af1f19d29bb0a4c8c7419929fd523c69e7', 'message': 'Fix command line arguments has lower priority than config file\n\n  *This bug happened because of how oslo is handling the order of command line\n\n  *Make sure the command line parameter will always send last\n\nChange-Id: Ia106ce2bd2994c494a6c25039d92358eeb0abdb9\nCloses-Bug: #1454111\n'}, {'number': 4, 'created': '2015-05-27 07:25:09.000000000', 'files': ['mistral/cmd/launch.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/379c6eb85b8171104522fcb9d02c262dad0860fa', 'message': 'Fix command line arguments has lower priority than config file\n\n  *This bug happened because of how oslo is handling the order of command line\n\n  *Make sure the command line parameter will always send last\n\nChange-Id: Ia106ce2bd2994c494a6c25039d92358eeb0abdb9\nCloses-Bug: #1454111\n'}]",5,185579,379c6eb85b8171104522fcb9d02c262dad0860fa,14,5,4,15881,,,0,"Fix command line arguments has lower priority than config file

  *This bug happened because of how oslo is handling the order of command line

  *Make sure the command line parameter will always send last

Change-Id: Ia106ce2bd2994c494a6c25039d92358eeb0abdb9
Closes-Bug: #1454111
",git fetch https://review.opendev.org/openstack/mistral refs/changes/79/185579/4 && git format-patch -1 --stdout FETCH_HEAD,['mistral/cmd/launch.py'],1,9e3d71e94757d0574b57bf923eda8dbb41c09bf3,bug/1454111,"def handle_parameters_order(): """"""In oslo it's important the order of the launch parameters. if --config-file came after the command line parameters the command line parameters are ignored. So to make user command line parameters are never ignore this method move the -config-file to be always first """""" args = sys.argv[1:] for arg in sys.argv[1:]: if arg == '--config-file' or arg.startswith('--config-file='): conf_file_value = args[args.index(arg) + 1] args.remove(conf_file_value) args.remove(arg) args.insert(0, arg) args.insert(1, conf_file_value) return args config.parse_args(handle_parameters_order()) ", config.parse_args(),21,1
openstack%2Fbifrost~master~Id24c481455a0ab3cf5bf0ab96c233db2aadec62b,openstack/bifrost,master,Id24c481455a0ab3cf5bf0ab96c233db2aadec62b,Move qemu-utils into install/defaults/main,MERGED,2015-05-14 19:56:27.000000000,2015-05-27 11:36:50.000000000,2015-05-27 11:36:49.000000000,"[{'_account_id': 3}, {'_account_id': 8106}, {'_account_id': 11655}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-05-14 19:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/f87de3b32fd623c281c98bf68d41d75eb29e5d21', 'message': 'Move qemu-utils into install/defaults/main\n\nQemu-utils package is required for the qemu-img command, which is\nrequired by diskimage-builder and therefor should be installed for all\nenvironments, not just testing environments.\n\nChange-Id: Id24c481455a0ab3cf5bf0ab96c233db2aadec62b\n'}, {'number': 2, 'created': '2015-05-25 13:53:14.000000000', 'files': ['playbooks/roles/ironic-install/defaults/main.yml', 'playbooks/roles/ironic-install/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/f993b667ce19ba8aeb17c2f473175b14ba25da10', 'message': 'Move qemu-utils into install/defaults/main\n\nQemu-utils package is required for the qemu-img command, which is\nrequired by diskimage-builder and therefor should be installed for all\nenvironments, not just testing environments.\n\nChange-Id: Id24c481455a0ab3cf5bf0ab96c233db2aadec62b\n'}]",0,183190,f993b667ce19ba8aeb17c2f473175b14ba25da10,13,4,2,2889,,,0,"Move qemu-utils into install/defaults/main

Qemu-utils package is required for the qemu-img command, which is
required by diskimage-builder and therefor should be installed for all
environments, not just testing environments.

Change-Id: Id24c481455a0ab3cf5bf0ab96c233db2aadec62b
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/90/183190/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/ironic-install/defaults/main.yml', 'playbooks/roles/ironic-install/tasks/main.yml']",2,f87de3b32fd623c281c98bf68d41d75eb29e5d21,,, - qemu-utils,1,1
openstack%2Fsahara~master~Ifa89f27e5e28873e86b8247d84b494732d16b038,openstack/sahara,master,Ifa89f27e5e28873e86b8247d84b494732d16b038,Added missing retries of clients calls,MERGED,2015-05-26 12:48:12.000000000,2015-05-27 11:30:01.000000000,2015-05-27 11:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 12038}]","[{'number': 1, 'created': '2015-05-26 12:48:12.000000000', 'files': ['sahara/service/volumes.py', 'sahara/service/api.py', 'sahara/service/quotas.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1210d718da79dae0f92cd0a2fa6fb4e484806cf6', 'message': 'Added missing retries of clients calls\n\nSome of clients calls was not wrapped with\nexecute_with_retries method\n\npartially implements bp clients-calls-retry\n\nChange-Id: Ifa89f27e5e28873e86b8247d84b494732d16b038\n'}]",0,185578,1210d718da79dae0f92cd0a2fa6fb4e484806cf6,9,5,1,12039,,,0,"Added missing retries of clients calls

Some of clients calls was not wrapped with
execute_with_retries method

partially implements bp clients-calls-retry

Change-Id: Ifa89f27e5e28873e86b8247d84b494732d16b038
",git fetch https://review.opendev.org/openstack/sahara refs/changes/78/185578/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/volumes.py', 'sahara/service/api.py', 'sahara/service/quotas.py']",3,1210d718da79dae0f92cd0a2fa6fb4e484806cf6,bp/clients-calls-retry, lim = b.execute_with_retries(nova.limits.get).to_dict()['absolute'], lim = nova.limits.get().to_dict()['absolute'],10,7
openstack%2Ftrove~master~I5a1e9300dd0a16395769acda672943899f9ad0ad,openstack/trove,master,I5a1e9300dd0a16395769acda672943899f9ad0ad,accepting network and availability zone for instances in cluster,MERGED,2015-05-01 18:21:30.000000000,2015-05-27 11:29:57.000000000,2015-05-27 11:29:56.000000000,"[{'_account_id': 3}, {'_account_id': 1870}, {'_account_id': 5293}, {'_account_id': 6160}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 11783}, {'_account_id': 14576}, {'_account_id': 14829}, {'_account_id': 14991}, {'_account_id': 15321}]","[{'number': 1, 'created': '2015-05-01 18:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4320bfe7776ef3a30e2ccdb38e453da60550fced', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nBug: 1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 2, 'created': '2015-05-01 21:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1548a010ff363b53ead4be35290c812efa0c3305', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nBug: 1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 3, 'created': '2015-05-05 23:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8d61065eab4ef349579dd64b787f0dfb52f0e139', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nAlso fixed issues where same flavor was being used for all the cluster\ninstances.\n\nCloses-Bug: 1447350\nCloses-Bug: 1452023\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 4, 'created': '2015-05-05 23:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7ab2c1a4166e61f34bb631ec4df6453783157256', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nAlso fixed issue where same flavor was being used for all the cluster\ninstances.\n\nCloses-Bug: 1447350\nCloses-Bug: 1452023\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 5, 'created': '2015-05-05 23:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a307e1b2b160f1c23b82970ce37b4af20cd1399c', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nAlso fixed issue where same flavor was being used for all the cluster\ninstances.\n\nCloses-Bug: 1447350\nCloses-Bug: 1452023\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 6, 'created': '2015-05-07 00:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0f6716ac100decc9e396d3665d2094e11ce8da9d', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nAlso fixed issue where same flavor was being used for all the cluster\ninstances.\n\nCloses-Bug: #1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 7, 'created': '2015-05-07 04:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/247f86f10cf0e7a67e16ac014b2fd315bde1c29c', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nCloses-Bug: #1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 8, 'created': '2015-05-11 16:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3081df214bb4052f021865f325a5ba6b50badc14', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nThis review is addressing the fix only for vertica datastore.\n\nCloses-Bug: #1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}, {'number': 9, 'created': '2015-05-14 19:07:28.000000000', 'files': ['trove/common/strategies/cluster/experimental/vertica/api.py', 'trove/cluster/service.py', 'trove/common/apischema.py', 'trove/tests/unittests/cluster/test_cluster_controller.py', 'trove/tests/unittests/cluster/test_cluster_vertica_controller.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/c4946145cc75fe4eb540afba02d2ab2d78be2b87', 'message': 'accepting network and availability zone for instances in cluster\n\nStandalone instance create call in trove already accepts neutron networks\nand availability zone information.\n\nIn the similar manner, instances which are part of the cluster can\nnow be supplied with a specific neutron network information and\navailability zone.\n\nThis review is addressing the fix only for vertica datastore.\n\nPartial-Bug: #1447350\nChange-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad\n'}]",20,179443,c4946145cc75fe4eb540afba02d2ab2d78be2b87,57,14,9,6160,,,0,"accepting network and availability zone for instances in cluster

Standalone instance create call in trove already accepts neutron networks
and availability zone information.

In the similar manner, instances which are part of the cluster can
now be supplied with a specific neutron network information and
availability zone.

This review is addressing the fix only for vertica datastore.

Partial-Bug: #1447350
Change-Id: I5a1e9300dd0a16395769acda672943899f9ad0ad
",git fetch https://review.opendev.org/openstack/trove refs/changes/43/179443/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/cluster/service.py', 'trove/common/strategies/cluster/experimental/vertica/api.py', 'trove/common/apischema.py']",3,4320bfe7776ef3a30e2ccdb38e453da60550fced,cluster-net-1447350," ""volume"": volume, ""nics"": nics, ""availability_zone"": non_empty_string"," ""volume"": volume",21,9
openstack%2Fheat-templates~master~I77f175b682fd0a5d074735eab3e60ad91fbdb67c,openstack/heat-templates,master,I77f175b682fd0a5d074735eab3e60ad91fbdb67c,Adding output section to templates,MERGED,2015-04-29 06:30:19.000000000,2015-05-27 11:11:23.000000000,2015-05-27 11:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 12259}]","[{'number': 1, 'created': '2015-04-29 06:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/449f73a069df6ea933493338c6ea50137890a2e4', 'message': 'Add output section.\n\nAdding output section to templates to make most use of the template.\n\nChange-Id: I77f175b682fd0a5d074735eab3e60ad91fbdb67c\n'}, {'number': 2, 'created': '2015-04-29 10:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/1cfc0f711bd8b7950109f4270ffda49f86412780', 'message': 'Add output section.(1)\n\nAdding output section to templates to make most use of the template.\n\nChange-Id: I77f175b682fd0a5d074735eab3e60ad91fbdb67c\n'}, {'number': 3, 'created': '2015-05-20 10:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/7cfa7f107be3c5ed57af0ea5b67223c2fb9260a2', 'message': 'Add output section.\n\nAdding output section to templates to make most use of the template.\n\nChange-Id: I77f175b682fd0a5d074735eab3e60ad91fbdb67c\n'}, {'number': 4, 'created': '2015-05-20 10:05:44.000000000', 'files': ['hot/lb_server.yaml', 'hot/resource_group/server_with_volumes.yaml', 'hot/software-config/example-templates/example-os-apply-config-plus-cloud-config.yaml', 'hot/multi_region_hello_world.yaml', 'hot/software-config/example-templates/example-structured-template.yaml', 'hot/software-config/example-templates/example-os-apply-config.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/791daca9104b9f55d840d2155e6e996ca7af5f4d', 'message': 'Adding output section to templates\n\nAdding output section to templates to make most use of the template.\n\nChange-Id: I77f175b682fd0a5d074735eab3e60ad91fbdb67c\n'}]",2,178520,791daca9104b9f55d840d2155e6e996ca7af5f4d,21,5,4,12259,,,0,"Adding output section to templates

Adding output section to templates to make most use of the template.

Change-Id: I77f175b682fd0a5d074735eab3e60ad91fbdb67c
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/20/178520/4 && git format-patch -1 --stdout FETCH_HEAD,"['hot/lb_server.yaml', 'hot/multi_region_hello_world.yaml']",2,449f73a069df6ea933493338c6ea50137890a2e4,provide-outputs-in-templates," region_name: RegionOneoutputs: stack_one_outputs: description: Output of stack_one. value: { get_attr: [stack_one, outputs] } stack_two_outputs: description: Output of stack_two. value: { get_attr: [stack_two, outputs] }", region_name: RegionTwo,16,1
openstack%2Fpython-novaclient~master~I6dd534c659d0b548375405b5589fbad0197125bf,openstack/python-novaclient,master,I6dd534c659d0b548375405b5589fbad0197125bf,Remove device arg from nova volume-attach,ABANDONED,2015-05-25 18:22:55.000000000,2015-05-27 11:08:30.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 8768}, {'_account_id': 9312}]","[{'number': 1, 'created': '2015-05-25 18:22:55.000000000', 'files': ['novaclient/v2/shell.py', 'novaclient/tests/unit/v2/test_volumes.py', 'novaclient/v2/volumes.py', 'novaclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e4c95c49bb4d547b40180cf9f3e33109ba7521fa', 'message': ""Remove device arg from nova volume-attach\n\nFor libvirt only clouds - passing this is almost always a mistake, for\nother hypervisors, it's not mandatory anyway (Nova will choose an\navailable one because it's needed by the database) - but this kind of\nlow level detail is really not something that makes sense exposed through\nthe public API.\n\nWe can't phase it out as easily from the API, but we can easily\ndisallow it in the CLI as a first step towards removing it's usage.\n\nChange-Id: I6dd534c659d0b548375405b5589fbad0197125bf\n""}]",6,185438,e4c95c49bb4d547b40180cf9f3e33109ba7521fa,12,10,1,5511,,,0,"Remove device arg from nova volume-attach

For libvirt only clouds - passing this is almost always a mistake, for
other hypervisors, it's not mandatory anyway (Nova will choose an
available one because it's needed by the database) - but this kind of
low level detail is really not something that makes sense exposed through
the public API.

We can't phase it out as easily from the API, but we can easily
disallow it in the CLI as a first step towards removing it's usage.

Change-Id: I6dd534c659d0b548375405b5589fbad0197125bf
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/38/185438/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v2/shell.py', 'novaclient/tests/unit/v2/test_volumes.py', 'novaclient/v2/volumes.py', 'novaclient/tests/unit/v2/test_shell.py']",4,e4c95c49bb4d547b40180cf9f3e33109ba7521fa,remove_device_from_volume_attach, {'volumeAttachment': {'volumeId': 'Work'}})," self.run_command('volume-attach sample-server Work /dev/vdb') self.assert_called('POST', '/servers/1234/os-volume_attachments', {'volumeAttachment': {'device': '/dev/vdb', 'volumeId': 'Work'}}) def test_volume_attach_without_device(self): {'volumeAttachment': {'device': None, 'volumeId': 'Work'}})",4,23
openstack%2Ffuel-qa~master~I85200028e0f7c66db40340b1e40db4da86f3ae17,openstack/fuel-qa,master,I85200028e0f7c66db40340b1e40db4da86f3ae17,Deleted cases for ceph checks from classic provisioning thread,MERGED,2015-05-27 10:53:13.000000000,2015-05-27 11:01:11.000000000,2015-05-27 11:01:11.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 14057}]","[{'number': 1, 'created': '2015-05-27 10:53:13.000000000', 'files': ['fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f9b73e098fb607c596c81795b36266cfb267d4c1', 'message': 'Deleted cases for ceph checks from classic provisioning thread\n\nChange-Id: I85200028e0f7c66db40340b1e40db4da86f3ae17\nCloses-Bug: #1459189\n'}]",0,185928,f9b73e098fb607c596c81795b36266cfb267d4c1,9,6,1,8882,,,0,"Deleted cases for ceph checks from classic provisioning thread

Change-Id: I85200028e0f7c66db40340b1e40db4da86f3ae17
Closes-Bug: #1459189
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/28/185928/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ceph.py'],1,f9b73e098fb607c596c81795b36266cfb267d4c1,,"@test(groups=[""thread_3"", ""ceph""]) groups=[""ceph_ha"", ""classic_provisioning""])","@test(groups=[""thread_3"", ""ceph"", ""classic_provisioning""]) groups=[""ceph_ha""])",2,2
openstack%2Fec2-api~master~I23ad5b1f64191d455f525747c8c62a450507682c,openstack/ec2-api,master,I23ad5b1f64191d455f525747c8c62a450507682c,Manage OS VPN connection for route table operations,MERGED,2015-05-26 17:13:39.000000000,2015-05-27 10:52:26.000000000,2015-05-27 10:52:26.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-26 17:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c1f97b40e01003a97abe229c54fee47deca6649a', 'message': 'Manage OS VPN connection for route table operations\n\nChange-Id: I23ad5b1f64191d455f525747c8c62a450507682c\n'}, {'number': 2, 'created': '2015-05-26 19:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/db681ed0e3091e669c05c97e4f0a6e2ca0e3dc6a', 'message': 'Manage OS VPN connection for route table operations\n\nChange-Id: I23ad5b1f64191d455f525747c8c62a450507682c\n'}, {'number': 3, 'created': '2015-05-26 23:05:19.000000000', 'files': ['ec2api/tests/unit/test_vpn_connection.py', 'ec2api/api/route_table.py', 'ec2api/tests/unit/test_route_table.py', 'ec2api/api/vpn_connection.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/9b64b36d597b92155f08eaa416d53f0e69b7b6bf', 'message': 'Manage OS VPN connection for route table operations\n\nChange-Id: I23ad5b1f64191d455f525747c8c62a450507682c\n'}]",0,185672,9b64b36d597b92155f08eaa416d53f0e69b7b6bf,16,4,3,10224,,,0,"Manage OS VPN connection for route table operations

Change-Id: I23ad5b1f64191d455f525747c8c62a450507682c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/72/185672/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/route_table.py', 'ec2api/api/vpn_connection.py']",2,c1f97b40e01003a97abe229c54fee47deca6649a,vpn,"def update_vpn_routes(context, neutron, cleaner, route_table, subnets): vpn_gateway = ec2utils.get_attached_gateway( context, route_table['vpc_id'], 'vgw') if not vpn_gateway: return _reset_vpn_connections(context, neutron, cleaner, vpn_gateway, route_tables=[route_table], subnets=subnets) ",,48,8
openstack%2Ffuel-web~master~Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085,openstack/fuel-web,master,Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085,Do not include offline nodes in repo connectivity check,MERGED,2015-05-26 16:07:58.000000000,2015-05-27 10:50:45.000000000,2015-05-27 10:39:00.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14543}]","[{'number': 1, 'created': '2015-05-26 16:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d215f771d2a2615e54699a42f9b4e8cf5f1f4d6d', 'message': 'Do not include offline nodes in repo connectivity check\n\nNodes are excluded from several tasks:\n- repo connectivity\n- repo connectivity with setup\n\nChange-Id: Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085\nPartial-Bug: 1318659\n'}, {'number': 2, 'created': '2015-05-27 07:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd2af429f9b2758b988790941382d32b7547eeb6', 'message': 'Do not include offline nodes in repo connectivity check\n\nNodes are excluded from several tasks:\n- repo connectivity\n- repo connectivity with setup\n\nChange-Id: Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085\nPartial-Bug: 1318659\n'}, {'number': 3, 'created': '2015-05-27 08:15:44.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/unit/test_check_repo_connection_task.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/10cb262275707743187ce1919673470fef6d3e33', 'message': 'Do not include offline nodes in repo connectivity check\n\nNodes are excluded from several tasks:\n- repo connectivity\n- repo connectivity with setup\n\nChange-Id: Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085\nPartial-Bug: 1318659\n'}]",4,185655,10cb262275707743187ce1919673470fef6d3e33,29,11,3,8907,,,0,"Do not include offline nodes in repo connectivity check

Nodes are excluded from several tasks:
- repo connectivity
- repo connectivity with setup

Change-Id: Iffdaae71b9e74e4e6a6f34f480f74bd52b93c085
Partial-Bug: 1318659
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/55/185655/3 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/task/task.py'],1,d215f771d2a2615e54699a42f9b4e8cf5f1f4d6d,online_repo, nodes = [] for n in objects.Cluster.get_nodes_not_for_deletion(self.task.cluster): if n.online: nodes.append({'uid': n.id}) return nodes if not node.online: continue ," return [{""uid"": n.id} for n in (objects.Cluster .get_nodes_not_for_deletion(self.task.cluster)) ]",8,4
openstack%2Fmurano~master~I9ca36d1f5fb1ec9206465542a8af42522465735b,openstack/murano,master,I9ca36d1f5fb1ec9206465542a8af42522465735b,Add MURANO_REPO_URL customization support for devstack,MERGED,2015-05-26 15:42:42.000000000,2015-05-27 10:48:40.000000000,2015-05-27 10:48:38.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-26 15:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f9cc52624332d40d8dbdbbec32ef2158561e37c2', 'message': 'Add MURANO_REPO_URL customization support for devstack\n\nChange-Id: I9ca36d1f5fb1ec9206465542a8af42522465735b\n'}, {'number': 2, 'created': '2015-05-26 15:44:47.000000000', 'files': ['contrib/devstack/lib/murano-dashboard'], 'web_link': 'https://opendev.org/openstack/murano/commit/90bd91ee4d9ebb1995d5791c887c825cd39201c3', 'message': 'Add MURANO_REPO_URL customization support for devstack\n\nChange-Id: I9ca36d1f5fb1ec9206465542a8af42522465735b\n'}]",1,185648,90bd91ee4d9ebb1995d5791c887c825cd39201c3,16,8,2,13752,,,0,"Add MURANO_REPO_URL customization support for devstack

Change-Id: I9ca36d1f5fb1ec9206465542a8af42522465735b
",git fetch https://review.opendev.org/openstack/murano refs/changes/48/185648/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/murano-dashboard'],1,f9cc52624332d40d8dbdbbec32ef2158561e37c2,,MURANO_REPOSITORY_URL=${MURANO_REPOSITORY_URL:-'http://apps.openstack.org/'} MURANO_REPO_URL = '$MURANO_REPOSITORY_URL',,3,0
openstack%2Ffuel-specs~master~I034590ca2c1c2d71364ffb58a209d349165f3288,openstack/fuel-specs,master,I034590ca2c1c2d71364ffb58a209d349165f3288,Added 'replace-obs' spec for 7.0,ABANDONED,2015-04-15 09:46:54.000000000,2015-05-27 10:47:02.000000000,,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8787}, {'_account_id': 9582}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-04-15 09:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b07138bac5560381f990eabea3ef5de155dae3d3', 'message': ""Added 'replace-obs' spec for 6.1\n\nChange-Id: I034590ca2c1c2d71364ffb58a209d349165f3288\n""}, {'number': 2, 'created': '2015-04-22 07:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/980c7bad4ea5703d042d0f2243b876d5c5340287', 'message': ""Added 'replace-obs' spec for 7.0\n\nChange-Id: I034590ca2c1c2d71364ffb58a209d349165f3288\n""}, {'number': 3, 'created': '2015-04-22 07:46:05.000000000', 'files': ['doc/source/index.rst', 'specs/7.0/replace-obs.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/86fb12bc42e66d3de6da2d77f3cab32ffddd9de4', 'message': ""Added 'replace-obs' spec for 7.0\n\nChange-Id: I034590ca2c1c2d71364ffb58a209d349165f3288\n""}]",0,173742,86fb12bc42e66d3de6da2d77f3cab32ffddd9de4,8,5,3,13124,,,0,"Added 'replace-obs' spec for 7.0

Change-Id: I034590ca2c1c2d71364ffb58a209d349165f3288
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/42/173742/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/6.1/replace-obs.rst'],1,b07138bac5560381f990eabea3ef5de155dae3d3,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Replace OBS ========================================== URL of the related launchpad blueprint: https://blueprints.launchpad.net/fuel/+spec/replace-obs We are going to create a new packaging build system inside internal infrastructure and get rid from existing one due to issues related to building process. Problem description =================== A detailed description of the problem: Currently OSCI team is using OBS as 'all in one' service for building, publishing and signing of DEB and RPM packages as well.We faced a number of challenges with OBS during the last year. * OBS builds packages in its own way which is different from upstream. It causes an issues when upstream package can't be rebuilt without changing packages sources. * OBS rebuilds package when its build dependency changed (and doesn't update revision number of such package) * OBS uses base upstream packages for target in the building stage. Every change in the target causes rebuilding of each package which was built with this target. * OBS doesn't support publishing udeb binary packages. This is due to the fact that it uses plain debian repository structure. But deb and udeb packages should not be published in one repository. * Our current OBS version (2.4) doesn't support debian python:any dependencies. That's why we decided to create new OBS (2.6) instance. We can't update current version because it totally breaks supporting previously shipped releases. * OBS doesn't support signing with predefined key. Only OBS auto generated keys can be used. Every OBS project has it's own key. Such keys can't be exported from OBS. * It's quite hard to reproduce our CI due to OBS. Every MOS OBS project based on previously shipped project. (e.g. 6.1 and 6.0.1 based on 6.0 release, 6.0 based on 5.1 and so on). So if you need to reproduce our CI for 6.1 release, you need to rebuild all packages for all shipped releases since 3.2. * OBS server side natively supported on openSUSE and SUSE Linux Enterprise Server. * We cannot support OBS as well as distribute it for our customers. Proposed change =============== * Using of native build tools for building DEB and RPM packages shall help us to solve bugs with versioning and make the build process open and transparent. By 'native build tools' we mean: * 'sbuild' for DEB packages. * 'mock' for RPM packages. * We can use Docker as wrapper for 'sbild' and 'mock' with our scripts inside. * We can wrap host side scripts of interaction in a package for easy deployment. Alternatives ------------ We can try to use another build system for packages which shall support RPM and DEB packaging at once. Data model impact ----------------- None REST API impact --------------- None Upgrade impact -------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Plugin impact ------------- None Other deployer impact --------------------- None Developer impact ---------------- None Infrastructure impact --------------------- In case of full replacement of OBS from infrastructure we shall think about publishing our packages on mirrors since there is no way to use publishing part of OBS with any foreign package builder instead of OBS package builder. * Current workflow of bulding packages will be the same in general. * We shall test and replace our current OBS related jenkins jobs on new ones. * We shall think about using Docker Hub as main repository of Docker Images * Deployment of infrastructure components shall be changed and reviewed. Implementation ============== Assignee(s) ----------- Primary assignee: `dburmistrov <https://launchpad.net/~dburmistrov>`_ Other contributors: `dkaiharodsev <https://launchpad.net/~dkaiharodsev>`_ Work Items ---------- * Write a scripts for interaction with native build tools inside Docker Images and pack them into DEB package. * Create Docker Images with packaging tools (sbuild and mockbuild) inside. * Create a Jenkins job for bulding packages by using Docker based packaging system. * Write a Puppet manifests for deploying buld system. Dependencies ============ * https://blueprints.launchpad.net/fuel/+spec/replace-obs * https://blueprints.launchpad.net/fuel/+spec/puppet-manifest-for-new-build-sysem Testing ======= All of the scripts and Jenkins jobs shall be tested in a sandbox environment for building packages. We shall compare performance results of building inside Docker with currently used OBS. Documentation Impact ==================== In case of using new build system we shall change workflow documentation where OBS mentioned. References ========== * OBS https://build.opensuse.org/ * Docker https://www.docker.com/ * Docker Hub https://hub.docker.com/ * sbuild https://wiki.debian.org/sbuild * mock https://fedoraproject.org/wiki/Projects/Mock). * Puppet https://puppetlabs.com/",,157,0
openstack%2Fsahara-image-elements~master~Ida7260d30ac5ba0fe1a1c48b9ef6389c62178823,openstack/sahara-image-elements,master,Ida7260d30ac5ba0fe1a1c48b9ef6389c62178823,storm: install supervisor using package-installs,MERGED,2015-05-18 15:09:28.000000000,2015-05-27 10:44:05.000000000,2015-05-27 10:44:03.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-05-18 15:09:28.000000000', 'files': ['elements/storm/install.d/60-storm', 'elements/storm/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/36db653bec2aaef3be18408e9d34f685af81db6b', 'message': 'storm: install supervisor using package-installs\n\nChange-Id: Ida7260d30ac5ba0fe1a1c48b9ef6389c62178823\n'}]",0,184080,36db653bec2aaef3be18408e9d34f685af81db6b,11,7,1,12320,,,0,"storm: install supervisor using package-installs

Change-Id: Ida7260d30ac5ba0fe1a1c48b9ef6389c62178823
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/80/184080/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/storm/install.d/60-storm', 'elements/storm/package-installs.yaml']",2,36db653bec2aaef3be18408e9d34f685af81db6b,storm-install,supervisor:,,1,1
openstack%2Fsahara-image-elements~master~I248872e77358f8388f4a66a54e53b2ffa727c7e3,openstack/sahara-image-elements,master,I248872e77358f8388f4a66a54e53b2ffa727c7e3,hadoop-cdh: simplify package installation,MERGED,2015-05-18 13:56:16.000000000,2015-05-27 10:42:26.000000000,2015-05-27 10:42:26.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12320}]","[{'number': 1, 'created': '2015-05-18 13:56:16.000000000', 'files': ['elements/hadoop-cdh/pre-install.d/40-cdh-repo', 'elements/hadoop-cdh/post-install.d/40-setup-hadoop', 'elements/hadoop-cdh/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/e1c6b32d1e8bd004d066a3276aaba5f4f6be77da', 'message': 'hadoop-cdh: simplify package installation\n\nMove the repository addition in a pre-install.d script, as that is the\nright place for such operations (no more need to manual `apt-get update`\nrun), and switch it from curl to wget (already in use in that script);\nas a result, wget is now installed in pre-install.d.\n\nThe above change makes the installation of hadoop-hdfs-namenode and\nhadoop-hdfs-datanode possible using the declarative package-installs\nway.\n\nAs a side effect of installing packages before setting up the hadoop\nuser and group, make sure to not create them if already present. The\npackaging as of today takes care of creating the hadoop group, so guard\nthe setup in case it is not done anymore or will be done for the user\ntoo.\n\nChange-Id: I248872e77358f8388f4a66a54e53b2ffa727c7e3\n'}]",0,184067,e1c6b32d1e8bd004d066a3276aaba5f4f6be77da,12,6,1,12320,,,0,"hadoop-cdh: simplify package installation

Move the repository addition in a pre-install.d script, as that is the
right place for such operations (no more need to manual `apt-get update`
run), and switch it from curl to wget (already in use in that script);
as a result, wget is now installed in pre-install.d.

The above change makes the installation of hadoop-hdfs-namenode and
hadoop-hdfs-datanode possible using the declarative package-installs
way.

As a side effect of installing packages before setting up the hadoop
user and group, make sure to not create them if already present. The
packaging as of today takes care of creating the hadoop group, so guard
the setup in case it is not done anymore or will be done for the user
too.

Change-Id: I248872e77358f8388f4a66a54e53b2ffa727c7e3
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/67/184067/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop-cdh/pre-install.d/40-cdh-repo', 'elements/hadoop-cdh/post-install.d/40-setup-hadoop', 'elements/hadoop-cdh/package-installs.yaml']",3,e1c6b32d1e8bd004d066a3276aaba5f4f6be77da,cdh-installs,wget: phase: pre-install.d hadoop-hdfs-namenode: hadoop-hdfs-datanode:,curl: phase: post-install.d wget: phase: post-install.d,38,40
openstack%2Ffuel-qa~master~I19328dfd4bb8ffbf2035197395fa6c3067a01384,openstack/fuel-qa,master,I19328dfd4bb8ffbf2035197395fa6c3067a01384,Fix Neutron L3 destructive tests by using proper SSH connection,MERGED,2015-05-22 19:54:55.000000000,2015-05-27 10:23:37.000000000,2015-05-27 10:23:37.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16414}]","[{'number': 1, 'created': '2015-05-22 19:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/12ddade6c65b83a80c3a1e8103b078eb5cd31eb8', 'message': 'Fix Neutron L3 destructive tests to use proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller instead of\nslave-01.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 2, 'created': '2015-05-22 20:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/08aeeaae4d7427a4166cb8caf0b6680ca4f8d0ea', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller instead of\nslave-01.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 3, 'created': '2015-05-24 11:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/7f17de8e61ffce04c48831fec635094a3092c91a', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller instead of\nslave-01.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 4, 'created': '2015-05-25 07:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9ce7d54b4e495f85dde604f2cb814bb4f4b569bb', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller instead of\nslave-01.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 5, 'created': '2015-05-25 16:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2c463e7bebe8a3b4e18c4e63c21a56828a109609', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller that wont be\nrebooted. Will be used controller from which L3 router agent\nis removed.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 6, 'created': '2015-05-25 17:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/deb7b8289eecc4de5d5eae769e630f96418769eb', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller that wont be\nrebooted. Will be used controller from which L3 router agent\nis removed.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 7, 'created': '2015-05-26 11:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c7d1689cd697b7810d60d9feed52f6af1a605cf5', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller that wont be\nrebooted. Will be used controller from which L3 router agent\nis removed.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}, {'number': 8, 'created': '2015-05-26 15:32:09.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/3b608bf2d8477803d48dffacbd0155f7f01c76ff', 'message': 'Fix Neutron L3 destructive tests by using proper SSH connection\n\nAfter a controller rebooted/destroyed, check_instance_connectivity\nshould use remote connetion to an online controller that wont be\nrebooted. Will be used controller from which L3 router agent\nis removed.\n\nChange-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384\nCloses-Bug:#1458020\n'}]",6,185125,3b608bf2d8477803d48dffacbd0155f7f01c76ff,59,14,8,11969,,,0,"Fix Neutron L3 destructive tests by using proper SSH connection

After a controller rebooted/destroyed, check_instance_connectivity
should use remote connetion to an online controller that wont be
rebooted. Will be used controller from which L3 router agent
is removed.

Change-Id: I19328dfd4bb8ffbf2035197395fa6c3067a01384
Closes-Bug:#1458020
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/25/185125/8 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_neutron.py'],1,12ddade6c65b83a80c3a1e8103b078eb5cd31eb8,bug/1458020,"# devops_node = self.env.d_env.nodes().slaves[0] # # _ip = self.fuel_web.get_nailgun_node_by_name(devops_node.name)['ip'] # remote = self.env.d_env.get_ssh_to_remote(_ip) remote = self.fuel_web.get_ssh_for_node(""slave-01"") # Wait for HA services ready self.fuel_web.assert_ha_services_ready(cluster_id) # Re-initialize SSHClient after slave-01 was rebooted remote.reconnect() # devops_node = self.env.d_env.nodes().slaves[0] # # _ip = self.fuel_web.get_nailgun_node_by_name(devops_node.name)['ip'] # remote = self.env.d_env.get_ssh_to_remote(_ip) remote = self.fuel_web.get_ssh_for_node(""slave-01"") # Wait for HA services ready self.fuel_web.assert_ha_services_ready(cluster_id) online_controllers_names = [n.name for n in set( self.env.d_env.nodes().slaves[:3]) - {new_devops}] self.fuel_web.wait_mysql_galera_is_up(online_controllers_names) # Re-initialize SSHClient for an online controller remote = self.fuel_web.get_ssh_for_node(online_controllers_names[0])", devops_node = self.env.d_env.nodes().slaves[0] _ip = self.fuel_web.get_nailgun_node_by_name(devops_node.name)['ip'] remote = self.env.d_env.get_ssh_to_remote(_ip) devops_node = self.env.d_env.nodes().slaves[0] _ip = self.fuel_web.get_nailgun_node_by_name(devops_node.name)['ip'] remote = self.env.d_env.get_ssh_to_remote(_ip) self.fuel_web.wait_mysql_galera_is_up( [n.name for n in set(self.env.d_env.nodes().slaves[:3]) - {new_devops}]),26,11
openstack%2Fmagnum~master~I5ed40bfb93f5246777643912de3e98bc3400bcab,openstack/magnum,master,I5ed40bfb93f5246777643912de3e98bc3400bcab,Use the status defined in bay object Status class,MERGED,2015-05-27 03:09:44.000000000,2015-05-27 10:23:04.000000000,2015-05-27 10:23:03.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 10206}, {'_account_id': 11650}, {'_account_id': 12175}, {'_account_id': 12927}]","[{'number': 1, 'created': '2015-05-27 03:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7fb60f82171dcf2fdfeaef6061b890fe80fb0530', 'message': ""Use the status defined in bay object Status class\n\nCurrently, we defined a status class in bay object file, it will be indicate\nthe bay's status(actually, it reuses heat's stack status), but we don't use\nStatus anywhere, this patch uses there status defined in Status.\n\nChange-Id: I5ed40bfb93f5246777643912de3e98bc3400bcab\n""}, {'number': 2, 'created': '2015-05-27 05:50:21.000000000', 'files': ['magnum/objects/bay.py', 'magnum/tests/unit/conductor/handlers/test_bay_conductor.py', 'magnum/conductor/handlers/bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b9b3b29f8e980c407b743d236643eece7771915b', 'message': ""Use the status defined in bay object Status class\n\nCurrently, we defined a status class in bay object file, it will be indicate\nthe bay's status(actually, it reuses heat's stack status), but we don't use\nStatus anywhere, this patch uses there status defined in Status.\n\nCloses-Bug: #1459104\nChange-Id: I5ed40bfb93f5246777643912de3e98bc3400bcab\n""}]",0,185831,b9b3b29f8e980c407b743d236643eece7771915b,14,6,2,12175,,,0,"Use the status defined in bay object Status class

Currently, we defined a status class in bay object file, it will be indicate
the bay's status(actually, it reuses heat's stack status), but we don't use
Status anywhere, this patch uses there status defined in Status.

Closes-Bug: #1459104
Change-Id: I5ed40bfb93f5246777643912de3e98bc3400bcab
",git fetch https://review.opendev.org/openstack/magnum refs/changes/31/185831/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/conductor/handlers/test_bay_k8s_heat.py', 'magnum/objects/bay.py', 'magnum/conductor/handlers/bay_k8s_heat.py']",3,7fb60f82171dcf2fdfeaef6061b890fe80fb0530,use_bay_status,"from magnum.objects.bay import Status as bay_status if (stack.stack_status != bay_status.CREATE_COMPLETE and stack.stack_status != bay_status.UPDATE_COMPLETE): if stack.stack_status == bay_status.DELETE_COMPLETE: if (stack.stack_status in [bay_status.CREATE_COMPLETE, bay_status.UPDATE_COMPLETE]): if stack.stack_status == bay_status.CREATE_FAILED: if stack.stack_status == bay_status.DELETE_FAILED: if stack.stack_status == bay_status.UPDATE_FAILED: if stack.stack_status == bay_status.CREATE_IN_PROGRESS:"," if (stack.stack_status != 'CREATE_COMPLETE' and stack.stack_status != 'UPDATE_COMPLETE'): if stack.stack_status == 'DELETE_COMPLETE': if (stack.stack_status in ['CREATE_COMPLETE', 'UPDATE_COMPLETE']): if stack.stack_status == 'CREATE_FAILED': if stack.stack_status == 'DELETE_FAILED': if stack.stack_status == 'UPDATE_FAILED': if stack.stack_status == 'CREATE_IN_PROGRESS':",37,34
openstack%2Fsahara-image-elements~master~I3a797e1a1a22e8f2c67d272449cdba94ab5c8df8,openstack/sahara-image-elements,master,I3a797e1a1a22e8f2c67d272449cdba94ab5c8df8,Save one fork,MERGED,2015-05-26 17:00:16.000000000,2015-05-27 10:22:13.000000000,2015-05-27 10:22:13.000000000,"[{'_account_id': 3}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 12038}]","[{'number': 1, 'created': '2015-05-26 17:00:16.000000000', 'files': ['elements/hadoop/post-install.d/firstboot'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/58156011f0f136d9fa07bd01fb526af9b02e5c49', 'message': 'Save one fork\n\nChanged \'cat file | grep smth\' to ""grep smth file""\n\nChange-Id: I3a797e1a1a22e8f2c67d272449cdba94ab5c8df8\n'}]",0,185666,58156011f0f136d9fa07bd01fb526af9b02e5c49,12,8,1,7125,,,0,"Save one fork

Changed 'cat file | grep smth' to ""grep smth file""

Change-Id: I3a797e1a1a22e8f2c67d272449cdba94ab5c8df8
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/66/185666/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/hadoop/post-install.d/firstboot'],1,58156011f0f136d9fa07bd01fb526af9b02e5c49,," until [[ -n $(grep ""$user:"" /etc/passwd) && -n $(grep ""$user:"" /etc/group) ]]; do"," until [[ -n $(grep ""$user:"" /etc/passwd) && -n $(cat /etc/group | grep ""$user:"") ]]; do",1,1
openstack%2Fhorizon~master~Ibbb20389fe61eda9ef8fab514bd4205de8621232,openstack/horizon,master,Ibbb20389fe61eda9ef8fab514bd4205de8621232,Imported Translations from Transifex,MERGED,2015-05-27 06:20:18.000000000,2015-05-27 10:22:04.000000000,2015-05-27 10:22:02.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9317}]","[{'number': 1, 'created': '2015-05-27 06:20:18.000000000', 'files': ['horizon/locale/pt/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/he/LC_MESSAGES/djangojs.po', 'horizon/locale/ka_GE/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/djangojs.po', 'horizon/locale/te_IN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/fi_FI/LC_MESSAGES/djangojs.po', 'horizon/locale/pl_PL/LC_MESSAGES/djangojs.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/hi/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'horizon/locale/ca/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e39b4ee7c375bacd2da8351067385789ea1b0f1d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibbb20389fe61eda9ef8fab514bd4205de8621232\n'}]",0,185848,e39b4ee7c375bacd2da8351067385789ea1b0f1d,10,5,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibbb20389fe61eda9ef8fab514bd4205de8621232
",git fetch https://review.opendev.org/openstack/horizon refs/changes/48/185848/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/pt/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/he/LC_MESSAGES/djangojs.po', 'horizon/locale/ka_GE/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/sr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/pa_IN/LC_MESSAGES/djangojs.po', 'horizon/locale/te_IN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/fi_FI/LC_MESSAGES/djangojs.po', 'horizon/locale/pl_PL/LC_MESSAGES/djangojs.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/hi/LC_MESSAGES/djangojs.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'horizon/locale/es/LC_MESSAGES/djangojs.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'horizon/locale/ca/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/djangojs.po']",54,e39b4ee7c375bacd2da8351067385789ea1b0f1d,transifex/translations,"""POT-Creation-Date: 2015-05-26 22:10-0500\n"" ""PO-Revision-Date: 2015-05-27 03:11+0000\n""#, c-format msgid ""%s GB"" msgstr ""%s GB"" #, c-format msgid ""%s MB"" msgstr ""%s MB"" #, c-format msgid ""%s TB"" msgstr ""%s TB"" #, c-format msgid ""%s KB"" msgstr ""%s KB"" #, c-format msgid ""Displaying %s item"" msgid_plural ""Displaying %s items"" msgstr[0] ""Zobrazena %s položka"" msgstr[1] ""Zobrazeny %s položky"" msgstr[2] ""Zobrazeno %s položek"" ","""POT-Creation-Date: 2015-05-07 20:21-0500\n"" ""PO-Revision-Date: 2015-05-07 18:03+0000\n""#, c-format msgid ""%s GB"" msgstr ""%s GB"" #, c-format msgid ""%s MB"" msgstr ""%s MB"" #, c-format msgid ""%s TB"" msgstr ""%s TB"" #, c-format msgid ""%s KB"" msgstr ""%s KB"" #, c-format msgid ""Displaying %s item"" msgid_plural ""Displaying %s items"" msgstr[0] ""Zobrazena %s položka"" msgstr[1] ""Zobrazeny %s položky"" msgstr[2] ""Zobrazeno %s položek"" ",1139,1358
openstack%2Ffuel-web~master~I8d528e77f37d521c575ae7bfad7759266c7e3b4c,openstack/fuel-web,master,I8d528e77f37d521c575ae7bfad7759266c7e3b4c,Rename NTP label under Settings tab,MERGED,2015-05-27 09:22:46.000000000,2015-05-27 10:19:44.000000000,2015-05-27 10:07:57.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-05-27 09:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c40ae0b7ac888a32ab3894dea8152eb10696c36d', 'message': 'Rename NTP label under Settings tab\n\nRename NTP label under Settings tab to be similar to DNS label\n\nChange-Id: I8d528e77f37d521c575ae7bfad7759266c7e3b4c\nCloses-Bug: 1459166\n'}, {'number': 2, 'created': '2015-05-27 09:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3bcd904b8a434309977c30395e42de75de2a1d9b', 'message': 'Rename NTP label under Settings tab\n\nRename NTP label under Settings tab to be similar to DNS label\n\nChange-Id: I8d528e77f37d521c575ae7bfad7759266c7e3b4c\nCloses-Bug: 1459166\n'}, {'number': 3, 'created': '2015-05-27 09:40:39.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f2ee9869463feac0d18da7647f4e43c4f4e6e65e', 'message': 'Rename NTP label under Settings tab\n\nRename NTP label under Settings tab to be similar to DNS label\n\nChange-Id: I8d528e77f37d521c575ae7bfad7759266c7e3b4c\nCloses-Bug: 1459166\n'}]",0,185897,f2ee9869463feac0d18da7647f4e43c4f4e6e65e,22,4,3,13344,,,0,"Rename NTP label under Settings tab

Rename NTP label under Settings tab to be similar to DNS label

Change-Id: I8d528e77f37d521c575ae7bfad7759266c7e3b4c
Closes-Bug: 1459166
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/97/185897/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,c40ae0b7ac888a32ab3894dea8152eb10696c36d,bug/1459166," label: ""DNS server list"" label: ""Host OS NTP Servers"""," label: ""DNS list"" label: ""Upstream NTP""",2,2
openstack%2Fopenstack-ansible~kilo~I7daa76e601a1bf430765866c1e4c0b8f9638aa73,openstack/openstack-ansible,kilo,I7daa76e601a1bf430765866c1e4c0b8f9638aa73,Removed memcached log directory task,MERGED,2015-05-26 22:56:06.000000000,2015-05-27 10:13:36.000000000,2015-05-27 10:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 7414}]","[{'number': 1, 'created': '2015-05-26 22:56:06.000000000', 'files': ['playbooks/roles/memcached_server/tasks/memcached_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a992a63d8a65d27b1400a2d9801d178cf0a217bc', 'message': 'Removed memcached log directory task\n\nThe memcached play has a log directory task that will cause an issue\nwith permissions with a container where memcached is installed. To\nsolve this issue the log directory permissions change task needs to\nbe removed\n\nChange-Id: I7daa76e601a1bf430765866c1e4c0b8f9638aa73\nCloses-Bug: 1459039\n(cherry picked from commit ca9cbb8f8ff2f3bfb96f96ae3c2cbd5300fe3348)\n'}]",0,185776,a992a63d8a65d27b1400a2d9801d178cf0a217bc,12,5,1,7353,,,0,"Removed memcached log directory task

The memcached play has a log directory task that will cause an issue
with permissions with a container where memcached is installed. To
solve this issue the log directory permissions change task needs to
be removed

Change-Id: I7daa76e601a1bf430765866c1e4c0b8f9638aa73
Closes-Bug: 1459039
(cherry picked from commit ca9cbb8f8ff2f3bfb96f96ae3c2cbd5300fe3348)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/76/185776/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/memcached_server/tasks/memcached_pre_install.yml'],1,a992a63d8a65d27b1400a2d9801d178cf0a217bc,,," - name: Ensure memcached directories file: path: ""{{ item }}"" state: ""directory"" owner: ""root"" group: ""root"" with_items: - ""{{ memcached_log | dirname }}"" tags: - memcached-dirs",0,11
openstack%2Fpuppet-keystone~master~I6acc21a638218e56fd4f7271937c41db543b61d3,openstack/puppet-keystone,master,I6acc21a638218e56fd4f7271937c41db543b61d3,Congiguring memcache_pool per,ABANDONED,2014-12-10 18:41:10.000000000,2015-05-27 10:07:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 8482}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-12-10 18:41:10.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/f07b151bc580e9d67ba4d04e5f14bb612eb574c3', 'message': 'Congiguring memcache_pool per\n\nhttps://git.openstack.org/cgit/openstack/keystone/commit/?id=0010803288748fcd3ce7dba212a54bffe7a61a0c\n\nChange-Id: I6acc21a638218e56fd4f7271937c41db543b61d3\n'}]",4,140801,f07b151bc580e9d67ba4d04e5f14bb612eb574c3,6,4,1,11090,,,0,"Congiguring memcache_pool per

https://git.openstack.org/cgit/openstack/keystone/commit/?id=0010803288748fcd3ce7dba212a54bffe7a61a0c

Change-Id: I6acc21a638218e56fd4f7271937c41db543b61d3
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/01/140801/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,f07b151bc580e9d67ba4d04e5f14bb612eb574c3,memcache_pool," 'cache/enabled': value => true; 'cache/backend': value => $cache_backend; 'cache/debug_cache_backend': value => $debug_cache_backend; } if $cache_backend =~ /memcache_pool/ { keystone_config { 'cache/memcache_servers': value => join($memcache_servers, ','); 'token/caching': value => 'false'; 'memcache/servers': ensure => absent; } } else { keystone_config { 'token/caching': value => 'true'; 'memcache/servers': value => join($memcache_servers, ','); }"," 'cache/enabled': value => true; 'cache/backend': value => $cache_backend; 'cache/debug_cache_backend': value => $debug_cache_backend; 'token/caching': value => $token_caching; 'memcache/servers': value => join($memcache_servers, ',');",36,9
openstack%2Ffuel-ostf~master~I215937cd058adb66ac6e573601490791dad5eb4a,openstack/fuel-ostf,master,I215937cd058adb66ac6e573601490791dad5eb4a,Using muranoclient for obtain package list,MERGED,2015-05-25 18:26:41.000000000,2015-05-27 10:04:26.000000000,2015-05-27 10:01:35.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13454}, {'_account_id': 13962}, {'_account_id': 14510}, {'_account_id': 14614}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-05-25 18:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/536f4636a6a94d8a748e0e7b4285c3e618785ef0', 'message': 'Using muranoclient for obtain package list\n\nFixes incorrect logic of get_list_packages function in tests.\nNow for obpaining package list in tests will be used muranoclient\ninstead of requests library.\n\nChange-Id: I215937cd058adb66ac6e573601490791dad5eb4a\nCloses-Bug: #1458646\n'}, {'number': 2, 'created': '2015-05-25 18:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/6f456e898547d18e7645c68d9c1ff20229947840', 'message': 'Using muranoclient for obtain package list\n\nFixes incorrect logic of get_list_packages function in tests.\nNow for obpaining package list in tests will be used muranoclient\ninstead of requests library.\n\nChange-Id: I215937cd058adb66ac6e573601490791dad5eb4a\nCloses-Bug: #1458646\n'}, {'number': 3, 'created': '2015-05-25 18:33:43.000000000', 'files': ['fuel_health/muranomanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/3a320afbe94d6ebc88b569e25d21ad648c382623', 'message': 'Using muranoclient for obtain package list\n\nFixes incorrect logic of get_list_packages function in tests.\nNow for obtaining package list in tests will be used muranoclient\ninstead of requests library.\n\nChange-Id: I215937cd058adb66ac6e573601490791dad5eb4a\nCloses-Bug: #1458646\n'}]",0,185439,3a320afbe94d6ebc88b569e25d21ad648c382623,27,13,3,13962,,,0,"Using muranoclient for obtain package list

Fixes incorrect logic of get_list_packages function in tests.
Now for obtaining package list in tests will be used muranoclient
instead of requests library.

Change-Id: I215937cd058adb66ac6e573601490791dad5eb4a
Closes-Bug: #1458646
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/39/185439/2 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/muranomanager.py'],1,536f4636a6a94d8a748e0e7b4285c3e618785ef0,bug/1458646," try: packages = self.murano_client.packages.list() except exceptions.ClientException: self.fail(""Can not get list of packages"") packages_list = list(packages) LOG.debug('Packages List: {0}'.format(packages_list)) self.assertIsInstance(packages_list, list) return packages_list def generate_fqn_list(self): fqn_list = [] packages = self.get_list_packages() LOG.debug('Packages list: {0}'.format(packages)) for package in packages: fqn_list.append(package.to_dict()['fully_qualified_name']) LOG.debug('FQN List: {0}'.format(fqn_list)) return fqn_list fqn_list = self.generate_fqn_list() LOG.debug(""Response for packages is {0}"".format(fqn_list)) for package in packages: if package not in fqn_list:"," resp = requests.get(self.endpoint + 'catalog/packages', headers=self.headers) self.assertEqual(200, resp.status_code) self.assertIsInstance(resp.json()['packages'], list) resp = requests.get(self.endpoint + 'catalog/packages', headers=self.headers) LOG.debug(""Response for packages is {0}"".format(resp.text)) for package in packages: if package not in resp.text:",19,8
openstack%2Ffuel-ostf~master~Icd367e5ce0dd44c060078bb81142b4ec5a1f5085,openstack/fuel-ostf,master,Icd367e5ce0dd44c060078bb81142b4ec5a1f5085,Add retries to connectivity check,MERGED,2015-05-27 08:49:59.000000000,2015-05-27 10:02:24.000000000,2015-05-27 10:00:09.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7428}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2015-05-27 08:49:59.000000000', 'files': ['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_health/tests/smoke/test_live_migration.py', 'fuel_health/tests/smoke/test_neutron_actions.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b42f9d0bac74d3a0a7994adcd1aca86563d0d42b', 'message': 'Add retries to connectivity check\n\nAdd retries for connectivity check\nIncrease timeouts for removal floating ips\n\nChange-Id: Icd367e5ce0dd44c060078bb81142b4ec5a1f5085\nCloses-Bug: #1458804\n'}]",0,185887,b42f9d0bac74d3a0a7994adcd1aca86563d0d42b,13,6,1,6719,,,0,"Add retries to connectivity check

Add retries for connectivity check
Increase timeouts for removal floating ips

Change-Id: Icd367e5ce0dd44c060078bb81142b4ec5a1f5085
Closes-Bug: #1458804
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/87/185887/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_health/tests/smoke/test_live_migration.py', 'fuel_health/tests/smoke/test_neutron_actions.py']",3,b42f9d0bac74d3a0a7994adcd1aca86563d0d42b,add_retries_to_connectivity_check," self.verify(20, self._assign_floating_ip_to_instance, self.verify(600, self._check_vm_connectivity, 9, 30, (9, 60)) self.verify(600, self._check_connectivity_from_vm, 30, (9, 60)) self.verify(20, self.compute_client.servers.remove_floating_ip, self.verify(20, self.compute_client.floating_ips.delete, self.verify(40, self._delete_server, 13,"," self.verify(10, self._assign_floating_ip_to_instance, self.verify(400, self._check_vm_connectivity, 9, 30, (6, 60)) self.verify(400, self._check_connectivity_from_vm, 30, (6, 60)) self.verify(10, self.compute_client.servers.remove_floating_ip, self.verify(10, self.compute_client.floating_ips.delete, self.verify(30, self._delete_server, 13,",24,24
openstack%2Fsecurity-doc~master~Iac71b5acfb3fdd8556316a3f316fa91c6a876d69,openstack/security-doc,master,Iac71b5acfb3fdd8556316a3f316fa91c6a876d69,Broke dashboard chapeter into section_ files,MERGED,2015-05-23 19:59:01.000000000,2015-05-27 10:00:29.000000000,2015-05-27 10:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10281}, {'_account_id': 10497}, {'_account_id': 10670}, {'_account_id': 12325}, {'_account_id': 12442}, {'_account_id': 12686}, {'_account_id': 15299}]","[{'number': 1, 'created': '2015-05-23 19:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/ac80731de3071b36f7cc11d97a45716497206081', 'message': 'Broke dashboard chapeter into section_ files\n\nChange-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69\nCloses-Bug: #1458022\n'}, {'number': 2, 'created': '2015-05-23 21:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/87272935e3886456c7c6e4b83c88329782e01e88', 'message': 'Broke dashboard chapeter into section_ files\n\nChange-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69\nCloses-Bug: #1458022\n'}, {'number': 3, 'created': '2015-05-24 09:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/379e56038be1d6cb796ab7444221cf523e9cff93', 'message': 'Broke dashboard chapeter into section_ files\n\nChange-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69\nCloses-Bug: #1458022\n'}, {'number': 4, 'created': '2015-05-24 10:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5b92317ba2b673fa206215e7d2d89f8a4e3f1d41', 'message': 'Broke dashboard chapeter into section_ files\n\nChange-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69\nCloses-Bug: #1458022\n'}, {'number': 5, 'created': '2015-05-26 10:38:47.000000000', 'files': ['security-guide/section_dashboard-cookies.xml', 'security-guide/section_dashboard-basic-web-server-configuration.xml', 'security-guide/section_dashboard-domain-names.xml', 'security-guide/section_dashboard-cross-site-scripting-xss.xml', 'security-guide/section_dashboard-secret-key.xml', 'security-guide/section_dashboard-horizon-image-upload.xml', 'security-guide/section_dashboard-static-media.xml', 'security-guide/section_dashboard-https.xml', 'security-guide/section_dashboard-debug.xml', 'security-guide/ch_dashboard.xml', 'security-guide/section_dashboard-http-strict-transport-security-hsts.xml', 'security-guide/section_dashboard-session-back-end.xml', 'security-guide/section_dashboard-front-end-caching.xml', 'security-guide/section_dashboard-cross-origin-resource-sharing-cors.xml', 'security-guide/section_dashboard-cross-site-request-forgery-csrf.xml', 'security-guide/section_dashboard-allowed-hosts.xml', 'security-guide/section_dashboard-upgrading.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/fd488ce01ed8d1f9269f95b36a68c5d794ca63ff', 'message': 'Broke dashboard chapeter into section_ files\n\nChange-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69\nCloses-Bug: #1458022\n'}]",0,185241,fd488ce01ed8d1f9269f95b36a68c5d794ca63ff,21,10,5,15299,,,0,"Broke dashboard chapeter into section_ files

Change-Id: Iac71b5acfb3fdd8556316a3f316fa91c6a876d69
Closes-Bug: #1458022
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/41/185241/2 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/ch_dashboard.xml', 'security-guide/section_dashboard-basic-web-server-configuration.xml', 'security-guide/section_dashboard-https.xml']",3,ac80731de3071b36f7cc11d97a45716497206081,1458022,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""dashboard-https""> <?dbhtml stop-chunking?> <title>HTTPS</title> <para> Deploy the dashboard behind a secure <glossterm>HTTPS</glossterm> server by using a valid, trusted certificate from a recognized certificate authority (CA). Private organization-issued certificates are only appropriate when the root of trust is pre-installed in all user browsers.</para> <para>Configure HTTP requests to the dashboard domain to redirect to the fully qualified HTTPS URL.</para> <section xml:id=""dashboard-http-strict-transport-security-hsts""> <title>HTTP Strict Transport Security (HSTS)</title> <para>It is highly recommended to use HTTP Strict Transport Security (HSTS).</para> <note> <para>If you are using an HTTPS proxy in front of your web server, rather than using an HTTP server with HTTPS functionality, modify the <literal>SECURE_PROXY_SSL_HEADER</literal> variable. Refer to the <link xlink:href=""https://docs.djangoproject.com/"" >Django documentation</link> for information about modifying the <literal>SECURE_PROXY_SSL_HEADER</literal> variable.</para> </note> <para>See the chapter on PKI/SSL Everywhere for more specific recommendations and server configurations for HTTPS configurations, including the configuration of HSTS.</para> </section> <section xml:id=""dashboard-front-end-caching""> <title>Front end caching</title> <para>Since the dashboard is rendering dynamic content passed directly from OpenStack API requests, we do not recommend front end caching layers such as varnish. In Django, static media is directly served from Apache or nginx and already benefits from web host caching.</para> </section> <section xml:id=""dashboard-domain-names""> <title>Domain names</title> <para>Many organizations typically deploy web applications at subdomains of an overarching organization domain. It is natural for users to expect a domain of the form <uri>openstack.example.org</uri>. In this context, there are often many other applications deployed in the same second-level namespace, often serving user-controlled content. This name structure is convenient and simplifies name server maintenance.</para> <para>We strongly recommend deploying horizon to a <emphasis>second-level domain</emphasis>, such as <uri>https://example.com</uri>, and advise against deploying horizon on a <emphasis>shared subdomain</emphasis> of any level, for example <uri>https://openstack.example.org</uri> or <uri>https://horizon.openstack.example.org</uri>. We also advise against deploying to bare internal domains like <uri>https://horizon/</uri>. These recommendations are based on the limitations of browser same-origin-policy.</para> <para>Recommendations given in this guide cannot effectively guard against known attacks if you deploy the dashboard in a domain that also hosts user-generated content, even when this content resides on a separate sub-domain. User-generated content can consist of scripts, images, or uploads of any type. Most major web presences, including googleusercontent.com, fbcdn.com, github.io, and twimg.co, use this approach to segregate user-generated content from cookies and security tokens.</para> <para>If you do not follow this recommendation regarding second-level domains, avoid a cookie-backed session store and employ HTTP Strict Transport Security (HSTS). When deployed on a subdomain, the dashboard's security is equivalent to the least secure application deployed on the same second-level domain.</para> </section> <section xml:id=""dashboard-static-media""> <title>Static media</title> <para>The dashboard's static media should be deployed to a subdomain of the dashboard domain and served by the web server. The use of an external content delivery network (CDN) is also acceptable. This subdomain should not set cookies or serve user-provided content. The media should also be served with HTTPS.</para> <para>Django media settings are documented in the <link xlink:href=""https://docs.djangoproject.com/"" >Django documentation</link>.</para> <para>Dashboard's default configuration uses <link xlink:href=""http://django-compressor.readthedocs.org/"" >django_compressor</link> to compress and minify CSS and JavaScript content before serving it. This process should be statically done before deploying the dashboard, rather than using the default in-request dynamic compression and copying the resulting files along with deployed code or to the CDN server. Compression should be done in a non-production build environment. If this is not practical, we recommend disabling resource compression entirely. Online compression dependencies (less, Node.js) should not be installed on production machines.</para> </section> <section xml:id=""dashboard-secret-key""> <title>Secret key</title> <para>The dashboard depends on a shared <option>SECRET_KEY</option> setting for some security functions. The secret key should be a randomly generated string at least 64 characters long, which must be shared across all active dashboard instances. Compromise of this key may allow a remote attacker to execute arbitrary code. Rotating this key invalidates existing user sessions and caching. Do not commit this key to public repositories.</para> </section> <section xml:id=""dashboard-session-back-end""> <title>Session back end</title> <para>Horizon's default session back end (<literal>django.contrib.sessions.backends.signed_cookies</literal>) stores user data in <emphasis>signed</emphasis> but <emphasis>unencrypted </emphasis>cookies stored in the browser. This approach allows the most simple session back-end scaling since each dashboard instance is stateless, but it comes at the cost of <emphasis>storing sensitive access tokens in the client browser</emphasis> and transmitting them with every request. This back end ensures that session data has not been tampered with, but the data itself is not encrypted other than the encryption provided by HTTPS.</para> <para>If your architecture allows it, we recommend using <literal>django.contrib.sessions.backends.cache</literal> as your session back end with memcache as the cache. Memcache must not be exposed publicly, and should communicate over a secured private channel. If you choose to use the signed cookies back end, refer to the Django documentation understand the security trade-offs.</para> <para>For further details, see the <link xlink:href=""https://docs.djangoproject.com/"" >Django documentation</link>.</para> </section> <section xml:id=""dashboard-allowed-hosts""> <title>Allowed hosts</title> <para>Configure the <option>ALLOWED_HOSTS</option> setting with the domain or domains where the dashboard is available. Failure to configure this setting (especially if not following the recommendation above regarding second level domains) opens the dashboard to a number of serious attacks. Wild card domains should be avoided.</para> <para>For further details, see the <link xlink:href=""https://docs.djangoproject.com/"" >Django documentation</link>.</para> </section> <section xml:id=""dashboard-cross-site-request-forgery-csrf""> <title>Cross Site Request Forgery (CSRF)</title> <para>Django has dedicated middleware for cross-site request forgery (CSRF). For further details, see the <link xlink:href=""https://docs.djangoproject.com/""> Django documentation</link>.</para> <para>Dashboard is designed to discourage developers from introducing cross-site scripting vulnerabilities with custom dashboards. However, it is important to audit custom dashboards, especially ones that are JavaScript-heavy for inappropriate use of the <literal>@csrf_exempt</literal> decorator. Dashboards which do not follow these recommended security settings should be carefully evaluated before restrictions are relaxed.</para> </section> <section xml:id=""dashboard-cookies""> <title>Cookies</title> <para>Session Cookies should be set to HTTPONLY:</para> <programlisting>SESSION_COOKIE_HTTPONLY = True</programlisting> <para>Never configure CSRF or session cookies to have a wild card domain with a leading dot. Horizon's session and CSRF cookie should be secured when deployed with HTTPS:</para> <programlisting>CSRF_COOKIE_SECURE = True SESSION_COOKIE_SECURE = True</programlisting> </section> <section xml:id=""dashboard-cross-site-scripting-xss""> <title>Cross Site Scripting (XSS)</title> <para>Unlike many similar systems, the OpenStack dashboard allows the entire Unicode character set in most fields. This means developers have less latitude to make escaping mistakes that open attack vectors for cross-site scripting (XSS).</para> <para>Dashboard provides tools for developers to avoid creating XSS vulnerabilities, but they only work if developers use them correctly. Audit any custom dashboards, paying particular attention to use of the <literal>mark_safe</literal> function, use of <literal>is_safe</literal> with custom template tags, the <literal>safe</literal> template tag, anywhere auto escape is turned off, and any JavaScript which might evaluate improperly escaped data.</para> </section> <section xml:id=""dashboard-cross-origin-resource-sharing-cors""> <title>Cross Origin Resource Sharing (CORS)</title> <para>Configure your web server to send a restrictive CORS header with each response, allowing only the dashboard domain and protocol:</para> <programlisting>Access-Control-Allow-Origin: https://example.com/</programlisting> <para>Never allow the wild card origin.</para> </section> <section xml:id=""dashboard-horizon-image-upload""> <title>Horizon image upload</title> <para>We recommend that implementers <link xlink:href=""http://docs.openstack.org/developer/horizon/topics/deployment.html#file-uploads"" >disable HORIZON_IMAGES_ALLOW_UPLOAD</link> unless they have implemented a plan to prevent resource exhaustion and denial of service.</para> </section> <section xml:id=""dashboard-upgrading""> <title>Upgrading</title> <para>Django security releases are generally well tested and aggressively backwards compatible. In almost all cases, new major releases of Django are also fully backwards compatible with previous releases. Dashboard implementers are strongly encouraged to run the latest stable release of Django with up-to-date security releases.</para> </section> <section xml:id=""dashboard-debug""> <title>Debug</title> <para>We recommend that the <option>DEBUG</option> setting is set to <literal>False</literal> in production environments. If <option>DEBUG</option> is set to True, Django will display stack traces and sensitive web server state information when exceptions are thrown.</para> </section> </section>",,238,224
openstack%2Fsecurity-doc~master~I6539286d0a6344e2a8f41f48b06870354d29e7d0,openstack/security-doc,master,I6539286d0a6344e2a8f41f48b06870354d29e7d0,Fix malformed sentence in security-guide,MERGED,2015-04-28 00:46:01.000000000,2015-05-27 09:56:54.000000000,2015-05-27 09:56:53.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10670}, {'_account_id': 12325}, {'_account_id': 12442}, {'_account_id': 14920}, {'_account_id': 15804}]","[{'number': 1, 'created': '2015-04-28 00:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/8baebfbf46ec321f7d5f0a2ec8c8405c1792aa84', 'message': 'Fix malformed sentence in security-guide\n\nUpdated note under ""Networking resource policy engine""\nto correct the malformed sentence in the\nsection_networking-services-security-best-practices.xml file\n\nChange-Id: I6539286d0a6344e2a8f41f48b06870354d29e7d0\nCloses-Bug: #1447769\nCo-Authored-By: Shellee Aragon <shellee.arnold@hp.com>\n'}, {'number': 2, 'created': '2015-05-11 22:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e845688e995b1f18d98d57d024e026c79045da22', 'message': 'Fix malformed sentence in security-guide\n\nUpdated note under ""Networking resource policy engine""\nto correct the malformed sentence in the\nsection_networking-services-security-best-practices.xml file\n\nChange-Id: I6539286d0a6344e2a8f41f48b06870354d29e7d0\nCloses-Bug: #1447769\nCo-Authored-By: Shellee Aragon <shellee.arnold@hp.com>\n'}, {'number': 3, 'created': '2015-05-21 22:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/29d9cf387a9cf93f669efe009e9400cd09068337', 'message': 'Fix malformed sentence in security-guide\n\nUpdated note under ""Networking resource policy engine""\nto correct the malformed sentence in the\nsection_networking-services-security-best-practices.xml file\n\nChange-Id: I6539286d0a6344e2a8f41f48b06870354d29e7d0\nCloses-Bug: #1447769\nCo-Authored-By: Shellee Aragon <shellee.arnold@hp.com>\n'}, {'number': 4, 'created': '2015-05-22 13:42:29.000000000', 'files': ['security-guide/section_networking-services-security-best-practices.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/62850cd05ef40706fc908c97d7917d3a687ef8a2', 'message': 'Fix malformed sentence in security-guide\n\nUpdated note under ""Networking resource policy engine""\nto correct the malformed sentence in the\nsection_networking-services-security-best-practices.xml file\n\nChange-Id: I6539286d0a6344e2a8f41f48b06870354d29e7d0\nCloses-Bug: #1447769\nCo-Authored-By: Shellee Aragon <shellee.arnold@hp.com>\n'}]",3,178014,62850cd05ef40706fc908c97d7917d3a687ef8a2,26,8,4,14920,,,0,"Fix malformed sentence in security-guide

Updated note under ""Networking resource policy engine""
to correct the malformed sentence in the
section_networking-services-security-best-practices.xml file

Change-Id: I6539286d0a6344e2a8f41f48b06870354d29e7d0
Closes-Bug: #1447769
Co-Authored-By: Shellee Aragon <shellee.arnold@hp.com>
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/14/178014/4 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/section_networking-services-security-best-practices.xml'],1,8baebfbf46ec321f7d5f0a2ec8c8405c1792aa84,bug/1447769, <note><para>Review and modification of the default networking resource policy should be performed to adequately assimilate the organization’s security posture.</para></note>, <note><para>It is important to review the default networking resource policy and modify the policy appropriately for your security posture.</para></note>,3,3
openstack%2Fneutron~master~I5204782eeef4b84285142ad4b67e9a9376193455,openstack/neutron,master,I5204782eeef4b84285142ad4b67e9a9376193455,Document the testing effort on OpenFlow stateful firewalling,ABANDONED,2015-02-27 13:48:08.000000000,2015-05-27 09:54:50.000000000,,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 7987}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9444}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10387}, {'_account_id': 11114}, {'_account_id': 11307}, {'_account_id': 11785}, {'_account_id': 12040}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15070}, {'_account_id': 15289}]","[{'number': 1, 'created': '2015-02-27 13:48:08.000000000', 'files': ['doc/source/index.rst', 'doc/source/testing/index.rst', 'doc/source/testing/openflow-firewall.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/62941afdf9923c148d0d84a2de03bea014c3e5d3', 'message': 'Document the testing effort on OpenFlow stateful firewalling\n\nThis patch introduces the testing directory and a proposed\narchitecture for testing OpenFlow stateful firewalling vs\nthe current iptables based firewall which combines\nOVS+LB+iptables+ipsets.\n\nChange-Id: I5204782eeef4b84285142ad4b67e9a9376193455\n'}]",16,159840,62941afdf9923c148d0d84a2de03bea014c3e5d3,36,30,1,8788,,,0,"Document the testing effort on OpenFlow stateful firewalling

This patch introduces the testing directory and a proposed
architecture for testing OpenFlow stateful firewalling vs
the current iptables based firewall which combines
OVS+LB+iptables+ipsets.

Change-Id: I5204782eeef4b84285142ad4b67e9a9376193455
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/159840/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/testing/index.rst', 'doc/source/testing/openflow-firewall.rst']",3,62941afdf9923c148d0d84a2de03bea014c3e5d3,openflow-stateful-firewalling,"============================== OpenFlow based security groups ============================== The current implementation of the reference driver security groups relies in LinuxBridge + iptables, which are combined with Openvswitch bridges and veths when the ML2/OVS mechanism driver is used. LB + Iptables is currently neccesary to avoid an excesive push of rules when providing stateful firewalling (RELATED + ESTABLISHED connections). `Future features of OVS`_ are going to allow the solid and proven linux connection tracking to be mixed into OpenFlow rules. .. _Future features of OVS: https://github.com/justinpettit/ovs/commits/conntrack The purpose of this test is to evaluate the performance gains of the solution and the scalability implications before starting a new OpenFlow firewall driver. Conditions to be benchmarked ============================ - Initial connection establishment time - Max throughput - Max pps And how those are impacted the next variables: - Number of filtering rules - Number of security group IPs - Size of packets - Going through external network, or in a single host. The last line is important, since processor caching can make differences on the performance when in a single host, yet, that's a valid test since VM's can communicate to each other within a single host. Architecture composition ======================== Please, be aware that any br-tun, br-ex or provider bridge has been removed from the architecture, as that would introduce unnecesary overhead to the test measurements. OVS+LB+iptables --------------- This architecture should mimic with precission how ovs+iptables_firewall builds on OVS + linuxbridge + iptables to provide security groups, providing two endpoints to perform the testing. :: (remote-port)<-->[(remote-veth) in ns-remote] | tag:1 ovs/br-int | network | ovs/br-int | tag:1 (filt-port)<---->(lb-filtport) | qbr-test (linux bridge) | (tap-port) <-- iptables+ipset rules | [(filtered-veth) in ns-filtered] OVS+CT ------ This architecture should provide the same exact functionality as the previous one, but making use of OpenFlow and openvswitch bridges. :: (remote-port)<-->[(remote-veth) in ns-remote] | tag:1 ovs/br-int | network | ovs/br-int <- OpenFlow rules | tag:1 (filt-port)<---->[(filtered-veth) in ns-filtered] Other considerations ==================== We should not only think in performance terms, scalability should also be considered if we believe implementation makes sense. For example, the way we update security group members, or insert and remove OpenFlow rules can heavily influence how the solution performs at scale. OpenFlow rule manipulation via command line may be avoided, and instead make agents act as an OpenFlow controller manipulating them via the OpenFlow protocol. Security group ip lists should be coalesced into conjunctive OpenFlow rules. ",,131,0
openstack%2Fopenstack-doc-tools~master~I5e58d60e2308d208e850f903559da5f5a6a949e3,openstack/openstack-doc-tools,master,I5e58d60e2308d208e850f903559da5f5a6a949e3,autohelp: generate rst tables,MERGED,2015-05-22 16:25:21.000000000,2015-05-27 09:54:25.000000000,2015-05-27 09:54:24.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-05-22 16:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b756bd4b884084f31823890e860d44edfdad9a4b', 'message': 'autohelp: generate rst tables\n\nWe are mmoving the guides to RST, so we need config-reference tables in\nthis format. This patch adds a `rst` subcommand to autohelp.py to handle\nthis new requirement.\n\nRST has limited tables-related features, and openstackdocstheme will\nneed an update to improve the output.\n\nChange-Id: I5e58d60e2308d208e850f903559da5f5a6a949e3\n'}, {'number': 2, 'created': '2015-05-22 16:44:51.000000000', 'files': ['autogenerate_config_docs/autohelp.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b455d12bfba5099d355d7d6ff583fe619ad2eef5', 'message': 'autohelp: generate rst tables\n\nWe are mmoving the guides to RST, so we need config-reference tables in\nthis format. This patch adds a `rst` subcommand to autohelp.py to handle\nthis new requirement.\n\nRST has limited tables-related features, and openstackdocstheme will\nneed an update to improve the output.\n\nChange-Id: I5e58d60e2308d208e850f903559da5f5a6a949e3\n'}]",0,185062,b455d12bfba5099d355d7d6ff583fe619ad2eef5,12,4,2,7923,,,0,"autohelp: generate rst tables

We are mmoving the guides to RST, so we need config-reference tables in
this format. This patch adds a `rst` subcommand to autohelp.py to handle
this new requirement.

RST has limited tables-related features, and openstackdocstheme will
need an update to improve the output.

Change-Id: I5e58d60e2308d208e850f903559da5f5a6a949e3
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/62/185062/1 && git format-patch -1 --stdout FETCH_HEAD,['autogenerate_config_docs/autohelp.py'],1,b756bd4b884084f31823890e860d44edfdad9a4b,rst-tables,"BASE_RST = ''' .. list-table:: Description of %(nice_cat)s configuration options :header-rows: 1 :widths: 100 100 :class: config-ref-table ''' NEW_GROUP_RST = ''' .. list-table:: :header-rows: 1 :widths: 100 100 :class: config-ref-table '''def _get_options_by_cat(package_name): return options_by_cat def _get_category_names(package_name): return category_names def write_docbook(package_name, options, target, verbose=0): """"""Write DocBook tables. Prints a docbook-formatted table for every group of options. """""" target = target or '../../doc/common/tables/' options_by_cat = _get_options_by_cat(package_name) category_names = _get_category_names(package_name) def write_rst(package_name, options, target, verbose=0): """"""Write RST tables. Prints an RST-formatted table for every group of options. """""" target = target or '../../doc/common/tables/rst/' options_by_cat = _get_options_by_cat(package_name) category_names = _get_category_names(package_name) if not os.path.isdir(target): os.makedirs(target) for cat in options_by_cat.keys(): if cat in category_names: nice_cat = category_names[cat] else: nice_cat = cat print(""No nicename for %s"" % cat) rst_table = (BASE_RST % {'pkg': package_name, 'cat': cat, 'nice_cat': nice_cat}) curgroup = None for optname in options_by_cat[cat]: group, option = options.get_option(optname) if group != curgroup: if curgroup is not None: rst_table += NEW_GROUP_RST rst_table += ' * - **[%s]**\n -\n' % group curgroup = group if not option.help: option.help = ""No help text available for this option."" default = _sanitize_default(option) option_text = ""%s = %s"" % (option.dest, default) option_text = ""``%s``"" % option_text.strip() option_help = ""(%s) %s"" % (type(option).__name__, option.help.strip()) rst_table += "" * - %s\n - %s\n"" % (option_text, option_help) file_path = (""%(target)s/%(package_name)s-%(cat)s.rst"" % {'target': target, 'package_name': package_name, 'cat': cat}) with open(file_path, 'w') as fd: fd.write(rst_table) choices=['create', 'update', 'docbook', 'rst', 'dump']) elif args.subcommand == 'rst': write_rst(package_name, options, args.target, verbose=args.verbose) ","def write_docbook(package_name, options, target, verbose=0): """"""Write DocBook tables. Prints a docbook-formatted table for every group of options. """""" target = target or '../../doc/common/tables/' choices=['create', 'update', 'docbook', 'dump'])",84,7
openstack%2Fha-guide~master~Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c,openstack/ha-guide,master,Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c,Updated from openstack-manuals,MERGED,2015-05-22 23:18:33.000000000,2015-05-27 09:53:32.000000000,2015-05-27 09:53:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 11444}]","[{'number': 1, 'created': '2015-05-22 23:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e03d6c2aa04f102f0da2b9bc32b811a200044bdb', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c\n'}, {'number': 2, 'created': '2015-05-25 07:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/9940bf8ef7c2d2cbebbd2c504be2b26f65876111', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c\n'}, {'number': 3, 'created': '2015-05-26 10:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/db9650e78e0004ef0e46a998e148da1f27bb02c8', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c\n'}, {'number': 4, 'created': '2015-05-26 18:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/97028b215d93b957061d7ca34d4ab186bcb7fa06', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c\n'}, {'number': 5, 'created': '2015-05-27 08:37:02.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/cb4ff6e090f22dcb551cfda33782e9cc3ae5b5d3', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c\n'}]",0,185188,cb4ff6e090f22dcb551cfda33782e9cc3ae5b5d3,16,3,5,11131,,,0,"Updated from openstack-manuals

Change-Id: Iff0ab3eb4452bc4764da5e5a7f8d2923bf3ba67c
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/88/185188/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,e03d6c2aa04f102f0da2b9bc32b811a200044bdb,openstack/openstack-manuals,"""POT-Creation-Date: 2015-05-22 00:23+0000\n"" ""PO-Revision-Date: 2015-05-21 23:00+0000\n""msgid ""barbican"" msgstr ""barbican"" msgid ""rally"" msgstr ""rally"" msgid ""congress"" msgstr ""congress"" msgid ""Cross-Origin Resource Sharing (CORS)"" msgstr ""Cross-Origin Resource Sharing (CORS)"" msgid ""Database service"" msgstr ""Database サービス"" msgid ""Data processing service"" msgstr ""Data processing サービス"" msgid ""DNS service"" msgstr ""DNS サービス"" msgid ""magnetoDB"" msgstr ""magnetoDB"" ","""POT-Creation-Date: 2015-05-15 19:06+0000\n"" ""PO-Revision-Date: 2015-05-15 13:32+0000\n""",26,2
openstack%2Foperations-guide~master~I5eb8a336d7ead112fd029a88a06e38d6cd30ad30,openstack/operations-guide,master,I5eb8a336d7ead112fd029a88a06e38d6cd30ad30,Updated from openstack-manuals,MERGED,2015-05-27 08:37:07.000000000,2015-05-27 09:52:30.000000000,2015-05-27 09:52:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-27 08:37:07.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/f26e2d84fc46b4caba416f497a5ba6e514d123c9', 'message': 'Updated from openstack-manuals\n\nChange-Id: I5eb8a336d7ead112fd029a88a06e38d6cd30ad30\n'}]",0,185880,f26e2d84fc46b4caba416f497a5ba6e514d123c9,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I5eb8a336d7ead112fd029a88a06e38d6cd30ad30
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/80/185880/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,f26e2d84fc46b4caba416f497a5ba6e514d123c9,openstack/openstack-manuals,"""POT-Creation-Date: 2015-05-27 04:05+0000\n"" ""PO-Revision-Date: 2015-05-27 02:50+0000\n""msgid ""Benchmark service"" msgstr ""Benchmark サービス"" ","""POT-Creation-Date: 2015-05-26 05:25+0000\n"" ""PO-Revision-Date: 2015-05-26 04:20+0000\n""",5,2
openstack%2Fsecurity-doc~master~Icc0d854084cfcd57b334012ceaf8bbb1b48e7e5c,openstack/security-doc,master,Icc0d854084cfcd57b334012ceaf8bbb1b48e7e5c,Updated from openstack-manuals,MERGED,2015-05-27 08:37:10.000000000,2015-05-27 09:51:25.000000000,2015-05-27 09:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-27 08:37:10.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/a2a1933c3c3a7fc4881d15990ce5d7f56bb81b11', 'message': 'Updated from openstack-manuals\n\nChange-Id: Icc0d854084cfcd57b334012ceaf8bbb1b48e7e5c\n'}]",0,185881,a2a1933c3c3a7fc4881d15990ce5d7f56bb81b11,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Icc0d854084cfcd57b334012ceaf8bbb1b48e7e5c
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/81/185881/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,a2a1933c3c3a7fc4881d15990ce5d7f56bb81b11,openstack/openstack-manuals,"""POT-Creation-Date: 2015-05-27 04:05+0000\n"" ""PO-Revision-Date: 2015-05-27 02:50+0000\n""msgid ""Benchmark service"" msgstr ""Benchmark サービス"" ","""POT-Creation-Date: 2015-05-26 05:25+0000\n"" ""PO-Revision-Date: 2015-05-26 04:20+0000\n""",5,2
openstack%2Fopenstack-ansible~kilo~Idddc9eedf868f1312d7a449bba7079d207309538,openstack/openstack-ansible,kilo,Idddc9eedf868f1312d7a449bba7079d207309538,run-upgrade.sh: add a missing redirect,MERGED,2015-05-26 12:49:44.000000000,2015-05-27 09:46:05.000000000,2015-05-27 09:46:03.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 15823}]","[{'number': 1, 'created': '2015-05-26 12:49:44.000000000', 'files': ['scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/92832ce13a36d4d5947439ee1863ff89f3cae203', 'message': 'run-upgrade.sh: add a missing redirect\n\nWhen adding rabbit_cluster_name: rpc to the user variables, it just\nechoed it and did not redirect the output to add it to the\nuser_variables.yml file.\n\nChange-Id: Idddc9eedf868f1312d7a449bba7079d207309538\n(cherry picked from commit a2a4bb6e3bab097017aa544d109a4e5f69b48dc2)\n'}]",0,185580,92832ce13a36d4d5947439ee1863ff89f3cae203,8,5,1,7307,,,0,"run-upgrade.sh: add a missing redirect

When adding rabbit_cluster_name: rpc to the user variables, it just
echoed it and did not redirect the output to add it to the
user_variables.yml file.

Change-Id: Idddc9eedf868f1312d7a449bba7079d207309538
(cherry picked from commit a2a4bb6e3bab097017aa544d109a4e5f69b48dc2)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/80/185580/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/run-upgrade.sh'],1,92832ce13a36d4d5947439ee1863ff89f3cae203,, echo 'rabbit_cluster_name: rpc' | tee -a /etc/openstack_deploy/user_variables.yml, echo 'rabbit_cluster_name: rpc' /etc/openstack_deploy/user_variables.yml,1,1
openstack%2Ftripleo-heat-templates~master~I31f45912fa9c116ccdee010a2c5d91ea43a25671,openstack/tripleo-heat-templates,master,I31f45912fa9c116ccdee010a2c5d91ea43a25671,Reuse the various service passwords as db passwords.,MERGED,2015-05-01 14:21:51.000000000,2015-05-27 09:38:46.000000000,2015-05-27 09:38:44.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 8042}, {'_account_id': 9410}, {'_account_id': 10787}]","[{'number': 1, 'created': '2015-05-01 14:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5eac9515b554785a29c9b7572f3bccbb997cf28f', 'message': 'Reuse the various service passwords as db passwords.\n\nWe need to stop using ""unset"" as the password for all databases. Ideally we\nwould add a ""XxxxDSN"" parameter (e.g. KeystoneDSN) but this wont work because\nwe don\'t know the VirtualIP to pass in.\n\nUntil we can come up with a better solution we should at least get rid of\nthe ""unset"" passwords.\n\nChange-Id: I31f45912fa9c116ccdee010a2c5d91ea43a25671\nDepends-On: I8ffe1eb481f615b0fbe127cd8107f1e70794c839\n'}, {'number': 2, 'created': '2015-05-01 16:06:58.000000000', 'files': ['overcloud-without-mergepy.yaml', 'cinder-storage.yaml', 'controller.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1db5013abd4b9ab14b254690f2a27d7299957b75', 'message': 'Reuse the various service passwords as db passwords.\n\nWe need to stop using ""unset"" as the password for all databases. Ideally we\nwould add a ""XxxxDSN"" parameter (e.g. KeystoneDSN) but this wont work because\nwe don\'t know the VirtualIP to pass in.\n\nUntil we can come up with a better solution we should at least get rid of\nthe ""unset"" passwords.\n\nChange-Id: I31f45912fa9c116ccdee010a2c5d91ea43a25671\nDepends-On: I8ffe1eb481f615b0fbe127cd8107f1e70794c839\n'}]",2,179394,1db5013abd4b9ab14b254690f2a27d7299957b75,19,5,2,1926,,,0,"Reuse the various service passwords as db passwords.

We need to stop using ""unset"" as the password for all databases. Ideally we
would add a ""XxxxDSN"" parameter (e.g. KeystoneDSN) but this wont work because
we don't know the VirtualIP to pass in.

Until we can come up with a better solution we should at least get rid of
the ""unset"" passwords.

Change-Id: I31f45912fa9c116ccdee010a2c5d91ea43a25671
Depends-On: I8ffe1eb481f615b0fbe127cd8107f1e70794c839
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/179394/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'cinder-storage.yaml', 'controller.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/controller-puppet.yaml']",5,5eac9515b554785a29c9b7572f3bccbb997cf28f,," description: The keystone auth secret and db password. description: The password for the ceilometer service and db account. description: The password for the cinder service and db account, used by cinder-api. description: The password for the glance service and db account, used by the glance services. description: The password for the Heat service and db account, used by the Heat services. description: The password for the neutron service and db account, used by neutron agents. description: The password for the nova service and db account, used by nova-api. - - 'mysql://cinder:' - {get_param: CinderPassword} - '@' - - 'mysql://glance:' - {get_param: GlancePassword} - '@' - - 'mysql://heat:' - {get_param: HeatPassword} - '@' - - 'mysql://keystone:' - {get_param: AdminToken} - '@' - - 'mysql://neutron:' - {get_param: NeutronPassword} - '@' - - 'mysql://nova:' - {get_param: NovaPassword} - '@'"," description: The keystone auth secret. description: The password for the ceilometer service account. description: The password for the cinder service account, used by cinder-api. description: The password for the glance service account, used by the glance services. description: The password for the Heat service account, used by the Heat services. description: The password for the neutron service account, used by neutron agents. description: The password for the nova service account, used by nova-api. - - 'mysql://cinder:unset@' - - 'mysql://glance:unset@' - - 'mysql://heat:unset@' - - 'mysql://keystone:unset@' - - 'mysql://neutron:unset@' - - 'mysql://nova:unset@'",66,29
openstack%2Fopenstack-ansible~master~I92a26b620aa7bc0fbe33175594d37da7d5aca7df,openstack/openstack-ansible,master,I92a26b620aa7bc0fbe33175594d37da7d5aca7df,Add handler flushing to roles that need it,MERGED,2015-05-26 16:48:44.000000000,2015-05-27 09:29:56.000000000,2015-05-26 20:22:22.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}]","[{'number': 1, 'created': '2015-05-26 16:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3e8564d0edf1c9267ed5f8912f36dfda30666fc7', 'message': 'Add handler flushing to roles that need it\n\nThis patch adds handler flushing as the last task in each role to ensure\nthat there are log files present when the rsyslog client configuration\ntask is executed a little later in the playbook that consumes the role.\n\nCloses-Bug: #1458822\nChange-Id: I92a26b620aa7bc0fbe33175594d37da7d5aca7df\n'}, {'number': 2, 'created': '2015-05-26 17:14:10.000000000', 'files': ['playbooks/roles/galera_server/tasks/main.yml', 'playbooks/roles/os_glance/tasks/main.yml', 'playbooks/roles/os_heat/tasks/main.yml', 'playbooks/roles/os_swift/tasks/main.yml', 'playbooks/roles/repo_server/tasks/main.yml', 'playbooks/roles/os_keystone/tasks/main.yml', 'playbooks/roles/os_tempest/tasks/main.yml', 'playbooks/roles/os_nova/tasks/main.yml', 'playbooks/roles/os_neutron/tasks/main.yml', 'playbooks/roles/rabbitmq_server/tasks/main.yml', 'playbooks/roles/lxc_hosts/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c7951c43e2f3bae01c595151af33d35dcf0b3ca4', 'message': 'Add handler flushing to roles that need it\n\nThis patch adds handler flushing as the last task in each role to ensure\nthat there are log files present when the rsyslog client configuration\ntask is executed a little later in the playbook that consumes the role.\n\nCloses-Bug: #1458822\nChange-Id: I92a26b620aa7bc0fbe33175594d37da7d5aca7df\n'}]",0,185662,c7951c43e2f3bae01c595151af33d35dcf0b3ca4,10,4,2,6816,,,0,"Add handler flushing to roles that need it

This patch adds handler flushing as the last task in each role to ensure
that there are log files present when the rsyslog client configuration
task is executed a little later in the playbook that consumes the role.

Closes-Bug: #1458822
Change-Id: I92a26b620aa7bc0fbe33175594d37da7d5aca7df
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/62/185662/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_glance/tasks/main.yml', 'playbooks/roles/os_heat/tasks/main.yml', 'playbooks/roles/os_swift/tasks/main.yml', 'playbooks/roles/os_keystone/tasks/main.yml', 'playbooks/roles/os_nova/tasks/main.yml', 'playbooks/roles/os_neutron/tasks/main.yml', 'playbooks/roles/lxc_hosts/tasks/main.yml']",7,3e8564d0edf1c9267ed5f8912f36dfda30666fc7,bug/1458822,- name: Flush handlers meta: flush_handlers,,19,0
openstack%2Fneutron~master~I823ff5ca66833cdca459f13ab28f5075ae03ded5,openstack/neutron,master,I823ff5ca66833cdca459f13ab28f5075ae03ded5,Add the rebinding chance in _bind_port_if_needed,ABANDONED,2015-05-22 00:45:56.000000000,2015-05-27 09:21:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 11114}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-22 00:45:56.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/763b23425e58da863c7ecbcff94fbba19e3cb201', 'message': ""Add the rebinding chance in _bind_port_if_needed\n\nMake function _bind_port_if_needed to bind at least one time when the port's\nbinding status passed in is already in binding_failed.\n\nCo-Autored-By: Eugene Nikanorov <enikanorov@mirantis.com>\nChange-Id: I823ff5ca66833cdca459f13ab28f5075ae03ded5\nCloses-Bug: #1399249\n""}]",0,184925,763b23425e58da863c7ecbcff94fbba19e3cb201,36,26,1,6072,,,0,"Add the rebinding chance in _bind_port_if_needed

Make function _bind_port_if_needed to bind at least one time when the port's
binding status passed in is already in binding_failed.

Co-Autored-By: Eugene Nikanorov <enikanorov@mirantis.com>
Change-Id: I823ff5ca66833cdca459f13ab28f5075ae03ded5
Closes-Bug: #1399249
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/184925/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,763b23425e58da863c7ecbcff94fbba19e3cb201,rebind," if (binding.vif_type not in [portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED] context = new_context if (context._binding.vif_type == portbindings.VIF_TYPE_BINDING_FAILED): return context need_notify |= did_commit", if (binding.vif_type != portbindings.VIF_TYPE_UNBOUND if did_commit and (new_context._binding.vif_type != portbindings.VIF_TYPE_BINDING_FAILED): need_notify = True context = new_context,57,5
openstack%2Fopenstack-ansible~kilo~I9badd032554000d0f4ea42f0d17c43ececd8ad9a,openstack/openstack-ansible,kilo,I9badd032554000d0f4ea42f0d17c43ececd8ad9a,Updated Kilo to use the head of the kilo branches,MERGED,2015-05-26 18:42:55.000000000,2015-05-27 09:20:59.000000000,2015-05-27 09:20:59.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7414}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-05-26 18:42:55.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/openstack_other.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aa472d0620dd01e670c526da0ce074b0352382ab', 'message': 'Updated Kilo to use the head of the kilo branches\n\nThis commit revs all services, and other to use the head of the\nstable/kilo branches. This change brings in various bug fixes\nand updates that will allow us to ensure that we have a stable and\ncapable deployment system.\n\nChange-Id: I9badd032554000d0f4ea42f0d17c43ececd8ad9a\nCloses-Bug: 1451860\n'}]",0,185694,aa472d0620dd01e670c526da0ce074b0352382ab,8,4,1,7353,,,0,"Updated Kilo to use the head of the kilo branches

This commit revs all services, and other to use the head of the
stable/kilo branches. This change brings in various bug fixes
and updates that will allow us to ensure that we have a stable and
capable deployment system.

Change-Id: I9badd032554000d0f4ea42f0d17c43ececd8ad9a
Closes-Bug: 1451860
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/185694/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/openstack_other.yml']",2,aa472d0620dd01e670c526da0ce074b0352382ab,bug/1451860,"glancestore_git_install_branch: d9b197b6d63e0cd2b2458c6a2a9c9701ef8b383b # HEAD of ""stable/kilo"" as of 26.05.2015requirements_git_install_branch: f883e293e606041b5e82875271cf1feb041914ba # HEAD of ""stable/kilo"" as of 26.05.2015","glancestore_git_install_branch: 0eafed02a0988f250dab5e52756b5fe26623b069 # HEAD of ""stable/kilo"" as of 30.04.2015requirements_git_install_branch: 65cd85989cc3ea09d7d7a1a46c175c1f3774bc20 # HEAD of ""stable/kilo"" as of 30.04.2015",13,13
openstack%2Ftripleo-ci~master~If9a716d1c35a03bdbcddc900aad21470fe242191,openstack/tripleo-ci,master,If9a716d1c35a03bdbcddc900aad21470fe242191,Specify Redis Virtual IP,ABANDONED,2015-05-13 19:11:49.000000000,2015-05-27 09:20:14.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-13 19:11:49.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2d33bc48b0817ff1fabcb0690f013520dc226a6e', 'message': 'Specify Redis Virtual IP\n\nSince the Redis cluster review[1] needs a VirtualIP to be specified for\nthis given scenario we specify it here.\n\n[1] https://review.openstack.org/#/c/182617/\n\nChange-Id: If9a716d1c35a03bdbcddc900aad21470fe242191\n'}]",0,182795,2d33bc48b0817ff1fabcb0690f013520dc226a6e,5,1,1,9410,,,0,"Specify Redis Virtual IP

Since the Redis cluster review[1] needs a VirtualIP to be specified for
this given scenario we specify it here.

[1] https://review.openstack.org/#/c/182617/

Change-Id: If9a716d1c35a03bdbcddc900aad21470fe242191
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/95/182795/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,2d33bc48b0817ff1fabcb0690f013520dc226a6e,pacemaker, RedisVirtualIp: 192.0.2.142,,1,0
openstack%2Fopenstack-ansible~master~I7daa76e601a1bf430765866c1e4c0b8f9638aa73,openstack/openstack-ansible,master,I7daa76e601a1bf430765866c1e4c0b8f9638aa73,Removed memcached log directory task,MERGED,2015-05-26 22:51:29.000000000,2015-05-27 09:13:35.000000000,2015-05-27 09:13:34.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7414}]","[{'number': 1, 'created': '2015-05-26 22:51:29.000000000', 'files': ['playbooks/roles/memcached_server/tasks/memcached_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca9cbb8f8ff2f3bfb96f96ae3c2cbd5300fe3348', 'message': 'Removed memcached log directory task\n\nThe memcached play has a log directory task that will cause an issue\nwith permissions with a container where memcached is installed. To\nsolve this issue the log directory permissions change task needs to\nbe removed\n\nChange-Id: I7daa76e601a1bf430765866c1e4c0b8f9638aa73\nCloses-Bug: 1459039\n'}]",0,185773,ca9cbb8f8ff2f3bfb96f96ae3c2cbd5300fe3348,8,3,1,7353,,,0,"Removed memcached log directory task

The memcached play has a log directory task that will cause an issue
with permissions with a container where memcached is installed. To
solve this issue the log directory permissions change task needs to
be removed

Change-Id: I7daa76e601a1bf430765866c1e4c0b8f9638aa73
Closes-Bug: 1459039
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/73/185773/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/memcached_server/tasks/memcached_pre_install.yml'],1,ca9cbb8f8ff2f3bfb96f96ae3c2cbd5300fe3348,bug/1459039,," - name: Ensure memcached directories file: path: ""{{ item }}"" state: ""directory"" owner: ""root"" group: ""root"" with_items: - ""{{ memcached_log | dirname }}"" tags: - memcached-dirs",0,11
openstack%2Ffuel-docs~master~I4bec3b87517e30c2cd43d6a524400a2966922d44,openstack/fuel-docs,master,I4bec3b87517e30c2cd43d6a524400a2966922d44,MOS-RN6.1 VMware technologies resolved issue,ABANDONED,2015-05-26 14:43:53.000000000,2015-05-27 09:11:43.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 12139}, {'_account_id': 13082}, {'_account_id': 14396}, {'_account_id': 14643}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-05-26 14:43:53.000000000', 'files': ['pages/release-notes/v6-1/9010-vmware-tech.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/eb5964c04629b1f60aa6de1d57a7af25b2e4f4cc', 'message': 'MOS-RN6.1 VMware technologies resolved issue\n\nAdds VMware technologies resolved issue to the MOS 6.1 Release\n Notes:\n[library] Enabling vCenter integration disables Ceph for Glance\n and RadosGW.\n\nChange-Id: I4bec3b87517e30c2cd43d6a524400a2966922d44\n'}]",0,185631,eb5964c04629b1f60aa6de1d57a7af25b2e4f4cc,6,7,1,14947,,,0,"MOS-RN6.1 VMware technologies resolved issue

Adds VMware technologies resolved issue to the MOS 6.1 Release
 Notes:
[library] Enabling vCenter integration disables Ceph for Glance
 and RadosGW.

Change-Id: I4bec3b87517e30c2cd43d6a524400a2966922d44
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/31/185631/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1/9010-vmware-tech.rst'],1,eb5964c04629b1f60aa6de1d57a7af25b2e4f4cc,RN6.1-VMware-technologies-issues,"* If vCenter is selected as hypervisor, radosgw and Ceph RBD can be used by Glance now. Only Ceph storage backends for Cinder and Nova are disabled, Ceph can still be used as a storage backend for Glance and Swift/S3 object storage. See `LP1316377`_... Links .. _`LP1316377`: https://bugs.launchpad.net/fuel/6.1.x/+bug/1316377",,7,0
openstack%2Fcinder~master~Ia1a99a08c3e74fe737b3f091751689654cd49e2f,openstack/cinder,master,Ia1a99a08c3e74fe737b3f091751689654cd49e2f,Stop registering opt fatal_exception_format_errors in cinder.exp,ABANDONED,2015-05-25 06:38:43.000000000,2015-05-27 08:57:00.000000000,,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 8105}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14428}, {'_account_id': 15374}, {'_account_id': 15831}, {'_account_id': 16160}]","[{'number': 1, 'created': '2015-05-25 06:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b45f1a908556379661f14b7a8847a7b34832362b', 'message': 'Stop registering opt fatal_exception_format_errors in cinder.exp\n\nGiven cinder switched to use oslo.versionedobject, and the opt has\nbeen registered by versionedobject.expection, we need to stop\nregistering opt fatal_exception_format_errors in cinder.expection,\nor it will cause errors and cinder-api cannot be started.\n\nBug 1458448\n\nChange-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f\n'}, {'number': 2, 'created': '2015-05-25 06:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1171aa2a06ebd424299058388ad5e4a85ffcfa2c', 'message': 'Stop registering opt fatal_exception_format_errors in cinder.exp\n\nGiven cinder switched to use oslo.versionedobject, and the opt has\nbeen registered by versionedobject.expection, we need to stop\nregistering opt fatal_exception_format_errors in cinder.expection,\nor it will cause errors and cinder-api cannot be started.\n\nCloses-Bug: #1458448\n\nChange-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f\n'}, {'number': 3, 'created': '2015-05-25 07:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df5c0b93af156b699ba4f601236f6d1cc68b38df', 'message': 'Stop registering opt fatal_exception_format_errors in cinder.exp\n\nGiven cinder switched to use oslo.versionedobject, and the opt has\nbeen registered by versionedobject.expection, we need to stop\nregistering opt fatal_exception_format_errors in cinder.expection,\nor it will cause errors and cinder-api cannot be started.\n\nCloses-Bug: #1458448\n\nChange-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f\n'}, {'number': 4, 'created': '2015-05-27 03:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9f494eae4366a7902a48c956cfccadaa701032e3', 'message': 'Stop registering opt fatal_exception_format_errors in cinder.exp\n\nGiven cinder switched to use oslo.versionedobject, and the opt has\nbeen registered by versionedobject.expection, we need to stop\nregistering opt fatal_exception_format_errors in cinder.expection,\nor it will cause errors and cinder-api cannot be started.\n\nCloses-Bug: #1458448\n\nChange-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f\n'}, {'number': 5, 'created': '2015-05-27 05:17:55.000000000', 'files': ['cinder/test.py', 'cinder/exception.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3bc5190fa69cbc50058762bf5dc95bae5076727b', 'message': 'Stop registering opt fatal_exception_format_errors in cinder.exp\n\nGiven cinder switched to use oslo.versionedobject, and the opt has\nbeen registered by versionedobject.expection, we need to stop\nregistering opt fatal_exception_format_errors in cinder.expection,\nor it will cause errors and cinder-api cannot be started.\n\nCloses-Bug: #1458448\n\nChange-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f\n'}]",5,185314,3bc5190fa69cbc50058762bf5dc95bae5076727b,67,17,5,8105,,,0,"Stop registering opt fatal_exception_format_errors in cinder.exp

Given cinder switched to use oslo.versionedobject, and the opt has
been registered by versionedobject.expection, we need to stop
registering opt fatal_exception_format_errors in cinder.expection,
or it will cause errors and cinder-api cannot be started.

Closes-Bug: #1458448

Change-Id: Ia1a99a08c3e74fe737b3f091751689654cd49e2f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/14/185314/5 && git format-patch -1 --stdout FETCH_HEAD,['cinder/exception.py'],1,b45f1a908556379661f14b7a8847a7b34832362b,Bug1458448,,"exc_log_opts = [ cfg.BoolOpt('fatal_exception_format_errors', default=False, help='Make exception message format errors fatal.'), ] CONF = cfg.CONF CONF.register_opts(exc_log_opts) ",0,10
openstack%2Ffuel-docs~master~I0a4cae743a2747d3e84c56efc3d78421403fbf0e,openstack/fuel-docs,master,I0a4cae743a2747d3e84c56efc3d78421403fbf0e,[Monitoring Guide] Appendix,MERGED,2015-05-15 16:38:20.000000000,2015-05-27 08:51:52.000000000,2015-05-27 08:51:50.000000000,"[{'_account_id': 3}, {'_account_id': 7075}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 14643}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-05-15 16:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3a805b305d838d582aea4e80186e013bd9f677bf', 'message': '[Monitoring Guide] Appendix\n\nAdds Appendix to the Monitoring Guide\n\nChange-Id: I0a4cae743a2747d3e84c56efc3d78421403fbf0e\nCo-Authored-By: Swann Croiset <swann@oopss.org>\nCo-Authored-By: Patrick Petit <ppetit@mirantis.com>\nCo-Authored-By: Nikita Konovalov <nkonovalov@mirantis.com>\nCo-Authored-By: Alexander Tivelkov <ativelkov@mirantis.com>\nCo-Authored-By: Alexander Adamov <aadamov@mirantis.com>\nCo-Authored-By: Maria Zlatkova <mzlatkova@mirantis.com>\n'}, {'number': 2, 'created': '2015-05-18 13:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a9483b63f817ec756589d1f71079a3e8d1ba74e4', 'message': '[Monitoring Guide] Appendix\n\nAdds Appendix to the Monitoring Guide\n\nChange-Id: I0a4cae743a2747d3e84c56efc3d78421403fbf0e\nCo-Authored-By: Swann Croiset <scroiset@mirantis.com>\nCo-Authored-By: Patrick Petit <ppetit@mirantis.com>\nCo-Authored-By: Nikita Konovalov <nkonovalov@mirantis.com>\nCo-Authored-By: Alexander Tivelkov <ativelkov@mirantis.com>\nCo-Authored-By: Alexander Adamov <aadamov@mirantis.com>\nCo-Authored-By: Maria Zlatkova <mzlatkova@mirantis.com>\n'}, {'number': 3, 'created': '2015-05-22 07:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/790e1027790cf787b42fbf96442587ff2800b117', 'message': '[Monitoring Guide] Appendix\n\nAdds Appendix to the Monitoring Guide\n\nCo-Authored-By: Swann Croiset <scroiset@mirantis.com>\nCo-Authored-By: Patrick Petit <ppetit@mirantis.com>\nCo-Authored-By: Nikita Konovalov <nkonovalov@mirantis.com>\nCo-Authored-By: Alexander Tivelkov <ativelkov@mirantis.com>\nCo-Authored-By: Alexander Adamov <aadamov@mirantis.com>\nCo-Authored-By: Maria Zlatkova <mzlatkova@mirantis.com>\n\nChange-Id: I0a4cae743a2747d3e84c56efc3d78421403fbf0e\n'}, {'number': 4, 'created': '2015-05-22 07:27:59.000000000', 'files': ['pages/monitoring-guide/appendix/vm-network-traffic.rst', 'pages/monitoring-guide/appendix/virtual-machine-monitoring.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7d0e8f177fe826e9a2f8a537632a3445f23db2f5', 'message': '[Monitoring Guide] Appendix\n\nAdds Appendix to the Monitoring Guide\n\nCo-Authored-By: Swann Croiset <scroiset@mirantis.com>\nCo-Authored-By: Patrick Petit <ppetit@mirantis.com>\nCo-Authored-By: Nikita Konovalov <nkonovalov@mirantis.com>\nCo-Authored-By: Alexander Tivelkov <ativelkov@mirantis.com>\nCo-Authored-By: Alexander Adamov <aadamov@mirantis.com>\nCo-Authored-By: Maria Zlatkova <mzlatkova@mirantis.com>\n\nChange-Id: I0a4cae743a2747d3e84c56efc3d78421403fbf0e\n'}]",5,183597,7d0e8f177fe826e9a2f8a537632a3445f23db2f5,30,6,4,14643,,,0,"[Monitoring Guide] Appendix

Adds Appendix to the Monitoring Guide

Co-Authored-By: Swann Croiset <scroiset@mirantis.com>
Co-Authored-By: Patrick Petit <ppetit@mirantis.com>
Co-Authored-By: Nikita Konovalov <nkonovalov@mirantis.com>
Co-Authored-By: Alexander Tivelkov <ativelkov@mirantis.com>
Co-Authored-By: Alexander Adamov <aadamov@mirantis.com>
Co-Authored-By: Maria Zlatkova <mzlatkova@mirantis.com>

Change-Id: I0a4cae743a2747d3e84c56efc3d78421403fbf0e
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/97/183597/3 && git format-patch -1 --stdout FETCH_HEAD,"['pages/monitoring-guide/appendix/vm-network-traffic.rst', 'pages/monitoring-guide/appendix/virtual-machine-monitoring.rst']",2,3a805b305d838d582aea4e80186e013bd9f677bf,appendix," It is possible to collect guests statistics from libvirt, see `libvirt-domain <http://libvirt.org/html/libvirt-libvirt-domain.html>`_ for details. #. Block IO * read_reqs * read_bytes * write_reqs * write_bytes #. Network IO * rx_bytes * rx_packets * rx_errors * rx_drops * tx_bytes * tx_packets * tx_errors * tx_drops #. CPU * cputime * vcputime * systemtime * usertime .. note:: The VCPU time is global and cumulative and is reported in nanoseconds since the last boot. To calculate a VCPU usage percentage you need to divide vcputime by the number of VCPUS divided by the wallclock time of the sampling interval. Guest agent +++++++++++ A guest agent allows running scripts or applications inside an instance while it runs. Unfortunately, there is no support of the guest agent with KVM hypervisor at the moment, only XEN driver supports it.",,64,0
openstack%2Fnova~stable%2Fjuno~I513e0a08b32aa7f38c480488b398cd97d8cdc471,openstack/nova,stable/juno,I513e0a08b32aa7f38c480488b398cd97d8cdc471,Add setup/cleanup_instance_network_on_host api for neutron/nova-network,ABANDONED,2015-05-21 15:13:49.000000000,2015-05-27 08:50:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-05-21 15:13:49.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/tests/network/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15698449628d1b2584174a7fdf4e7d0eee8d711d', 'message': 'Add setup/cleanup_instance_network_on_host api for neutron/nova-network\n\nWhen reschedule/unshelve/evacuate/rebuild instance, the instance\nis moved from one host to another. The network should be updated\nfor the instance. And there are similar APIs\nmigrate_instance_start/stop, those two APIs should be used for\nmigration case as the name. So adds new APIs used to update\nnetwork resource when instance is moved.\n\nThis patch implements the new APIs both for neutron and\nnova-network.\n\n(cherry picked from commit 7368d9f6e9e94819b199d0f2cc1ac69706870586)\n\nChange-Id: I513e0a08b32aa7f38c480488b398cd97d8cdc471\nRelated-bug: #1327124\n'}]",0,184801,15698449628d1b2584174a7fdf4e7d0eee8d711d,7,6,1,8151,,,0,"Add setup/cleanup_instance_network_on_host api for neutron/nova-network

When reschedule/unshelve/evacuate/rebuild instance, the instance
is moved from one host to another. The network should be updated
for the instance. And there are similar APIs
migrate_instance_start/stop, those two APIs should be used for
migration case as the name. So adds new APIs used to update
network resource when instance is moved.

This patch implements the new APIs both for neutron and
nova-network.

(cherry picked from commit 7368d9f6e9e94819b199d0f2cc1ac69706870586)

Change-Id: I513e0a08b32aa7f38c480488b398cd97d8cdc471
Related-bug: #1327124
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/184801/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/tests/network/test_api.py']",5,15698449628d1b2584174a7fdf4e7d0eee8d711d,bug/1327124," @mock.patch('nova.network.api.API.migrate_instance_start') def test_cleanup_instance_network_on_host(self, fake_migrate_start): instance = fake_instance.fake_instance_obj(self.context) self.network_api.cleanup_instance_network_on_host( self.context, instance, 'fake_compute_source') fake_migrate_start.assert_called_once_with( self.context, instance, {'source_compute': 'fake_compute_source', 'dest_compute': None}) @mock.patch('nova.network.api.API.migrate_instance_finish') def test_setup_instance_network_on_host(self, fake_migrate_finish): instance = fake_instance.fake_instance_obj(self.context) self.network_api.setup_instance_network_on_host( self.context, instance, 'fake_compute_source') fake_migrate_finish.assert_called_once_with( self.context, instance, {'source_compute': None, 'dest_compute': 'fake_compute_source'}) ",,128,29
openstack%2Fnova~stable%2Fjuno~Id4822ca0a902b35396025bde2a16411a02c46e0e,openstack/nova,stable/juno,Id4822ca0a902b35396025bde2a16411a02c46e0e,Update network resource when rescheduling instance,ABANDONED,2015-05-21 14:36:15.000000000,2015-05-27 08:49:34.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9732}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-05-21 14:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b096630ba6582097be1532092c5c43ed16fe0ae5', 'message': ""Update network resource when rescheduling instance\n\nWhen instance building failed, compute manager will try to reschedule\nthe failed instance. If the network resource already allocated before\nfailed, the network resource need update at current compute node and\nnext compute node.\n\nBefore rescheduling the failed instance, for nova-network with multihost,\nbecause the network already setup on the compute node, the floating ip\nshould be cleanup at compute node.\n\nAfter rescheduling, because the network already allocated, then compute\nmanager won't allocate network again. For neutron, the port binding info\nneed update to new compute node. For nova-network with multihost, the\nfloating ip should be setup on the new compute node.\n\n(cherry picked from commit 05cd4824a9749c6067bb3eddc0994126d8940941)\n\nChange-Id: Id4822ca0a902b35396025bde2a16411a02c46e0e\nCloses-Bug: #1327124\n""}, {'number': 2, 'created': '2015-05-21 14:39:12.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0834b16e2ea16205916949645f48d72ff5d98800', 'message': ""Update network resource when rescheduling instance\n\nWhen instance building failed, compute manager will try to reschedule\nthe failed instance. If the network resource already allocated before\nfailed, the network resource need update at current compute node and\nnext compute node.\n\nBefore rescheduling the failed instance, for nova-network with multihost,\nbecause the network already setup on the compute node, the floating ip\nshould be cleanup at compute node.\n\nAfter rescheduling, because the network already allocated, then compute\nmanager won't allocate network again. For neutron, the port binding info\nneed update to new compute node. For nova-network with multihost, the\nfloating ip should be setup on the new compute node.\n\n(cherry picked from commit 05cd4824a9749c6067bb3eddc0994126d8940941)\n\nChange-Id: Id4822ca0a902b35396025bde2a16411a02c46e0e\nCloses-Bug: #1327124\n""}]",0,184796,0834b16e2ea16205916949645f48d72ff5d98800,8,5,2,8151,,,0,"Update network resource when rescheduling instance

When instance building failed, compute manager will try to reschedule
the failed instance. If the network resource already allocated before
failed, the network resource need update at current compute node and
next compute node.

Before rescheduling the failed instance, for nova-network with multihost,
because the network already setup on the compute node, the floating ip
should be cleanup at compute node.

After rescheduling, because the network already allocated, then compute
manager won't allocate network again. For neutron, the port binding info
need update to new compute node. For nova-network with multihost, the
floating ip should be setup on the new compute node.

(cherry picked from commit 05cd4824a9749c6067bb3eddc0994126d8940941)

Change-Id: Id4822ca0a902b35396025bde2a16411a02c46e0e
Closes-Bug: #1327124
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/184796/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,b096630ba6582097be1532092c5c43ed16fe0ae5,bug/1327124," # NOTE(alex_xu): The network_allocated is True means the network # resource already allocated at previous scheduling, and the # network setup is cleanup at previous. After rescheduling, the # network resource need setup on the new host. self.network_api.setup_instance_network_on_host( context, instance, instance.host) else: # NOTE(alex_xu): Network already allocated and we don't # want to deallocate them before rescheduling. But we need # cleanup those network resource setup on this host before # rescheduling. self.network_api.cleanup_instance_network_on_host( context, instance, self.host)",,75,0
openstack%2Fopenstack-manuals~master~I1f881da9eaa82a3e3ac01660aaf612b4a4d153e4,openstack/openstack-manuals,master,I1f881da9eaa82a3e3ac01660aaf612b4a4d153e4,Live migration setup is not needed in kilo,MERGED,2015-05-20 18:59:10.000000000,2015-05-27 08:45:32.000000000,2015-05-27 08:45:30.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6772}, {'_account_id': 8768}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-05-20 18:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dce1f47905835c2eec15ad46d6ceb0a249c5a072', 'message': 'Live migration setup is not needed in kilo\n\nSpecify that nova configuration for live migration is only needed for\nrelease prior to Kilo.\n\nChange-Id: I1f881da9eaa82a3e3ac01660aaf612b4a4d153e4\nCloses-Bug: #1455681\n'}, {'number': 2, 'created': '2015-05-21 16:16:44.000000000', 'files': ['doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b2b286b4a54ad4de6a8586e1f1d977487dd05451', 'message': 'Live migration setup is not needed in kilo\n\nSpecify that nova configuration for live migration is only needed for\nrelease prior to Kilo.\n\nChange-Id: I1f881da9eaa82a3e3ac01660aaf612b4a4d153e4\nCloses-Bug: #1455681\n'}]",1,184589,b2b286b4a54ad4de6a8586e1f1d977487dd05451,12,5,2,7923,,,0,"Live migration setup is not needed in kilo

Specify that nova configuration for live migration is only needed for
release prior to Kilo.

Change-Id: I1f881da9eaa82a3e3ac01660aaf612b4a4d153e4
Closes-Bug: #1455681
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/89/184589/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml'],1,dce1f47905835c2eec15ad46d6ceb0a249c5a072,bug/1455681," <para>Prior to the Kilo release, the Compute service did not use the libvirt live migration function by default. To enable this function, add the following line to the <literal>[libvirt]</literal> section of the <filename>nova.conf</filename> file: <programlisting>live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_TUNNELLED</programlisting>"," <para>By default, the Compute service does not use the libvirt live migration function. To enable this function, add the following line to the <filename>nova.conf</filename> file: <programlisting>live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE, VIR_MIGRATE_TUNNELLED</programlisting>",6,4
openstack%2Fopenstack-manuals~master~I77c9ed37c53124a870bb289f00a184ae7d376cb5,openstack/openstack-manuals,master,I77c9ed37c53124a870bb289f00a184ae7d376cb5,Adding rabbit_userid to the heat.conf file,MERGED,2015-05-26 02:22:50.000000000,2015-05-27 08:45:23.000000000,2015-05-27 08:45:22.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7923}, {'_account_id': 9515}]","[{'number': 1, 'created': '2015-05-26 02:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/595b45bf1b0983b6172b772e49301085baa31ebd', 'message': 'Adding rabbit_userid to the heat.conf file\n\nChange-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5\nCloses-bug: #1458440\n'}, {'number': 2, 'created': '2015-05-26 03:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e865ab2abf41d36deb4325bbf53fe7e6349ce5cd', 'message': 'Adding rabbit_userid to the heat.conf file\n\nChange-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5\nCloses-bug: #1458440\n'}, {'number': 3, 'created': '2015-05-26 23:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f811b0e9688a00262d65ccb09387d9e799213cdc', 'message': 'Adding rabbit_userid to the heat.conf file\n\nChange-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5\nCloses-bug: #1458440\nCloses-bug: #1458859\n'}, {'number': 4, 'created': '2015-05-27 00:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a02541c8a16d062b7f95cbe8eac1c8a33bfa58e9', 'message': 'Adding rabbit_userid to the heat.conf file\n\nChange-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5\nCloses-bug: #1458440\n'}, {'number': 5, 'created': '2015-05-27 03:25:42.000000000', 'files': ['doc/install-guide/section_heat-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d49261710331a02bc8d0b87677df1af505045f0c', 'message': 'Adding rabbit_userid to the heat.conf file\n\nChange-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5\nCloses-bug: #1458440\n'}]",1,185489,d49261710331a02bc8d0b87677df1af505045f0c,19,4,5,10607,,,0,"Adding rabbit_userid to the heat.conf file

Change-Id: I77c9ed37c53124a870bb289f00a184ae7d376cb5
Closes-bug: #1458440
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/89/185489/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_heat-install.xml'],1,595b45bf1b0983b6172b772e49301085baa31ebd,bug/1458440,rabbit_userid = openstack,,1,0
openstack%2Ftripleo-heat-templates~master~I98149f108baf28d46eb199b69a72d0f6914486fd,openstack/tripleo-heat-templates,master,I98149f108baf28d46eb199b69a72d0f6914486fd,Map Cinder services to isolated networks,MERGED,2015-05-26 22:41:02.000000000,2015-05-27 08:43:15.000000000,2015-05-27 08:43:14.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-26 22:41:02.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/089c26acab8ed3b5a6c32ea862969d71f7bd033c', 'message': ""Map Cinder services to isolated networks\n\nThis change adds parameters to specify which networks the Cinder API and\nCinder iSCSI services will listen on. If the internal_api network exists,\nCinder API will be bound to the IP on that network, otherwise it will\ndefault to the Undercloud 'ctlplane' network. The Cinder iSCSI service will\nbind to the storage network if it exists, otherwise will also default to\nusing the Undercloud 'ctlplane' network.\n\nChange-Id: I98149f108baf28d46eb199b69a72d0f6914486fd\n""}]",0,185767,089c26acab8ed3b5a6c32ea862969d71f7bd033c,8,3,1,12398,,,0,"Map Cinder services to isolated networks

This change adds parameters to specify which networks the Cinder API and
Cinder iSCSI services will listen on. If the internal_api network exists,
Cinder API will be bound to the IP on that network, otherwise it will
default to the Undercloud 'ctlplane' network. The Cinder iSCSI service will
bind to the storage network if it exists, otherwise will also default to
using the Undercloud 'ctlplane' network.

Change-Id: I98149f108baf28d46eb199b69a72d0f6914486fd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/185767/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,089c26acab8ed3b5a6c32ea862969d71f7bd033c,service_map_cinder," cinder_iscsi_ip_address: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, CinderIscsiNetwork]}]} cinder::api::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, CinderApiNetwork]}]}", cinder_iscsi_ip_address: {get_input: controller_host} cinder::api::bind_host: {get_input: controller_host},4,2
openstack%2Ftripleo-heat-templates~master~Ib646e4a34496966f9b1d454f04d07bf95543517f,openstack/tripleo-heat-templates,master,Ib646e4a34496966f9b1d454f04d07bf95543517f,Map Ceilometer services to isolated networks,MERGED,2015-05-26 19:21:08.000000000,2015-05-27 08:42:36.000000000,2015-05-27 08:42:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8042}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-26 19:21:08.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04a0133e559edbe283370804313822b205df1d94', 'message': ""Map Ceilometer services to isolated networks\n\nThis change adds the parameters to specify which networks the Ceilometer\nand MongoDB servers listen on. It is set to the internal_api network if\npresent, and reverts to the default Undercloud 'ctlplane' network if not.\n\nChange-Id: Ib646e4a34496966f9b1d454f04d07bf95543517f\n""}]",0,185708,04a0133e559edbe283370804313822b205df1d94,10,4,1,12398,,,0,"Map Ceilometer services to isolated networks

This change adds the parameters to specify which networks the Ceilometer
and MongoDB servers listen on. It is set to the internal_api network if
present, and reverts to the default Undercloud 'ctlplane' network if not.

Change-Id: Ib646e4a34496966f9b1d454f04d07bf95543517f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/185708/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,04a0133e559edbe283370804313822b205df1d94,service_map_ceilometer," mongodb::server::bind_ip: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, MongoDbNetwork]}]} ceilometer::api::host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, CeilometerApiNetwork]}]}", mongodb::server::bind_ip: {get_input: controller_host} ceilometer::api::host: {get_input: controller_host},4,2
openstack%2Fopenstack-manuals~master~I3e32bd82577ac3e0ed29e998ebb1bd0e90a44fc5,openstack/openstack-manuals,master,I3e32bd82577ac3e0ed29e998ebb1bd0e90a44fc5,Add pt_BR api-quick-start to draft index,MERGED,2015-05-21 13:54:41.000000000,2015-05-27 08:32:51.000000000,2015-05-27 08:32:50.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-05-21 13:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2541b8b315a54962a0ee819a364579b67cc19be3', 'message': ""Add pt_BR api-quick-start to draft index\n\nThe guide is published, let's link to it. First from the drafts page\nuntil it is reviewed and can moved to the pt_BR one.\n\nChange-Id: I3e32bd82577ac3e0ed29e998ebb1bd0e90a44fc5\nDepends-On: Ia07843591d468304fd102547840b6471094b86f6\n""}, {'number': 2, 'created': '2015-05-27 08:19:42.000000000', 'files': ['www/draft/draft-index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3f3d77d923c6f56ec1cc622e3d443b12d1c58008', 'message': ""Add pt_BR api-quick-start to draft index\n\nThe guide is published, let's link to it. First from the drafts page\nuntil it is reviewed and can moved to the pt_BR one.\n\nChange-Id: I3e32bd82577ac3e0ed29e998ebb1bd0e90a44fc5\nDepends-On: Ia07843591d468304fd102547840b6471094b86f6\n""}]",0,184789,3f3d77d923c6f56ec1cc622e3d443b12d1c58008,11,5,2,6547,,,0,"Add pt_BR api-quick-start to draft index

The guide is published, let's link to it. First from the drafts page
until it is reviewed and can moved to the pt_BR one.

Change-Id: I3e32bd82577ac3e0ed29e998ebb1bd0e90a44fc5
Depends-On: Ia07843591d468304fd102547840b6471094b86f6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/89/184789/2 && git format-patch -1 --stdout FETCH_HEAD,['www/draft/draft-index.html'],1,2541b8b315a54962a0ee819a364579b67cc19be3,pt_BR-api-quick-start," <h4>Brasilian Portugese (pt_BR)</h4> <a href=""/pt_BR/api/quick-start/content/index.html"">API Quick Start</a>",,2,0
openstack%2Fopenstack-manuals~master~Ia635969f395a4b612039602e58591f7692d34ffb,openstack/openstack-manuals,master,Ia635969f395a4b612039602e58591f7692d34ffb,Imported Translations from Transifex,MERGED,2015-05-27 06:12:00.000000000,2015-05-27 08:32:43.000000000,2015-05-27 08:32:42.000000000,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2015-05-27 06:12:00.000000000', 'files': ['doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/user-guide/source/locale/user-guide.pot', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f97f24e9b81ac848d0549e8c40c2bb0fae5eb7c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ia635969f395a4b612039602e58591f7692d34ffb\n'}]",0,185847,0f97f24e9b81ac848d0549e8c40c2bb0fae5eb7c,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ia635969f395a4b612039602e58591f7692d34ffb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/185847/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/user-guide/source/locale/user-guide.pot', 'doc/glossary/locale/ja.po']",9,0f97f24e9b81ac848d0549e8c40c2bb0fae5eb7c,transifex/translations,"""POT-Creation-Date: 2015-05-27 04:05+0000\n"" ""PO-Revision-Date: 2015-05-27 02:50+0000\n""msgid ""Benchmark service"" msgstr ""Benchmark サービス"" ","""POT-Creation-Date: 2015-05-26 05:25+0000\n"" ""PO-Revision-Date: 2015-05-26 04:20+0000\n""",709,153
openstack%2Ffuel-docs~master~Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d,openstack/fuel-docs,master,Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d,Adds a note about pdf,ABANDONED,2015-05-22 12:08:09.000000000,2015-05-27 08:28:03.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13695}]","[{'number': 1, 'created': '2015-05-22 12:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/913e408b82ff0b9548ed56fe5d5f74b975ad458b', 'message': 'Adds a note about pdf\n\nChange-Id: Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d\n'}, {'number': 2, 'created': '2015-05-22 12:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/193aa9f936144eda5e207c727c7f1a57e58bdc61', 'message': 'Adds a note about pdf\n\nChange-Id: Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d\n'}, {'number': 3, 'created': '2015-05-22 12:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0d6aac35c9553b7042c6258d5fbbd96d55163d20', 'message': 'Adds a note about pdf\n\nChange-Id: Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d\n'}, {'number': 4, 'created': '2015-05-22 12:25:07.000000000', 'files': ['contents.rst', 'eula.rst', 'index_content.rst', 'third-party-licenses.rst', 'contents/contents-eula.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6b922c5866dd8c7c4799b91b66ec0d604a2523cf', 'message': 'Adds a note about pdf\n\nChange-Id: Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d\n'}]",0,185001,6b922c5866dd8c7c4799b91b66ec0d604a2523cf,17,3,4,13082,,,0,"Adds a note about pdf

Change-Id: Idf0f80ee0fbf35836c7f41cf41fae3452d9ab95d
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/01/185001/1 && git format-patch -1 --stdout FETCH_HEAD,"['contents.rst', 'eula.rst', 'index_content.rst', 'third-party-licenses.rst']",4,913e408b82ff0b9548ed56fe5d5f74b975ad458b,license-note-add,,.. index:: Third-Party Components Licenses =============================== Third-Party Components Licenses =============================== Mirantis OpenStack includes a number of third-party open source components: `DEB Packages Licenses <http://docs.mirantis.com/openstack/fuel/fuel-6.0/pdf/Mirantis-OpenStack-6.0-DEB-packages-licenses.pdf>`__ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ `RPM Packages Licenses <http://docs.mirantis.com/openstack/fuel/fuel-6.0/pdf/Mirantis-OpenStack-6.0-RPM-packages-licenses.pdf>`__ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ `JavaScript Libraries Licenses <http://docs.mirantis.com/openstack/fuel/fuel-6.0/pdf/Mirantis-OpenStack-6.0-JS-libraries-licenses.pdf>`__ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ,24,26
openstack%2Foslo.messaging~master~I945b30ebad35f463220eedc092c7fcd958740bd7,openstack/oslo.messaging,master,I945b30ebad35f463220eedc092c7fcd958740bd7,rabbit: doc fixes,MERGED,2015-05-26 09:02:29.000000000,2015-05-27 08:19:23.000000000,2015-05-27 08:19:22.000000000,"[{'_account_id': 3}, {'_account_id': 2813}]","[{'number': 1, 'created': '2015-05-26 09:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f6363b7fe25ac45ea08445f06c868e1fb05f62d1', 'message': 'rabbit: doc fixes\n\nChange-Id: I945b30ebad35f463220eedc092c7fcd958740bd7\n'}, {'number': 2, 'created': '2015-05-27 06:37:54.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/336e3c8f60be3511b4768e65bd199df177ebbd89', 'message': 'rabbit: doc fixes\n\nChange-Id: I945b30ebad35f463220eedc092c7fcd958740bd7\n'}]",0,185538,336e3c8f60be3511b4768e65bd199df177ebbd89,8,2,2,2813,,,0,"rabbit: doc fixes

Change-Id: I945b30ebad35f463220eedc092c7fcd958740bd7
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/38/185538/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,f6363b7fe25ac45ea08445f06c868e1fb05f62d1,sileht/refactor, # List of notification queue declared on the channel to avoid # unnecessary redeclaration. This list is resetted each time # the connection is resetted in Connection._set_current_channel When the exchange is missing instead of silently creates an exchange them yet. If the future consumer bind the default queue it can retrieve, When the exchange is missing instead of silency creates an exchange them yet. If the futur consumer bind the default queue it can retrieve,5,2
openstack%2Fpython-heatclient~master~I5861ab178ae8bf4861c93941c33b551b7f90e835,openstack/python-heatclient,master,I5861ab178ae8bf4861c93941c33b551b7f90e835,Update hacking version to fix pep8 gate job,MERGED,2015-05-27 03:46:19.000000000,2015-05-27 08:06:03.000000000,2015-05-27 08:06:00.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 8833}, {'_account_id': 10873}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-05-27 03:46:19.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/58fd470f959e553397771c95486f134e6ba4920e', 'message': 'Update hacking version to fix pep8 gate job\n\nAny new failing rules have just been added to ignore for now, so\nthat the gate can be unblocked quickly, although future changes\nwhich un-ignore those rules would be welcome.\n\nChange-Id: I5861ab178ae8bf4861c93941c33b551b7f90e835\n'}]",0,185834,58fd470f959e553397771c95486f134e6ba4920e,10,6,1,4571,,,0,"Update hacking version to fix pep8 gate job

Any new failing rules have just been added to ignore for now, so
that the gate can be unblocked quickly, although future changes
which un-ignore those rules would be welcome.

Change-Id: I5861ab178ae8bf4861c93941c33b551b7f90e835
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/34/185834/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,58fd470f959e553397771c95486f134e6ba4920e,hacking,"ignore = E123,E126,E128,E241,E265,E713,H202,H405,H238",,2,1
openstack%2Ftrove-integration~master~I58e45e7025b62a603dec16e012500e4ae2a92734,openstack/trove-integration,master,I58e45e7025b62a603dec16e012500e4ae2a92734,code:line 17:apt-key adv --keyserver hkp://keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A It could not get valid OpenPGP data,ABANDONED,2015-05-07 04:17:22.000000000,2015-05-27 08:01:03.000000000,,"[{'_account_id': 3}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 14576}]","[{'number': 1, 'created': '2015-05-07 04:17:22.000000000', 'files': ['scripts/files/elements/ubuntu-mysql/pre-install.d/10-percona-apt-key'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/ab6ff123ac55e1f6c2f9607fccc5377daddb34ab', 'message': 'code:line 17:apt-key adv --keyserver hkp://keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A\nIt could not get valid OpenPGP data\n\nFixes Bug 1451644\n\nChange-Id: I58e45e7025b62a603dec16e012500e4ae2a92734\n'}]",0,180851,ab6ff123ac55e1f6c2f9607fccc5377daddb34ab,9,6,1,16246,,,0,"code:line 17:apt-key adv --keyserver hkp://keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A
It could not get valid OpenPGP data

Fixes Bug 1451644

Change-Id: I58e45e7025b62a603dec16e012500e4ae2a92734
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/51/180851/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/files/elements/ubuntu-mysql/pre-install.d/10-percona-apt-key'],1,ab6ff123ac55e1f6c2f9607fccc5377daddb34ab,bug/1451644, apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv-keys 1C4CBDCDCD2EFD2A ,gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 1C4CBDCDCD2EFD2A,4,1
openstack%2Fos-net-config~master~I9d226e032eb1cb411b6ea617936f4425c7fd2c74,openstack/os-net-config,master,I9d226e032eb1cb411b6ea617936f4425c7fd2c74,Add NM_CONTROLLED=no to each interface configuration,MERGED,2015-05-14 18:00:17.000000000,2015-05-27 07:54:54.000000000,2015-05-27 07:54:54.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}]","[{'number': 1, 'created': '2015-05-14 18:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/b0b859508428111b62656e29276bba736f8f3589', 'message': 'Add NM_CONTROLLED=no to each interface configuration\n\nIn order to allow os-net-config to coexist with NetworkManager, this\npatch adds NM_CONTROLLED=no to the top of each interface configuration.\nThis ensures that NetworkManager will not mess with interfaces that are\nconfigured by os-net-config.\n\nChange-Id: I9d226e032eb1cb411b6ea617936f4425c7fd2c74\n'}, {'number': 2, 'created': '2015-05-14 18:17:14.000000000', 'files': ['os_net_config/tests/test_impl_ifcfg.py', 'os_net_config/impl_ifcfg.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/afcd514b7cb4b9a465c615c0a16d7f6af2a1d0ed', 'message': 'Add NM_CONTROLLED=no to each interface configuration\n\nIn order to allow os-net-config to coexist with NetworkManager, this\npatch adds NM_CONTROLLED=no to the top of each interface configuration.\nThis ensures that NetworkManager will not mess with interfaces that are\nconfigured by os-net-config.\n\nChange-Id: I9d226e032eb1cb411b6ea617936f4425c7fd2c74\n'}]",0,183136,afcd514b7cb4b9a465c615c0a16d7f6af2a1d0ed,15,3,2,12398,,,0,"Add NM_CONTROLLED=no to each interface configuration

In order to allow os-net-config to coexist with NetworkManager, this
patch adds NM_CONTROLLED=no to the top of each interface configuration.
This ensures that NetworkManager will not mess with interfaces that are
configured by os-net-config.

Change-Id: I9d226e032eb1cb411b6ea617936f4425c7fd2c74
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/36/183136/1 && git format-patch -1 --stdout FETCH_HEAD,['os_net_config/impl_ifcfg.py'],1,b0b859508428111b62656e29276bba736f8f3589,nm_controlled_no," data += ""NM_CONTROLLED=no\n""",,1,0
openstack%2Frally~master~I93626ee6ff8dc75cb94adaabf7c4f419367b58d1,openstack/rally,master,I93626ee6ff8dc75cb94adaabf7c4f419367b58d1,Add sshutils._put_file_shell,MERGED,2015-05-21 12:29:05.000000000,2015-05-27 07:49:34.000000000,2015-05-27 07:49:33.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-21 12:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2da620e7ff0068e3861340d774df3cce41db2fbb', 'message': ""Add sshutils._put_file_shell\n\nSome images such as cirros have no SFTP client installed.\nImplemented function `sshutils._put_file_shell' generates\na simple shell script that uploads the file as a here-doc.\n\nChange-Id: I93626ee6ff8dc75cb94adaabf7c4f419367b58d1\nImplements: blueprint vm-workloads-framework\n""}, {'number': 2, 'created': '2015-05-21 20:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/35f114d5cf7798803602742927fbf09a6c31107f', 'message': ""Add sshutils._put_file_shell\n\nSome images such as cirros have no SFTP client installed.\nImplemented function `sshutils._put_file_shell' generates\na simple shell script that uploads the file as a here-doc.\n\nChange-Id: I93626ee6ff8dc75cb94adaabf7c4f419367b58d1\nImplements: blueprint vm-workloads-framework\n""}, {'number': 3, 'created': '2015-05-26 14:41:29.000000000', 'files': ['rally/common/sshutils.py', 'tests/unit/common/test_sshutils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ab1c053a6e53f682285ec52bd56ecc1131ffe172', 'message': ""Add sshutils._put_file_shell\n\nSome images such as cirros have no SFTP client installed.\nImplemented function `sshutils._put_file_shell' generates\na simple shell script that uploads the file as a here-doc.\n\nChange-Id: I93626ee6ff8dc75cb94adaabf7c4f419367b58d1\nImplements: blueprint vm-workloads-framework\n""}]",1,184767,ab1c053a6e53f682285ec52bd56ecc1131ffe172,21,5,3,13609,,,0,"Add sshutils._put_file_shell

Some images such as cirros have no SFTP client installed.
Implemented function `sshutils._put_file_shell' generates
a simple shell script that uploads the file as a here-doc.

Change-Id: I93626ee6ff8dc75cb94adaabf7c4f419367b58d1
Implements: blueprint vm-workloads-framework
",git fetch https://review.opendev.org/openstack/rally refs/changes/67/184767/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/common/sshutils.py', 'tests/unit/common/test_sshutils.py']",2,2da620e7ff0068e3861340d774df3cce41db2fbb,bp/vm-workloads-framework," @mock.patch(""six.moves.StringIO"") @mock.patch(""rally.common.sshutils.open"", side_effect=mock.mock_open(read_data=""foobar""), create=True) def test__put_file_shell(self, mock_open, mock_stringio): self.ssh.execute = mock.Mock() self.ssh._put_file_shell(""localfile"", ""remotefile"", 0o42) self.assertEqual([ mock.call(""cat > remotefile <<'SHELL_EOF_SHELL'\n""), mock.call(""foobar""), mock.call(""\nSHELL_EOF_SHELL\n""), mock.call(""chmod 042 remotefile\n"") ], mock_stringio.return_value.write.mock_calls) self.ssh.execute.assert_called_once_with( ""/bin/sh"", stdin=mock_stringio.return_value) def test__put_file_sftp(self, mock_stat): self.ssh._put_file_sftp(""localfile"", ""remotefile"") def test__put_file_sftp_mode(self): self.ssh._put_file_sftp(""localfile"", ""remotefile"", mode=0o753) def test_put_file(self): self.ssh._put_file_sftp = mock.Mock( side_effect=sshutils.paramiko.SSHException()) self.ssh._put_file_shell = mock.Mock() self.ssh.put_file(""foo"", ""bar"", 42) self.ssh._put_file_sftp.assert_called_once_with(""foo"", ""bar"", mode=42) self.ssh._put_file_shell.assert_called_once_with(""foo"", ""bar"", mode=42)"," def test_put_file(self, mock_stat): self.ssh.put_file(""localfile"", ""remotefile"") def test_put_file_mode(self): self.ssh.put_file(""localfile"", ""remotefile"", mode=0o753)",54,11
openstack%2Fzaqar~master~If687a982ed74f3b104df845c90365f2dd0c8f4df,openstack/zaqar,master,If687a982ed74f3b104df845c90365f2dd0c8f4df,Imported Translations from Transifex,MERGED,2015-05-16 07:34:03.000000000,2015-05-27 07:40:04.000000000,2015-05-27 07:40:01.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-05-16 07:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d4c943abe8b7a1eee9d8f01d0ff010cad5138cb9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 2, 'created': '2015-05-17 06:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fdf5b6ad09488de25c38b2c4707b81b7ba25a7a2', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 3, 'created': '2015-05-18 06:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fbe957226bde6891d6371a1f288dcbd50c6b7931', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 4, 'created': '2015-05-19 06:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1561e52dd55694122693ccbe2c23af2ef45d8a6e', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 5, 'created': '2015-05-20 06:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9c3c3a7ce673052e7c58e7e6d83eaa1c6ef3a2f7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 6, 'created': '2015-05-21 06:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ff24a0948d78b7df3401d98107a8280dbc5ab00d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 7, 'created': '2015-05-22 06:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7b61fd4acb4af0fffe8b3481f4bb55561d6ac69a', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 8, 'created': '2015-05-23 06:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d940e1583d9c8b8f44bb01f7d4249e12d59e88ee', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 9, 'created': '2015-05-24 06:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/df61791f4e17ef8e26170164201a7a4aba4d0ad9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 10, 'created': '2015-05-25 06:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f6cd119530eb7cf8005cb936b941a06b579afdc1', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 11, 'created': '2015-05-26 06:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ba87703294d11b5f106e2f6d3109fd820f2c1053', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}, {'number': 12, 'created': '2015-05-27 06:02:18.000000000', 'files': ['zaqar/locale/fr/LC_MESSAGES/zaqar-log-error.po'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/23ad93e9c664bdf0be08c308b09dd7259e5dd1d9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df\n'}]",0,183770,23ad93e9c664bdf0be08c308b09dd7259e5dd1d9,28,2,12,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If687a982ed74f3b104df845c90365f2dd0c8f4df
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/70/183770/10 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/locale/fr/LC_MESSAGES/zaqar-log-error.po'],1,d4c943abe8b7a1eee9d8f01d0ff010cad5138cb9,transifex/translations,"# Translations template for zaqar. # Copyright (C) 2015 ORGANIZATION # This file is distributed under the same license as the zaqar project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014-2015 msgid """" msgstr """" ""Project-Id-Version: Zaqar\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2015-05-16 07:34+0000\n"" ""PO-Revision-Date: 2015-05-15 17:20+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language-Team: French (http://www.transifex.com/projects/p/zaqar/language/"" ""fr/)\n"" ""Language: fr\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" #, python-format msgid ""Original exception being dropped: %s"" msgstr ""L' exception d'origine est supprimé: %s"" #, python-format msgid ""Unexpected exception occurred %d time(s)... retrying."" msgstr ""Une exception inattendue a eu lieu %d temps(s) ... réessayer. "" #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr ""Impossible de libérer le verrou '%s'"" ",,33,0
openstack%2Fzaqar~master~I7a2da87e55fab50ffd2313b649cf4be3a7d50783,openstack/zaqar,master,I7a2da87e55fab50ffd2313b649cf4be3a7d50783,Fix duplicated test cases of notifier,MERGED,2015-04-27 11:24:05.000000000,2015-05-27 07:39:24.000000000,2015-05-27 07:39:22.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-04-27 11:24:05.000000000', 'files': ['zaqar/tests/unit/notification/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b7a66c971a1a84fc1d1b7d127eddcbb6951e4828', 'message': 'Fix duplicated test cases of notifier\n\nChange-Id: I7a2da87e55fab50ffd2313b649cf4be3a7d50783\n'}]",0,177716,b7a66c971a1a84fc1d1b7d127eddcbb6951e4828,8,4,1,6484,,,0,"Fix duplicated test cases of notifier

Change-Id: I7a2da87e55fab50ffd2313b649cf4be3a7d50783
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/16/177716/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/tests/unit/notification/test_notifier.py'],1,b7a66c971a1a84fc1d1b7d127eddcbb6951e4828,tiny_test_duplicated," self.messages[0]) mock_post.assert_called_with(self.subscription[0]['subscriber'], self.messages[1]) mock_post.assert_called_with(self.subscription[1]['subscriber'],"," mock_post.assert_called_with(self.subscription[0]['subscriber'], self.messages[0]) mock_post.assert_called_with(self.subscription[1]['subscriber'], self.messages[1])",4,4
openstack%2Fpython-zaqarclient~master~Icd30e32a17247790dfd57d6420d67f9140020db6,openstack/python-zaqarclient,master,Icd30e32a17247790dfd57d6420d67f9140020db6,Fix handling of 1.1 API,MERGED,2015-04-27 14:36:05.000000000,2015-05-27 07:37:40.000000000,2015-05-27 07:37:37.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 7385}]","[{'number': 1, 'created': '2015-04-27 14:36:05.000000000', 'files': ['zaqarclient/queues/v1/core.py', 'tests/unit/queues/v1/test_queues.py', 'zaqarclient/queues/v1/iterator.py', 'zaqarclient/queues/v1/message.py', 'tests/functional/queues/v1/test_queues.py', 'zaqarclient/tests/queues/queues.py', 'zaqarclient/queues/v1/api.py', 'zaqarclient/queues/v1/queues.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/0047c541169747064b57464d6dcd0c07958c27e9', 'message': 'Fix handling of 1.1 API\n\nThis fixes various behaviors of the client talking to the v1.1 API, and\nenables functional tests for queues.\n\nChange-Id: Icd30e32a17247790dfd57d6420d67f9140020db6\nCloses-Bug: #1446677\nCloses-Bug: #1446679\n'}]",0,177792,0047c541169747064b57464d6dcd0c07958c27e9,9,4,1,7385,,,0,"Fix handling of 1.1 API

This fixes various behaviors of the client talking to the v1.1 API, and
enables functional tests for queues.

Change-Id: Icd30e32a17247790dfd57d6420d67f9140020db6
Closes-Bug: #1446677
Closes-Bug: #1446679
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/92/177792/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqarclient/queues/v1/core.py', 'tests/unit/queues/v1/test_queues.py', 'zaqarclient/queues/v1/iterator.py', 'zaqarclient/queues/v1/message.py', 'tests/functional/queues/v1/test_queues.py', 'zaqarclient/tests/queues/queues.py', 'zaqarclient/queues/v1/api.py', 'zaqarclient/queues/v1/queues.py']",8,0047c541169747064b57464d6dcd0c07958c27e9,bug/1446677,"from zaqarclient import errors if self.client.api_version >= 1.1: raise errors.InvalidOperation(""Unavailable on versions >= 1.1"") else: return core.queue_exists(trans, req, self._name) if self.client.api_version >= 1.1: self._metadata = core.queue_get(trans, req, self._name) else: self._metadata = core.queue_get_metadata(trans, req, self._name)"," return core.queue_exists(trans, req, self._name) self._metadata = core.queue_get_metadata(trans, req, self._name)",79,9
openstack%2Fpython-zaqarclient~master~Id54b2381f00d9905c4bb07821f54c5aaaa48d970,openstack/python-zaqarclient,master,Id54b2381f00d9905c4bb07821f54c5aaaa48d970,Drop use of 'oslo' namespace package,MERGED,2015-05-06 19:49:50.000000000,2015-05-27 07:37:15.000000000,2015-05-27 07:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 8119}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-05-06 19:49:50.000000000', 'files': ['zaqarclient/_i18n.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f81c36d4fe31815ed6692b573ad660067151d215', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: Id54b2381f00d9905c4bb07821f54c5aaaa48d970\n""}]",0,180711,f81c36d4fe31815ed6692b573ad660067151d215,9,5,1,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: Id54b2381f00d9905c4bb07821f54c5aaaa48d970
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/11/180711/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqarclient/_i18n.py'],1,f81c36d4fe31815ed6692b573ad660067151d215,bp/remove-namespace-packages,from oslo_i18n import * # noqa,from oslo.i18n import * # noqa,1,1
openstack%2Ffuel-ostf~master~I72330d18e95207e9e7fa454a78bcf1cab7dbd2f0,openstack/fuel-ostf,master,I72330d18e95207e9e7fa454a78bcf1cab7dbd2f0,Fix bug in OSTF Heat tests,MERGED,2015-05-26 09:28:07.000000000,2015-05-27 07:34:23.000000000,2015-05-27 07:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13962}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-05-26 09:28:07.000000000', 'files': ['fuel_health/heatmanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/8db0ea7e0617d240382f3669c7c0b11dd5ba2c72', 'message': ""Fix bug in OSTF Heat tests\n\nIn case of previous implementation of _create_stack():\n\n    stack_name = rand_name('ost1_test-')\n    client.stacks.create(stack_name=stack_name,\n                         template=template,\n                         parameters=parameters,\n                         disable_rollback=disable_rollback)\n    stack = self._find_stack(client, 'stack_name', stack_name)\n    self.addCleanup(self._delete_stack, stack.id)\n\nthe following situation was possible: if _find_stack doesn't get\nlist of stacks in 20 sec (timeout), step will fail with timeout error\nand addCleanup() won't get 'stack.id',that's why created stack won't be\ndeleted.\n\nChange-Id: I72330d18e95207e9e7fa454a78bcf1cab7dbd2f0\nCloses-Bug: #1458639\n""}]",3,185544,8db0ea7e0617d240382f3669c7c0b11dd5ba2c72,15,10,1,8592,,,0,"Fix bug in OSTF Heat tests

In case of previous implementation of _create_stack():

    stack_name = rand_name('ost1_test-')
    client.stacks.create(stack_name=stack_name,
                         template=template,
                         parameters=parameters,
                         disable_rollback=disable_rollback)
    stack = self._find_stack(client, 'stack_name', stack_name)
    self.addCleanup(self._delete_stack, stack.id)

the following situation was possible: if _find_stack doesn't get
list of stacks in 20 sec (timeout), step will fail with timeout error
and addCleanup() won't get 'stack.id',that's why created stack won't be
deleted.

Change-Id: I72330d18e95207e9e7fa454a78bcf1cab7dbd2f0
Closes-Bug: #1458639
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/44/185544/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/heatmanager.py'],1,8db0ea7e0617d240382f3669c7c0b11dd5ba2c72,," self.addCleanup(self._delete_stack, stack_name) def _delete_stack(self, stack_name): LOG.debug(""Deleting stack: %s"" % stack_name) stack = self._find_stack(self.heat_client, 'stack_name', stack_name) if stack is None: self.heat_client.stacks.delete(stack.id) self._wait_for_stack_deleted(stack.id) LOG.debug(""Resource '%s' has been deleted."" % stack_name)"," self.addCleanup(self._delete_stack, stack.id) def _delete_stack(self, stack_id): LOG.debug(""Deleting stack: %s"" % stack_id) if self._find_stack(self.heat_client, 'id', stack_id) is None: self.heat_client.stacks.delete(stack_id) self._wait_for_stack_deleted(stack_id) LOG.debug(""Resource '%s' has been deleted."" % stack_id)",10,7
openstack%2Ftrove~master~I74074621686cc408b15d3a2146da41a4fd767bae,openstack/trove,master,I74074621686cc408b15d3a2146da41a4fd767bae,Fix typo in mysql guestagent service.py,ABANDONED,2015-05-20 13:51:40.000000000,2015-05-27 07:19:59.000000000,,"[{'_account_id': 3}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 14576}, {'_account_id': 15854}]","[{'number': 1, 'created': '2015-05-20 13:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/00c41a1af71086b56b020f6850253c01521bd68a', 'message': 'Fix typo get_auth_password() in mysql guestagent service.py\n\nChange-Id: I74074621686cc408b15d3a2146da41a4fd767bae\n'}, {'number': 2, 'created': '2015-05-20 21:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c3508a5a602f7d402a70c870fdbbb55507fc1799', 'message': 'Fix typo in mysql guestagent service.py\n\nChange-Id: I74074621686cc408b15d3a2146da41a4fd767bae\n'}, {'number': 3, 'created': '2015-05-21 14:06:54.000000000', 'files': ['trove/guestagent/datastore/mysql/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/41800cd761cab1fe3d45d3f534e732d7284ae493', 'message': 'Fix typo in mysql guestagent service.py\n\nCloses-Bug: #1457045\nChange-Id: I74074621686cc408b15d3a2146da41a4fd767bae\n'}]",1,184496,41800cd761cab1fe3d45d3f534e732d7284ae493,18,7,3,15854,,,0,"Fix typo in mysql guestagent service.py

Closes-Bug: #1457045
Change-Id: I74074621686cc408b15d3a2146da41a4fd767bae
",git fetch https://review.opendev.org/openstack/trove refs/changes/96/184496/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/datastore/mysql/service.py'],1,00c41a1af71086b56b020f6850253c01521bd68a,bug/1457045," ""'/password\\t=/{print $3; exit}'"","," ""/password\\t=/{print $3; exit}"",",1,1
openstack%2Fcinder~master~I213776ee6aef6e5dee2807c19b7eea05af23d6c0,openstack/cinder,master,I213776ee6aef6e5dee2807c19b7eea05af23d6c0,Fix overwrite of params in SF image cache update,MERGED,2015-05-12 21:50:22.000000000,2015-05-27 07:11:15.000000000,2015-05-13 17:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14259}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-12 21:50:22.000000000', 'files': ['cinder/volume/drivers/solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf4c885c20fb46672a758a6ec94e61346fa317cc', 'message': ""Fix overwrite of params in SF image cache update\n\nIn the update cache volume routine of the SolidFire driver\nwe're unintentionally re-initializing the params variable\nwhen assigning volID as opposed to just appending another key\nto it.\n\nThis patch fixes that.\n\nChange-Id: I213776ee6aef6e5dee2807c19b7eea05af23d6c0\nCloses-Bug: #1454425\n""}]",0,182471,cf4c885c20fb46672a758a6ec94e61346fa317cc,41,27,1,2243,,,0,"Fix overwrite of params in SF image cache update

In the update cache volume routine of the SolidFire driver
we're unintentionally re-initializing the params variable
when assigning volID as opposed to just appending another key
to it.

This patch fixes that.

Change-Id: I213776ee6aef6e5dee2807c19b7eea05af23d6c0
Closes-Bug: #1454425
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/182471/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/solidfire.py'],1,cf4c885c20fb46672a758a6ec94e61346fa317cc,bug/1454425, params['volumeID'] = sf_vol['volumeID'], params = {'volumeID': sf_vol['volumeID']},1,1
openstack%2Fpython-mistralclient~master~Id4b7594c6873e29b45d2b53417d316e0ed5b1e39,openstack/python-mistralclient,master,Id4b7594c6873e29b45d2b53417d316e0ed5b1e39,Make create commands cut long output,MERGED,2015-05-20 09:36:25.000000000,2015-05-27 07:09:21.000000000,2015-05-27 07:09:20.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}]","[{'number': 1, 'created': '2015-05-20 09:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/9f6a58ebd98bd8b250eeb21db5f84388ad6155bb', 'message': 'Make create commands cut long output\n\n * When we use workflow-create of action-create cmds,\n   client uses default format function for output the data.\n   But in case long strings (e.g. a lot of input keys to\n   workflow or action) table is crashed by these long strings.\n   Using format_list function solves the problem.\n\nChange-Id: Id4b7594c6873e29b45d2b53417d316e0ed5b1e39\n'}, {'number': 2, 'created': '2015-05-20 17:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/6fddec09ff836564a1d39f21cac9fabe56b7eb39', 'message': 'Make create commands cut long output\n\n * When we use workflow-create or action-create cmds,\n   client uses default format function for data output.\n   But in case of long strings (e.g. a lot of input keys to\n   workflow or action) table is crashed by these long strings.\n   Using format_list function solves the problem.\n\nChange-Id: Id4b7594c6873e29b45d2b53417d316e0ed5b1e39\n'}, {'number': 3, 'created': '2015-05-20 17:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/dd6eae782a50df52d24934d2be72890e79d2b1dc', 'message': 'Make create commands cut long output\n\n * When we use workflow-create or action-create cmds,\n   client uses default format function for data output.\n   But in case of long strings (e.g. a lot of input keys to\n   workflow or action) table is crashed by these long strings.\n   Using format_list function solves the problem.\n\nChange-Id: Id4b7594c6873e29b45d2b53417d316e0ed5b1e39\n'}, {'number': 4, 'created': '2015-05-22 09:57:27.000000000', 'files': ['mistralclient/commands/v2/actions.py', 'mistralclient/tests/unit/v2/test_cli_actions.py', 'mistralclient/commands/v2/workflows.py', 'mistralclient/tests/unit/v2/test_cli_workflows.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/e0755168908f8b4ef7fb8f9037dde0ad7fb73d45', 'message': 'Make create commands cut long output\n\n * When we use workflow-create of action-create cmds,\n   client uses default format function for output the data.\n   But in case long strings (e.g. a lot of input keys to\n   workflow or action) table is crashed by these long strings.\n   Using format_list function solves the problem.\n\nChange-Id: Id4b7594c6873e29b45d2b53417d316e0ed5b1e39\n'}]",0,184446,e0755168908f8b4ef7fb8f9037dde0ad7fb73d45,18,5,4,7700,,,0,"Make create commands cut long output

 * When we use workflow-create of action-create cmds,
   client uses default format function for output the data.
   But in case long strings (e.g. a lot of input keys to
   workflow or action) table is crashed by these long strings.
   Using format_list function solves the problem.

Change-Id: Id4b7594c6873e29b45d2b53417d316e0ed5b1e39
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/46/184446/4 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/commands/v2/actions.py', 'mistralclient/commands/v2/workflows.py']",2,9f6a58ebd98bd8b250eeb21db5f84388ad6155bb,simplify_create_cmd, return format_list, return format,2,2
openstack%2Ffuel-docs~master~Iabbc6cd3d34aa875dbe1b762ebe8ea535c7e906c,openstack/fuel-docs,master,Iabbc6cd3d34aa875dbe1b762ebe8ea535c7e906c,tab back updates,MERGED,2015-05-26 19:09:09.000000000,2015-05-27 07:07:22.000000000,2015-05-27 07:07:22.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 13695}]","[{'number': 1, 'created': '2015-05-26 19:09:09.000000000', 'files': ['_templates/mirantis/static/index.html', 'index_content.rst', '_templates/mirantis/static/styles.css', '_templates/mirantis/static/abtest.js'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1f56f3d4c0e337f1a578db37fc4514186516ff7a', 'message': 'tab back updates\n\nChange-Id: Iabbc6cd3d34aa875dbe1b762ebe8ea535c7e906c\n'}]",0,185706,1f56f3d4c0e337f1a578db37fc4514186516ff7a,9,4,1,15341,,,0,"tab back updates

Change-Id: Iabbc6cd3d34aa875dbe1b762ebe8ea535c7e906c
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/06/185706/1 && git format-patch -1 --stdout FETCH_HEAD,"['_templates/mirantis/static/index.html', 'index_content.rst', '_templates/mirantis/static/styles.css', '_templates/mirantis/static/abtest.js']",4,1f56f3d4c0e337f1a578db37fc4514186516ff7a,bootstrap-theme," $(window).on(""popstate"", function (e) {function showHashTab(){ if(location.hash){ var activeTab = $('[href=' + location.hash + ']'); if (activeTab.length) { activeTab.tab('show'); } } } function populateContent(callback){ $.get(""index_content.html"", function (data) { var homeTitle = $(data).find('.home-title').html(); var home = $(data).find('.what-is-mirantis-openstack').html(); var guides = $(data).find('#guides'); populateGuides(guides); var pdfs = $(data).find('#pdf .reference'); populatePdfs(pdfs); var download = $(data).find('#download-now'); populateDownload(download); $('#home').html(home); $('#main').html(homeTitle); }); $.get(""eula.html"", function (data) { var fuel_license = $(data).find('#fuel-license').html(); $('#fuel-license').html($(fuel_license).find('pre')); }); $.get(""third-party-licenses.html"", function (data) { var third_party = $(data).find("".section > .section""); $(third_party).each(function (i, v) { var el = $(v).find('.reference'); var href = $(el).attr('href'); var heading = $(el).text(); $('#third-party-licenses').append('<a class=""btn btn-default red btn-block"" href=""' + href + '""><i class=""fa fa-file-pdf-o""></i> ' + heading + '</a>'); }); }); callback(); } populateContent(showHashTab); history.pushState({}, '', $(this).attr('href'));"," window.addEventListener(""popstate"", function (e) { $.get(""index_content.html"", function (data) { var homeTitle = $(data).find('.home-title').html(); var home = $(data).find('.what-is-mirantis-openstack').html(); var guides = $(data).find('#guides'); populateGuides(guides); var pdfs = $(data).find('#pdf .reference'); populatePdfs(pdfs); var download = $(data).find('#download-mirantis-openstack'); populateDownload(download); $('#home').html(home); $('#main').html(homeTitle); }); $.get(""eula.html"", function (data) { var fuel_license = $(data).find('#fuel-license').html(); $('#fuel-license').html($(fuel_license).find('pre')); }); $.get(""third-party-licenses.html"", function (data) { var third_party = $(data).find("".section > .section""); $(third_party).each(function (i, v) { var el = $(v).find('.reference'); var href = $(el).attr('href'); var heading = $(el).text(); $('#third-party-licenses').append('<a class=""btn btn-default red btn-block"" href=""' + href + '""><i class=""fa fa-file-pdf-o""></i> ' + heading + '</a>'); }); }); history.pushState(null, null, $(this).attr('href'));",69,113
openstack%2Fpython-mistralclient~master~Iad4a667f65373cf74eb9d4613a3336fe1d46b90b,openstack/python-mistralclient,master,Iad4a667f65373cf74eb9d4613a3336fe1d46b90b,Remove unnecessary validation in update environment form the client,MERGED,2015-05-26 12:38:52.000000000,2015-05-27 07:06:45.000000000,2015-05-27 07:06:45.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-26 12:38:52.000000000', 'files': ['mistralclient/api/v2/environments.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/df46403d8cc893995aca135eb04d22a37ac8983c', 'message': 'Remove unnecessary validation in update environment form the client\n\nChange-Id: Iad4a667f65373cf74eb9d4613a3336fe1d46b90b\nCloses-Bug: #1457211\n'}]",0,185576,df46403d8cc893995aca135eb04d22a37ac8983c,7,5,1,15881,,,0,"Remove unnecessary validation in update environment form the client

Change-Id: Iad4a667f65373cf74eb9d4613a3336fe1d46b90b
Closes-Bug: #1457211
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/76/185576/1 && git format-patch -1 --stdout FETCH_HEAD,['mistralclient/api/v2/environments.py'],1,df46403d8cc893995aca135eb04d22a37ac8983c,bug/1457211,," attrs = kwargs.keys() attrs.remove('name') allowed = ['description', 'variables', 'scope'] disallowed = list(set(attrs) - set(allowed)) if disallowed: raise ValueError('The attributes %s cannot be updated.' % disallowed) ",0,9
openstack%2Fdragonflow~master~I6098fcf7f5f41ec196e84d9615993607c45f58c7,openstack/dragonflow,master,I6098fcf7f5f41ec196e84d9615993607c45f58c7,Simplify the datapath port desc handling,ABANDONED,2015-05-14 06:14:24.000000000,2015-05-27 07:02:48.000000000,,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-14 06:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9aae55ed29fd931901691215c7aaac9c3efba63e', 'message': 'Simplify the datapath port desc handling\n\nFixes bug and simplifying the data path port description handling\n\nChange-Id: I6098fcf7f5f41ec196e84d9615993607c45f58c7\n'}, {'number': 2, 'created': '2015-05-14 06:39:23.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ca12dfa1394d7ad9af4f4a62d560ebeac2d009ba', 'message': 'Simplify the datapath port desc handling\n\nFixes bug and simplifying the data path port description handling\n\nChange-Id: I6098fcf7f5f41ec196e84d9615993607c45f58c7\n'}]",1,182940,ca12dfa1394d7ad9af4f4a62d560ebeac2d009ba,9,5,2,11343,,,0,"Simplify the datapath port desc handling

Fixes bug and simplifying the data path port description handling

Change-Id: I6098fcf7f5f41ec196e84d9615993607c45f58c7
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/40/182940/2 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/controller/l3_openflow_app.py', 'dragonflow/tests/unit/test_openflow_app.py']",2,9aae55ed29fd931901691215c7aaac9c3efba63e,fix_bug_and_simplify_subnet_adding_in_dp, call_args_list[i][0][mac_id_arg_vrouter_arp]), call_args_list[i][0][mac_id_arg_vrouter_arp]),27,24
openstack%2Ftripleo-heat-templates~master~I4631f962415164975143e94ec0b251ee5972c552,openstack/tripleo-heat-templates,master,I4631f962415164975143e94ec0b251ee5972c552,Add Keystone as Pacemaker resource,MERGED,2015-04-29 14:15:52.000000000,2015-05-27 06:53:34.000000000,2015-05-27 06:53:32.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-04-29 14:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e36aeda0b9743f5add235176ada03c3555c74efd', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 2, 'created': '2015-04-29 20:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5d5924147b35b6b3ff63626e683347d1955ee428', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 3, 'created': '2015-04-30 14:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2c7e492c41c4f759a2b4f5a1cc2174dda6a036af', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 4, 'created': '2015-04-30 14:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cfb4005618e1b8dc3b08cac7570ef571fe62a567', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 5, 'created': '2015-05-04 13:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2dd75af44fa214b2017784cb0554f2d56e526a76', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 6, 'created': '2015-05-05 14:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27ec504f30d8d5af1c1283ca827637aa8e42d38b', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 7, 'created': '2015-05-06 19:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7a737cb1b67e28c2d8f3404346ae72a54ab123f9', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 8, 'created': '2015-05-08 18:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fb39a1f0df7a278e99f321d282272f29c4043008', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 9, 'created': '2015-05-08 18:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a4bf240344a32307a2c7e8d7e84772351e71b65e', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 10, 'created': '2015-05-08 18:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc8eefa937e4fd4527465f63ffe0d3374fe48b1f', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\nDepends-On: I6eb3d137173d2542a8083bbca3acf3bee10c5919\n'}, {'number': 11, 'created': '2015-05-08 19:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a46e1f82a4d82f9c85d77194fd44f8769933cee8', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\nDepends-On: I6eb3d137173d2542a8083bbca3acf3bee10c5919\n'}, {'number': 12, 'created': '2015-05-13 20:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/62c5dc4cf4b0aa24234fcc4d6743cb480c068cbd', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\nDepends-On: I6eb3d137173d2542a8083bbca3acf3bee10c5919\n'}, {'number': 13, 'created': '2015-05-22 08:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f68509e3d83de5b2e9839619091ade254290fb1', 'message': 'Add Keystone as Pacemaker resource\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 14, 'created': '2015-05-22 08:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b63f1ec752ec2301ef57c56141eb3d6efdc1dcfc', 'message': 'Add Keystone as a Pacemaker resource when EnablePacemaker\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}, {'number': 15, 'created': '2015-05-22 08:33:59.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13044ecee11e476a8b2f62091d9b517d46813573', 'message': 'Add Keystone as Pacemaker resource\n\nChange-Id: I4631f962415164975143e94ec0b251ee5972c552\n'}]",11,178694,13044ecee11e476a8b2f62091d9b517d46813573,80,9,15,8399,,,0,"Add Keystone as Pacemaker resource

Change-Id: I4631f962415164975143e94ec0b251ee5972c552
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/178694/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller.pp'],1,e36aeda0b9743f5add235176ada03c3555c74efd,pacemaker," # Keystone if $enable_pacemaker { if $pacemaker_master { pacemaker::resource::systemd { 'openstack-keystone': clone => true, require => Class['::keystone'], } } } ",,10,0
openstack%2Fdragonflow~master~Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1,openstack/dragonflow,master,Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1,VLAN support fix.,MERGED,2015-05-10 12:30:56.000000000,2015-05-27 06:49:36.000000000,2015-05-27 06:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-10 12:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8eb7deceb87c3e13ccfa862a3bed2e8b4cad090d', 'message': 'VLAN fix to discuss (do not yet merge).\nThe solution consists to:\n - use the existant rule for VLAN in br-int (for inbound traffic)\nand br-{eth} (for outbound traffic).\n - set in the table #60 the VLAN VID (in place of PKT_MARK) from the TUN_ID for\ninter-network traffic.\n - execute the br-int update flow locally after the set controller (to discuss).\n\nChange-Id: Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1\n'}, {'number': 2, 'created': '2015-05-25 13:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1e484a165cb48636ad210547b81a7e6489833ecd', 'message': 'VLAN support fix.\n\nThe solution is compatible with the existing VLAN flows:\n - inbound in br-int that converts the global vlan to the local\n - outbound in br-{eth} that convert the local vlan to the global one\n\nThe initialization is done in the set_controller method after that the controller is sets:\n - the physical bridges rules are reinitiliazed, without the drop flow. packet with the global vlan must also be forwarded.\n      - low priority normal flow\n      - flows that changes the local vlan id to the global one\n - For br-int:\n      - in the table #60 the VLAN global VID from the TUN_ID for inter-network traffic is set\n      - the flows that change the global vlan id to the local one\n\nChange-Id: Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1\n'}, {'number': 3, 'created': '2015-05-27 05:45:27.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py', 'dragonflow/neutron/agent/l2/ovs_dragonflow_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a291417266acce8ce341933bec0ce790e141eea5', 'message': 'VLAN support fix.\n\nThe solution is compatible with the existing VLAN flows:\n - inbound in br-int that converts the global vlan to the local\n - outbound in br-{eth} that convert the local vlan to the global one\n\nThe initialization is done in the set_controller method after that the controller is sets:\n - the physical bridges rules are reinitiliazed, without the drop flow. packet with the global vlan must also be forwarded.\n      - low priority normal flow\n      - flows that changes the local vlan id to the global one\n - For br-int:\n      - in the table #60 the VLAN global VID from the TUN_ID for inter-network traffic is set\n      - the flows that change the global vlan id to the local one\n\nChange-Id: Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1\n'}]",10,181724,a291417266acce8ce341933bec0ce790e141eea5,14,5,3,14249,,,0,"VLAN support fix.

The solution is compatible with the existing VLAN flows:
 - inbound in br-int that converts the global vlan to the local
 - outbound in br-{eth} that convert the local vlan to the global one

The initialization is done in the set_controller method after that the controller is sets:
 - the physical bridges rules are reinitiliazed, without the drop flow. packet with the global vlan must also be forwarded.
      - low priority normal flow
      - flows that changes the local vlan id to the global one
 - For br-int:
      - in the table #60 the VLAN global VID from the TUN_ID for inter-network traffic is set
      - the flows that change the global vlan id to the local one

Change-Id: Ifdc78c6edbe2dc3cef4107fbfb44613b6ae025d1
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/24/181724/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/agent/l2/ovs_dragonflow_neutron_agent.py'],1,8eb7deceb87c3e13ccfa862a3bed2e8b4cad090d,bug/1429601,"from neutron.plugins.common import constants as p_const init_set_controller = False if self.patch_tun_ofport > 0: # Mark the tunnel ID so the data will be transferred to the # br-tun virtual switch, tun id and metadata are local bridge.add_flow(table=""60"", priority=1, actions=""move:NXM_NX_TUN_ID[0..31]"" ""->NXM_NX_PKT_MARK[],"" ""output:%s"" % (self.patch_tun_ofport)) L2OVSControllerAgent.init_set_controller = True def provision_local_vlan2(self, net_uuid, network_type, physical_network, segmentation_id): while not L2OVSControllerAgent.init_set_controller: LOG.debug(""sleep"") eventlet.sleep(1) super(L2OVSControllerAgent, self).provision_local_vlan( net_uuid, network_type, physical_network, segmentation_id) if network_type == p_const.TYPE_VLAN: self.int_br.add_flow(table=""60"", priority=1, actions=""move:NXM_NX_TUN_ID[0..11]"" ""->OXM_OF_VLAN_VID[],"" ""output:%s"" % (self. int_ofports[physical_network])) def provision_local_vlan(self, net_uuid, network_type, physical_network, segmentation_id): # On a restart or crash of OVS, the network associated with this VLAN # will already be assigned, so check for that here before assigning a # new one. lvm = self.local_vlan_map.get(net_uuid) if lvm: lvid = lvm.vlan else: if not self.available_local_vlans: LOG.error(_LE(""No local VLAN available for net-id=%s""), net_uuid) return lvid = self.available_local_vlans.pop() self.local_vlan_map[net_uuid] = ( ovs_neutron_agent.LocalVLANMapping(lvid, network_type, physical_network, segmentation_id)) LOG.info(_LI(""Assigning %(vlan_id)s as local vlan for "" ""net-id=%(net_uuid)s""), {'vlan_id': lvid, 'net_uuid': net_uuid}) eventlet.spawn(self.provision_local_vlan2, net_uuid=net_uuid, network_type=network_type, physical_network=physical_network, segmentation_id=segmentation_id) "," # Mark the tunnel ID so the data will be transferred to the # br-tun virtual switch, tun id and metadata are local bridge.add_flow(table=""60"", priority=1, actions=""move:NXM_NX_TUN_ID[0..31]"" ""->NXM_NX_PKT_MARK[],"" ""output:%s"" % (self.patch_tun_ofport))",58,7
openstack%2Fsenlin~master~Iba9ffecdc7f4ed61eac9b6163db4bc789f034764,openstack/senlin,master,Iba9ffecdc7f4ed61eac9b6163db4bc789f034764,Add TODO wrt start_action function in scheduler,MERGED,2015-05-27 06:07:03.000000000,2015-05-27 06:43:36.000000000,2015-05-27 06:43:35.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-05-27 06:07:03.000000000', 'files': ['TODO.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/374346ccb332c228cd05109e8e797eff82011b3f', 'message': 'Add TODO wrt start_action function in scheduler\n\nThe start_action() entry function could be used for notifying the\nscheduler to pick up any READY actions for execution.\n\nChange-Id: Iba9ffecdc7f4ed61eac9b6163db4bc789f034764\n'}]",0,185846,374346ccb332c228cd05109e8e797eff82011b3f,6,2,1,8246,,,0,"Add TODO wrt start_action function in scheduler

The start_action() entry function could be used for notifying the
scheduler to pick up any READY actions for execution.

Change-Id: Iba9ffecdc7f4ed61eac9b6163db4bc789f034764
",git fetch https://review.opendev.org/openstack/senlin refs/changes/46/185846/1 && git format-patch -1 --stdout FETCH_HEAD,['TODO.rst'],1,374346ccb332c228cd05109e8e797eff82011b3f,TODO," - Revise start_action() in scheduler module so that it can handle cases when action_id specified is None. When ``action_id`` parameter is None, it means that the scheduler will pick a suitable READY action for execution. ",,4,0
openstack%2Fdragonflow~master~If82be23264b5122e86aad5124e2dbc5649deb868,openstack/dragonflow,master,If82be23264b5122e86aad5124e2dbc5649deb868,Sync ports on L2 Agent startup,MERGED,2015-05-14 14:03:20.000000000,2015-05-27 06:39:21.000000000,2015-05-27 06:39:20.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-14 14:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8c88a08ac948b044cdec96ac91f6ec75bab1a6f4', 'message': 'Sync ports on L3 Agent startup\n\nWIP\n\nTODO:\n\n1) Add subnets to the port_context.current object (has only subnet id)\n   need to pull subnet object from DB and attach all subnets\n2) Change sync_port API to support flag to indicate that no flows\n   should be configured and this is just a sync task\n3) Only start the controller application when sync finished\n   (Currently start() happens on init of controller, need to seperate)\n\nChange-Id: If82be23264b5122e86aad5124e2dbc5649deb868\n'}, {'number': 2, 'created': '2015-05-14 14:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/722d314597e3668a1afbb23b352fb304108a3c77', 'message': 'Sync ports on L3 Agent startup\n\nWIP\n\nTODO:\n\n1) Add subnets to the port_context.current object (has only subnet id)\n   need to pull subnet object from DB and attach all subnets\n\n2) Change sync_port API to support flag to indicate that no flows\n   should be configured and this is just a sync task\n\n3) Only start the controller application when sync finished\n   (Currently start() happens on init of controller, need to seperate)\n\nChange-Id: If82be23264b5122e86aad5124e2dbc5649deb868\n'}, {'number': 3, 'created': '2015-05-26 08:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d4fa783560b0cae04d34e996de790b4a64e5bef6', 'message': 'Sync ports on L3 Agent startup\n\nThis patch sync all the ports with the L3 application on the\nL3 Agent startup.\nThis fixes a bug that was noticed during L3 agent startup,\nas the local structures are empty (for ports data).\n\nBefore the agent is started it reads all the ports/subnets/networks\ninformation, build port dictionaries and send that data to the\napplication.\nA special flag was added to the sync_port method in order to\nrecognize that this is not a live port update and no flows\nupdates should be sent\n\nChange-Id: If82be23264b5122e86aad5124e2dbc5649deb868\n'}, {'number': 4, 'created': '2015-05-26 13:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a1452921611a6c0cd156cca15762a4b85bf5e6d3', 'message': 'Sync ports on L2 Agent startup\n\nThis patch sync all the ports with the L3 application on the\nL3 Agent startup.\nThis fixes a bug that was noticed during L3 agent startup,\nas the local structures are empty (for ports data).\n\nBefore the agent is started it reads all the ports/subnets/networks\ninformation, build port dictionaries and send that data to the\napplication.\nA special flag was added to the sync_port method in order to\nrecognize that this is not a live port update and no flows\nupdates should be sent\n\nChange-Id: If82be23264b5122e86aad5124e2dbc5649deb868\n'}, {'number': 5, 'created': '2015-05-26 13:28:45.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py', 'dragonflow/controller/openflow_controller.py', 'dragonflow/controller/base_controller.py', 'dragonflow/neutron/agent/l3/l3_controller_agent.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/99c27b888e63ea3eed20ca7b6c9fc40fd56512e0', 'message': 'Sync ports on L2 Agent startup\n\nThis patch sync all the ports with the L3 application on the\nL3 Agent startup.\nThis fixes a bug that was noticed during L3 agent startup,\nas the local structures are empty (for ports data).\n\nBefore the agent is started it reads all the ports/subnets/networks\ninformation, build port dictionaries and send that data to the\napplication.\nA special flag was added to the sync_port method in order to\nrecognize that this is not a live port update and no flows\nupdates should be sent\n\nChange-Id: If82be23264b5122e86aad5124e2dbc5649deb868\n'}]",1,183051,99c27b888e63ea3eed20ca7b6c9fc40fd56512e0,16,5,5,11343,,,0,"Sync ports on L2 Agent startup

This patch sync all the ports with the L3 application on the
L3 Agent startup.
This fixes a bug that was noticed during L3 agent startup,
as the local structures are empty (for ports data).

Before the agent is started it reads all the ports/subnets/networks
information, build port dictionaries and send that data to the
application.
A special flag was added to the sync_port method in order to
recognize that this is not a live port update and no flows
updates should be sent

Change-Id: If82be23264b5122e86aad5124e2dbc5649deb868
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/51/183051/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/agent/l3/l3_controller_agent.py'],1,8c88a08ac948b044cdec96ac91f6ec75bab1a6f4,sync_ports_on_l3_startup,"from neutron import manager from neutron import context as neutron_context from neutron.plugins.ml2 import db as l2_db from neutron.plugins.ml2 import driver_context # Sync all ports data from neutron to the L3 Agent self.sync_ports_on_startup() # Start the controller application self.controller.start() def sync_ports_on_startup(self): core_plugin = manager.NeutronManager.get_plugin() ctx = neutron_context.get_admin_context() for port in core_plugin.get_ports(ctx): _, binding = l2_db.get_locked_port_and_binding(ctx.session, port['id']) network = core_plugin.get_network(ctx, port['network_id']) port_context = driver_context.PortContext(core_plugin, ctx, port, network, binding, []) segment = port_context.network.network_segments[0] port_context.current['segmentation_id'] = ( segment['segmentation_id']) raise Exception self.controller.sync_port(port_context.current) ",,29,0
openstack%2Fkeystonemiddleware~master~Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a,openstack/keystonemiddleware,master,Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a,Make v3 auth work for Swift,ABANDONED,2015-02-02 21:43:04.000000000,2015-05-27 06:38:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2622}, {'_account_id': 7191}, {'_account_id': 7847}]","[{'number': 1, 'created': '2015-02-02 21:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/1f1213b3442f890ccef63a7cff6cdf847b113311', 'message': 'Make v3 auth work for Swift\n\nPlumb through the paste-deploy config options into the auth-middleware\nsection of the global CONF object. This should let Swift operators and\nother consumers of the paste-deploy API use v3 auth.\n\nChange-Id: Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a\n'}, {'number': 2, 'created': '2015-02-03 00:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/05cb11c7fb5506a1eec9b83fed1dbf34c7bad981', 'message': 'Make v3 auth work for Swift\n\nPlumb through the paste-deploy config options into the auth-middleware\nsection of the global CONF object. This should let Swift operators and\nother consumers of the paste-deploy API use v3 auth.\n\nChange-Id: Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a\n'}, {'number': 3, 'created': '2015-02-03 07:14:05.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d208fc58a5ff660a3ece28fd28db8ccd9c22ae36', 'message': 'Make v3 auth work for Swift\n\nPlumb through the paste-deploy config options into the auth-middleware\nsection of the global CONF object. This should let Swift operators and\nother consumers of the paste-deploy API use v3 auth.\n\nChange-Id: Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a\n'}]",2,152283,d208fc58a5ff660a3ece28fd28db8ccd9c22ae36,14,5,3,2622,,,0,"Make v3 auth work for Swift

Plumb through the paste-deploy config options into the auth-middleware
section of the global CONF object. This should let Swift operators and
other consumers of the paste-deploy API use v3 auth.

Change-Id: Icc1c4ba5bf7ef113a7a36029834d722e3f39cf7a
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/83/152283/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,1f1213b3442f890ccef63a7cff6cdf847b113311,plugins-from-paste," # Make sure the options from paste.ini make it into the global # config so that plugins can find them. for k, v in self._conf.items(): try: CONF.set_override(k, v, _AUTHTOKEN_GROUP) except cfg.NoSuchOptError: pass auth_plugin = auth.load_from_conf_options(CONF, _AUTHTOKEN_GROUP) if auth_plugin: auth_plugin.register_conf_options(CONF, _AUTHTOKEN_GROUP) else:"," # NOTE(jamielennox): The original auth mechanism allowed deployers # to configure authentication information via paste file. These # are accessible via _conf_get, however this doesn't work with the # plugin loading mechanisms. For using auth plugins we only support # configuring via the CONF file. auth_plugin = auth.load_from_conf_options(CONF, _AUTHTOKEN_GROUP) if not auth_plugin:",11,7
openstack%2Fdragonflow~master~Ib4e13ae9421ac524f2f06c9e8d9d1c46c96821b7,openstack/dragonflow,master,Ib4e13ae9421ac524f2f06c9e8d9d1c46c96821b7,Fix unit test test_new_subnet_installed_order_ports_router_dp failure,MERGED,2015-05-26 13:40:09.000000000,2015-05-27 06:31:22.000000000,2015-05-27 06:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-26 13:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3baf2ee61fb1a4276c9a4b95e35f6982de0e87e9', 'message': 'Fix unit test test_new_subnet_installed_order_ports_router_dp failure\n\nChange-Id: Ib4e13ae9421ac524f2f06c9e8d9d1c46c96821b7\n'}, {'number': 2, 'created': '2015-05-27 05:45:27.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4bbcb641db8df91105ae4a7be3e359b3d7b8cfe0', 'message': 'Fix unit test test_new_subnet_installed_order_ports_router_dp failure\n\nChange-Id: Ib4e13ae9421ac524f2f06c9e8d9d1c46c96821b7\n'}]",0,185595,4bbcb641db8df91105ae4a7be3e359b3d7b8cfe0,15,5,2,14249,,,0,"Fix unit test test_new_subnet_installed_order_ports_router_dp failure

Change-Id: Ib4e13ae9421ac524f2f06c9e8d9d1c46c96821b7
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/95/185595/2 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/l3_openflow_app.py'],1,3baf2ee61fb1a4276c9a4b95e35f6982de0e87e9,bug/1429601," return self.data.get('gateway_ip') subnet = tenant_topo.subnets.setdefault( subnet_dict['id'], Subnet(subnet_dict, segmentation_id)) if subnet.segmentation_id == 0: subnet.segmentation_id = segmentation_id"," return self.data['gateway_ip'] tenant_topo.subnets[subnet_dict['id']] = subnet = Subnet( subnet_dict, segmentation_id)",6,4
openstack%2Ftraining-guides~master~If8ff129c796cca0cea3198bd31830c135be2c351,openstack/training-guides,master,If8ff129c796cca0cea3198bd31830c135be2c351,labs: move lbaas_controller script to ubuntu folder.,MERGED,2015-05-10 17:49:22.000000000,2015-05-27 06:31:02.000000000,2015-05-27 06:31:00.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 9178}, {'_account_id': 11109}]","[{'number': 1, 'created': '2015-05-10 17:49:22.000000000', 'files': ['labs/scripts/ubuntu/setup_lbaas_controller.sh', 'labs/config/scripts.ubuntu_cluster'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/93fdc6cdcd135e5327a6626b4b7ccf56934e588e', 'message': 'labs: move lbaas_controller script to ubuntu folder.\n\nAlthough lbaas controller script does not install any package(s), it\nstill has ubuntu oriented workflow.\n\nChange-Id: If8ff129c796cca0cea3198bd31830c135be2c351\n'}]",0,181748,93fdc6cdcd135e5327a6626b4b7ccf56934e588e,6,4,1,7007,,,0,"labs: move lbaas_controller script to ubuntu folder.

Although lbaas controller script does not install any package(s), it
still has ubuntu oriented workflow.

Change-Id: If8ff129c796cca0cea3198bd31830c135be2c351
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/48/181748/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/scripts/ubuntu/setup_lbaas_controller.sh', 'labs/config/scripts.ubuntu_cluster']",2,93fdc6cdcd135e5327a6626b4b7ccf56934e588e,move-lb-cntrl,cmd queue ubuntu/setup_lbaas_controller.sh,cmd queue setup_lbaas_controller.sh,1,1
openstack%2Ftraining-guides~master~I0b7888d02de6eb50760d421d6d897f516f8c7718,openstack/training-guides,master,I0b7888d02de6eb50760d421d6d897f516f8c7718,labs: repeat test from snapshot,MERGED,2015-04-05 19:06:23.000000000,2015-05-27 06:30:55.000000000,2015-05-27 06:30:51.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2015-04-05 19:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/6cbad0638e662946983ffd8d00901afd97eed719', 'message': 'labs: repeat test from snapshot\n\nWith this changeset, the cluster build can be tested starting from a\nspecific snapshot. This is mostly useful for testing client scripts\nwithout having to go through the whole cluster build every time.\n\nFor instance, to rebuild the cluster from snapshot neuntron_configured:\n\n./tools/repeat-test.sh -b -t neutron_configured -s ""controller compute""\n\nThis will restore the appropriate snapshot on each node, boot nodes\ncontroller and compute, and continue the cluster build from the named\nsnapshot onward.\n\nNote: this procedure restores, boots, and continues in short order which\nuncovers new shortcomings (races) in scripts that assume a service is\navailable when they should check and wait for the service.\n\nIf you just want to restore all nodes to the appropriate snapshots:\n./tools/restore-cluster.sh -t <snapshot>\n\nChange-Id: I0b7888d02de6eb50760d421d6d897f516f8c7718\n'}, {'number': 2, 'created': '2015-05-10 14:15:48.000000000', 'files': ['labs/osbash.sh', 'labs/tools/restore-cluster.sh', 'labs/tools/repeat-test.sh', 'labs/lib/osbash/functions-host.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4749e620b6d3e04a5647d8a7f8a6b984b714af2e', 'message': 'labs: repeat test from snapshot\n\nWith this changeset, the cluster build can be tested starting from a\nspecific snapshot. This is mostly useful for testing client scripts\nwithout having to go through the whole cluster build every time.\n\nFor instance, to rebuild the cluster from snapshot neuntron_configured:\n\n./tools/repeat-test.sh -b -t neutron_configured -s ""controller compute""\n\nThis will restore the appropriate snapshot on each node, boot nodes\ncontroller and compute, and continue the cluster build from the named\nsnapshot onward.\n\nNote: this procedure restores, boots, and continues in short order which\nuncovers new shortcomings (races) in scripts that assume a service is\navailable when they should check and wait for the service.\n\nIf you just want to restore all nodes to the appropriate snapshots:\n./tools/restore-cluster.sh -t <snapshot>\n\nChange-Id: I0b7888d02de6eb50760d421d6d897f516f8c7718\n'}]",0,170731,4749e620b6d3e04a5647d8a7f8a6b984b714af2e,19,3,2,11109,,,0,"labs: repeat test from snapshot

With this changeset, the cluster build can be tested starting from a
specific snapshot. This is mostly useful for testing client scripts
without having to go through the whole cluster build every time.

For instance, to rebuild the cluster from snapshot neuntron_configured:

./tools/repeat-test.sh -b -t neutron_configured -s ""controller compute""

This will restore the appropriate snapshot on each node, boot nodes
controller and compute, and continue the cluster build from the named
snapshot onward.

Note: this procedure restores, boots, and continues in short order which
uncovers new shortcomings (races) in scripts that assume a service is
available when they should check and wait for the service.

If you just want to restore all nodes to the appropriate snapshots:
./tools/restore-cluster.sh -t <snapshot>

Change-Id: I0b7888d02de6eb50760d421d6d897f516f8c7718
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/31/170731/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash.sh', 'labs/tools/restore-cluster.sh', 'labs/lib/osbash/functions.host', 'labs/tools/repeat-test.sh']",4,6cbad0638e662946983ffd8d00901afd97eed719,jts,"source ""$CONFIG_DIR/provider.virtualbox""source ""$OSBASH_LIB_DIR/virtualbox.functions"" OSBASH=exec_cmd echo ""Usage: $0 {-b|-c|-t <SNAP>} [-s '<NODES>']"" echo """" echo ""-h Help"" echo ""-c Restore node VMs to current snapshot for each test"" echo ""-t SNAP Restore cluster to target snapshot for each test"" echo ""-s NODES Start each named node VM after restoring the cluster"" echo ""-b Rebuild cluster for each test, from scratch or snapshot"" echo "" (osbash.sh -b cluster [...])"" } while getopts :bchs:t: opt; do case $opt in b) REBUILD=yes ;; c) CURRENT=yes ;; h) usage exit 0 ;; s) START_VMS=$OPTARG ;; t) TARGET_SNAPSHOT=$OPTARG if ! ""$TOP_DIR/tools/restore-cluster.sh"" -l | grep -q ""Name: $TARGET_SNAPSHOT ""; then echo >&2 ""No snapshot named $TARGET_SNAPSHOT found."" exit 1 fi ;; :) echo ""Error: -$OPTARG needs argument"" ;; ?) echo ""Error: invalid option -$OPTARG"" echo usage exit 1 ;; esac done if [ -z ""${REBUILD:-}"" -a -z ""${CURRENT:-}"" -a -z ""${TARGET_SNAPSHOT:-}"" ]; then exit 1# Remove processed options from arguments shift $(( OPTIND - 1 )); if [ -n ""${TARGET_SNAPSHOT:-}"" ]; then ""$TOP_DIR/tools/restore-cluster.sh"" -t ""$TARGET_SNAPSHOT"" if [ -n ""${START_VMS:-}"" ]; then # Start VMs as requested by user for vm_name in $START_VMS; do echo >&2 ""$0: booting node $vm_name."" vbox_boot ""$vm_name"" # Sleeping for 10 s fixes some problems, but it might be # better to fix client scripts to wait for the services they # need instead of just failing. done fi fi if [ -n ""${REBUILD:-}"" ]; then if [ -n ""${TARGET_SNAPSHOT:-}"" ]; then ""$TOP_DIR/osbash.sh"" -t ""$TARGET_SNAPSHOT"" -b cluster else ""$TOP_DIR/osbash.sh"" -b cluster fi if [ ""${VERBOSE:-}"" -eq 1 ]; then"," echo ""Usage: $0 {rebuild|restore}"" echo "" rebuild: rebuild cluster for each test (osbash.sh -b cluster)"" echo "" restore: restore cluster for each test (cluster-restore.sh)"" exit 1 } if [ $# = 0 ]; thenelif [ ""$1"" = ""rebuild"" ]; then INIT=rebuild elif [ ""$1"" = ""restore"" ]; then unset INIT else usage if [ ""${INIT:=""""}"" = ""rebuild"" ]; then echo ""Building cluster."" ""$TOP_DIR/osbash.sh"" -b cluster else echo ""Restoring cluster."" ""$TOP_DIR/tools/restore-cluster.sh"" ""$CONTROLLER_SNAPSHOT"" if [ ""$VERBOSE"" -eq 1 ]; then",230,72
openstack%2Fec2-api~master~I3b718da1da19e9b1c5b973b9076ee64563018637,openstack/ec2-api,master,I3b718da1da19e9b1c5b973b9076ee64563018637,Do not update host routes if vpn routes are changed,MERGED,2015-05-26 17:13:39.000000000,2015-05-27 06:28:39.000000000,2015-05-27 06:28:38.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-26 17:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/100932e54e51595b81b742a525cce27810142bcd', 'message': 'Do not update host routes if vpn routes are changed\n\nChange-Id: I3b718da1da19e9b1c5b973b9076ee64563018637\n'}, {'number': 2, 'created': '2015-05-26 19:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/149757555dc5ab9b4ae4413d899cb443eefec973', 'message': 'Do not update host routes if vpn routes are changed\n\nChange-Id: I3b718da1da19e9b1c5b973b9076ee64563018637\n'}, {'number': 3, 'created': '2015-05-26 23:05:19.000000000', 'files': ['ec2api/api/route_table.py', 'ec2api/tests/unit/test_route_table.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c676dd28b3d0d65a27d6f10462a32a54c52e4f63', 'message': 'Do not update host routes if vpn routes are changed\n\nChange-Id: I3b718da1da19e9b1c5b973b9076ee64563018637\n'}]",0,185671,c676dd28b3d0d65a27d6f10462a32a54c52e4f63,15,4,3,10224,,,0,"Do not update host routes if vpn routes are changed

Change-Id: I3b718da1da19e9b1c5b973b9076ee64563018637
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/71/185671/2 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/api/route_table.py'],1,100932e54e51595b81b742a525cce27810142bcd,vpn,"HOST_TARGET = 'host' VPN_TARGET = 'vpn' update_target = _get_route_target(route) if update_target == VPN_TARGET: vpn_gateway = db_api.get_item_by_id(context, route['gateway_id']) if (not vpn_gateway or vpn_gateway['vpc_id'] != route_table['vpc_id']): update_target = None if update_target: _update_routes_in_associated_subnets( context, cleaner, route_table, update_targets=(update_target,)) route_index, old_route = next( ((ind, r) for ind, r in enumerate(route_table['routes']) if r['destination_cidr_block'] != destination_cidr_block), (None, None)) del route_table['routes'][route_index] if route_index is None: update_targets = [_get_route_target(route)] old_target = _get_route_target(old_route) if old_target not in update_targets: update_targets.append(old_target) _update_routes_in_associated_subnets(context, cleaner, route_table, update_targets=update_targets) default_associations_only=None, update_targets=None): if not update_targets or HOST_TARGET in update_targets: _update_host_routes(context, neutron, cleaner, route_table, subnets)def _get_route_target(route): if ec2utils.get_ec2_id_kind(route.get('gateway_id', '')) == 'vgw': return VPN_TARGET else: return HOST_TARGET "," _update_routes_in_associated_subnets(context, cleaner, route_table) route_count = len(route_table['routes']) route_table['routes'] = [ r for r in route_table['routes'] if r['destination_cidr_block'] != destination_cidr_block] if route_count == len(route_table['routes']): _update_routes_in_associated_subnets(context, cleaner, route_table) default_associations_only=None): _update_host_routes(context, neutron, cleaner, route_table, subnets)",36,9
openstack%2Ftraining-guides~master~I95ec52898115ecec37f084efb476db82e4f38658,openstack/training-guides,master,I95ec52898115ecec37f084efb476db82e4f38658,"Change the order of PTL, APC, and ATC slides",MERGED,2015-05-20 18:42:26.000000000,2015-05-27 06:27:14.000000000,2015-05-27 06:27:14.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 10497}, {'_account_id': 11889}]","[{'number': 1, 'created': '2015-05-20 18:42:26.000000000', 'files': ['doc/upstream-training/source/03-technical-committee.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d5e6feac8af8a801b6b3b7d9b3130e421b05ca69', 'message': 'Change the order of PTL, APC, and ATC slides\n\nThis change reverses the order of the PTL, APC, and ATC slides in\nresponse to student feedback in the last two Upstream training sessions.\n\nChange-Id: I95ec52898115ecec37f084efb476db82e4f38658\nCloses-Bug: #1457174\n'}]",0,184581,d5e6feac8af8a801b6b3b7d9b3130e421b05ca69,8,4,1,9041,,,0,"Change the order of PTL, APC, and ATC slides

This change reverses the order of the PTL, APC, and ATC slides in
response to student feedback in the last two Upstream training sessions.

Change-Id: I95ec52898115ecec37f084efb476db82e4f38658
Closes-Bug: #1457174
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/81/184581/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/03-technical-committee.rst'],1,d5e6feac8af8a801b6b3b7d9b3130e421b05ca69,tc-participant-slides,Active Project Contributor (APC) ================================= - Voters for a given program PTL - Subset of the Foundation Individual Member - Committed a change over the last two 6-month release cycles - Candidacy for the corresponding program PTL election Project Team Leads (PTLs) ========================= - Manage day-to-day operations - Drive the program goals - Resolve technical disputes ,Project Team Leads (PTLs) ========================= - Manage day-to-day operations - Drive the program goals - Resolve technical disputes Active Project Contributor (APC) ================================= - Voters for a given program PTL - Subset of the Foundation Individual Member - Committed a change over the last two 6-month release cycles - Candidacy for the corresponding program PTL election ,15,15
openstack%2Fheat~master~I13f8e03ff090dd5f5739e5af231c77d066eb9eac,openstack/heat,master,I13f8e03ff090dd5f5739e5af231c77d066eb9eac,Remove TaskRunner from Volume resources,MERGED,2015-02-11 17:50:07.000000000,2015-05-27 06:22:23.000000000,2015-05-27 06:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7230}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 10487}]","[{'number': 1, 'created': '2015-02-11 17:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48c54d7ef749aded919ea1c6e38f2d57419b4b0e', 'message': 'Remove TaskRunner from AWS Volume resource\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 2, 'created': '2015-02-12 15:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d73b126ff89c42b4b95cd764aae915dbb3d1111', 'message': 'Remove TaskRunner from Volume resources\n\nOld-style tasks for volume attach and detach are left in place as they\nare used in server resources.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 3, 'created': '2015-03-10 16:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d2498472eb3f6b06dc4b3acabb459f8d67b1f8a', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nOld-style tasks for volume attach and detach are left in place as they\nare still used in AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 4, 'created': '2015-03-11 09:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6cdfd7391953f037e4912010b2263496e095603', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nOld-style tasks for volume attach and detach are left in place as they\nare still used in AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 5, 'created': '2015-03-12 15:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3c667416cce0cc7e57df4af3ea1a2b9d8252ab93', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nOld-style tasks for volume attach and detach are left in place as they\nare still used in AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 6, 'created': '2015-03-20 10:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b8394f9ba608d0dfd3b0b2cc8e2bd4b4c0897a6', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nOld-style tasks for volume attach and detach are left in place as they\nare still used in AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 7, 'created': '2015-04-03 10:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d3dae24b1fcd15aff7d5df5014f3cb223c70377', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nThe old VolumeAttachTask is left in place as it is still used in\ncreating the AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 8, 'created': '2015-04-19 17:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b80f41ae7d33fac50f0a9bf4158d3211e4c638d3', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nThe old VolumeAttachTask is left in place as it is still used in\ncreating the AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 9, 'created': '2015-05-05 20:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4539118ab62b247c4b1dfd98d16773e0075858b4', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nThe old VolumeAttachTask is left in place as it is still used in\ncreating the AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 10, 'created': '2015-05-14 10:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c5b28b452be9633b8179dc3e5d1b9e1ceab4783b', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nThe old VolumeAttachTask is left in place as it is still used in\ncreating the AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}, {'number': 11, 'created': '2015-05-18 22:15:04.000000000', 'files': ['heat/tests/aws/test_volume.py', 'heat/engine/clients/os/cinder.py', 'heat/engine/resources/openstack/cinder/volume.py', 'heat/engine/clients/os/nova.py', 'heat/engine/resources/volume_base.py', 'heat/engine/volume_tasks.py', 'heat/tests/openstack/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a484c739736c8ccea74ec684da8971b189747193', 'message': 'Remove TaskRunner from Volume resources\n\nAll the volume_tasks logic has been redistributed as methods of either\ncinder or nova client plugins.\n\nThe logic of detaching was simplified and a check for out-of-band\nchanges is no longer executed.\n\nThe old VolumeAttachTask is left in place as it is still used in\ncreating the AWS::EC2::Instance resource.\n\nChange-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac\nPartial-Bug: #1393268\n'}]",26,154977,a484c739736c8ccea74ec684da8971b189747193,84,9,11,9542,,,0,"Remove TaskRunner from Volume resources

All the volume_tasks logic has been redistributed as methods of either
cinder or nova client plugins.

The logic of detaching was simplified and a check for out-of-band
changes is no longer executed.

The old VolumeAttachTask is left in place as it is still used in
creating the AWS::EC2::Instance resource.

Change-Id: I13f8e03ff090dd5f5739e5af231c77d066eb9eac
Partial-Bug: #1393268
",git fetch https://review.opendev.org/openstack/heat refs/changes/77/154977/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/aws/test_volume.py', 'heat/engine/resources/aws/volume.py', 'heat/engine/resources/openstack/volume.py', 'heat/engine/volume_tasks.py', 'heat/tests/openstack/test_volume.py']",5,48c54d7ef749aded919ea1c6e38f2d57419b4b0e,bug/1393268,, self.cinder_fc.volumes.get(fv.id).AndReturn(fv) self.cinder_fc.volumes.get(fv.id).AndReturn(fv) self.cinder_fc.volumes.get(fv.id).AndReturn(fv),378,159
openstack%2Ftaskflow~master~Ic4792c08942b51bf019f62238a609a9b66947983,openstack/taskflow,master,Ic4792c08942b51bf019f62238a609a9b66947983,Updated from global requirements,MERGED,2015-05-27 01:14:10.000000000,2015-05-27 05:39:25.000000000,2015-05-27 05:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-05-27 01:14:10.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/553b6b33751114eaee0dcda03a613481b936c282', 'message': 'Updated from global requirements\n\nChange-Id: Ic4792c08942b51bf019f62238a609a9b66947983\n'}]",0,185800,553b6b33751114eaee0dcda03a613481b936c282,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ic4792c08942b51bf019f62238a609a9b66947983
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/00/185800/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,553b6b33751114eaee0dcda03a613481b936c282,openstack/requirements,"kazoo>=1.3.1,!=2.1",kazoo>=1.3.1,1,1
openstack%2Fec2-api~master~Ia9ab7d4ad37f5e08531d3654039bc07ff939f1cb,openstack/ec2-api,master,Ia9ab7d4ad37f5e08531d3654039bc07ff939f1cb,Manage OS VPN connection for subnet operations,MERGED,2015-05-26 16:54:12.000000000,2015-05-27 05:28:13.000000000,2015-05-27 05:28:13.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-26 16:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/bd02a833c4e047eb9028c852a4657e9b6f54cb27', 'message': 'Manage OS VPN connection for subnet operations\n\nChange-Id: Ia9ab7d4ad37f5e08531d3654039bc07ff939f1cb\n'}, {'number': 2, 'created': '2015-05-26 19:33:33.000000000', 'files': ['ec2api/api/vpn_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/dccda4ed4f83a86b703fe20ea8a59c82c70726e0', 'message': 'Manage OS VPN connection for subnet operations\n\nChange-Id: Ia9ab7d4ad37f5e08531d3654039bc07ff939f1cb\n'}]",0,185665,dccda4ed4f83a86b703fe20ea8a59c82c70726e0,11,3,2,10224,,,0,"Manage OS VPN connection for subnet operations

Change-Id: Ia9ab7d4ad37f5e08531d3654039bc07ff939f1cb
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/65/185665/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/vpn_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py']",2,bd02a833c4e047eb9028c852a4657e9b6f54cb27,vpn," @mock.patch('ec2api.api.vpn_connection._reset_vpn_connections') def test_start_vpn_in_subnet(self, create_subnet_vpnservice, reset_vpn_connection): mock_manager = mock.Mock() mock_manager.attach_mock(create_subnet_vpnservice, 'create_subnet_vpnservice') mock_manager.attach_mock(reset_vpn_connection, 'reset_vpn_connection') self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1, fakes.DB_VPN_GATEWAY_2) mock_manager.assert_has_calls([ mock.call.create_subnet_vpnservice( context, self.neutron, cleaner, fakes.DB_SUBNET_1, fakes.DB_VPC_1), mock.call.reset_vpn_connection( context, self.neutron, cleaner, fakes.DB_VPN_GATEWAY_1, subnets=[fakes.DB_SUBNET_1], route_tables=[fakes.DB_ROUTE_TABLE_1])]) reset_vpn_connection.reset_mock() self.assertFalse(reset_vpn_connection.called) @mock.patch('ec2api.api.vpn_connection._delete_subnet_vpn') def test_stop_vpn_in_subnet(self, delete_vpnservice, delete_subnet_vpn): mock_manager = mock.Mock() mock_manager.attach_mock(delete_vpnservice, 'delete_vpnservice') mock_manager.attach_mock(delete_subnet_vpn, 'delete_subnet_vpn') self.set_mock_db_items(fakes.DB_VPN_CONNECTION_1, fakes.DB_VPN_CONNECTION_2) mock_manager.has_calls([ mock.call.delete_subnet_vpn( context, self.neutron, cleaner, fakes.DB_SUBNET_1, fakes.DB_VPN_CONNECTION_1), mock.call.delete_subnet_vpn( context, self.neutron, cleaner, fakes.DB_SUBNET_1, fakes.DB_VPN_CONNECTION_2), mock.call.delete_vpnservice( self.neutron, fakes.ID_OS_VPNSERVICE_1, fakes.ID_EC2_SUBNET_1)]) delete_subnet_vpn.reset_mock() self.assertFalse(delete_subnet_vpn.called)"," def test_start_vpn_in_subnet(self, create_subnet_vpnservice): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1, fakes.DB_VPN_GATEWAY_2) create_subnet_vpnservice.assert_called_once_with( context, self.neutron, cleaner, fakes.DB_SUBNET_1, fakes.DB_VPC_1) def test_stop_vpn_in_subnet(self, delete_vpnservice): delete_vpnservice.assert_called_once_with( self.neutron, fakes.ID_OS_VPNSERVICE_1, fakes.ID_EC2_SUBNET_1) ",45,10
openstack%2Fec2-api~master~I7f59191ee2fd05eda8e59264d526a624d54d6a3d,openstack/ec2-api,master,I7f59191ee2fd05eda8e59264d526a624d54d6a3d,Manage OS VPN connection for VPN gateway operations,MERGED,2015-05-26 16:54:12.000000000,2015-05-27 05:26:48.000000000,2015-05-27 05:26:47.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-26 16:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1868635fc052b07f88a508d8ebe9f157ac00ea53', 'message': 'Manage OS VPN connection for VPN gateway operations\n\nChange-Id: I7f59191ee2fd05eda8e59264d526a624d54d6a3d\n'}, {'number': 2, 'created': '2015-05-26 19:33:33.000000000', 'files': ['ec2api/tests/unit/tools.py', 'ec2api/tests/unit/test_vpn_connection.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_vpn_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/53b87755e45025fc797e16bf7a499a4c67f61d23', 'message': 'Manage OS VPN connection for VPN gateway operations\n\nChange-Id: I7f59191ee2fd05eda8e59264d526a624d54d6a3d\n'}]",0,185664,53b87755e45025fc797e16bf7a499a4c67f61d23,11,3,2,10224,,,0,"Manage OS VPN connection for VPN gateway operations

Change-Id: I7f59191ee2fd05eda8e59264d526a624d54d6a3d
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/64/185664/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/tools.py', 'ec2api/tests/unit/test_vpn_connection.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_vpn_gateway.py']",5,1868635fc052b07f88a508d8ebe9f157ac00ea53,vpn,"from ec2api.api import vpn_connection as vpn_connection_api @mock.patch('ec2api.api.vpn_connection._reset_vpn_connections', wraps=vpn_connection_api._reset_vpn_connections) def test_attach_vpn_gateway(self, create_vpnservice, reset_vpn_connections): mock_manager = mock.Mock() mock_manager.attach_mock(create_vpnservice, 'create_vpnservice') mock_manager.attach_mock(reset_vpn_connections, 'reset_vpn_connections') reset_vpn_connections.assert_called_once_with( mock.ANY, self.neutron, mock.ANY, self.DB_VPN_GATEWAY_2_ATTACHED, subnets=[subnet_2_updated]) self.assertIsInstance(reset_vpn_connections.call_args[0][2], common.OnCrashCleaner) mock_manager.assert_has_calls([ mock.call.create_vpnservice( *(mock.ANY for _x in xrange(5))), mock.call.reset_vpn_connections( subnets=mock.ANY, *(mock.ANY for _x in xrange(4)))]) reset_vpn_connections.reset_mock() mock_manager.reset_mock() @mock.patch('ec2api.api.vpn_connection._stop_gateway_vpn_connections', wraps=vpn_connection_api._stop_gateway_vpn_connections) def test_detach_vpn_gateway(self, delete_vpnservice, stop_gateway_vpn_connections): mock_manager = mock.Mock() mock_manager.attach_mock(delete_vpnservice, 'delete_vpnservice') mock_manager.attach_mock(stop_gateway_vpn_connections, 'stop_gateway_vpn_connections') fakes.DB_VPN_GATEWAY_1, fakes.DB_VPC_1, fakes.DB_VPN_CONNECTION_1, self.assertEqual(3, self.db_api.update_item.call_count) mock.call(mock.ANY, tools.update_dict( fakes.DB_VPN_CONNECTION_1, {'os_ipsec_site_connections': {}})), stop_gateway_vpn_connections.assert_called_once_with( mock.ANY, self.neutron, mock.ANY, self.DB_VPN_GATEWAY_1_DETACHED) self.assertIsInstance(stop_gateway_vpn_connections.call_args[0][2], common.OnCrashCleaner) self.neutron.delete_ipsec_site_connection.assert_called_once_with( fakes.ID_OS_IPSEC_SITE_CONNECTION_2) mock_manager.assert_has_calls([ mock.call.stop_gateway_vpn_connections( *(mock.ANY for _x in xrange(4))), mock.call.delete_vpnservice( *(mock.ANY for _x in xrange(4)))]) stop_gateway_vpn_connections.reset_mock() mock_manager.reset_mock()"," def test_attach_vpn_gateway(self, create_vpnservice): def test_detach_vpn_gateway(self, delete_vpnservice): fakes.DB_VPN_GATEWAY_1, fakes.DB_VPC_1, self.assertEqual(2, self.db_api.update_item.call_count)",130,22
openstack%2Fec2-api~master~Ic08bd5c27da06c40412ac208c703de5e35c01a45,openstack/ec2-api,master,Ic08bd5c27da06c40412ac208c703de5e35c01a45,Manage OS VPN connection for VPN connection operations,MERGED,2015-05-26 10:19:54.000000000,2015-05-27 05:26:40.000000000,2015-05-27 05:26:39.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-26 10:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/9658fd71d20007b05b2c1ec43408b35e90907ca0', 'message': 'Manage OS VPN connection for VPN connection operations\n\nChange-Id: Ic08bd5c27da06c40412ac208c703de5e35c01a45\n'}, {'number': 2, 'created': '2015-05-26 13:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/f4a5aac1f0f0df48f74e6134a26f3b5650755a35', 'message': 'Manage OS VPN connection for VPN connection operations\n\nChange-Id: Ic08bd5c27da06c40412ac208c703de5e35c01a45\n'}, {'number': 3, 'created': '2015-05-26 16:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cf59334f34e32cf5198eecbd1c63d7a8f1982f3f', 'message': 'Manage OS VPN connection for VPN connection operations\n\nChange-Id: Ic08bd5c27da06c40412ac208c703de5e35c01a45\n'}, {'number': 4, 'created': '2015-05-26 19:33:33.000000000', 'files': ['ec2api/tests/unit/test_vpn_connection.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/vpn_connection.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/fd6cd196dbbb6395e18c947214167b616b87f891', 'message': 'Manage OS VPN connection for VPN connection operations\n\nChange-Id: Ic08bd5c27da06c40412ac208c703de5e35c01a45\n'}]",0,185553,fd6cd196dbbb6395e18c947214167b616b87f891,16,3,4,10224,,,0,"Manage OS VPN connection for VPN connection operations

Change-Id: Ic08bd5c27da06c40412ac208c703de5e35c01a45
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/53/185553/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_vpn_connection.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/vpn_connection.py']",3,9658fd71d20007b05b2c1ec43408b35e90907ca0,vpn," 'os_ipsec_site_connections': {}}) _reset_vpn_connections(context, neutron, cleaner, vpn_gateway, vpn_connections=[vpn_connection]) with common.OnCrashCleaner() as cleaner: _add_cidr_to_vpn_connection_item(context, vpn_connection, destination_cidr_block) cleaner.addCleanup(_remove_cidr_from_vpn_connection_item, context, vpn_connection, destination_cidr_block) _reset_vpn_connection_routes(context, cleaner, vpn_connection) with common.OnCrashCleaner() as cleaner: _remove_cidr_from_vpn_connection_item(context, vpn_connection, destination_cidr_block) cleaner.addCleanup(_add_cidr_to_vpn_connection_item, context, destination_cidr_block) _reset_vpn_connection_routes(context, cleaner, vpn_connection) _stop_vpn_connection(neutron, vpn_connection) def _reset_vpn_connection_routes(context, cleaner, vpn_connection): neutron = clients.neutron(context) vpn_gateway = db_api.get_item_by_id(context, vpn_connection['vpn_gateway_id']) _reset_vpn_connections(context, neutron, cleaner, vpn_gateway, [vpn_connection]) def _stop_vpn_connection(neutron, vpn_connection): connection_ids = vpn_connection['os_ipsec_site_connections'] for os_connection_id in connection_ids.itervalues(): try: neutron.delete_ipsec_site_connection(os_connection_id) except neutron_exception.NotFound: pass def _reset_vpn_connections(context, neutron, cleaner, vpn_gateway, subnets=None, route_tables=None, vpn_connections=None): if not vpn_gateway['vpc_id']: return vpc = db_api.get_item_by_id(context, vpn_gateway['vpc_id']) customer_gateways = {cgw['id']: cgw for cgw in db_api.get_items(context, 'cgw')} # TODO(ft): implement search filters in DB api subnets = (subnets or [subnet for subnet in db_api.get_items(context, 'subnet') if subnet['vpc_id'] == vpc['id']]) route_tables = route_tables or db_api.get_items(context, 'rtb') route_tables = {rtb['id']: rtb for rtb in route_tables if rtb['vpc_id'] == vpc['id']} vpn_connections = (vpn_connections or [vpn for vpn in db_api.get_items(context, 'vpn') if vpn['vpn_gateway_id'] == vpn_gateway['id']]) route_tables_cidrs = {} for subnet in subnets: route_table_id = subnet.get('route_table_id', vpc['route_table_id']) if route_table_id not in route_tables_cidrs: route_tables_cidrs[route_table_id] = ( _get_route_table_vpn_cidrs(route_tables[route_table_id], vpn_gateway, vpn_connections)) cidrs = route_tables_cidrs[route_table_id] for vpn_conn in vpn_connections: if vpn_conn['id'] in cidrs: _set_subnet_vpn( context, neutron, cleaner, subnet, vpn_conn, customer_gateways[vpn_conn['customer_gateway_id']], cidrs[vpn_conn['id']]) else: _delete_subnet_vpn(context, neutron, cleaner, subnet, vpn_conn) def _set_subnet_vpn(context, neutron, cleaner, subnet, vpn_connection, customer_gateway, cidrs): subnets_connections = vpn_connection['os_ipsec_site_connections'] os_connection_id = subnets_connections.get(subnet['id']) if os_connection_id: # TODO(ft): restore original peer_cidrs on crash neutron.update_ipsec_site_connection( os_connection_id, {'ipsec_site_connection': {'peer_cidrs': cidrs}}) else: os_connection = { 'vpnservice_id': subnet['os_vpnservice_id'], 'ikepolicy_id': vpn_connection['os_ikepolicy_id'], 'ipsecpolicy_id': vpn_connection['os_ipsecpolicy_id'], 'peer_address': customer_gateway['ip_address'], 'peer_cidrs': cidrs, 'psk': vpn_connection['pre_shared_key'], 'name': '%s/%s' % (vpn_connection['id'], subnet['id']), 'peer_id': customer_gateway['ip_address'], 'mtu': 1387 + 40, # AWS MSS + 20 byte IP and 20 byte TCP headers 'initiator': 'response-only', # 'dpd_action': '', # 'dpd_interval': '', # 'dpd_timeout': '', } os_connection = (neutron.create_ipsec_site_connection( {'ipsec_site_connection': os_connection}) ['ipsec_site_connection']) cleaner.addCleanup(neutron.delete_ipsec_site_connection, os_connection['id']) _add_subnet_connection_to_vpn_connection_item( context, vpn_connection, subnet['id'], os_connection['id']) cleaner.addCleanup(_remove_subnet_connection_from_vpn_connection_item, context, vpn_connection, subnet['id']) def _delete_subnet_vpn(context, neutron, cleaner, subnet, vpn_connection): subnets_connections = vpn_connection['os_ipsec_site_connections'] os_connection_id = subnets_connections.get(subnet['id']) if not os_connection_id: return _remove_subnet_connection_from_vpn_connection_item( context, vpn_connection, subnet['id']) cleaner.addCleanup(_add_subnet_connection_to_vpn_connection_item, context, vpn_connection, subnet['id'], os_connection_id) try: neutron.delete_ipsec_site_connection(os_connection_id) except neutron_exception.NotFound: pass def _get_route_table_vpn_cidrs(route_table, vpn_gateway, vpn_connections): static_cidrs = [route['destination_cidr_block'] for route in route_table['routes'] if route.get('gateway_id') == vpn_gateway['id']] is_propagation_enabled = ( vpn_gateway['id'] in route_table.get('propagating_gateways', [])) vpn_cidrs = {} for vpn in vpn_connections: cidrs = set(static_cidrs + vpn['cidrs'] if is_propagation_enabled else static_cidrs) if cidrs: vpn_cidrs[vpn['id']] = cidrs return vpn_cidrs def _add_cidr_to_vpn_connection_item(context, vpn_connection, cidr): vpn_connection['cidrs'].append(cidr) db_api.update_item(context, vpn_connection) def _remove_cidr_from_vpn_connection_item(context, vpn_connection, cidr): vpn_connection['cidrs'].remove(cidr) db_api.update_item(context, vpn_connection) def _add_subnet_connection_to_vpn_connection_item(context, vpn_connection, subnet_id, os_connection_id): vpn_connection['os_ipsec_site_connections'][subnet_id] = os_connection_id db_api.update_item(context, vpn_connection) def _remove_subnet_connection_from_vpn_connection_item(context, vpn_connection, subnet_id): del vpn_connection['os_ipsec_site_connections'][subnet_id] db_api.update_item(context, vpn_connection)"," }) vpn_connection['cidrs'].append(destination_cidr_block) db_api.update_item(context, vpn_connection) vpn_connection['cidrs'].remove(destination_cidr_block) db_api.update_item(context, vpn_connection)",416,13
openstack%2Fcinder~master~Ic7b606b88f063b9ed6df62fd1fb7248922496326,openstack/cinder,master,Ic7b606b88f063b9ed6df62fd1fb7248922496326,Use nfs_oversub_ratio when reporting pool capacity,MERGED,2015-05-05 15:33:30.000000000,2015-05-27 05:26:18.000000000,2015-05-26 02:32:54.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 8846}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 15831}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-05 15:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71c39eb9fb47f90d501fc3c2fe8101381aa4a569', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 2, 'created': '2015-05-06 20:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe66916691cf5b96a7beba0ba99c9082cd20ca07', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 3, 'created': '2015-05-07 09:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f3f52985fb49a9843203eb2e354f1df5dab2aa4d', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using \n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nIn liberty, we should as a community decide either to deprecate\nnfs_oversub_ratio in favor of max_oversubscription ratio or to\nsupport both configuration options but perhaps also re-implement the\nnfs_oversub_ratio using the support in the scheduler for ""virtual""\nfree space rather than having drivers report ""apparent"" free space.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 4, 'created': '2015-05-08 19:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/88ef4487a0f2c2f9aa72031012da555c6d79ee81', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using\n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nIn liberty, we should as a community decide either to deprecate\nnfs_oversub_ratio in favor of max_oversubscription ratio or to\nsupport both configuration options but perhaps also re-implement the\nnfs_oversub_ratio using the support in the scheduler for ""virtual""\nfree space rather than having drivers report ""apparent"" free space.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 5, 'created': '2015-05-12 11:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e4ef3ece739956ed84cde32347e94685cb92959', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using\n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nIn liberty, we should as a community decide either to deprecate\nnfs_oversub_ratio in favor of max_oversubscription ratio or to\nsupport both configuration options but perhaps also re-implement the\nnfs_oversub_ratio using the support in the scheduler for ""virtual""\nfree space rather than having drivers report ""apparent"" free space.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 6, 'created': '2015-05-12 17:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cb14583e033e58c4efb80e75d504f1e640a58d4', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler.\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using\n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 7, 'created': '2015-05-13 10:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/826c968187732b508d8f34cfeac4e6891b47cfab', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented.\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using\n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}, {'number': 8, 'created': '2015-05-13 20:52:58.000000000', 'files': ['cinder/volume/drivers/netapp/dataontap/nfs_7mode.py', 'cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode.py', 'cinder/volume/drivers/netapp/dataontap/client/client_7mode.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e52f304313efc695f7dd89c222041bffd53c131a', 'message': 'Use nfs_oversub_ratio when reporting pool capacity\n\nCurrently NetApp NFS drivers do not make use of the nfs_oversub_ratio\nconfiguration parameter to enable OpenStack administrators to report\nanything other than the most conservative capacity and usage information\nup to the scheduler\n\nThis commit:\n  *  modifies the NetApp drivers to use the nfs_oversub_ratio as\n     documented.\n  *  uses direct API with filers to gather capacity information rather\n     than stat and du commands\n  *  brings our reporting of reserved percentage in line with the way\n     the scheduler actually makes use of this statistic\n  *  simplifies and cleans up the way we gather and report pool statistics\n\nNote that this fix addresses an in-the-field bug report from juno\nand is intended to be the basis for backported fixes.\n\nIn kilo, a more general approach to overprovisioning using\n     max_oversubscription_ratio\nwas introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.\nIn this newer approach, the scheduler computes ""virtual"" free space\nrather than the driver reporting ""apparent"" free space.\n\nThis fix to bring NetApp NFS drivers into conformity with the generic\nNFS driver is not intended as a substitute for introducing support\nin our drivers for the newer approach to overprovisioning.  Rather,\nit is a bug-fix for an existing failure to honor the nfs_oversub_ratio.\n\nDocImpact\nCo-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>\nCloses-bug: 1449620\nChange-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326\n'}]",18,180199,e52f304313efc695f7dd89c222041bffd53c131a,169,34,8,9003,,,0,"Use nfs_oversub_ratio when reporting pool capacity

Currently NetApp NFS drivers do not make use of the nfs_oversub_ratio
configuration parameter to enable OpenStack administrators to report
anything other than the most conservative capacity and usage information
up to the scheduler

This commit:
  *  modifies the NetApp drivers to use the nfs_oversub_ratio as
     documented.
  *  uses direct API with filers to gather capacity information rather
     than stat and du commands
  *  brings our reporting of reserved percentage in line with the way
     the scheduler actually makes use of this statistic
  *  simplifies and cleans up the way we gather and report pool statistics

Note that this fix addresses an in-the-field bug report from juno
and is intended to be the basis for backported fixes.

In kilo, a more general approach to overprovisioning using
     max_oversubscription_ratio
was introduced via commit 3548a4bc9edbb26b248b5af5ecc2145f2c6f7481.
In this newer approach, the scheduler computes ""virtual"" free space
rather than the driver reporting ""apparent"" free space.

This fix to bring NetApp NFS drivers into conformity with the generic
NFS driver is not intended as a substitute for introducing support
in our drivers for the newer approach to overprovisioning.  Rather,
it is a bug-fix for an existing failure to honor the nfs_oversub_ratio.

DocImpact
Co-Authored-By: Dustin Schoenbrun <dustin.schoenbrun@netapp.com>
Closes-bug: 1449620
Change-Id: Ic7b606b88f063b9ed6df62fd1fb7248922496326
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/180199/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/dataontap/nfs_7mode.py', 'cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode.py', 'cinder/volume/drivers/netapp/dataontap/client/client_7mode.py']",12,71c39eb9fb47f90d501fc3c2fe8101381aa4a569,bug/1449620," def get_flexvol_capacity(self, flexvol_path): """"""Gets total capacity and free capacity, in bytes, of the flexvol."""""" api_args = {'volume': flexvol_path, 'verbose': 'false'} result = self.send_request('volume-list-info', api_args) flexvol_info_list = result.get_child_by_name('volumes') flexvol_info = flexvol_info_list.get_children()[0] total_bytes = float( flexvol_info.get_child_content('size-total')) available_bytes = float( flexvol_info.get_child_content('size-available')) return total_bytes, available_bytes",,315,55
openstack%2Fheat-specs~master~I0b7eed9b09d5ba0d32f55b6e942edba802e3e2e9,openstack/heat-specs,master,I0b7eed9b09d5ba0d32f55b6e942edba802e3e2e9,Messages for users,ABANDONED,2015-04-01 02:23:22.000000000,2015-05-27 05:21:56.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 12606}]","[{'number': 1, 'created': '2015-04-01 02:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/31d0ecf960bb96f3eaaec6ea84899428abce1a3f', 'message': 'Messages for users\n\nAPIImpact\nblueprint user-visible-logs\n\nChange-Id: I0b7eed9b09d5ba0d32f55b6e942edba802e3e2e9\n'}, {'number': 2, 'created': '2015-04-01 02:46:17.000000000', 'files': ['specs/liberty/messaging-the-user.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ab7ac14824b47aaec371d3c32f8fe565ee0cb917', 'message': 'Messages for users\n\nAPIImpact\nblueprint user-visible-logs\nChange-Id: I0b7eed9b09d5ba0d32f55b6e942edba802e3e2e9\n'}]",4,169591,ab7ac14824b47aaec371d3c32f8fe565ee0cb917,11,6,2,4715,,,0,"Messages for users

APIImpact
blueprint user-visible-logs
Change-Id: I0b7eed9b09d5ba0d32f55b6e942edba802e3e2e9
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/91/169591/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/messaging-the-user.rst'],1,31d0ecf960bb96f3eaaec6ea84899428abce1a3f,bp/user-visible-logs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================ Improved messaging for the user ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/user-visible-logs Users that don't have access to heat-engine logs are disadvantaged. We log messages that are really useful to whilst you are debugging a templete. While we have the events table it would be better to use existing services like zaqar to send these messages to the user. This would enable us to send more information as well. Problem description =================== It would be good to have the facility to not only send OK or Failure messages but things like: - deprecation notices (property x has been deprecated...) - warnings https://github.com/openstack/heat/blob/master/heat/engine/resources/openstack/neutron/port.py#L343 - action notifications (scaling, suspend/resume) - info/progress messages https://github.com/openstack/heat/blob/master/heat/engine/volume_tasks.py#L224 Proposed change =============== If the user passes in a zaqar message queue, we use that to post messages to. The queue name will also be sent in the top level stack-show output to show that user messaging is enabled. The heat client will also have support for sending a custom message queue name and log level to alter the verbosity. A swift ""queue"" will be investigated for environments that do not have zaqar. (TODO(asalkeld) ask Steve Baker more about this). Alternatives ------------ - remote syslog tcp socket Implementation ============== Assignee(s) ----------- Primary assignee: <asalkeld> Milestones ---------- Target Milestone for completion: liberty-1 Work Items ---------- - Investigate swift-as-message-queue. - python-heatclient: add the ability to specify the queue name and log level in ""heat stack-create"". - python-heatclient: show the queue name, type and log level in ""heat stack-show"" output. - heat: add a small module to make sending logs easy from within heat. - heat: convert obvious logs that only make sense to the user and not to the operator to user-messages. - Document the API modifications. - Add to Heat getting started guide to show how to use it. Dependencies ============ None ",,97,0
openstack%2Ffuel-library~master~If0d41447e31aac505ca6f7a5f4ee91c401862609,openstack/fuel-library,master,If0d41447e31aac505ca6f7a5f4ee91c401862609,Disable 512b sector,MERGED,2015-05-26 19:37:01.000000000,2015-05-27 05:08:58.000000000,2015-05-27 05:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 3009}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8003}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 9760}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14168}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-26 19:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fecf4db8d6de914e74a44a5119c113a1e8a80bb4', 'message': 'Disable 512b sector\n\nPatch I4b38ef148c16baacfba12ed07534a3761b3cecf1 (bug/1316266) introduced\nperformance downgrade for all SSDs and HDD with advanced formatting\nwhere physical sector size is 4k. According to test results in some\ncases performance is 10 times slower. Also, there is only one RAID\nadapter found with such behavior ""LSI Logic / Symbios Logic MegaRAID SAS\n2208""\n\nDocImpact: release-notes\nUsers with MegaRAID SAS 2208 must upgrade firmware to latest (Provided\nby Cisco and Dell)\n\nChange-Id: If0d41447e31aac505ca6f7a5f4ee91c401862609\n'}, {'number': 2, 'created': '2015-05-26 19:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/799d862cec3dec913ddcdb96f6344f46f6b26278', 'message': 'Disable 512b sector\n\nPatch I4b38ef148c16baacfba12ed07534a3761b3cecf1 (bug/1316266) introduced\nperformance downgrade for all SSDs and HDD with advanced formatting\nwhere physical sector size is 4k. According to test results in some\ncases performance is 10 times slower. Also, there is only one RAID\nadapter found with such behavior ""LSI Logic / Symbios Logic MegaRAID SAS\n2208""\n\nDocImpact: release-notes\nUsers with MegaRAID SAS 2208 must upgrade firmware to latest (Provided\nby Cisco and Dell)\n\nChange-Id: If0d41447e31aac505ca6f7a5f4ee91c401862609\nClose-Bug: 1318614\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2015-05-26 19:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/86f9adfca0e6f20be602a7cf37a01b95b0f5675d', 'message': 'Disable 512b sector\n\nPatch I4b38ef148c16baacfba12ed07534a3761b3cecf1 (bug/1316266) introduced\nperformance downgrade for all SSDs and HDD with advanced formatting\nwhere physical sector size is 4k. According to test results in some\ncases performance is 10 times slower. Also, there is only one RAID\nadapter found with such behavior ""LSI Logic / Symbios Logic MegaRAID SAS\n2208""\n\nDocImpact: release-notes\nUsers with MegaRAID SAS 2208 must upgrade firmware to latest (Provided\nby Cisco and Dell)\n\nChange-Id: If0d41447e31aac505ca6f7a5f4ee91c401862609\nClose-Bug: 1318614\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 4, 'created': '2015-05-26 20:08:18.000000000', 'files': ['deployment/puppet/cobbler/templates/scripts/pmanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ccfc554e3df5b96ad49525c5b57d0ad6c2ae43c4', 'message': 'Disable 512b sector\n\nPatch I4b38ef148c16baacfba12ed07534a3761b3cecf1 (bug/1316266) introduced\nperformance downgrade for all SSDs and HDD with advanced formatting\nwhere physical sector size is 4k. According to test results in some\ncases performance is 10 times slower. Also, there is only one RAID\nadapter found with such behavior ""LSI Logic / Symbios Logic MegaRAID SAS\n2208""\n\nDocImpact: release-notes\nUsers with MegaRAID SAS 2208 must upgrade firmware to latest (Provided\nby Cisco and Dell)\n\nChange-Id: If0d41447e31aac505ca6f7a5f4ee91c401862609\nCloses-Bug: 1318614\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",1,185713,ccfc554e3df5b96ad49525c5b57d0ad6c2ae43c4,84,22,4,11090,,,0,"Disable 512b sector

Patch I4b38ef148c16baacfba12ed07534a3761b3cecf1 (bug/1316266) introduced
performance downgrade for all SSDs and HDD with advanced formatting
where physical sector size is 4k. According to test results in some
cases performance is 10 times slower. Also, there is only one RAID
adapter found with such behavior ""LSI Logic / Symbios Logic MegaRAID SAS
2208""

DocImpact: release-notes
Users with MegaRAID SAS 2208 must upgrade firmware to latest (Provided
by Cisco and Dell)

Change-Id: If0d41447e31aac505ca6f7a5f4ee91c401862609
Closes-Bug: 1318614
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/13/185713/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/scripts/pmanager.py'],1,fecf4db8d6de914e74a44a5119c113a1e8a80bb4,bug/1318614," return ""-f"""," return ""-f -s size=512""",1,1
openstack%2Ftrove~master~I198e1f637b12827c33f930b07405432e3f2151c0,openstack/trove,master,I198e1f637b12827c33f930b07405432e3f2151c0,Enabled H306 hacking rule,ABANDONED,2015-05-11 15:50:11.000000000,2015-05-27 05:06:54.000000000,,"[{'_account_id': 3}, {'_account_id': 1870}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 14576}, {'_account_id': 14829}]","[{'number': 1, 'created': '2015-05-11 15:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/85bc88da449528e6f099e8a5dec41221428d96f7', 'message': 'Enabled H306 hacking rule.\n\nThe import order rule was disabled in trove for pep8 checks.\nEnabled the rule and fixed the erroring imports in modules.\n\nChange-Id: I198e1f637b12827c33f930b07405432e3f2151c0\n'}, {'number': 2, 'created': '2015-05-11 18:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0a5b847183bd03c0b3501508918c2d96dc519628', 'message': 'Enabled H306 hacking rule\n\nThe import order rule was disabled in trove for pep8 checks.\nEnabled the rule and fixed the erroring imports in modules.\n\nChange-Id: I198e1f637b12827c33f930b07405432e3f2151c0\n'}, {'number': 3, 'created': '2015-05-26 08:15:56.000000000', 'files': ['trove/common/wsgi.py', 'trove/guestagent/datastore/experimental/couchbase/manager.py', 'trove/tests/unittests/db/test_migration_utils.py', 'trove/instance/service.py', 'trove/tests/config.py', 'trove/db/sqlalchemy/migrate_repo/schema.py', 'trove/db/__init__.py', 'trove/db/sqlalchemy/migration.py', 'trove/tests/api/instances_delete.py', 'trove/tests/unittests/guestagent/test_mongodb_cluster_manager.py', 'trove/tests/api/configurations.py', 'trove/tests/unittests/instance/test_instance_models.py', 'trove/extensions/account/service.py', 'trove/tests/unittests/cluster/test_cluster_views.py', 'trove/instance/views.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/extensions/account/models.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/guestagent/models.py', 'trove/common/strategies/cluster/experimental/mongodb/api.py', 'trove/tests/fakes/swift.py', 'trove/guestagent/strategies/restore/mysql_impl.py', 'trove/tests/api/mgmt/configurations.py', 'trove/tests/unittests/guestagent/test_models.py', 'trove/extensions/security_group/models.py', 'trove/tests/unittests/guestagent/test_db2_manager.py', 'trove/tests/unittests/network/test_neutron_driver.py', 'trove/tests/unittests/guestagent/test_pkg.py', 'trove/tests/api/header.py', 'trove/db/sqlalchemy/migrate_repo/versions/012_backup.py', 'trove/tests/api/mgmt/accounts.py', 'trove/guestagent/strategies/replication/mysql_base.py', 'trove/tests/api/mgmt/admin_required.py', 'trove/tests/unittests/guestagent/test_mysql_manager.py', 'trove/guestagent/common/operating_system.py', 'trove/conductor/api.py', 'trove/db/sqlalchemy/migrate_repo/versions/027_add_datastore_capabilities.py', 'trove/guestagent/datastore/experimental/cassandra/service.py', 'run_tests.py', 'trove/extensions/mgmt/instances/models.py', 'trove/tests/util/event_simulator.py', 'trove/extensions/security_group/service.py', 'generate_examples.py', 'trove/tests/unittests/guestagent/test_couchdb_manager.py', 'trove/tests/api/mgmt/quotas.py', 'trove/common/auth.py', 'trove/configuration/service.py', 'trove/guestagent/strategies/backup/experimental/couchbase_impl.py', 'trove/common/utils.py', 'trove/db/sqlalchemy/migrate_repo/versions/030_add_master_slave.py', 'trove/backup/models.py', 'trove/common/pagination.py', 'trove/extensions/mgmt/quota/service.py', 'trove/guestagent/backup/backupagent.py', 'trove/db/sqlalchemy/migrate_repo/versions/020_configurations.py', 'trove/extensions/mgmt/volume/service.py', 'trove/tests/unittests/datastore/base.py', 'trove/tests/api/mgmt/instances.py', 'trove/tests/util/usage.py', 'trove/db/sqlalchemy/migrate_repo/versions/031_add_timestamps_to_configurations.py', 'trove/guestagent/dbaas.py', 'trove/tests/api/root_on_create.py', 'trove/tests/util/check.py', 'trove/dns/models.py', 'trove/tests/unittests/guestagent/test_mongodb_manager.py', 'trove/guestagent/datastore/experimental/postgresql/service/users.py', 'trove/tests/api/instances_actions.py', 'trove/guestagent/datastore/experimental/db2/service.py', 'trove/common/template.py', 'trove/tests/api/instances.py', 'trove/tests/api/mgmt/malformed_json.py', 'trove/tests/api/flavors.py', 'trove/datastore/models.py', 'trove/db/sqlalchemy/migrate_repo/versions/033_datastore_parameters.py', 'trove/tests/api/instances_mysql_down.py', 'trove/tests/unittests/guestagent/test_dbmodels.py', 'trove/guestagent/datastore/experimental/postgresql/service/access.py', 'trove/tests/unittests/api/common/test_limits.py', 'trove/tests/unittests/upgrade/test_controller.py', 'trove/cmd/manage.py', 'trove/guestagent/datastore/experimental/db2/manager.py', 'trove/db/sqlalchemy/session.py', 'trove/guestagent/datastore/experimental/mongodb/service.py', 'trove/common/exception.py', 'trove/tests/api/mgmt/instances_actions.py', 'trove/tests/api/users.py', 'trove/tests/unittests/configuration/test_configuration_controller.py', 'trove/guestagent/pkg.py', 'trove/tests/db/migrations.py', 'trove/tests/unittests/router/test_router.py', 'trove/tests/unittests/guestagent/test_operating_system.py', 'trove/tests/unittests/guestagent/test_volume.py', 'trove/tests/unittests/guestagent/test_vertica_manager.py', 'trove/guestagent/datastore/experimental/couchdb/manager.py', 'trove/common/strategies/cluster/experimental/vertica/taskmanager.py', 'trove/guestagent/datastore/experimental/cassandra/manager.py', 'trove/extensions/mgmt/configuration/service.py', 'trove/extensions/mgmt/clusters/service.py', 'trove/tests/api/instances_resize.py', 'trove/tests/api/mgmt/storage.py', 'trove/db/sqlalchemy/migrate_repo/versions/021_conductor_last_seen.py', 'trove/tests/fakes/guestagent.py', 'trove/tests/api/mgmt/hosts.py', 'trove/dns/designate/driver.py', 'trove/common/api.py', 'trove/guestagent/datastore/experimental/postgresql/service/root.py', 'trove/common/models.py', 'trove/tests/util/__init__.py', 'trove/extensions/mysql/models.py', 'trove/db/models.py', 'trove/cluster/models.py', 'trove/cmd/fakemode.py', 'trove/guestagent/datastore/experimental/vertica/service.py', 'trove/tests/examples/snippets.py', 'trove/extensions/routes/security_group.py', 'trove/tests/unittests/guestagent/test_couchbase_manager.py', 'trove/taskmanager/manager.py', 'trove/tests/util/mysql.py', 'trove/db/sqlalchemy/migrate_repo/versions/024_add_backup_indexes.py', 'trove/guestagent/datastore/experimental/mongodb/manager.py', 'trove/tests/unittests/taskmanager/test_models.py', 'trove/common/limits.py', 'trove/common/extensions.py', 'trove/extensions/mgmt/upgrade/service.py', 'trove/guestagent/datastore/experimental/redis/manager.py', 'trove/guestagent/strategies/storage/swift.py', 'trove/taskmanager/api.py', 'trove/db/sqlalchemy/migrate_repo/versions/025_add_service_statuses_indexes.py', 'trove/tests/unittests/mgmt/test_models.py', 'trove/tests/unittests/dns/test_designate_driver.py', 'trove/extensions/mysql/service.py', 'trove/tests/unittests/common/test_remote.py', 'trove/db/sqlalchemy/migrate_repo/versions/032_clusters.py', 'trove/tests/unittests/mysql/test_user_controller.py', 'trove/instance/models.py', 'trove/tests/unittests/secgroups/test_security_group.py', 'trove/extensions/mgmt/host/models.py', 'trove/tests/unittests/guestagent/test_redis_manager.py', 'trove/cluster/service.py', 'trove/db/sqlalchemy/migrate_repo/versions/019_datastore_fix.py', 'trove/extensions/mgmt/host/service.py', 'trove/guestagent/datastore/experimental/postgresql/service/database.py', 'trove/dns/manager.py', 'trove/guestagent/common/timeutils.py', 'trove/guestagent/datastore/experimental/couchdb/service.py', 'trove/common/strategies/cluster/experimental/mongodb/taskmanager.py', 'trove/flavor/views.py', 'trove/tests/fakes/dns.py', 'trove/tests/unittests/guestagent/test_cassandra_manager.py', 'trove/guestagent/volume.py', 'trove/tests/api/datastores.py', 'trove/guestagent/datastore/experimental/couchbase/service.py', 'trove/guestagent/strategies/restore/base.py', 'trove/tests/examples/client.py', 'trove/guestagent/datastore/experimental/postgresql/manager.py', 'trove/guestagent/datastore/experimental/vertica/manager.py', 'trove/guestagent/datastore/experimental/postgresql/service/config.py', 'trove/tests/unittests/backup/test_storage.py', 'trove/tests/unittests/common/test_template.py', 'trove/tests/api/replication.py', 'trove/tests/fakes/taskmanager.py', 'trove/tests/unittests/api/test_versions.py', 'trove/guestagent/strategies/restore/experimental/postgresql_impl.py', 'trove/configuration/models.py', 'contrib/trove-guestagent', 'trove/tests/api/databases.py', 'trove/extensions/routes/mgmt.py', 'trove/tests/api/backups.py', 'trove/tests/api/user_access.py', 'trove/guestagent/strategies/restore/experimental/couchbase_impl.py', 'trove/guestagent/datastore/experimental/postgresql/service/status.py', 'trove/backup/service.py', 'trove/extensions/security_group/views.py', 'trove/network/neutron.py', 'trove/guestagent/datastore/experimental/redis/service.py', 'tox.ini', 'trove/tests/unittests/instance/test_instance_controller.py', 'trove/tests/unittests/taskmanager/test_manager.py', 'trove/guestagent/datastore/mysql/manager.py', 'trove/tests/unittests/conductor/test_conf.py', 'trove/extensions/mgmt/host/instance/service.py', 'trove/guestagent/datastore/mysql/service.py', 'trove/tests/unittests/datastore/test_datastore.py', 'trove/db/sqlalchemy/migrate_repo/versions/006_dns_records.py', 'trove/quota/quota.py', 'trove/db/sqlalchemy/migrate_repo/versions/023_add_instance_indexes.py', 'trove/datastore/views.py', 'trove/guestagent/datastore/service.py', 'trove/guestagent/datastore/experimental/postgresql/service/install.py', 'trove/conductor/manager.py', 'trove/network/nova.py', 'trove/db/sqlalchemy/mappers.py', 'trove/tests/api/limits.py', 'trove/db/sqlalchemy/migrate_repo/versions/013_add_security_group_artifacts.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/tests/unittests/guestagent/test_agent_heartbeats_models.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/tests/unittests/quota/test_quota.py', 'trove/tests/api/root.py', 'trove/tests/unittests/conductor/test_methods.py', 'trove/tests/unittests/datastore/test_capability.py', 'trove/extensions/mgmt/instances/service.py', 'trove/tests/api/versions.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/7db58bf5cf357c1d34bcb199fb4278e2542ca843', 'message': 'Enabled H306 hacking rule\n\nThe import order rule was disabled in trove for pep8 checks.\nEnabled the rule and fixed the erroring imports in modules.\n\nChange-Id: I198e1f637b12827c33f930b07405432e3f2151c0\n'}]",3,181950,7db58bf5cf357c1d34bcb199fb4278e2542ca843,16,7,3,7806,,,0,"Enabled H306 hacking rule

The import order rule was disabled in trove for pep8 checks.
Enabled the rule and fixed the erroring imports in modules.

Change-Id: I198e1f637b12827c33f930b07405432e3f2151c0
",git fetch https://review.opendev.org/openstack/trove refs/changes/50/181950/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/wsgi.py', 'trove/guestagent/datastore/experimental/couchbase/manager.py', 'trove/instance/service.py', 'trove/tests/config.py', 'trove/db/sqlalchemy/migrate_repo/schema.py', 'trove/db/__init__.py', 'trove/db/sqlalchemy/migration.py', 'trove/tests/api/instances_delete.py', 'trove/tests/unittests/guestagent/test_mongodb_cluster_manager.py', 'trove/tests/api/configurations.py', 'trove/tests/unittests/instance/test_instance_models.py', 'trove/extensions/account/service.py', 'trove/tests/unittests/cluster/test_cluster_views.py', 'trove/instance/views.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/extensions/account/models.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/guestagent/models.py', 'trove/common/strategies/cluster/experimental/mongodb/api.py', 'trove/tests/fakes/swift.py', 'trove/guestagent/strategies/restore/mysql_impl.py', 'trove/tests/api/mgmt/configurations.py', 'trove/tests/unittests/guestagent/test_models.py', 'trove/extensions/security_group/models.py', 'trove/tests/unittests/guestagent/test_db2_manager.py', 'trove/tests/unittests/network/test_neutron_driver.py', 'trove/tests/unittests/guestagent/test_pkg.py', 'trove/tests/api/header.py', 'trove/db/sqlalchemy/migrate_repo/versions/012_backup.py', 'trove/tests/api/mgmt/accounts.py', 'trove/guestagent/strategies/replication/mysql_base.py', 'trove/tests/api/mgmt/admin_required.py', 'trove/tests/unittests/guestagent/test_mysql_manager.py', 'trove/guestagent/common/operating_system.py', 'trove/conductor/api.py', 'trove/db/sqlalchemy/migrate_repo/versions/027_add_datastore_capabilities.py', 'trove/tests/unittests/instance/test_instance_views.py', 'trove/guestagent/datastore/experimental/cassandra/service.py', 'run_tests.py', 'trove/extensions/mgmt/instances/models.py', 'trove/tests/util/event_simulator.py', 'trove/extensions/security_group/service.py', 'generate_examples.py', 'trove/tests/unittests/guestagent/test_couchdb_manager.py', 'trove/tests/api/mgmt/quotas.py', 'trove/common/auth.py', 'trove/configuration/service.py', 'trove/guestagent/strategies/backup/experimental/couchbase_impl.py', 'trove/common/utils.py', 'trove/db/sqlalchemy/migrate_repo/versions/030_add_master_slave.py', 'trove/backup/models.py', 'trove/common/pagination.py', 'trove/extensions/mgmt/quota/service.py', 'trove/guestagent/backup/backupagent.py', 'trove/db/sqlalchemy/migrate_repo/versions/020_configurations.py', 'trove/extensions/mgmt/volume/service.py', 'trove/tests/unittests/datastore/base.py', 'trove/tests/api/mgmt/instances.py', 'trove/tests/util/usage.py', 'trove/db/sqlalchemy/migrate_repo/versions/031_add_timestamps_to_configurations.py', 'trove/guestagent/dbaas.py', 'trove/tests/api/root_on_create.py', 'trove/tests/util/check.py', 'trove/dns/models.py', 'trove/tests/unittests/guestagent/test_mongodb_manager.py', 'trove/guestagent/datastore/experimental/postgresql/service/users.py', 'trove/tests/api/instances_actions.py', 'trove/guestagent/datastore/experimental/db2/service.py', 'trove/common/template.py', 'trove/tests/api/instances.py', 'trove/tests/api/mgmt/malformed_json.py', 'trove/tests/api/flavors.py', 'trove/datastore/models.py', 'trove/db/sqlalchemy/migrate_repo/versions/033_datastore_parameters.py', 'trove/tests/api/instances_mysql_down.py', 'trove/tests/unittests/guestagent/test_dbmodels.py', 'trove/guestagent/datastore/experimental/postgresql/service/access.py', 'trove/tests/unittests/api/common/test_limits.py', 'trove/tests/unittests/upgrade/test_controller.py', 'trove/cmd/manage.py', 'trove/guestagent/datastore/experimental/db2/manager.py', 'trove/db/sqlalchemy/session.py', 'trove/guestagent/datastore/experimental/mongodb/service.py', 'trove/common/exception.py', 'trove/tests/api/mgmt/instances_actions.py', 'trove/tests/api/users.py', 'trove/tests/unittests/configuration/test_configuration_controller.py', 'trove/guestagent/pkg.py', 'trove/tests/db/migrations.py', 'trove/tests/unittests/guestagent/test_operating_system.py', 'trove/tests/unittests/guestagent/test_volume.py', 'trove/tests/unittests/instance/test_instance_status.py', 'trove/tests/unittests/guestagent/test_vertica_manager.py', 'trove/guestagent/datastore/experimental/couchdb/manager.py', 'trove/common/strategies/cluster/experimental/vertica/taskmanager.py', 'trove/guestagent/datastore/experimental/cassandra/manager.py', 'trove/extensions/mgmt/configuration/service.py', 'trove/extensions/mgmt/clusters/service.py', 'trove/tests/api/instances_resize.py', 'trove/tests/api/mgmt/storage.py', 'trove/db/sqlalchemy/migrate_repo/versions/021_conductor_last_seen.py', 'trove/tests/fakes/guestagent.py', 'trove/tests/api/mgmt/hosts.py', 'trove/dns/designate/driver.py', 'trove/common/api.py', 'trove/guestagent/datastore/experimental/postgresql/service/root.py', 'trove/common/models.py', 'trove/tests/util/__init__.py', 'trove/extensions/mysql/models.py', 'trove/db/models.py', 'trove/cluster/models.py', 'trove/guestagent/datastore/experimental/vertica/service.py', 'trove/tests/examples/snippets.py', 'trove/extensions/routes/security_group.py', 'trove/tests/unittests/guestagent/test_couchbase_manager.py', 'trove/taskmanager/manager.py', 'trove/tests/util/mysql.py', 'trove/db/sqlalchemy/migrate_repo/versions/024_add_backup_indexes.py', 'trove/guestagent/datastore/experimental/mongodb/manager.py', 'trove/tests/unittests/taskmanager/test_models.py', 'trove/common/limits.py', 'trove/common/extensions.py', 'trove/extensions/mgmt/upgrade/service.py', 'trove/guestagent/datastore/experimental/redis/manager.py', 'trove/guestagent/strategies/storage/swift.py', 'trove/taskmanager/api.py', 'trove/db/sqlalchemy/migrate_repo/versions/025_add_service_statuses_indexes.py', 'trove/tests/unittests/mgmt/test_models.py', 'trove/tests/unittests/dns/test_designate_driver.py', 'trove/tests/unittests/mysql/test_common.py', 'trove/extensions/mysql/service.py', 'trove/tests/unittests/common/test_remote.py', 'trove/db/sqlalchemy/migrate_repo/versions/032_clusters.py', 'trove/tests/unittests/mysql/test_user_controller.py', 'trove/instance/models.py', 'trove/tests/unittests/secgroups/test_security_group.py', 'trove/extensions/mgmt/host/models.py', 'trove/tests/unittests/guestagent/test_redis_manager.py', 'trove/cluster/service.py', 'trove/db/sqlalchemy/migrate_repo/versions/019_datastore_fix.py', 'trove/extensions/mgmt/host/service.py', 'trove/guestagent/datastore/experimental/postgresql/service/database.py', 'trove/dns/manager.py', 'trove/guestagent/common/timeutils.py', 'trove/guestagent/datastore/experimental/couchdb/service.py', 'trove/common/strategies/cluster/experimental/mongodb/taskmanager.py', 'trove/flavor/views.py', 'trove/tests/fakes/dns.py', 'trove/tests/unittests/guestagent/test_cassandra_manager.py', 'trove/guestagent/volume.py', 'trove/tests/api/datastores.py', 'trove/guestagent/datastore/experimental/couchbase/service.py', 'trove/guestagent/strategies/restore/base.py', 'trove/tests/examples/client.py', 'trove/guestagent/datastore/experimental/postgresql/manager.py', 'trove/guestagent/datastore/experimental/vertica/manager.py', 'trove/guestagent/datastore/experimental/postgresql/service/config.py', 'trove/tests/unittests/backup/test_storage.py', 'trove/tests/unittests/common/test_template.py', 'trove/tests/api/replication.py', 'trove/tests/fakes/taskmanager.py', 'trove/tests/unittests/api/test_versions.py', 'trove/guestagent/strategies/restore/experimental/postgresql_impl.py', 'trove/configuration/models.py', 'contrib/trove-guestagent', 'trove/tests/api/databases.py', 'trove/extensions/routes/mgmt.py', 'trove/tests/api/backups.py', 'trove/tests/api/user_access.py', 'trove/guestagent/strategies/restore/experimental/couchbase_impl.py', 'trove/guestagent/datastore/experimental/postgresql/service/status.py', 'trove/backup/service.py', 'trove/extensions/security_group/views.py', 'trove/network/neutron.py', 'trove/guestagent/datastore/experimental/redis/service.py', 'tox.ini', 'trove/tests/unittests/instance/test_instance_controller.py', 'trove/tests/unittests/taskmanager/test_manager.py', 'trove/guestagent/datastore/mysql/manager.py', 'trove/tests/unittests/conductor/test_conf.py', 'trove/extensions/mgmt/host/instance/service.py', 'trove/guestagent/datastore/mysql/service.py', 'trove/tests/unittests/datastore/test_datastore.py', 'trove/db/sqlalchemy/migrate_repo/versions/006_dns_records.py', 'trove/quota/quota.py', 'trove/db/sqlalchemy/migrate_repo/versions/023_add_instance_indexes.py', 'trove/datastore/views.py', 'trove/guestagent/datastore/service.py', 'trove/guestagent/datastore/experimental/postgresql/service/install.py', 'trove/conductor/manager.py', 'trove/network/nova.py', 'trove/db/sqlalchemy/mappers.py', 'trove/tests/api/limits.py', 'trove/db/sqlalchemy/migrate_repo/versions/013_add_security_group_artifacts.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/tests/unittests/guestagent/test_agent_heartbeats_models.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/tests/unittests/quota/test_quota.py', 'trove/tests/api/root.py', 'trove/tests/unittests/conductor/test_methods.py', 'trove/tests/unittests/datastore/test_capability.py', 'trove/extensions/mgmt/instances/service.py', 'trove/tests/api/versions.py']",204,85bc88da449528e6f099e8a5dec41221428d96f7,master,from proboscis import before_classfrom proboscis import test from trove.tests.util import test_configfrom troveclient.compat.exceptions import ClientException,from proboscis import before_class from proboscis import test from troveclient.compat.exceptions import ClientExceptionfrom trove.tests.util import test_config,700,698
openstack%2Fmagnum~master~Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb,openstack/magnum,master,Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb,Rename bay_k8s_heat to more general name,MERGED,2015-05-14 06:42:42.000000000,2015-05-27 05:05:09.000000000,2015-05-27 05:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 8580}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12175}, {'_account_id': 12927}, {'_account_id': 16439}]","[{'number': 1, 'created': '2015-05-14 06:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e3fbe982c18453f38778fc3d3a0db0ae03ba623b', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 2, 'created': '2015-05-25 00:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f8b895cc08ddefb86ab87420df0cdb262700a9d5', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 3, 'created': '2015-05-25 01:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fa6940c737b2531f6422c4a7ffd9fc5b740e273d', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 4, 'created': '2015-05-25 01:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f91886890f655653d861bb4b43ca2c2e1e45c16d', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 5, 'created': '2015-05-25 23:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5d42f3d8d31dc0a77405d34ea9243c822e5a4de0', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 6, 'created': '2015-05-26 00:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b4cbca8bcb357fc8428f99069e027df4267fca5e', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 7, 'created': '2015-05-26 23:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/454c20a02dc98a5ec9a8567ba944239865d65111', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}, {'number': 8, 'created': '2015-05-27 02:54:02.000000000', 'files': ['etc/magnum/magnum.conf.sample', 'magnum/tests/unit/conductor/handlers/test_bay_conductor.py', 'magnum/conductor/template_definition.py', 'magnum/db/sqlalchemy/alembic/versions/592131657ca1_add_coe_column_to_baymodel.py', 'magnum/opts.py', 'magnum/cmd/conductor.py', 'magnum/conductor/handlers/bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/86cf092a6852ed7c7f040b8d7a092eb1a92c245a', 'message': 'Rename bay_k8s_heat to more general name\n\nSince bay is not bind to k8s, it can use with swarm or other containers\ncluster ways. We rename it to make it more general case.\n\nCloses-Bug: #1459081\nChange-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb\n'}]",15,182946,86cf092a6852ed7c7f040b8d7a092eb1a92c245a,55,11,8,7049,,,0,"Rename bay_k8s_heat to more general name

Since bay is not bind to k8s, it can use with swarm or other containers
cluster ways. We rename it to make it more general case.

Closes-Bug: #1459081
Change-Id: Idd7bc9497b3059ceea153a641a0c65d1f2ed50eb
",git fetch https://review.opendev.org/openstack/magnum refs/changes/46/182946/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/conductor/handlers/test_bay_k8s_heat.py', 'magnum/conductor/template_definition.py', 'magnum/conductor/handlers/bay_heat.py', 'magnum/db/sqlalchemy/alembic/versions/592131657ca1_add_coe_column_to_baymodel.py', 'magnum/opts.py', 'magnum/cmd/conductor.py']",6,e3fbe982c18453f38778fc3d3a0db0ae03ba623b,renamefile,"from magnum.conductor.handlers import bay_heat bay_heat.Handler(),","from magnum.conductor.handlers import bay_k8s_heat bay_k8s_heat.Handler(),",58,58
openstack%2Fheat~master~I883313bf0f66c312cc592c62720dd828be488a5c,openstack/heat,master,I883313bf0f66c312cc592c62720dd828be488a5c,Add attribute type for aws resources,MERGED,2015-05-12 06:42:53.000000000,2015-05-27 05:04:39.000000000,2015-05-27 05:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 10487}, {'_account_id': 11424}, {'_account_id': 11956}, {'_account_id': 12606}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2015-05-12 06:42:53.000000000', 'files': ['heat/engine/resources/aws/cfn/wait_condition.py', 'heat/engine/resources/aws/s3/s3.py', 'heat/engine/resources/aws/ec2/eip.py', 'heat/engine/resources/aws/autoscaling/autoscaling_group.py', 'heat/engine/resources/aws/ec2/network_interface.py', 'heat/engine/resources/aws/iam/user.py', 'heat/engine/resources/aws/ec2/instance.py', 'heat/engine/resources/aws/ec2/subnet.py', 'heat/engine/resources/aws/autoscaling/scaling_policy.py', 'heat/engine/resources/aws/lb/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/557d926d4071b82725d09d97bd9ab783484144a8', 'message': 'Add attribute type for aws resources\n\nAdd type field to the schema of the aws resources.\n\nImplements: blueprint add-type-in-attributes-schema\ncloses-bug: #1434539\nChange-Id: I883313bf0f66c312cc592c62720dd828be488a5c\n'}]",7,182169,557d926d4071b82725d09d97bd9ab783484144a8,19,12,1,11956,,,0,"Add attribute type for aws resources

Add type field to the schema of the aws resources.

Implements: blueprint add-type-in-attributes-schema
closes-bug: #1434539
Change-Id: I883313bf0f66c312cc592c62720dd828be488a5c
",git fetch https://review.opendev.org/openstack/heat refs/changes/69/182169/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/aws/cfn/wait_condition.py', 'heat/engine/resources/aws/s3/s3.py', 'heat/engine/resources/aws/ec2/eip.py', 'heat/engine/resources/aws/autoscaling/autoscaling_group.py', 'heat/engine/resources/aws/ec2/network_interface.py', 'heat/engine/resources/aws/iam/user.py', 'heat/engine/resources/aws/ec2/instance.py', 'heat/engine/resources/aws/autoscaling/scaling_policy.py', 'heat/engine/resources/aws/ec2/subnet.py', 'heat/engine/resources/aws/lb/loadbalancer.py']",10,557d926d4071b82725d09d97bd9ab783484144a8,bp/add-type-in-attributes-schema," ""LoadBalancer.""), type=attributes.Schema.STRING ""LoadBalancer.""), type=attributes.Schema.STRING _(""The DNS name for the LoadBalancer.""), type=attributes.Schema.STRING ""rules for your LoadBalancer's back-end instances.""), type=attributes.Schema.STRING _(""Owner of the source security group.""), type=attributes.Schema.STRING"," ""LoadBalancer."") ""LoadBalancer."") _(""The DNS name for the LoadBalancer."") ""rules for your LoadBalancer's back-end instances."") _(""Owner of the source security group."")",41,21
openstack%2Fheat~master~Iaf3731ccf5e4693f26a068191cfbb26088dd516c,openstack/heat,master,Iaf3731ccf5e4693f26a068191cfbb26088dd516c,Remove deprecated resolve_runtime_data,MERGED,2015-05-22 15:27:25.000000000,2015-05-27 05:04:35.000000000,2015-05-27 05:04:33.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 12321}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2015-05-22 15:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9a64a3910ef1cc82efde6cc90063e2dced9919a', 'message': 'Remove deprecated resolve_runtime_data\n\nRemove unused resolve_runtime_data according to\nhttps://etherpad.openstack.org/p/YVR-heat-liberty-deprecation\n\nChange-Id: Iaf3731ccf5e4693f26a068191cfbb26088dd516c\n'}, {'number': 2, 'created': '2015-05-22 19:47:09.000000000', 'files': ['heat/tests/test_template.py', 'heat/engine/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0295570d3186ce64bbb17ae254720c0c15251458', 'message': 'Remove deprecated resolve_runtime_data\n\nRemove unused resolve_runtime_data according to\nhttps://etherpad.openstack.org/p/YVR-heat-liberty-deprecation\n\nChange-Id: Iaf3731ccf5e4693f26a068191cfbb26088dd516c\n'}]",0,185047,0295570d3186ce64bbb17ae254720c0c15251458,22,10,2,13323,,,0,"Remove deprecated resolve_runtime_data

Remove unused resolve_runtime_data according to
https://etherpad.openstack.org/p/YVR-heat-liberty-deprecation

Change-Id: Iaf3731ccf5e4693f26a068191cfbb26088dd516c
",git fetch https://review.opendev.org/openstack/heat refs/changes/47/185047/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_template.py', 'heat/engine/stack.py']",2,d9a64a3910ef1cc82efde6cc90063e2dced9919a,remove-resolve-runtime-data,," def resolve_runtime_data(self, snippet): """"""DEPRECATED. Use heat.engine.function.resolve() instead."""""" warnings.warn('Stack.resolve_runtime_data() is deprecated. ' 'Use heat.engine.function.resolve() instead', DeprecationWarning) return function.resolve(snippet) ",0,19
openstack%2Fneutron-vpnaas~master~Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf,openstack/neutron-vpnaas,master,Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf,Assign external_ip based on ip version of peer_address,MERGED,2015-05-11 09:36:36.000000000,2015-05-27 04:57:30.000000000,2015-05-27 04:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10267}, {'_account_id': 10980}, {'_account_id': 12860}, {'_account_id': 14216}]","[{'number': 1, 'created': '2015-05-11 09:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/76209a76ccb7f0bc74b169da6e100a30dc625ff3', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, the following addresses version should match\n1) external_ip and peer_address should be of same ip version for *Swaan.\n   So external_ip should be assigned based on ip version of peer_address.\n2) peer_cidrs and subnet cidr should be of same ip version for *Swaan.\n3) peer_cidrs and peer_address should be of same ip version for OpenSwan.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 2, 'created': '2015-05-13 13:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/e871d1092ed593b0fbdcdbf864455328a956ac0a', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nvpnservice creation should fail if external network associated\nwith the router has no subnets.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 3, 'created': '2015-05-18 14:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/fa914f2a9e0d963ed36fc8822526de46e1814fbf', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 4, 'created': '2015-05-18 16:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/4e3492916af0fe630a048261def8542ec40bae6e', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 5, 'created': '2015-05-19 13:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/96eb921500d3ca300263ae166f6d7adf9786e2c4', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 6, 'created': '2015-05-19 14:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7ff79d248c0093f43ca0517e230b9e95849b0590', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 7, 'created': '2015-05-19 20:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/33e4697d9c0b42c66bb47cb4918b375874f27550', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swaan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nDocImpact\na, In the same ipsec site connection, external_ip and peer_address\n   should be of same ip version for *Swaan.\nb, To support vpnaas with ipv6, external network must have ipv6 subnet,\n   as ipsec won't work with IPv6 LLA and neutron unaware GUA.\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}, {'number': 8, 'created': '2015-05-20 06:28:47.000000000', 'files': ['neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'neutron_vpnaas/db/vpn/vpn_validator.py', 'neutron_vpnaas/services/vpn/device_drivers/template/strongswan/ipsec.conf.template', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/template/openswan/ipsec.conf.template', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_db.py', 'neutron_vpnaas/services/vpn/device_drivers/template/strongswan/ipsec.secret.template', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/db/vpn/vpn_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/0003f936b040a16ee9c1f72de7702cb083d41d9d', 'message': ""Assign external_ip based on ip version of peer_address\n\nIn the same ipsec site connection, external_ip and peer_address\nshould be of same ip version for *Swan.\nSo external_ip should be assigned from router gateway addresses\nbased on ip version of peer_address.\n\nIpsec won't work with IPv6 LLA and neutron unaware GUA.\nSo to support vpnaas with ipv6, external network must have ipv6 subnet.\n\nDocImpact\na, In the same ipsec site connection, external_ip and peer_address\n   should be of same ip version for *Swan.\nb, To support vpnaas with ipv6, external network must have ipv6 subnet,\n   as ipsec won't work with IPv6 LLA and neutron unaware GUA.\nChange-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf\nCloses-bug: #1450479\n""}]",39,181842,0003f936b040a16ee9c1f72de7702cb083d41d9d,47,6,8,10267,,,0,"Assign external_ip based on ip version of peer_address

In the same ipsec site connection, external_ip and peer_address
should be of same ip version for *Swan.
So external_ip should be assigned from router gateway addresses
based on ip version of peer_address.

Ipsec won't work with IPv6 LLA and neutron unaware GUA.
So to support vpnaas with ipv6, external network must have ipv6 subnet.

DocImpact
a, In the same ipsec site connection, external_ip and peer_address
   should be of same ip version for *Swan.
b, To support vpnaas with ipv6, external network must have ipv6 subnet,
   as ipsec won't work with IPv6 LLA and neutron unaware GUA.
Change-Id: Id6ce9939d448d7d009af491ae3d49ba5e1efb9cf
Closes-bug: #1450479
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/42/181842/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/db/vpn/vpn_validator.py', 'neutron_vpnaas/services/vpn/device_drivers/template/strongswan/ipsec.conf.template', 'neutron_vpnaas/services/vpn/device_drivers/template/openswan/ipsec.conf.template', 'neutron_vpnaas/services/vpn/device_drivers/template/strongswan/ipsec.secret.template', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py']",7,76209a76ccb7f0bc74b169da6e100a30dc625ff3,," def _resolve_fqdn(self, fqdn): # The first addrinfo member from the list returned by # socket.getaddrinfo is used for the address resolution. # The code doesn't filter for ipv4 or ipv6 address. try: addrinfo = socket.getaddrinfo(fqdn, None)[0] return addrinfo[-1][0] except socket.gaierror: LOG.exception(_LE(""Peer address %s cannot be resolved""), fqdn) def get_peer_address(self, address, connection_id): # check if address is an ip address or fqdn invalid_ip_address = attributes._validate_ip_address(address) if invalid_ip_address: ip_addr = self._resolve_fqdn(address) if not ip_addr: self._record_connection_status(connection_id, constants.ERROR, updated_pending_status=True) raise vpnaas.VPNPeerAddressNotResolved(peer_address=address) return ip_addr else: return address def _validate_ipsec_sitecon_addresses(self): for ipsec_site_conn in self.vpnservice['ipsec_site_connections']: external_ip = ipsec_site_conn['external_ip'] ip_version = netaddr.IPAddress(external_ip).version # addresses used in same connection should have same ip version # for openswan for peer_cidr in ipsec_site_conn['peer_cidrs']: peer_cidr_version = netaddr.IPNetwork(peer_cidr) if ip_version != peer_cidr_version: raise vpnaas.VPNPeerCidrVersionMismatch( peer_cidr=peer_cidr) self._validate_ipsec_sitecon_addresses() ip_addr = self.get_peer_address(self, address, connection_id) return ip_addr def assign_ipsec_sitecon_external_ip(self, process): """"""Assign external_ip to ipsec siteconn. We need to assign ip from gateway based on the ip version of peer_address. :param process: process This method do nothing if there is no router """""" router = self.routers.get(router_id) vpnservice = process.vpnservice for ipsec_site_conn in vpnservice['ipsec_site_connections']: peer_address = process.get_peer_address( ipsec_site_conn['peer_address'], ipsec_site_conn['id']) ip_version = netaddr.IPAddress(peer_address).version # *Swan use same ip version for left and right gateway ips # If gateway has multiple GUA, we assign the first one, as # any GUA can be used to reach the external network router = self.routers.get(vpnservice['router_id']) if not router: return LOG.debug(router.router) for fixed_ip in router.router['gw_port']['fixed_ips']: addr = fixed_ip['ip_address'] if ip_version == netaddr.IPAddress(addr).version: ipsec_site_conn['external_ip'] = addr break # ipsec won't work with IPv6 LLA and neutron unaware GUA. # So to support vpnaas with ipv6, external network must # have ipv6 subnet if not ipsec_site_conn['external_ip']: raise vpnaas.ExternalNetworkHasNoIPv6Subnet() self.assign_ipsec_sitecon_external_ip(process) self.assign_ipsec_sitecon_external_ip(process)"," def _resolve_fqdn(self, fqdn): # The first addrinfo member from the list returned by # socket.getaddrinfo is used for the address resolution. # The code doesn't filter for ipv4 or ipv6 address. try: addrinfo = socket.getaddrinfo(fqdn, None)[0] return addrinfo[-1][0] except socket.gaierror: LOG.exception(_LE(""Peer address %s cannot be resolved""), fqdn) invalid_ip_address = attributes._validate_ip_address(address) if invalid_ip_address: ip_addr = self._resolve_fqdn(address) if not ip_addr: self._record_connection_status(connection_id, constants.ERROR, updated_pending_status=True) raise vpnaas.VPNPeerAddressNotResolved(peer_address=address) else: ip_addr = address return address",93,28
openstack%2Fproject-config~master~I272c1e301e26e8cde278ddf763e0c6f9630bb985,openstack/project-config,master,I272c1e301e26e8cde278ddf763e0c6f9630bb985,Add project 'networking-freescale' to Stackforge.,ABANDONED,2015-02-26 07:54:27.000000000,2015-05-27 04:40:00.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1106}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 7069}, {'_account_id': 8645}, {'_account_id': 11809}]","[{'number': 1, 'created': '2015-02-26 07:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/74c9f65a2177a4034106abe7b1f92c627793e126', 'message': ""Adding project 'networking-freescale' to Stackforge.\n\nChange-Id: I272c1e301e26e8cde278ddf763e0c6f9630bb985\n""}, {'number': 2, 'created': '2015-02-27 06:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eef385c3b3b35107bffb08e61e0dda413bc78b74', 'message': ""Add project 'networking-freescale' to Stackforge.\n\nChange-Id: I272c1e301e26e8cde278ddf763e0c6f9630bb985\n""}, {'number': 3, 'created': '2015-02-28 15:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7b5c96db58e81dbca3592683f0ad2cd2a02d2fc7', 'message': ""Add project 'networking-freescale' to Stackforge.\n\nChange-Id: I272c1e301e26e8cde278ddf763e0c6f9630bb985\n""}, {'number': 4, 'created': '2015-02-28 16:06:32.000000000', 'files': ['gerrit/acls/stackforge/networking-freescale.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e4a0f5c4e4a49f3e8dbabdedfcd4532c6a00803d', 'message': ""Add project 'networking-freescale' to Stackforge.\n\nChange-Id: I272c1e301e26e8cde278ddf763e0c6f9630bb985\n""}]",4,159362,e4a0f5c4e4a49f3e8dbabdedfcd4532c6a00803d,24,10,4,8645,,,0,"Add project 'networking-freescale' to Stackforge.

Change-Id: I272c1e301e26e8cde278ddf763e0c6f9630bb985
",git fetch https://review.opendev.org/openstack/project-config refs/changes/62/159362/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/acls/stackforge/networking-freescale.config', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,74c9f65a2177a4034106abe7b1f92c627793e126,networking-freescale, - name: stackforge/networking-freescale template: - name: merge-check - name: python-jobs ,,30,0
openstack%2Fcinder~master~I8e06195dc3625ef07bc9858d844541e37a231b73,openstack/cinder,master,I8e06195dc3625ef07bc9858d844541e37a231b73,LVM: Pass volume size in MiB to copy_volume() during volume migration,MERGED,2015-05-13 20:37:29.000000000,2015-05-27 04:37:39.000000000,2015-05-14 01:54:55.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14969}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-13 20:37:29.000000000', 'files': ['cinder/tests/unit/test_volume.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a5da4c353a1df17341c1e745796e00a4ec1afd21', 'message': 'LVM: Pass volume size in MiB to copy_volume() during volume migration\n\nCurrently migrate_volume() in lvm.py does not pass volume size in\nMiB but passes volume size in GiB to copy_volume(). The size argument\nof copy_volume() requires MiB value. As a result, if the volume size\nis 1GiB, copy_volume() copies only 1MiB head of 1GiB volume to the\ndestination volume, and then the volume data is corrupted.\nThis patch fixes to pass volume size in MiB.\n\nCloses-bug: #1454835\nChange-Id: I8e06195dc3625ef07bc9858d844541e37a231b73\n'}]",3,182832,a5da4c353a1df17341c1e745796e00a4ec1afd21,28,22,1,10115,,,0,"LVM: Pass volume size in MiB to copy_volume() during volume migration

Currently migrate_volume() in lvm.py does not pass volume size in
MiB but passes volume size in GiB to copy_volume(). The size argument
of copy_volume() requires MiB value. As a result, if the volume size
is 1GiB, copy_volume() copies only 1MiB head of 1GiB volume to the
destination volume, and then the volume data is corrupted.
This patch fixes to pass volume size in MiB.

Closes-bug: #1454835
Change-Id: I8e06195dc3625ef07bc9858d844541e37a231b73
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/182832/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_volume.py', 'cinder/volume/drivers/lvm.py']",2,a5da4c353a1df17341c1e745796e00a4ec1afd21,bug/1454835," # copy_volume expects sizes in MiB, we store integer GiB # be sure to convert before passing in size_in_mb = int(volume['size']) * units.Ki size_in_mb,"," volume['size'],",27,29
openstack%2Fheat~master~I162248ba4993ca5e55c8d8f015c8252c08cc9b8c,openstack/heat,master,I162248ba4993ca5e55c8d8f015c8252c08cc9b8c,Add network uuid to server networks attribute,MERGED,2015-04-08 09:31:55.000000000,2015-05-27 04:34:04.000000000,2015-05-27 04:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8833}, {'_account_id': 12606}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-04-08 09:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5d386e82df89c2c4ae207b74fb1f39f878e51b9', 'message': 'Add network uuid to server networks attribute\n\nThis patch will change server networks attribute to return both\nnetwork name and network id, so that we can use\n{get_attr: [server, networks, {get_param: net_uuid}, 0]} to get\nserver IP.\n\nCloses-Bug: #1441480\nChange-Id: I162248ba4993ca5e55c8d8f015c8252c08cc9b8c\n'}, {'number': 2, 'created': '2015-05-12 05:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b9313084b61637f1218df07483608f5058f59202', 'message': 'Add network uuid to server networks attribute\n\nThis patch will change server networks attribute to return both\nnetwork name and network id, so that we can use\n{get_attr: [server, networks, {get_param: net_uuid}, 0]} to get\nserver IP.\n\nCloses-Bug: #1441480\nChange-Id: I162248ba4993ca5e55c8d8f015c8252c08cc9b8c\n'}, {'number': 3, 'created': '2015-05-12 05:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48e9a8dc3c11bcd0e74571074081b8c546b498d3', 'message': 'Add network uuid to server networks attribute\n\nThis patch will change server networks attribute to return both\nnetwork name and network id, so that we can use\n{get_attr: [server, networks, {get_param: net_uuid}, 0]} to get\nserver IP.\n\nCloses-Bug: #1441480\nChange-Id: I162248ba4993ca5e55c8d8f015c8252c08cc9b8c\n'}, {'number': 4, 'created': '2015-05-13 09:29:33.000000000', 'files': ['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/63fb9dba7690d0b30f6a3bc60be63849100519e1', 'message': 'Add network uuid to server networks attribute\n\nThis patch will change server networks attribute to return both\nnetwork name and network id, so that we can use\n{get_attr: [server, networks, {get_param: net_uuid}, 0]} to get\nserver IP.\n\nCloses-Bug: #1441480\nChange-Id: I162248ba4993ca5e55c8d8f015c8252c08cc9b8c\n'}]",6,171534,63fb9dba7690d0b30f6a3bc60be63849100519e1,33,10,4,7404,,,0,"Add network uuid to server networks attribute

This patch will change server networks attribute to return both
network name and network id, so that we can use
{get_attr: [server, networks, {get_param: net_uuid}, 0]} to get
server IP.

Closes-Bug: #1441480
Change-Id: I162248ba4993ca5e55c8d8f015c8252c08cc9b8c
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/171534/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py']",2,f5d386e82df89c2c4ae207b74fb1f39f878e51b9,bug/1441480," def test_resolve_attribute_networks(self): return_server = self.fc.servers.list()[1] server = self._create_test_server(return_server, 'srv_resolve_attr') server.resource_id = '1234' server.networks = {""fake_net"": [""10.0.0.3""]} self.m.StubOutWithMock(self.fc.servers, 'get') self.fc.servers.get(server.resource_id).AndReturn(server) self.m.StubOutWithMock(nova.NovaClientPlugin, 'get_net_id_by_label') nova.NovaClientPlugin.get_net_id_by_label( 'fake_net').AndReturn('fake_uuid') self.m.ReplayAll() expect_networks = {""fake_uuid"": [""10.0.0.3""], ""fake_net"": [""10.0.0.3""]} self.assertEqual(expect_networks, server._resolve_attribute(""networks"")) self.m.VerifyAll() ",,32,1
openstack%2Fmanila~master~Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d,openstack/manila,master,Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d,Add share extend API,MERGED,2015-05-12 16:20:53.000000000,2015-05-27 04:32:36.000000000,2015-05-27 04:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-12 16:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7c15facc3e92824d712183e0fd504c9722bd0ddb', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}, {'number': 2, 'created': '2015-05-15 08:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/366b2ff2cacd1abe9b02495fd89f4497bf38ddf3', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}, {'number': 3, 'created': '2015-05-15 12:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/355a1c888d622d20ecf2c65ef8a27e3dd2906a8b', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}, {'number': 4, 'created': '2015-05-15 13:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6b6c7736a3c589296a9959d2edb0e5160999456f', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}, {'number': 5, 'created': '2015-05-15 15:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/41928a6daa9333b94afc8a58e7e87199fe2a654b', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}, {'number': 6, 'created': '2015-05-18 14:23:15.000000000', 'files': ['manila/api/contrib/share_actions.py', 'manila/share/driver.py', 'manila/tests/share/test_rpcapi.py', 'manila/share/rpcapi.py', 'manila/tests/share/test_api.py', 'etc/manila/policy.json', 'manila/share/api.py', 'manila/tests/api/contrib/test_share_actions.py', 'manila/share/manager.py', 'manila/tests/policy.json', 'manila/common/constants.py', 'manila/exception.py', 'manila/tests/share/test_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f67bcf81ae3ee43733481d547fb46d3c54efca87', 'message': 'Add share extend API\n\nImplement API for extending shares similar to Cinder:\n""manila extend <share-id> <new-size>""\n\n- Implement tenant-facing API for extending shares\n- Add appropriate unit tests\n\nPartially implements bp share-extend-api\n\nChange-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d\n'}]",21,182377,f67bcf81ae3ee43733481d547fb46d3c54efca87,34,9,6,14232,,,0,"Add share extend API

Implement API for extending shares similar to Cinder:
""manila extend <share-id> <new-size>""

- Implement tenant-facing API for extending shares
- Add appropriate unit tests

Partially implements bp share-extend-api

Change-Id: Ic63ecb1c2881ac9c8b59010efe3a37413f18f28d
",git fetch https://review.opendev.org/openstack/manila refs/changes/77/182377/6 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/contrib/share_actions.py', 'manila/share/driver.py', 'manila/tests/share/test_rpcapi.py', 'manila/share/rpcapi.py', 'manila/tests/share/test_api.py', 'etc/manila/policy.json', 'manila/share/api.py', 'manila/tests/api/contrib/test_share_actions.py', 'manila/share/manager.py', 'manila/common/constants.py', 'manila/exception.py', 'manila/tests/share/test_manager.py']",12,7c15facc3e92824d712183e0fd504c9722bd0ddb,bp/share-extend-api," def test_extend_share_invalid(self): share = self._create_share() share_id = share['id'] self.mock_object(self.share_manager, 'driver') self.mock_object(self.share_manager.db, 'share_update') self.mock_object(quota.QUOTAS, 'rollback') self.mock_object(self.share_manager.driver, 'extend_share', mock.Mock(side_effect=Exception('fake'))) self.assertRaises( exception.ShareExtendingDriverError, self.share_manager.extend_share, self.context, share_id, 123, {}) def test_extend_share(self): share = self._create_share() share_id = share['id'] new_size = 123 shr_update = { 'size': int(new_size), 'status': constants.STATUS_AVAILABLE.lower() } reservations = {} fake_share_server = 'fake' manager = self.share_manager self.mock_object(manager, 'driver') self.mock_object(manager.db, 'share_get', mock.Mock(return_value=share)) self.mock_object(manager.db, 'share_update', mock.Mock(return_value=share)) self.mock_object(quota.QUOTAS, 'commit') self.mock_object(manager.driver, 'extend_share') self.mock_object(manager, '_get_share_server', mock.Mock(return_value=fake_share_server)) self.share_manager.extend_share(self.context, share_id, new_size, reservations) self.assertTrue(manager._get_share_server.called) manager.driver.extend_share.assert_called_once_with( share, new_size, fake_share_server ) quota.QUOTAS.commit.assert_called_once_with(mock.ANY, reservations) manager.db.share_update.assert_called_once_with( mock.ANY, share_id, shr_update )",,269,2
openstack%2Fkolla~master~Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f,openstack/kolla,master,Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f,Remove unnecessary dependencies,MERGED,2015-05-22 21:46:21.000000000,2015-05-27 04:28:11.000000000,2015-05-27 04:28:10.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 13039}]","[{'number': 1, 'created': '2015-05-22 21:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/924ea2b67efdba1761200498bd7e497b68a54e23', 'message': 'Remove unnecessary dependencies\n\nGlance RPM has been confirmed to depend on python-oslo-log and\npython-oslo-policy, so remove explicit package installs.\n\nChange-Id: Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f\n'}, {'number': 2, 'created': '2015-05-22 21:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a959a21d372b957bda57b3b42150ad2d71598bf1', 'message': 'Remove unnecessary dependencies\n\nGlance RPM has been confirmed to depend on python-oslo-log and\npython-oslo-policy, so remove explicit package installs.\n\nChange-Id: Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f\n'}, {'number': 3, 'created': '2015-05-26 21:26:10.000000000', 'files': ['docker/centos/binary/glance/glance-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/314b6d4c3ccf769aa7699583b8f8c86f09e6766b', 'message': 'Remove unnecessary dependencies\n\nGlance RPM has been confirmed to depend on python-oslo-log and\npython-oslo-policy, so remove explicit package installs.\n\nChange-Id: Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f\n'}]",0,185157,314b6d4c3ccf769aa7699583b8f8c86f09e6766b,13,4,3,3098,,,0,"Remove unnecessary dependencies

Glance RPM has been confirmed to depend on python-oslo-log and
python-oslo-policy, so remove explicit package installs.

Change-Id: Ia390b4ff1b57a079032e1f3fb2403b9fb78f038f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/57/185157/3 && git format-patch -1 --stdout FETCH_HEAD,['docker/glance/glance-base/Dockerfile'],1,924ea2b67efdba1761200498bd7e497b68a54e23,quickfix,RUN yum -y install openstack-glance && yum clean all,# We really shouldn't need to install python-oslo-log or python-oslo-policy # See: https://bugzilla.redhat.com/show_bug.cgi?id=1218349 RUN yum -y install openstack-glance python-oslo-log python-oslo-policy && yum clean all,1,3
openstack%2Fpython-ironicclient~master~I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e,openstack/python-ironicclient,master,I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e,Disable meaningless sort keys in list command,MERGED,2015-04-26 03:37:48.000000000,2015-05-27 04:09:17.000000000,2015-05-27 04:09:15.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 13360}, {'_account_id': 14228}, {'_account_id': 14760}, {'_account_id': 14810}]","[{'number': 1, 'created': '2015-04-26 03:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/cbab8af8646257372f1edecb59ca272a3b173f8e', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nCloses-Bug: #1446146\n""}, {'number': 2, 'created': '2015-05-06 13:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/0dfa6b09294802b0f8bacc1afeb5be3250765869', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nCloses-Bug: #1446146\n""}, {'number': 3, 'created': '2015-05-06 15:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/fc217a340119e8dc609dddbee144fa92934bc201', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nCloses-Bug: #1446146\n""}, {'number': 4, 'created': '2015-05-06 15:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/48b011abf08e49e1324e6b7047d7ccda7cd1636d', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nCloses-Bug: #1446146\n""}, {'number': 5, 'created': '2015-05-07 16:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/d9abefe00ec9dc014e8bfa0e191b20b3f293e5e2', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nCloses-Bug: #1446146\n""}, {'number': 6, 'created': '2015-05-13 03:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/0f039a80ddafea61e8499b9e47a51199920b24f6', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nPartial-Bug: #1446146\n""}, {'number': 7, 'created': '2015-05-13 03:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/d910abe5b85f642aa0732ff2330ae3845d64d677', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nPartial-Bug: #1446146\n""}, {'number': 8, 'created': '2015-05-13 07:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/062485541e9fca0a06860cd11606652e25a44b3c', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nPartial-Bug: #1446146\n""}, {'number': 9, 'created': '2015-05-22 14:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f9f6afa244c325c5dc995a123f15fe906a7b4377', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nDepends-On: I340c88ea7d098ca5943d60adc73f63a0af79a405\nPartial-Bug: #1446146\n""}, {'number': 10, 'created': '2015-05-27 02:12:58.000000000', 'files': ['ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_chassis_shell.py', 'ironicclient/v1/chassis_shell.py', 'ironicclient/v1/port_shell.py', 'ironicclient/v1/resource_fields.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/6e8d76168876d3e1110c9dbae557e22e18fd8d47', 'message': ""Disable meaningless sort keys in list command\n\nThe sort keys are:\nFor ports: 'extra'\nFor chassis: 'extra'\nFor nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info\n\nChange-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e\nDepends-On: I340c88ea7d098ca5943d60adc73f63a0af79a405\nCloses-Bug: #1446146\n""}]",21,177578,6e8d76168876d3e1110c9dbae557e22e18fd8d47,69,9,10,14810,,,0,"Disable meaningless sort keys in list command

The sort keys are:
For ports: 'extra'
For chassis: 'extra'
For nodes: 'properties', 'driver_info', 'extra', 'instance_info', 'driver_internal_info

Change-Id: I6b9fce16893335b7e4fb0b663b21f2dff2cdbe8e
Depends-On: I340c88ea7d098ca5943d60adc73f63a0af79a405
Closes-Bug: #1446146
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/78/177578/10 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node_shell.py', 'ironicclient/v1/chassis_shell.py', 'ironicclient/v1/port_shell.py', 'ironicclient/v1/resource_fields.py']",4,cbab8af8646257372f1edecb59ca272a3b173f8e,bug1446146,"CHASSIS_SORT_FIELDS = ['uuid', 'description', 'created_at', 'updated_at'] CHASSIS_SORT_FIELD_LABELS = ['UUID', 'Description', 'Created At', 'Updated At'] NODE_SORT_FIELDS = ['chassis_uuid', 'created_at', 'console_enabled', 'driver', 'instance_uuid', 'last_error', 'maintenance', 'maintenance_reason', 'power_state', 'provision_state', 'reservation', 'target_power_state', 'target_provision_state', 'updated_at', 'inspection_finished_at', 'inspection_started_at', 'uuid', 'name'] NODE_SORT_FIELD_LABELS = ['Chassis UUID', 'Created At', 'Console Enabled', 'Driver', 'Instance UUID', 'Last Error', 'Maintenance', 'Maintenance Reason', 'Power State', 'Provision State', 'Reservation', 'Target Power State', 'Target Provision State', 'Updated At', 'Inspection Finished At', 'Inspection Started At', 'UUID', 'Name'] PORT_SORT_FIELDS = ['uuid', 'address', 'created_at', 'node_uuid', 'updated_at'] PORT_SORT_FIELD_LABELS = ['UUID', 'Address', 'Created At', 'Node UUID', 'Updated At'] ",,31,6
openstack%2Fopenstack-manuals~master~I1371abcf63a6a4107d48b2c2a402fa56eab674c3,openstack/openstack-manuals,master,I1371abcf63a6a4107d48b2c2a402fa56eab674c3,Add Japanese draft documents to draft web page,MERGED,2015-05-26 22:13:28.000000000,2015-05-27 04:03:52.000000000,2015-05-27 04:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-05-26 22:13:28.000000000', 'files': ['www/draft/draft-index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c8148b7563b17de466cb4995265c5a8b7367f35e', 'message': 'Add Japanese draft documents to draft web page\n\nChange-Id: I1371abcf63a6a4107d48b2c2a402fa56eab674c3\n'}]",0,185758,c8148b7563b17de466cb4995265c5a8b7367f35e,8,4,1,10497,,,0,"Add Japanese draft documents to draft web page

Change-Id: I1371abcf63a6a4107d48b2c2a402fa56eab674c3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/185758/1 && git format-patch -1 --stdout FETCH_HEAD,['www/draft/draft-index.html'],1,c8148b7563b17de466cb4995265c5a8b7367f35e,www-draft," <a href=""/draft/ja/user-guide/"">End User Guide (includes Python SDK)</a> <a href=""/draft/ja/user-guide-admin/"">Admin User Guide</a>",,2,0
openstack%2Fnova~stable%2Ficehouse~I0bf7535ae3f7d9e6820f8dc07075892953d80a78,openstack/nova,stable/icehouse,I0bf7535ae3f7d9e6820f8dc07075892953d80a78,XenAPI improve post snapshot coalesce detection,ABANDONED,2014-12-19 15:14:31.000000000,2015-05-27 03:58:37.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 6735}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 15286}]","[{'number': 1, 'created': '2014-12-19 15:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c16b9257e5ec2786021eb7d2630576568e140ae6', 'message': ""XenAPI improve post snapshot coalesce detection\n\nThe coalesce detection is not working well after this change:\nae2a27ce19f3e24d4a8c713a73e617f4cd71d4b4\n\nThe snapshot operation will introduce a new VHD file into the VDI chain,\nand in many cases, that would be coalesced during the next SR scan. So\nwe need to walk the chain after the snapshot has been taken, not before.\n\nThis fixes the cause of the mentioned bug, but it doesn't help with\nlaunching the partially corrupted snapshots created because of this bug,\nso this only partially fixes the bug.\n\nChange-Id: I0bf7535ae3f7d9e6820f8dc07075892953d80a78\nPartial-Bug: #1362595\n""}, {'number': 2, 'created': '2014-12-21 21:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30c4d447fbbc999306f37670e2b072c44b48a65b', 'message': 'XenAPI improve post snapshot coalesce detection\n\nThe snapshot operation will introduce a new VHD file into the VDI chain,\nand in many cases, that would be coalesced during the next SR scan. So\nwe need to walk the chain after the snapshot has been taken, not before.\n\nCoalescing in Icehouse was unstable and the cause of many\nfailures.  These backported changes are needed to fix the\ncoalescing functionality and ensure stability when using XenAPI\n\nChange-Id: I0bf7535ae3f7d9e6820f8dc07075892953d80a78\nPartial-Bug: #1362595\n'}, {'number': 3, 'created': '2015-01-26 11:28:03.000000000', 'files': ['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/776408c004094eb37fe7a4e70734ebfc1d6917e4', 'message': 'XenAPI improve post snapshot coalesce detection\n\n(Cherry picked from commit 48b6af716994a8a60ddaacacd090df0ca528c4b1)\n\nThe snapshot operation will introduce a new VHD file into the VDI chain,\nand in many cases, that would be coalesced during the next SR scan. So\nwe need to walk the chain after the snapshot has been taken, not before.\n\nCoalescing in Icehouse was unstable and the cause of many\nfailures.  These backported changes are needed to fix the\ncoalescing functionality and ensure stability when using XenAPI\n\nChange-Id: I0bf7535ae3f7d9e6820f8dc07075892953d80a78\nPartial-Bug: #1362595\n'}]",7,143110,776408c004094eb37fe7a4e70734ebfc1d6917e4,31,11,3,6735,,,0,"XenAPI improve post snapshot coalesce detection

(Cherry picked from commit 48b6af716994a8a60ddaacacd090df0ca528c4b1)

The snapshot operation will introduce a new VHD file into the VDI chain,
and in many cases, that would be coalesced during the next SR scan. So
we need to walk the chain after the snapshot has been taken, not before.

Coalescing in Icehouse was unstable and the cause of many
failures.  These backported changes are needed to fix the
coalescing functionality and ensure stability when using XenAPI

Change-Id: I0bf7535ae3f7d9e6820f8dc07075892953d80a78
Partial-Bug: #1362595
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/143110/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,c16b9257e5ec2786021eb7d2630576568e140ae6,bug/1362595," def test_wait_for_vhd_coalesce_leaf_node(self, mock_sleep): instance = {""uuid"": ""fake""} vm_utils._wait_for_vhd_coalesce(""session"", instance, ""sr_ref"", ""vdi_ref"", [""uuid""]) self.assertFalse(mock_sleep.called) @mock.patch.object(vm_utils, '_count_children') @mock.patch.object(greenthread, 'sleep') def test_wait_for_vhd_coalesce_parent_snapshot(self, mock_sleep, mock_count): mock_count.return_value = 2 instance = {""uuid"": ""fake""} vm_utils._wait_for_vhd_coalesce(""session"", instance, ""sr_ref"", ""vdi_ref"", [""uuid1"", ""uuid2""]) self.assertFalse(mock_sleep.called) self.assertTrue(mock_count.called) @mock.patch.object(vm_utils, '_count_children') def test_wait_for_vhd_coalesce_raises(self, mock_scan_sr, mock_count, mock_get_vhd_parent_uuid, mock_sleep): mock_count.return_value = 1 instance = {""uuid"": ""fake""} self.assertRaises(exception.NovaException, vm_utils._wait_for_vhd_coalesce, ""session"", instance, ""sr_ref"", ""vdi_ref"", [""uuid1"", ""uuid2""]) self.assertTrue(mock_count.called) self.assertEqual(20, mock_sleep.call_count) self.assertEqual(20, mock_scan_sr.call_count) @mock.patch.object(greenthread, 'sleep') @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') @mock.patch.object(vm_utils, '_count_children') @mock.patch.object(vm_utils, '_scan_sr') def test_wait_for_vhd_coalesce_success(self, mock_scan_sr, mock_count, mock_get_vhd_parent_uuid, mock_sleep): mock_count.return_value = 1 instance = {""uuid"": ""fake""} mock_get_vhd_parent_uuid.side_effect = [""bad"", ""uuid2""] vm_utils._wait_for_vhd_coalesce(""session"", instance, ""sr_ref"", ""vdi_ref"", [""uuid1"", ""uuid2""]) self.assertEqual(1, mock_sleep.call_count) self.assertEqual(2, mock_scan_sr.call_count) def test_count_children(self, mock_get_all_vdis_in_sr): self.assertEqual(2, vm_utils._count_children('session', 'parent1', 'sr'))"," @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') @mock.patch.object(vm_utils, '_count_parents_children') @mock.patch.object(vm_utils, '_scan_sr') def test_wait_for_vhd_coalesce(self, mock_scan_sr, mock_count_parents_children, mock_get_vhd_parent_uuid, mock_sleep): cfg.CONF.import_opt('vhd_coalesce_max_attempts', 'nova.virt.xenapi.driver', group=""xenserver"") max_sr_scan_count = cfg.CONF.xenserver.vhd_coalesce_max_attempts - 1 vhd_chain = ['vdi_base_ref', 'vdi_coalescable_ref', 'vdi_leaf_ref'] instance = {""uuid"": ""uuid""} sr_ref = 'sr_ref' session = mock.Mock() def fake_scan_sr(session, sr_ref): fake_scan_sr.count += 1 if fake_scan_sr.count == max_sr_scan_count: vhd_chain.remove('vdi_coalescable_ref') def fake_get_vhd_parent_uuid(session, vdi_ref): index = vhd_chain.index(vdi_ref) if index > 0: return vhd_chain[index - 1].replace('ref', 'uuid') return None def fake_call_xenapi(method, *args): if method == 'VDI.get_by_uuid': return args[0].replace('uuid', 'ref') fake_scan_sr.count = 0 fake_scan_sr.running = True mock_scan_sr.side_effect = fake_scan_sr session.call_xenapi.side_effect = fake_call_xenapi mock_get_vhd_parent_uuid.side_effect = fake_get_vhd_parent_uuid mock_count_parents_children.return_value = 1 vm_utils._wait_for_vhd_coalesce(session, instance, sr_ref, 'vdi_leaf_ref', ['vdi_base_uuid']) self.assertEqual(max_sr_scan_count, mock_scan_sr.call_count) session.call_plugin_serialized.has_calls(session, ""vdi_ref"") # We'll sleep one fewer times than we scan the SR due to # the scan at the start self.assertEqual(max_sr_scan_count - 1, mock_sleep.call_count) @mock.patch.object(vm_utils, '_count_parents_children') def test_wait_for_vhd_coalesce_1317792(self, mock_scan_sr, mock_count_parents_children, mock_get_vhd_parent_uuid, mock_sleep): cfg.CONF.import_opt('vhd_coalesce_max_attempts', 'nova.virt.xenapi.driver', group=""xenserver"") vhd_chain = ['vdi_base_ref', 'vdi_coalescable_ref1', 'vdi_coalescable_ref2', 'vdi_leaf_ref'] instance = {""uuid"": ""uuid""} sr_ref = 'sr_ref' session = mock.Mock() def fake_scan_sr(session, sr_ref): fake_scan_sr.count += 1 if fake_scan_sr.count == 1: vhd_chain.remove('vdi_coalescable_ref1') elif fake_scan_sr.count == 2: vhd_chain.remove('vdi_coalescable_ref2') def fake_get_vhd_parent_uuid(session, vdi_ref): index = vhd_chain.index(vdi_ref) if index > 0: return vhd_chain[index - 1].replace('ref', 'uuid') return None def fake_call_xenapi(method, *args): if method == 'VDI.get_by_uuid': return args[0].replace('uuid', 'ref') fake_scan_sr.count = 0 fake_scan_sr.running = True mock_scan_sr.side_effect = fake_scan_sr session.call_xenapi.side_effect = fake_call_xenapi mock_get_vhd_parent_uuid.side_effect = fake_get_vhd_parent_uuid mock_count_parents_children.return_value = 1 vm_utils._wait_for_vhd_coalesce( session, instance, sr_ref, 'vdi_leaf_ref', ['vdi_base_uuid', 'vdi_coalescable_uuid1']) session.call_plugin_serialized.has_calls(session, ""vdi_ref"") @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') def test_count_parents_children(self, mock_get_parent_uuid, mock_get_all_vdis_in_sr): mock_get_parent_uuid.return_value = 'parent1' self.assertEqual(2, vm_utils._count_parents_children('session', 'child3', 'sr'))",74,103
openstack%2Fnova~stable%2Ficehouse~I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf,openstack/nova,stable/icehouse,I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf,XenAPI: Tolerate multiple coalesces,ABANDONED,2014-12-19 15:14:31.000000000,2015-05-27 03:58:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-19 15:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41f5639669556db167db486d46d95fddadfec6a7', 'message': ""XenAPI: Tolerate multiple coalesces\n\nVHD coalescing might coalesce more than one VDI while waiting\nand might coalesce the 'grandparent' before the parent.  Wait\nfor the parent to be any of the original tree instead of just\nthe original parent.\n\nCloses bug: 1317792\n\nChange-Id: I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf\n""}, {'number': 2, 'created': '2014-12-21 21:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/750cf0b40aad53a905481190441e2c7e85e79f0e', 'message': ""XenAPI: Tolerate multiple coalesces\n\nVHD coalescing might coalesce more than one VDI while waiting\nand might coalesce the 'grandparent' before the parent.  Wait\nfor the parent to be any of the original tree instead of just\nthe original parent.\n\nCoalescing in Icehouse was unstable and the cause of many\nfailures.  These backported changes are needed to fix the\ncoalescing functionality and ensure stability when using XenAPI\n\nCloses bug: 1317792\n\nChange-Id: I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf\n""}, {'number': 3, 'created': '2015-01-26 11:28:03.000000000', 'files': ['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/478ad985e2c717e04e6a7a5fd981c8333be9fbc3', 'message': ""XenAPI: Tolerate multiple coalesces\n\n(Cherry picked from commit ae2a27ce19f3e24d4a8c713a73e617f4cd71d4b4)\n\nVHD coalescing might coalesce more than one VDI while waiting\nand might coalesce the 'grandparent' before the parent.  Wait\nfor the parent to be any of the original tree instead of just\nthe original parent.\n\nCoalescing in Icehouse was unstable and the cause of many\nfailures.  These backported changes are needed to fix the\ncoalescing functionality and ensure stability when using XenAPI\n\nCloses bug: 1317792\n\nChange-Id: I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf\n""}]",0,143109,478ad985e2c717e04e6a7a5fd981c8333be9fbc3,21,7,3,6735,,,0,"XenAPI: Tolerate multiple coalesces

(Cherry picked from commit ae2a27ce19f3e24d4a8c713a73e617f4cd71d4b4)

VHD coalescing might coalesce more than one VDI while waiting
and might coalesce the 'grandparent' before the parent.  Wait
for the parent to be any of the original tree instead of just
the original parent.

Coalescing in Icehouse was unstable and the cause of many
failures.  These backported changes are needed to fix the
coalescing functionality and ensure stability when using XenAPI

Closes bug: 1317792

Change-Id: I82c4db0e8a36c41a86adf4bd32304a4bfdabebbf
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/143109/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,41f5639669556db167db486d46d95fddadfec6a7,bug/1362595," mock_vdi_snapshot, mock_vdi_get_uuid, {""SR"": ""sr_ref"", ""uuid"": ""vdi_uuid""}) ""sr_ref"", ""vdi_ref"", ['a', 'b']) mock_walk_vdi_chain.assert_has_calls([mock.call(session, ""vdi_uuid""), mock.call(session, ""snap_uuid"")]) @mock.patch.object(vm_utils, '_count_parents_children') def test_wait_for_vhd_coalesce(self, mock_scan_sr, mock_count_parents_children, mock_get_vhd_parent_uuid, mock_sleep): mock_count_parents_children.return_value = 1 vm_utils._wait_for_vhd_coalesce(session, instance, sr_ref, 'vdi_leaf_ref', ['vdi_base_uuid']) @mock.patch.object(greenthread, 'sleep') @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') @mock.patch.object(vm_utils, '_count_parents_children') @mock.patch.object(vm_utils, '_scan_sr') def test_wait_for_vhd_coalesce_1317792(self, mock_scan_sr, mock_count_parents_children, mock_get_vhd_parent_uuid, mock_sleep): cfg.CONF.import_opt('vhd_coalesce_max_attempts', 'nova.virt.xenapi.driver', group=""xenserver"") vhd_chain = ['vdi_base_ref', 'vdi_coalescable_ref1', 'vdi_coalescable_ref2', 'vdi_leaf_ref'] instance = {""uuid"": ""uuid""} sr_ref = 'sr_ref' session = mock.Mock() def fake_scan_sr(session, sr_ref): fake_scan_sr.count += 1 if fake_scan_sr.count == 1: vhd_chain.remove('vdi_coalescable_ref1') elif fake_scan_sr.count == 2: vhd_chain.remove('vdi_coalescable_ref2') def fake_get_vhd_parent_uuid(session, vdi_ref): index = vhd_chain.index(vdi_ref) if index > 0: return vhd_chain[index - 1].replace('ref', 'uuid') return None def fake_call_xenapi(method, *args): if method == 'VDI.get_by_uuid': return args[0].replace('uuid', 'ref') fake_scan_sr.count = 0 fake_scan_sr.running = True mock_scan_sr.side_effect = fake_scan_sr session.call_xenapi.side_effect = fake_call_xenapi mock_get_vhd_parent_uuid.side_effect = fake_get_vhd_parent_uuid mock_count_parents_children.return_value = 1 vm_utils._wait_for_vhd_coalesce( session, instance, sr_ref, 'vdi_leaf_ref', ['vdi_base_uuid', 'vdi_coalescable_uuid1']) session.call_plugin_serialized.has_calls(session, ""vdi_ref"") @mock.patch.object(vm_utils, '_get_all_vdis_in_sr') @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') def test_count_parents_children(self, mock_get_parent_uuid, mock_get_all_vdis_in_sr): mock_get_parent_uuid.return_value = 'parent1' vdis = [('child1', {'sm_config': {'vhd-parent': 'parent1'}}), ('child2', {'sm_config': {'vhd-parent': 'parent2'}}), ('child3', {'sm_config': {'vhd-parent': 'parent1'}})] mock_get_all_vdis_in_sr.return_value = vdis self.assertEqual(2, vm_utils._count_parents_children('session', 'child3', 'sr')) "," @mock.patch.object(vm_utils, '_get_vhd_parent_uuid') mock_get_vhd_parent_uuid, mock_vdi_snapshot, mock_vdi_get_uuid, {""SR"": ""sr_ref""}) mock_get_vhd_parent_uuid.return_value = ""original_uuid"" mock_get_vhd_parent_uuid.assert_called_once_with(session, ""vdi_ref"") ""sr_ref"", ""vdi_ref"", ""original_uuid"") mock_walk_vdi_chain.assert_called_once_with(session, ""snap_uuid"") @mock.patch.object(vm_utils, '_another_child_vhd') def test_wait_for_vhd_coalesce(self, mock_scan_sr, mock_another_child_vhd, mock_get_vhd_parent_uuid, mock_sleep): mock_another_child_vhd.return_value = False self.assertEqual(('vdi_base_uuid', None), vm_utils._wait_for_vhd_coalesce(session, instance, sr_ref, 'vdi_leaf_ref', 'vdi_base_uuid'))",105,54
openstack%2Fcinder~master~I743f823ca38529b12301a89308d1d406aa3fa45f,openstack/cinder,master,I743f823ca38529b12301a89308d1d406aa3fa45f,"LVM: Support efficient data copy using ""dd"" for create_cloned_volume",MERGED,2015-05-12 22:01:32.000000000,2015-05-27 03:46:25.000000000,2015-05-14 04:12:26.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9176}, {'_account_id': 10058}, {'_account_id': 10115}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14969}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16160}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-12 22:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/36df4a3bc308ce521abc1a042ddffe725c1d06e1', 'message': 'LVM: Support efficient data copy using ""dd"" for create_cloned_volume\n\nThe create_cloned_volume uses dd command for data copy, but the\ncopy always copy full blocks even if the source data contains\nmany null or zero blocks. When we use thin provisioned LVM,\nblocks are not pre-allocated, so unused region returns zero.\nIf we copy full block for destination volume, unnecessary blocks\nwill be allocated and the usage will be 100%.\n\nThe dd command has conv=sparse option in order to copy data more\nefficiently. This patch enables conv=sparse option as an argument\nof dd command for create_cloned_volume when we use thin provisioned\nLVM.\n\n[NOTE]\nThis option can be applied if the destination volume is ensured\nto be zero cleared beforehand to avoid security issue.\n\nHere are some results for this option.\n\n- Without conv=sparse option\n  LV            VG    Attr       LSize   Pool     Origin Data%\n  vg1-pool      vg1   twi-a-tz--   3.80g                  31.45\n  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool        100.00\n  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n\n- With conv=sparse option\n  LV            VG    Attr       LSize   Pool     Origin Data%\n  vg1-pool      vg1   twi-a-tz--   3.80g                  10.28\n  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n\nChange-Id: I743f823ca38529b12301a89308d1d406aa3fa45f\nCloses-bug: #1224671\n'}, {'number': 2, 'created': '2015-05-13 18:30:31.000000000', 'files': ['cinder/volume/utils.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e4a54d41ca8801f35d9988d0b8742bf354df049', 'message': 'LVM: Support efficient data copy using ""dd"" for create_cloned_volume\n\nThe create_cloned_volume uses dd command for data copy, but the\ncopy always copy full blocks even if the source data contains\nmany null or zero blocks. When we use thin provisioned LVM,\nblocks are not pre-allocated, so unused region returns zero.\nIf we copy full block for destination volume, unnecessary blocks\nwill be allocated and the usage will be 100%.\n\nThe dd command has conv=sparse option in order to copy data more\nefficiently. This patch enables conv=sparse option as an argument\nof dd command for create_cloned_volume when we use thin provisioned\nLVM.\n\n[NOTE]\nThis patch only enables conv=sparse parameter of dd command for\ncreate_cloned_volume() path of LVM driver. There are some places\nusing dd in Cinder, but we should carefully consider to apply\nthis parameter for other places because misuse of this parameter\ncauses security issues or data corruptions. Also we DO NOT use this\nparameter for volume wiping case because the volume is not cleared\nat all.\n\nHere are some results for this option.\n\n- Without conv=sparse option\n  LV            VG    Attr       LSize   Pool     Origin Data%\n  vg1-pool      vg1   twi-a-tz--   3.80g                  31.45\n  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool        100.00\n  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n\n- With conv=sparse option\n  LV            VG    Attr       LSize   Pool     Origin Data%\n  vg1-pool      vg1   twi-a-tz--   3.80g                  10.28\n  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53\n\nChange-Id: I743f823ca38529b12301a89308d1d406aa3fa45f\nCloses-bug: #1224671\n'}]",8,182473,4e4a54d41ca8801f35d9988d0b8742bf354df049,77,31,2,10115,,,0,"LVM: Support efficient data copy using ""dd"" for create_cloned_volume

The create_cloned_volume uses dd command for data copy, but the
copy always copy full blocks even if the source data contains
many null or zero blocks. When we use thin provisioned LVM,
blocks are not pre-allocated, so unused region returns zero.
If we copy full block for destination volume, unnecessary blocks
will be allocated and the usage will be 100%.

The dd command has conv=sparse option in order to copy data more
efficiently. This patch enables conv=sparse option as an argument
of dd command for create_cloned_volume when we use thin provisioned
LVM.

[NOTE]
This patch only enables conv=sparse parameter of dd command for
create_cloned_volume() path of LVM driver. There are some places
using dd in Cinder, but we should carefully consider to apply
this parameter for other places because misuse of this parameter
causes security issues or data corruptions. Also we DO NOT use this
parameter for volume wiping case because the volume is not cleared
at all.

Here are some results for this option.

- Without conv=sparse option
  LV            VG    Attr       LSize   Pool     Origin Data%
  vg1-pool      vg1   twi-a-tz--   3.80g                  31.45
  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool        100.00
  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53

- With conv=sparse option
  LV            VG    Attr       LSize   Pool     Origin Data%
  vg1-pool      vg1   twi-a-tz--   3.80g                  10.28
  volume-clone  vg1   Vwi-a-tz--   1.00g vg1-pool         19.53
  volume-source vg1   Vwi-a-tz--   1.00g vg1-pool         19.53

Change-Id: I743f823ca38529b12301a89308d1d406aa3fa45f
Closes-bug: #1224671
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/182473/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/utils.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/volume/drivers/lvm.py']",3,36df4a3bc308ce521abc1a042ddffe725c1d06e1,bug/1224671," sparse = True if self.configuration.lvm_type == 'thin' else False execute=self._execute, sparse=sparse)", execute=self._execute),47,5
openstack%2Fos-cloud-config~master~I7e82584f75a309c4cea6fb3f7c0c420358c778e1,openstack/os-cloud-config,master,I7e82584f75a309c4cea6fb3f7c0c420358c778e1,Shift EnvironmentVariable fixture setup to base,MERGED,2015-02-11 05:33:22.000000000,2015-05-27 03:24:52.000000000,2015-05-27 03:24:49.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-02-11 05:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/a4abe85142acd696d596586860ba0bceef8f3eac', 'message': 'Shift EnvironmentVariable fixture setup to base\n\nWhile investigating a different branch, I came across a test failure\ndue to the ROOT_DISK environment variable leaking into a test. The\nCMDEnvironmentTest already had code to deal with that case, added to\ndeal with the same problem affecting it, so I moved the code into\nthe base module so all tests can benefit.\n\nChange-Id: I7e82584f75a309c4cea6fb3f7c0c420358c778e1\n'}, {'number': 2, 'created': '2015-02-11 05:41:22.000000000', 'files': ['os_cloud_config/tests/base.py', 'os_cloud_config/cmd/utils/tests/test_environment.py'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/2a80f77c54f3f44c9a449a1a95647e19973251c6', 'message': 'Shift EnvironmentVariable fixture setup to base\n\nWhile investigating a different branch, I came across a test failure\ndue to the ROOT_DISK environment variable leaking into a test. The\nCMDEnvironmentTest already had code to deal with that case, added to\ndeal with the same problem affecting it, so I moved the code into\nthe base module so all tests can benefit.\n\nChange-Id: I7e82584f75a309c4cea6fb3f7c0c420358c778e1\n'}]",0,154759,2a80f77c54f3f44c9a449a1a95647e19973251c6,10,3,2,9369,,,0,"Shift EnvironmentVariable fixture setup to base

While investigating a different branch, I came across a test failure
due to the ROOT_DISK environment variable leaking into a test. The
CMDEnvironmentTest already had code to deal with that case, added to
deal with the same problem affecting it, so I moved the code into
the base module so all tests can benefit.

Change-Id: I7e82584f75a309c4cea6fb3f7c0c420358c778e1
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/59/154759/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_cloud_config/tests/base.py', 'os_cloud_config/cmd/utils/tests/test_environment.py']",2,a4abe85142acd696d596586860ba0bceef8f3eac,environmental-safety,," def setUp(self): super(CMDEnviromentTest, self).setUp() for key in ('OS_AUTH_URL', 'OS_PASSWORD', 'OS_TENANT_NAME', 'OS_USERNAME', 'OS_CACERT'): fixture = fixtures.EnvironmentVariable(key) self.useFixture(fixture) ",5,7
openstack%2Fhorizon~master~I4fec94a78168d48fee5b21d24064200b2aefce91,openstack/horizon,master,I4fec94a78168d48fee5b21d24064200b2aefce91,Remove unused config access via REST,MERGED,2015-05-14 21:39:52.000000000,2015-05-27 03:07:15.000000000,2015-05-27 03:07:13.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 14151}]","[{'number': 1, 'created': '2015-05-14 21:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c11ca69f0a69c15e70406b92522d90be90b3c379', 'message': 'Remove unused config access via REST\n\nThis original method to retrieve user settings has been\nreplaced by https://review.openstack.org/#/c/170351/.\n\nRemove old way to prevent confusion.\n\nChange-Id: I4fec94a78168d48fee5b21d24064200b2aefce91\nCloses-Bug: #1455246\n'}, {'number': 2, 'created': '2015-05-26 20:33:37.000000000', 'files': ['horizon/static/horizon/js/angular/services/hz.api.config.js', 'openstack_dashboard/api/rest/config.py', 'openstack_dashboard/test/api_tests/config_rest_tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a4b48e4c05579513d8a4447d663d80dfac89bc37', 'message': 'Remove unused config access via REST\n\nThis original method to retrieve user settings has been\nreplaced by https://review.openstack.org/#/c/170351/.\n\nRemove old way to prevent confusion.\n\nChange-Id: I4fec94a78168d48fee5b21d24064200b2aefce91\nCloses-Bug: #1455246\n'}]",0,183224,a4b48e4c05579513d8a4447d663d80dfac89bc37,18,6,2,9622,,,0,"Remove unused config access via REST

This original method to retrieve user settings has been
replaced by https://review.openstack.org/#/c/170351/.

Remove old way to prevent confusion.

Change-Id: I4fec94a78168d48fee5b21d24064200b2aefce91
Closes-Bug: #1455246
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/183224/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/config.py', 'openstack_dashboard/test/api_tests/config_rest_tests.py']",2,c11ca69f0a69c15e70406b92522d90be90b3c379,removeOldConfig,,"import mock from horizon import conf def test_user_config_get(self): user_config = {""modal_backdrop"": ""static""} content = '""modal_backdrop"": ""static""' with mock.patch.dict(conf.HORIZON_CONFIG, user_config): request = self.mock_rest_request() response = config.DefaultUserConfigs().get(request) self.assertStatusCode(response, 200) self.assertContains(response.content, content) def test_admin_config_get(self): admin_config = {""user_home"": ""somewhere.com""} content = '""user_home"": ""somewhere.com""' with mock.patch.dict(conf.HORIZON_CONFIG, admin_config): request = self.mock_rest_request() response = config.AdminConfigs().get(request) self.assertStatusCode(response, 200) self.assertContains(response.content, content) def test_ignore_list(self): ignore_config = {""password_validator"": ""someobject""} content = '""password_validator"": ""someobject""' with mock.patch.dict(conf.HORIZON_CONFIG, ignore_config): request = self.mock_rest_request() response = config.AdminConfigs().get(request) self.assertStatusCode(response, 200) self.assertNotContains(response.content, content)",0,84
openstack%2Fhorizon~master~I6766027addeaaa04756a478d07dc37fd4307907f,openstack/horizon,master,I6766027addeaaa04756a478d07dc37fd4307907f,Small fix to angular docs,MERGED,2015-05-26 17:08:40.000000000,2015-05-27 03:07:09.000000000,2015-05-27 03:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 14307}, {'_account_id': 15742}]","[{'number': 1, 'created': '2015-05-26 17:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7b387303bd50314d40f39c12ac40ec55f8b90266', 'message': 'Small fix to angular docs\n\nChange-Id: I6766027addeaaa04756a478d07dc37fd4307907f\nCloses-bug: #1458938\n'}, {'number': 2, 'created': '2015-05-26 20:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1e347d36d06113ddb8c22e9044ca4ec5921d08fb', 'message': ""Small fix to angular docs\n\nRemoving outdated docs since we are now adopting JP's style guide.\n\nChange-Id: I6766027addeaaa04756a478d07dc37fd4307907f\nCloses-bug: #1458938""}, {'number': 3, 'created': '2015-05-26 20:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5b86116574197fff789e8a7b1633ef23f2d0da7e', 'message': ""Small fix to angular docs\n\nRemoving outdated docs since we are now adopting JP's style guide.\n\nChange-Id: I6766027addeaaa04756a478d07dc37fd4307907f\nCloses-bug: #1458938""}, {'number': 4, 'created': '2015-05-26 20:45:26.000000000', 'files': ['doc/source/contributing.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c16b271a2b9381470ee284faf6dea4e5b403312a', 'message': ""Small fix to angular docs\n\nRemoving outdated docs since we are now adopting JP's style guide.\n\nChange-Id: I6766027addeaaa04756a478d07dc37fd4307907f\nCloses-bug: #1458938""}]",4,185668,c16b271a2b9381470ee284faf6dea4e5b403312a,16,6,4,9576,,,0,"Small fix to angular docs

Removing outdated docs since we are now adopting JP's style guide.

Change-Id: I6766027addeaaa04756a478d07dc37fd4307907f
Closes-bug: #1458938",git fetch https://review.opendev.org/openstack/horizon refs/changes/68/185668/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributing.rst'],1,7b387303bd50314d40f39c12ac40ec55f8b90266,docs/angular," .controller('my_module.my_controller', ['$scope', function($scope) {"," .controller('my_controller', ['$scope', function($scope) {",1,1
openstack%2Ftrove~master~I09a8f4bacaba2f409dc152f4f9b6dc1123f03131,openstack/trove,master,I09a8f4bacaba2f409dc152f4f9b6dc1123f03131,Fixed the unmocked entry in taskmanager unit-tests,MERGED,2015-05-14 15:35:12.000000000,2015-05-27 03:07:05.000000000,2015-05-27 03:07:03.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 13355}, {'_account_id': 14576}, {'_account_id': 14829}, {'_account_id': 14991}]","[{'number': 1, 'created': '2015-05-14 15:35:12.000000000', 'files': ['trove/tests/unittests/taskmanager/test_models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/03c38b46ffa9ff1680271ebc5902da2e443f2264', 'message': 'Fixed the unmocked entry in taskmanager unit-tests\n\nMade use of patch.object to resolve the unmocking problem.\n\nChange-Id: I09a8f4bacaba2f409dc152f4f9b6dc1123f03131\nCloses-Bug: #1455125\n'}]",2,183084,03c38b46ffa9ff1680271ebc5902da2e443f2264,24,10,1,7806,,,0,"Fixed the unmocked entry in taskmanager unit-tests

Made use of patch.object to resolve the unmocking problem.

Change-Id: I09a8f4bacaba2f409dc152f4f9b6dc1123f03131
Closes-Bug: #1455125
",git fetch https://review.opendev.org/openstack/trove refs/changes/84/183084/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/taskmanager/test_models.py'],1,03c38b46ffa9ff1680271ebc5902da2e443f2264,master," self.taskmanager_models_CONF = patch.object(taskmanager_models, 'CONF') self.mock_conf = self.taskmanager_models_CONF.start() self.mock_conf.get = Mock(return_value=FakeGroup()) self.addCleanup(self.taskmanager_models_CONF.stop)", taskmanager_models.CONF.get = Mock(return_value=FakeGroup()),5,1
openstack%2Fsenlin~master~Ic4d872d8c2995614aba966ccd179181ab11bc640,openstack/senlin,master,Ic4d872d8c2995614aba966ccd179181ab11bc640,Revised dispatcher notification,MERGED,2015-05-26 14:55:50.000000000,2015-05-27 03:04:29.000000000,2015-05-27 03:04:29.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-05-26 14:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2becb79704c76f422bfb814d852929864dd557a2', 'message': ""Revised dispatcher notification\n\nThis patch revised the interface for notifying an action's readiness for\nexecution (we execute them right away at the moment). The revision set\nthe default engine_id to be None, which is the most common cases, thus\nwe don't have to pass None into notify(). It also eliminates the passing\nof NEW_ACTION (renamed to START_ACTION) by providing a more user\nfriendly interface function.\n\nThis patch also fixed the incorrect usage of engline_life_timeout, where\nwe should use rpc_response_timeout.\n\nChange-Id: Ic4d872d8c2995614aba966ccd179181ab11bc640\n""}, {'number': 2, 'created': '2015-05-27 02:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/35eb16c0df216b5a124a7dc2d800347ecdae1a8e', 'message': ""Revised dispatcher notification\n\nThis patch revised the interface for notifying an action's readiness for\nexecution (we execute them right away at the moment). The revision set\nthe default engine_id to be None, which is the most common cases, thus\nwe don't have to pass None into notify(). It also eliminates the passing\nof NEW_ACTION (renamed to START_ACTION) by providing a more user\nfriendly interface function.\n\nThis patch also fixed the incorrect usage of engline_life_timeout, where\nwe should use rpc_response_timeout if needed. Currently, we leave it to\nthe oslo.messaing library to use the configuration option instead of\ninjecting new values from an inappropriate place.\n\nChange-Id: Ic4d872d8c2995614aba966ccd179181ab11bc640\n""}, {'number': 3, 'created': '2015-05-27 02:34:11.000000000', 'files': ['senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/tests/engine/test_cluster_policies.py', 'senlin/engine/scheduler.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/engine/test_clusters.py', 'senlin/tests/engine/test_nodes.py', 'senlin/tests/engine/test_webhooks.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/094fcab0732febad5017efd870a9e255b6a82331', 'message': ""Revised dispatcher notification\n\nThis patch revised the interface for notifying an action's readiness for\nexecution (we execute them right away at the moment). The revision set\nthe default engine_id to be None, which is the most common cases, thus\nwe don't have to pass None into notify(). It also eliminates the passing\nof NEW_ACTION (renamed to START_ACTION) by providing a more user\nfriendly interface function.\n\nThis patch also fixed the incorrect usage of engline_life_timeout, where\nwe should use rpc_response_timeout if needed. Currently, we leave it to\nthe oslo.messaing library to use the configuration option instead of\ninjecting new values from an inappropriate place.\n\nChange-Id: Ic4d872d8c2995614aba966ccd179181ab11bc640\n""}]",0,185636,094fcab0732febad5017efd870a9e255b6a82331,11,2,3,8246,,,0,"Revised dispatcher notification

This patch revised the interface for notifying an action's readiness for
execution (we execute them right away at the moment). The revision set
the default engine_id to be None, which is the most common cases, thus
we don't have to pass None into notify(). It also eliminates the passing
of NEW_ACTION (renamed to START_ACTION) by providing a more user
friendly interface function.

This patch also fixed the incorrect usage of engline_life_timeout, where
we should use rpc_response_timeout if needed. Currently, we leave it to
the oslo.messaing library to use the configuration option instead of
injecting new values from an inappropriate place.

Change-Id: Ic4d872d8c2995614aba966ccd179181ab11bc640
",git fetch https://review.opendev.org/openstack/senlin refs/changes/36/185636/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/tests/engine/test_cluster_policies.py', 'senlin/engine/scheduler.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/engine/test_clusters.py', 'senlin/tests/engine/test_nodes.py', 'senlin/tests/engine/test_webhooks.py']",9,2becb79704c76f422bfb814d852929864dd557a2,fix-dispatcher," @mock.patch.object(dispatcher, 'start_action') @mock.patch.object(dispatcher, 'start_action') notify.assert_called_once_with(self.ctx, action_id=mock.ANY) @mock.patch.object(dispatcher, 'start_action') notify.assert_called_once_with(self.ctx, action_id=mock.ANY)"," @mock.patch.object(dispatcher, 'notify') @mock.patch.object(dispatcher, 'notify') expected_call = mock.call(self.ctx, self.eng.dispatcher.NEW_ACTION, None, action_id=mock.ANY) # two calls: one for create, the other for scaling operation notify.assert_has_calls([expected_call] * 1) @mock.patch.object(dispatcher, 'notify') expected_call = mock.call(self.ctx, self.eng.dispatcher.NEW_ACTION, None, action_id=mock.ANY) # two calls: one for create, the other for scaling operation notify.assert_has_calls([expected_call] * 1)",146,214
openstack%2Fcinder~master~Ibb086f336e78c23e4907562d39f460eae3004bca,openstack/cinder,master,Ibb086f336e78c23e4907562d39f460eae3004bca,Fix a problem with FAST support in VMAX driver,MERGED,2015-04-02 05:37:43.000000000,2015-05-27 02:59:02.000000000,2015-05-20 00:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10263}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 12802}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 15882}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-04-02 05:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/690969ce9947c42c600ee4d0248a5eaec62ff1e2', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 2, 'created': '2015-04-02 05:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d2aac06de83e76d8132ed3df839b63312698fba4', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 3, 'created': '2015-04-14 03:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/19ac31533d2b615e522a459207f73803b49b3e5e', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 4, 'created': '2015-04-24 02:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/99001c58629d5e6e1aa23d12b8529d4de7b9c318', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 5, 'created': '2015-04-24 02:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a46749bd67413dc74940833efd10309a80af3f12', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 6, 'created': '2015-04-28 19:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/baea63e2d48cfd4c6dbb793f38be9974a42f072a', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 7, 'created': '2015-05-10 02:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1fc4ebfd53f186a310677885ccd353cd86e7bf3c', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 8, 'created': '2015-05-11 15:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/515a382358f73a4c4f21b8c87f9cbb3ca40ffe5b', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 9, 'created': '2015-05-12 21:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/182879c8b4fbac948c417884f974e390a2b350b6', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 10, 'created': '2015-05-13 15:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/077559155d036587e33931622c0aaf14d88b1509', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}, {'number': 11, 'created': '2015-05-13 15:55:32.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_fc.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/tests/unit/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b0a58fa0e6017def37acbb1c4f8dabc1a550223', 'message': ""Fix a problem with FAST support in VMAX driver\n\nThe VMAX driver doesn't distinguish between storage groups for\nmasking views (used for attachment) and storage groups for volumes\nunder FAST policy. This causes problems during attach volume.\nThis patch fixed the problem.\n\nChange-Id: Ibb086f336e78c23e4907562d39f460eae3004bca\nCloses-Bug: #1435069\n""}]",16,170000,3b0a58fa0e6017def37acbb1c4f8dabc1a550223,212,38,11,6491,,,0,"Fix a problem with FAST support in VMAX driver

The VMAX driver doesn't distinguish between storage groups for
masking views (used for attachment) and storage groups for volumes
under FAST policy. This causes problems during attach volume.
This patch fixed the problem.

Change-Id: Ibb086f336e78c23e4907562d39f460eae3004bca
Closes-Bug: #1435069
",git fetch https://review.opendev.org/openstack/cinder refs/changes/00/170000/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/tests/test_emc_vmax.py']",5,690969ce9947c42c600ee4d0248a5eaec62ff1e2,fast,"from cinder.i18n import _ storagegroupname = 'OS-fakehost-gold-I-SG' defaultstoragegroupname = 'OS_default_GOLD1_SG' assoc1 = CIM_DeviceMaskingGroup() assoc1['ElementName'] = self.data.storagegroupname assoc1['SystemName'] = self.data.storage_system assoc1['CreationClassName'] = 'CIM_DeviceMaskingGroup' assoc1.path = assoc1 assocs.append(assoc1) assoc2 = CIM_DeviceMaskingGroup() assoc2['ElementName'] = self.data.defaultstoragegroupname assoc2['SystemName'] = self.data.storage_system assoc2['CreationClassName'] = 'CIM_DeviceMaskingGroup' assoc2.path = assoc2 assocs.append(assoc2) if 'CreationClassName' in objectpath: targetmaskinggroup['CreationClassName'] = ( objectpath['CreationClassName']) else: targetmaskinggroup['CreationClassName'] = ( 'CIM_DeviceMaskingGroup') if 'ElementName' in objectpath: targetmaskinggroup['ElementName'] = objectpath['ElementName'] else: targetmaskinggroup['ElementName'] = ( self.data.storagegroupname) storagegroup1 = {} storagegroup1['CreationClassName'] = ( storagegroup1['ElementName'] = self.data.storagegroupname storagegroups.append(storagegroup1) storagegroup2 = {} storagegroup2['CreationClassName'] = ( self.data.storagegroup_creationclass) storagegroup2['ElementName'] = self.data.defaultstoragegroupname storagegroups.append(storagegroup2) storagegroup3 = {} storagegroup3['CreationClassName'] = ( self.data.storagegroup_creationclass) storagegroup3['ElementName'] = 'OS-fakehost-SRP_1-Bronze-DSS-SG' storagegroups.append(storagegroup3) storagegroup4 = {} storagegroup4['CreationClassName'] = ( self.data.storagegroup_creationclass) storagegroup4['ElementName'] = 'OS-SRP_1-Bronze-DSS-SG' storagegroups.append(storagegroup4) def test_check_if_rollback_action_for_masking_required(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'storagetype:fastpolicy': 'GOLD1'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] rollbackDict = {} rollbackDict['isV3'] = False rollbackDict['defaultStorageGroupInstanceName'] = ( self.data.default_storage_group) rollbackDict['sgName'] = self.data.storagegroupname rollbackDict['volumeName'] = 'vol1' rollbackDict['fastPolicyName'] = 'GOLD1' rollbackDict['volumeInstance'] = vol rollbackDict['controllerConfigService'] = controllerConfigService rollbackDict['extraSpecs'] = extraSpecs # Path 1 - The volume is in another storage group that isn't the # default storage group expectedmessage = (_(""V2 rollback - Volume in another storage "" ""group besides default storage group"")) message = ( self.driver.common.masking. _check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) # Path 2 - The volume is not in any storage group rollbackDict['sgName'] = 'sq_not_exist' expectedmessage = (_(""V2 rollback, volume is not in any storage "" ""group"")) message = ( self.driver.common.masking. _check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) for _var in range(0, 10):"," storagegroupname = 'OS_default_GOLD1_SG' assoc = CIM_DeviceMaskingGroup() assoc['ElementName'] = 'OS_default_GOLD1_SG' assoc['SystemName'] = self.data.storage_system assoc['CreationClassName'] = 'CIM_DeviceMaskingGroup' assoc.path = assoc assocs.append(assoc) targetmaskinggroup['CreationClassName'] = 'CIM_DeviceMaskingGroup' targetmaskinggroup['ElementName'] = 'OS_default_GOLD1_SG' storagegroup = {} storagegroup['CreationClassName'] = ( storagegroup['ElementName'] = self.data.storagegroupname storagegroups.append(storagegroup) def test_format_system_name(self): v2array = ['SYMMETRIX', '000195900551', 'U', 'gold'] systemnameV2 = self.driver.utils._format_system_name(v2array[0], v2array[1], '+') self.assertEqual('SYMMETRIX+000195900551', systemnameV2) v3array = ['SYMMETRIX', '000197200056', 'SRP_1'] systemnameV3 = self.driver.utils._format_system_name(v3array[0], v3array[1], '-+-') self.assertEqual('SYMMETRIX-+-000197200056', systemnameV3) for _ in range(0, 10):",204,94
openstack%2Ftrove~master~Iee9ed970a789bae8d4f19636c0b5bfd7402641be,openstack/trove,master,Iee9ed970a789bae8d4f19636c0b5bfd7402641be,Added more unit-tests to Vertica-Cluster-Strategy,MERGED,2015-04-28 15:20:03.000000000,2015-05-27 02:42:23.000000000,2015-05-27 02:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 1870}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 11783}, {'_account_id': 13355}, {'_account_id': 14576}, {'_account_id': 14829}, {'_account_id': 14912}]","[{'number': 1, 'created': '2015-04-28 15:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/71bc2c5509c27a1f6b8ee096f363fb2ee1212a89', 'message': 'Added more unit-tests to Vertica-Cluster-Strategy\n\nMore tests have been added to improve code-coverage\nof following code-files:\n\n- trove/common/strategies/cluster/experimental/vertica/api.py\n- trove/common/strategies/cluster/experimental/vertica/taskmanager.py\n- trove/common/strategies/cluster/experimental/vertica/guestagent.py\n\nChange-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be\n'}, {'number': 2, 'created': '2015-05-08 09:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/37713b89d354a3e61e4d8de0dcaf21f4b49865a7', 'message': 'Added more unit-tests to Vertica-Cluster-Strategy\n\nMore tests have been added to improve code-coverage\nof following code-files:\n\n- trove/common/strategies/cluster/experimental/vertica/api.py\n- trove/common/strategies/cluster/experimental/vertica/taskmanager.py\n- trove/common/strategies/cluster/experimental/vertica/guestagent.py\n\nChange-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be\n'}, {'number': 3, 'created': '2015-05-08 16:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f9d60d5d02bdc932a32c9730375571e8ad6a8049', 'message': 'Added more unit-tests to Vertica-Cluster-Strategy\n\nMore tests have been added to improve code-coverage\nof following code-files:\n\n- trove/common/strategies/cluster/experimental/vertica/api.py\n- trove/common/strategies/cluster/experimental/vertica/taskmanager.py\n- trove/common/strategies/cluster/experimental/vertica/guestagent.py\n\nChange-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be\n'}, {'number': 4, 'created': '2015-05-14 14:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/71511c7e23315f120ad45d699f2f098eb568f550', 'message': 'Added more unit-tests to Vertica-Cluster-Strategy\n\nMore tests have been added to improve code-coverage\nof following code-files:\n\n- trove/common/strategies/cluster/experimental/vertica/api.py\n- trove/common/strategies/cluster/experimental/vertica/taskmanager.py\n- trove/common/strategies/cluster/experimental/vertica/guestagent.py\n\nChange-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be\n'}, {'number': 5, 'created': '2015-05-17 05:00:05.000000000', 'files': ['trove/tests/unittests/guestagent/test_vertica_api.py', 'trove/tests/unittests/taskmanager/test_vertica_clusters.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/tests/unittests/cluster/test_vertica_cluster.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/b3cef41bf3f14e9e732dc71f5443e99dfcee9c21', 'message': 'Added more unit-tests to Vertica-Cluster-Strategy\n\nMore tests have been added to improve code-coverage\nof following code-files:\n\n- trove/common/strategies/cluster/experimental/vertica/api.py\n- trove/common/strategies/cluster/experimental/vertica/taskmanager.py\n- trove/common/strategies/cluster/experimental/vertica/guestagent.py\n\nChange-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be\n'}]",38,178236,b3cef41bf3f14e9e732dc71f5443e99dfcee9c21,62,15,5,7806,,,0,"Added more unit-tests to Vertica-Cluster-Strategy

More tests have been added to improve code-coverage
of following code-files:

- trove/common/strategies/cluster/experimental/vertica/api.py
- trove/common/strategies/cluster/experimental/vertica/taskmanager.py
- trove/common/strategies/cluster/experimental/vertica/guestagent.py

Change-Id: Iee9ed970a789bae8d4f19636c0b5bfd7402641be
",git fetch https://review.opendev.org/openstack/trove refs/changes/36/178236/5 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/guestagent/test_vertica_api.py', 'trove/tests/unittests/taskmanager/test_vertica_clusters.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/tests/unittests/cluster/test_vertica_cluster.py']",4,71bc2c5509c27a1f6b8ee096f363fb2ee1212a89,master,"from novaclient import exceptions as nova_exceptions def test_create_invalid_flavor_specified(self, mock_client): instances = [{'flavor_id': '1234'}, {'flavor_id': '1234'}, {'flavor_id': '1234'}] (mock_client.return_value.flavors.get) = Mock( side_effect=nova_exceptions.NotFound( 404, ""Flavor id not found %s"" % id)) self.assertRaises(exception.FlavorNotFound, Cluster.create, Mock(), self.cluster_name, self.datastore, self.datastore_version, instances ) @patch.object(remote, 'create_nova_client') @patch.object(remote, 'create_nova_client') def test_create_volume_not_equal(self, mock_client): instances = self.instances instances[0]['volume_size'] = 2 flavors = Mock() mock_client.return_value.flavors = flavors self.assertRaises(exception.ClusterVolumeSizesNotEqual, Cluster.create, Mock(), self.cluster_name, self.datastore, self.datastore_version, instances ) @patch.object(inst_models.Instance, 'create') @patch.object(DBCluster, 'create') @patch.object(task_api, 'load') @patch.object(QUOTAS, 'check_quotas') @patch.object(remote, 'create_nova_client') def test_create_with_ephemeral_flavor(self, mock_client, mock_check_quotas, mock_task_api, mock_db_create, mock_ins_create): class FakeFlavor: def __init__(self, flavor_id): self.flavor_id = flavor_id @property def id(self): return self.flavor.id @property def ephemeral(self): return 1 instances = [{'flavor_id': '1234'}, {'flavor_id': '1234'}, {'flavor_id': '1234'}] CONF.get(self.dv.manager).volume_support = False (mock_client.return_value. flavors.get.return_value) = FakeFlavor('1234') self.cluster.create(Mock(), self.cluster_name, self.datastore, self.datastore_version, instances) mock_task_api.create_cluster.assert_called self.assertEqual(3, mock_ins_create.call_count) ",,288,4
openstack%2Frally~master~I26d3d7446e9652dc8df424854ee6204b95638f36,openstack/rally,master,I26d3d7446e9652dc8df424854ee6204b95638f36,Remove break from case statement to allow for parsing of CLI args,MERGED,2015-05-25 02:57:07.000000000,2015-05-27 02:33:58.000000000,2015-05-27 02:33:55.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-25 02:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f558544649db1cc2fcb1de823d8d6393a4b7424e', 'message': 'Remove break from case statement to allow for parsing of CLI args.\nCloses-bug: 1458408\n\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n'}, {'number': 2, 'created': '2015-05-25 12:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/093650d71f61593623b45d891bc25bf30ea28420', 'message': 'Fix install_rally.sh make it work with various DB backends\n\nRemove break from case statement to allow for parsing \nof CLI args.\n\nCloses-bug: 1458408\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n'}, {'number': 3, 'created': '2015-05-26 19:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/141be62192b4f9087d203ffa4c9d696f970d3d47', 'message': ""Remove break from case statement to allow for parsing of CLI args.\n\nAdded 2 lines of tests to test_install.sh.  One for sqlite db type and\none for mysql db type with the necessary  parameters. The mysql test\nwill fail since there's probably no db server setup with those params\nbut will verify that the script is actually parsing the CLI args for\nthat parameter.\n\nCloses-bug: 1458408\n\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n""}, {'number': 4, 'created': '2015-05-26 21:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1f97ac144357b2ce771d6ed57d8d3500aa9c9c62', 'message': 'Remove break from case statement to allow for parsing of CLI args.\n\nAdded 2 lines of tests to test_install.sh. One for sqlite db type and\none for mysql db type with the necessary parameters.\n\nCloses-bug: 1458408\n\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n'}, {'number': 5, 'created': '2015-05-26 22:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7cd3e78815b3c85d04eb702217c887a593462c98', 'message': 'Remove break from case statement to allow for parsing of CLI args\n\nAdded test to check that --dbtype\n\nCloses-bug: 1458408\n\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n'}, {'number': 6, 'created': '2015-05-26 23:39:03.000000000', 'files': ['install_rally.sh', 'tests/ci/test_install.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/a6f9d3c19017ec5bc0a8828761ec6e8082dcb3d8', 'message': 'Remove break from case statement to allow for parsing of CLI args\n\nAdded test to check that --dbtype works\n\nCloses-bug: 1458408\n\nChange-Id: I26d3d7446e9652dc8df424854ee6204b95638f36\n'}]",5,185296,a6f9d3c19017ec5bc0a8828761ec6e8082dcb3d8,27,5,6,11635,,,0,"Remove break from case statement to allow for parsing of CLI args

Added test to check that --dbtype works

Closes-bug: 1458408

Change-Id: I26d3d7446e9652dc8df424854ee6204b95638f36
",git fetch https://review.opendev.org/openstack/rally refs/changes/96/185296/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,f558544649db1cc2fcb1de823d8d6393a4b7424e,bug/1458408, sqlite|mysql|postgres);;, sqlite|mysql|postgres) break ;;,1,1
openstack%2Fcinder~master~Id2e6cba489d8509601820b5aed83652f71be2bdc,openstack/cinder,master,Id2e6cba489d8509601820b5aed83652f71be2bdc,Remove use of deprecated LOG.warn,MERGED,2015-05-13 14:33:05.000000000,2015-05-27 02:13:44.000000000,2015-05-13 22:31:41.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14969}, {'_account_id': 15011}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-13 14:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/19ea07bf79085c57f28437f629dbc573438bf790', 'message': ""Remove use of deprecated LOG.warn\n\nLOG.warn is deprecated and LOG.warning should be used.\n\nThis patch fixes up instances of LOG.warn usage and adds a\nhacking check to make sure it doesn't creep back in.\n\nSee Logger.warning note here for background:\nhttps://docs.python.org/3/library/logging.html\n\nChange-Id: Id2e6cba489d8509601820b5aed83652f71be2bdc\n""}, {'number': 2, 'created': '2015-05-13 15:52:27.000000000', 'files': ['cinder/volume/flows/api/create_volume.py', 'cinder/hacking/checks.py', 'cinder/tests/unit/integrated/integrated_helpers.py', 'cinder/volume/throttling.py', 'cinder/volume/targets/iet.py', 'cinder/tests/unit/image/fake.py', 'cinder/tests/unit/integrated/test_volumes.py', 'cinder/volume/utils.py', 'cinder/tests/unit/integrated/test_xml.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/qos_specs.py', 'cinder/tests/unit/test_hds_iscsi.py', 'HACKING.rst', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/adfff0b1413814c58ea17338cccb2ca81c1b8641', 'message': ""Remove use of deprecated LOG.warn\n\nLOG.warn is deprecated and LOG.warning should be used.\n\nThis patch fixes up instances of LOG.warn usage and adds a\nhacking check to make sure it doesn't creep back in.\n\nSee Logger.warning note here for background:\nhttps://docs.python.org/3/library/logging.html\n\nAlso cleaned up some remaining instances where logging was\npreformatting strings rather than passing in formatting\narguments to the logger to handle.\n\nChange-Id: Id2e6cba489d8509601820b5aed83652f71be2bdc\n""}]",0,182697,adfff0b1413814c58ea17338cccb2ca81c1b8641,38,23,2,11904,,,0,"Remove use of deprecated LOG.warn

LOG.warn is deprecated and LOG.warning should be used.

This patch fixes up instances of LOG.warn usage and adds a
hacking check to make sure it doesn't creep back in.

See Logger.warning note here for background:
https://docs.python.org/3/library/logging.html

Also cleaned up some remaining instances where logging was
preformatting strings rather than passing in formatting
arguments to the logger to handle.

Change-Id: Id2e6cba489d8509601820b5aed83652f71be2bdc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/182697/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/flows/api/create_volume.py', 'cinder/hacking/checks.py', 'cinder/tests/unit/integrated/integrated_helpers.py', 'cinder/volume/throttling.py', 'cinder/volume/targets/iet.py', 'cinder/tests/unit/image/fake.py', 'cinder/tests/unit/integrated/test_volumes.py', 'cinder/volume/utils.py', 'cinder/tests/unit/integrated/test_xml.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/qos_specs.py', 'cinder/tests/unit/test_hds_iscsi.py', 'HACKING.rst', 'cinder/volume/api.py']",14,19ea07bf79085c57f28437f629dbc573438bf790,nologwarn," LOG.warning(msg, {'s_pid': context.project_id, 's_size': volume['size'], 'd_consumed': _consumed(over), 'd_quota': quotas[over]}) LOG.warning(msg, {'s_pid': context.project_id, 'd_consumed': _consumed(over)}) LOG.warning(msg) LOG.warning(msg) LOG.warning(msg)"," LOG.warn(msg, {'s_pid': context.project_id, 's_size': volume['size'], 'd_consumed': _consumed(over), 'd_quota': quotas[over]}) LOG.warn(msg, {'s_pid': context.project_id, 'd_consumed': _consumed(over)}) LOG.warn(msg) LOG.warn(msg) LOG.warn(msg)",125,117
openstack%2Fpuppet-nova~master~I112d364b29518468c6acd88bbb6844a0aba3bb0d,openstack/puppet-nova,master,I112d364b29518468c6acd88bbb6844a0aba3bb0d,Dummy commit,ABANDONED,2015-05-27 02:03:35.000000000,2015-05-27 02:05:11.000000000,,[{'_account_id': 6554}],"[{'number': 1, 'created': '2015-05-27 02:03:35.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/0e412a985f9fb7aee51dc077c6a821743ba2bdab', 'message': 'Dummy commit\n\nChange-Id: I112d364b29518468c6acd88bbb6844a0aba3bb0d\n'}]",0,185817,0e412a985f9fb7aee51dc077c6a821743ba2bdab,3,1,1,6554,,,0,"Dummy commit

Change-Id: I112d364b29518468c6acd88bbb6844a0aba3bb0d
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/17/185817/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,0e412a985f9fb7aee51dc077c6a821743ba2bdab,,," { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",0,1
openstack%2Fheat~master~Ie02d6f6a05f5a5d6df1500d9f34a2084a595bd32,openstack/heat,master,Ie02d6f6a05f5a5d6df1500d9f34a2084a595bd32,Remove deprecated parser module,MERGED,2015-05-22 14:57:59.000000000,2015-05-27 02:04:15.000000000,2015-05-27 02:04:13.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6899}, {'_account_id': 8246}, {'_account_id': 8833}, {'_account_id': 9751}, {'_account_id': 12321}, {'_account_id': 13009}, {'_account_id': 13323}, {'_account_id': 14027}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-05-22 14:57:59.000000000', 'files': ['heat/engine/parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/59e889c9242e7f70ba0ce457c02fa5ee5fc7790b', 'message': 'Remove deprecated parser module\n\nRemove unused engine/parser according to\nhttps://etherpad.openstack.org/p/YVR-heat-liberty-deprecation\n\nChange-Id: Ie02d6f6a05f5a5d6df1500d9f34a2084a595bd32\n'}]",0,185040,59e889c9242e7f70ba0ce457c02fa5ee5fc7790b,20,11,1,13323,,,0,"Remove deprecated parser module

Remove unused engine/parser according to
https://etherpad.openstack.org/p/YVR-heat-liberty-deprecation

Change-Id: Ie02d6f6a05f5a5d6df1500d9f34a2084a595bd32
",git fetch https://review.opendev.org/openstack/heat refs/changes/40/185040/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/parser.py'],1,59e889c9242e7f70ba0ce457c02fa5ee5fc7790b,remove-parser,,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import warnings from heat.engine import stack from heat.engine import template # Note: these classes are here for backwards compatibility. # New uses of the Stack class should use stack.Stack(). # warnings.warn('Module parser.py is deprecated. Please use class Template ' 'in heat.engine.template and class Stack in heat.engine.stack.') Template = template.Template Stack = stack.Stack ",0,25
openstack%2Ftripleo-heat-templates~master~I467dba4c7625f47ee6fe9053307971133d25a8a9,openstack/tripleo-heat-templates,master,I467dba4c7625f47ee6fe9053307971133d25a8a9,Map Heat services to isolated networks,ABANDONED,2015-05-27 01:27:04.000000000,2015-05-27 01:31:52.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-27 01:27:04.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1062de0447be995c17aad77fcf6223f6c058f9c1', 'message': ""Map Heat services to isolated networks\n\nThis change adds parameters to specify which networks the Heat services\nwill use. If the internal_api network exists, the Heat API, Heat Cloud\nFormations, and Heat Cloudwatch services will bind to the IP address on\nthat network, otherwise the services will default to the IP on the\nUndercloud 'ctlplane' network.\n\nChange-Id: I467dba4c7625f47ee6fe9053307971133d25a8a9\n""}]",0,185803,1062de0447be995c17aad77fcf6223f6c058f9c1,3,1,1,12398,,,0,"Map Heat services to isolated networks

This change adds parameters to specify which networks the Heat services
will use. If the internal_api network exists, the Heat API, Heat Cloud
Formations, and Heat Cloudwatch services will bind to the IP address on
that network, otherwise the services will default to the IP on the
Undercloud 'ctlplane' network.

Change-Id: I467dba4c7625f47ee6fe9053307971133d25a8a9
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/185803/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,1062de0447be995c17aad77fcf6223f6c058f9c1,service_map_heat," heat::api::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiNetwork]}]} heat::api_cloudwatch::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiCloudwatchNetwork]}]} heat::api_cfn::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, HeatApiCfnNetwork]}]}", heat::api::bind_host: {get_input: controller_host} heat::api_cloudwatch::bind_host: {get_input: controller_host} heat::api_cfn::bind_host: {get_input: controller_host},6,5
openstack%2Ftripleo-heat-templates~master~I90752179819dd6afe890ca557014036dbc177316,openstack/tripleo-heat-templates,master,I90752179819dd6afe890ca557014036dbc177316,Map Neutron services to isolated networks,ABANDONED,2015-05-27 01:23:37.000000000,2015-05-27 01:30:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-27 01:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f614bda1dcb1ad4eeb4239bf40b1db4e073cd4d', 'message': ""Map Neutron services to isolated networks\n\nThis change adds parameters to specify which network the Neutron API should\nuse. If the internal_api network exists, Neutron will bind to the IP on that\nnetwork, otherwise the Undercloud 'ctlplane' network will be used. The\nnetwork that the Neutron API is bound to can be overridden in an environment\nfile.\n\nChange-Id: I90752179819dd6afe890ca557014036dbc177316\n""}, {'number': 2, 'created': '2015-05-27 01:27:04.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ac081c240b722eb9bdb0733ce588f88669626219', 'message': 'Map Neutron services to isolated networks\n\nChange-Id: I90752179819dd6afe890ca557014036dbc177316\n'}]",0,185802,ac081c240b722eb9bdb0733ce588f88669626219,5,1,2,12398,,,0,"Map Neutron services to isolated networks

Change-Id: I90752179819dd6afe890ca557014036dbc177316
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/185802/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml']",2,5f614bda1dcb1ad4eeb4239bf40b1db4e073cd4d,service_map_heat," neutron::bind_host: {get_attr: [NetIpMap, net_ip_map, {get_param: [ServiceNetMap, NeutronApiNetwork]}]}", neutron::bind_host: {get_input: controller_host},2,1
openstack%2Fglance~stable%2Fjuno~I54b91aeac9acee944f36e52b8849f039e85df1b2,openstack/glance,stable/juno,I54b91aeac9acee944f36e52b8849f039e85df1b2,Updated from global requirements,MERGED,2015-04-13 23:31:23.000000000,2015-05-27 01:29:45.000000000,2015-05-27 01:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5202}, {'_account_id': 6484}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-04-13 23:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3e2e06fc7cc811e5f7d866a0d4b56162701bbc63', 'message': 'Updated from global requirements\n\nChange-Id: I54b91aeac9acee944f36e52b8849f039e85df1b2\n'}, {'number': 2, 'created': '2015-04-22 12:40:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/glance/commit/f002d57d97190d72ffaff3278538db64eb998c0b', 'message': 'Updated from global requirements\n\nChange-Id: I54b91aeac9acee944f36e52b8849f039e85df1b2\n'}]",0,173118,f002d57d97190d72ffaff3278538db64eb998c0b,16,5,2,11131,,,0,"Updated from global requirements

Change-Id: I54b91aeac9acee944f36e52b8849f039e85df1b2
",git fetch https://review.opendev.org/openstack/glance refs/changes/18/173118/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3e2e06fc7cc811e5f7d866a0d4b56162701bbc63,openstack/requirements,"python-keystoneclient>=0.10.0,<1.2.0","python-keystoneclient>=0.10.0,<=1.1.0",1,1
openstack%2Fcinder~master~Ib2bd745c7ef600c514a94c3fd638d15d17a623a2,openstack/cinder,master,Ib2bd745c7ef600c514a94c3fd638d15d17a623a2,Fix incorrect reraising of exceptions,MERGED,2015-04-25 00:45:00.000000000,2015-05-27 01:26:24.000000000,2015-05-13 22:23:48.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 10263}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11343}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}]","[{'number': 1, 'created': '2015-04-25 00:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/daaf17052c3508afbad381e74a7dc86c594892cf', 'message': 'Fix incorrect reraising of exceptions\n\nThere are several places in the code where exception handling raises\nthe exception variable rather than just calling raise. This results\nin the traceback being incorrect.\n\nHad considered adding a hacking check for this, but that becomes a\nlittle tricky. There are valid places where ""raise ex"" is used that\nwould prevent a simple check.\n\nChange-Id: Ib2bd745c7ef600c514a94c3fd638d15d17a623a2\n'}, {'number': 2, 'created': '2015-05-13 13:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7f60a6b2b570f774707f76fa8a3f3faa5ccf369', 'message': 'Fix incorrect reraising of exceptions\n\nThere are several places in the code where exception handling raises\nthe exception variable rather than just calling raise. This results\nin the traceback being incorrect.\n\nHad considered adding a hacking check for this, but that becomes a\nlittle tricky. There are valid places where ""raise ex"" is used that\nwould prevent a simple check.\n\nChange-Id: Ib2bd745c7ef600c514a94c3fd638d15d17a623a2\n'}, {'number': 3, 'created': '2015-05-13 15:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f06df95d3fafd7f293716214799faada941ba072', 'message': 'Fix incorrect reraising of exceptions\n\nThere are several places in the code where exception handling raises\nthe exception variable rather than just calling raise. This results\nin the traceback being incorrect.\n\nHad considered adding a hacking check for this, but that becomes a\nlittle tricky. There are valid places where ""raise ex"" is used that\nwould prevent a simple check.\n\nChange-Id: Ib2bd745c7ef600c514a94c3fd638d15d17a623a2\n'}, {'number': 4, 'created': '2015-05-13 15:51:13.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/volume/drivers/netapp/dataontap/client/client_7mode.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/zfssa/restclient.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fea27a526ca7d18a7981141dd19bc9cad647a622', 'message': 'Fix incorrect reraising of exceptions\n\nThere are several places in the code where exception handling raises\nthe exception variable rather than just calling raise. This results\nin the traceback being incorrect.\n\nHad considered adding a hacking check for this, but that becomes a\nlittle tricky. There are valid places where ""raise ex"" is used that\nwould prevent a simple check.\n\nChange-Id: Ib2bd745c7ef600c514a94c3fd638d15d17a623a2\n'}]",6,177502,fea27a526ca7d18a7981141dd19bc9cad647a622,66,31,4,11904,,,0,"Fix incorrect reraising of exceptions

There are several places in the code where exception handling raises
the exception variable rather than just calling raise. This results
in the traceback being incorrect.

Had considered adding a hacking check for this, but that becomes a
little tricky. There are valid places where ""raise ex"" is used that
would prevent a simple check.

Change-Id: Ib2bd745c7ef600c514a94c3fd638d15d17a623a2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/02/177502/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/volume/drivers/netapp/dataontap/client/client_7mode.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/zfssa/restclient.py']",11,daaf17052c3508afbad381e74a7dc86c594892cf,reraise, except RestClientError: raise, except RestClientError as err: raise err,30,32
openstack%2Fpython-glanceclient~master~I99f5d4bf3f2247275adfac27076a005098728105,openstack/python-glanceclient,master,I99f5d4bf3f2247275adfac27076a005098728105,Add service catalog support for Glance client,ABANDONED,2014-01-17 06:48:35.000000000,2015-05-27 01:11:28.000000000,,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 6484}, {'_account_id': 6676}, {'_account_id': 8107}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-01-17 06:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ada8a02811216aeb329b111e407433f5ae29b475', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 2, 'created': '2014-01-20 08:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/93b25e2cf065e05c5e2b9e041ad83441db780202', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 3, 'created': '2014-01-21 03:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/575dd8f97b54e03e676c62467861fc698dc7f7d9', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 4, 'created': '2014-01-22 06:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/2c727ee0c5722151dca98e18ebcad2b4cf6dabe1', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 5, 'created': '2014-03-13 09:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/dba54fbd37a5a8c7150af9b268799a7fd8257392', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 6, 'created': '2014-03-17 08:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/63f8846f2e581c9e1196d75cb6ed2706c6e72363', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 7, 'created': '2014-03-25 06:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e62a4cef756dd21322df6b7afa200cd53a4d75d3', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 8, 'created': '2014-03-25 06:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cbe0d93d882f9759814a7ddbe46f96177370405e', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 9, 'created': '2014-03-25 08:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/92c7a59c41bb80fdd07b40729eda53e0e9004b84', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}, {'number': 10, 'created': '2014-03-25 10:12:09.000000000', 'files': ['glanceclient/common/http.py', 'tests/test_http.py', 'glanceclient/service_catalog.py', 'tests/test_service_catalog.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8f68ecacd977c9198260449bb6a4aa9b1e67a03f', 'message': ""Add service catalog support for Glance client\n\nNow glance client doesn't support service catalog\nso that we can't create glance client if the\nendpoint is None.\n\nThis commit adds service catalog support for glance client\nto make sure we can get endpoint from keystone if the endpoint\nis None when we try to create glance client.\n\nCloses-Bug: #1270049\n\nChange-Id: I99f5d4bf3f2247275adfac27076a005098728105\n""}]",43,67383,8f68ecacd977c9198260449bb6a4aa9b1e67a03f,67,7,10,8107,,,0,"Add service catalog support for Glance client

Now glance client doesn't support service catalog
so that we can't create glance client if the
endpoint is None.

This commit adds service catalog support for glance client
to make sure we can get endpoint from keystone if the endpoint
is None when we try to create glance client.

Closes-Bug: #1270049

Change-Id: I99f5d4bf3f2247275adfac27076a005098728105
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/83/67383/10 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/common/http.py', 'glanceclient/service_catalog.py']",2,ada8a02811216aeb329b111e407433f5ae29b475,master,"# Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import glanceclient.exc class ServiceCatalog(object): """"""Helper methods for dealing with a Keystone Service Catalog."""""" def __init__(self, resource_dict): self.catalog = resource_dict def get_token(self): return self.catalog['access']['token']['id'] def url_for(self, attr=None, filter_value=None, service_type=None, endpoint_type='publicURL', service_name=None): """"""Fetch the public URL from the Image service for a particular endpoint attribute. If none given, return the first. See tests for sample service catalog. """""" matching_endpoints = [] if 'endpoints' in self.catalog: # We have a bastardized service catalog. Treat it special. for endpoint in self.catalog['endpoints']: if not filter_value or endpoint[attr] == filter_value: matching_endpoints.append(endpoint) if not matching_endpoints: raise glanceclient.exc.EndpointNotFound() # We don't always get a service catalog back ... if 'serviceCatalog' not in self.catalog['access']: return None # Full catalog ... catalog = self.catalog['access']['serviceCatalog'] for service in catalog: # NOTE(thingee): For backwards compatibility, if they have v2 # enabled and the service_type is set to 'volume', go ahead and # accept that. if service.get(""type"") != service_type: continue endpoints = service['endpoints'] for endpoint in endpoints: if not filter_value or endpoint.get(attr) == filter_value: endpoint[""serviceName""] = service.get(""name"") matching_endpoints.append(endpoint) if not matching_endpoints: raise glanceclient.exc.EndpointNotFound() else: # NOTE(hweihu): This will return only one endpoint, until # keystone can return multiple endpoint with one service. dst_endpoints = [] for me in matching_endpoints: dst_endpoints.append(me[endpoint_type]) return dst_endpoints ",,180,10
openstack%2Fkolla~master~Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058,openstack/kolla,master,Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058,Force developers not to run build-docker-image as root,MERGED,2015-05-24 20:29:57.000000000,2015-05-27 01:01:38.000000000,2015-05-27 01:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 10419}, {'_account_id': 10428}, {'_account_id': 13039}, {'_account_id': 15697}]","[{'number': 1, 'created': '2015-05-24 20:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/848ba8003eb73291cf563cfe526115dea7db5b6e', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer to run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}, {'number': 2, 'created': '2015-05-24 21:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1d5b62d0bb293af82299b3399c9a1d545a2845f4', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}, {'number': 3, 'created': '2015-05-24 21:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2291d38de7c559e8f877c669a5b9dd00bdedc521', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}, {'number': 4, 'created': '2015-05-24 21:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/89fd85647f4ccb531086771ef4bf5cf80fd69299', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}, {'number': 5, 'created': '2015-05-26 17:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/967cd8c7a35a1e5cce9106e6ba847ad0189dacf4', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}, {'number': 6, 'created': '2015-05-26 17:46:14.000000000', 'files': ['tools/build-docker-image'], 'web_link': 'https://opendev.org/openstack/kolla/commit/751180ae013221ef8782e16c741ac6dc9c1fd5f0', 'message': 'Force developers not to run build-docker-image as root\n\nInstead recommend developer run build within the docker group.\nThis script is non-functional as the root user.\n\nChange-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058\n'}]",2,185282,751180ae013221ef8782e16c741ac6dc9c1fd5f0,25,6,6,2834,,,0,"Force developers not to run build-docker-image as root

Instead recommend developer run build within the docker group.
This script is non-functional as the root user.

Change-Id: Ib70ab55e5e9bc2e7b8639d5d5ffc32a2b8795058
",git fetch https://review.opendev.org/openstack/kolla refs/changes/82/185282/5 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-docker-image'],1,848ba8003eb73291cf563cfe526115dea7db5b6e,,"if [[ $EUID -eq 0 ]]; then echo ""This script must not be run as root. Instead add yourself to the docker group."" 1>&2 exit 1 fi ",,5,0
openstack%2Fhorizon~master~I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d,openstack/horizon,master,I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d,Bootstrap variable overrides should only be default values,MERGED,2015-05-20 19:28:21.000000000,2015-05-27 00:58:38.000000000,2015-05-27 00:58:37.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 13785}]","[{'number': 1, 'created': '2015-05-20 19:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c79f69cfac02ebbf1df5e9fd71a68d443cfb7a4f', 'message': 'static/dashboard/scss/_variables.scss:\n\nBootstrap variables overrides should only be default values to allow for skin variables to override properly\n\nChange-Id: I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d\nCloses-Bug: #1457188\n'}, {'number': 2, 'created': '2015-05-20 19:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8f1c46f7190bf998c56c5dabc5a5902fe5d02221', 'message': 'static/dashboard/scss/_variables.scss:\n\nBootstrap variables overrides should only be default values to allow\nfor skin variables to override properly\n\nChange-Id: I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d\nCloses-Bug: #1457188\n'}, {'number': 3, 'created': '2015-05-20 19:34:51.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/_variables.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/71d495f4aded416f6c4c7fb7ada1ef1426a5902f', 'message': ""Bootstrap variable overrides should only be default values\n\nIn openstack_dashboard/static/dashboard/scss/_variables.scss, the 4\nbootstrap variables 'overrides' should only be defaults to allow\nfor skinning.\n\nChange-Id: I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d\nCloses-Bug: #1457188\n""}]",0,184595,71d495f4aded416f6c4c7fb7ada1ef1426a5902f,15,5,3,11778,,,0,"Bootstrap variable overrides should only be default values

In openstack_dashboard/static/dashboard/scss/_variables.scss, the 4
bootstrap variables 'overrides' should only be defaults to allow
for skinning.

Change-Id: I88384f4fb75f4e8c3cf4d33ae89c73e8f04c7b1d
Closes-Bug: #1457188
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/184595/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/_variables.scss'],1,c79f69cfac02ebbf1df5e9fd71a68d443cfb7a4f,bug/1457188,"$icon-font-path: ""../../bootstrap/fonts/bootstrap/"" !default; $font-size-base: 13px !default; $modal-md: 732px !default; $gray-light: #cccccc !default;","$icon-font-path: ""../../bootstrap/fonts/bootstrap/""; $font-size-base: 13px; $modal-md: 732px; $gray-light: #cccccc;",4,4
openstack%2Fkolla~master~Ic9033d08784d67a2629b2f5c60fb9a4f6db53529,openstack/kolla,master,Ic9033d08784d67a2629b2f5c60fb9a4f6db53529,Use latest delorean repo location,MERGED,2015-05-24 19:56:13.000000000,2015-05-27 00:57:04.000000000,2015-05-27 00:57:03.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 10419}, {'_account_id': 10428}, {'_account_id': 13039}, {'_account_id': 15697}]","[{'number': 1, 'created': '2015-05-24 19:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/047fa4eec542599651e60bb5de1d80804d1e0f13', 'message': 'Use latest delorean repo location\n\nThe latest delorean repo location is needed instead of the ""rc2""\nlocation used prevoiusly.\n\nChange-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529\n'}, {'number': 2, 'created': '2015-05-24 21:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1733186e1a928a46e558ad2ba14bde48a43a49b5', 'message': 'Use latest delorean repo location\n\nThe latest delorean repo location is needed instead of the ""rc2""\nlocation used previously.\n\nChange-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529\n'}, {'number': 3, 'created': '2015-05-24 21:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a943a81bd1b2d4bbc760e05cbc1d5c54f40b3e41', 'message': 'Use latest delorean repo location\n\nThe latest delorean repo location is needed instead of the ""rc2""\nlocation used previously.\n\nAlso document what the repos do in the dockerfile.\n\nChange-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529\n'}, {'number': 4, 'created': '2015-05-26 17:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/95fc13a5f1805c5a45f81798dcd7abcd8e1e4548', 'message': 'Use latest delorean repo location\n\nThe latest delorean repo location is needed instead of the ""rc2""\nlocation used previously.\n\nAlso document what the repos do in the dockerfile.\n\nChange-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529\n'}, {'number': 5, 'created': '2015-05-26 17:46:14.000000000', 'files': ['docker/centos/binary/centos-binary-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/23370e52d432c73d331aef88eaf5a820dcff966d', 'message': 'Use latest delorean repo location\n\nThe latest delorean repo location is needed instead of the ""rc2""\nlocation used previously.\n\nAlso document what the repos do in the dockerfile.\n\nChange-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529\n'}]",4,185281,23370e52d432c73d331aef88eaf5a820dcff966d,21,6,5,2834,,,0,"Use latest delorean repo location

The latest delorean repo location is needed instead of the ""rc2""
location used previously.

Also document what the repos do in the dockerfile.

Change-Id: Ic9033d08784d67a2629b2f5c60fb9a4f6db53529
",git fetch https://review.opendev.org/openstack/kolla refs/changes/81/185281/5 && git format-patch -1 --stdout FETCH_HEAD,['docker/centos/binary/centos-binary-base/Dockerfile'],1,047fa4eec542599651e60bb5de1d80804d1e0f13,,RUN curl http://trunk.rdoproject.org/centos70/current/delorean.repo -o /etc/yum.repos.d/delorean-kilo.repo,RUN curl https://repos.fedorapeople.org/repos/openstack/openstack-trunk/epel-7/rc2/delorean-kilo.repo -o /etc/yum.repos.d/delorean-kilo.repo,1,1
openstack%2Fcinder~master~I883f387c8247e8d79da82016a624cef2180cde88,openstack/cinder,master,I883f387c8247e8d79da82016a624cef2180cde88,Switch to oslo_versionedobjects,MERGED,2015-03-02 01:13:01.000000000,2015-05-27 00:34:38.000000000,2015-05-14 00:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10263}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 10796}, {'_account_id': 11459}, {'_account_id': 11600}, {'_account_id': 11611}, {'_account_id': 11751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}]","[{'number': 1, 'created': '2015-03-02 01:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fa9b79a137aa6664cbbdbe38d7ee2e022b20d256', 'message': 'WIP: Switch to oslo_versionedobjects\n\nDepends-On: I43fd794f17d309f67e95dfe7e61507ef65c4af34\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 2, 'created': '2015-03-03 02:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd54c171590cc2dc4ae89e3a109555c6e95c711f', 'message': 'Switch to oslo_versionedobjects\n\nDepends-On: I43fd794f17d309f67e95dfe7e61507ef65c4af34\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 3, 'created': '2015-03-03 02:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e25baee9207e51d340d668a0d5c9631ac5678b4', 'message': 'Switch to oslo_versionedobjects\n\nDepends-On: I43fd794f17d309f67e95dfe7e61507ef65c4af34\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 4, 'created': '2015-03-03 02:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6bef53b2542848db0e4c257bb88535f61a0510c1', 'message': 'Switch to oslo_versionedobjects\n\nDepends-On: I43fd794f17d309f67e95dfe7e61507ef65c4af34\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 5, 'created': '2015-03-04 01:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ca583ceee608cc45fdc20d5eafa97c51d60a689', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 6, 'created': '2015-03-06 18:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3cc7026db40cf4305de552ef664d3848a6c6ee84', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 7, 'created': '2015-03-07 15:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/99b19d8e7f140dd904f46b7697c8f1a41c25efec', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 8, 'created': '2015-03-09 00:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/151910a6ec444fe7898c115fe5ed47545330d765', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 9, 'created': '2015-03-09 15:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/031048ee6a79b1c7edb1e4d922d54b24a3c8ed23', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 10, 'created': '2015-03-11 00:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7efdb1b2ac976dbeb8245e7d0a20d249487e1c0b', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 11, 'created': '2015-03-12 14:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d412e109404154e2c9af5aba65c681bdd26e67a', 'message': 'Switch to oslo_versionedobjects\n\nThe following patch switches the cinder objects internals\nto oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 12, 'created': '2015-03-16 16:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8cf00d9b87bbe3b8554b5e14d0f5455465df05c', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 13, 'created': '2015-03-16 16:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22a159acffa24cf02f649d6a85408feaf31046da', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 14, 'created': '2015-03-30 04:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7bd70e784a47a14213e51916c85ec221624d47d', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 15, 'created': '2015-03-30 15:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/99e3b037bf7887fe7a59105686cc2b9816e2d47e', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 16, 'created': '2015-03-30 16:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/656f6921c10c56f620cec464c259fa6c00526fdc', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 17, 'created': '2015-04-06 23:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9fdc192d5b8c612611611e3bf45401fdbb14d5f2', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 18, 'created': '2015-04-23 02:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e60f323d513290be8721642a348747def29bfe0', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 19, 'created': '2015-04-23 02:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5099a0c3cf455c6da59987b55e65fa788a624784', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 20, 'created': '2015-04-24 02:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6e87427a7ae5e74ce0895cd58ba2ab2d42fd08c1', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 21, 'created': '2015-04-24 15:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bcebe09c29a4f52346eb08a27e0af6b6684e4bc4', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 22, 'created': '2015-04-24 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/568830f66268ed763d1982ae055603d465576bcf', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 23, 'created': '2015-04-24 22:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a4584b4cc1122b5daec626d77aeb7ce27fa3db22', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 24, 'created': '2015-04-29 01:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/750457d38d3ae1f829c6bf59d2bcd23c53505b9b', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}, {'number': 25, 'created': '2015-05-13 15:37:12.000000000', 'files': ['cinder/volume/manager.py', 'cinder/objects/base.py', 'cinder/objects/fields.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/objects/test_fields.py', 'cinder/objects/snapshot.py', 'requirements.txt', 'cinder/objects/volume.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/exception.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4f63f7ff48c365e6cd1fe64630c92dafec41f0ce', 'message': 'Switch to oslo_versionedobjects\n\noslo_versionedobjects was not made available until very\nlate in the Kilo cycle (i.e. near the end of kilo-3).\nIn order to make progress on cinder objects, a fork of\nnova objects was made, so that proper trial and testing\ncould be done. The following patch makes the switch to\nuse oslo_versionedobjects.\n\nImplements: blueprint cinder-objects\nChange-Id: I883f387c8247e8d79da82016a624cef2180cde88\n'}]",13,160209,4f63f7ff48c365e6cd1fe64630c92dafec41f0ce,554,49,25,8247,,,0,"Switch to oslo_versionedobjects

oslo_versionedobjects was not made available until very
late in the Kilo cycle (i.e. near the end of kilo-3).
In order to make progress on cinder objects, a fork of
nova objects was made, so that proper trial and testing
could be done. The following patch makes the switch to
use oslo_versionedobjects.

Implements: blueprint cinder-objects
Change-Id: I883f387c8247e8d79da82016a624cef2180cde88
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/160209/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/objects/test_snapshot.py', 'requirements.txt', 'cinder/objects/base.py', 'cinder/objects/volume.py', 'cinder/objects/fields.py', 'cinder/tests/objects/test_objects.py', 'cinder/exception.py', 'cinder/tests/objects/test_fields.py', 'cinder/objects/snapshot.py', 'cinder/volume/api.py']",11,fa9b79a137aa6664cbbdbe38d7ee2e022b20d256,bp/cinder-objects, snapshot.destroy(context), snapshot.destroy(),61,2622
openstack%2Fkeystoneauth~master~Iacd08f1d0d5acf4cb15dfaf46b1296aab007879e,openstack/keystoneauth,master,Iacd08f1d0d5acf4cb15dfaf46b1296aab007879e,Remove oslo serialization dependency,MERGED,2015-05-26 05:14:44.000000000,2015-05-27 00:27:40.000000000,2015-05-27 00:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-26 05:14:44.000000000', 'files': ['keystoneauth/tests/unit/test_discovery.py', 'keystoneauth/tests/unit/test_session.py', 'keystoneauth/tests/unit/utils.py', 'keystoneauth/session.py', 'requirements.txt', 'keystoneauth/adapter.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/06575d3ca5ce26b503931f0e2cffb250b3f0b9f0', 'message': 'Remove oslo serialization dependency\n\nOslo.serialization has a number of dependencies include msgpack which we\nwant to avoid. We maintain a couple of conversions for convenience that\noslo serialization did for us.\n\nChange-Id: Iacd08f1d0d5acf4cb15dfaf46b1296aab007879e\n'}]",0,185497,06575d3ca5ce26b503931f0e2cffb250b3f0b9f0,7,3,1,7191,,,0,"Remove oslo serialization dependency

Oslo.serialization has a number of dependencies include msgpack which we
want to avoid. We maintain a couple of conversions for convenience that
oslo serialization did for us.

Change-Id: Iacd08f1d0d5acf4cb15dfaf46b1296aab007879e
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/97/185497/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth/tests/unit/test_discovery.py', 'keystoneauth/tests/unit/test_session.py', 'keystoneauth/tests/unit/utils.py', 'keystoneauth/session.py', 'requirements.txt', 'keystoneauth/adapter.py']",6,06575d3ca5ce26b503931f0e2cffb250b3f0b9f0,jsonutils, try: body = resp.json() except ValueError: body = None,from oslo_serialization import jsonutils body = None if resp.text: try: body = jsonutils.loads(resp.text) except ValueError: pass,54,38
openstack%2Fshade~master~If57531a72eb90ee7bc6e67905ddfd5bda9bb6f1b,openstack/shade,master,If57531a72eb90ee7bc6e67905ddfd5bda9bb6f1b,Always refresh glanceclient for tokens validity,MERGED,2015-05-26 23:12:31.000000000,2015-05-26 23:57:10.000000000,2015-05-26 23:57:10.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6609}, {'_account_id': 7069}, {'_account_id': 10035}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-26 23:12:31.000000000', 'files': ['shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/24385adb7a8829885f0172e0cd3607e5dba9a594', 'message': ""Always refresh glanceclient for tokens validity\n\nGlanceclient doesn't refresh tokens on its own. Work around this by\nalways making a new glanceclient with a potentialy new token if the\nexisting token is near expiration. This adds some overhead to our use of\nglance but that is preferable to having glanceclient break because its\ntoken has expired.\n\nChange-Id: If57531a72eb90ee7bc6e67905ddfd5bda9bb6f1b\n""}]",0,185782,24385adb7a8829885f0172e0cd3607e5dba9a594,11,7,1,4146,,,0,"Always refresh glanceclient for tokens validity

Glanceclient doesn't refresh tokens on its own. Work around this by
always making a new glanceclient with a potentialy new token if the
existing token is near expiration. This adds some overhead to our use of
glance but that is preferable to having glanceclient break because its
token has expired.

Change-Id: If57531a72eb90ee7bc6e67905ddfd5bda9bb6f1b
",git fetch https://review.opendev.org/openstack/shade refs/changes/82/185782/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,24385adb7a8829885f0172e0cd3607e5dba9a594,dont-cache-auth-tokens," # Note that glanceclient doesn't use keystoneclient sessions # which means that it won't make a new token if the old one has # expired. Work around that by always making a new glanceclient here # which may create a new token if the current one is close to # expiration. token = self.auth_token endpoint = self.get_session_endpoint('image') glance_api_version = self._get_glance_api_version() kwargs = dict() if self.api_timeout is not None: kwargs['timeout'] = self.api_timeout try: self._glance_client = glanceclient.Client( glance_api_version, endpoint, token=token, session=self.keystone_session, **kwargs) except Exception as e: self.log.debug(""glance unknown issue"", exc_info=True) raise OpenStackCloudException( ""Error in connecting to glance: %s"" % str(e)) if not self._glance_client: raise OpenStackCloudException(""Error connecting to glance"")"," if self._glance_client is None: token = self.auth_token endpoint = self.get_session_endpoint('image') glance_api_version = self._get_glance_api_version() kwargs = dict() if self.api_timeout is not None: kwargs['timeout'] = self.api_timeout try: self._glance_client = glanceclient.Client( glance_api_version, endpoint, token=token, session=self.keystone_session, **kwargs) except Exception as e: self.log.debug(""glance unknown issue"", exc_info=True) raise OpenStackCloudException( ""Error in connecting to glance: %s"" % str(e)) if not self._glance_client: raise OpenStackCloudException(""Error connecting to glance"")",22,18
openstack%2Fshade~master~I23f90b6292f32ce9cef962bdc641c291e4d2fe4d,openstack/shade,master,I23f90b6292f32ce9cef962bdc641c291e4d2fe4d,Don't cache keystone tokens as KSC does it for us,MERGED,2015-05-26 23:12:31.000000000,2015-05-26 23:57:09.000000000,2015-05-26 23:57:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6609}, {'_account_id': 7069}, {'_account_id': 10035}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-26 23:12:31.000000000', 'files': ['shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/be3ddcd09b7713d3651020d87a9d3295a007efd8', 'message': ""Don't cache keystone tokens as KSC does it for us\n\nWe don't need to keep track of what our current valid keystone token is\nbecauase keystone client does it for us. Instead defer to\nksc.session.get_token() to either reuse a valid token or make a new one\nfor us if necessary.\n\nChange-Id: I23f90b6292f32ce9cef962bdc641c291e4d2fe4d\n""}]",0,185781,be3ddcd09b7713d3651020d87a9d3295a007efd8,10,6,1,4146,,,0,"Don't cache keystone tokens as KSC does it for us

We don't need to keep track of what our current valid keystone token is
becauase keystone client does it for us. Instead defer to
ksc.session.get_token() to either reuse a valid token or make a new one
for us if necessary.

Change-Id: I23f90b6292f32ce9cef962bdc641c291e4d2fe4d
",git fetch https://review.opendev.org/openstack/shade refs/changes/81/185781/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,be3ddcd09b7713d3651020d87a9d3295a007efd8,dont-cache-auth-tokens," # Keystone's session will reuse a token if it is still valid. # We don't need to track validity here, just get_token() each time. return self.keystone_session.get_token() # Ironic can operate in no keystone mode. Signify this with a # token of None. return None else: # Keystone's session will reuse a token if it is still valid. # We don't need to track validity here, just get_token() each time. return self.keystone_session.get_token()", self._auth_token = None if not self._auth_token: self._auth_token = self.keystone_session.get_token() return self._auth_token return self._auth_token if not self._auth_token: self._auth_token = self.keystone_session.get_token() return self._auth_token,10,8
openstack%2Fcinder~master~Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba,openstack/cinder,master,Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba,Check volume_backend in retype,MERGED,2015-05-11 20:03:05.000000000,2015-05-26 23:46:19.000000000,2015-05-20 16:37:41.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 7219}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13900}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16160}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-11 20:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ebcc87b40114cc7898480b27790e165f86f64169', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 2, 'created': '2015-05-11 20:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a279efa1a6988e901068c36a02d8e7fd2d557e89', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 3, 'created': '2015-05-11 22:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/95bced97b9b821515c9819d4a94e89a0d095a684', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nThis introduces a new hosts_are_equivalent method in\ncinder.volume.utils\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 4, 'created': '2015-05-12 01:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/36cac3ea890265237a3aef9264a8d07158650198', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nThis introduces a new hosts_are_equivalent method in\ncinder.volume.utils\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 5, 'created': '2015-05-12 13:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/91c96d9ba5a077f23831279cdf99ab16bdfcac3f', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True. I think this is ""ok"" for the drivers to do,\ndrivers should be allowed to be somewhat dumb WRT Cinder\nstate management and placement info.  If we give them an\ninvalid command (which we\'re doing here) then it\'s on us\nhigher up the chain IMO.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nThis introduces a new hosts_are_equivalent method in\ncinder.volume.utils\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 6, 'created': '2015-05-12 15:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14aa3c7539b342677ddadda11dc014aaee8b6492', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True. I think this is ""ok"" for the drivers to do,\ndrivers should be allowed to be somewhat dumb WRT Cinder\nstate management and placement info.  If we give them an\ninvalid command (which we\'re doing here) then it\'s on us\nhigher up the chain IMO.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nThis introduces a new hosts_are_equivalent method in\ncinder.volume.utils\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}, {'number': 7, 'created': '2015-05-13 01:36:16.000000000', 'files': ['cinder/volume/utils.py', 'cinder/volume/manager.py', 'cinder/tests/unit/test_volume_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bbb83aff023c90cfc186459603320ad3c622a40b', 'message': 'Check volume_backend in retype\n\nThe retype command will always attempt a call\nto the driver.retype method.  In *most* cases this\nwill hit the default impl which returns False because\nmost drivers don\'t implement any retype (most, a few do).\n\nThe problem is that the drivers that do implement this in\nmost cases will iterate through the settings and just make\nthe changes that are valid and ignore the rest, and then\nreturn True. I think this is ""ok"" for the drivers to do,\ndrivers should be allowed to be somewhat dumb WRT Cinder\nstate management and placement info.  If we give them an\ninvalid command (which we\'re doing here) then it\'s on us\nhigher up the chain IMO.\n\nThe result is that for example if you\'re trying to retype\nfrom backend-a to backend-b and backend-a implements retype\nit can return True telling the manager that the volume was\nsuccesfully retyped, even when it wasn\'t.\n\nThere\'s a lot of confusion around this bug, YES the\nfilter scheduler is used to determine if the retype is\nvalid and to what host.  That\'s not the issue, the issue\nis that regardless of the source and destination host settings\nthat are provided from the filter-scheduler, we always make the\ncall to the driver, introducing the opportunity for a false\nsuccess status being reported back.\n\nThis patch adds a very simple check between the source and\ndestination host settings as provided by the scheduler and in\nthe case that the two are ""different""(not including pool designations)\nwe skip calling the driver.retype method altogether and fall through\nto the migrate process.\n\nThis introduces a new hosts_are_equivalent method in\ncinder.volume.utils\n\nChange-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba\nCloses-Bug: #1452823\n'}]",20,182055,bbb83aff023c90cfc186459603320ad3c622a40b,128,31,7,2243,,,0,"Check volume_backend in retype

The retype command will always attempt a call
to the driver.retype method.  In *most* cases this
will hit the default impl which returns False because
most drivers don't implement any retype (most, a few do).

The problem is that the drivers that do implement this in
most cases will iterate through the settings and just make
the changes that are valid and ignore the rest, and then
return True. I think this is ""ok"" for the drivers to do,
drivers should be allowed to be somewhat dumb WRT Cinder
state management and placement info.  If we give them an
invalid command (which we're doing here) then it's on us
higher up the chain IMO.

The result is that for example if you're trying to retype
from backend-a to backend-b and backend-a implements retype
it can return True telling the manager that the volume was
succesfully retyped, even when it wasn't.

There's a lot of confusion around this bug, YES the
filter scheduler is used to determine if the retype is
valid and to what host.  That's not the issue, the issue
is that regardless of the source and destination host settings
that are provided from the filter-scheduler, we always make the
call to the driver, introducing the opportunity for a false
success status being reported back.

This patch adds a very simple check between the source and
destination host settings as provided by the scheduler and in
the case that the two are ""different""(not including pool designations)
we skip calling the driver.retype method altogether and fall through
to the migrate process.

This introduces a new hosts_are_equivalent method in
cinder.volume.utils

Change-Id: Idfd7dfa2284fcea66cf23c4273efda61ee8f7eba
Closes-Bug: #1452823
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/182055/6 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,ebcc87b40114cc7898480b27790e165f86f64169,bug/1452823," # NOTE(jdg): Check to see if the destination host is the same # as the current. If it's not don't call the driver.retype # method, otherwise drivers that implement retype may report # success, but it's invalid in the case of a migrate. # We assume that those that support pools do this internally # so we strip off the pools designation if (not retyped and (self.driver.host.split('#', 1)[0] in host['host'].split('#', 1)[0])):", if not retyped:,11,1
openstack%2Fopenstack-ansible~master~I4cabbb0c620933a4e26e0172820ad0c728f544ff,openstack/openstack-ansible,master,I4cabbb0c620933a4e26e0172820ad0c728f544ff,Update documentation in the swift config file,MERGED,2015-05-11 18:53:58.000000000,2015-05-26 23:36:53.000000000,2015-05-26 23:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 9515}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-05-11 18:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/733cf26fb9fc5fe923a857cda4b88df9e6450c54', 'message': 'Update documentation in the swift configuration file\n\nChange-Id: I4cabbb0c620933a4e26e0172820ad0c728f544ff\n'}, {'number': 2, 'created': '2015-05-11 19:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7e075c584fa7a082fe5adf46cc111e0dbe7fe91b', 'message': 'Update documentation in the swift configuration file\n\nChange-Id: I4cabbb0c620933a4e26e0172820ad0c728f544ff\n'}, {'number': 3, 'created': '2015-05-14 16:26:12.000000000', 'files': ['etc/openstack_deploy/conf.d/swift.yml.example'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c64418d2f4dbf7bf6b813da13e882450f329af1a', 'message': 'Update documentation in the swift config file\n\nChange-Id: I4cabbb0c620933a4e26e0172820ad0c728f544ff\n'}]",0,182013,c64418d2f4dbf7bf6b813da13e882450f329af1a,18,6,3,9515,,,0,"Update documentation in the swift config file

Change-Id: I4cabbb0c620933a4e26e0172820ad0c728f544ff
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/182013/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/openstack_deploy/conf.d/swift.yml.example'],1,733cf26fb9fc5fe923a857cda4b88df9e6450c54,configdoc2,"# You can customize the options in this file and copy it to # /etc/openstack_deploy/openstack_user_config.yml or create a new # file containing only necessary options for your environment # before deployment. # # OpenStack Ansible Deployment (OSAD) implements PyYAML to parse YAML files # and therefore supports structure and formatting options that augment # traditional YAML. For more information on PyYAML, see the documentation at # # http://pyyaml.org/wiki/PyYAMLDocumentation# Level: global_overrides (required) # Contains global options that require customization for a deployment. For # example, the ring stricture. This level also provides a mechanism to # override other options defined in the playbook structure.# Level: swift (required) # Contains options for swift.# Option: storage_network (required, string) # Name of the storage network bridge on target hosts. Typically # 'br-storage'.# Option: repl_network (optional, string) # Name of the replication network bridge on target hosts. Typically # 'br-repl'. Defaults to the value of the 'storage_network' option.# Option: part_power (required, integer) # Partition power. Applies to all rings unless overridden at the 'account' # or 'container' levels or within a policy in the 'storage_policies' level. # Immutable without rebuilding the rings.# Option: repl_number (optional, integer) # Number of replicas for each partition. Applies to all rings unless # overridden at the 'account' or 'container' levels or within a policy # in the 'storage_policies' level. Defaults to 3.# Option: min_part_hours (optional, integer) # Minimum time in hours between multiple moves of the same partition. # Applies to all rings unless overridden at the 'account' or 'container' # levels or within a policy in the 'storage_policies' level. Defaults # to 1.# Option: region (optional, integer) # Region of a disk. Applies to all disks in all storage hosts unless # overridden deeper in the structure. Defaults to 1.# Option: zone (optional, integer) # Zone of a disk. Applies to all disks in all storage hosts unless # overridden deeper in the structure. Defaults to 0.# Option: weight (optional, integer) # Weight of a disk. Applies to all disks in all storage hosts unless # overridden deeper in the structure. Defaults to 100.# Example:# Define a typical deployment:# - Storage network that uses the 'br-storage' bridge. Proxy containers # typically use the 'storage' IP address pool. However, storage hosts # use bare metal and require manual configuration of the 'br-storage' # bridge on each host. # - Replication network that uses the 'br-repl' bridge. Only storage hosts # contain this network. Storage hosts use bare metal and require manual # configuration of the bridge on each host. # - Ring configuration with partition power of 8, three replicas of each # file, and minimum 1 hour between migrations of the same partition. All # rings use region 1 and zone 0. All disks include a weight of 100.# # Note: Most typical deployments override the 'zone' option in the # 'swift_vars' level to use a unique zone for each storage host. # # Option: mount_point (required, string) # Top-level directory for mount points of disks. Defaults to /mnt. # Applies to all hosts unless overridden deeper in the structure. # # Level: drives (required) # Contains the mount points of disks. # Applies to all hosts unless overridden deeper in the structure. # # Option: name (required, string) # Mount point of a disk. Use one entry for each disk. # Applies to all hosts unless overridden deeper in the structure. # # Example: # # Mount disks 'sdc', 'sdd', 'sde', and 'sdf' to the '/mnt' directory on all # storage hosts: ## Level: account (optional) # Contains 'min_part_hours' and 'repl_number' options specific to the # account ring. # # Level: container (optional) # Contains 'min_part_hours' and 'repl_number' options specific to the # container ring. # # Level: storage_policies (required) # Contains storage policies. Minimum one policy. One policy must include # the 'index: 0' and 'default: True' options. # # Level: policy (required) # Contains a storage policy. Define for each policy. # # Option: name (required, string) # Policy name. # # Option: index (required, integer) # Policy index. One policy must include this option with a '0' # value. # # Option: policy_type (optional, string) # Defines policy as replication or erasure coding. Accepts 'replication' # 'erasure_coding' values. Defaults to 'replication' value if omitted. # # Option: ec_type (conditionally required, string) # Defines the erasure coding algorithm. Required for erasure coding # policies. # # Option: ec_num_data_fragments (conditionally required, integer) # Defines the number of object data fragments. Required for erasure # coding policies. # # Option: ec_num_parity_fragments (conditionally required, integer) # Defines the number of object parity fragments. Required for erasure # coding policies. # # Option: ec_object_segment_size (conditionally required, integer) # Defines the size of object segments in bytes. Swift sends incoming # objects to an erasure coding policy in segments of this size. # Required for erasure coding policies. # # Option: default (conditionally required, boolean) # Defines the default policy. One policy must include this option # with a 'True' value. # # Option: deprecated (optional, boolean) # Defines a deprecated policy. # # Note: The following levels and options override any values higher # in the structure and generally apply to advanced deployments. # # Option: repl_number (optional, integer) # Number of replicas of each partition in this policy. # # Option: min_part_hours (optional, integer) # Minimum time in hours between multiple moves of the same partition # in this policy. # # Example: # # Define three storage policies: A default 'gold' policy, a deprecated # 'silver' policy, and an erasure coding 'ec10-4' policy. # # storage_policies: # - policy: # name: gold # index: 0 # default: True # - policy: # name: silver # index: 1 # repl_number: 3 # deprecated: True # - policy: # name: ec10-4 # index: 2 # policy_type: erasure_coding # ec_type: jerasure_rs_vand # ec_num_data_fragments: 10 # ec_num_parity_fragments: 4 # ec_object_segment_size: 1048576 # # -------- # # Level: swift_proxy-hosts (required) # List of target hosts on which to deploy the swift proxy service. Recommend # three minimum target hosts for these services. Typically contains the same # target hosts as the 'shared-infra_hosts' level in complete OpenStack # deployments. # # Level: <value> (optional, string) # Name of a proxy host. # # Option: ip (required, string) # IP address of this target host, typically the IP address assigned to # the management bridge. # # Example: # # Define three swift proxy hosts: # # swift_proxy-hosts: # # infra1: # ip: 172.29.236.101 # infra2: # ip: 172.29.236.102 # infra3: # ip: 172.29.236.103 # # -------- # # Level: swift_hosts (required) # List of target hosts on which to deploy the swift storage services. # Recommend three minimum target hosts for these services. # # Level: <value> (required, string) # Name of a storage host. # # Option: ip (required, string) # IP address of this target host, typically the IP address assigned to # the management bridge. # # Note: The following levels and options override any values higher # in the structure and generally apply to advanced deployments. # # Level: container_vars (optional) # Contains options for this target host. # # Level: swift_vars (optional) # Contains swift options for this target host. Typical deployments # use this level to define a unique zone for each storage host. # # Option: storage_ip (optional, string) # IP address to use for accessing the account, container, and object # services if different than the IP address of the storage network # bridge on the target host. Also requires manual configuration of # the host. # # Option: repl_ip (optional, string) # IP address to use for replication services if different than the IP # address of the replication network bridge on the target host. Also # requires manual configuration of the host. # # Option: region (optional, integer) # Region of all disks. # # Option: zone (optional, integer) # Zone of all disks. # # Option: weight (optional, integer) # Weight of all disks. # # Level: groups (optional) # List of one of more Ansible groups that apply to this host. # # Example: # # Deploy the account ring, container ring, and 'silver' policy. # # groups: # - account # - container # - silver # # Level: drives (optional) # Contains the mount points of disks specific to this host. # # Level or option: name (optional, string) # Mount point of a disk specific to this host. Use one entry for # each disk. Functions as a level for disks that contain additional # options. # # Option: storage_ip (optional, string) # IP address to use for accessing the account, container, and object # services of a disk if different than the IP address of the storage # network bridge on the target host. Also requires manual # configuration of the host. # # Option: repl_ip (optional, string) # IP address to use for replication services of a disk if different # than the IP address of the replication network bridge on the target # host. Also requires manual configuration of the host. # # Option: region (optional, integer) # Region of a disk. # # Option: zone (optional, integer) # Zone of a disk. # # Option: weight (optional, integer) # Weight of a disk. # # Level: groups (optional) # List of one or more Ansible groups that apply to this disk. # # Example: # # Define four storage hosts. The first three hosts contain typical options # and the last host contains advanced options. ## ip: 172.29.236.151 # container_vars: # swift_vars: # zone: 0 # swift-node2: # ip: 172.29.236.152 # container_vars: # swift_vars: # zone: 1 # swift-node3: # ip: 172.29.236.153 # container_vars: # swift_vars: # zone: 2 # swift-node4: # ip: 172.29.236.154# storage_ip: 198.51.100.11 # repl_ip: 203.0.113.11 # region: 2 # zone: 0# - name: sdc # storage_ip: 198.51.100.21 # repl_ip: 203.0.113.21","# The hierarchical structure of this file supports overrides for most # options. However, for typical deployments, defining options closest # to the top level provides a functional configuration.# Level: swift (required) # Contains global options.# Option: storage_network (optional, string) # Network to use for object storage operations. Defaults to the management # network if omitted. # If using a storage network, specify the network bridge containing it, # typically 'br-storage'.# Option: repl_network (optional, string) # Network to use for object replication operations. Defaults to the # 'storage_network' value if omitted. # If using a replication network, specify the network bridge containing it, # typically 'br-repl'.# Option: part_power (required, integer) # Partition power. Immutable without rebuilding the rings. # Applies to all rings unless overridden at the 'account' or 'container' # levels or within a policy under the 'storage_policies' level.# Option: repl_number (optional, integer) # Number of replicas for each partition. Defaults to 3. # Applies to all rings unless overridden at the 'account' or 'container' # levels or within a policy under the 'storage_policies' level.# Option: min_part_hours (optional, integer) # Minimum time in hours between multiple moves of the same partition. # Defaults to 1. # Applies to all rings unless overridden at the 'account' or 'container' # levels or within a policy under the 'storage_policies' level.# Option: region (optional, integer) # Region of a disk. Defaults to 1. # Applies to all disks in all hosts unless overridden deeper in the # structure.# Option: zone (optional, integer) # Zone of a disk. Defaults to 0. # Applies to all disks in all hosts unless overridden deeper in the # structure.# Option: weight (optional, integer) # Weight of a disk. Defaults to 100. # Applies to all disks in all hosts unless overridden deeper in the # structure.# Option: mount_point (required, string) # Top-level directory for mount points of disks. Defaults to /mnt. # Applies to all hosts unless overridden deeper in the structure.# Level: drives (required) # Contains the mount points of disks. # Applies to all hosts unless overridden deeper in the structure.# Option: name (required, string) # Mount point of a disk. Use one entry for each disk. # Applies to all hosts unless overridden deeper in the structure.# The following example shows disks mounted at /mnt/sda and /mnt/sdb # on all storage hosts: # mount_point: /mnt # drives: # - name: sda # - name: sdb# Level: account (optional) # Contains 'min_part_hours' and 'repl_number' options specific to the # account ring. # # Level: container (optional) # Contains 'min_part_hours' and 'repl_number' options specific to the # container ring. # # Level: storage_policies (required) # Contains storage policies. Minimum one policy. One policy must include # the 'index: 0' and 'default: True' options. # # Level: policy (required) # Contains a storage policy. # # Option: name (required, string) # Policy name. # # Option: index (required, integer) # Policy index. One policy must include this option with a '0' # value. # # Option: policy_type (optional, string) # Policy type. Defines if this type of policy, possible values: # - replication (default); or # - erasure_coding # # Option: ec_type (optional, string) # Defines the erasure code algorithm to use. This option is required # when policy_type == erasure_coding. # # Option: ec_num_data_fragments (optional, integer) # Defines the number of data fragments to break object into. This # option is required when policy_type == erasure_coding. # # Option: ec_num_parity_fragments (optional, integer) # Defines the number of parity fragments to break object into. This # option is required when policy_type == erasure_coding. # # Option: ec_object_segment_size (optional, integer) # Defines the segment size (btyes). Swift will send the incoming object # data a segment size at a time in to the erasure code encoder. # This option is required when policy_type == erasure_coding. # # Option: default (optional, boolean) # Defines the default policy. One policy must include this option # with a 'True' value. # # Option: deprecated (optional, boolean) # Defines a deprecated policy. # # Note: The following levels and options override any values higher # in the structure and generally apply to advanced deployments. # # Option: repl_number (optional, integer) # Number of replicas of each partition in this policy. # # Option: min_part_hours (optional, integer) # Minimum time between multiple moves of the same partition in this # policy. # # Level: swift_proxy-hosts (required) # Contains definitions for proxy hosts. # # Level: <value> (optional, string) # Name of a proxy host. Typical deployments require at least three # proxy hosts. # # Option: ip (required, string) # IP address of the host. # # Level: swift_hosts (required) # Contains definitions for storage hosts. # # Level: <value> (required, string) # Name of a storage host. Typical deployments require at least three # storage hosts. # # Option: ip (required, string) # IP address of the host. # # Note: The following levels and options override any values higher # in the structure and generally apply to advanced deployments. # # Level: container_vars (optional) # Contains options specific to this host. # # Level: swift_vars (optional) # Contains swift options specific to this host. # # Option: region (optional, integer) # Region of all disks in this host. # # Option: zone (optional, integer) # Zone of all disks in this host. # # Option: weight (optional, integer) # Weight of all disks in this host. # # Level: groups (optional) # Contains groups specific to this host. # The following example shows a storage host with the account ring, # container ring, and 'silver' storage policy: # groups: # - account # - container # - silver # # Level: drives (optional) # Contains the mount points of disks specific to this host. # # Level or option: name (optional, string) # Mount point of a disk specific to this host. Use one entry for # each disk. Functions as a level for disks that contain additional # options. # # Option: region (optional, integer) # Region of a disk in this host. # # Option: zone (optional, integer) # Zone of a disk in this host. # # Option: weight (optional, integer) # Weight of a disk in this host. # # Level: groups (optional) # Contains groups for a disk in this host. # The following example shows a disk with the account ring, # container ring, and 'silver' storage policy: # groups: # - account # - container # - silver # Default (example) configuration # =============================== # Global options # global_overrides:# account: # container: # storage_policies: # - policy: # name: gold # index: 0 # default: True # - policy: # name: silver # index: 1 # repl_number: 3 # deprecated: True # - policy: # name: ec10-4 # index: 2 # policy_type: erasure_coding # ec_type: jerasure_rs_vand # ec_num_data_fragments: 10 # ec_num_parity_fragments: 4 # ec_object_segment_size: 1048576 # Proxy hosts # swift-proxy_hosts: # infra-node1: # ip: 192.0.2.1 # infra-node2: # ip: 192.0.2.2 # infra-node3: # ip: 192.0.2.3 # Storage hosts# The first three hosts contain options for typical deployments. Hosts # four and five show options for more advanced deployments. # ip: 192.0.2.4 # swift-node2: # ip: 192.0.2.5 # swift-node3: # ip: 192.0.2.6 # swift-node4: # ip: 192.0.2.7# zone: 3 # swift-node5: # ip: 192.0.2.8 # container_vars: # swift_vars: # storage_ip: 198.51.100.8 # repl_ip: 203.0.113.8 # region: 3 # zone: 4# - name: sdb # storage_ip: 198.51.100.9 # repl_ip: 203.0.113.9# - name: sdc",300,247
openstack%2Fswift~master~Ic658a199e952558db329268f4d7b4009f47c6d03,openstack/swift,master,Ic658a199e952558db329268f4d7b4009f47c6d03,EC: don't 503 on marginally-successful PUT,MERGED,2015-05-06 23:35:59.000000000,2015-05-26 23:16:29.000000000,2015-05-26 23:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 14619}, {'_account_id': 14967}, {'_account_id': 16206}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-06 23:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ce92005ec7c55da8f7052e00215a1a4ce8dad310', 'message': 'EC: don\'t 503 on marginally-successful PUT\n\nOn EC PUT in an M+K scheme, we require M+1 fragment archives to\ndurably land on disk. If we get that, then we go ahead and ask the\nobject servers to ""commit"" the object by writing out .durable\nfiles. We only require 2 of those.\n\nWhen we got exactly M+1 fragment archives on disk, and then one\nconnection timed out while writing .durable files, we should still be\nokay (provided M is at least 3). However, we\'d take our M > 2\nremaining successful responses and pass that off to best_response()\nwith a quorum size of M+1, thus getting a 503 even though everything\nworked well enough.\n\nNow we pass 2 to best_response() to avoid that false negative.\n\nChange-Id: Ic658a199e952558db329268f4d7b4009f47c6d03\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: 1452468\n'}, {'number': 2, 'created': '2015-05-06 23:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/90ff92872dc33a77f9f9e40154f8eff09236c5ab', 'message': 'EC: don\'t 503 on marginally-successful PUT\n\nOn EC PUT in an M+K scheme, we require M+1 fragment archives to\ndurably land on disk. If we get that, then we go ahead and ask the\nobject servers to ""commit"" the object by writing out .durable\nfiles. We only require 2 of those.\n\nWhen we got exactly M+1 fragment archives on disk, and then one\nconnection timed out while writing .durable files, we should still be\nokay (provided M is at least 3). However, we\'d take our M > 2\nremaining successful responses and pass that off to best_response()\nwith a quorum size of M+1, thus getting a 503 even though everything\nworked well enough.\n\nNow we pass 2 to best_response() to avoid that false negative.\n\nChange-Id: Ic658a199e952558db329268f4d7b4009f47c6d03\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: 1452468\n'}, {'number': 3, 'created': '2015-05-08 00:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c1eedbece1c34851b0a5ab5b9c081e6b1d715222', 'message': 'EC: don\'t 503 on marginally-successful PUT\n\nOn EC PUT in an M+K scheme, we require M+1 fragment archives to\ndurably land on disk. If we get that, then we go ahead and ask the\nobject servers to ""commit"" the object by writing out .durable\nfiles. We only require 2 of those.\n\nWhen we got exactly M+1 fragment archives on disk, and then one\nconnection timed out while writing .durable files, we should still be\nokay (provided M is at least 3). However, we\'d take our M > 2\nremaining successful responses and pass that off to best_response()\nwith a quorum size of M+1, thus getting a 503 even though everything\nworked well enough.\n\nNow we pass 2 to best_response() to avoid that false negative.\n\nThere was also a spot where we were getting the quorum size wrong. If\nwe wrote out 3 fragment archives for a 2+1 policy, we were only\nrequiring 2 successful backend PUTs. That\'s wrong; the right number is\n3, which is what the policy\'s .quorum() method says. There was a spot\nwhere the right number wasn\'t getting plumbed through, but it is now.\n\nChange-Id: Ic658a199e952558db329268f4d7b4009f47c6d03\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: 1452468\n'}, {'number': 4, 'created': '2015-05-26 18:39:16.000000000', 'files': ['test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/666bf06c26bc9e0d6256d054835386e50e67b8a2', 'message': 'EC: don\'t 503 on marginally-successful PUT\n\nOn EC PUT in an M+K scheme, we require M+1 fragment archives to\ndurably land on disk. If we get that, then we go ahead and ask the\nobject servers to ""commit"" the object by writing out .durable\nfiles. We only require 2 of those.\n\nWhen we got exactly M+1 fragment archives on disk, and then one\nconnection timed out while writing .durable files, we should still be\nokay (provided M is at least 3). However, we\'d take our M > 2\nremaining successful responses and pass that off to best_response()\nwith a quorum size of M+1, thus getting a 503 even though everything\nworked well enough.\n\nNow we pass 2 to best_response() to avoid that false negative.\n\nThere was also a spot where we were getting the quorum size wrong. If\nwe wrote out 3 fragment archives for a 2+1 policy, we were only\nrequiring 2 successful backend PUTs. That\'s wrong; the right number is\n3, which is what the policy\'s .quorum() method says. There was a spot\nwhere the right number wasn\'t getting plumbed through, but it is now.\n\nChange-Id: Ic658a199e952558db329268f4d7b4009f47c6d03\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: 1452468\n'}]",6,180795,666bf06c26bc9e0d6256d054835386e50e67b8a2,31,13,4,2622,,,0,"EC: don't 503 on marginally-successful PUT

On EC PUT in an M+K scheme, we require M+1 fragment archives to
durably land on disk. If we get that, then we go ahead and ask the
object servers to ""commit"" the object by writing out .durable
files. We only require 2 of those.

When we got exactly M+1 fragment archives on disk, and then one
connection timed out while writing .durable files, we should still be
okay (provided M is at least 3). However, we'd take our M > 2
remaining successful responses and pass that off to best_response()
with a quorum size of M+1, thus getting a 503 even though everything
worked well enough.

Now we pass 2 to best_response() to avoid that false negative.

There was also a spot where we were getting the quorum size wrong. If
we wrote out 3 fragment archives for a 2+1 policy, we were only
requiring 2 successful backend PUTs. That's wrong; the right number is
3, which is what the policy's .quorum() method says. There was a spot
where the right number wasn't getting plumbed through, but it is now.

Change-Id: Ic658a199e952558db329268f4d7b4009f47c6d03
Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
Closes-Bug: 1452468
",git fetch https://review.opendev.org/openstack/swift refs/changes/95/180795/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py']",3,ce92005ec7c55da8f7052e00215a1a4ce8dad310,bug/1452468," # The .durable file will propagate in a replicated fashion; if # one exists, the reconstructor will spread it around. Thus, we # don't require as many .durable files to be successfully # written as we do fragment archives in order to call the PUT a # success. min_conns = 2 final_phase, min_conns,"," min_resp = 2 final_phase, min_resp,",107,35
openstack%2Fceilometer~stable%2Fkilo~Ieffa3fddc3c8d3152742455ca46d69bcc7208d69,openstack/ceilometer,stable/kilo,Ieffa3fddc3c8d3152742455ca46d69bcc7208d69,Update a test to properly anticipate HTTP 405 for RestController,MERGED,2015-05-26 18:05:57.000000000,2015-05-26 23:15:29.000000000,2015-05-26 23:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2109}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 8005}, {'_account_id': 8470}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-05-26 18:05:57.000000000', 'files': ['ceilometer/tests/gabbi/gabbits/meters.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/76dc5d8279e88880e06bb157d4143354bdf36b88', 'message': 'Update a test to properly anticipate HTTP 405 for RestController\n\nThe behavior of RestController is changing (to be more correct):\nhttps://review.openstack.org/#/c/181979.  Until this change hits PyPI and\nglobal-requirements, ceilometer should accept both the old and new behavior as\nvalid.\n\nChange-Id: Ieffa3fddc3c8d3152742455ca46d69bcc7208d69\nCloses-bug: #1450109\n(cherry picked from commit f59da0da65c0e5e32e959e9d654763e1ae35df87)\n'}]",0,185685,76dc5d8279e88880e06bb157d4143354bdf36b88,5,8,1,8005,,,0,"Update a test to properly anticipate HTTP 405 for RestController

The behavior of RestController is changing (to be more correct):
https://review.openstack.org/#/c/181979.  Until this change hits PyPI and
global-requirements, ceilometer should accept both the old and new behavior as
valid.

Change-Id: Ieffa3fddc3c8d3152742455ca46d69bcc7208d69
Closes-bug: #1450109
(cherry picked from commit f59da0da65c0e5e32e959e9d654763e1ae35df87)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/185685/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/gabbi/gabbits/meters.yaml'],1,76dc5d8279e88880e06bb157d4143354bdf36b88,," status: ""404 || 405""", status: 404,1,1
openstack%2Foslo-incubator~master~I271debac1e05a353f9876ced77970e6030912111,openstack/oslo-incubator,master,I271debac1e05a353f9876ced77970e6030912111,Remove local module,MERGED,2015-05-20 21:27:15.000000000,2015-05-26 23:14:43.000000000,2015-05-26 23:14:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-20 21:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/694068ff10d8ef2eb352a2d9333f339950c3c2a1', 'message': 'Remove local module\n\nPer discussion at the oslo graduation working session at the 2015\nVancouver Summit, remove the local module as it is deprecated and no\nlonger necessary.\n\nSee also: https://etherpad.openstack.org/p/YVR-oslo-graduation-schedule\n\nChange-Id: I271debac1e05a353f9876ced77970e6030912111\n'}, {'number': 2, 'created': '2015-05-20 21:44:25.000000000', 'files': ['tests/unit/test_local.py', 'openstack/common/local.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/06573d1181e6702bdd07acf5d410ef1078d13840', 'message': 'Remove local module\n\nPer discussion at the oslo graduation working session at the 2015\nVancouver Summit, remove the local module as it is deprecated and no\nlonger necessary.\n\nSee also: https://etherpad.openstack.org/p/YVR-oslo-graduation-schedule\n\nChange-Id: I271debac1e05a353f9876ced77970e6030912111\n'}]",0,184628,06573d1181e6702bdd07acf5d410ef1078d13840,10,4,2,12000,,,0,"Remove local module

Per discussion at the oslo graduation working session at the 2015
Vancouver Summit, remove the local module as it is deprecated and no
longer necessary.

See also: https://etherpad.openstack.org/p/YVR-oslo-graduation-schedule

Change-Id: I271debac1e05a353f9876ced77970e6030912111
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/28/184628/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/local.py'],1,694068ff10d8ef2eb352a2d9333f339950c3c2a1,I271debac1e05a353f9876ced77970e6030912111,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Local storage of variables using weak references"""""" import threading import weakref class WeakLocal(threading.local): def __getattribute__(self, attr): rval = super(WeakLocal, self).__getattribute__(attr) if rval: # NOTE(mikal): this bit is confusing. What is stored is a weak # reference, not the value itself. We therefore need to lookup # the weak reference and return the inner value here. rval = rval() return rval def __setattr__(self, attr, value): value = weakref.ref(value) return super(WeakLocal, self).__setattr__(attr, value) # NOTE(mikal): the name ""store"" should be deprecated in the future store = WeakLocal() # A ""weak"" store uses weak references and allows an object to fall out of scope # when it falls out of scope in the code that uses the thread local storage. A # ""strong"" store will hold a reference to the object so that it never falls out # of scope. weak_store = WeakLocal() strong_store = threading.local() ",0,45
openstack%2Fopenstack-manuals~master~Ic840b3ee8a3383cd3ff42089d8d53db78be8332d,openstack/openstack-manuals,master,Ic840b3ee8a3383cd3ff42089d8d53db78be8332d,Add step to restart rabbitmq service,ABANDONED,2015-05-26 21:38:05.000000000,2015-05-26 23:08:42.000000000,,"[{'_account_id': 3}, {'_account_id': 9515}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-26 21:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a88e185e9042c276a882dfc04448f90494d57a4d', 'message': 'Add step to restart rabbitmq service\n\nAdd a step to restart the rabbitmq service\nto avoid problems, e.g. swift authentification with keystone.\n\nCloses-Bug: #1458988\nChange-Id: Ic840b3ee8a3383cd3ff42089d8d53db78be8332d\n'}, {'number': 2, 'created': '2015-05-26 22:46:44.000000000', 'files': ['doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_env_vars.po', 'doc/install-guide/section_basics-queue.xml', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_nova_specify_host.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_create_and_manage_networks.po', 'doc/user-guide-admin/source/locale/common.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_assign_cors_headers.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/backup_db.po', 'doc/user-guide/source/locale/cli_ceilometer.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_manage_services.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_authenticate_against_compute_endpoint.po', 'doc/user-guide/source/locale/cli_manage_instances_hosts.pot', 'doc/user-guide/source/locale/sdk_install.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_create_networks.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/set_up_replication.po', 'doc/user-guide-admin/source/locale/cli_admin_manage_environment.pot', 'doc/user-guide-admin/source/locale/analyzing-log-files-with-swift-cli.pot', 'doc/user-guide/source/locale/dashboard_launch_instances.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard.po', 'doc/user-guide-admin/source/locale/cli_admin_manage_stacks.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_nova_manage_services.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_nova_configure_access_security_for_instances.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_manage_images.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_admin_manage_roles.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_manage_flavors.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_stacks.po', 'doc/user-guide/source/locale/cli_change_the_size_of_your_server.pot', 'doc/user-guide/source/locale/cli_launch_instances.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/set_up_clustering.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_resources.po', 'doc/user-guide/source/locale/sdk_configure_access_security_instances.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_nova_migrate.po', 'doc/user-guide-admin/source/locale/cli.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_set_quotas.po', 'doc/user-guide/source/locale/cli_create_and_manage_stacks.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_manage_objects.po', 'doc/user-guide/source/locale/cli_nova_configure_access_security_for_instances.pot', 'doc/user-guide/source/locale/backup_db_incremental.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/manage_db_config.po', 'doc/user-guide/source/locale/sdk_authenticate_against_image_service_endpoint.pot', 'doc/user-guide/source/locale/managing-openstack-object-storage-with-swift-cli.pot', 'doc/user-guide/source/locale/cli_swift_manage_objects.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_databases.po', 'doc/user-guide/source/locale/dashboard_databases.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/networking_advanced_quotas.po', 'doc/user-guide/source/locale/cli_swift_env_vars.pot', 'doc/user-guide/source/locale/cli_swift_manage_access_swift.pot', 'doc/user-guide/source/locale/sdk_authenticate_against_networking_endpoint.pot', 'doc/user-guide-admin/source/locale/dashboard_manage_instances.pot', 'doc/user-guide/source/locale/cli_reboot_an_instance.pot', 'doc/user-guide/source/locale/cli_stop_and_start_an_instance.pot', 'doc/user-guide/source/locale/cli_manage_ip_addresses.pot', 'doc/user-guide/source/locale/cli_swift_pseudo_hierarchical_folders_directories.pot', 'doc/user-guide/source/locale/index.pot', 'doc/user-guide/source/locale/sdk_compute_apis.pot', 'doc/user-guide-admin/source/locale/dashboard_set_quotas.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_neutron_apis.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_admin_manage_environment.po', 'doc/user-guide/source/locale/create_db.pot', 'doc/user-guide/source/locale/cli_nova_show_usage_statistics_for_hosts_instances.pot', 'doc/user-guide/source/locale/set_up_clustering.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_create_containers.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/nova_cli_manage_projects_security.po', 'doc/user-guide-admin/source/locale/cli_keystone_manage_services.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/configure_access_and_security_for_instances.po', 'doc/user-guide/source/locale/cli_swift_archive_auto_extract.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_authenticate.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_authenticate_against_identity_endpoint.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_ceilometer.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_services.po', 'doc/user-guide/source/locale/cli_nova_launch_instance_from_volume.pot', 'doc/user-guide/source/locale/intro-user.pot', 'doc/user-guide/source/locale/cli_create_and_manage_networks.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_admin_manage_stacks.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_set_quotas.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/managing-openstack-object-storage-with-swift-cli.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/index.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_compute_apis.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_use_snapshots_to_migrate_instances.po', 'doc/user-guide-admin/source/locale/dashboard_admin_manage_roles.pot', 'doc/user-guide-admin/source/locale/nova_cli_manage_projects_security.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_stop_and_start_an_instance.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_configure_access_security_instances.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_manage_instances_hosts.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_access_instance_through_a_console.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_volumes.po', 'doc/user-guide/source/locale/cli_swift_bulk_delete.pot', 'doc/user-guide-admin/source/locale/dashboard.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/create_db.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_launch_instances.po', 'doc/user-guide/source/locale/configure_access_and_security_for_instances.pot', 'doc/user-guide-admin/source/locale/cli_set_compute_quotas.pot', 'doc/user-guide-admin/source/locale/cli_cinder_quotas.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/backup_db_incremental.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_manage_ip_addresses.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_authenticate_against_image_service_endpoint.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_pseudo_hierarchical_folders_directories.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_nova_launch_instance_from_volume.po', 'doc/user-guide/source/locale/sdk.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_large_object_creation.po', 'doc/user-guide/source/locale/cli_swift_create_containers.pot', 'doc/user-guide/source/locale/dashboard_manage_containers.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_images.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_schedule_objects_for_deletion.po', 'doc/user-guide-admin/source/locale/cli_nova_manage_services.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_manage_volumes.po', 'doc/user-guide/source/locale/common.pot', 'doc/user-guide/source/locale/dashboard.pot', 'doc/user-guide-admin/source/locale/dashboard_admin_manage_stacks.pot', 'doc/user-guide/source/locale/cli_access_instance_through_a_console.pot', 'doc/user-guide/source/locale/dashboard_manage_volumes.pot', 'doc/user-guide/source/locale/sdk_neutron_apis.pot', 'doc/user-guide/source/locale/cli_search_instance_with_ip_address.pot', 'doc/user-guide/source/locale/manage_db_config.pot', 'doc/user-guide/source/locale/sdk_authenticate.pot', 'doc/user-guide-admin/source/locale/intro-admin.pot', 'doc/user-guide/source/locale/cli_swift_set_object_versions.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_archive_auto_extract.po', 'doc/user-guide-admin/source/locale/dashboard_manage_volumes.pot', 'doc/user-guide-admin/source/locale/cli_admin_manage_ip_addresses.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_large_lists.po', 'doc/user-guide-admin/source/locale/networking_advanced_quotas.pot', 'doc/user-guide/source/locale/dashboard_stacks.pot', 'doc/user-guide-admin/source/locale/dashboard_view_cloud_resources.pot', 'doc/user-guide-admin/source/locale/index.pot', 'doc/user-guide/source/locale/sdk_assign_cors_headers.pot', 'doc/user-guide/source/locale/cli_swift_static_website.pot', 'doc/user-guide/source/locale/cli_swift_discoverability.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_discoverability.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_cinder_quotas.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/manage_projects_users_and_roles.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/dashboard_manage_containers.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/index.po', 'doc/user-guide/source/locale/cli_manage_bare_metal_nodes.pot', 'doc/user-guide-admin/source/locale/dashboard_manage_services.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_set_compute_quotas.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_cheat_sheet.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_delete_an_instance.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/hot-guide.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_flavors.po', 'doc/user-guide/source/locale/cli_use_snapshots_to_migrate_instances.pot', 'doc/user-guide/source/locale/dashboard_create_networks.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_static_website.po', 'doc/user-guide-admin/source/locale/dashboard_manage_resources.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/intro-user.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_serialized_response_formats.po', 'doc/user-guide/source/locale/cli_swift_serialized_response_formats.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_manage_images.po', 'doc/user-guide-admin/source/locale/cli_set_quotas.pot', 'doc/user-guide/source/locale/cli_provide_user_data_to_instances.pot', 'doc/user-guide/source/locale/cli_swift_large_object_creation.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_provide_user_data_to_instances.po', 'doc/user-guide/source/locale/sdk_authenticate_against_compute_endpoint.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_install.po', 'doc/user-guide-admin/source/locale/cli_nova_migrate.pot', 'doc/user-guide/source/locale/dashboard_manage_images.pot', 'doc/user-guide-admin/source/locale/cli_manage_services.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_keystone_manage_services.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_config_drive.po', 'doc/user-guide/source/locale/sdk_schedule_objects_for_deletion.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_view_cloud_resources.po', 'doc/user-guide/source/locale/sdk_authenticate_against_identity_endpoint.pot', 'doc/user-guide/source/locale/set_up_replication.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_nova_evacuate.po', 'doc/user-guide-admin/source/locale/cli_nova_specify_host.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_set_object_versions.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_change_the_size_of_your_server.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/trove-manage-db.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_manage_access_swift.po', 'doc/user-guide/source/locale/cli_swift_large_lists.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_reboot_an_instance.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_instances.po', 'doc/user-guide/source/locale/cli_cheat_sheet.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_manage_host_aggregates.po', 'doc/user-guide-admin/source/locale/dashboard_manage_images.pot', 'doc/user-guide/source/locale/trove-manage-db.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/common.po', 'doc/user-guide/source/locale/hot-guide.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/intro-admin.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_nova_show_usage_statistics_for_hosts_instances.po', 'doc/user-guide/source/locale/cli_delete_an_instance.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_swift_bulk_delete.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_create_and_manage_stacks.po', 'doc/user-guide-admin/source/locale/dashboard_manage_host_aggregates.pot', 'doc/user-guide-admin/source/locale/cli_manage_flavors.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/dashboard_admin_manage_stacks.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/common.po', 'doc/user-guide/source/locale/backup_db.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/sdk_authenticate_against_networking_endpoint.po', 'doc/user-guide/source/locale/sdk_manage_images.pot', 'doc/user-guide-admin/source/locale/manage_projects_users_and_roles.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_manage_bare_metal_nodes.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/analyzing-log-files-with-swift-cli.po', 'doc/user-guide/source/locale/cli.pot', 'doc/user-guide-admin/source/locale/cli_nova_evacuate.pot', 'doc/user-guide-admin/source/locale/dashboard_manage_flavors.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/cli_admin_manage_ip_addresses.po', 'doc/user-guide/source/locale/cli_config_drive.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_launch_instances.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/cli_search_instance_with_ip_address.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64a5f06891d70c8eb9bf2d32a9f64b9711c232bc', 'message': 'Add step to restart rabbitmq service\n\nAdd a step to restart the rabbitmq service\nto avoid problems, e.g. swift authentification with keystone.\n\nCloses-Bug: #1458988\nChange-Id: Ic840b3ee8a3383cd3ff42089d8d53db78be8332d\n'}]",0,185745,64a5f06891d70c8eb9bf2d32a9f64b9711c232bc,8,3,2,16233,,,0,"Add step to restart rabbitmq service

Add a step to restart the rabbitmq service
to avoid problems, e.g. swift authentification with keystone.

Closes-Bug: #1458988
Change-Id: Ic840b3ee8a3383cd3ff42089d8d53db78be8332d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/185745/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-queue.xml'],1,a88e185e9042c276a882dfc04448f90494d57a4d,bug/1458988, <step> <para>Restart the message queue service:</para> <screen><prompt>#</prompt> <userinput>service rabbitmq-server restart</userinput></screen> </step>,,4,0
openstack%2Ftempest~master~I3a3d41a5482a007dab0a210a830d82f2b104c8da,openstack/tempest,master,I3a3d41a5482a007dab0a210a830d82f2b104c8da,Project: openstack/tempest,ABANDONED,2015-05-13 00:53:34.000000000,2015-05-26 23:03:36.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 6873}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-05-13 00:53:34.000000000', 'files': ['tempest/api/object_storage/test_object_services.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ede13c5596b60cba0da63a2805fa530006dcedb', 'message': 'Project: openstack/tempest\n\nAdd gzip encoding test for swift api\nImplements: blueprint add-gzip-encoding-swift-api-test\n\nChange-Id: I3a3d41a5482a007dab0a210a830d82f2b104c8da\n'}]",4,182511,5ede13c5596b60cba0da63a2805fa530006dcedb,11,4,1,16233,,,0,"Project: openstack/tempest

Add gzip encoding test for swift api
Implements: blueprint add-gzip-encoding-swift-api-test

Change-Id: I3a3d41a5482a007dab0a210a830d82f2b104c8da
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/182511/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_object_services.py'],1,5ede13c5596b60cba0da63a2805fa530006dcedb,bp/add-gzip-encoding-swift-api-test,"import cStringIO as StringIO import gzip def test_create_object_with_content_encoding_deflate(self): self.assertEqual(resp['status'], '201') @test.idempotent_id('61a82c33-e67d-429e-a53f-362a41c757e6') def test_create_object_with_content_encoding_gzip(self): # create object with content_encoding object_name = data_utils.rand_name(name='TestObject') # put compressed string data_before = 'x' * 2000 file_gzip = StringIO.StringIO() gzip_file = gzip.GzipFile( filename=object_name, mode='wb', fileobj=file_gzip) gzip_file.write(data_before) gzip_file.close() data = file_gzip.getvalue() metadata = {} metadata['content-encoding'] = 'gzip' resp, _ = self.object_client.create_object( self.container_name, object_name, data, metadata=metadata) self.assertEqual(resp['status'], '201') self.assertHeaders(resp, 'Object', 'PUT') # download compressed object metadata = {} metadata['accept-encoding'] = 'gzip' resp, body = self.object_client.get_object( self.container_name, object_name, metadata=metadata) self.assertEqual(body, data_before) ", def test_create_object_with_content_encoding(self):,40,1
openstack%2Fshade~master~I7f30ba908552fbecaedd364ecf20b19e096b03d9,openstack/shade,master,I7f30ba908552fbecaedd364ecf20b19e096b03d9,Make sure glance image list actually runs in Tasks,MERGED,2015-05-26 22:07:02.000000000,2015-05-26 22:56:51.000000000,2015-05-26 22:56:51.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-26 22:07:02.000000000', 'files': ['shade/__init__.py', 'shade/_tasks.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/39eefc1989ff4e51db8716dd7106967b14fee12a', 'message': ""Make sure glance image list actually runs in Tasks\n\nimages.list() does not actually talk to an API. So putting it in\nTaskManager actually takes an execution slot that it does not need. On\nthe other hand, the follow up list expansion DOES talk to the API. So\nput it in the Task, since it's the evil thing.\n\nChange-Id: I7f30ba908552fbecaedd364ecf20b19e096b03d9\n""}]",0,185756,39eefc1989ff4e51db8716dd7106967b14fee12a,10,6,1,2,,,0,"Make sure glance image list actually runs in Tasks

images.list() does not actually talk to an API. So putting it in
TaskManager actually takes an execution slot that it does not need. On
the other hand, the follow up list expansion DOES talk to the API. So
put it in the Task, since it's the evil thing.

Change-Id: I7f30ba908552fbecaedd364ecf20b19e096b03d9
",git fetch https://review.opendev.org/openstack/shade refs/changes/56/185756/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/__init__.py', 'shade/_tasks.py']",2,39eefc1989ff4e51db8716dd7106967b14fee12a,, return [image for image in self.args['image_gen']], return client.glance_client.images.list(),7,4
openstack%2Fpython-openstackclient~master~Id9f40f15702e8f14f0327a37fcc7d7971338c258,openstack/python-openstackclient,master,Id9f40f15702e8f14f0327a37fcc7d7971338c258,Add missing properties to image set command,MERGED,2015-05-23 06:11:17.000000000,2015-05-26 22:43:51.000000000,2015-05-26 22:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 10234}, {'_account_id': 13664}]","[{'number': 1, 'created': '2015-05-23 06:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/dfbf42cd3e12aaa15a5a3c1c477232eab5c917d5', 'message': 'Add missing properties to image set command\n\nEnable user to update the following image properties from OSC:\ncontainer-format, disk-format, size\n\nCloses-Bug: #1446362\nChange-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258\n'}, {'number': 2, 'created': '2015-05-25 04:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a22341bac928813bc34c7ea64ae1c4209134b0ea', 'message': 'Add missing properties to image set command\n\nEnable user to update the following image properties from OSC:\ncontainer-format, disk-format, size\n\nCloses-Bug: #1446362\nChange-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258\n'}, {'number': 3, 'created': '2015-05-25 22:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/991d1a43269e06fcff3c69a2f4b0b0b1631534fd', 'message': 'Add missing properties to image set command\n\nEnable user to update the following image properties from OSC:\ncontainer-format, disk-format, size\n\nCloses-Bug: #1446362\nChange-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258\n'}, {'number': 4, 'created': '2015-05-25 22:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8ecb67dee57626cbe40576697fe6b44498785c20', 'message': 'Add missing properties to image set command\n\nEnable user to update the following image properties from OSC:\ncontainer-format, disk-format, size\n\nCloses-Bug: #1446362\nChange-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258\n'}, {'number': 5, 'created': '2015-05-26 05:50:02.000000000', 'files': ['doc/source/command-objects/image.rst', 'openstackclient/image/v1/image.py', 'openstackclient/tests/image/v1/test_image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ba21d463de948697b1e884cae883a0e64a4d35f6', 'message': 'Add missing properties to image set command\n\nEnable user to update the following image properties from OSC:\ncontainer-format, disk-format, size\n\nCloses-Bug: #1446362\nChange-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258\n'}]",5,185217,ba21d463de948697b1e884cae883a0e64a4d35f6,22,6,5,13664,,,0,"Add missing properties to image set command

Enable user to update the following image properties from OSC:
container-format, disk-format, size

Closes-Bug: #1446362
Change-Id: Id9f40f15702e8f14f0327a37fcc7d7971338c258
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/17/185217/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/image/v1/image.py', 'openstackclient/tests/image/v1/test_image.py']",2,dfbf42cd3e12aaa15a5a3c1c477232eab5c917d5,1446362," '--container-format', 'ovf', '--disk-format', 'vmdk', '--size', '35165824', ('container_format', 'ovf'), ('disk_format', 'vmdk'), ('size', 35165824), 'container_format': 'ovf', 'disk_format': 'vmdk', 'size': 35165824",,29,1
openstack%2Fastara-neutron~stable%2Fkilo~I407a9d62507cba2234dff2b803dd8c4e51bb889b,openstack/astara-neutron,stable/kilo,I407a9d62507cba2234dff2b803dd8c4e51bb889b,prep for next stable,MERGED,2015-05-16 07:59:55.000000000,2015-05-26 22:25:44.000000000,2015-05-26 22:25:44.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-05-16 07:59:55.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-neutron/commit/69e9374aef44e5ec5a7e776b16b60f8fe91aba32', 'message': 'prep for next stable\n\nupdate package configuration\n\nChange-Id: I407a9d62507cba2234dff2b803dd8c4e51bb889b\n'}]",0,183776,69e9374aef44e5ec5a7e776b16b60f8fe91aba32,7,3,1,6923,,,0,"prep for next stable

update package configuration

Change-Id: I407a9d62507cba2234dff2b803dd8c4e51bb889b
",git fetch https://review.opendev.org/openstack/astara-neutron refs/changes/76/183776/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,69e9374aef44e5ec5a7e776b16b60f8fe91aba32,prepare-for-next-stable,version = 2015.1.1,version = 2015.1,1,1
openstack%2Fmanila~master~I7d1df234834e30d452803acfb6d93c4ed32f0599,openstack/manila,master,I7d1df234834e30d452803acfb6d93c4ed32f0599,Remove usage of utils.test_utils,MERGED,2015-05-22 21:47:29.000000000,2015-05-26 22:24:16.000000000,2015-05-26 22:24:14.000000000,"[{'_account_id': 3}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-05-22 21:47:29.000000000', 'files': ['contrib/tempest/tempest/scenario/test_share_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/e8db9ed682ab2571ab80885997dc22598cd497f4', 'message': 'Remove usage of utils.test_utils\n\nIn order to transform the Manila tempest test into a consumable\nplugin all dependency to tempest must be limited. Remove the usage\nof tempest.utils.test_utils due it is optional for the scenario\ntest.\n\nChange-Id: I7d1df234834e30d452803acfb6d93c4ed32f0599\nPartly-implements: bp tempest-plugin-interface\n'}]",0,185159,e8db9ed682ab2571ab80885997dc22598cd497f4,9,5,1,7872,,,0,"Remove usage of utils.test_utils

In order to transform the Manila tempest test into a consumable
plugin all dependency to tempest must be limited. Remove the usage
of tempest.utils.test_utils due it is optional for the scenario
test.

Change-Id: I7d1df234834e30d452803acfb6d93c4ed32f0599
Partly-implements: bp tempest-plugin-interface
",git fetch https://review.opendev.org/openstack/manila refs/changes/59/185159/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/test_share_basic_ops.py'],1,e8db9ed682ab2571ab80885997dc22598cd497f4,bp/tempest-plugin-interface,,"from tempest.scenario import utils as test_utilsload_tests = test_utils.load_tests_input_scenario_utils self.image_utils = test_utils.ImageUtils() if not self.image_utils.is_flavor_enough(self.flavor_ref, self.image_ref): raise self.skipException( '{image} does not fit in {flavor}'.format( image=self.image_ref, flavor=self.flavor_ref ) )",0,11
openstack%2Fcongress~master~I5c134e14d1ae5fec802a649be9834f86dab5c37a,openstack/congress,master,I5c134e14d1ae5fec802a649be9834f86dab5c37a,Add status api calls for policy and rule,MERGED,2015-04-30 17:56:01.000000000,2015-05-26 22:19:43.000000000,2015-05-26 22:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 8878}, {'_account_id': 12875}]","[{'number': 1, 'created': '2015-04-30 17:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/8880844a740ead4d9709eaca2940ad8c321bd43c', 'message': 'Add status api calls for policy and rule\n\nThis change allows an API client to request the status of a rule or policy.\nThe response will reflect the state of the policy engine, not the state of the\ndatabase, since the policy engine and the database can become out of sync.\n\nFor a policy that exists, the API response will contain the policy name and\nid.  For a rule that exists, the API response will contain the rule name, id,\ncomment, and original string.  If the rule or policy does not exist, the\ncongress server will return a 404 error.\n\nChange-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a\n'}, {'number': 2, 'created': '2015-05-06 18:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/07e3cc07ef69c412e20160e9f424cb85ef207c7b', 'message': 'Add status api calls for policy and rule\n\nThis change allows an API client to request the status of a rule or policy.\nThe response will reflect the state of the policy engine, not the state of the\ndatabase, since the policy engine and the database can become out of sync.\n\nFor a policy that exists, the API response will contain the policy name and\nid.  For a rule that exists, the API response will contain the rule name, id,\ncomment, and original string.  If the rule or policy does not exist, the\ncongress server will return a 404 error.\n\nChange-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a\n'}, {'number': 3, 'created': '2015-05-06 18:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a0fb500a0f16c2afde3d906647988ca00188e5d6', 'message': 'Add status api calls for policy and rule\n\nThis change allows an API client to request the status of a rule or policy.\nThe response will reflect the state of the policy engine, not the state of the\ndatabase, since the policy engine and the database can become out of sync.\n\nFor a policy that exists, the API response will contain the policy name and\nid.  For a rule that exists, the API response will contain the rule name, id,\ncomment, and original string.  If the rule or policy does not exist, the\ncongress server will return a 404 error.\n\nChange-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a\n'}, {'number': 4, 'created': '2015-05-06 18:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9d993c57fdad0e14f59b2066c91f60bdadaa5f17', 'message': 'Add status api calls for policy and rule\n\nThis change allows an API client to request the status of a rule or policy.\nThe response will reflect the state of the policy engine, not the state of the\ndatabase, since the policy engine and the database can become out of sync.\n\nFor a policy that exists, the API response will contain the policy name and\nid.  For a rule that exists, the API response will contain the rule name, id,\ncomment, and original string.  If the rule or policy does not exist, the\ncongress server will return a 404 error.\n\nChange-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a\n'}, {'number': 5, 'created': '2015-05-26 21:25:04.000000000', 'files': ['congress/api/status_model.py', 'congress/datalog/compile.py', 'congress/datalog/base.py', 'congress/policy_engines/agnostic.py', 'congress/api/policy_model.py', 'congress/dse/d6cage.py', 'congress/tests/api/test_status_model.py', 'congress/dse/deepsix.py', 'congress/api/rule_model.py', 'congress/api/router.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/50d3d073c42569032d92a53413f57564c0e79ac9', 'message': 'Add status api calls for policy and rule\n\nThis change allows an API client to request the status of a rule or policy.\nThe response will reflect the state of the policy engine, not the state of the\ndatabase, since the policy engine and the database can become out of sync.\n\nFor a policy that exists, the API response will contain the policy name and\nid.  For a rule that exists, the API response will contain the rule name, id,\ncomment, and original string.  If the rule or policy does not exist, the\ncongress server will return a 404 error.\n\nChange-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a\n'}]",16,179181,50d3d073c42569032d92a53413f57564c0e79ac9,24,4,5,12875,,,0,"Add status api calls for policy and rule

This change allows an API client to request the status of a rule or policy.
The response will reflect the state of the policy engine, not the state of the
database, since the policy engine and the database can become out of sync.

For a policy that exists, the API response will contain the policy name and
id.  For a rule that exists, the API response will contain the rule name, id,
comment, and original string.  If the rule or policy does not exist, the
congress server will return a 404 error.

Change-Id: I5c134e14d1ae5fec802a649be9834f86dab5c37a
",git fetch https://review.opendev.org/openstack/congress refs/changes/81/179181/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/api/status_model.py', 'congress/datalog/compile.py', 'congress/api/policy_model.py', 'congress/datalog/base.py', 'congress/dse/d6cage.py', 'congress/policy_engines/agnostic.py', 'congress/tests/api/test_status_model.py', 'congress/api/router.py', 'congress/api/rule_model.py']",9,8880844a740ead4d9709eaca2940ad8c321bd43c,master-rulestatus2," id = uuid.uuid4() rule.set_id(id) rule.set_name(item.get('name')) rule.set_comment(None) rule.set_original_str(str_rule) 'id': str(id), 'comment': rule.comment,"," 'id': str(uuid.uuid4()), 'comment': None,",224,59
openstack%2Fhorizon~stable%2Fkilo~Icb91cdc0d4610407c4eeeda82f194c7016e3b540,openstack/horizon,stable/kilo,Icb91cdc0d4610407c4eeeda82f194c7016e3b540,Inherit environment variables for tests that use nodeenv,MERGED,2015-05-26 19:46:39.000000000,2015-05-26 22:19:33.000000000,2015-05-26 22:19:31.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5623}, {'_account_id': 6486}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-05-26 19:46:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/322a74c13c10b03155701162c277fa74e2db6a7b', 'message': 'Inherit environment variables for tests that use nodeenv\n\nTox 2.0 stopped automatically passing environment variables into the\nvirtual environment which potentially breaks test jobs which use nodeenv\nbecause of the nature of running nodeenv within a virtual environment.\n\nThe nodeenv documentation (https://pypi.python.org/pypi/nodeenv) even\nsays:\n\n""\nIf you already have the python virtualenv tool, and want to use nodeenv\nand virtualenv in conjunction, then you should create (or activate) the\npython virtual environment:\n\n$ mkvirtualenv my_env\n\n$ . my_env/bin/activate\nand add a node virtual environment to this existing new_venv:\n\n$ nodeenv -p\n""\n\nSince we can\'t source {envdir}/bin/activate from within the tox.ini, we\njust pass the environment variables into the virtual environment using\npassenv = *.\n\nAn alternative may be to change run_test.sh to run tests which use\nnodeenv within a venv by sourcing $VIRTUAL_ENV/bin/activate from within\nrun_test.sh.\n\nConflicts:\n        tox.ini\n\nNOTE(mriedem): The conflict is on the jscs job which was not in kilo.\n\nCloses-Bug: #1458928\n\nChange-Id: Icb91cdc0d4610407c4eeeda82f194c7016e3b540\n(cherry picked from commit 22c485b179681aa3fdcf3dc1207bbd0d2588acb9)\n'}]",0,185719,322a74c13c10b03155701162c277fa74e2db6a7b,9,5,1,6873,,,0,"Inherit environment variables for tests that use nodeenv

Tox 2.0 stopped automatically passing environment variables into the
virtual environment which potentially breaks test jobs which use nodeenv
because of the nature of running nodeenv within a virtual environment.

The nodeenv documentation (https://pypi.python.org/pypi/nodeenv) even
says:

""
If you already have the python virtualenv tool, and want to use nodeenv
and virtualenv in conjunction, then you should create (or activate) the
python virtual environment:

$ mkvirtualenv my_env

$ . my_env/bin/activate
and add a node virtual environment to this existing new_venv:

$ nodeenv -p
""

Since we can't source {envdir}/bin/activate from within the tox.ini, we
just pass the environment variables into the virtual environment using
passenv = *.

An alternative may be to change run_test.sh to run tests which use
nodeenv within a venv by sourcing $VIRTUAL_ENV/bin/activate from within
run_test.sh.

Conflicts:
        tox.ini

NOTE(mriedem): The conflict is on the jscs job which was not in kilo.

Closes-Bug: #1458928

Change-Id: Icb91cdc0d4610407c4eeeda82f194c7016e3b540
(cherry picked from commit 22c485b179681aa3fdcf3dc1207bbd0d2588acb9)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/185719/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,322a74c13c10b03155701162c277fa74e2db6a7b,bug/1458928-kilo,passenv = *,,1,0
openstack%2Ftrove~master~Ief129369bbffbaec7694e3f0d36668dde1772f05,openstack/trove,master,Ief129369bbffbaec7694e3f0d36668dde1772f05,Fix gate failure on gate-trove-pep8,MERGED,2015-05-26 19:37:18.000000000,2015-05-26 22:18:40.000000000,2015-05-26 22:18:38.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 10215}, {'_account_id': 14576}, {'_account_id': 14912}]","[{'number': 1, 'created': '2015-05-26 19:37:18.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/4e3e0e83c6fdd210819b2e446b379ae5bc1c838e', 'message': ""Fix gate failure on gate-trove-pep8\n\nThe gate-trove-pep8 job fails on Jenkins with the following error:\n\npkg_resources.VersionConflict:\n(pbr 1.0.1 (/home/jenkins/workspace/gate-trove-pep8/\n.tox/pep8/lib/python2.7/site-packages),\nRequirement.parse('pbr<1.0,>=0.5.21'))\n\nThis is caused by the fact that pbr has now released 1.0.1 and\nalthough most of the dependencies in Trove have switched to:\n\npbr>=0.11,<2.0\n\nwe are still using the hacking module from last year\n(hacking>=0.8.0,<0.9), which has pbr pegged to <1.0\n\nThe hacking module needs to be updated and the new rules ignored.\n\nThe following rules are now ignored:\n\nE111,E122,E123,E128,E251,E265,E713,F821,H105,H237,H238,H301,H305,H306,\nH307,H402,H404,H405,H407,H501,H904\n\nChange-Id: Ief129369bbffbaec7694e3f0d36668dde1772f05\nCloses-Bug: #1458985\n""}]",2,185714,4e3e0e83c6fdd210819b2e446b379ae5bc1c838e,11,5,1,10215,,,0,"Fix gate failure on gate-trove-pep8

The gate-trove-pep8 job fails on Jenkins with the following error:

pkg_resources.VersionConflict:
(pbr 1.0.1 (/home/jenkins/workspace/gate-trove-pep8/
.tox/pep8/lib/python2.7/site-packages),
Requirement.parse('pbr<1.0,>=0.5.21'))

This is caused by the fact that pbr has now released 1.0.1 and
although most of the dependencies in Trove have switched to:

pbr>=0.11,<2.0

we are still using the hacking module from last year
(hacking>=0.8.0,<0.9), which has pbr pegged to <1.0

The hacking module needs to be updated and the new rules ignored.

The following rules are now ignored:

E111,E122,E123,E128,E251,E265,E713,F821,H105,H237,H238,H301,H305,H306,
H307,H402,H404,H405,H407,H501,H904

Change-Id: Ief129369bbffbaec7694e3f0d36668dde1772f05
Closes-Bug: #1458985
",git fetch https://review.opendev.org/openstack/trove refs/changes/14/185714/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,4e3e0e83c6fdd210819b2e446b379ae5bc1c838e,bug/1458985,"ignore = E111,E122,E123,E128,E251,E265,E713,F821,H105,H237,H238,H301,H305,H306,H307,H402,H404,H405,H407,H501,H904","ignore = F821,H301,H306,H404",2,2
openstack%2Ftripleo-heat-templates~master~I839ee49b153aa96ec08ebdb7e44aaeac28785963,openstack/tripleo-heat-templates,master,I839ee49b153aa96ec08ebdb7e44aaeac28785963,Define Glance Pacemaker resources on $pacemaker_master node only,MERGED,2015-05-22 11:53:56.000000000,2015-05-26 22:13:34.000000000,2015-05-26 22:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-22 11:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5c5f776e0d4a4712610a2e70fa3cc1052bae642b', 'message': 'Define Glance Pacemaker resources from Pacemaker master only\n\nPreviously the Glance Pacemaker resources where mistakenly defined\non all nodes causing intermittent duplication errors.\n # Please enter the commit message for your changes. Lines starting\n\nChange-Id: I839ee49b153aa96ec08ebdb7e44aaeac28785963\n'}, {'number': 2, 'created': '2015-05-22 11:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1014950772c4fd541fa3fb07163bd37c150577eb', 'message': 'Define Glance Pacemaker resources on $pacemaker_master node only\n\nPreviously the Glance Pacemaker resources where mistakenly defined\non all nodes causing intermittent duplication errors.\n\nChange-Id: I839ee49b153aa96ec08ebdb7e44aaeac28785963\n'}, {'number': 3, 'created': '2015-05-22 11:59:33.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d6541b1c932c1062999a89e774d9da176aa7c008', 'message': 'Define Glance Pacemaker resources on $pacemaker_master node only\n\nPreviously the Glance Pacemaker resources were mistakenly defined\non all nodes causing intermittent duplication errors.\n\nChange-Id: I839ee49b153aa96ec08ebdb7e44aaeac28785963'}]",0,184996,d6541b1c932c1062999a89e774d9da176aa7c008,25,7,3,6796,,,0,"Define Glance Pacemaker resources on $pacemaker_master node only

Previously the Glance Pacemaker resources were mistakenly defined
on all nodes causing intermittent duplication errors.

Change-Id: I839ee49b153aa96ec08ebdb7e44aaeac28785963",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/184996/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,5c5f776e0d4a4712610a2e70fa3cc1052bae642b,," # Glance pacemaker::resource::service { $::glance::params::registry_service_name : clone_params => ""interleave=true"", } pacemaker::resource::service { $::glance::params::api_service_name : clone_params => ""interleave=true"", } pacemaker::constraint::base { 'glance-registry-then-glance-api-constraint': constraint_type => ""order"", first_resource => ""${::glance::params::registry_service_name}-clone"", second_resource => ""${::glance::params::api_service_name}-clone"", first_action => ""start"", second_action => ""start"", require => [Pacemaker::Resource::Service[$::glance::params::registry_service_name], Pacemaker::Resource::Service[$::glance::params::api_service_name]], } pacemaker::constraint::colocation { 'glance-registry-with-glance-api-colocation': source => ""${::glance::params::registry_service_name}-clone"", target => ""${::glance::params::api_service_name}-clone"", score => ""INFINITY"", require => [Pacemaker::Resource::Service[$::glance::params::registry_service_name], Pacemaker::Resource::Service[$::glance::params::api_service_name]], }"," } # Glance pacemaker::resource::service { $::glance::params::registry_service_name : clone_params => ""interleave=true"", } pacemaker::resource::service { $::glance::params::api_service_name : clone_params => ""interleave=true"", } pacemaker::constraint::base { 'glance-registry-then-glance-api-constraint': constraint_type => ""order"", first_resource => ""${::glance::params::registry_service_name}-clone"", second_resource => ""${::glance::params::api_service_name}-clone"", first_action => ""start"", second_action => ""start"", require => [Pacemaker::Resource::Service[$::glance::params::registry_service_name], Pacemaker::Resource::Service[$::glance::params::api_service_name]], } pacemaker::constraint::colocation { 'glance-registry-with-glance-api-colocation': source => ""${::glance::params::registry_service_name}-clone"", target => ""${::glance::params::api_service_name}-clone"", score => ""INFINITY"", require => [Pacemaker::Resource::Service[$::glance::params::registry_service_name], Pacemaker::Resource::Service[$::glance::params::api_service_name]],",23,24
openstack%2Ftripleo-heat-templates~master~Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32,openstack/tripleo-heat-templates,master,Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32,os-net-config templates to configure vlans on bond,MERGED,2015-05-20 18:40:07.000000000,2015-05-26 22:04:49.000000000,2015-05-26 22:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e8bb2712de08174564e66a0f0f2aa7ac37ea1861', 'message': 'os-net-config templates to configure vlans on bond\n\nThis patch adds 5 new role templates to help configure\nan OVS bond with vlans on top for each of the overcloud\nroles.\n\nThese are meant to represent a more production network\nwhich might use isolated nets, and should help facilitate\ncreate a CI job which configures a bond w/ vlans on it.\n\nChange-Id: Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32\n'}, {'number': 2, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/02b5762e4311918f696231f2ee5f8bb699d2b7ef', 'message': 'os-net-config templates to configure vlans on bond\n\nThis patch adds 5 new role templates to help configure\nan OVS bond with vlans on top for each of the overcloud\nroles.\n\nThese are meant to represent a more production network\nwhich might use isolated nets, and should help facilitate\ncreate a CI job which configures a bond w/ vlans on it.\n\nThe patch also includes an environment file to\nenable configuration of bonded vlans by simply\nsourcing this file.\n\nChange-Id: Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32\n'}, {'number': 3, 'created': '2015-05-26 12:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f7c17293175c7b1a84ec8239c3b371bc4c12dd4', 'message': 'os-net-config templates to configure vlans on bond\n\nThis patch adds 5 new role templates to help configure\nan OVS bond with vlans on top for each of the overcloud\nroles.\n\nThese are meant to represent a more production network\nwhich might use isolated nets, and should help facilitate\ncreate a CI job which configures a bond w/ vlans on it.\n\nThe patch also includes an environment file to\nenable configuration of bonded vlans by simply\nsourcing this file.\n\nChange-Id: Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32\n'}, {'number': 4, 'created': '2015-05-26 14:25:00.000000000', 'files': ['network/config/bond-with-vlans/cinder-storage.yaml', 'network/config/bond-with-vlans/swift-storage.yaml', 'network/config/bond-with-vlans/README.md', 'network/config/bond-with-vlans/ceph-storage.yaml', 'network/config/bond-with-vlans/controller.yaml', 'environments/net-bond-with-vlans.yaml', 'network/config/bond-with-vlans/compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b982219b65e350b41c13e4e80a9fc154869c4128', 'message': 'os-net-config templates to configure vlans on bond\n\nThis patch adds 5 new role templates to help configure\nan OVS bond with vlans on top for each of the overcloud\nroles.\n\nThese are meant to represent a more production network\nwhich might use isolated nets, and should help facilitate\ncreate a CI job which configures a bond w/ vlans on it.\n\nThe patch also includes an environment file to\nenable configuration of bonded vlans by simply\nsourcing this file.\n\nChange-Id: Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32\n'}]",1,184580,b982219b65e350b41c13e4e80a9fc154869c4128,20,4,4,360,,,0,"os-net-config templates to configure vlans on bond

This patch adds 5 new role templates to help configure
an OVS bond with vlans on top for each of the overcloud
roles.

These are meant to represent a more production network
which might use isolated nets, and should help facilitate
create a CI job which configures a bond w/ vlans on it.

The patch also includes an environment file to
enable configuration of bonded vlans by simply
sourcing this file.

Change-Id: Ibe4c9d933445014ce3bec5fb3d7e3139fc40cb32
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/80/184580/4 && git format-patch -1 --stdout FETCH_HEAD,"['network/config/bond-with-vlans/cinder-storage.yaml', 'network/config/bond-with-vlans/swift-storage.yaml', 'network/config/bond-with-vlans/README.md', 'network/config/bond-with-vlans/ceph-storage.yaml', 'network/config/bond-with-vlans/controller.yaml', 'network/config/bond-with-vlans/compute.yaml']",6,e8bb2712de08174564e66a0f0f2aa7ac37ea1861,networks,"heat_template_version: 2015-04-30 description: > Software Config to drive os-net-config with 2 bonded nics on a bridge with a VLANs attached for the compute role. parameters: ExternalIpSubnet: default: '' description: IP address/subnet on the external network type: string InternalApiIpSubnet: default: '' description: IP address/subnet on the internal API network type: string StorageIpSubnet: default: '' description: IP address/subnet on the storage network type: string StorageMgmtIpSubnet: default: '' description: IP address/subnet on the storage mgmt network type: string TenantIpSubnet: default: '' description: IP address/subnet on the tenant network type: string resources: OsNetConfigImpl: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: os_net_config: network_config: - type: ovs_bridge name: {get_input: bridge_name} use_dhcp: true members: - type: interface name: nic1 # force the MAC address of the bridge to this interface primary: true - type: ovs_bridge name: br-bond members: - type: ovs_bond name: bond1 ovs_options: vlan_mode=trunk trunks=10,20,30,40,50 members: - type: interface name: nic2 primary: true - type: interface name: nic3 - type: vlan device: bond1 vlan_id: 20 addresses: - ip_netmask: {get_param: InternalApiIpSubnet} - type: vlan device: bond1 vlan_id: 30 addresses: - ip_netmask: {get_param: StorageIpSubnet} - type: vlan device: bond1 vlan_id: 50 addresses: - ip_netmask: {get_param: TenantIpSubnet} outputs: OS::stack_id: description: The OsNetConfigImpl resource. value: {get_resource: OsNetConfigImpl} ",,462,0
openstack%2Foslo-cookiecutter~master~I3da35630b4f65587e28acfaedd97f02114d53886,openstack/oslo-cookiecutter,master,I3da35630b4f65587e28acfaedd97f02114d53886,Remove script already nuked from oslo-incubator,MERGED,2015-05-16 19:55:06.000000000,2015-05-26 22:03:16.000000000,2015-05-26 22:03:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-05-16 19:55:06.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/b30dd542ee8c154362e04727e0331cecd3479a6d', 'message': 'Remove script already nuked from oslo-incubator\n\nChange-Id: I3da35630b4f65587e28acfaedd97f02114d53886\n'}]",0,183828,b30dd542ee8c154362e04727e0331cecd3479a6d,7,3,1,5638,,,0,"Remove script already nuked from oslo-incubator

Change-Id: I3da35630b4f65587e28acfaedd97f02114d53886
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/28/183828/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,b30dd542ee8c154362e04727e0331cecd3479a6d,,,# The list of modules to copy from oslo-incubator.git script = tools/run_cross_tests.sh ,0,3
openstack%2Fpbr~master~I033cc482f441d59a193b4b1a87ddcbc96fd99885,openstack/pbr,master,I033cc482f441d59a193b4b1a87ddcbc96fd99885,Add home-page into sample setup.cfg,MERGED,2015-05-21 21:07:58.000000000,2015-05-26 21:47:16.000000000,2015-05-26 21:47:16.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-21 21:07:58.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/pbr/commit/f6cd7b7419197119861d97d09fa01a8bb665c5b0', 'message': 'Add home-page into sample setup.cfg\n\nChange-Id: I033cc482f441d59a193b4b1a87ddcbc96fd99885\n'}]",0,184866,f6cd7b7419197119861d97d09fa01a8bb665c5b0,7,3,1,9453,,,0,"Add home-page into sample setup.cfg

Change-Id: I033cc482f441d59a193b4b1a87ddcbc96fd99885
",git fetch https://review.opendev.org/openstack/pbr refs/changes/66/184866/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,f6cd7b7419197119861d97d09fa01a8bb665c5b0,docs, home-page = https://launchpad.net/pbr,,1,0
openstack%2Fpbr~master~If9b4db43cd260da731ec5a14599eddedfc33808a,openstack/pbr,master,If9b4db43cd260da731ec5a14599eddedfc33808a,Add kerberos deps to build the kerberos wheel.,MERGED,2015-05-19 16:54:15.000000000,2015-05-26 21:47:03.000000000,2015-05-26 21:47:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-19 16:54:15.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/e2ac0e00982ebcc772e75d2beb3a7896864c8be4', 'message': 'Add kerberos deps to build the kerberos wheel.\n\nChange-Id: If9b4db43cd260da731ec5a14599eddedfc33808a\n'}]",0,184294,e2ac0e00982ebcc772e75d2beb3a7896864c8be4,9,4,1,4190,,,0,"Add kerberos deps to build the kerberos wheel.

Change-Id: If9b4db43cd260da731ec5a14599eddedfc33808a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/94/184294/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,e2ac0e00982ebcc772e75d2beb3a7896864c8be4,,sudo apt-get install -y --force-yes libvirt-dev libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev libldap2-dev libsasl2-dev ccache libkrb5-dev,sudo apt-get install -y --force-yes libvirt-dev libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev libldap2-dev libsasl2-dev ccache,1,1
openstack%2Fhorizon~stable%2Fkilo~I0f3103d4b3438fb46f65482f642460a6bbdcb4a2,openstack/horizon,stable/kilo,I0f3103d4b3438fb46f65482f642460a6bbdcb4a2,Fix jshint test,ABANDONED,2015-05-22 22:25:32.000000000,2015-05-26 21:45:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9981}]","[{'number': 1, 'created': '2015-05-22 22:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a079ed2bc06efae205d0ade08b4fd2d6ee34250b', 'message': ""Don't jshint angular\n\njshint doesn't work on angular anyways.\n\nChange-Id: I0f3103d4b3438fb46f65482f642460a6bbdcb4a2\n""}, {'number': 2, 'created': '2015-05-22 23:15:10.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/horizon/commit/12394008ffdf7e8cf118b63afff021df6fab903f', 'message': ""Fix jshint test\n\nThe jshint test would fail because for some reason jshint doesn't\nread .jshintrc without the --config option.\n\nChange-Id: I0f3103d4b3438fb46f65482f642460a6bbdcb4a2\n""}]",5,185172,12394008ffdf7e8cf118b63afff021df6fab903f,21,6,2,6486,,,0,"Fix jshint test

The jshint test would fail because for some reason jshint doesn't
read .jshintrc without the --config option.

Change-Id: I0f3103d4b3438fb46f65482f642460a6bbdcb4a2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/185172/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,a079ed2bc06efae205d0ade08b4fd2d6ee34250b,183656,, jshint horizon/static/angular/,0,1
openstack%2Foslo.middleware~master~I3c0ff620f10bec2cbf7b748d48fff025aab44351,openstack/oslo.middleware,master,I3c0ff620f10bec2cbf7b748d48fff025aab44351,Add CORS Middleware for Oslo.,MERGED,2015-04-02 19:51:04.000000000,2015-05-26 21:41:09.000000000,2015-04-09 13:24:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2218}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 6928}, {'_account_id': 9717}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-04-02 19:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/12cd27f8640cdfb4fe8f3c70963eef6aae83a91a', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 2, 'created': '2015-04-02 23:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/373d277b092eacf8a719984fa422bb7402b4cab0', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 3, 'created': '2015-04-02 23:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/98d670ea9c1a93765a58dd36cb6442f45be30136', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 4, 'created': '2015-04-03 18:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/4c6644ba1c1e2d8ddeadbd71a2f894a5bdbbfe13', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 5, 'created': '2015-04-03 18:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/3a735eeaa47099839ffc4931d9837539e035a2f1', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 6, 'created': '2015-04-03 19:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/fc2f212b657c56c56ece2dba79e068530100cac1', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 7, 'created': '2015-04-03 19:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/269130baaa6645e63dba5d21fde4b05f8ea8b833', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 8, 'created': '2015-04-03 20:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/b5c7a6fc5f4a20a55685f4af0b8155b1f4511096', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 9, 'created': '2015-04-03 21:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/6d0bcb141cd9577335efcbeaaafd7bb89e8ccc18', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 10, 'created': '2015-04-06 18:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/add85dd0b75d3fd745c515f87e6ebd5737200927', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 11, 'created': '2015-04-06 18:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/3d0f353cad41ac5ebbdfd38e0146cdf1ae8affb3', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 12, 'created': '2015-04-06 21:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/b898df44ada3632021a47eab6c2fd85c5ebdab11', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 13, 'created': '2015-04-07 18:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/e314153a4902708517f344376abdb425f04c95c8', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 14, 'created': '2015-04-07 21:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/bcb2b24349cc5d13d5dd11b5f67e6b71e1b3b9f7', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}, {'number': 15, 'created': '2015-04-09 01:32:06.000000000', 'files': ['doc/source/index.rst', 'oslo_middleware/cors.py', 'doc/source/cors.rst', 'oslo_middleware/tests/test_cors.py', 'oslo_middleware/opts.py', 'oslo_middleware/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/027dd345f3ae6c2bd4fcda5d664e5eb71131bcd7', 'message': 'Add CORS Middleware for Oslo.\n\nThis aims to provide a comprehensive middleware solution\nfor the CORS (Cross-Origin-Resource-Sharing) specification -\nhttp://www.w3.org/TR/cors/.\n\nTests and documentation have been provided.\n\nChange-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351\n'}]",33,170260,027dd345f3ae6c2bd4fcda5d664e5eb71131bcd7,49,10,15,9717,,,0,"Add CORS Middleware for Oslo.

This aims to provide a comprehensive middleware solution
for the CORS (Cross-Origin-Resource-Sharing) specification -
http://www.w3.org/TR/cors/.

Tests and documentation have been provided.

Change-Id: I3c0ff620f10bec2cbf7b748d48fff025aab44351
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/60/170260/13 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'oslo/middleware/cors.py', 'oslo_middleware/cors.py', 'doc/source/cors.rst', 'oslo_middleware/tests/test_cors.py']",5,12cd27f8640cdfb4fe8f3c70963eef6aae83a91a,cors,"# Copyright (c) 2015 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import fixture as config from oslotest import base as test_base import webob import webob.dec from oslo_middleware import cors class CORSTestBase(test_base.BaseTestCase): """"""Base class for all CORS tests. Sets up applications and helper methods. """""" def setUp(self): super(CORSTestBase, self).setUp() @webob.dec.wsgify def application(req): return 'Hello, World!!!' # Set up our configuration. fixture = self.useFixture(config.Config(cors.CONF)) # Settings for http://valid.example.com fixture.register_opts(cors.CORS_OPTS, 'cors.valid') fixture.config(group='cors.valid', allowed_origin='http://valid.example.com', allow_credentials=False, expose_headers=[], max_age=None, allow_methods=['GET'], allow_headers=[]) fixture.register_opts(cors.CORS_OPTS, 'cors.credentials') fixture.config(group='cors.credentials', allowed_origin='http://creds.example.com', allow_credentials=True, expose_headers=[], max_age=None, allow_methods=['GET'], allow_headers=[]) fixture.register_opts(cors.CORS_OPTS, 'cors.exposed-headers') fixture.config(group='cors.exposed-headers', allowed_origin='http://headers.example.com', allow_credentials=False, expose_headers=['X-Header-1', 'X-Header-2'], max_age=None, allow_methods=['GET'], allow_headers=['X-Header-1', 'X-Header-2']) fixture.register_opts(cors.CORS_OPTS, 'cors.cached') fixture.config(group='cors.cached', allowed_origin='http://cached.example.com', allow_credentials=False, expose_headers=[], max_age=3600, allow_methods=['GET'], allow_headers=[]) fixture.register_opts(cors.CORS_OPTS, 'cors.get-only') fixture.config(group='cors.get-only', allowed_origin='http://get.example.com', allow_credentials=False, expose_headers=[], max_age=None, allow_methods=['GET'], allow_headers=[]) fixture.register_opts(cors.CORS_OPTS, 'cors.all-methods') fixture.config(group='cors.all-methods', allowed_origin='http://all.example.com', allow_credentials=False, expose_headers=[], max_age=None, allow_methods=['GET', 'PUT', 'POST', 'DELETE', 'HEAD'], allow_headers=[]) # Now that the config is set up, create our application. self.application = cors.CORS(application) def assertCORSResponse(self, response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None): """"""Test helper for CORS response headers. Assert all the headers in a given response. By default, we assume the response is empty. """""" # Assert response status. self.assertEqual(response.status, status) # Assert the Access-Control-Allow-Origin header. self.assertHeader(response, 'Access-Control-Allow-Origin', allow_origin) # Assert the Access-Control-Max-Age header. self.assertHeader(response, 'Access-Control-Max-Age', max_age) # Assert the Access-Control-Allow-Methods header. self.assertHeader(response, 'Access-Control-Allow-Methods', allow_methods) # Assert the Access-Control-Allow-Headers header. self.assertHeader(response, 'Access-Control-Allow-Headers', allow_headers) # Assert the Access-Control-Allow-Credentials header. self.assertHeader(response, 'Access-Control-Allow-Credentials', allow_credentials) # Assert the Access-Control-Expose-Headers header. self.assertHeader(response, 'Access-Control-Expose-Headers', expose_headers) # If we're expecting an origin response, also assert that the # Vary: Origin header is set, since this implementation of the CORS # specification permits multiple origin domains. if allow_origin: self.assertHeader(response, 'Vary', 'Origin') def assertHeader(self, response, header, value=None): if value: self.assertIn(header, response.headers) self.assertEqual(value, response.headers[header]) else: self.assertNotIn(header, response.headers) class CORSRegularRequestTest(CORSTestBase): """"""CORS Specification Section 6.1 http://www.w3.org/TR/cors/#resource-requests """""" # List of HTTP methods (other than OPTIONS) to test with. methods = ['POST', 'PUT', 'DELETE', 'GET', 'TRACE', 'HEAD'] def test_no_origin_header(self): """"""CORS Specification Section 6.1.1 If the Origin header is not present terminate this set of steps. The request is outside the scope of this specification. """""" for method in self.methods: request = webob.Request({}) request.method = method response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_origin_headers(self): """"""CORS Specification Section 6.1.2 If the value of the Origin header is not a case-sensitive match for any of the values in list of origins, do not set any additional headers and terminate this set of steps. """""" # Test valid origin header. for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://valid.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://valid.example.com', max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) # Test origin header not present in configuration. for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://invalid.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) # Test valid, but case-mismatched origin header. for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://VALID.EXAMPLE.COM' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_supports_credentials(self): """"""CORS Specification Section 6.1.3 If the resource supports credentials add a single Access-Control-Allow-Origin header, with the value of the Origin header as value, and add a single Access-Control-Allow-Credentials header with the case-sensitive string ""true"" as value. Otherwise, add a single Access-Control-Allow-Origin header, with either the value of the Origin header or the string ""*"" as value. NOTE: We never use the ""*"" as origin. """""" # Test valid origin header without credentials. for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://valid.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://valid.example.com', max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) # Test valid origin header with credentials for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://creds.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://creds.example.com', max_age=None, allow_methods=None, allow_headers=None, allow_credentials=""true"", expose_headers=None) def test_expose_headers(self): """"""CORS Specification Section 6.1.4 If the list of exposed headers is not empty add one or more Access-Control-Expose-Headers headers, with as values the header field names given in the list of exposed headers. """""" for method in self.methods: request = webob.Request({}) request.method = method request.headers['Origin'] = 'http://headers.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://headers.example.com', max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers='X-Header-1,X-Header-2') class CORSPreflightRequestTest(CORSTestBase): """"""CORS Specification Section 6.2 http://www.w3.org/TR/cors/#resource-preflight-requests """""" def test_no_origin_header(self): """"""CORS Specification Section 6.2.1 If the Origin header is not present terminate this set of steps. The request is outside the scope of this specification. """""" request = webob.Request({}) request.method = ""OPTIONS"" response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_case_sensitive_origin(self): """"""CORS Specification Section 6.2.2 If the value of the Origin header is not a case-sensitive match for any of the values in list of origins do not set any additional headers and terminate this set of steps. """""" # Test valid domain request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://valid.example.com' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://valid.example.com', max_age=None, allow_methods='GET', allow_headers='', allow_credentials=None, expose_headers=None) # Test invalid domain request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://invalid.example.com' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) # Test case-sensitive mismatch domain request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://VALID.EXAMPLE.COM' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_no_request_method(self): """"""CORS Specification Section 6.2.3 If there is no Access-Control-Request-Method header or if parsing failed, do not set any additional headers and terminate this set of steps. The request is outside the scope of this specification. """""" # Test valid domain, valid method. request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://get.example.com' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://get.example.com', max_age=None, allow_methods='GET', allow_headers=None, allow_credentials=None, expose_headers=None) # Test valid domain, invalid HTTP method. request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://valid.example.com' request.headers['Access-Control-Request-Method'] = 'TEAPOT' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) # Test valid domain, no HTTP method. request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://valid.example.com' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_invalid_method(self): """"""CORS Specification Section 6.2.3 If method is not a case-sensitive match for any of the values in list of methods do not set any additional headers and terminate this set of steps. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://get.example.com' request.headers['Access-Control-Request-Method'] = 'get' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_no_parse_request_headers(self): """"""CORS Specification Section 6.2.4 If there are no Access-Control-Request-Headers headers let header field-names be the empty list. If parsing failed do not set any additional headers and terminate this set of steps. The request is outside the scope of this specification. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://headers.example.com' request.headers['Access-Control-Request-Method'] = 'GET' request.headers['Access-Control-Request-Headers'] = 'value with spaces' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_no_request_headers(self): """"""CORS Specification Section 6.2.4 If there are no Access-Control-Request-Headers headers let header field-names be the empty list. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://headers.example.com' request.headers['Access-Control-Request-Method'] = 'GET' request.headers['Access-Control-Request-Headers'] = '' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://headers.example.com', max_age=None, allow_methods='GET', allow_headers=None, allow_credentials=None, expose_headers=None) def test_request_headers(self): """"""CORS Specification Section 6.2.4 Let header field-names be the values as result of parsing the Access-Control-Request-Headers headers. If there are no Access-Control-Request-Headers headers let header field-names be the empty list. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://headers.example.com' request.headers['Access-Control-Request-Method'] = 'GET' request.headers['Access-Control-Request-Headers'] = 'X-Header-1,' \ 'X-Header-2' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://headers.example.com', max_age=None, allow_methods='GET', allow_headers='X-Header-1,X-Header-2', allow_credentials=None, expose_headers=None) def test_request_headers_not_permitted(self): """"""CORS Specification Section 6.2.4, 6.2.6 If there are no Access-Control-Request-Headers headers let header field-names be the empty list. If any of the header field-names is not a ASCII case-insensitive match for any of the values in list of headers do not set any additional headers and terminate this set of steps. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://headers.example.com' request.headers['Access-Control-Request-Method'] = 'GET' request.headers['Access-Control-Request-Headers'] = 'X-Not-Exposed,' \ 'X-Never-Exposed' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_credentials(self): """"""CORS Specification Section 6.2.7 If the resource supports credentials add a single Access-Control-Allow-Origin header, with the value of the Origin header as value, and add a single Access-Control-Allow-Credentials header with the case-sensitive string ""true"" as value. Otherwise, add a single Access-Control-Allow-Origin header, with either the value of the Origin header or the string ""*"" as value. NOTE: We never use the ""*"" as origin. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://creds.example.com' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://creds.example.com', max_age=None, allow_methods='GET', allow_headers=None, allow_credentials=""true"", expose_headers=None) def test_optional_max_age(self): """"""CORS Specification Section 6.2.8 Optionally add a single Access-Control-Max-Age header with as value the amount of seconds the user agent is allowed to cache the result of the request. """""" request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://cached.example.com' request.headers['Access-Control-Request-Method'] = 'GET' response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://cached.example.com', max_age=3600, allow_methods='GET', allow_headers=None, allow_credentials=None, expose_headers=None) def test_allow_methods(self): """"""CORS Specification Section 6.2.9 Add one or more Access-Control-Allow-Methods headers consisting of (a subset of) the list of methods. Since the list of methods can be unbounded, simply returning the method indicated by Access-Control-Request-Method (if supported) can be enough. """""" for method in ['GET', 'PUT', 'POST', 'DELETE']: request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://all.example.com' request.headers['Access-Control-Request-Method'] = method response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://all.example.com', max_age=None, allow_methods=method, allow_headers=None, allow_credentials=None, expose_headers=None) for method in ['PUT', 'POST', 'DELETE']: request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://get.example.com' request.headers['Access-Control-Request-Method'] = method response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin=None, max_age=None, allow_methods=None, allow_headers=None, allow_credentials=None, expose_headers=None) def test_allow_headers(self): """"""CORS Specification Section 6.2.10 Add one or more Access-Control-Allow-Headers headers consisting of (a subset of) the list of headers. If each of the header field-names is a simple header and none is Content-Type, this step may be skipped. If a header field name is a simple header and is not Content-Type, it is not required to be listed. Content-Type is to be listed as only a subset of its values makes it qualify as simple header. """""" requested_headers = 'Content-Type,X-Header-1,Cache-Control,Expires,' \ 'Last-Modified,Pragma' request = webob.Request({}) request.method = ""OPTIONS"" request.headers['Origin'] = 'http://headers.example.com' request.headers['Access-Control-Request-Method'] = 'GET' request.headers['Access-Control-Request-Headers'] = requested_headers response = request.get_response(self.application) self.assertCORSResponse(response, status='200 OK', allow_origin='http://headers.example.com', max_age=None, allow_methods='GET', allow_headers=requested_headers, allow_credentials=None, expose_headers=None)",,953,0
openstack%2Fneutron~master~I9bd552110785c09b3eaa8762a8141446e51ea02a,openstack/neutron,master,I9bd552110785c09b3eaa8762a8141446e51ea02a,Remove unnecessary brackets,MERGED,2015-05-25 04:20:46.000000000,2015-05-26 21:33:35.000000000,2015-05-26 21:33:33.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7634}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9911}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12955}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15752}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-25 04:20:46.000000000', 'files': ['neutron/ipam/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/514245d63fe902e4548829b9bb66fa60c86509f1', 'message': 'Remove unnecessary brackets\n\nTrivialFix\n\nChange-Id: I9bd552110785c09b3eaa8762a8141446e51ea02a\n'}]",1,185301,514245d63fe902e4548829b9bb66fa60c86509f1,35,29,1,1653,,,0,"Remove unnecessary brackets

TrivialFix

Change-Id: I9bd552110785c09b3eaa8762a8141446e51ea02a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/185301/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/ipam/exceptions.py'],1,514245d63fe902e4548829b9bb66fa60c86509f1,extras," message = _(""IPv6 address %(ip)s cannot be directly "" ""assigned to a port on subnet %(subnet_id)s as the "" ""subnet is configured for automatic addresses"")"," message = (_(""IPv6 address %(ip)s cannot be directly "" ""assigned to a port on subnet %(subnet_id)s as the "" ""subnet is configured for automatic addresses""))",3,3
openstack%2Foslo.vmware~master~I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd,openstack/oslo.vmware,master,I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd,Raise VimFaultException for unknown faults,MERGED,2015-04-23 10:37:46.000000000,2015-05-26 21:32:40.000000000,2015-04-30 11:42:47.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 9008}, {'_account_id': 9171}]","[{'number': 1, 'created': '2015-04-23 10:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/728cbc1ab64965f2a1c886f41035a7d7e3498a7a', 'message': 'Raise VimFaultException for unknown faults\n\nCurrently VMwareDriverException is raised for unknown\nVIM faults. Sometimes clients may need to handle such\nfaults. Therefore it is better if we throw\nVimFaultException with the fault_list set to the relevant\nVIM fault class name.\n\nChange-Id: I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd\n'}, {'number': 2, 'created': '2015-04-23 10:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/c5c9f86ddf1030c004f56ca195783e420dc2e27e', 'message': 'Raise VimFaultException for unknown faults\n\nCurrently VMwareDriverException is raised for unknown\nVIM faults. Sometimes clients may need to handle such\nfaults. Therefore it is better if we throw\nVimFaultException with the fault_list set to the relevant\nVIM fault class name.\n\nChange-Id: I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd\n'}, {'number': 3, 'created': '2015-04-30 06:43:31.000000000', 'files': ['oslo_vmware/tests/test_exceptions.py', 'oslo_vmware/exceptions.py', 'oslo_vmware/tests/test_api.py', 'oslo_vmware/api.py', 'tests/test_api.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/1668fef9cabea6a23023aab6b97617b4368b14d6', 'message': 'Raise VimFaultException for unknown faults\n\nCurrently VMwareDriverException is raised for unknown\nVIM faults. Sometimes clients may need to handle such\nfaults. Therefore it is better if we throw\nVimFaultException with the fault_list set to the relevant\nVIM fault class name.\n\nChange-Id: I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd\n'}]",0,176694,1668fef9cabea6a23023aab6b97617b4368b14d6,20,5,3,9171,,,0,"Raise VimFaultException for unknown faults

Currently VMwareDriverException is raised for unknown
VIM faults. Sometimes clients may need to handle such
faults. Therefore it is better if we throw
VimFaultException with the fault_list set to the relevant
VIM fault class name.

Change-Id: I34f84f3ea3f5f0d6878f1d4438cf25bf22f293fd
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/94/176694/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_vmware/tests/test_exceptions.py', 'oslo_vmware/exceptions.py', 'oslo_vmware/tests/test_api.py', 'oslo_vmware/api.py']",4,728cbc1ab64965f2a1c886f41035a7d7e3498a7a,unknown_fault," if clazz: raise clazz(six.text_type(excep), excep.details) fault_class = exceptions.get_fault_class(name) if fault_class: task_ex = fault_class(error_msg) else: task_ex = exceptions.VimFaultException([fault_class], error_msg)"," raise clazz(six.text_type(excep), excep.details) task_ex = exceptions.get_fault_class(name)(error_msg)",25,8
openstack%2Fneutron~master~If4a310da06f9b0076a9f62926a16b574a8c109ce,openstack/neutron,master,If4a310da06f9b0076a9f62926a16b574a8c109ce,OVS-DVR: Suppress a confusing error log about csnat port,MERGED,2015-05-15 02:36:06.000000000,2015-05-26 21:29:54.000000000,2015-05-26 21:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-05-15 02:36:06.000000000', 'files': ['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8dbacebf6752e7654afbf9451388b42d4d6355a9', 'message': 'OVS-DVR: Suppress a confusing error log about csnat port\n\nComplain only when the port was seen on a different subnet.\n\nChange-Id: If4a310da06f9b0076a9f62926a16b574a8c109ce\n'}]",3,183380,8dbacebf6752e7654afbf9451388b42d4d6355a9,34,22,1,6854,,,0,"OVS-DVR: Suppress a confusing error log about csnat port

Complain only when the port was seen on a different subnet.

Change-Id: If4a310da06f9b0076a9f62926a16b574a8c109ce
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/183380/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py'],1,8dbacebf6752e7654afbf9451388b42d4d6355a9,csnat, if subs[0] == fixed_ips[0]['subnet_id']: return,,2,0
openstack%2Fdevstack~master~I3384039392be786d3c189f3e4f84e069ddaf4339,openstack/devstack,master,I3384039392be786d3c189f3e4f84e069ddaf4339,Use correct conf file variable name in sahara,MERGED,2015-05-26 19:35:01.000000000,2015-05-26 21:29:48.000000000,2015-05-26 21:29:46.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 7662}]","[{'number': 1, 'created': '2015-05-26 19:35:01.000000000', 'files': ['lib/sahara'], 'web_link': 'https://opendev.org/openstack/devstack/commit/aece9ff9eff94fcdd2bdac14d64536e16207139d', 'message': 'Use correct conf file variable name in sahara\n\nWhen the tls-proxy service is enabled then a separate\nset of ports is used internally vs externally. The\nservices listen on the internal port and a proxy (stud)\nlisten on the ""standard"" port and forward requests to\nthe internal port.\n\nAn incorrect environment variable was being used to set\nthe internal port in the sahara configuration so it wasn\'t\nlistening on the correct port, causing stack.sh to fail\nbecause it thought the service wasn\'t up (at least not\non the right port).\n\nChange-Id: I3384039392be786d3c189f3e4f84e069ddaf4339\nCloses-Bug: #1458984\n'}]",0,185712,aece9ff9eff94fcdd2bdac14d64536e16207139d,7,3,1,7662,,,0,"Use correct conf file variable name in sahara

When the tls-proxy service is enabled then a separate
set of ports is used internally vs externally. The
services listen on the internal port and a proxy (stud)
listen on the ""standard"" port and forward requests to
the internal port.

An incorrect environment variable was being used to set
the internal port in the sahara configuration so it wasn't
listening on the correct port, causing stack.sh to fail
because it thought the service wasn't up (at least not
on the right port).

Change-Id: I3384039392be786d3c189f3e4f84e069ddaf4339
Closes-Bug: #1458984
",git fetch https://review.opendev.org/openstack/devstack refs/changes/12/185712/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/sahara'],1,aece9ff9eff94fcdd2bdac14d64536e16207139d,1458984, iniset $SAHARA_CONF_FILE DEFAULT port $SAHARA_SERVICE_PORT_INT, iniset $SAHARA_CONF DEFAULT port $SAHARA_SERVICE_PORT_INT,1,1
openstack%2Fhorizon~master~I18c37225b9a5b4943fa36f70539b20a9b739bf2b,openstack/horizon,master,I18c37225b9a5b4943fa36f70539b20a9b739bf2b,Add kernel/ramdisk for image create,MERGED,2015-05-04 16:15:19.000000000,2015-05-26 21:27:28.000000000,2015-05-26 20:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 7509}, {'_account_id': 8532}, {'_account_id': 9317}, {'_account_id': 9622}, {'_account_id': 10442}, {'_account_id': 11997}, {'_account_id': 13785}]","[{'number': 1, 'created': '2015-05-04 16:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/780a39ae6d60b94dad05397fc729187cb8d1ee62', 'message': 'Add kernel/ramdisk for image create\n\nAdd ability to specify kernel and ramdisk during image create.\n\nCloses-bug: #1451413\nChange-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b\n'}, {'number': 2, 'created': '2015-05-04 16:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4a9fef76c551f85b6328240c30e88db3df422a3b', 'message': 'Add kernel/ramdisk for image create\n\nAdd ability to specify kernel and ramdisk during image create.\n\nCloses-bug: #1451413\nChange-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b\n'}, {'number': 3, 'created': '2015-05-05 12:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e9924f8ae8614754ce558e161109e3f47a8bc05', 'message': 'Add kernel/ramdisk for image create\n\nAdd ability to specify kernel and ramdisk during image create.\n\nCloses-bug: #1451413\nChange-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b\n'}, {'number': 4, 'created': '2015-05-06 10:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/440ea566adac5304e1a3d4b47e828e3680854443', 'message': 'Add kernel/ramdisk for image create\n\nAdd ability to specify kernel and ramdisk during image create.\n\nCloses-bug: #1451413\nChange-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b\n'}, {'number': 5, 'created': '2015-05-09 13:22:30.000000000', 'files': ['openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/dashboards/project/images/images/forms.py', 'openstack_dashboard/dashboards/project/images/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5784a81e11b30133df8d1bae1cf08f715e7ba338', 'message': 'Add kernel/ramdisk for image create\n\nAdd ability to specify kernel and ramdisk during image create.\n\nCloses-bug: #1451413\nChange-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b\n'}]",18,179833,5784a81e11b30133df8d1bae1cf08f715e7ba338,35,10,5,9317,,,0,"Add kernel/ramdisk for image create

Add ability to specify kernel and ramdisk during image create.

Closes-bug: #1451413
Change-Id: I18c37225b9a5b4943fa36f70539b20a9b739bf2b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/33/179833/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/dashboards/project/images/images/forms.py']",3,780a39ae6d60b94dad05397fc729187cb8d1ee62,bug/1451413,"from django.template import defaultfilters kernel = forms.ChoiceField( required=False, widget=forms.SelectWidget( transform=lambda x: ""%s (%s)"" % ( x.name, defaultfilters.filesizeformat(x.size)))) ramdisk = forms.ChoiceField( required=False, widget=forms.SelectWidget( transform=lambda x: ""%s (%s)"" % ( x.name, defaultfilters.filesizeformat(x.size)))) kernel_images = api.glance.image_list_detailed( request, filters={'disk_format': 'aki'})[0] if kernel_images: choices = [('', _(""Choose an image""))] for image in kernel_images: choices.append((image.id, image)) self.fields['kernel'].choices = choices else: del self.fields['kernel'] ramdisk_images = api.glance.image_list_detailed( request, filters={'disk_format': 'ari'})[0] if ramdisk_images: choices = [('', _(""Choose an image""))] for image in ramdisk_images: choices.append((image.id, image)) self.fields['ramdisk'].choices = choices else: del self.fields['ramdisk'] if data['kernel']: meta['properties']['kernel_id'] = data['kernel'] if data['ramdisk']: meta['properties']['ramdisk_id'] = data['ramdisk']",,105,6
openstack%2Fpuppet-monasca~master~I3a2b53ea9eb12caadfdce58987e33b8171773335,openstack/puppet-monasca,master,I3a2b53ea9eb12caadfdce58987e33b8171773335,Fix syntax errors in metadata.json,MERGED,2015-05-26 20:15:30.000000000,2015-05-26 21:10:11.000000000,2015-05-26 21:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 8126}, {'_account_id': 9500}, {'_account_id': 11155}]","[{'number': 1, 'created': '2015-05-26 20:15:30.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/bb9cee03df736c8cfea1fe21ade44fd8965ca5c6', 'message': 'Fix syntax errors in metadata.json\n\nChange-Id: I3a2b53ea9eb12caadfdce58987e33b8171773335\n'}]",0,185727,bb9cee03df736c8cfea1fe21ade44fd8965ca5c6,7,4,1,10540,,,0,"Fix syntax errors in metadata.json

Change-Id: I3a2b53ea9eb12caadfdce58987e33b8171773335
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/27/185727/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,bb9cee03df736c8cfea1fe21ade44fd8965ca5c6,(detached," ""summary"": ""Puppet module for OpenStack Monasca"", { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }"," ""summary"": ""Puppet module for OpenStack Monasca"" { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",2,2
openstack%2Fpuppet-monasca~master~I69d1f48d360073caa1b04b30ca304966cbd7fac5,openstack/puppet-monasca,master,I69d1f48d360073caa1b04b30ca304966cbd7fac5,Fix variable access in nagios wrapper config,MERGED,2015-05-26 18:21:05.000000000,2015-05-26 21:09:21.000000000,2015-05-26 21:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 8126}, {'_account_id': 9500}, {'_account_id': 11155}]","[{'number': 1, 'created': '2015-05-26 18:21:05.000000000', 'files': ['templates/checks/nagios_wrapper.yaml.erb'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/d6cc45127c0f310551b03a3de4a0812afaa81b7f', 'message': 'Fix variable access in nagios wrapper config\n\nWithout this puppet issues warning.\n\nChange-Id: I69d1f48d360073caa1b04b30ca304966cbd7fac5\n'}]",0,185690,d6cc45127c0f310551b03a3de4a0812afaa81b7f,8,4,1,10540,,,0,"Fix variable access in nagios wrapper config

Without this puppet issues warning.

Change-Id: I69d1f48d360073caa1b04b30ca304966cbd7fac5
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/90/185690/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/checks/nagios_wrapper.yaml.erb'],1,d6cc45127c0f310551b03a3de4a0812afaa81b7f,template_variable_warning, check_path: <%= @check_path %> temp_file_path: <%= @temp_file_path %>, check_path: <%= check_path %> temp_file_path: <%= temp_file_path %>,2,2
openstack%2Foslo-cookiecutter~master~Iee95676db2e7ec521fa1117d81819b3271593827,openstack/oslo-cookiecutter,master,Iee95676db2e7ec521fa1117d81819b3271593827,Replace ci.o.o links with docs.o.o/infra,MERGED,2015-05-14 21:42:00.000000000,2015-05-26 21:02:55.000000000,2015-05-26 21:02:55.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-14 21:42:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/aa73b592c8c71c8b6ab65141e445d3bca628af25', 'message': 'Replace ci.o.o links with docs.o.o/infra\n\nThe http://ci.openstack.org/ documentation site has been deprecated,\nreplaced by redirects to corresponding paths within\nhttp://docs.openstack.org/infra/ where other Project Infrastructure\ndocumentation already resides.\n\nChange-Id: Iee95676db2e7ec521fa1117d81819b3271593827\n'}]",0,183230,aa73b592c8c71c8b6ab65141e445d3bca628af25,7,3,1,5263,,,0,"Replace ci.o.o links with docs.o.o/infra

The http://ci.openstack.org/ documentation site has been deprecated,
replaced by redirects to corresponding paths within
http://docs.openstack.org/infra/ where other Project Infrastructure
documentation already resides.

Change-Id: Iee95676db2e7ec521fa1117d81819b3271593827
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/30/183230/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,aa73b592c8c71c8b6ab65141e445d3bca628af25,infra-docs,.. _OpenStack-Infra: http://docs.openstack.org/infra/system-config,.. _OpenStack-Infra: http://ci.openstack.org,1,1
openstack%2Fhorizon~master~Icb91cdc0d4610407c4eeeda82f194c7016e3b540,openstack/horizon,master,Icb91cdc0d4610407c4eeeda82f194c7016e3b540,Inherit environment variables for tests that use nodeenv,MERGED,2015-05-26 19:18:03.000000000,2015-05-26 21:02:45.000000000,2015-05-26 21:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9981}]","[{'number': 1, 'created': '2015-05-26 19:18:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/22c485b179681aa3fdcf3dc1207bbd0d2588acb9', 'message': 'Inherit environment variables for tests that use nodeenv\n\nTox 2.0 stopped automatically passing environment variables into the\nvirtual environment which potentially breaks test jobs which use nodeenv\nbecause of the nature of running nodeenv within a virtual environment.\n\nThe nodeenv documentation (https://pypi.python.org/pypi/nodeenv) even\nsays:\n\n""\nIf you already have the python virtualenv tool, and want to use nodeenv\nand virtualenv in conjunction, then you should create (or activate) the\npython virtual environment:\n\n# in case of using virtualenv_wrapper\n$ mkvirtualenv my_env\n\n# in case of using virtualenv\n$ . my_env/bin/activate\nand add a node virtual environment to this existing new_venv:\n\n$ nodeenv -p\n""\n\nSince we can\'t source {envdir}/bin/activate from within the tox.ini, we\njust pass the environment variables into the virtual environment using\npassenv = *.\n\nAn alternative may be to change run_test.sh to run tests which use\nnodeenv within a venv by sourcing $VIRTUAL_ENV/bin/activate from within\nrun_test.sh.\n\nCloses-Bug: #1458928\n\nChange-Id: Icb91cdc0d4610407c4eeeda82f194c7016e3b540\n'}]",0,185707,22c485b179681aa3fdcf3dc1207bbd0d2588acb9,10,7,1,6873,,,0,"Inherit environment variables for tests that use nodeenv

Tox 2.0 stopped automatically passing environment variables into the
virtual environment which potentially breaks test jobs which use nodeenv
because of the nature of running nodeenv within a virtual environment.

The nodeenv documentation (https://pypi.python.org/pypi/nodeenv) even
says:

""
If you already have the python virtualenv tool, and want to use nodeenv
and virtualenv in conjunction, then you should create (or activate) the
python virtual environment:

# in case of using virtualenv_wrapper
$ mkvirtualenv my_env

# in case of using virtualenv
$ . my_env/bin/activate
and add a node virtual environment to this existing new_venv:

$ nodeenv -p
""

Since we can't source {envdir}/bin/activate from within the tox.ini, we
just pass the environment variables into the virtual environment using
passenv = *.

An alternative may be to change run_test.sh to run tests which use
nodeenv within a venv by sourcing $VIRTUAL_ENV/bin/activate from within
run_test.sh.

Closes-Bug: #1458928

Change-Id: Icb91cdc0d4610407c4eeeda82f194c7016e3b540
",git fetch https://review.opendev.org/openstack/horizon refs/changes/07/185707/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,22c485b179681aa3fdcf3dc1207bbd0d2588acb9,bug/1458928,passenv = *passenv = *,,2,0
openstack%2Foslo-cookiecutter~master~I5b370a806ef2acde57cc6c21cf200f28fa7adfa6,openstack/oslo-cookiecutter,master,I5b370a806ef2acde57cc6c21cf200f28fa7adfa6,Improve CONTRIBUTING.rst for clarity,MERGED,2015-05-16 13:16:01.000000000,2015-05-26 21:02:33.000000000,2015-05-26 21:02:33.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-16 13:16:01.000000000', 'files': ['CONTRIBUTING.rst', 'oslo.{{cookiecutter.module_name}}/CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/26b22bb1cd7f74b2ce16e505f8ca3f99c3b0118c', 'message': 'Improve CONTRIBUTING.rst for clarity\n\nChange-Id: I5b370a806ef2acde57cc6c21cf200f28fa7adfa6\n'}]",0,183793,26b22bb1cd7f74b2ce16e505f8ca3f99c3b0118c,7,3,1,5263,,,0,"Improve CONTRIBUTING.rst for clarity

Change-Id: I5b370a806ef2acde57cc6c21cf200f28fa7adfa6
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/93/183793/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'oslo.{{cookiecutter.module_name}}/CONTRIBUTING.rst']",2,26b22bb1cd7f74b2ce16e505f8ca3f99c3b0118c,contributing-doc,"If you would like to contribute to the development of OpenStack, you must follow the steps in this page:If you already have a good understanding of how the system works and your OpenStack accounts are set up, you can skip to the development workflow section of this documentation to learn how changes to OpenStack should be submitted for review via the Gerrit tool:","If you would like to contribute to the development of OpenStack, you must follow the steps in this page:Once those steps have been completed, changes to OpenStack should be submitted for review via the Gerrit tool, following the workflow documented at:",12,10
openstack%2Fceilometer~master~I526467ef2f8204e8093f7470b86949e3e0e69990,openstack/ceilometer,master,I526467ef2f8204e8093f7470b86949e3e0e69990,Fixing event types pattern for Role Noti. handler,MERGED,2015-05-22 21:12:41.000000000,2015-05-26 21:01:47.000000000,2015-05-26 09:22:33.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12927}, {'_account_id': 13560}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-22 21:12:41.000000000', 'files': ['ceilometer/identity/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/02bab799bab051cc22f4fdf9d19d7a17939cdde7', 'message': 'Fixing event types pattern for Role Noti. handler\n\nIdentity(Keystone) notifications have a handler\nfor Role that has event type as identity.role.*\nAnother for RoleAssignment which accepts\nidentity.role_assignment.* events.\n\nSince event types are regular expressions,\nan event like identity.role_assignment.created\nis matched with identity.role.* and gets incorrectly\nrouted to the Role Handler.\n\nThis fix restricts the event type regex for Role\nhandler to just identity.role.* events and excludes\nidentity.role_* events.\n\nChange-Id: I526467ef2f8204e8093f7470b86949e3e0e69990\nCloses-Bug: #1457785\n'}]",0,185146,02bab799bab051cc22f4fdf9d19d7a17939cdde7,15,8,1,13560,,,0,"Fixing event types pattern for Role Noti. handler

Identity(Keystone) notifications have a handler
for Role that has event type as identity.role.*
Another for RoleAssignment which accepts
identity.role_assignment.* events.

Since event types are regular expressions,
an event like identity.role_assignment.created
is matched with identity.role.* and gets incorrectly
routed to the Role Handler.

This fix restricts the event type regex for Role
handler to just identity.role.* events and excludes
identity.role_* events.

Change-Id: I526467ef2f8204e8093f7470b86949e3e0e69990
Closes-Bug: #1457785
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/46/185146/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/identity/notifications.py'],1,02bab799bab051cc22f4fdf9d19d7a17939cdde7,bug/1457785, return ['%s\..*' % self.resource_name], return ['%s.*' % self.resource_name],1,1
openstack%2Fshade~master~I78d0e6daedfe3cf1a0db5f606c21af803450f018,openstack/shade,master,I78d0e6daedfe3cf1a0db5f606c21af803450f018,Make caching work when cloud name is None,MERGED,2015-05-26 18:49:59.000000000,2015-05-26 20:53:23.000000000,2015-05-26 20:53:21.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 4146}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-26 18:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0530ee2cc428f61097abe337bd1bd1c8fea8cc90', 'message': 'Make caching work when cloud name is None\n\nAll of the other keys are coerced to strings through some method but a\ncloud name of None with no namespace produces a TypeError because\nsequence 0 is not a string when joined.\n\nChange-Id: I78d0e6daedfe3cf1a0db5f606c21af803450f018\n'}, {'number': 2, 'created': '2015-05-26 19:45:54.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/f57433929a9d51fd7927ed43a639a1d8917695a4', 'message': 'Make caching work when cloud name is None\n\nAll of the other keys are coerced to strings through some method but a\ncloud name of None with no namespace produces a TypeError because\nsequence 0 is not a string when joined.\n\nChange-Id: I78d0e6daedfe3cf1a0db5f606c21af803450f018\n'}]",1,185699,f57433929a9d51fd7927ed43a639a1d8917695a4,13,5,2,6488,,,0,"Make caching work when cloud name is None

All of the other keys are coerced to strings through some method but a
cloud name of None with no namespace produces a TypeError because
sequence 0 is not a string when joined.

Change-Id: I78d0e6daedfe3cf1a0db5f606c21af803450f018
",git fetch https://review.opendev.org/openstack/shade refs/changes/99/185699/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_caching.py', 'shade/__init__.py']",2,0530ee2cc428f61097abe337bd1bd1c8fea8cc90,," [str(name_key), fname, arg_key, kwargs_key])"," [name_key, fname, arg_key, kwargs_key])",7,1
openstack%2Fdesignate~stable%2Fkilo~I90b8f499f23762cbc6333be764439104189238b8,openstack/designate,stable/kilo,I90b8f499f23762cbc6333be764439104189238b8,Remove unnecessary RestController usage,MERGED,2015-05-26 17:56:51.000000000,2015-05-26 20:43:04.000000000,2015-05-26 20:43:02.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 9382}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-26 17:56:51.000000000', 'files': ['designate/api/v2/controllers/zones/tasks/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/c7b7975d877fc09462f4f761ed2527a0db1e062a', 'message': ""Remove unnecessary RestController usage\n\nTasksControllers is just an intermediate path segment, and doesn't need to be\na RestController.  Additionally, this resolves a failing test associated with\na RestController bug fix in pecan [1].\n\n[1] https://review.openstack.org/#/c/181979/\nCloses-Bug: #1334690\n\nChange-Id: I90b8f499f23762cbc6333be764439104189238b8\n(cherry picked from commit 35b6d607e130a8c2b5db3553e52cf71d93bded2c)\n""}]",0,185684,c7b7975d877fc09462f4f761ed2527a0db1e062a,8,7,1,8005,,,0,"Remove unnecessary RestController usage

TasksControllers is just an intermediate path segment, and doesn't need to be
a RestController.  Additionally, this resolves a failing test associated with
a RestController bug fix in pecan [1].

[1] https://review.openstack.org/#/c/181979/
Closes-Bug: #1334690

Change-Id: I90b8f499f23762cbc6333be764439104189238b8
(cherry picked from commit 35b6d607e130a8c2b5db3553e52cf71d93bded2c)
",git fetch https://review.opendev.org/openstack/designate refs/changes/84/185684/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/v2/controllers/zones/tasks/__init__.py'],1,c7b7975d877fc09462f4f761ed2527a0db1e062a,,class TasksController(object):,from designate.api.v2.controllers import restclass TasksController(rest.RestController):,1,2
openstack%2Ftripleo-heat-templates~master~I7e9eb665275bd48d9c079934cc01ba62b5f59e16,openstack/tripleo-heat-templates,master,I7e9eb665275bd48d9c079934cc01ba62b5f59e16,Ensures mongodb configuration only happens if mongodb is needed,MERGED,2015-05-20 13:49:33.000000000,2015-05-26 20:38:53.000000000,2015-05-26 20:38:47.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-20 13:49:33.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c4a822668199ca52fdaec28b0ba16c2fe417e4b4', 'message': 'Ensures mongodb configuration only happens if mongodb is needed\n\nChange-Id: I7e9eb665275bd48d9c079934cc01ba62b5f59e16\n'}]",0,184494,c4a822668199ca52fdaec28b0ba16c2fe417e4b4,20,8,1,6796,,,0,"Ensures mongodb configuration only happens if mongodb is needed

Change-Id: I7e9eb665275bd48d9c079934cc01ba62b5f59e16
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/184494/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,c4a822668199ca52fdaec28b0ba16c2fe417e4b4,mongodb," if downcase(hiera('ceilometer_backend')) == 'mongodb' { include ::mongodb::globals # FIXME: replace with service_manage => false on ::mongodb::server # when this is merged: https://github.com/puppetlabs/pupp etlabs-mongodb/pull/198 class { '::mongodb::server' : service_ensure => undef, service_enable => false, }"," # MongoDB include ::mongodb::globals # FIXME: replace with service_manage => false on ::mongodb::server # when this is merged: https://github.com/puppetlabs/pupp etlabs-mongodb/pull/198 class { '::mongodb::server' : service_ensure => undef, service_enable => false,",8,8
openstack%2Foslo.log~master~I4605f1596e59950d321cf9733d292b71feb98cdb,openstack/oslo.log,master,I4605f1596e59950d321cf9733d292b71feb98cdb,Use proper deprecation for use-syslog-rfc-format option,MERGED,2015-03-19 01:44:24.000000000,2015-05-26 20:36:33.000000000,2015-05-26 20:36:32.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 8119}]","[{'number': 1, 'created': '2015-03-19 01:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/eb36aabdd26a65bcd7bf643bb5833512b72694e9', 'message': 'Update confusing help text\n\nThe help text was referring to the Juno release as if it was in\nthe future.\n\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n'}, {'number': 2, 'created': '2015-03-19 01:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/264d433df378a01e4c5eb7692f2dcd82d85cc1e7', 'message': 'Syslog uses RFC format\n\nSyslog had an option to use RFC format or a different format for\nmessages, which was scheduled to be changed in Juno. The\ndeprecation period is now well past, so get rid of the deprecated\nbehavior.\n\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n'}, {'number': 3, 'created': '2015-03-19 17:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/f9ff83e2a882b311347eab8c113bceb7871d86d5', 'message': 'Syslog uses RFC format\n\nSyslog had an option to use RFC format or a different format for\nmessages, which was scheduled to be changed in Juno. The\ndeprecation period is now well past, so get rid of the deprecated\nbehavior.\n\nCloses-Bug: 1434212\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n'}, {'number': 4, 'created': '2015-05-10 15:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/9caf40c8a52ca7138f22397eda087deca7966e11', 'message': 'Remove use-syslog-rfc-format option\n\nSyslog logging had an option to use RFC format or a non-RFC format\nfor messages. The help text for this option says it will be removed\nin L.\n\nThe deprecated option and support for the old non-RFC syslog log\nformat are removed.\n\nRelated-Bug: 1434212\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n'}, {'number': 5, 'created': '2015-05-21 21:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/96c71af1b6f4d29e068b8583521242a52cc1d8fa', 'message': ""Use proper deprecation for use-syslog-rfc-format option\n\nThe use-syslog-rfc-format option wasn't deprecated properly since\nthere would be no log warning if the option was used.\n\nRelated-Bug: 1434212\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n""}, {'number': 6, 'created': '2015-05-26 00:42:39.000000000', 'files': ['oslo_log/_options.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/7730773d2e141c30272d4df79da2cdfde387120c', 'message': ""Use proper deprecation for use-syslog-rfc-format option\n\nThe use-syslog-rfc-format option wasn't deprecated properly since\nthere would be no log warning if the option was used.\n\nRelated-Bug: 1434212\nChange-Id: I4605f1596e59950d321cf9733d292b71feb98cdb\n""}]",2,165674,7730773d2e141c30272d4df79da2cdfde387120c,33,6,6,6486,,,0,"Use proper deprecation for use-syslog-rfc-format option

The use-syslog-rfc-format option wasn't deprecated properly since
there would be no log warning if the option was used.

Related-Bug: 1434212
Change-Id: I4605f1596e59950d321cf9733d292b71feb98cdb
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/74/165674/6 && git format-patch -1 --stdout FETCH_HEAD,['oslo_log/_options.py'],1,eb36aabdd26a65bcd7bf643bb5833512b72694e9,bug/1434212," help='Use syslog for logging.'), 'syslog message with APP-NAME (RFC5424).'),"," help='Use syslog for logging. ' 'Existing syslog format is DEPRECATED during I, ' 'and will change in J to honor RFC5424.'), # TODO(bogdando) remove or use True after existing # syslog format deprecation in J 'syslog message with APP-NAME (RFC5424). The ' 'format without the APP-NAME is deprecated in I, ' 'and will be removed in J.'),",2,8
openstack%2Fkeystonemiddleware~stable%2Fjuno~Ia708602b882d797eb6a11a6fd00091183e904560,openstack/keystonemiddleware,stable/juno,Ia708602b882d797eb6a11a6fd00091183e904560,Updated from global requirements,MERGED,2015-05-14 22:29:08.000000000,2015-05-26 20:36:05.000000000,2015-05-26 20:36:04.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-05-14 22:29:08.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4c7366a46164e97663d925568ea74dc3026df471', 'message': 'Updated from global requirements\n\nChange-Id: Ia708602b882d797eb6a11a6fd00091183e904560\n'}]",0,183335,4c7366a46164e97663d925568ea74dc3026df471,9,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ia708602b882d797eb6a11a6fd00091183e904560
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/35/183335/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4c7366a46164e97663d925568ea74dc3026df471,openstack/requirements,"pycadf>=0.6.0,!=0.6.2,<0.7.0 # Apache-2.0","pycadf>=0.6.0,<0.7.0 # Apache-2.0",1,1
openstack%2Fdesignate~master~Ic6cd00850442c7b31ca5034f1306d37e69991014,openstack/designate,master,Ic6cd00850442c7b31ca5034f1306d37e69991014,Infoblox Backend,MERGED,2015-05-14 16:39:53.000000000,2015-05-26 20:33:52.000000000,2015-05-26 20:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 12912}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-14 16:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4281a52e92b8c97f2d0e8c8a5bbde21d42454057', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint bp/infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}, {'number': 2, 'created': '2015-05-14 16:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f2c5d12a023539f3cf3d1c4b5b11a8333423a90d', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}, {'number': 3, 'created': '2015-05-15 17:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4ecf3abec122e2610dd5fa8b56883ca446a69f8e', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}, {'number': 4, 'created': '2015-05-15 18:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/dba2e0eb405d2ca2799c898adca8a9b8bdae2540', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}, {'number': 5, 'created': '2015-05-26 13:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c05fa7c5e63cba5024d63890f27f7c98db998ef1', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}, {'number': 6, 'created': '2015-05-26 17:05:54.000000000', 'files': ['designate/backend/impl_infoblox/ibexceptions.py', 'designate/backend/impl_infoblox/object_manipulator.py', 'doc/source/backends/infoblox.rst', 'designate/backend/impl_infoblox/__init__.py', 'designate/backend/impl_infoblox/connector.py', 'doc/source/backends.rst', 'designate/tests/test_backend/test_infoblox.py', 'contrib/devstack/lib/designate_plugins/backend-infoblox', 'designate/backend/impl_infoblox/config.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/designate/commit/65a53e54388fcd4a39625334351a867450bb2f9a', 'message': 'Infoblox Backend\n\nAdd a backend for integrating with Infoblox grids. Infoblox will\nserve as a secondary for Designate-controlled zones.\n\nImplements: blueprint infoblox-backend\n\nChange-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014\n'}]",6,183105,65a53e54388fcd4a39625334351a867450bb2f9a,27,6,6,12912,,,0,"Infoblox Backend

Add a backend for integrating with Infoblox grids. Infoblox will
serve as a secondary for Designate-controlled zones.

Implements: blueprint infoblox-backend

Change-Id: Ic6cd00850442c7b31ca5034f1306d37e69991014
",git fetch https://review.opendev.org/openstack/designate refs/changes/05/183105/3 && git format-patch -1 --stdout FETCH_HEAD,"['designate/backend/impl_infoblox/ibexceptions.py', 'designate/backend/impl_infoblox/object_manipulator.py', 'doc/source/backends/infoblox.rst', 'designate/backend/impl_infoblox/__init__.py', 'designate/backend/impl_infoblox/connector.py', 'designate/tests/test_backend/test_infoblox.py', 'contrib/devstack/lib/designate_plugins/backend-infoblox', 'designate/backend/impl_infoblox/config.py', 'setup.cfg']",9,4281a52e92b8c97f2d0e8c8a5bbde21d42454057,bp/infoblox-backend, infoblox = designate.backend.impl_infoblox:InfobloxBackend,,941,0
openstack%2Ftripleo-heat-templates~master~Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f,openstack/tripleo-heat-templates,master,Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f,We don't need to create the clustercheck user anymore,MERGED,2015-05-20 12:54:42.000000000,2015-05-26 20:30:59.000000000,2015-05-26 20:30:57.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-20 12:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf9724122b08a4ce131cca202c5e0eaf38324b27', 'message': 'We only need galera-ready on the pacemaker_master node\n\nThe galera-ready exec is meant to unlock creation of the services\ndatabase and clustercheckuser, we do both these things only on the\npacemaker_master nodes so we can make galera-ready visible only\nwithin that scope, avoiding other nodes to attempt to use the mysql\nclient when the service is unavailable and logging errors.\n\nAlso ensures mongodb configuration in step 1 only happens if\nmongodb is needed.\n\nChange-Id: Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f\n'}, {'number': 2, 'created': '2015-05-20 12:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5446efe83105f8dd5218f372ca836c98b82c03bc', 'message': 'We only need galera-ready on the pacemaker_master node\n\nThe galera-ready exec is meant to unlock creation of the services\ndatabase and clustercheckuser, we do both these things only on the\npacemaker_master nodes so we can make galera-ready visible only\nwithin that scope, avoiding other nodes to attempt to use the mysql\nclient when the service is unavailable and logging errors.\n\nAlso ensures mongodb configuration in step 1 only happens if\nmongodb is needed.\n\nChange-Id: Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f\n'}, {'number': 3, 'created': '2015-05-21 09:44:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4d5c7a8cf6735e505a0d5e7391623828b03e87e', 'message': ""We don't need to create the clustercheck user anymore\n\nWith change I4b6b77e878017bf92d7c59c868d393e74405a355 we started\nusing the root user for clustercheck script so we don't need to\ncreate the clustercheck user anymore.\n\nChange-Id: Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f\n""}]",1,184476,b4d5c7a8cf6735e505a0d5e7391623828b03e87e,19,7,3,6796,,,0,"We don't need to create the clustercheck user anymore

With change I4b6b77e878017bf92d7c59c868d393e74405a355 we started
using the root user for clustercheck script so we don't need to
create the clustercheck user anymore.

Change-Id: Ic92bd12baeeeaf3f674e766fbc0a8badfb44822f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/76/184476/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,cf9724122b08a4ce131cca202c5e0eaf38324b27,clustercheck," if downcase(hiera('ceilometer_backend')) == 'mongodb' { include ::mongodb::globals # FIXME: replace with service_manage => false on ::mongodb::server # when this is merged: https://github.com/puppetlabs/pupp etlabs-mongodb/pull/198 class { '::mongodb::server' : service_ensure => undef, service_enable => false, } fi exec { 'galera-ready' : command => '/bin/mysql -e ""SHOW GLOBAL VARIABLES LIKE \'read_only\'"" | /bin/grep -i off', timeout => 600, tries => 60, try_sleep => 10, environment => 'HOME=/root', } # Create all the database schemas # Example DSN format: mysql://user:password@host/dbname # NOTE(gfidente): this is needed by clustercheck script mysql_user { 'clustercheckuser@localhost' : password_hash => mysql_password($clustercheck_password), require => Exec['galera-ready'], } } file { '/etc/sysconfig/clustercheck' : ensure => file, content => ""MYSQL_USERNAME=clustercheckuser\n MYSQL_PASSWORD=${clustercheck_password}\n MYSQL_HOST=localhost\n"", } xinetd::service { 'galera-monitor' : port => '9200', server => '/usr/bin/clustercheck', per_source => 'UNLIMITED', log_on_success => '', log_on_failure => 'HOST', flags => 'REUSE', service_type => 'UNLISTED', user => 'root', group => 'root', require => File['/etc/sysconfig/clustercheck'], } # Redis $redis_node_ips = split(hiera('redis_node_ips'), ',') $redis_master_hostname = downcase(hiera('bootstrap_nodeid')) if $redis_master_hostname == $::hostname { $slaveof = undef } else { $slaveof = ""${redis_master_hostname} 6379"" } class {'::redis' : slaveof => $slaveof, } if count($redis_node_ips) > 1 { Class['::tripleo::redis_notification'] -> Service['redis-sentinel'] include ::redis::sentinel class {'::tripleo::redis_notification' : haproxy_monitor_ip => hiera('tripleo::loadbalancer::controller_virtual_ip'), }"," # MongoDB include ::mongodb::globals # FIXME: replace with service_manage => false on ::mongodb::server # when this is merged: https://github.com/puppetlabs/pupp etlabs-mongodb/pull/198 class { '::mongodb::server' : service_ensure => undef, service_enable => false, } mysql_user { 'clustercheckuser@localhost' : password_hash => mysql_password($clustercheck_password), require => Exec['galera-ready'], } } # Redis $redis_node_ips = split(hiera('redis_node_ips'), ',') $redis_master_hostname = downcase(hiera('bootstrap_nodeid')) if $redis_master_hostname == $::hostname { $slaveof = undef } else { $slaveof = ""${redis_master_hostname} 6379"" } class {'::redis' : slaveof => $slaveof, } if count($redis_node_ips) > 1 { Class['::tripleo::redis_notification'] -> Service['redis-sentinel'] include ::redis::sentinel class {'::tripleo::redis_notification' : haproxy_monitor_ip => hiera('tripleo::loadbalancer::controller_virtual_ip'), } } exec { 'galera-ready' : command => '/bin/mysql -e ""SHOW GLOBAL VARIABLES LIKE \'read_only\'"" | /bin/grep -i off', timeout => 600, tries => 60, try_sleep => 10, environment => 'HOME=/root', } file { '/etc/sysconfig/clustercheck' : ensure => file, content => ""MYSQL_USERNAME=clustercheckuser\n MYSQL_PASSWORD=${clustercheck_password}\n MYSQL_HOST=localhost\n"", require => Exec['galera-ready'], } xinetd::service { 'galera-monitor' : port => '9200', server => '/usr/bin/clustercheck', per_source => 'UNLIMITED', log_on_success => '', log_on_failure => 'HOST', flags => 'REUSE', service_type => 'UNLISTED', user => 'root', group => 'root', require => File['/etc/sysconfig/clustercheck'], } # Create all the database schemas # Example DSN format: mysql://user:password@host/dbname if $sync_db {",62,67
openstack%2Fironic~master~I942c42afd12dac0f53fa51e9bf73835d5c546ad7,openstack/ironic,master,I942c42afd12dac0f53fa51e9bf73835d5c546ad7,DO NOT MERGE - Added Vancouver UI Demo CORS domain.,ABANDONED,2015-05-14 00:17:28.000000000,2015-05-26 20:29:22.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 9717}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-05-14 00:17:28.000000000', 'files': ['vagrant.yml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bee9c9f5f5f32d250d36dfdc9396448cd5dbf4b7', 'message': 'DO NOT MERGE - Added Vancouver UI Demo CORS domain.\n\nThis adds an entry to the ironic.conf.local file that permits\na locally running instance of ironic to talk to the demo UI currently\nhosted at krotscheck.github.io. Note that this patch is there for\ndemo purposes only, to demonstrate how a UI developer may setup\ntheir local environment to build on.\n\nChange-Id: I942c42afd12dac0f53fa51e9bf73835d5c546ad7\n'}]",0,182899,bee9c9f5f5f32d250d36dfdc9396448cd5dbf4b7,8,4,1,9717,,,0,"DO NOT MERGE - Added Vancouver UI Demo CORS domain.

This adds an entry to the ironic.conf.local file that permits
a locally running instance of ironic to talk to the demo UI currently
hosted at krotscheck.github.io. Note that this patch is there for
demo purposes only, to demonstrate how a UI developer may setup
their local environment to build on.

Change-Id: I942c42afd12dac0f53fa51e9bf73835d5c546ad7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/99/182899/1 && git format-patch -1 --stdout FETCH_HEAD,['vagrant.yml'],1,bee9c9f5f5f32d250d36dfdc9396448cd5dbf4b7,cors," - { # CORS Domain for the ironic-webclient demo in Vancouver. section: 'cors.vancouver', option: 'allowed_origin', value: ""http://krotscheck.github.io"" }",,4,0
openstack%2Fgovernance~master~I18f507da315951352e31a9d1be2aeb0e40c9d085,openstack/governance,master,I18f507da315951352e31a9d1be2aeb0e40c9d085,Adding the Chef cookbooks to OpenStack,MERGED,2015-04-17 18:36:01.000000000,2015-05-26 20:28:01.000000000,2015-05-26 20:27:58.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2243}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 11915}, {'_account_id': 12323}, {'_account_id': 13252}]","[{'number': 1, 'created': '2015-04-17 18:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/20af5c4802ce475fbee248a7b7d4912a356765f0', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, and our\nroadmap is as transparent and managed on Launchpad again using standard OpenStack community practices\n[1].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085\n'}, {'number': 2, 'created': '2015-04-17 19:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/25c059f8d64ea751c35f86d3d8170019ff2051f9', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, and our\nroadmap is as transparent and managed on Launchpad again using standard OpenStack community practices\n[1].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085\n'}, {'number': 3, 'created': '2015-04-21 15:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/62e380ae632cd135fc9b9b8d492e73769149d915', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, which are posted and recorded here[1], and our roadmap is as transparent and managed on Launchpad again using standard OpenStack community practices\n[2].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n\n[1] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[2] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085'}, {'number': 4, 'created': '2015-04-21 15:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/0e98c0b094172aaf0a8f4684f980482379731a25', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, which are posted\nand recorded here[1], and our roadmap is as transparent and managed on\nLaunchpad again using standard OpenStack community practices\n[2].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n\n[1] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[2] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085'}, {'number': 5, 'created': '2015-04-21 20:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/2663ca7f8bf796e0229339a50ec1f85aaf3defe6', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, which are posted\nand recorded here[1], and our roadmap is as transparent and managed on\nLaunchpad again using standard OpenStack community practices\n[2].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[2] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085\n'}, {'number': 6, 'created': '2015-04-21 20:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a16b3b1e444c08d7af94e116aced3f3c9284d745', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings are twice weekly, on IRC and Google hangouts, which are posted\nand recorded here[1], and our roadmap is as transparent and managed on\nLaunchpad again using standard OpenStack community practices\n[2].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[2] https://wiki.openstack.org/wiki/Chef\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085\n'}, {'number': 7, 'created': '2015-04-27 17:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/30f642300601a3235d780cdc2dbec19657fc4d05', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings and office hours are twice weekly[1], on IRC, and our roadmap is as transparent and managed on Launchpad again using standard OpenStack community practices[3].\n\nAs of 2015-04-27 our community has decided to depreciate the Monday Hangout in favor for IRC. The youtube channel[2] will be there for historical tracking, but we will leverage the IRC logging here[4].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef/GettingStarted#Communication\n[2] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[3] https://wiki.openstack.org/wiki/Chef\n[4] http://eavesdrop.openstack.org/meetings/openstack_chef/\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085'}, {'number': 8, 'created': '2015-04-28 15:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/79919a0b1f8635bd9f9a1606c2869e0540629682', 'message': '[WIP] Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack\nname space.\n\nOur meetings and office hours are twice weekly[1], on IRC, and our roadmap is as transparent and managed on Launchpad again using standard OpenStack community practices[3].\n\nAs of 2015-04-27 our community has decided to depreciate the Monday Hangout in favor for IRC. The youtube channel[2] will be there for historical tracking, but we will leverage the IRC logging here[4].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef/GettingStarted#Communication\n[2] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[3] https://wiki.openstack.org/wiki/Chef\n[4] http://eavesdrop.openstack.org/meetings/openstack_chef/\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085'}, {'number': 9, 'created': '2015-04-29 21:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/f57ba22d602aa06e62b3ec0879f2872d65ceb1d3', 'message': '[WIP] Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack name\nspace.\n\nOur meetings and office hours are twice weekly[1], on IRC, and our\nroadmap is as transparent and managed on Launchpad again using standard\nOpenStack community practices[3].\n\nAs of 2015-04-27 our community has decided to depreciate the Monday\nHangout in favor for IRC. The youtube channel[2] will be there for\nhistorical tracking, but we will leverage the IRC logging here[4].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef/GettingStarted#Communication\n[2] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[3] https://wiki.openstack.org/wiki/Chef\n[4] http://eavesdrop.openstack.org/meetings/openstack_chef/\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085\n'}, {'number': 10, 'created': '2015-05-22 17:46:39.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/3e85ee472e3e63a6707fbaed3274f60e6f65075b', 'message': 'Adding the Chef cookbooks to OpenStack\n\nThis in the commit to added the Chef cookbooks to the OpenStack name\nspace.\n\nOur meetings and office hours are twice weekly[1], on IRC, and our\nroadmap is as transparent and managed on Launchpad again using standard\nOpenStack community practices[3].\n\nAs of 2015-04-27 our community has decided to depreciate the Monday\nHangout in favor for IRC. The youtube channel[2] will be there for\nhistorical tracking, but we will leverage the IRC logging here[4].\n\nThis patch is an official request to be part of the big tent and become\nan official project.\n\n[1] https://wiki.openstack.org/wiki/Chef/GettingStarted#Communication\n[2] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos\n[3] https://wiki.openstack.org/wiki/Chef\n[4] http://eavesdrop.openstack.org/meetings/openstack_chef/\n\nChange-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085'}]",2,175000,3e85ee472e3e63a6707fbaed3274f60e6f65075b,60,18,10,12323,,,0,"Adding the Chef cookbooks to OpenStack

This in the commit to added the Chef cookbooks to the OpenStack name
space.

Our meetings and office hours are twice weekly[1], on IRC, and our
roadmap is as transparent and managed on Launchpad again using standard
OpenStack community practices[3].

As of 2015-04-27 our community has decided to depreciate the Monday
Hangout in favor for IRC. The youtube channel[2] will be there for
historical tracking, but we will leverage the IRC logging here[4].

This patch is an official request to be part of the big tent and become
an official project.

[1] https://wiki.openstack.org/wiki/Chef/GettingStarted#Communication
[2] https://www.youtube.com/channel/UCPQhSl-wxgWJH6_r7pk5PbQ/videos
[3] https://wiki.openstack.org/wiki/Chef
[4] http://eavesdrop.openstack.org/meetings/openstack_chef/

Change-Id: I18f507da315951352e31a9d1be2aeb0e40c9d085",git fetch https://review.opendev.org/openstack/governance refs/changes/00/175000/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,20af5c4802ce475fbee248a7b7d4912a356765f0,openstack_chef,ChefOpenStack: ptl: JJ Asghar (j^2) service: Chef cookbooks for the OpenStack components mission: > The Chef cookbooks for OpenStack to build and consume OpenStack cloud deployments. url: https://wiki.openstack.org/wiki/Chef projects: - repo: openstack/cookbook-openstack-bare-metal tags: - name: release:independent - repo: openstack/cookbook-openstack-block-storage tags: - name: release:independent - repo: openstack/cookbook-openstack-compute tags: - name: release:independent - repo: openstack/cookbook-openstack-dashboard tags: - name: release:independent - repo: openstack/cookbook-openstack-data-processing tags: - name: release:independent - repo: openstack/cookbook-openstack-image tags: - name: release:independent - repo: openstack/cookbook-openstack-network tags: - name: release:independent - repo: openstack/cookbook-openstack-object-storage tags: - name: release:independent - repo: openstack/cookbook-openstack-orchestration tags: - name: release:independent - repo: openstack/cookbook-openstack-telemetry tags: - name: release:independent - repo: openstack/cookbook-openstack-client tags: - name: release:independent - repo: openstack/cookbook-openstack-common tags: - name: release:independent - repo: openstack/cookbook-openstack-integration-test tags: - name: release:independent - repo: openstack/cookbook-openstack-ops-messaging tags: - name: release:independent - repo: openstack/cookbook-openstack-ops-database tags: - name: release:independent - repo: openstack/openstack-chef-repo tags: - name: release:independent,,55,0
openstack%2Frally~master~I63ecda94afe8c9d36943a404a3e63fbffc119f83,openstack/rally,master,I63ecda94afe8c9d36943a404a3e63fbffc119f83,Added 2 lines of tests to test_install.sh.  One for sqlite db type and one for mysql db type with the necessary  parameters. The mysql test will fail since there's probably no db server setup with those params but will verify that the script is actually parsing the CLI args for that parameter.,ABANDONED,2015-05-25 17:06:03.000000000,2015-05-26 20:23:15.000000000,,"[{'_account_id': 3}, {'_account_id': 11635}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-25 17:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/50566a6971b542e6f28227e50998a4b575276fba', 'message': ""Added 2 lines of tests to test_install.sh.  One for sqlite db type and\none for mysql db type with the necessary  parameters. The mysql test\nwill fail since there's probably no db server setup with those params\nbut will verify that the script is actually parsing the CLI args for\nthat parameter.\n\nChange-Id: I63ecda94afe8c9d36943a404a3e63fbffc119f83\nRelated-Bug: 185296\n""}, {'number': 2, 'created': '2015-05-25 17:10:09.000000000', 'files': ['tests/ci/test_install.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/61ae5715964966db419cfefe518a6a9fee8328c1', 'message': ""Added 2 lines of tests to test_install.sh.  One for sqlite db type and\none for mysql db type with the necessary  parameters. The mysql test\nwill fail since there's probably no db server setup with those params\nbut will verify that the script is actually parsing the CLI args for\nthat parameter.\n\nChange-Id: I63ecda94afe8c9d36943a404a3e63fbffc119f83\nRelated-Bug: 1458408\n""}]",0,185430,61ae5715964966db419cfefe518a6a9fee8328c1,7,3,2,11635,,,0,"Added 2 lines of tests to test_install.sh.  One for sqlite db type and
one for mysql db type with the necessary  parameters. The mysql test
will fail since there's probably no db server setup with those params
but will verify that the script is actually parsing the CLI args for
that parameter.

Change-Id: I63ecda94afe8c9d36943a404a3e63fbffc119f83
Related-Bug: 1458408
",git fetch https://review.opendev.org/openstack/rally refs/changes/30/185430/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/ci/test_install.sh'],1,50566a6971b542e6f28227e50998a4b575276fba,bug/185296, ./install_rally.sh --overwrite --dbtype sqlite ./install_rally.sh --overwrite --dbtype mysql --db-host localhost --db-name rally --db-user rally --db-password rally,,4,0
openstack%2Ftripleo-heat-templates~master~Ibab567f0a37b832ea2b5966288ad55b5682c31ab,openstack/tripleo-heat-templates,master,Ibab567f0a37b832ea2b5966288ad55b5682c31ab,overcloud stepped deployment environment,MERGED,2015-03-05 22:34:29.000000000,2015-05-26 20:21:30.000000000,2015-05-26 20:21:29.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-03-05 22:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4e3e9323c720630db1450453210359e9e0bc5b9', 'message': ""WIP overcloud stepped deployment environment\n\nThis is to test https://review.openstack.org/#/c/146123/\n\nCurrently, this uses the syntax from patchset 11, enabled in devtest via:\n\nexport DIB_INSTALLTYPE_heat=source\nexport DIB_REPOLOCATION_heat=https://review.openstack.org/openstack/heat\nexport DIB_REPOREF_heat=refs/changes/23/146123/11\n\nIt will need to be rebased on the latest version (the interfaces changed)\nwhen client support has been added.\n\nCurrently, this doesn't work, posted for discussion with shadower\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n""}, {'number': 2, 'created': '2015-03-06 11:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c130339e3facae723bcc5f84a79eec5dc647521', 'message': 'WIP overcloud stepped deployment environment\n\nThis is to test https://review.openstack.org/#/c/146123/\n\nCurrently, this uses the syntax from patchset 11, enabled in devtest via:\n\nexport DIB_INSTALLTYPE_heat=source\nexport DIB_REPOLOCATION_heat=https://review.openstack.org/openstack/heat\nexport DIB_REPOREF_heat=refs/changes/23/146123/11\n\nIt will need to be rebased on the latest version (the interfaces changed)\nwhen client support has been added.\n\nNote this currently only steps through the steps defined in the puppet\nimplementation of ControllerNodesPostDeployment.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 3, 'created': '2015-03-11 18:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8bdc72a629bd1c404a3b9b8f854ca6d5cf6732a0', 'message': 'overcloud stepped deployment environment\n\nThis tests the new heat breakpoints/hooks support:\n\nhttps://review.openstack.org/#/c/146123/\n\nWhen combined with --with-steps added to devtest_overcloud:\n\nhttps://review.openstack.org/#/c/162109/\n\nNote this currently only steps through the steps defined in the puppet\nimplementation of ControllerNodesPostDeployment, more can be added later\nwhen other deployment nested stacks contain multiple steps.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 4, 'created': '2015-04-07 16:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b26cebd4e89eed0d5d1423910b65ba155666fa42', 'message': 'overcloud stepped deployment environment\n\nThis tests the new heat breakpoints/hooks support:\n\nhttps://review.openstack.org/#/c/146123/\n\nWhen combined with --with-steps added to devtest_overcloud:\n\nhttps://review.openstack.org/#/c/162109/\n\nNote this currently only steps through the steps defined in the puppet\nimplementation of ControllerNodesPostDeployment, more can be added later\nwhen other deployment nested stacks contain multiple steps.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 5, 'created': '2015-04-08 15:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cc28c7e0697f91f5a2ae6551e51791a021177a32', 'message': 'overcloud stepped deployment environment\n\nThis tests the new heat breakpoints/hooks support:\nhttps://review.openstack.org/#/c/146123/\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 6, 'created': '2015-04-15 17:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/14fdbfc5aa20571c268b9a8c2417802900b66725', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 7, 'created': '2015-05-12 16:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5075c5ad022fa856fc92179d74ff2cd29af6c335', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 8, 'created': '2015-05-13 17:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e7901cd49355ffb140a37a0674f9487b104a65a', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 9, 'created': '2015-05-15 11:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4654a6b39e8ada22924592a46e9525b05420d126', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 10, 'created': '2015-05-21 16:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e0fda5112f5ed0e926ee4c3b23af37b80a038d2', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}, {'number': 11, 'created': '2015-05-22 20:31:07.000000000', 'files': ['environments/overcloud-steps.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/02b413d18bb715cd7c8d9bf243cd2e777c432865', 'message': 'overcloud stepped deployment environment\n\nWhen combined with --with-steps added to devtest_overcloud:\nhttps://review.openstack.org/#/c/162109/ this enables stepped\ndeployments using heat hooks.\n\nThis environment file will break on all *StepN resources in every\n*NodesPostDeployment resource, on both create and update.\n\nChange-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab\n'}]",2,161927,02b413d18bb715cd7c8d9bf243cd2e777c432865,66,10,11,4328,,,0,"overcloud stepped deployment environment

When combined with --with-steps added to devtest_overcloud:
https://review.openstack.org/#/c/162109/ this enables stepped
deployments using heat hooks.

This environment file will break on all *StepN resources in every
*NodesPostDeployment resource, on both create and update.

Change-Id: Ibab567f0a37b832ea2b5966288ad55b5682c31ab
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/161927/4 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-steps.yaml'],1,e4e3e9323c720630db1450453210359e9e0bc5b9,stepped_deployment,"# Specifies hooks/breakpoints where overcloud deployment should stop # Allows operator validation between steps # Note the wildcards relate to naming convention for some resource suffixes breakpoints: - ""*_Step1"" - ""*_Step2"" - ""*_Step3"" - ""*_Step4"" ",,8,0
openstack%2Fgovernance~master~Idcfa3162514fb4d02a49f20efbe43a8163f9b162,openstack/governance,master,Idcfa3162514fb4d02a49f20efbe43a8163f9b162,Add board-owned openstack/transparency-policy repo,MERGED,2015-05-16 13:02:56.000000000,2015-05-26 20:20:28.000000000,2015-05-26 20:20:28.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-05-16 13:02:56.000000000', 'files': ['reference/foundation-board-repos.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/e6d85a5303a609dff1c22107dbae57876c8cfd72', 'message': 'Add board-owned openstack/transparency-policy repo\n\nThis is a repo which the transparency committee will use to draft\nproposed changes to the OpenStack Foundation Transparency Policy,\nbefore each individual change is approved by a board vote.\n\nSee also:\n\n  http://lists.openstack.org/pipermail/transparency/2015-May/000029.html\n\nChange-Id: Idcfa3162514fb4d02a49f20efbe43a8163f9b162\n'}]",0,183791,e6d85a5303a609dff1c22107dbae57876c8cfd72,15,10,1,1247,,,0,"Add board-owned openstack/transparency-policy repo

This is a repo which the transparency committee will use to draft
proposed changes to the OpenStack Foundation Transparency Policy,
before each individual change is approved by a board vote.

See also:

  http://lists.openstack.org/pipermail/transparency/2015-May/000029.html

Change-Id: Idcfa3162514fb4d02a49f20efbe43a8163f9b162
",git fetch https://review.opendev.org/openstack/governance refs/changes/91/183791/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/foundation-board-repos.yaml'],1,e6d85a5303a609dff1c22107dbae57876c8cfd72,, Transparency subcommittee: - repo: openstack/transparency-policy,,3,0
openstack%2Fgovernance~master~I79aa1f08de57526c7626c34e30d08fa4102ec744,openstack/governance,master,I79aa1f08de57526c7626c34e30d08fa4102ec744,Adds a resolution acknowledging UTC.,MERGED,2015-05-12 19:48:07.000000000,2015-05-26 20:19:08.000000000,2015-05-26 20:19:06.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-12 19:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/27ba51cc68d526c7b367a8efaddadaa31ae4849f', 'message': ""Adds a resolution acknowledging UTC.\n\nWe use UTC for timekeeping, let's acknowledge that.\n\nChange-Id: I79aa1f08de57526c7626c34e30d08fa4102ec744\nCo-Authored-By: Doug Hellmann <doug@doughellmann.com>\n""}, {'number': 2, 'created': '2015-05-12 22:01:03.000000000', 'files': ['resolutions/20150512-utc.rst', 'resolutions/index.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/5d57454440ea8adb344a3703a7affbcf2e628e2e', 'message': ""Adds a resolution acknowledging UTC.\n\nWe use UTC for timekeeping, let's acknowledge that.\n\nChange-Id: I79aa1f08de57526c7626c34e30d08fa4102ec744\nCo-Authored-By: Doug Hellmann <doug@doughellmann.com>\n""}]",0,182430,5d57454440ea8adb344a3703a7affbcf2e628e2e,21,13,2,6316,,,0,"Adds a resolution acknowledging UTC.

We use UTC for timekeeping, let's acknowledge that.

Change-Id: I79aa1f08de57526c7626c34e30d08fa4102ec744
Co-Authored-By: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/30/182430/2 && git format-patch -1 --stdout FETCH_HEAD,['resolutions/20150512-utc.rst'],1,27ba51cc68d526c7b367a8efaddadaa31ae4849f,,"=================================== 2015-05-12 Acknowledging use of UTC =================================== We use UTC for specifying dates and times related to activities overseen by the TC, such as events with deadlines (elections) or specific times (meetings). ",,6,0
openstack%2Fdevstack~master~Ib6603b4f6ea0b4079f9a4ea46e723ecbb2ea371d,openstack/devstack,master,Ib6603b4f6ea0b4079f9a4ea46e723ecbb2ea371d,Set IP_VERSION default value to 4+6,MERGED,2015-05-26 00:15:28.000000000,2015-05-26 20:17:17.000000000,2015-05-26 20:17:16.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 13252}]","[{'number': 1, 'created': '2015-05-26 00:15:28.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/93ee8c876ca2a8cdea98b6685538f85f1a7979ef', 'message': 'Set IP_VERSION default value to 4+6\n\nThis is actually the default value since 645114b\n\nChange-Id: Ib6603b4f6ea0b4079f9a4ea46e723ecbb2ea371d\n'}]",0,185474,93ee8c876ca2a8cdea98b6685538f85f1a7979ef,9,5,1,13938,,,0,"Set IP_VERSION default value to 4+6

This is actually the default value since 645114b

Change-Id: Ib6603b4f6ea0b4079f9a4ea46e723ecbb2ea371d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/74/185474/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,93ee8c876ca2a8cdea98b6685538f85f1a7979ef,doc/ip_version, | Default: ``IP_VERSION=4+6``, | Default: ``IP_VERSION=4``,1,1
openstack%2Fhorizon~master~I76fc34d85c0917829cd299a8882b2d3c46202a14,openstack/horizon,master,I76fc34d85c0917829cd299a8882b2d3c46202a14,Test Patch Do Not Merge,ABANDONED,2015-05-26 17:30:11.000000000,2015-05-26 20:14:13.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-05-26 17:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f427ac8f2c2901d3e76b85006c8585d9a58de9da', 'message': 'Test Patch Do Not Merge\n\ntesting to see if we really detect unused vars with jshint\n\nChange-Id: I76fc34d85c0917829cd299a8882b2d3c46202a14\n'}, {'number': 2, 'created': '2015-05-26 19:21:50.000000000', 'files': ['horizon/static/framework/widgets/widgets.module.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3afa00ce3148bc43b5719d1fe53f081aa33c9681', 'message': 'Test Patch Do Not Merge\n\ntesting to see if we really detect unused vars with jshint\n\nChange-Id: I76fc34d85c0917829cd299a8882b2d3c46202a14\n'}]",0,185681,3afa00ce3148bc43b5719d1fe53f081aa33c9681,9,2,2,9981,,,0,"Test Patch Do Not Merge

testing to see if we really detect unused vars with jshint

Change-Id: I76fc34d85c0917829cd299a8882b2d3c46202a14
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/185681/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/framework/widgets/widgets.module.js'],1,f427ac8f2c2901d3e76b85006c8585d9a58de9da,bug/1458928, var heyWhatsUp;,,1,0
openstack%2Fgovernance~master~I169fcb3bf488862488006b556ee4c0bbf4977101,openstack/governance,master,I169fcb3bf488862488006b556ee4c0bbf4977101,Prepare for M release name poll,MERGED,2015-05-17 03:21:01.000000000,2015-05-26 20:11:49.000000000,2015-05-26 20:11:48.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-17 03:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/318b9d255b4876220c9277e89120b060fd65788f', 'message': 'Prepare for M release name poll\n\nIdentify Monty Taylor as the election coordinator for the M release\nnaming poll and establish the dates for the election.\n\nChange-Id: I169fcb3bf488862488006b556ee4c0bbf4977101\n'}, {'number': 2, 'created': '2015-05-17 03:39:50.000000000', 'files': ['reference/release-naming.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/11ef42529a1815d9b1e77745bd928d1516e394df', 'message': 'Prepare for M release name poll\n\nIdentify Monty Taylor as the election coordinator for the M release\nnaming poll and establish the dates for the election.\n\nChange-Id: I169fcb3bf488862488006b556ee4c0bbf4977101\n'}]",0,183893,11ef42529a1815d9b1e77745bd928d1516e394df,17,11,2,1,,,0,"Prepare for M release name poll

Identify Monty Taylor as the election coordinator for the M release
naming poll and establish the dates for the election.

Change-Id: I169fcb3bf488862488006b556ee4c0bbf4977101
",git fetch https://review.opendev.org/openstack/governance refs/changes/93/183893/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/release-naming.rst'],1,318b9d255b4876220c9277e89120b060fd65788f,, Elections --------- ======= ============ ================ ============== =============== Release Coordinator Nominations Open Election Opens Election Closes ======= ============ ================ ============== =============== M Monty Taylor 2015-06-01 2015-06-08 2015-06-15 ======= ============ ================ ============== ===============,,9,0
openstack%2Fproject-config~master~Ic188c1849559a9c8f282845940f56cf533b9bfd6,openstack/project-config,master,Ic188c1849559a9c8f282845940f56cf533b9bfd6,Reconfigure irc-meetings output,MERGED,2015-05-26 17:21:51.000000000,2015-05-26 20:10:55.000000000,2015-05-26 20:06:58.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5263}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-26 17:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/410e437f7ce5ba9443a0e79b9b59d1dfb7c73dee', 'message': 'Reconfigure irc-meetings output\n\nUpdate the irc meetings publish job to expect all output in the\noutput/ directory and copy the entire directory contents to\neavesdrop.o.o.\n\nThe previous configuration actually caused jenkins to create\nsubdirectories with the names of the files we intended to copy.\n\nAlso, rename the job to match existing patterns.\n\nChange-Id: Ic188c1849559a9c8f282845940f56cf533b9bfd6\n'}, {'number': 2, 'created': '2015-05-26 18:46:27.000000000', 'files': ['jenkins/jobs/infra.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e3e9836739f21fbd447495f7398e1505768f0836', 'message': 'Reconfigure irc-meetings output\n\nUpdate the irc meetings publish job to expect all output in the\noutput/ directory and copy the entire directory contents to\neavesdrop.o.o.\n\nThe previous configuration actually caused jenkins to create\nsubdirectories with the names of the files we intended to copy.\n\nAlso, rename the job to match existing patterns.\n\nChange-Id: Ic188c1849559a9c8f282845940f56cf533b9bfd6\n'}]",0,185677,e3e9836739f21fbd447495f7398e1505768f0836,11,5,2,1,,,0,"Reconfigure irc-meetings output

Update the irc meetings publish job to expect all output in the
output/ directory and copy the entire directory contents to
eavesdrop.o.o.

The previous configuration actually caused jenkins to create
subdirectories with the names of the files we intended to copy.

Also, rename the job to match existing patterns.

Change-Id: Ic188c1849559a9c8f282845940f56cf533b9bfd6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/77/185677/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/infra.yaml', 'zuul/layout.yaml']",2,410e437f7ce5ba9443a0e79b9b59d1dfb7c73dee,, - irc-meetings-publish, - publish-irc-meeting-ical,3,9
openstack%2Fswift~master~I4ea8015f512616dc25072080bef79b8734971ccf,openstack/swift,master,I4ea8015f512616dc25072080bef79b8734971ccf,Add swift-durability-calculator line to docs,MERGED,2015-05-25 06:35:06.000000000,2015-05-26 20:09:29.000000000,2015-05-26 20:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 8542}, {'_account_id': 8871}, {'_account_id': 12193}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-25 06:35:06.000000000', 'files': ['doc/source/associated_projects.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/f11d92d566757a54ff1e3800ec0bfac098347a68', 'message': 'Add swift-durability-calculator line to docs\n\nThis commits add a line (link and small doc) for\nswift-durability-calculator which provides a browser based\ndurability calculation tool to docs as an associated project.\n\nChange-Id: I4ea8015f512616dc25072080bef79b8734971ccf\n'}]",0,185313,f11d92d566757a54ff1e3800ec0bfac098347a68,16,9,1,4608,,,0,"Add swift-durability-calculator line to docs

This commits add a line (link and small doc) for
swift-durability-calculator which provides a browser based
durability calculation tool to docs as an associated project.

Change-Id: I4ea8015f512616dc25072080bef79b8734971ccf
",git fetch https://review.opendev.org/openstack/swift refs/changes/13/185313/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/associated_projects.rst'],1,f11d92d566757a54ff1e3800ec0bfac098347a68,associated-project,* `Swift Durability Calculator <https://github.com/enovance/swift-durability-calculator>`_ - Data Durability Calculation Tool for Swift,,1,0
openstack%2Fpython-swiftclient~master~I14f33c7ea90ab1fe58aa67f1ff70e527c88cd141,openstack/python-swiftclient,master,I14f33c7ea90ab1fe58aa67f1ff70e527c88cd141,be more explicit in the --version CLI option,MERGED,2015-05-13 23:46:24.000000000,2015-05-26 20:09:05.000000000,2015-05-26 20:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 7847}, {'_account_id': 12193}]","[{'number': 1, 'created': '2015-05-13 23:46:24.000000000', 'files': ['swiftclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/888bf6f1a00856ea3a16faad88ece571c1e7d72d', 'message': 'be more explicit in the --version CLI option\n\nChange-Id: I14f33c7ea90ab1fe58aa67f1ff70e527c88cd141\n'}]",0,182892,888bf6f1a00856ea3a16faad88ece571c1e7d72d,13,5,1,330,,,0,"be more explicit in the --version CLI option

Change-Id: I14f33c7ea90ab1fe58aa67f1ff70e527c88cd141
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/92/182892/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/shell.py'],1,888bf6f1a00856ea3a16faad88ece571c1e7d72d,version_report," parser = OptionParser(version='python-swiftclient %s' % version,"," parser = OptionParser(version='%%prog %s' % version,",1,1
openstack%2Fgovernance~master~I9467d8976b940186df4c3b8795704885d2ffadde,openstack/governance,master,I9467d8976b940186df4c3b8795704885d2ffadde,Add Scott Moser as extra-atc,MERGED,2015-05-08 14:46:46.000000000,2015-05-26 20:08:55.000000000,2015-05-26 20:08:53.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6524}]","[{'number': 1, 'created': '2015-05-08 14:46:46.000000000', 'files': ['reference/extra-atcs'], 'web_link': 'https://opendev.org/openstack/governance/commit/6482251bad7da3ac3fb92ea5a6da58cb994f3dd7', 'message': 'Add Scott Moser as extra-atc\n\nScott has been contributing CirrOS [1] as a means to allow for creating\nlightweight instances that are particularly useful in development and\ntesting for OpenStack.\n\nHe has also been added as Co-Author to [2] and [3].\n\n[1] https://launchpad.net/cirros\n[2] https://review.openstack.org/166778\n[3] https://review.openstack.org/176782\n\nChange-Id: I9467d8976b940186df4c3b8795704885d2ffadde\n'}]",0,181415,6482251bad7da3ac3fb92ea5a6da58cb994f3dd7,21,14,1,13252,,,0,"Add Scott Moser as extra-atc

Scott has been contributing CirrOS [1] as a means to allow for creating
lightweight instances that are particularly useful in development and
testing for OpenStack.

He has also been added as Co-Author to [2] and [3].

[1] https://launchpad.net/cirros
[2] https://review.openstack.org/166778
[3] https://review.openstack.org/176782

Change-Id: I9467d8976b940186df4c3b8795704885d2ffadde
",git fetch https://review.opendev.org/openstack/governance refs/changes/15/181415/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/extra-atcs'],1,6482251bad7da3ac3fb92ea5a6da58cb994f3dd7,atc-smoser, Quality Assurance: Scott Moser (smoser@ubuntu.com) [May 2016],,2,0
openstack%2Fpython-ironicclient~master~Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9,openstack/python-ironicclient,master,Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9,Add node-show-states command,MERGED,2015-05-14 13:26:44.000000000,2015-05-26 20:06:01.000000000,2015-05-26 20:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 12356}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-05-14 13:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/afcb82d57c5851acf471b42b38f3d26b6c4e3510', 'message': ""Add node-show-states command\n\nThe Ironic API exposes an endpoint that can be used to get information\nabout the node's state (v1/nodes/<uuid>/states). This was implemented in\nthe Ironic library but we didn't have a command in the CLI to invoke it,\nthis patch is adding this command.\n\nChange-Id: Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9\n""}, {'number': 2, 'created': '2015-05-14 13:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/81cb8251d70c475aed2a6593a5dcd460909525a5', 'message': ""Add node-show-states command\n\nThe Ironic API exposes an endpoint that can be used to get information\nabout the node's state (v1/nodes/<uuid>/states). This was implemented in\nthe Ironic library but we didn't have a command in the CLI to invoke it,\nthis patch is adding this command.\n\nChange-Id: Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9\n""}, {'number': 3, 'created': '2015-05-14 22:37:24.000000000', 'files': ['ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3d66fa1a1fb278073353cd2af2c14f4a31795014', 'message': ""Add node-show-states command\n\nThe Ironic API exposes an endpoint that can be used to get information\nabout the node's state (v1/nodes/<uuid>/states). This was implemented in\nthe Ironic library but we didn't have a command in the CLI to invoke it,\nthis patch is adding this command.\n\nDepends-On: I340c88ea7d098ca5943d60adc73f63a0af79a405\nChange-Id: Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9\n""}]",1,183039,3d66fa1a1fb278073353cd2af2c14f4a31795014,17,7,3,6773,,,0,"Add node-show-states command

The Ironic API exposes an endpoint that can be used to get information
about the node's state (v1/nodes/<uuid>/states). This was implemented in
the Ironic library but we didn't have a command in the CLI to invoke it,
this patch is adding this command.

Depends-On: I340c88ea7d098ca5943d60adc73f63a0af79a405
Change-Id: Ia42775a2ca484c7e4c3bd91f60e7c71a2a3d8ff9
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/39/183039/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py']",2,afcb82d57c5851acf471b42b38f3d26b6c4e3510,node-show-states," def test_do_node_show_states(self): client_mock = mock.MagicMock() args = mock.MagicMock() args.node = 'node_uuid' n_shell.do_node_show_states(client_mock, args) client_mock.node.states.assert_called_once_with('node_uuid')",,15,0
openstack%2Foslo.config~master~I8c022356f88a21f5a79f1b1c0ae6e315a76d3f3b,openstack/oslo.config,master,I8c022356f88a21f5a79f1b1c0ae6e315a76d3f3b,Document properties as properties,MERGED,2015-05-26 00:56:20.000000000,2015-05-26 19:57:34.000000000,2015-05-26 19:57:32.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-05-26 00:56:20.000000000', 'files': ['oslo_config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/5f62407025ba6a3d7ebeba8e593cedc290f48c03', 'message': 'Document properties as properties\n\nSphinx has a directive for python object properties (it calls them\nattributes)[1]. This should be used for properties since then they\ncan be referenced.\n\n[1] http://sphinx-doc.org/domains.html#directive-py:attribute\n\nChange-Id: I8c022356f88a21f5a79f1b1c0ae6e315a76d3f3b\n'}]",0,185476,5f62407025ba6a3d7ebeba8e593cedc290f48c03,7,3,1,6486,,,0,"Document properties as properties

Sphinx has a directive for python object properties (it calls them
attributes)[1]. This should be used for properties since then they
can be referenced.

[1] http://sphinx-doc.org/domains.html#directive-py:attribute

Change-Id: I8c022356f88a21f5a79f1b1c0ae6e315a76d3f3b
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/76/185476/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_config/cfg.py'],1,5f62407025ba6a3d7ebeba8e593cedc290f48c03,doc, .. py:attribute:: name .. py:attribute:: type .. py:attribute:: dest .. py:attribute:: short .. py:attribute:: default .. py:attribute:: sample_default .. py:attribute:: positional .. py:attribute:: metavar .. py:attribute:: help .. py:attribute:: name .. py:attribute:: title .. py:attribute:: help , name: type: dest: short: default: sample_default: positional: metavar: help: name: title: help:,34,12
openstack%2Fneutron-fwaas~master~Ib9d2a0e06c808b3f6047e32d5b51b3b53eaf8b5d,openstack/neutron-fwaas,master,Ib9d2a0e06c808b3f6047e32d5b51b3b53eaf8b5d,Merge tag '2015.1.0',MERGED,2015-05-01 00:12:22.000000000,2015-05-26 19:53:42.000000000,2015-05-26 19:53:40.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 10119}, {'_account_id': 10692}, {'_account_id': 15330}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-05-01 00:12:22.000000000', 'files': ['requirements.txt', '.gitreview', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/a32bbe40b703a5f366d4412d9dabecf807ef416d', 'message': ""Merge tag '2015.1.0'\n\nNeutron-fwaas 2015.1.0\n\nChange-Id: Ib9d2a0e06c808b3f6047e32d5b51b3b53eaf8b5d\n""}]",0,179303,a32bbe40b703a5f366d4412d9dabecf807ef416d,20,8,1,11131,,,0,"Merge tag '2015.1.0'

Neutron-fwaas 2015.1.0

Change-Id: Ib9d2a0e06c808b3f6047e32d5b51b3b53eaf8b5d
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/03/179303/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitreview', 'tox.ini']",3,a32bbe40b703a5f366d4412d9dabecf807ef416d,merge/release-tag,deps = -egit+https://git.openstack.org/openstack/neutron#egg=neutron,deps = -egit+https://git.openstack.org/openstack/neutron@stable/kilo#egg=neutron,2,3
openstack%2Foslo.config~master~I2b45bbffeca22811da09fb8431fc23f6926c6595,openstack/oslo.config,master,I2b45bbffeca22811da09fb8431fc23f6926c6595,Remove pbr requirement,MERGED,2015-05-26 07:14:24.000000000,2015-05-26 19:51:32.000000000,2015-05-26 19:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-05-26 07:14:24.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/cc9940f91ebf91c9b827462441d0ea9b8b3b0efd', 'message': ""Remove pbr requirement\n\nOslo.config doesn't have a runtime dependency on PBR so remove it from\nrequirements.\n\nChange-Id: I2b45bbffeca22811da09fb8431fc23f6926c6595\n""}]",0,185516,cc9940f91ebf91c9b827462441d0ea9b8b3b0efd,7,3,1,7191,,,0,"Remove pbr requirement

Oslo.config doesn't have a runtime dependency on PBR so remove it from
requirements.

Change-Id: I2b45bbffeca22811da09fb8431fc23f6926c6595
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/16/185516/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cc9940f91ebf91c9b827462441d0ea9b8b3b0efd,pbr,,"pbr>=0.11,<2.0",0,1
openstack%2Foslo.utils~master~I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a,openstack/oslo.utils,master,I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a,Add a rate limiting utility class,ABANDONED,2015-04-10 00:43:14.000000000,2015-05-26 19:46:56.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-04-10 00:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f944c4ca35f16c3f0feb7bbf55aa86f56bcaf6b1', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 2, 'created': '2015-04-10 00:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/36fd660c67232d1e28685ea027098edee392660b', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 3, 'created': '2015-04-10 00:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f402f7faa65d7c8b558c47dd74651fe620b62276', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 4, 'created': '2015-04-10 00:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/02907973ac9b24e790496539359ea4bad1c15f82', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 5, 'created': '2015-04-10 00:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/c83b251b1e8442b36988050852725b5a7b1d9b30', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 6, 'created': '2015-04-10 00:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/482b75a089a77521fede1b9b652275d15a7f5ab4', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 7, 'created': '2015-04-10 01:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4d5ab245dac88b6a55322ed87951a09f5ddd084a', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 8, 'created': '2015-04-10 01:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/ca7e08c6af4e93b1d925856e8971b88413a8290f', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 9, 'created': '2015-04-10 18:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/c648041a33aa24a4de3bf0f2ecf2591f26342342', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 10, 'created': '2015-04-10 19:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/9c04fbc84b709d6b092cf27643963d3ea3d741d1', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 11, 'created': '2015-04-14 19:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4d994081a7695e76da7e49d1059bc723fd1bd1df', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}, {'number': 12, 'created': '2015-04-15 23:09:13.000000000', 'files': ['doc/source/index.rst', 'doc/source/api/speedutils.rst', 'oslo_utils/speedutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/6c5b1e2c74c589c1574ea89beb2bd768d4a8aa39', 'message': 'Add a rate limiting utility class\n\nIn various scenarios it is useful to rate-limit an iterator\nso that items can be processed at some defined rate. Having\nthe ability to rate-limit yielded values allows for some powerful\ncombinations where function executions can be limited, processing\nof actions can be limited and so on.\n\nThis code initially came from:\n\nhttps://review.openstack.org/#/c/21380/\n\nWhere it was rejected but it seems useful to revive and retain.\n\nChange-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a\n'}]",13,172246,6c5b1e2c74c589c1574ea89beb2bd768d4a8aa39,28,5,12,1297,,,0,"Add a rate limiting utility class

In various scenarios it is useful to rate-limit an iterator
so that items can be processed at some defined rate. Having
the ability to rate-limit yielded values allows for some powerful
combinations where function executions can be limited, processing
of actions can be limited and so on.

This code initially came from:

https://review.openstack.org/#/c/21380/

Where it was rejected but it seems useful to revive and retain.

Change-Id: I3c1c223c2e3311b08fd9364f5ff83a3ef79c7c7a
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/46/172246/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'oslo_utils/speedutils.py']",2,f944c4ca35f16c3f0feb7bbf55aa86f56bcaf6b1,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import time from oslo_utils import timeutils class SpeedLimit(object): """"""Speed/limiting iterator wrapper object. A wrapper object that uses the token bucket algorithm to limit the rate at which data comes out of an iterable. This can be used to limit the consumption speed of iteration of some other iterator (or iterable). """""" def __init__(self, items_per_second, refresh_rate_seconds=0.1, initial_bucket_size=1, sleep_func=time.sleep): self._refresh_rate_seconds = refresh_rate_seconds self._bucket = (items_per_second * refresh_rate_seconds * initial_bucket_size) self._items_per_tic = items_per_second * refresh_rate_seconds self._next_fill = (timeutils.utcnow() + datetime.timedelta(seconds=refresh_rate_seconds)) self._sleep = sleep_func def _check_fill(self): # Fill the bucket based on elapsed time. # # This simulates a background thread now = timeutils.utcnow() if now > self._next_fill: d = now - self._next_fill tics = 1 + int(self._total_seconds(d) / self._refresh_rate_seconds) self._bucket = self._bucket + tics * self._items_per_tic secs = tics * self._refresh_rate_seconds self._next_fill = (self._next_fill + datetime.timedelta(seconds=secs)) def speed_limit_iter(self, itr): """"""Return an iterator/generator which limits after each iteration. :param itr: an iterator to wrap """""" for chunk in itr: if hasattr(chunk, '__len__'): sz = len(chunk) else: sz = 1 self._check_fill() if sz > self._bucket: now = timeutils.utcnow() tics = int((sz - self._bucket) / self._items_per_tic) tm_diff = self._next_fill - now secs = tics * self._refresh_rate_seconds ts = self._total_seconds(tm_diff) if ts > 0: secs += ts self._sleep(secs) self._check_fill() self._bucket = self._bucket - sz yield chunk def _total_seconds(self, td): if getattr(td, 'total_seconds', None): return td.total_seconds() else: return (td.microseconds + (td.seconds + td.days * 24 * 3600) * 1000000.0) / (1000000.0) ",,88,0
openstack%2Frally~master~Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a,openstack/rally,master,Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a,Nova: Refactor utils._boot_servers to generate its own name prefix,MERGED,2015-05-14 18:23:16.000000000,2015-05-26 19:46:16.000000000,2015-05-26 19:46:14.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 8840}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 11748}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-14 18:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab361c05c667d0236ebf8268c322511d3e51ec2a', 'message': 'Nova: Refactor utils._boot_servers to generate its own name prefix\n\nPreviously, _boot_servers() required a server name prefix; it now\ngenerates its own, moving name generation into the utility instead of\nneeding to put it in the scenario..\n\nChange-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a\n'}, {'number': 2, 'created': '2015-05-20 16:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4a208c3e08ad300d190ce5532a2cbad344d5752a', 'message': 'Nova: Refactor utils._boot_servers to generate its own name prefix\n\nPreviously, _boot_servers() required a server name prefix; it now\ngenerates its own, moving name generation into the utility instead of\nneeding to put it in the scenario..\n\nChange-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a\n'}, {'number': 3, 'created': '2015-05-21 22:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/68708e239a5a7806a0017895418be77f62b468cd', 'message': 'Nova: Refactor utils._boot_servers to generate its own name prefix\n\nPreviously, _boot_servers() required a server name prefix; it now\ngenerates its own, moving name generation into the utility instead of\nneeding to put it in the scenario..\n\nChange-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a\n'}, {'number': 4, 'created': '2015-05-26 13:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/23d3c496d57c07764704e22da26d7658631ab1da', 'message': 'Nova: Refactor utils._boot_servers to generate its own name prefix\n\nPreviously, _boot_servers() required a server name prefix; it now\ngenerates its own if one is not provided, moving name generation into\nthe utility instead of needing to put it in the scenario.\n\nChange-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a\n'}, {'number': 5, 'created': '2015-05-26 15:15:04.000000000', 'files': ['rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/54e8b6722d3e228c2219019a5812efad0c3cbe93', 'message': 'Nova: Refactor utils._boot_servers to generate its own name prefix\n\nPreviously, _boot_servers() required a server name prefix; it now\ngenerates its own if one is not provided, moving name generation into\nthe utility instead of needing to put it in the scenario.\n\nChange-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a\n'}]",2,183152,54e8b6722d3e228c2219019a5812efad0c3cbe93,33,8,5,11748,,,0,"Nova: Refactor utils._boot_servers to generate its own name prefix

Previously, _boot_servers() required a server name prefix; it now
generates its own if one is not provided, moving name generation into
the utility instead of needing to put it in the scenario.

Change-Id: Ie3b6a8ff06d7f05e15fdff4e338c3705f6d0124a
",git fetch https://review.opendev.org/openstack/rally refs/changes/52/183152/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/benchmark/scenarios/glance/test_images.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/context/servers.py', 'rally/benchmark/scenarios/glance/images.py', 'tests/unit/benchmark/scenarios/nova/test_utils.py']",5,ab361c05c667d0236ebf8268c322511d3e51ec2a,nova-boot-multiple," nova_scenario._boot_servers(""image"", ""flavor"", 2)"," nova_scenario._boot_servers(""prefix"", ""image"", ""flavor"", 2)",15,21
openstack%2Ftripleo-incubator~master~I3a8428cdc5a43f31244a91a76c0a23925262f7c1,openstack/tripleo-incubator,master,I3a8428cdc5a43f31244a91a76c0a23925262f7c1,Remove sysctl element from puppet image,MERGED,2015-05-21 09:47:04.000000000,2015-05-26 19:45:42.000000000,2015-05-26 19:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-21 09:47:04.000000000', 'files': ['scripts/overcloud_puppet_disk_images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d795f9677d56ca87d044603a11e6007a5625ed7e', 'message': 'Remove sysctl element from puppet image\n\nWith change Ieb129d4cbe4b6d4184172631499ecd638073564f we configure\nsystcl setting via puppet so the sysctl element should be removed\nfrom the puppet image.\n\nChange-Id: I3a8428cdc5a43f31244a91a76c0a23925262f7c1\n'}]",0,184749,d795f9677d56ca87d044603a11e6007a5625ed7e,18,7,1,6796,,,0,"Remove sysctl element from puppet image

With change Ieb129d4cbe4b6d4184172631499ecd638073564f we configure
systcl setting via puppet so the sysctl element should be removed
from the puppet image.

Change-Id: I3a8428cdc5a43f31244a91a76c0a23925262f7c1
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/49/184749/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/overcloud_puppet_disk_images.yaml'],1,d795f9677d56ca87d044603a11e6007a5625ed7e,, - hosts baremetal dhcp-all-interfaces os-collect-config heat-config-puppet heat-config-script puppet-modules hiera overcloud-compute overcloud-controller stackuser os-net-config delorean-repo rdo-release, - hosts sysctl baremetal dhcp-all-interfaces os-collect-config heat-config-puppet heat-config-script puppet-modules hiera overcloud-compute overcloud-controller stackuser os-net-config delorean-repo rdo-release,1,1
openstack%2Ftripleo-incubator~master~If1c7efc129f51626df073cca2dadbe38446d583b,openstack/tripleo-incubator,master,If1c7efc129f51626df073cca2dadbe38446d583b,devtest_testenv.sh: support for multiple bridges,MERGED,2015-04-27 16:59:38.000000000,2015-05-26 19:45:40.000000000,2015-05-26 19:45:37.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-04-27 16:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2f07b6d8c78d9e2761c30ec6fa80d875d2175ce8', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 2, 'created': '2015-04-28 17:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2c6c0139da6194cab90b0d6e5e4372d9b6d613c5', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 3, 'created': '2015-05-01 19:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/886615301b47e46d0c35d810efe1c1b7a2a9799e', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 4, 'created': '2015-05-07 21:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/df1f9cbb6d1348854103b996e67939fbec7049d7', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 5, 'created': '2015-05-08 14:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b42fe9da1db1c6306c14a767ade5f08aef91401d', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 6, 'created': '2015-05-08 23:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f951b5e6eeeb1fbadc4d2b79a9d58e28a6c616c4', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 7, 'created': '2015-05-09 00:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bd54f5d05d8ddbf7f15a159eacf66bf5487ef293', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 8, 'created': '2015-05-09 22:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/a03d974c645a78914b013bf7abb23d559f6ba3e5', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 9, 'created': '2015-05-11 18:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e4759a66bc272e1911d6e5bb33732aaac66511da', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 10, 'created': '2015-05-11 18:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3137a4822fb538cfad3d2b5065a0a64069e3471d', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 11, 'created': '2015-05-12 11:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5e453206b6ad56a071777762e54dd098a1a1e103', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 12, 'created': '2015-05-12 16:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c6e0a315ab90c49bb37fc149512b258da1962af3', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 13, 'created': '2015-05-15 16:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2ef935a3f52a92ba8d6f04ee15bebf7cffda4855', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 14, 'created': '2015-05-21 17:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ce2f5464139914bfaba050a2c809f753645e9e55', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 15, 'created': '2015-05-22 18:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5126a161fd81eca6839a10e56b456d38e3c4b48a', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 16, 'created': '2015-05-26 12:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/38977a2af6579bcc140bc56efb260c6a34843c72', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}, {'number': 17, 'created': '2015-05-26 16:59:06.000000000', 'files': ['scripts/devtest_testenv.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/56471eebc4d43f028bf0828834d0f860af073358', 'message': 'devtest_testenv.sh: support for multiple bridges\n\nThis patch updates devtest_testenv.sh so that it supports\nmultiple baremetal bridges. This is useful if you want to\ntest an Overcloud with a split out network architecture.\n\nChange-Id: If1c7efc129f51626df073cca2dadbe38446d583b\n'}]",13,177880,56471eebc4d43f028bf0828834d0f860af073358,68,5,17,360,,,0,"devtest_testenv.sh: support for multiple bridges

This patch updates devtest_testenv.sh so that it supports
multiple baremetal bridges. This is useful if you want to
test an Overcloud with a split out network architecture.

Change-Id: If1c7efc129f51626df073cca2dadbe38446d583b
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/80/177880/9 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_testenv.sh'],1,2f07b6d8c78d9e2761c30ec6fa80d875d2175ce8,baremetal_network_config,"set -eux echo "" --baremetal-bridge-names BRIDGE_NAMES -- Name(s) of baremetal bridges"" echo "" To create and attach to each VM."" BRIDGE_NAMES=brbmTEMP=$(getopt -o h,n:,b:,s: -l nodes:,bm-networks:,baremetal-bridge-names:,keep-vms -n $SCRIPT_NAME -- ""$@"") --baremetal-bridge-names) BRIDGE_NAMES=""$2"" ; shift 2 ;; # FIXME: this is poorly named (should be -p to match setup-seed-vm)setup-network ""$NUM"" ""$BRIDGE_NAMES""NUMBERED_BRIDGE_NAMES= SEED_ARGS=""$SEED_ARGS -p $OVSBRIDGE""if [ -n ""$BRIDGE_NAMES"" ]; then for NAME in $BRIDGE_NAMES; do NUMBERED_BRIDGE_NAMES=""$NUMBERED_BRIDGE_NAMES$NAME${NUM} "" done #SEED_ARGS=""$SEED_ARGS -b ${NUMBERED_BRIDGE_NAMES% }"" fi cleanup-env -n $NUM -b ""$BRIDGE_NAMES"" cleanup-env -b ""$BRIDGE_NAMES""setup-seed-vm $SEED_ARGS -c ${SEED_CPU} -m $((1024 * ${SEED_MEM})) -b ""${NUMBERED_BRIDGE_NAMES% }""create-nodes $NODE_CPU $NODE_MEM $NODE_DISK $NODE_ARCH $NODE_CNT $SSH_USER $HOSTIP $JSONFILE ""${NUMBERED_BRIDGE_NAMES% }""","set -euTEMP=$(getopt -o h,n:,b:,s: -l nodes:,bm-networks:,keep-vms -n $SCRIPT_NAME -- ""$@"")setup-network $NUMBRIDGE= BRIDGE=""brbm${NUM}"" SEED_ARGS=""$SEED_ARGS -b $BRIDGE -p $OVSBRIDGE"" cleanup-env -n $NUM cleanup-envsetup-seed-vm $SEED_ARGS -c ${SEED_CPU} -m $((1024 * ${SEED_MEM}))create-nodes $NODE_CPU $NODE_MEM $NODE_DISK $NODE_ARCH $NODE_CNT $SSH_USER $HOSTIP $JSONFILE $BRIDGE",23,10
openstack%2Ftripleo-incubator~master~I94d1bcf4112c1e3f62c14abb7028f7215b6e7662,openstack/tripleo-incubator,master,I94d1bcf4112c1e3f62c14abb7028f7215b6e7662,cleanup-env: Allow configurable bridge names.,MERGED,2015-04-27 16:59:38.000000000,2015-05-26 19:45:11.000000000,2015-05-26 19:45:11.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-04-27 16:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/11ad0f04121e6085144d811e29294c608355b703', 'message': 'Allow configurable bridge names and clean all.\n\nAdds two new (related) options to cleanup-env that can\nbe used when multiple baremetal interfaces are getting\nassigned to nodes.\n\nThe -b option can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\nVMs are named based on the bridge name(s). This option\nworks similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nThe -a option can be used to cleanup everything locally\nregardless of name. I found myself wanting this option when\ncleaning up an environment created with multiple bridges\non the CLI manually. This avoids having to specify anything,\nand just cleans it all.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 2, 'created': '2015-05-01 19:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/a2c54808f1239e8a07cc246b1d39b0832c8dd7b5', 'message': 'Allow configurable bridge names and clean all.\n\nAdds two new (related) options to cleanup-env that can\nbe used when multiple baremetal interfaces are getting\nassigned to nodes.\n\nThe -b option can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\nVMs are named based on the bridge name(s). This option\nworks similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nThe -a option can be used to cleanup everything locally\nregardless of name. I found myself wanting this option when\ncleaning up an environment created with multiple bridges\non the CLI manually. This avoids having to specify anything,\nand just cleans it all.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 3, 'created': '2015-05-07 21:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3de8b82aff08a55aa6695411814c9f8c1d786a41', 'message': 'Allow configurable bridge names and clean all.\n\nAdds two new (related) options to cleanup-env that can\nbe used when multiple baremetal interfaces are getting\nassigned to nodes.\n\nThe -b option can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\nVMs are named based on the bridge name(s). This option\nworks similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nThe -a option can be used to cleanup everything locally\nregardless of name. I found myself wanting this option when\ncleaning up an environment created with multiple bridges\non the CLI manually. This avoids having to specify anything,\nand just cleans it all.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 4, 'created': '2015-05-09 00:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/458a9d0801f58419ac9319ed6159f2f1fa431721', 'message': 'Allow configurable bridge names and clean all.\n\nAdds two new (related) options to cleanup-env that can\nbe used when multiple baremetal interfaces are getting\nassigned to nodes.\n\nThe -b option can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the first bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nThe -a option can be used to cleanup everything locally\nregardless of name. I found myself wanting this option when\ncleaning up an environment created with multiple bridges\non the CLI manually. This avoids having to specify anything,\nand just cleans it all.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 5, 'created': '2015-05-09 22:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e480eff0659787f622a1eedfaf4241533fd3fc80', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 6, 'created': '2015-05-11 18:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/02bec33338e4cc67fc17c64dc4011e78b508efa6', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 7, 'created': '2015-05-12 11:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/39215c81d630af382f7684c1d2fb6ed63f19f42a', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 8, 'created': '2015-05-12 16:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1d3e290f3dadc76855bbf00f41e7f974e4d4a91a', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 9, 'created': '2015-05-15 16:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e014108d36bc28ca35cc26ae99de465eb4d6add7', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 10, 'created': '2015-05-21 17:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bb763d50536d63e359b3faacd3f85f0f7b349728', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 11, 'created': '2015-05-22 18:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/41a49ab9f3f3cfaae816fcbce62bf6bea76e6a9a', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 12, 'created': '2015-05-26 12:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/acf451ed890d29e7e30b147de72c6da807e5c0b8', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}, {'number': 13, 'created': '2015-05-26 16:59:06.000000000', 'files': ['scripts/cleanup-env'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d7463ac9ee1ee5cd22e91c85782e5a7cb809717b', 'message': 'cleanup-env: Allow configurable bridge names.\n\nAdd a -b option that can be used to specify multiple bridge\nnames to cleanup-env. This option is useful because\ncreate-nodes VMs are named based on the bridge name(s).\nThis option works similarly to the -n option and can be used to\ncleanup only specific nodes which match a regex.\n\nChange-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662\n'}]",17,177877,d7463ac9ee1ee5cd22e91c85782e5a7cb809717b,75,5,13,360,,,0,"cleanup-env: Allow configurable bridge names.

Add a -b option that can be used to specify multiple bridge
names to cleanup-env. This option is useful because
create-nodes VMs are named based on the bridge name(s).
This option works similarly to the -n option and can be used to
cleanup only specific nodes which match a regex.

Change-Id: I94d1bcf4112c1e3f62c14abb7028f7215b6e7662
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/77/177877/12 && git format-patch -1 --stdout FETCH_HEAD,['scripts/cleanup-env'],1,11ad0f04121e6085144d811e29294c608355b703,baremetal_network_config," echo "" -b -- Baremetal bridge name(s)."" echo "" -a -- Cleanup all nodes/volumes.""CLEAN_ALL=0 BRIDGE_NAME=brbm TEMP=$(getopt -o h,a,n:,b: -n $SCRIPT_NAME -- ""$@"") -b) BRIDGE_NAME=""${2/ /}"" ; shift 2 ;; #remove spaces -a) CLEAN_ALL=1; shift 1 ;; #remove spaces BRIDGE_NAME=""$BRIDGE_NAMES${NUM}""echo $BAREMETAL_REGEX function run_cmd { local CMD=$@ if [ $CLEAN_ALL == 0 ]; then CMD=""$CMD | $grep \""^\($SEED_NAME\|${BAREMETAL_REGEX}_.*\)$\"""" fi echo $($CMD) } for NAME in $(run_cmd sudo virsh list --name); dofor NAME in $(run_cmd sudo virsh list --name --all); dofor NAME in $(run_cmd sudo virsh vol-list $LIBVIRT_VOL_POOL 2>/dev/null | grep /var/ | awk '{print $1}'); do"," TEMP=$(getopt -o h,n: -n $SCRIPT_NAME -- ""$@"")BRIDGE_NAME= BRIDGE_NAME=""brbm${NUM}"" for NAME in $(sudo virsh list --name | grep ""^\($SEED_NAME\|${BAREMETAL_REGEX}_.*\)$""); dofor NAME in $(sudo virsh list --name --all | grep ""^\($SEED_NAME\|${BAREMETAL_REGEX}_.*\)$""); dofor NAME in $(sudo virsh vol-list $LIBVIRT_VOL_POOL 2>/dev/null | grep /var/ | awk '{print $1}' | grep ""^\($SEED_NAME\|$BAREMETAL_REGEX\)"" ); do",20,6
openstack%2Ftripleo-incubator~master~I756a164c568809babf6bc10accc3afab30c0d042,openstack/tripleo-incubator,master,I756a164c568809babf6bc10accc3afab30c0d042,Update puppet docs to set ROOT_DISK,MERGED,2015-04-22 14:42:24.000000000,2015-05-26 19:43:06.000000000,2015-05-26 19:43:05.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-04-22 14:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9f0f078e034146ebcf2b8b9b12ce3f15ce96186b', 'message': ""Update puppet docs to set ROOT_DISK\n\nThis is recommended because with puppet /mnt/state is a\nwaste of space because we aren't actually putting any data there.\nWith this change the root filesystem will be expanded to consume\nall the extra available space on the partition.\n\nChange-Id: I756a164c568809babf6bc10accc3afab30c0d042\n""}, {'number': 2, 'created': '2015-05-07 12:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2e4b314a6315f6718f36b0abcf875eaa1b569803', 'message': ""Update puppet docs to set ROOT_DISK\n\nThis is recommended because with puppet /mnt/state is a\nwaste of space because we aren't actually putting any data there.\nWith this change the root filesystem will be expanded to consume\nall the extra available space on the partition.\n\nChange-Id: I756a164c568809babf6bc10accc3afab30c0d042\n""}, {'number': 3, 'created': '2015-05-21 17:58:30.000000000', 'files': ['doc/source/puppet.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b5162032aae6f60f0c95fec88f731324dd537d06', 'message': ""Update puppet docs to set ROOT_DISK\n\nThis is recommended because with puppet /mnt/state is a\nwaste of space because we aren't actually putting any data there.\nWith this change the root filesystem will be expanded to consume\nall the extra available space on the partition.\n\nChange-Id: I756a164c568809babf6bc10accc3afab30c0d042\n""}]",6,176337,b5162032aae6f60f0c95fec88f731324dd537d06,32,8,3,360,,,0,"Update puppet docs to set ROOT_DISK

This is recommended because with puppet /mnt/state is a
waste of space because we aren't actually putting any data there.
With this change the root filesystem will be expanded to consume
all the extra available space on the partition.

Change-Id: I756a164c568809babf6bc10accc3afab30c0d042
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/37/176337/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/puppet.rst'],1,9f0f078e034146ebcf2b8b9b12ce3f15ce96186b,puppet_root_disk, # Set ROOT_DISK == NODE_DISK default value (no ephemeral partition) export ROOT_DISK=40,,2,0
openstack%2Fcinder~master~Ia665f6a20703218065aa4cf65b766def3daee290,openstack/cinder,master,Ia665f6a20703218065aa4cf65b766def3daee290,Add missing '-o' CLI option to VNX Cinder Driver,MERGED,2015-05-22 01:46:09.000000000,2015-05-26 19:36:30.000000000,2015-05-26 18:21:09.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9382}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 13394}, {'_account_id': 14428}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16160}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-22 01:46:09.000000000', 'files': ['cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/97668e807d110c44660d0784f8facf8a1d27dd80', 'message': ""Add missing '-o' CLI option to VNX Cinder Driver\n\nIn some NaviSecCLI command, if -o is not given, the command may prompt\nsome message and ask for 'y' or 'n' for confirmation in some special\nscenario, which is not working for Cinder.\n\nThis patch is to add the missing '-o' option to avoid these failures.\n\nChange-Id: Ia665f6a20703218065aa4cf65b766def3daee290\nCloses-Bug: #1453654\n""}]",0,184931,97668e807d110c44660d0784f8facf8a1d27dd80,30,26,1,9924,,,0,"Add missing '-o' CLI option to VNX Cinder Driver

In some NaviSecCLI command, if -o is not given, the command may prompt
some message and ask for 'y' or 'n' for confirmation in some special
scenario, which is not working for Cinder.

This patch is to add the missing '-o' option to avoid these failures.

Change-Id: Ia665f6a20703218065aa4cf65b766def3daee290
Closes-Bug: #1453654
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/184931/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",2,97668e807d110c44660d0784f8facf8a1d27dd80,bug/1453654," '-name', smp_name, '-o') '-gname', sg_name, '-o')"," '-name', smp_name) '-gname', sg_name)",15,15
openstack%2Fhorizon~master~I7f90fb7b965aee4fac779ec98ae86d2e39d134f0,openstack/horizon,master,I7f90fb7b965aee4fac779ec98ae86d2e39d134f0,Add explicit path to jshint config file,ABANDONED,2015-05-26 18:59:25.000000000,2015-05-26 19:34:42.000000000,,[{'_account_id': 6873}],"[{'number': 1, 'created': '2015-05-26 18:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7877a3f18d4afc867d8e2e5dac84a9c85d50a2da', 'message': ""Add explicit path to jshint config file\n\nIn run_tests.sh it's necessary to have an explicit\n--config .jshintrc parameter for each jshint call or else the\nconfig file is not found when running tests from tox (like\nthe gate does). In master this means that no jshint checks\nare being performed, and a default success is always returned. In\nkilo this means that angular checks will always fail.\n\nChange-Id: I7f90fb7b965aee4fac779ec98ae86d2e39d134f0\nCloses-Bug: 1458928\n""}, {'number': 2, 'created': '2015-05-26 19:05:10.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0b0c33f889485f6d4b09ae5ecc8508c984785581', 'message': ""Add explicit path to jshint config file\n\nIn run_tests.sh it's necessary to have an explicit\n--config .jshintrc parameter for each jshint call or else the\nconfig file is not found when running tests from tox (like\nthe gate does). In master this means that no jshint checks\nare being performed, and a default success is always returned. In\nkilo this means that angular checks will always fail.\n\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\n\nChange-Id: I7f90fb7b965aee4fac779ec98ae86d2e39d134f0\nCloses-Bug: 1458928\n""}]",0,185703,0b0c33f889485f6d4b09ae5ecc8508c984785581,4,1,2,9981,,,0,"Add explicit path to jshint config file

In run_tests.sh it's necessary to have an explicit
--config .jshintrc parameter for each jshint call or else the
config file is not found when running tests from tox (like
the gate does). In master this means that no jshint checks
are being performed, and a default success is always returned. In
kilo this means that angular checks will always fail.

Co-Authored-By: Brant Knudson <bknudson@us.ibm.com>

Change-Id: I7f90fb7b965aee4fac779ec98ae86d2e39d134f0
Closes-Bug: 1458928
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/185703/2 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,7877a3f18d4afc867d8e2e5dac84a9c85d50a2da,bug/1458928, jshint --config .jshintrc horizon/static/horizon/js jshint --config .jshintrc horizon/static/horizon/tests jshint --config .jshintrc horizon/static/framework/ jshint --config .jshintrc openstack_dashboard/static/dashboard/, jshint horizon/static/horizon/js jshint horizon/static/horizon/tests jshint horizon/static/framework/ jshint openstack_dashboard/static/dashboard/,4,4
openstack%2Fproject-config~master~Ia01d4aa620097d9da8b7fca132e1a11a08b03a32,openstack/project-config,master,Ia01d4aa620097d9da8b7fca132e1a11a08b03a32,Switch on docs and publish jobs for magnum,MERGED,2015-05-14 10:16:07.000000000,2015-05-26 19:31:14.000000000,2015-05-26 19:31:10.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-05-14 10:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/453eb26cdb25e17357cf9bf7f5163434217ac8f7', 'message': '[WIP] Switch on docs and publish jobs for magnum\n\nChange-Id: Ia01d4aa620097d9da8b7fca132e1a11a08b03a32\n'}, {'number': 2, 'created': '2015-05-14 10:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0c59fec24f0878232dadb325b31e8ba4e1c7b3a1', 'message': '[WIP] Switch on docs and publish jobs for magnum\n\nDepends-On: Ib34bfbe1ae47e077e92a4262642842c845d1a5d6\nDepends-On: Id9f5b08835a4780a8448c989a878c03b70a97803\nChange-Id: Ia01d4aa620097d9da8b7fca132e1a11a08b03a32\n'}, {'number': 3, 'created': '2015-05-14 13:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5fea1e2e74bd92f8d4c13cf4a24ea985027eee23', 'message': 'Switch on docs and publish jobs for magnum\n\nNow that Magnum is out of stackforge, we should enable\nthe usual jobs for docs etc for magnum and python-magnumclient\n\nDepends-On: Ib34bfbe1ae47e077e92a4262642842c845d1a5d6\nDepends-On: Id9f5b08835a4780a8448c989a878c03b70a97803\nChange-Id: Ia01d4aa620097d9da8b7fca132e1a11a08b03a32\n'}, {'number': 4, 'created': '2015-05-14 15:25:57.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7fe78d49c19d774f97c0d93d286ca62845df4341', 'message': 'Switch on docs and publish jobs for magnum\n\nNow that Magnum is out of stackforge, we should enable\nthe usual jobs for docs etc for magnum and python-magnumclient\n\nDepends-On: Ib34bfbe1ae47e077e92a4262642842c845d1a5d6\nDepends-On: Id9f5b08835a4780a8448c989a878c03b70a97803\nChange-Id: Ia01d4aa620097d9da8b7fca132e1a11a08b03a32\n'}]",2,182998,7fe78d49c19d774f97c0d93d286ca62845df4341,21,7,4,5638,,,0,"Switch on docs and publish jobs for magnum

Now that Magnum is out of stackforge, we should enable
the usual jobs for docs etc for magnum and python-magnumclient

Depends-On: Ib34bfbe1ae47e077e92a4262642842c845d1a5d6
Depends-On: Id9f5b08835a4780a8448c989a878c03b70a97803
Change-Id: Ia01d4aa620097d9da8b7fca132e1a11a08b03a32
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/182998/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,453eb26cdb25e17357cf9bf7f5163434217ac8f7,, - name: openstack-server-publish-jobs - name: openstack-server-release-jobs - name: translation-jobs - name: openstack-client-publish-jobs - name: publish-to-pypi - name: translation-jobs, pre-release: - magnum-tarball release: - magnum-tarball pre-release: - python-magnumclient-tarball release: - python-magnumclient-tarball,11,8
openstack%2Fglance~stable%2Ficehouse~I4fab5b507d5b9d165cdc3a5bb24458b56d6fdebd,openstack/glance,stable/icehouse,I4fab5b507d5b9d165cdc3a5bb24458b56d6fdebd,Fix Icehouse RBD delete image on creation failure,MERGED,2015-04-28 16:59:00.000000000,2015-05-26 19:29:33.000000000,2015-05-26 19:29:30.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 9303}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-04-28 16:59:00.000000000', 'files': ['glance/tests/unit/test_rbd_store.py', 'glance/store/rbd.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f66170d59121e12973ca3b064c9bff34c697a576', 'message': 'Fix Icehouse RBD delete image on creation failure\n\nWhen an exception rises on RBD store while adding/creating an image, and\nthe image has already been created, this new image is not properly\ndeleted as it should be.be\n\nFault lies in incorrect call to Store._delete_image method, as it is\ncalled with the wrong arguments.\n\nChange-Id: I4fab5b507d5b9d165cdc3a5bb24458b56d6fdebd\nCloses-Bug: #1449639\n'}]",0,178288,f66170d59121e12973ca3b064c9bff34c697a576,10,6,1,9535,,,0,"Fix Icehouse RBD delete image on creation failure

When an exception rises on RBD store while adding/creating an image, and
the image has already been created, this new image is not properly
deleted as it should be.be

Fault lies in incorrect call to Store._delete_image method, as it is
called with the wrong arguments.

Change-Id: I4fab5b507d5b9d165cdc3a5bb24458b56d6fdebd
Closes-Bug: #1449639
",git fetch https://review.opendev.org/openstack/glance refs/changes/88/178288/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_rbd_store.py', 'glance/store/rbd.py']",2,f66170d59121e12973ca3b064c9bff34c697a576,bug/1449639," target_pool = loc.pool or self.pool self._delete_image(target_pool, loc.image, loc.snapshot)"," self._delete_image(loc.image, loc.snapshot)",17,4
openstack%2Fcinder~master~I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a,openstack/cinder,master,I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a,Targets test refactoring,MERGED,2015-04-30 13:56:32.000000000,2015-05-26 19:29:20.000000000,2015-05-26 19:29:18.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14242}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15764}]","[{'number': 1, 'created': '2015-04-30 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1a75a6a15d9ab4e4c76b67ee8c7fef2c26bca1f6', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n""}, {'number': 2, 'created': '2015-04-30 15:03:10.000000000', 'files': ['cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/targets/targets_fixture.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/targets/test_tgt_driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n""}]",0,179082,bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d,40,25,2,13636,,,0,"Targets test refactoring

The unit tests for iser inherit from the tgtAdm, it means that any
time run tests for iser, tgtAdm tests run too. This chache add
TargetFixture to tests, it allows to decouple tests and delete
duplicated code.

Other changes:
 -  deleted  __init__ in test's classes; __init__ may work as a
replacement for setUp, but  setUp should be used instead because
it is part of the protocol for writing tests. It also has a
counterpart, tearDown, which __init__ does no;
 - replaced stubs to mock.

Change-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a
Closes-Bug: #1420009
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/179082/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/targets/targets_fixture.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/targets/test_tgt_driver.py']",8,1a75a6a15d9ab4e4c76b67ee8c7fef2c26bca1f6,bug/1420009,"from cinder.tests.unit.targets import targets_fixture as tfclass TestTgtAdmDriver(tf.TargetDriverFixture): with mock.patch('cinder.utils.execute', return_value=(self.fake_iscsi_scan, None)): self.assertEqual('1', self.target._get_target( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45')) with mock.patch('cinder.utils.execute', return_value=(self.fake_iscsi_scan, None)): self.assertTrue(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) with mock.patch('cinder.utils.execute', return_value=(bad_scan, None)): self.assertFalse(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) @mock.patch('cinder.utils.execute') def test_recreate_backing_lun(self, mock_execute, mock_sleep): self.target._recreate_backing_lun(self.test_vol, '1', self.test_vol, self.test_vol.split(':')[1]), self.target._get_target_chap_auth(ctxt, self.test_vol)) ctxt, self.test_vol) ctxt, self.test_vol) with mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True): self.assertEqual( self.target.create_iscsi_target( self.test_vol, 1, 0, self.fake_volumes_dir)) with mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True),\ mock.patch('cinder.utils.execute', _fake_execute): self.assertEqual( self.target.create_iscsi_target( self.test_vol, 1, 0, self.fake_volumes_dir)) @mock.patch('cinder.utils.execute') @mock.patch('cinder.utils.execute') @mock.patch('cinder.utils.execute') calls = [mock.call('tgt-admin', '--force', '--delete', self.iscsi_target_prefix + self.testvol['name'], mock.call('tgt-admin', '--delete', self.iscsi_target_prefix + self.testvol['name'], expected_result = {'location': '10.9.8.7:3260,1 ' + self.iscsi_target_prefix + self.testvol['name'] + ' 1', 'QZJbisG9AL954FNF4D P68eE7u9eFqDGexd28DQ'} with mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True),\ mock.patch.object(self.target, '_get_target_chap_auth', side_effect=lambda x, y: None) as m_chap,\ mock.patch.object(vutils, 'generate_username', side_effect=lambda: 'QZJbisG9AL954FNF4D'),\ mock.patch.object(vutils, 'generate_password', side_effect=lambda: 'P68eE7u9eFqDGexd28DQ'): ctxt = context.get_admin_context() self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) m_chap.side_effect = lambda x, y: ('otzLy2UYbYfnP4zXLG5z', '234Zweo38VGBBvrpK9nt') expected_result['auth'] = ('CHAP ' 'otzLy2UYbYfnP4zXLG5z ' '234Zweo38VGBBvrpK9nt') self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) self.iscsi_target_prefix + self.testvol['name'],","import tempfilefrom oslo_utils import timeutilsfrom cinder import testfrom cinder.volume import configuration as confclass TestTgtAdmDriver(test.TestCase): self.configuration = conf.Configuration(None) self.configuration.append_config_values = mock.Mock(return_value=0) self.configuration.iscsi_ip_address = '10.9.8.7' self.fake_volumes_dir = tempfile.mkdtemp() self.iscsi_target_prefix = 'iqn.2010-10.org.openstack:' self.fake_project_id = 'ed2c1fd4-5fc0-11e4-aa15-123b93f75cba' self.fake_volume_id = '83c2e877-feed-46be-8435-77884fe55b45' self.stubs.Set(self.configuration, 'safe_get', self.fake_safe_get) self.testvol =\ {'project_id': self.fake_project_id, 'name': 'volume-%s' % self.fake_volume_id, 'size': 1, 'id': self.fake_volume_id, 'volume_type_id': None, 'provider_location': '10.9.8.7:3260 ' 'iqn.2010-10.org.openstack:' 'volume-%s 0' % self.fake_volume_id, 'provider_auth': 'CHAP stack-1-a60e2611875f40199931f2' 'c76370d66b 2FE0CQ8J196R', 'provider_geometry': '512 512', 'created_at': timeutils.utcnow(), 'host': 'fake_host@lvm#lvm'} self.expected_iscsi_properties = \ {'auth_method': 'CHAP', 'auth_password': '2FE0CQ8J196R', 'auth_username': 'stack-1-a60e2611875f40199931f2c76370d66b', 'encrypted': False, 'logical_block_size': '512', 'physical_block_size': '512', 'target_discovered': False, 'target_iqn': 'iqn.2010-10.org.openstack:volume-%s' % self.fake_volume_id, 'target_lun': 0, 'target_portal': '10.9.8.7:3260', 'volume_id': self.fake_volume_id} def fake_safe_get(self, value): if value == 'volumes_dir': return self.fake_volumes_dir elif value == 'iscsi_protocol': return self.configuration.iscsi_protocol elif value == 'iscsi_target_prefix': return self.iscsi_target_prefix def _fake_execute(*args, **kwargs): return self.fake_iscsi_scan, None self.stubs.Set(utils, 'execute', _fake_execute) self.assertEqual('1', self.target._get_target('iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45')) def _fake_execute(*args, **kwargs): return self.fake_iscsi_scan, None self.stubs.Set(utils, 'execute', _fake_execute) self.assertTrue(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) def _fake_execute_bad_lun(*args, **kwargs): return bad_scan, None self.stubs.Set(utils, 'execute', _fake_execute_bad_lun) self.assertFalse(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) @mock.patch.object(utils, 'execute') def test_recreate_backing_lun(self, mock_execute, mock_sleep): test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.target._recreate_backing_lun(test_vol, '1', test_vol, test_vol =\ 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' test_vol.split(':')[1]), self.target._get_target_chap_auth(ctxt, test_vol)) test_vol =\ 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' ctxt, test_vol) ctxt, test_vol) def _fake_execute(*args, **kwargs): return '', '' self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.assertEqual( 1, self.target.create_iscsi_target( test_vol, 0, self.fake_volumes_dir)) self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.assertEqual( 1, self.target.create_iscsi_target( test_vol, 0, self.fake_volumes_dir)) @mock.patch.object(utils, 'execute') @mock.patch.object(utils, 'execute') @mock.patch.object(utils, 'execute') test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' calls = [mock.call('tgt-admin', '--force', '--delete', test_vol, mock.call('tgt-admin', '--delete', test_vol, def _fake_execute(*args, **kwargs): return '', '' self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) self.stubs.Set(self.target, '_get_target_chap_auth', lambda x, y: None) self.stubs.Set(vutils, 'generate_username', lambda: 'QZJbisGmn9AL954FNF4D') self.stubs.Set(vutils, 'generate_password', lambda: 'P68eE7u9eFqDGexd28DQ') expected_result = {'location': '10.9.8.7:3260,1 ' 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-8435-77884fe55b45 1', 'QZJbisGmn9AL954FNF4D P68eE7u9eFqDGexd28DQ'} ctxt = context.get_admin_context() self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) self.stubs.Set(self.target, '_get_target_chap_auth', lambda x, y: ('otzLy2UYbYfnP4zXLG5z', '234Zweo38VGBBvrpK9nt')) expected_result['auth'] = ('CHAP ' 'otzLy2UYbYfnP4zXLG5z 234Zweo38VGBBvrpK9nt') self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' test_vol,",318,614
openstack%2Fhorizon~master~If2cbc243ebfd0b2f1f834056e34b8e2d3df06060,openstack/horizon,master,If2cbc243ebfd0b2f1f834056e34b8e2d3df06060,ngReorg - Create dashboard-app,MERGED,2015-05-20 19:34:10.000000000,2015-05-26 19:14:31.000000000,2015-05-26 19:14:29.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-05-20 19:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/be5ff91239ce70a1d501dcb90eddd74e508d2e83', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 2, 'created': '2015-05-20 19:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c12c24b4c288daf96348fd1ec69edc4e48d1965d', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 3, 'created': '2015-05-20 19:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2f9777d625349e37d06f3bf1f4460bc5cfb8d2d0', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 4, 'created': '2015-05-21 21:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8b9d86f06988b16b7af3fdcebc9d119303534536', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 5, 'created': '2015-05-21 21:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2f17928f06febdfc3f6a435579326edf332a6f96', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 6, 'created': '2015-05-21 23:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec3f379fbef8c7148a59615f7c3e0d74b8f28d4d', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 7, 'created': '2015-05-21 23:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6c509f61c79444b5818610ff3e3d7093c36c7cbe', 'message': 'ngReorg - Create dashboard-app\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nPartial-Bug: #1454880\n'}, {'number': 8, 'created': '2015-05-21 23:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bcd11963d520a3f49867f5c2f177944d9398108b', 'message': 'ngReorg - Create dashboard-app\n\nThis is the last patch of this ngReorg series!!\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis was the last step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nThe next refactoring effort (not addressed by this patch series)\nis to restructure the Django templates so that\nhorizon.dashboard-app can be moved OUT of horizon/horizon.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nCloses-Bug: #1454880\n'}, {'number': 9, 'created': '2015-05-22 14:43:50.000000000', 'files': ['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/wizard/wizard.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.spec.js', 'horizon/static/framework/widgets/charts/pie-chart.spec.js', 'horizon/static/dashboard-app/dashboard-app.module.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.js', 'horizon/static/dashboard-app/controllers/image-form-controller.js', 'horizon/static/framework/util/validators/validators.spec.js', 'horizon/static/dashboard-app/utils/helper-functions.js', 'horizon/static/dashboard-app/utils/helper-functions.spec.js', 'horizon/templates/base.html', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.spec.js', 'horizon/static/dashboard-app/controllers/namespace-controller.js', 'horizon/static/horizon/js/horizon.images.js', 'horizon/static/dashboard-app/controllers/dummy.js', 'horizon/static/framework/widgets/table/table.spec.js', 'horizon/static/dashboard-app/controllers/modal-form-update-metadata-ctrl.js', 'horizon/templates/horizon/_conf.html', 'horizon/static/framework/widgets/table/basic-table.spec.js', 'horizon/static/dashboard-app/utils/image-file-on-change.js', 'horizon/static/dashboard-app/login/login.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/horizon/js/angular/horizon.conf.js', 'horizon/static/framework/widgets/action-list/action-list.spec.js', 'horizon/static/framework/widgets/help-panel/help-panel.spec.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/util/form/form.spec.js', 'horizon/static/dashboard-app/utils/utils.module.js', 'horizon/static/framework/framework.module.js', 'horizon/static/dashboard-app/login/login.spec.js', 'horizon/static/framework/conf/conf.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.spec.js', 'horizon/static/framework/util/bind-scope/bind-scope.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/31de099efb7fea9ba2fdd9b27ea005bc8e83e0c4', 'message': 'ngReorg - Create dashboard-app\n\nThis is the last patch of this ngReorg series!!\n\nThis commit attempts to refactor the ""hz"" module and horizon.js\ninto ""dashboard-app"" because the code is actually bootstrapping\nthe default dashboard application, created using framework and\nopenstack_dashboard pieces. Ideally, this moves into a directory\nthat is a peer to openstack_dashboard, but for now, it is at\nleast grouped together with a name that reflects its purpose.\n\nThis was the last step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nThe next refactoring effort (not addressed by this patch series)\nis to restructure the Django templates so that\nhorizon.dashboard-app can be moved OUT of horizon/horizon.\n\nChange-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060\nCloses-Bug: #1454880\n'}]",13,184597,31de099efb7fea9ba2fdd9b27ea005bc8e83e0c4,27,6,9,14307,,,0,"ngReorg - Create dashboard-app

This is the last patch of this ngReorg series!!

This commit attempts to refactor the ""hz"" module and horizon.js
into ""dashboard-app"" because the code is actually bootstrapping
the default dashboard application, created using framework and
openstack_dashboard pieces. Ideally, this moves into a directory
that is a peer to openstack_dashboard, but for now, it is at
least grouped together with a name that reflects its purpose.

This was the last step in a larger effort to restructure the Angular
source. See https://review.openstack.org/#/c/176152/ for the
full set of planned changes.

The next refactoring effort (not addressed by this patch series)
is to restructure the Django templates so that
horizon.dashboard-app can be moved OUT of horizon/horizon.

Change-Id: If2cbc243ebfd0b2f1f834056e34b8e2d3df06060
Closes-Bug: #1454880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/184597/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/dashboard-app/dashboard-app.js'],1,be5ff91239ce70a1d501dcb90eddd74e508d2e83,bug/1454880,,,0,0
openstack%2Fdevstack~master~I01cec39dae8c6a99620d43471c9a7d34b84da846,openstack/devstack,master,I01cec39dae8c6a99620d43471c9a7d34b84da846,Ensure also last extension in the list can be removed,ABANDONED,2015-01-09 23:22:20.000000000,2015-05-26 19:12:25.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-09 23:22:20.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7669e0e4f88c228f8a90ea1bbebb4548848e549b', 'message': 'Ensure also last extension in the list can be removed\n\nThe algorithm for removing disabled extensions from the list which\nwill be supplied to tempest assumes that an extension name is\nfollowed by a comma. This is not true for the last element in the\nlist; the current algorithm cannot therefore remove it.\n\nThis patch fixes this issue by adding a comma at the end of the\nextension list string. The additional comma is removed immediately\nbefore returning the string.\n\nChange-Id: I01cec39dae8c6a99620d43471c9a7d34b84da846\n'}]",0,146223,7669e0e4f88c228f8a90ea1bbebb4548848e549b,7,4,1,261,,,0,"Ensure also last extension in the list can be removed

The algorithm for removing disabled extensions from the list which
will be supplied to tempest assumes that an extension name is
followed by a comma. This is not true for the last element in the
list; the current algorithm cannot therefore remove it.

This patch fixes this issue by adding a comma at the end of the
extension list string. The additional comma is removed immediately
before returning the string.

Change-Id: I01cec39dae8c6a99620d43471c9a7d34b84da846
",git fetch https://review.opendev.org/openstack/devstack refs/changes/23/146223/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,7669e0e4f88c228f8a90ea1bbebb4548848e549b,fix_remove_dis_extensions," # append a trailing comma to ensure the last element in the list is safely # removed by this method too local extensions_list=$1"","" # remove previously added trailing comma echo ${extensions_list%?}", local extensions_list=$1 echo $extensions_list,5,2
openstack%2Ftripleo-ci~master~I10430795733b8ecff8aca6eedf8679ffcee5207f,openstack/tripleo-ci,master,I10430795733b8ecff8aca6eedf8679ffcee5207f,Update delorean URL,MERGED,2015-05-20 22:21:29.000000000,2015-05-26 19:03:24.000000000,2015-05-26 19:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-20 22:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d8099125c72a9084bc273bdc4102e177ee3f2639', 'message': 'Update delorean URL\n\nUpdate the DELOREAN_URL pin to use one from today 2015-05-20.\n\nChange-Id: I10430795733b8ecff8aca6eedf8679ffcee5207f\n'}, {'number': 2, 'created': '2015-05-21 16:44:39.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f6580aa2631218cd5623194e612b64c2f304485a', 'message': 'Update delorean URL\n\nUpdate the DELOREAN_URL pin to use one from today 2015-05-21.\n\nChange-Id: I10430795733b8ecff8aca6eedf8679ffcee5207f\n'}]",0,184640,f6580aa2631218cd5623194e612b64c2f304485a,34,6,2,360,,,0,"Update delorean URL

Update the DELOREAN_URL pin to use one from today 2015-05-21.

Change-Id: I10430795733b8ecff8aca6eedf8679ffcee5207f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/40/184640/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,d8099125c72a9084bc273bdc4102e177ee3f2639,delorean_current," export DELOREAN_REPO_URL=""http://trunk.rdoproject.org/f21/be/f1/bef1b187a859567414e65cd93c9b208c3da768f8_422c5f68"""," export DELOREAN_REPO_URL=""http://trunk.rdoproject.org/f21/bf/59/bf59764b9a7f14c1f0223b28aa839142cfec3bf3_c3766014""",1,1
openstack%2Fhorizon~master~I139c4811617af19d16278cc9f8617b1b3be55c69,openstack/horizon,master,I139c4811617af19d16278cc9f8617b1b3be55c69,Quota graph label aligned,MERGED,2015-03-30 20:35:20.000000000,2015-05-26 18:57:36.000000000,2015-05-26 18:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6638}, {'_account_id': 6825}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12525}, {'_account_id': 12826}, {'_account_id': 13785}]","[{'number': 1, 'created': '2015-03-30 20:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32cda78a36680b0194a87b5c7daff75b661d8442', 'message': 'Quota graph label aligned\n\nChange-Id: I139c4811617af19d16278cc9f8617b1b3be55c69\nCloses-Bug: #1349621\n'}, {'number': 2, 'created': '2015-05-15 03:58:31.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/components/_charts.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fc893179927dfff3cbb3fd8f28061d4cbba37e9d', 'message': 'Quota graph label aligned\n\nExtends the quota bar for better alignment.\n\nChange-Id: I139c4811617af19d16278cc9f8617b1b3be55c69\nCloses-Bug: #1349621\n'}]",0,169076,fc893179927dfff3cbb3fd8f28061d4cbba37e9d,14,9,2,14702,,,0,"Quota graph label aligned

Extends the quota bar for better alignment.

Change-Id: I139c4811617af19d16278cc9f8617b1b3be55c69
Closes-Bug: #1349621
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/169076/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/horizon.scss'],1,32cda78a36680b0194a87b5c7daff75b661d8442,label_align, padding-right: 35px;,,1,0
openstack%2Ftripleo-heat-templates~master~I99b5c46fff8a90b56080354a4d7f267c9a1b183f,openstack/tripleo-heat-templates,master,I99b5c46fff8a90b56080354a4d7f267c9a1b183f,Add service mappings for OpenStack services to networks,ABANDONED,2015-05-05 21:09:29.000000000,2015-05-26 18:55:57.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-05-05 21:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a27ad368886d05bdffbd96190f873b7972523165', 'message': 'Add service mappings for OpenStack services to networks\n\nThis patch adds the service mappings that are required for the\ncontroller. Mapping a network to a service results in an IP on that\nnetwork being used as the bind IP for the service. Services are\nmapped to the networks using parameters, which can be overridden\nto change the network mapping.\n\nChange-Id: I99b5c46fff8a90b56080354a4d7f267c9a1b183f\n'}, {'number': 2, 'created': '2015-05-05 21:39:19.000000000', 'files': ['network/ports/service_map.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7a886962fded60cf2544ebadba922c675fefd460', 'message': 'Add service mappings for OpenStack services to networks\n\nThis patch adds the service mappings that are required for the\ncontroller. Mapping a network to a service results in an IP on that\nnetwork being used as the bind IP for the service. Services are\nmapped to the networks using parameters, which can be overridden\nto change the network mapping.\n\nChange-Id: I99b5c46fff8a90b56080354a4d7f267c9a1b183f\n'}]",5,180322,7a886962fded60cf2544ebadba922c675fefd460,9,3,2,12398,,,0,"Add service mappings for OpenStack services to networks

This patch adds the service mappings that are required for the
controller. Mapping a network to a service results in an IP on that
network being used as the bind IP for the service. Services are
mapped to the networks using parameters, which can be overridden
to change the network mapping.

Change-Id: I99b5c46fff8a90b56080354a4d7f267c9a1b183f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/180322/1 && git format-patch -1 --stdout FETCH_HEAD,['network/ports/service_map.yaml'],1,a27ad368886d05bdffbd96190f873b7972523165,service_map_mappings, CeilometerApiNetwork: default: internal_api type: string CinderApiNetwork: default: storage type: string CinderIscsiNetwork: default: storage type: string GlanceApiNetwork: default: storage type: string GlanceRegistryNetwork: default: storage type: string HeatApiNetwork: default: internal_api type: string HeatApiCfnNetwork: default: internal_api type: string HeatApiCloudwatchNetwork: default: internal_api type: string KeystoneAdminApiNetwork: default: internal_api type: string KeystonePublicApiNetwork: default: external type: string MemcachedNetwork: default: internal_api type: string MongodbNetwork: default: internal_api type: string NeutronApiNetwork: default: internal_api type: string NeutronPublicApiNetwork: default: external type: string NovaApiNetwork: default: internal_api type: string NovaMetadataNetwork: default: internal_api type: string RabbitmqNetwork: default: internal_api type: string RedisNetwork: default: internal_api type: string SwiftMgmtNetwork: default: storage_mgmt type: string SwiftProxyNetwork: default: storage type: string ceilometer_api_network: {get_param: CeilometerApiNetwork} cinder_api_network: {get_param: CinderApiNetwork} cinder_iscsi_network: {get_param: CinderIscsiNetwork} glance_api_network: {get_param: GlanceApiNetwork} glance_registry_network: {get_param: GlanceRegistryNetwork} heat_api_network: {get_param: HeatApiNetwork} heat_api_cfn_network: {get_param: HeatApiCfnNetwork} heat_api_cloudwatch_network: {get_param: HeatApiCloudwatchNetwork} keystone_admin_api_network: {get_param: KeystoneAdminApiNetwork} keystone_public_api_network: {get_param: KeystonePublicApiNetwork} memcached_network: {get_param: MemcachedNetwork} mongodb_network: {get_param: MongodbNetwork} neutron_api_network: {get_param: NeutronApiNetwork} neutron_public_api_network: {get_param: NeutronPublicApiNetwork} nova_api_network: {get_param: NovaApiNetwork} nova_metadata_network: {get_param: NovaMetadataNetwork} rabbitmq_network: {get_param: RabbitmqNetwork} redis_network: {get_param: RedisNetwork} swift_mgmt_network: {get_param: SwiftMgmtNetwork} swift_proxy_network: {get_param: SwiftProxyNetwork}, # TODO: define the rest of our Service -> network mappings here,80,1
openstack%2Ftripleo-heat-templates~master~Ieecfc965dda8e3746d8542cd470564c2569325c7,openstack/tripleo-heat-templates,master,Ieecfc965dda8e3746d8542cd470564c2569325c7,Map services in controller-puppet.yaml to networks in service_map.yaml,ABANDONED,2015-05-05 21:53:31.000000000,2015-05-26 18:55:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-05 21:53:31.000000000', 'files': ['puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c0c0a511dcd7c647b96d937494daf7c14d1d6c7', 'message': 'Map services in controller-puppet.yaml to networks in service_map.yaml\n\nThis change modifies the value of the various bind_host parameters\nin controller-puppet.yaml to lookup addresses from the networks defined in\nnet_ip_map.yaml. The values that we are looking up are defined as outputs\nin the service_map.yaml file. These outputs correspond to the static IP\naddresses that are assigned on each network.\n\nChange-Id: Ieecfc965dda8e3746d8542cd470564c2569325c7\n'}]",0,180335,3c0c0a511dcd7c647b96d937494daf7c14d1d6c7,4,1,1,12398,,,0,"Map services in controller-puppet.yaml to networks in service_map.yaml

This change modifies the value of the various bind_host parameters
in controller-puppet.yaml to lookup addresses from the networks defined in
net_ip_map.yaml. The values that we are looking up are defined as outputs
in the service_map.yaml file. These outputs correspond to the static IP
addresses that are assigned on each network.

Change-Id: Ieecfc965dda8e3746d8542cd470564c2569325c7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/180335/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/controller-puppet.yaml'],1,3c0c0a511dcd7c647b96d937494daf7c14d1d6c7,service_map_lookups," swift::proxy::proxy_local_net_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, swift_proxy_net]}]} swift::storage::all::storage_local_net_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, swift_mgmt_net]}]} cinder_iscsi_ip_address: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, cinder_iscsi_net]}]} cinder::api::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, cinder_api_net]}]} glance::api::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, glance_api_net]}]} glance::api::registry_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, glance_registry_net]}]} glance::registry::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, glance_registry_net]}]} heat::api::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, heat_api_net]}]} heat::api_cloudwatch::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, heat_api_cloudwatch_net]}]} heat::api_cfn::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, heat_api_cfn_net]}]} keystone::public_bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, keystone_public_api_net]}]} keystone::admin_bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, keystone_admin_api_net]}]} mongodb::server::bind_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, mongodb_net]}]} neutron::bind_host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, neutron_api_net]}]} ceilometer::api::host: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, ceilometer_api_net]}]} nova::api::api_bind_address: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, nova_api_net]}]} nova::api::metadata_listen: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, nova_metadata_net]}]} rabbitmq::node_ip_address: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, rabbitmq_net]}]} redis::bind: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, redis_net]}]} memcached::listen_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, memcached_net]}]} neutron_public_interface_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr : [NetworkPorts, service_map, neutron_public_api_net]}]}", swift::proxy::proxy_local_net_ip: {get_input: controller_host} swift::storage::all::storage_local_net_ip: {get_input: controller_host} cinder_iscsi_ip_address: {get_input: controller_host} cinder::api::bind_host: {get_input: controller_host} glance::api::bind_host: {get_input: controller_host} glance::api::registry_host: {get_input: controller_host} glance::registry::bind_host: {get_input: controller_host} heat::api::bind_host: {get_input: controller_host} heat::api_cloudwatch::bind_host: {get_input: controller_host} heat::api_cfn::bind_host: {get_input: controller_host} keystone::public_bind_host: {get_input: controller_host} keystone::admin_bind_host: {get_input: controller_host} mongodb::server::bind_ip: {get_input: controller_host} neutron::bind_host: {get_input: controller_host} ceilometer::api::host: {get_input: controller_host} nova::api::api_bind_address: {get_input: controller_host} nova::api::metadata_listen: {get_input: controller_host} rabbitmq::node_ip_address: {get_input: controller_host} redis::bind: {get_input: controller_host} memcached::listen_ip: {get_input: controller_host} neutron_public_interface_ip: {get_input: neutron_public_interface_ip},21,21
openstack%2Fcinder~master~I969a4d60aa156ccfff09a58c3a448b5a9619e71f,openstack/cinder,master,I969a4d60aa156ccfff09a58c3a448b5a9619e71f,Leave sqlalchemy convert to boolean to the DB SQL type to use.,MERGED,2015-05-20 13:08:23.000000000,2015-05-26 18:52:44.000000000,2015-05-20 19:33:25.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12249}, {'_account_id': 12491}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16160}, {'_account_id': 16269}]","[{'number': 1, 'created': '2015-05-20 13:08:23.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/040_add_volume_attachment.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc1dcbb9c847b531593d7d6b130ac2b2d04e5302', 'message': 'Leave sqlalchemy convert to boolean to the DB SQL type to use.\n\nCloses-Bug: #1457033\n\nChange-Id: I969a4d60aa156ccfff09a58c3a448b5a9619e71f'}]",0,184478,dc1dcbb9c847b531593d7d6b130ac2b2d04e5302,26,22,1,10020,,,0,"Leave sqlalchemy convert to boolean to the DB SQL type to use.

Closes-Bug: #1457033

Change-Id: I969a4d60aa156ccfff09a58c3a448b5a9619e71f",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/184478/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/migrate_repo/versions/040_add_volume_attachment.py'],1,dc1dcbb9c847b531593d7d6b130ac2b2d04e5302,bug/1457033," 'deleted': False,"," 'deleted': 0,",1,1
openstack%2Fnova~master~I40b9bad64d7d955dac6836e17f1f59604d484391,openstack/nova,master,I40b9bad64d7d955dac6836e17f1f59604d484391,Validate Ironic's Nova primitives during scheduling,ABANDONED,2015-02-05 11:18:29.000000000,2015-05-26 18:48:30.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 6899}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}]","[{'number': 1, 'created': '2015-02-05 11:18:29.000000000', 'files': ['nova/scheduler/filters/ironic_validate_filter.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/unit/scheduler/filters/test_ironic_validate_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ea85b9477ebcff423e06a5e52307ffba01d1cdc7', 'message': ""Validate Ironic's Nova primitives during scheduling\n\nThis will currently validate the flavor against the image properties.\n\nThe following assertions are done:\n- Flavor without root partition size isn't accepted.\n- Whole disk images with swap/ephemeral values aren't accepted.\n\nDepends-On I4478eff302a0ffeb3e9f2077a41170671863c478\n\nPartially-Implements blueprint whole-disk-image-support\n\nChange-Id: I40b9bad64d7d955dac6836e17f1f59604d484391\n""}]",0,153196,ea85b9477ebcff423e06a5e52307ffba01d1cdc7,11,8,1,6899,,,0,"Validate Ironic's Nova primitives during scheduling

This will currently validate the flavor against the image properties.

The following assertions are done:
- Flavor without root partition size isn't accepted.
- Whole disk images with swap/ephemeral values aren't accepted.

Depends-On I4478eff302a0ffeb3e9f2077a41170671863c478

Partially-Implements blueprint whole-disk-image-support

Change-Id: I40b9bad64d7d955dac6836e17f1f59604d484391
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/153196/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/ironic_validate_filter.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/unit/scheduler/filters/test_ironic_validate_filter.py']",3,ea85b9477ebcff423e06a5e52307ffba01d1cdc7,bp/whole-disk-image-support,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.scheduler.filters import ironic_validate_filter from nova import test from nova.tests.unit.scheduler import fakes class TestIronicValidateFilter(test.NoDBTestCase): def setUp(self): super(TestIronicValidateFilter, self).setUp() self.filt_cls = ironic_validate_filter.IronicValidateFilter() def test_ironic_validate_partition_image(self): img_props = {'properties': {'kernel_id': 'kernel', 'ramdisk_id': 'ramdisk', }} instance_type = {'root_gb': 100, 'swap_mb': 10, 'ephemeral_mb': 10} filter_properties = {'request_spec': {'image': img_props, 'instance_type': instance_type}} host = fakes.FakeHostState('host1', 'node1', {}) self.assertTrue(self.filt_cls.host_passes(host, filter_properties)) def test_ironic_validate_no_root(self): img_props = {'properties': {'kernel_id': 'kernel', 'ramdisk_id': 'ramdisk', }} instance_type = {'root_gb': 0} filter_properties = {'request_spec': {'image': img_props, 'instance_type': instance_type}} host = fakes.FakeHostState('host1', 'node1', {}) self.assertTrue(self.filt_cls.host_passes(host, filter_properties)) def test_ironic_validate_whole_disk_image_good(self): img_props = {'properties': {}} instance_type = {'root_gb': 100, 'swap_mb': 0, 'ephemeral_mb': 0} filter_properties = {'request_spec': {'image': img_props, 'instance_type': instance_type}} host = fakes.FakeHostState('host1', 'node1', {}) self.assertTrue(self.filt_cls.host_passes(host, filter_properties)) def test_ironic_validate_whole_disk_image_fail_swap(self): img_props = {'properties': {}} instance_type = {'root_gb': 100, 'swap_mb': 10, 'ephemeral_mb': 0} filter_properties = {'request_spec': {'image': img_props, 'instance_type': instance_type}} host = fakes.FakeHostState('host1', 'node1', {}) self.assertFalse(self.filt_cls.host_passes(host, filter_properties)) def test_ironic_validate_whole_disk_image_fail_ephemeral(self): img_props = {'properties': {}} instance_type = {'root_gb': 100, 'swap_mb': 0, 'ephemeral_mb': 10} filter_properties = {'request_spec': {'image': img_props, 'instance_type': instance_type}} host = fakes.FakeHostState('host1', 'node1', {}) self.assertFalse(self.filt_cls.host_passes(host, filter_properties)) ",,130,0
openstack%2Fpython-ironicclient~master~I541695388489cdc640265df8ee6a9999e1442870,openstack/python-ironicclient,master,I541695388489cdc640265df8ee6a9999e1442870,Consistent and more valid strings for Booleans,MERGED,2015-04-02 18:25:59.000000000,2015-05-26 18:47:34.000000000,2015-05-25 18:50:13.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 9382}, {'_account_id': 11655}, {'_account_id': 11929}, {'_account_id': 13997}, {'_account_id': 14228}, {'_account_id': 14619}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-04-02 18:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f4623d43637193769ec9d1f6ce772997604c865e', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}, {'number': 2, 'created': '2015-04-09 18:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/150bf8314084f23613a193a2e1e7d3d808a05068', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nFor invalid strings, we output the subcommand usage along with the\nargument, invalid string, and valid string choices.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}, {'number': 3, 'created': '2015-04-27 14:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/083fbf80d909377b50c08cdb1e15386a6e10b269', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nFor invalid strings, we output the subcommand usage along with the\nargument, invalid string, and valid string choices.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}, {'number': 4, 'created': '2015-04-28 19:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2b91abec51d75cc8c7a2e14c6eef84e4a06f4f9d', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands of the Ironic CLI. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nFor invalid strings, we output the subcommand usage along with the\nargument, invalid string, and valid string choices.\n\nAt the API level, if NodeManager.set_maintenance() is passed an invalid\nstate (maintenance mode) value, an InvalidAttribute exception is raised.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}, {'number': 5, 'created': '2015-04-28 20:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8618429d6d7f4c444298400fab9b6e437e0c260e', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands of the Ironic CLI. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nFor invalid strings, we output the subcommand usage along with the\nargument, invalid string, and valid string choices.\n\nAt the API level, if NodeManager.set_maintenance() is passed an invalid\nstate (maintenance mode) value, an InvalidAttribute exception is raised.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}, {'number': 6, 'created': '2015-05-07 01:30:21.000000000', 'files': ['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/shell.py', 'ironicclient/tests/unit/v1/test_node.py', 'ironicclient/tests/unit/test_utils.py', 'ironicclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8fd2ac3ba1c48189d60d73043c4b6868de2633f2', 'message': ""Consistent and more valid strings for Booleans\n\nThe set of valid input strings for Boolean values was inconsistent among\nthe subcommands of the Ironic CLI. egs:\n -for node-set-console-mode: 'true', 'false'\n -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'\n\nThis change allows the same set of valid values for all the subcommands:\n'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.\n\nFor invalid strings, we output the subcommand usage along with the\nargument, invalid string, and valid string choices.\n\nAt the API level, if NodeManager.set_maintenance() is passed an invalid\nstate (maintenance mode) value, an InvalidAttribute exception is raised.\n\nChange-Id: I541695388489cdc640265df8ee6a9999e1442870\nCloses-Bug: #1415943\n""}]",21,170230,8fd2ac3ba1c48189d60d73043c4b6868de2633f2,53,14,6,6618,,,0,"Consistent and more valid strings for Booleans

The set of valid input strings for Boolean values was inconsistent among
the subcommands of the Ironic CLI. egs:
 -for node-set-console-mode: 'true', 'false'
 -for node-set-maintenance: 'on', 'off', 'true', 'false', 'True', 'False'

This change allows the same set of valid values for all the subcommands:
'0', '1', 'f', 'false', 'n', 'no', 'off', 'on', 't', 'true', 'y', 'yes'.

For invalid strings, we output the subcommand usage along with the
argument, invalid string, and valid string choices.

At the API level, if NodeManager.set_maintenance() is passed an invalid
state (maintenance mode) value, an InvalidAttribute exception is raised.

Change-Id: I541695388489cdc640265df8ee6a9999e1442870
Closes-Bug: #1415943
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/30/170230/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_node.py']",4,f4623d43637193769ec9d1f6ce772997604c865e,bug/1415943," {'enabled': True}, maintenance = self.mgr.set_maintenance(NODE1['uuid'], True, maintenance = self.mgr.set_maintenance(NODE1['uuid'], False) enabled = True"," {'enabled': 'true'}, maintenance = self.mgr.set_maintenance(NODE1['uuid'], 'true', maintenance = self.mgr.set_maintenance(NODE1['uuid'], 'false') expect = [ ('DELETE', '/v1/nodes/%s/maintenance' % NODE1['uuid'], {}, None), ] self.assertEqual(expect, self.api.calls) self.assertEqual(None, maintenance) def test_node_set_maintenance_on(self): maintenance = self.mgr.set_maintenance(NODE1['uuid'], 'on', maint_reason='reason') body = {'reason': 'reason'} expect = [ ('PUT', '/v1/nodes/%s/maintenance' % NODE1['uuid'], {}, body), ] self.assertEqual(expect, self.api.calls) self.assertEqual(None, maintenance) def test_node_set_maintenance_off(self): maintenance = self.mgr.set_maintenance(NODE1['uuid'], 'off') enabled = 'true'",75,44
openstack%2Fpython-glanceclient~master~I9189a45908c8dc1301a79013bb9140a6765779b6,openstack/python-glanceclient,master,I9189a45908c8dc1301a79013bb9140a6765779b6,Accept CLI argument 'public' in image creation,ABANDONED,2014-10-28 17:28:00.000000000,2015-05-26 18:41:38.000000000,,"[{'_account_id': 3}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-10-28 17:28:00.000000000', 'files': ['glanceclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5223ce2c721c50a3a6049808fdad99c2f514c824', 'message': ""Accept CLI argument 'public' in image creation\n\nCurrently, if '--public' is specified, an image is created but it is not\nmarked as public.\n\nThis fix makes glance client to accept both arguments: 'is-public' and\n'public'.\n\nChange-Id: I9189a45908c8dc1301a79013bb9140a6765779b6\nCloses-Bug: 1378844\n""}]",0,131509,5223ce2c721c50a3a6049808fdad99c2f514c824,5,3,1,13024,,,0,"Accept CLI argument 'public' in image creation

Currently, if '--public' is specified, an image is created but it is not
marked as public.

This fix makes glance client to accept both arguments: 'is-public' and
'public'.

Change-Id: I9189a45908c8dc1301a79013bb9140a6765779b6
Closes-Bug: 1378844
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/09/131509/1 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/v1/shell.py'],1,5223ce2c721c50a3a6049808fdad99c2f514c824,bug/1378844, if 'is_public' in fields: fields['is_public'] = fields.get('is_public') else: fields['is_public'] = fields.get('public'), fields['is_public'] = fields.get('is_public'),4,1
openstack%2Fneutron~stable%2Fkilo~I45477713d7ce16f2451fa6fbe04c610388b06867,openstack/neutron,stable/kilo,I45477713d7ce16f2451fa6fbe04c610388b06867,Router is not unscheduled when the last port is deleted,MERGED,2015-04-27 15:36:10.000000000,2015-05-26 18:37:16.000000000,2015-05-26 18:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-27 15:36:10.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/tests/unit/scheduler/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1813da49aded224e273e0a33a90dca902fa05b75', 'message': ""Router is not unscheduled when the last port is deleted\n\nWhen checking for ports that are still in use on a DVR router,\nthe L3 agent scheduler makes the assumption that a port's\nnetwork must be owned by the same tenant. This isn't always\ntrue as the admin could have created a shared network that\nother tenants may use. The result of this assumption is that\nthe router associated with the shared network may not be\nunscheduled from a VM host when the last VM (created by a\nnon-admin tenant) using the shared network is deleted from\nthe compute node.\n\nThe owner of a VM may not own all the ports of a shared\nnetwork.  Other tenants may have VMs using the same shared\nnetwork running on the same compute node. Also the VM owner\nmay not own the router ports. In order to check whether a\nrouter can be unscheduled from a node has to be run with\nadmin context so all the ports associated with router are\nreturned from database queries.\n\nThis patch fixes this problem by using the admin context to\nmake the queries needed for the DVR scheduler to make the\ncorrect unschedule decision.\n\nChange-Id: I45477713d7ce16f2451fa6fbe04c610388b06867\nCloses-bug: #1424096\n(cherry picked from commit edbade486102a219810137d1c6b916e87475d477)\n""}]",0,177825,1813da49aded224e273e0a33a90dca902fa05b75,59,22,1,6876,,,0,"Router is not unscheduled when the last port is deleted

When checking for ports that are still in use on a DVR router,
the L3 agent scheduler makes the assumption that a port's
network must be owned by the same tenant. This isn't always
true as the admin could have created a shared network that
other tenants may use. The result of this assumption is that
the router associated with the shared network may not be
unscheduled from a VM host when the last VM (created by a
non-admin tenant) using the shared network is deleted from
the compute node.

The owner of a VM may not own all the ports of a shared
network.  Other tenants may have VMs using the same shared
network running on the same compute node. Also the VM owner
may not own the router ports. In order to check whether a
router can be unscheduled from a node has to be run with
admin context so all the ports associated with router are
returned from database queries.

This patch fixes this problem by using the admin context to
make the queries needed for the DVR scheduler to make the
correct unschedule decision.

Change-Id: I45477713d7ce16f2451fa6fbe04c610388b06867
Closes-bug: #1424096
(cherry picked from commit edbade486102a219810137d1c6b916e87475d477)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/177825/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_dvrscheduler_db.py', 'neutron/tests/unit/scheduler/test_l3_agent_scheduler.py']",2,1813da49aded224e273e0a33a90dca902fa05b75,,"class FakePortDB(object): def __init__(self, port_list): self._port_list = port_list def _get_query_answer(self, port_list, filters): answers = [] for port in port_list: matched = True for key, search_values in filters.items(): port_value = port.get(key, None) if not port_value: matched = False break if isinstance(port_value, list): sub_answers = self._get_query_answer(port_value, search_values) matched = len(sub_answers) > 0 else: matched = port_value in search_values if not matched: break if matched: answers.append(port) return answers def get_port(self, context, port_id): for port in self._port_list: if port['id'] == port_id: if port['tenant_id'] == context.tenant_id or context.is_admin: return port break return None def get_ports(self, context, filters=None): query_filters = dict() if filters: query_filters.update(filters) if not context.is_admin: query_filters['tenant_id'] = [context.tenant_id] result = self._get_query_answer(self._port_list, query_filters) return result def _create_port(self, port_name, tenant_id, host, subnet_id, ip_address, status='ACTIVE', device_owner='compute:nova'): return { 'id': port_name + '-port-id', 'tenant_id': tenant_id, 'device_id': port_name, 'device_owner': device_owner, 'status': status, 'binding:host_id': host, 'fixed_ips': [ { 'subnet_id': subnet_id, 'ip_address': ip_address } ] } def test_dvr_deletens_if_no_port_no_routers(self): # Delete a vm port, the port subnet has no router interface. vm_tenant_id = 'tenant-1' my_context = q_context.Context('user-1', vm_tenant_id, is_admin=False) vm_port_host = 'compute-node-1' vm_port = self._create_port( 'deleted-vm', vm_tenant_id, vm_port_host, 'shared-subnet', '10.10.10.3', status='INACTIVE') vm_port_id = vm_port['id'] fakePortDB = FakePortDB([vm_port]) with contextlib.nested( mock.patch.object(my_context, 'elevated', return_value=self.adminContext), mock.patch('neutron.plugins.ml2.db.' 'get_port_binding_host', return_value=vm_port_host), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_ports', side_effect=fakePortDB.get_ports), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_port', return_value=vm_port)) as ( _, mock_get_port_binding_host, _, _): routers = self.dut.dvr_deletens_if_no_port(my_context, vm_port_id) self.assertEqual([], routers) mock_get_port_binding_host.assert_called_once_with( self.adminContext.session, vm_port_id) def test_dvr_deletens_if_no_ports_no_removeable_routers(self): # A VM port is deleted, but the router can't be unscheduled from the # compute node because there is another VM port present. vm_tenant_id = 'tenant-1' my_context = q_context.Context('user-1', vm_tenant_id, is_admin=False) shared_subnet_id = '80947d4a-fbc8-484b-9f92-623a6bfcf3e0', vm_port_host = 'compute-node-1' dvr_port = self._create_port( 'dvr-router', 'admin-tenant', vm_port_host, shared_subnet_id, '10.10.10.1', device_owner=constants.DEVICE_OWNER_DVR_INTERFACE) deleted_vm_port = self._create_port( 'deleted-vm', vm_tenant_id, vm_port_host, shared_subnet_id, '10.10.10.3', status='INACTIVE') deleted_vm_port_id = deleted_vm_port['id'] running_vm_port = self._create_port( 'running-vn', 'tenant-2', vm_port_host, shared_subnet_id, '10.10.10.33') fakePortDB = FakePortDB([running_vm_port, deleted_vm_port, dvr_port]) vm_port_binding = { 'port_id': deleted_vm_port_id, 'host': vm_port_host } with contextlib.nested( mock.patch.object(my_context, 'elevated', return_value=self.adminContext), mock.patch('neutron.plugins.ml2.db.get_port_binding_host', return_value=vm_port_host), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_port', side_effect=fakePortDB.get_port), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_ports', side_effect=fakePortDB.get_ports), mock.patch('neutron.plugins.ml2.db.get_dvr_port_binding_by_host', return_value=vm_port_binding)) as (_, mock_get_port_binding_host, _, mock_get_ports, mock_get_dvr_port_binding_by_host): routers = self.dut.dvr_deletens_if_no_port( my_context, deleted_vm_port_id) self.assertEqual([], routers) mock_get_port_binding_host.assert_called_once_with( self.adminContext.session, deleted_vm_port_id) self.assertTrue(mock_get_ports.called) self.assertFalse(mock_get_dvr_port_binding_by_host.called) def _test_dvr_deletens_if_no_ports_delete_routers(self, vm_tenant, router_tenant): class FakeAgent(object): def __init__(self, id, host, agent_type): self.id = id self.host = host self.agent_type = agent_type my_context = q_context.Context('user-1', vm_tenant, is_admin=False) shared_subnet_id = '80947d4a-fbc8-484b-9f92-623a6bfcf3e0', vm_port_host = 'compute-node-1' router_id = 'dvr-router' dvr_port = self._create_port( router_id, router_tenant, vm_port_host, shared_subnet_id, '10.10.10.1', device_owner=constants.DEVICE_OWNER_DVR_INTERFACE) dvr_port_id = dvr_port['id'] deleted_vm_port = self._create_port( 'deleted-vm', vm_tenant, vm_port_host, shared_subnet_id, '10.10.10.3', status='INACTIVE') deleted_vm_port_id = deleted_vm_port['id'] running_vm_port = self._create_port( 'running-vn', vm_tenant, 'compute-node-2', shared_subnet_id, '10.10.10.33') fakePortDB = FakePortDB([running_vm_port, dvr_port, deleted_vm_port]) dvr_port_binding = { 'port_id': dvr_port_id, 'host': vm_port_host } agent_id = 'l3-agent-on-compute-node-1' l3_agent_on_vm_host = FakeAgent(agent_id, vm_port_host, constants.AGENT_TYPE_L3) with contextlib.nested( mock.patch.object(my_context, 'elevated', return_value=self.adminContext), mock.patch('neutron.plugins.ml2.db.get_port_binding_host', return_value=vm_port_host), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_port', side_effect=fakePortDB.get_port), mock.patch('neutron.db.db_base_plugin_v2.NeutronDbPluginV2.' 'get_ports', side_effect=fakePortDB.get_ports), mock.patch('neutron.plugins.ml2.db.get_dvr_port_binding_by_host', return_value=dvr_port_binding), mock.patch('neutron.db.agents_db.AgentDbMixin.' '_get_agent_by_type_and_host', return_value=l3_agent_on_vm_host)) as (_, mock_get_port_binding_host, _, mock_get_ports, mock_get_dvr_port_binding_by_host, mock__get_agent_by_type_and_host): routers = self.dut.dvr_deletens_if_no_port( my_context, deleted_vm_port_id) expected_router = { 'router_id': router_id, 'host': vm_port_host, 'agent_id': agent_id } self.assertEqual([expected_router], routers) mock_get_port_binding_host.assert_called_once_with( self.adminContext.session, deleted_vm_port_id) self.assertTrue(mock_get_ports.called) mock_get_dvr_port_binding_by_host.assert_called_once_with( my_context.session, dvr_port_id, vm_port_host) def test_dvr_deletens_if_no_ports_delete_admin_routers(self): # test to see whether the last VM using a router created # by the admin will be unscheduled on the compute node self._test_dvr_deletens_if_no_ports_delete_routers( 'tenant-1', 'admin-tenant') def test_dvr_deletens_if_no_ports_delete_tenant_routers(self): # test to see whether the last VM using a tenant's private # router will be unscheduled on the compute node self._test_dvr_deletens_if_no_ports_delete_routers( 'tenant-1', 'tenant-1') ",,248,5
openstack%2Fec2-api~master~I14771b1092d069511b25be05b8dd02acf46bdb99,openstack/ec2-api,master,I14771b1092d069511b25be05b8dd02acf46bdb99,fix rally scenario 'describe_one_instance',MERGED,2015-05-25 11:50:01.000000000,2015-05-26 18:29:21.000000000,2015-05-26 18:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-25 11:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/f314bda9b4ea621fca22fa1eef3b20abe848a599', 'message': ""fix rally scenario 'describe_one_instance'\n\nChange-Id: I14771b1092d069511b25be05b8dd02acf46bdb99\n""}, {'number': 2, 'created': '2015-05-25 17:56:06.000000000', 'files': ['rally-scenarios/plugins/ec2api_plugin.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/53ca11c0302f7c4f47da0fb1cc7ad03519737455', 'message': ""fix rally scenario 'describe_one_instance'\n\nChange-Id: I14771b1092d069511b25be05b8dd02acf46bdb99\n""}]",0,185366,53ca11c0302f7c4f47da0fb1cc7ad03519737455,12,4,2,10234,,,0,"fix rally scenario 'describe_one_instance'

Change-Id: I14771b1092d069511b25be05b8dd02acf46bdb99
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/66/185366/2 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/plugins/ec2api_plugin.py'],1,f314bda9b4ea621fca22fa1eef3b20abe848a599,, client_id = str(client._endpoint), client_id = client._endpoint,1,1
openstack%2Fopenstacksdk~master~I9955330078bca9a6b1992b74b0c14822d3e44957,openstack/openstacksdk,master,I9955330078bca9a6b1992b74b0c14822d3e44957,Accept intermediate path arguments at proxy,MERGED,2015-05-15 19:32:07.000000000,2015-05-26 18:22:13.000000000,2015-05-26 18:22:11.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-05-15 19:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8e1286fdeba22846429f6891f0c9fc8ecd535fca', 'message': 'WIP: accept intermediate path arguments at proxy\n\nWe need a way to get what amounts to ""path_args"" in the resource layer\nthrough via the proxy layer.\n\nChange-Id: I9955330078bca9a6b1992b74b0c14822d3e44957\n'}, {'number': 2, 'created': '2015-05-16 20:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/df2324f0f774327a5e366c5722bafe4ba395f770', 'message': 'Accept intermediate path arguments at proxy\n\nWe need a way to get what amounts to ""path_args"" in the resource layer\nthrough via the proxy layer. This change adds support in the BaseProxy\nclass for sending the path_args through, and applies it to several\nobject_store calls that need the container name to come through while\nworking with object operations.\n\nChange-Id: I9955330078bca9a6b1992b74b0c14822d3e44957\n'}, {'number': 3, 'created': '2015-05-26 17:50:42.000000000', 'files': ['openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/resource.py', 'openstack/proxy.py', 'openstack/tests/unit/test_proxy_base.py', 'openstack/tests/unit/test_proxy.py', 'openstack/object_store/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ded72c8d356770667c163c78c5eaad41ec9f9904', 'message': 'Accept intermediate path arguments at proxy\n\nWe need a way to get what amounts to ""path_args"" in the resource layer\nthrough via the proxy layer. This change adds support in the BaseProxy\nclass for sending the path_args through, and applies it to several\nobject_store calls that need the container name to come through while\nworking with object operations.\n\nChange-Id: I9955330078bca9a6b1992b74b0c14822d3e44957\n'}]",1,183664,ded72c8d356770667c163c78c5eaad41ec9f9904,16,4,3,8257,,,0,"Accept intermediate path arguments at proxy

We need a way to get what amounts to ""path_args"" in the resource layer
through via the proxy layer. This change adds support in the BaseProxy
class for sending the path_args through, and applies it to several
object_store calls that need the container name to come through while
working with object operations.

Change-Id: I9955330078bca9a6b1992b74b0c14822d3e44957
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/64/183664/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/resource.py', 'openstack/proxy.py', 'openstack/object_store/v1/_proxy.py']",3,8e1286fdeba22846429f6891f0c9fc8ecd535fca,path_args_to_proxy_methods," def get_object(self, value, container=None): return self._get(_obj.Object, value, path_args={""container"": container}) def get_object_metadata(self, value, container=None): return self._head(_obj.Object, value, path_args={""container"": container})"," def get_object(self, value): return self._get(_obj.Object, value) def get_object_metadata(self, value): # TODO(brian): Currently this requires that you pass in only an # Object instance, not a name like other places. We should explore # expanding this to support taking container and name. self._head(_obj.Object, value)",49,19
openstack%2Fpython-glanceclient~master~I1c687ae6c5da239090b0b7a4a855b3271a9076da,openstack/python-glanceclient,master,I1c687ae6c5da239090b0b7a4a855b3271a9076da,Improve import related error handling,MERGED,2015-04-07 13:00:41.000000000,2015-05-26 18:20:18.000000000,2015-05-26 18:20:16.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 9096}, {'_account_id': 11356}, {'_account_id': 12000}, {'_account_id': 12807}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-04-07 13:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/75bcd97b7e5d80d3e54591f6049cda2c80c31478', 'message': 'Improve version related  error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace if \'--debug\' is passed on the command\nline.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}, {'number': 2, 'created': '2015-04-07 13:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/a78bbf1d5b4f75f23cf6f7a86ee2f43bb84783ea', 'message': 'Improve version related error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace in this case if \'--debug\' is passed\non the command line.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}, {'number': 3, 'created': '2015-04-07 15:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8549fb69015062cbf1a5a1f1301fe363acb5cb8d', 'message': 'Improve import related error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace in this case if \'--debug\' is passed\non the command line.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}, {'number': 4, 'created': '2015-04-16 12:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ae69e02b29e9667fa41ac4fb2828e9d74a97fe3c', 'message': 'Improve import related error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace in this case if \'--debug\' is passed\non the command line.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}, {'number': 5, 'created': '2015-04-16 14:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/98b94ba8bf875d15541c592439f1b1535d381e8e', 'message': 'Improve import related error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace in this case if \'--debug\' is passed\non the command line.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}, {'number': 6, 'created': '2015-05-08 12:53:17.000000000', 'files': ['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1f89beb6098f4f6a8d8c2912392b273bc068b2e3', 'message': 'Improve import related error handling\n\nIf there was a problem importing a library we would incorrectly raise\nan unsupported version error:\n\n  $ glance --os-image-api-version 1 image-list\n  ""1"" is not a supported API version. Example values are ""1"" or ""2"".\n\nWe should change this to provide information on the failed import, eg:\n\n  $ glance --os-image-api-version 1 image-list\n  No module named badimport\n\nWe also now raise the full stacktrace in this case if \'--debug\' is passed\non the command line.\n\nChange-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da\nRelated-bug: 1402632\n'}]",7,171180,1f89beb6098f4f6a8d8c2912392b273bc068b2e3,40,7,6,455,,,0,"Improve import related error handling

If there was a problem importing a library we would incorrectly raise
an unsupported version error:

  $ glance --os-image-api-version 1 image-list
  ""1"" is not a supported API version. Example values are ""1"" or ""2"".

We should change this to provide information on the failed import, eg:

  $ glance --os-image-api-version 1 image-list
  No module named badimport

We also now raise the full stacktrace in this case if '--debug' is passed
on the command line.

Change-Id: I1c687ae6c5da239090b0b7a4a855b3271a9076da
Related-bug: 1402632
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/80/171180/3 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/shell.py', 'tests/test_shell.py']",2,75bcd97b7e5d80d3e54591f6049cda2c80c31478,bug/1402632,"from glanceclient.common.utils import exit as utils_exitfrom glanceclient.shell import SUPPORTED_VERSIONS @mock.patch('glanceclient.common.utils.exit') def test_shell_illegal_version(self, mock_exit): # Only int versions are allowed on cli mock_exit.side_effect = utils_exit shell = openstack_shell.OpenStackImagesShell() argstr = '--os-image-api-version 1.1 image-list' try: shell.main(argstr.split()) except SystemExit as ex: self.assertEqual(1, ex.code) msg = (""Invalid API version parameter. "" ""Supported values are %s"" % SUPPORTED_VERSIONS) mock_exit.assert_called_with(msg=msg) @mock.patch('glanceclient.common.utils.exit') def test_shell_unsupported_version(self, mock_exit): # Test an integer version which is not supported (-1) mock_exit.side_effect = utils_exit shell = openstack_shell.OpenStackImagesShell() argstr = '--os-image-api-version -1 image-list' try: shell.main(argstr.split()) except SystemExit as ex: self.assertEqual(1, ex.code) msg = (""Invalid API version parameter. "" ""Supported values are %s"" % SUPPORTED_VERSIONS) mock_exit.assert_called_with(msg=msg) @mock.patch.object(openstack_shell.OpenStackImagesShell, 'get_subcommand_parser') def test_shell_import_error(self, mock_parser): mock_parser.side_effect = ImportError shell = openstack_shell.OpenStackImagesShell() argstr = '--os-image-api-version 2 image-list' self.assertRaises(ImportError, shell.main, argstr.split()) ",,53,9
openstack%2Ftripleo-heat-templates~master~I8c5e0ca300b86a38925f59c9df7831d69da9f787,openstack/tripleo-heat-templates,master,I8c5e0ca300b86a38925f59c9df7831d69da9f787,An environment file to enable network isolation,MERGED,2015-05-22 16:10:11.000000000,2015-05-26 18:17:51.000000000,2015-05-26 18:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6daad9a68fd73cd94fc2a0986bb8b18a87a6d7ed', 'message': 'An environment file to enable network isolation\n\nThis commit adds an environment file which adds all\nthe relevant resource registry entries to enable isolated\novercloud networks.\n\nChange-Id: I8c5e0ca300b86a38925f59c9df7831d69da9f787\n'}, {'number': 2, 'created': '2015-05-26 12:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04f51050727657e3007afbc822605a299fe5e1f9', 'message': 'An environment file to enable network isolation\n\nThis commit adds an environment file which adds all\nthe relevant resource registry entries to enable isolated\novercloud networks.\n\nChange-Id: I8c5e0ca300b86a38925f59c9df7831d69da9f787\n'}, {'number': 3, 'created': '2015-05-26 14:25:00.000000000', 'files': ['environments/network-isolation.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fb1e41921400e7d47f802bea68c813ce0c52e507', 'message': 'An environment file to enable network isolation\n\nThis commit adds an environment file which adds all\nthe relevant resource registry entries to enable isolated\novercloud networks.\n\nChange-Id: I8c5e0ca300b86a38925f59c9df7831d69da9f787\n'}]",0,185059,fb1e41921400e7d47f802bea68c813ce0c52e507,17,4,3,360,,,0,"An environment file to enable network isolation

This commit adds an environment file which adds all
the relevant resource registry entries to enable isolated
overcloud networks.

Change-Id: I8c5e0ca300b86a38925f59c9df7831d69da9f787
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/185059/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/network-isolation.yaml'],1,6daad9a68fd73cd94fc2a0986bb8b18a87a6d7ed,networks,# Enable the creation of Neutron networks for isolated Overcloud # traffic and configure each role to assign ports (related # to that role) on these networks. resource_registry: OS::TripleO::Network::External: network/external.yaml OS::TripleO::Network::InternalApi: network/internal_api.yaml OS::TripleO::Network::StorageMgmt: network/storage_mgmt.yaml OS::TripleO::Network::Storage: network/storage.yaml OS::TripleO::Network::Tenant: network/tenant.yaml # Port assignments for the controller role OS::TripleO::Controller::Ports::ExternalPort: network/ports/external.yaml OS::TripleO::Controller::Ports::InternalApiPort: network/ports/internal_api.yaml OS::TripleO::Controller::Ports::StoragePort: network/ports/storage.yaml OS::TripleO::Controller::Ports::StorageMgmtPort: network/ports/storage_mgmt.yaml OS::TripleO::Controller::Ports::TenantPort: network/ports/tenant.yaml # Port assignments for the compute role OS::TripleO::Compute::Ports::InternalApiPort: network/ports/internal_api.yaml OS::TripleO::Compute::Ports::StoragePort: network/ports/storage.yaml OS::TripleO::Compute::Ports::TenantPort: network/ports/tenant.yaml # Port assignments for the ceph storage role OS::TripleO::CephStorage::Ports::StoragePort: network/ports/storage.yaml OS::TripleO::CephStorage::Ports::StorageMgmtPort: network/ports/storage_mgmt.yaml # Port assignments for the swift storage role OS::TripleO::SwiftStorage::Ports::InternalApiPort: network/ports/internal_api.yaml OS::TripleO::SwiftStorage::Ports::StoragePort: network/ports/storage.yaml OS::TripleO::SwiftStorage::Ports::StorageMgmtPort: network/ports/storage_mgmt.yaml # Port assignments for the block storage role OS::TripleO::BlockStorage::Ports::InternalApiPort: network/ports/internal_api.yaml OS::TripleO::BlockStorage::Ports::StoragePort: network/ports/storage.yaml OS::TripleO::BlockStorage::Ports::StorageMgmtPort: network/ports/storage_mgmt.yaml ,,35,0
openstack%2Ftripleo-heat-templates~master~I6fcb26024b94420779b86766e16d8a24210c4f8e,openstack/tripleo-heat-templates,master,I6fcb26024b94420779b86766e16d8a24210c4f8e,Switch net-config templates to use OS::stack_id,MERGED,2015-05-19 22:15:18.000000000,2015-05-26 18:16:56.000000000,2015-05-26 18:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/970a9cb0578699a285c1405093ed27db1f7faf30', 'message': ""Switch net-config templates to use OS::stack_id\n\nThis patch removes the custom config_id outputs and replaces\nit with OS::stack_id which allows us to just call get_resource\nin the parent stack.\n\nThe motivation for this change is we'll be adding more os-net-config\ntemplates and it would be nice to take advantage of this newer\ntemplate feature.\n\nChange-Id: I6fcb26024b94420779b86766e16d8a24210c4f8e\n""}, {'number': 2, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/274e99abe744cb3291a9f83045961af34a41b3c1', 'message': ""Switch net-config templates to use OS::stack_id\n\nThis patch removes the custom config_id outputs and replaces\nit with OS::stack_id which allows us to just call get_resource\nin the parent stack.\n\nThe motivation for this change is we'll be adding more os-net-config\ntemplates and it would be nice to take advantage of this newer\ntemplate feature.\n\nChange-Id: I6fcb26024b94420779b86766e16d8a24210c4f8e\n""}, {'number': 3, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a972399d6bdb43b3accb82f0ad8e0b8ba13f3af3', 'message': ""Switch net-config templates to use OS::stack_id\n\nThis patch removes the custom config_id outputs and replaces\nit with OS::stack_id which allows us to just call get_resource\nin the parent stack.\n\nThe motivation for this change is we'll be adding more os-net-config\ntemplates and it would be nice to take advantage of this newer\ntemplate feature.\n\nChange-Id: I6fcb26024b94420779b86766e16d8a24210c4f8e\n""}, {'number': 4, 'created': '2015-05-26 12:51:28.000000000', 'files': ['net-config-bond.yaml', 'swift-storage.yaml', 'cinder-storage.yaml', 'controller.yaml', 'ceph-storage.yaml', 'puppet/ceph-storage-puppet.yaml', 'net-config-noop.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'net-config-bridge.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e38f7cae7db615c36c9e87bd9bb629fd18eda28a', 'message': ""Switch net-config templates to use OS::stack_id\n\nThis patch removes the custom config_id outputs and replaces\nit with OS::stack_id which allows us to just call get_resource\nin the parent stack.\n\nThe motivation for this change is we'll be adding more os-net-config\ntemplates and it would be nice to take advantage of this newer\ntemplate feature.\n\nChange-Id: I6fcb26024b94420779b86766e16d8a24210c4f8e\n""}]",0,184343,e38f7cae7db615c36c9e87bd9bb629fd18eda28a,22,5,4,360,,,0,"Switch net-config templates to use OS::stack_id

This patch removes the custom config_id outputs and replaces
it with OS::stack_id which allows us to just call get_resource
in the parent stack.

The motivation for this change is we'll be adding more os-net-config
templates and it would be nice to take advantage of this newer
template feature.

Change-Id: I6fcb26024b94420779b86766e16d8a24210c4f8e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/184343/4 && git format-patch -1 --stdout FETCH_HEAD,"['net-config-bond.yaml', 'swift-storage.yaml', 'cinder-storage.yaml', 'controller.yaml', 'ceph-storage.yaml', 'puppet/ceph-storage-puppet.yaml', 'net-config-noop.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'net-config-bridge.yaml', 'puppet/controller-puppet.yaml']",13,970a9cb0578699a285c1405093ed27db1f7faf30,networks, config: {get_resource: NetworkConfig}," config: {get_attr: [NetworkConfig, config_id]}",19,22
openstack%2Ftripleo-heat-templates~master~I9db7dd0c282af4e5f24947f31da2b89f231e6ae4,openstack/tripleo-heat-templates,master,I9db7dd0c282af4e5f24947f31da2b89f231e6ae4,Update neutron local_ip to use the tenant network,MERGED,2015-04-29 15:05:37.000000000,2015-05-26 18:14:57.000000000,2015-05-26 18:14:57.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-04-29 15:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26812cbf66eb18f160891b551bbe2c8098217d77', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetworkPorts abstraction to\nassign the Neutron tenant tunneling network. By default\nthis is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP however.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 2, 'created': '2015-04-29 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/db01e0f8d192177828f07d28d2b4d66ffb5c0d0b', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetworkPorts abstraction to\nassign the Neutron tenant tunneling network. By default\nthis is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP however.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 3, 'created': '2015-04-29 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/10c72c36b5915db1baa0e4bf1c95d99d63b4e24b', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetworkPorts abstraction to\nassign the Neutron tenant tunneling network. By default\nthis is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP however.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 4, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a9bd9c9b5252de22b848b1d0bb68b7ce4a03f774', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 5, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/89d7e524c88491200a8e865f138fb38f639eb2fd', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 6, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2babfe316cb37e2490dddf1ff7c792693c1dd34a', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 7, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2d36474b2b923adac5e2c59fdf8445c9c3874db8', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 8, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/179feff04510ac02dea701f9a04e075114e1e074', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 9, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/376418ad1a3ecec8c2770d16ed8eaafc346822ff', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 10, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/450732fbb0371288505c71e5e4b5d36ae28a0f52', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 11, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/74629680afa422284f9e4d7fb06f4370b8026c3d', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}, {'number': 12, 'created': '2015-05-26 12:51:28.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cfdd314564a8531d916cee389990684f9e4e11c8', 'message': 'Update neutron local_ip to use the tenant network\n\nThis patch uses the new NetIpMap and ServiceMap abstractions\nto assign the Neutron tenant tunneling network addresses.\nBy default this is associated with the tenant network. If no\ntenant network is activated this will still default to\nthe control plane IP address.\n\nChange-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4\n'}]",4,178716,cfdd314564a8531d916cee389990684f9e4e11c8,51,5,12,360,,,0,"Update neutron local_ip to use the tenant network

This patch uses the new NetIpMap and ServiceMap abstractions
to assign the Neutron tenant tunneling network addresses.
By default this is associated with the tenant network. If no
tenant network is activated this will still default to
the control plane IP address.

Change-Id: I9db7dd0c282af4e5f24947f31da2b89f231e6ae4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/16/178716/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/compute-puppet.yaml', 'puppet/controller-puppet.yaml']",2,26812cbf66eb18f160891b551bbe2c8098217d77,networks," neutron::agents::ml2::ovs::local_ip: {get_attr: [NetworkPorts, net_ip_map, {get_attr: [NetworkPorts, service_map, neutron_tunneling_net]}]}", neutron::agents::ml2::ovs::local_ip: {get_input: controller_host},3,2
openstack%2Fcongress~master~I77f73dec503ce645b7070e8d15f316849c5ecbc1,openstack/congress,master,I77f73dec503ce645b7070e8d15f316849c5ecbc1,Update .gitignore with .idea,MERGED,2015-05-24 20:42:04.000000000,2015-05-26 18:13:46.000000000,2015-05-26 18:13:45.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9382}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-05-24 20:42:04.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/congress/commit/f82a7985a565d7d59b2952d004dc68c5f0128b5e', 'message': 'Update .gitignore with .idea\n\nUpdate .gitignore to hide .idea directory generated by IntelliJ.\n\nChange-Id: I77f73dec503ce645b7070e8d15f316849c5ecbc1\n'}]",0,185285,f82a7985a565d7d59b2952d004dc68c5f0128b5e,8,4,1,16490,,,0,"Update .gitignore with .idea

Update .gitignore to hide .idea directory generated by IntelliJ.

Change-Id: I77f73dec503ce645b7070e8d15f316849c5ecbc1
",git fetch https://review.opendev.org/openstack/congress refs/changes/85/185285/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,f82a7985a565d7d59b2952d004dc68c5f0128b5e,update-gitignore-for-intellij, # IDEs .idea,,3,0
openstack%2Ftripleo-heat-templates~master~I1a8c382651f8096f606ad38f78bbd76314fbae5f,openstack/tripleo-heat-templates,master,I1a8c382651f8096f606ad38f78bbd76314fbae5f,Add a network ports IP mapping resource,MERGED,2015-04-29 15:05:37.000000000,2015-05-26 18:13:39.000000000,2015-05-26 18:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-04-29 15:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ef8c85678a063f8b84bc4184b1ff8e343ed29ae', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\ncalled net_ip_map which will allow us to easily extract\narbitrary IP addresses for each network using the\nget_attr function in heat. This has been wired into\nthe OS::TripleO::Network::Ports resource as a convience\noutput parameter as well.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 2, 'created': '2015-04-29 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb555bff01909bc2815b1b96d14dfca1f9d6ad04', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\ncalled net_ip_map which will allow us to easily extract\narbitrary IP addresses for each network using the\nget_attr function in heat. This has been wired into\nthe OS::TripleO::Network::Ports resource as a convience\noutput parameter as well.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 3, 'created': '2015-04-29 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a9b1412019873cace6447ae87d290180dad51d14', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\ncalled net_ip_map which will allow us to easily extract\narbitrary IP addresses for each network using the\nget_attr function in heat. This has been wired into\nthe OS::TripleO::Network::Ports resource as a convience\noutput parameter as well.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 4, 'created': '2015-05-05 21:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a43d8b3adb6aa19c47e1febfab8c2b0fee280d37', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\ncalled net_ip_map which will allow us to easily extract\narbitrary IP addresses for each network using the\nget_attr function in heat. This has been wired into\nthe OS::TripleO::Network::Ports resource as a convience\noutput parameter as well.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 5, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/961926288d4af27c0af26ea5343574740495a39e', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 6, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6202d6a4efb6e514f2accfb9b778d7b86df16d1f', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 7, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/477d1ec307771561a4c18b75fd0c06dd756b7d98', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 8, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/692df11eaaedc3f15f826fb8827b17228bc8bc65', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 9, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d92ffe7b0a83b0b65e2a0dda6972737b15ba9feb', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 10, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8fb79ae6830b321bd1c64f395befbf9f4a0beb09', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 11, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe38b19b609f15115cbf8c886be082d39d5da0ea', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 12, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b6f1586715f3f40f2643f1eedd12b3555fe5ec39', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}, {'number': 13, 'created': '2015-05-26 12:51:28.000000000', 'files': ['overcloud-resource-registry.yaml', 'network/ports/net_ip_map.yaml', 'overcloud-resource-registry-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b7ead8ec638ce9a08224032e1dced0de2817bd31', 'message': 'Add a network ports IP mapping resource\n\nThis patch adds a resource which constructs a Json output\nparameter called net_ip_map which will allow us to easily\nextract arbitrary IP addresses for each network using the\nget_attr function in heat.\n\nThe goal is to use this data construct in each role\ntemplate to obtain the correct IP address on each\nnetwork.\n\nChange-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f\n'}]",0,178714,b7ead8ec638ce9a08224032e1dced0de2817bd31,50,6,13,360,,,0,"Add a network ports IP mapping resource

This patch adds a resource which constructs a Json output
parameter called net_ip_map which will allow us to easily
extract arbitrary IP addresses for each network using the
get_attr function in heat.

The goal is to use this data construct in each role
template to obtain the correct IP address on each
network.

Change-Id: I1a8c382651f8096f606ad38f78bbd76314fbae5f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/178714/9 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry.yaml', 'network/ports/net_ip_map.yaml', 'overcloud-resource-registry-puppet.yaml', 'network/ports/ports.yaml']",4,0ef8c85678a063f8b84bc4184b1ff8e343ed29ae,networks," NetIpMap: type: OS::TripleO::Network::Ports::NetIpMap properties: InternalApiIp: {get_attr: [InternalApiPort, ip_address]} PublicApiIp: {get_attr: [PublicApiPort, ip_address]} ClusterMgmtIp: {get_attr: [ClusterMgmtPort, ip_address]} StorageIp: {get_attr: [StoragePort, ip_address]} ExternalIp: {get_attr: [ExternalPort, ip_address]} TenantIp: {get_attr: [TenantPort, ip_address]} net_ip_map: description: A mapping of network names to IPs for this machine. value: {get_attr: [NetIpMap, net_ip_map]}",,43,0
openstack%2Ftripleo-heat-templates~master~I4e18cd4763455f815a8f8b82c93a598c99cc3842,openstack/tripleo-heat-templates,master,I4e18cd4763455f815a8f8b82c93a598c99cc3842,Add isolated network ports to block storage roles,MERGED,2015-05-07 01:49:48.000000000,2015-05-26 18:12:23.000000000,2015-05-26 18:12:23.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e8b0eb124174cf36e8ac92bff7c7262f9160abb7', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 2, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e7e7bb742fe1af644fd8697b45761f471db1bd60', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 3, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/16a28bf8fd9b9f14c0366b7a184ba872dcd8a369', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 4, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b1d838517056fd3abb607eb637df3582cb5076f', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 5, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/269669a925105edd4ba43ba1fed6163cc5a94584', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 6, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b16d765719ad15761f7d26249691c91e9fd12fdb', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 7, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b9a298e3725d245c653acc71fbcbc4926b28593f', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 8, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/790335a32b5b64968cc26986220aa0f69eee28cd', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}, {'number': 9, 'created': '2015-05-26 12:51:28.000000000', 'files': ['cinder-storage.yaml', 'overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/cinder-storage-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1b66947a021b23699d6080b2cba78cd64efc814', 'message': 'Add isolated network ports to block storage roles\n\nThis patch updates the cinder block storage roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal_api\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842\n'}]",0,180824,b1b66947a021b23699d6080b2cba78cd64efc814,39,5,9,360,,,0,"Add isolated network ports to block storage roles

This patch updates the cinder block storage roles so that
they can optionally make use of isolated network
ports on the storage, storage management, and internal_api
networks.

 -Multiple networks are created based upon settings in the heat
  resource registry. These nets will either use the noop network (the
  control plane pass-thru default) or create a custom Neutron port on
  each of the configured networks.

 -The ipaddress/subnet of each network is passed passed into the
  NetworkConfig resource which drives os-net-config. This allows the
  deployer to define a custom network template for static IPs, etc
  on each of the networks.

 -The ipaddress is exposed as an output parameter. By exposing
  the individual addresses as outputs we allow Heat to construct
  collections of ports for various services.

Change-Id: I4e18cd4763455f815a8f8b82c93a598c99cc3842
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/180824/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder-storage.yaml', 'overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/cinder-storage-puppet.yaml']",4,e8b0eb124174cf36e8ac92bff7c7262f9160abb7,networks," ExternalPort: type: OS::TripleO::BlockStorage::Ports::ExternalPort properties: ControlPlaneIP: {get_attr: [BlockStorage, networks, ctlplane, 0]} InternalApiPort: type: OS::TripleO::BlockStorage::Ports::InternalApiPort properties: ControlPlaneIP: {get_attr: [BlockStorage, networks, ctlplane, 0]} StoragePort: type: OS::TripleO::BlockStorage::Ports::StoragePort properties: ControlPlaneIP: {get_attr: [BlockStorage, networks, ctlplane, 0]} StorageMgmtPort: type: OS::TripleO::BlockStorage::Ports::StorageMgmtPort properties: ControlPlaneIP: {get_attr: [BlockStorage, networks, ctlplane, 0]} TenantPort: type: OS::TripleO::BlockStorage::Ports::TenantPort properties: ControlPlaneIP: {get_attr: [BlockStorage, networks, ctlplane, 0]} NetIpMap: type: OS::TripleO::Network::Ports::NetIpMap properties: ExternalIp: {get_attr: [ExternalPort, ip_address]} InternalApiIp: {get_attr: [InternalApiPort, ip_address]} StorageIp: {get_attr: [StoragePort, ip_address]} StorageMgmtIp: {get_attr: [StorageMgmtPort, ip_address]} TenantIp: {get_attr: [TenantPort, ip_address]} ServiceMap: type: OS::TripleO::Network::Ports::ServiceMap properties: ExternalIpSubnet: {get_attr: [ExternalPort, ip_subnet]} InternalApiIpSubnet: {get_attr: [InternalApiPort, ip_subnet]} StorageIpSubnet: {get_attr: [StoragePort, ip_subnet]} StorageMgmtIpSubnet: {get_attr: [StorageMgmtPort, ip_subnet]} TenantIpSubnet: {get_attr: [TenantPort, ip_subnet]} external_ip_address: description: IP address of the server in the external network value: {get_attr: [ExternalPort, ip_address]} internal_api_ip_address: description: IP address of the server in the internal_api network value: {get_attr: [InternalApiPort, ip_address]} storage_ip_address: description: IP address of the server in the storage network value: {get_attr: [StoragePort, ip_address]} storage_mgmt_ip_address: description: IP address of the server in the storage_mgmt network value: {get_attr: [StorageMgmtPort, ip_address]} tenant_ip_address: description: IP address of the server in the tenant network value: {get_attr: [TenantPort, ip_address]}",,130,0
openstack%2Fmurano-dashboard~master~Idb332e56b764d494a51de74398e7098c68561c61,openstack/murano-dashboard,master,Idb332e56b764d494a51de74398e7098c68561c61,Call location.reload only once at successfull env deployment,MERGED,2015-05-22 16:02:10.000000000,2015-05-26 18:11:50.000000000,2015-05-26 18:11:49.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 14265}]","[{'number': 1, 'created': '2015-05-22 16:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5fee40cc6ab2eef97e03de80f83c8cab427db31e', 'message': 'Call location.reload only once at successfull env deployment\n\nBefore it was possible, that in some configurations table update events\nwould stack and reload would be called multiple times.\nThis change introduces a global js variable, that would prevent\nlocation.reload from being called more than once.\n\nChange-Id: Idb332e56b764d494a51de74398e7098c68561c61\nRelated-Bug: #1454221\n'}, {'number': 2, 'created': '2015-05-22 16:06:47.000000000', 'files': ['muranodashboard/static/muranodashboard/js/horizon.tables+reload.js'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/275b545e5a9a48bdb08afa68f8c3e0520afe02c4', 'message': 'Call location.reload only once at successfull env deployment\n\nBefore it was possible, that in some configurations table update events\nwould stack and reload would be called multiple times.\nThis change introduces a global js variable, that would prevent\nlocation.reload from being called more than once.\n\nChange-Id: Idb332e56b764d494a51de74398e7098c68561c61\nRelated-Bug: #1454221\n'}]",0,185057,275b545e5a9a48bdb08afa68f8c3e0520afe02c4,14,7,2,15168,,,0,"Call location.reload only once at successfull env deployment

Before it was possible, that in some configurations table update events
would stack and reload would be called multiple times.
This change introduces a global js variable, that would prevent
location.reload from being called more than once.

Change-Id: Idb332e56b764d494a51de74398e7098c68561c61
Related-Bug: #1454221
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/57/185057/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/static/muranodashboard/js/horizon.tables+reload.js'],1,5fee40cc6ab2eef97e03de80f83c8cab427db31e,bug/1454221,// In some cases successfull update events can stack up in case we have lots of apps in an env. // This might lead to a situation when lots of reloads are scheduled simultaneously. // The following cariable forces reload to be called only once. var reload_called = false; if (reload_called === false) { reload_called = true; location.reload(true); }, location.reload(true);,8,1
openstack%2Ftripleo-heat-templates~master~I9984404331705f6ce569fb54a38b2838a8142faa,openstack/tripleo-heat-templates,master,I9984404331705f6ce569fb54a38b2838a8142faa,Add isolated network ports to swift roles,MERGED,2015-05-07 01:49:48.000000000,2015-05-26 18:11:38.000000000,2015-05-26 18:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca46ec6155b9c9804281ed23abc87117e1b18671', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 2, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/222f570aae41fc5eb28210763f7b58f9f3e79339', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 3, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/333cbd48011fbd742db079fedda8d3954dbdee0d', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 4, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9347cc2552c4fd4d77b70dd74e49a47cbd3624b', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 5, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47dbc81d96ae1c503c3dc20b0232dc05dd506b08', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 6, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c05cde708f8ce5fc7f043759d6c69c63dc7537fd', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 7, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc495c69a03ad13fa2e76f7069fd1afc1cea2871', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 8, 'created': '2015-05-22 16:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e1b30860bc64e202e8995b1125311d8c30c4f9cc', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}, {'number': 9, 'created': '2015-05-26 12:51:28.000000000', 'files': ['swift-storage.yaml', 'overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/swift-storage-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8e5b1d2a39279df2166142be325d0eae5be870e', 'message': 'Add isolated network ports to swift roles\n\nThis patch updates the swift roles so that\nthey can optionally make use of isolated network\nports on the storage, storage management, and internal API\nnetworks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9984404331705f6ce569fb54a38b2838a8142faa\n'}]",0,180823,c8e5b1d2a39279df2166142be325d0eae5be870e,39,5,9,360,,,0,"Add isolated network ports to swift roles

This patch updates the swift roles so that
they can optionally make use of isolated network
ports on the storage, storage management, and internal API
networks.

 -Multiple networks are created based upon settings in the heat
  resource registry. These nets will either use the noop network (the
  control plane pass-thru default) or create a custom Neutron port on
  each of the configured networks.

 -The ipaddress/subnet of each network is passed passed into the
  NetworkConfig resource which drives os-net-config. This allows the
  deployer to define a custom network template for static IPs, etc
  on each of the networks.

 -The ipaddress is exposed as an output parameter. By exposing
  the individual addresses as outputs we allow Heat to construct
  collections of ports for various services.

Change-Id: I9984404331705f6ce569fb54a38b2838a8142faa
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/23/180823/9 && git format-patch -1 --stdout FETCH_HEAD,"['swift-storage.yaml', 'overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/swift-storage-puppet.yaml']",4,ca46ec6155b9c9804281ed23abc87117e1b18671,networks," ExternalPort: type: OS::TripleO::SwiftStorage::Ports::ExternalPort properties: ControlPlaneIP: {get_attr: [SwiftStorage, networks, ctlplane, 0]} InternalApiPort: type: OS::TripleO::SwiftStorage::Ports::InternalApiPort properties: ControlPlaneIP: {get_attr: [SwiftStorage, networks, ctlplane, 0]} StoragePort: type: OS::TripleO::SwiftStorage::Ports::StoragePort properties: ControlPlaneIP: {get_attr: [SwiftStorage, networks, ctlplane, 0]} StorageMgmtPort: type: OS::TripleO::SwiftStorage::Ports::StorageMgmtPort properties: ControlPlaneIP: {get_attr: [SwiftStorage, networks, ctlplane, 0]} TenantPort: type: OS::TripleO::SwiftStorage::Ports::TenantPort properties: ControlPlaneIP: {get_attr: [SwiftStorage, networks, ctlplane, 0]} NetIpMap: type: OS::TripleO::Network::Ports::NetIpMap properties: ExternalIp: {get_attr: [ExternalPort, ip_address]} InternalApiIp: {get_attr: [InternalApiPort, ip_address]} StorageIp: {get_attr: [StoragePort, ip_address]} StorageMgmtIp: {get_attr: [StorageMgmtPort, ip_address]} TenantIp: {get_attr: [TenantPort, ip_address]} ServiceMap: type: OS::TripleO::Network::Ports::ServiceMap properties: ExternalIpSubnet: {get_attr: [ExternalPort, ip_subnet]} InternalApiIpSubnet: {get_attr: [InternalApiPort, ip_subnet]} StorageIpSubnet: {get_attr: [StoragePort, ip_subnet]} StorageMgmtIpSubnet: {get_attr: [StorageMgmtPort, ip_subnet]} TenantIpSubnet: {get_attr: [TenantPort, ip_subnet]} external_ip_address: description: IP address of the server in the external network value: {get_attr: [ExternalPort, ip_address]} internal_api_ip_address: description: IP address of the server in the internal_api network value: {get_attr: [InternalApiPort, ip_address]} storage_ip_address: description: IP address of the server in the storage network value: {get_attr: [StoragePort, ip_address]} storage_mgmt_ip_address: description: IP address of the server in the storage_mgmt network value: {get_attr: [StorageMgmtPort, ip_address]} tenant_ip_address: description: IP address of the server in the tenant network value: {get_attr: [TenantPort, ip_address]}",,130,0
openstack%2Ftripleo-heat-templates~master~I35cb8e7812202f8a7bc0379067bf33d483cd2aec,openstack/tripleo-heat-templates,master,I35cb8e7812202f8a7bc0379067bf33d483cd2aec,Add isolated network ports to ceph roles,MERGED,2015-05-07 01:49:48.000000000,2015-05-26 18:11:19.000000000,2015-05-26 18:11:18.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ff1f032a282f3cdf5957a49c5aa7bd0cac1d3e1e', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 2, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/da7574a3b85e5cd2fdb5b1e66b320295913b5bd3', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 3, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ab1851b32e64f9454d3eb168bd2e417c9a13f13', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 4, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/007bff9b3b412cf3c14339c5a935fd486015b99c', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 5, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1faacb9b4841d43047a333b6129c7996739570bc', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 6, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/44fefc634706e68fe61ba5075d20249c02cace9a', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 7, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b841709a8cd3dc390dd4b3fd08655e928e1b565a', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 8, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc181216b7e24a39aeb2f58d99821c6ef0a5e7f0', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}, {'number': 9, 'created': '2015-05-26 12:51:28.000000000', 'files': ['puppet/ceph-storage-puppet.yaml', 'overcloud-resource-registry.yaml', 'ceph-storage.yaml', 'overcloud-resource-registry-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e2ecdfb27bde043ed1b48a3c5afda64df6d2d8d', 'message': 'Add isolated network ports to ceph roles\n\nThis patch updates the ceph roles so that\nthey can optionally make use of isolated network\nports on the storage and storage management networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec\n'}]",2,180822,0e2ecdfb27bde043ed1b48a3c5afda64df6d2d8d,41,6,9,360,,,0,"Add isolated network ports to ceph roles

This patch updates the ceph roles so that
they can optionally make use of isolated network
ports on the storage and storage management networks.

 -Multiple networks are created based upon settings in the heat
  resource registry. These nets will either use the noop network (the
  control plane pass-thru default) or create a custom Neutron port on
  each of the configured networks.

 -The ipaddress/subnet of each network is passed passed into the
  NetworkConfig resource which drives os-net-config. This allows the
  deployer to define a custom network template for static IPs, etc
  on each of the networks.

 -The ipaddress is exposed as an output parameter. By exposing
  the individual addresses as outputs we allow Heat to construct
  collections of ports for various services.

Change-Id: I35cb8e7812202f8a7bc0379067bf33d483cd2aec
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/180822/9 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/ceph-storage-puppet.yaml', 'overcloud-resource-registry.yaml', 'ceph-storage.yaml', 'overcloud-resource-registry-puppet.yaml']",4,ff1f032a282f3cdf5957a49c5aa7bd0cac1d3e1e,networks, # Port assignments for the ceph storage role OS::TripleO::CephStorage::Ports::ExternalPort: network/ports/noop.yaml OS::TripleO::CephStorage::Ports::InternalApiPort: network/ports/noop.yaml OS::TripleO::CephStorage::Ports::StoragePort: network/ports/noop.yaml OS::TripleO::CephStorage::Ports::StorageMgmtPort: network/ports/noop.yaml OS::TripleO::CephStorage::Ports::TenantPort: network/ports/noop.yaml ,,130,0
openstack%2Fopenstack-manuals~master~I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0,openstack/openstack-manuals,master,I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0,Updates to Config ref and Cloud Admin guide,MERGED,2015-05-06 02:23:14.000000000,2015-05-26 18:11:13.000000000,2015-05-26 18:11:10.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 8103}, {'_account_id': 9382}, {'_account_id': 10607}, {'_account_id': 14643}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-05-06 02:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8b6e97dae5017af5ee2f9237b5799e468e664d19', 'message': 'Updates to Config ref and Cloud Admin guide based on info sent by SME\n\nIncludes updates EQL driver documentation, multi-storage instructions:\n* added EQL-specific example, with description of additional required options.\n* link back to Config reference guide.\n* link to multi-backend instructions in Cloud Admin guide.\n\nChange-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0\n'}, {'number': 2, 'created': '2015-05-06 03:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/70c2cfe4c89781c5a3b1220b1cdf602ea1fd2f63', 'message': 'Updates to Config ref and Cloud Admin guide based on info sent by SME\n\nIncludes updates EQL driver documentation, multi-storage instructions:\n* added EQL-specific example, with description of additional required options.\n* link back to Config reference guide.\n* link to multi-backend instructions in Cloud Admin guide.\n\nChange-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0\n'}, {'number': 3, 'created': '2015-05-12 05:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/21df5d782d5e37d98e76f51d3479257038482ec9', 'message': 'Updates to Config ref and Cloud Admin guide based on info sent by SME\n\nIncludes updates EQL driver documentation, multi-storage instructions:\n* added EQL-specific example, with description of additional required options.\n* link back to Config reference guide.\n* link to multi-backend instructions in Cloud Admin guide.\n\nChange-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0\n'}, {'number': 4, 'created': '2015-05-15 07:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/721f9babf6ca846de8c8f9b2eb1678e6ae374dcc', 'message': 'Updates to Config ref and Cloud Admin guide based on info sent by SME\n\nIncludes updates EQL driver documentation, multi-storage instructions:\n* added EQL-specific example, with description of additional required options.\n* link back to Config reference guide.\n* link to multi-backend instructions in Cloud Admin guide.\n\nChange-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0\n'}, {'number': 5, 'created': '2015-05-18 00:38:49.000000000', 'files': ['doc/config-reference/block-storage/drivers/dell-equallogic-driver.xml', 'doc/admin-guide-cloud/blockstorage/section_multi_backend.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df7ff14f4c04ecd4e8a012e68684cbfe209d7d31', 'message': 'Updates to Config ref and Cloud Admin guide\n\nIncludes updates EQL driver documentation, multi-storage instructions:\n* added EQL-specific example, with description of additional required options.\n* link back to Config reference guide.\n* link to multi-backend instructions in Cloud Admin guide.\n\nChange-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0\n'}]",21,180382,df7ff14f4c04ecd4e8a012e68684cbfe209d7d31,27,10,5,8103,,,0,"Updates to Config ref and Cloud Admin guide

Includes updates EQL driver documentation, multi-storage instructions:
* added EQL-specific example, with description of additional required options.
* link back to Config reference guide.
* link to multi-backend instructions in Cloud Admin guide.

Change-Id: I317ed6ac8d2e57dcb722436dd669eb2ebf798ed0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/180382/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/drivers/dell-equallogic-driver.xml', 'doc/admin-guide-cloud/blockstorage/section_multi_backend.xml']",2,8b6e97dae5017af5ee2f9237b5799e468e664d19,dell-eql-update," <para>Some volume drivers require additional settings to be configured for each back-end. The following example shows the typical configuration for a Block Storage service that uses two Dell EqualLogic back-ends:</para> <programlisting language=""ini"">enabled_backends=backend1,backend2 ​san_ssh_port=22 ​ssh_conn_timeout=30 ​san_thin_provision=true ​ ​[backend1] ​volume_driver=cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver ​volume_backend_name=backend1 ​san_ip=IP_EQLX1 ​san_login=SAN_UNAME ​san_password=SAN_PW ​eqlx_group_name=EQLX_GROUP ​eqlx_pool=EQLX_POOL ​ ​[backend2] ​volume_driver=cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver ​volume_backend_name=backend2 ​san_ip=IP_EQLX2 ​san_login=SAN_UNAME ​san_password=SAN_PW ​eqlx_group_name=EQLX_GROUP ​eqlx_pool=EQLX_POOL </programlisting> <para>In this example:</para> <itemizedlist> <listitem><para>Thin provisioning for SAN volumes is enabled (<literal>san_thin_provision=true</literal>). This is recommended when setting up Dell EqualLogic back-ends.</para></listitem> <listitem><para>Each Dell EqualLogic back-end configuration (<literal>[backend1]</literal> and <literal>[backend2]</literal>) has the same required settings as a single back-end configuration, with the addition of <literal>volume_backend_name</literal>.</para></listitem> <listitem><para>The <literal>san_ssh_port</literal> option is set to its default value, 22. This option sets the port used for SSH.</para></listitem> <listitem><para>The <literal>ssh_conn_timeout</literal> option is also set to its default value, 30. This option sets the timeout (in seconds) for CLI commands over SSH.</para></listitem> <listitem><para>The <literal>IP_EQLX1</literal> and <literal>IP_EQLX2</literal> refer to the IP addresses used to reach the Dell EqualLogic Group of <literal>backend1</literal> and <literal>backend2</literal> through SSH, respectively.</para></listitem> </itemizedlist> <para>For more information on required and optional settings for Dell EqualLogic back-ends, see <link xlink:href=""http://docs.openstack.org/trunk/config-reference/content/dell-equallogic-driver.html""> Dell EqualLogic volume driver</link>.</para>",,58,0
openstack%2Ftripleo-heat-templates~master~Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1,openstack/tripleo-heat-templates,master,Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1,Add isolated network ports to compute roles,MERGED,2015-05-07 01:49:48.000000000,2015-05-26 18:10:16.000000000,2015-05-26 18:10:16.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eccc6b456e9941a4b9dcf524db0e1bdf6c618a80', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 2, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d8b1cf056a0a8e8c2ed77aac49e84b2741efddc9', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 3, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/010a6ec8abfe91d519a31766a7dcb6332e01d227', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 4, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00cbe179c59aef0e631fd28b3c5d22f3a6013c21', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 5, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/de0288d16b3f99a84262fe82ec6283c95b2e373a', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 6, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5edd1b775b9b4e0b5a6de6cea92a2b2d2b04211f', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 7, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a54e8780c04cc0442c81af93b1ca6bae9b91cc8f', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 8, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/85c9bcaf39e8d275cd8d09b3e0f0f96635f07d88', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}, {'number': 9, 'created': '2015-05-26 12:51:28.000000000', 'files': ['overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'compute.yaml', 'puppet/compute-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b87fe75b87e0a2cb3e35e1ffb8270cbe190c1f6c', 'message': 'Add isolated network ports to compute roles\n\nThis patch updates the compute roles so that\nthey can optionally make use of isolated network\nports on the tenant, storage, and internal_api networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1\n'}]",1,180821,b87fe75b87e0a2cb3e35e1ffb8270cbe190c1f6c,41,6,9,360,,,0,"Add isolated network ports to compute roles

This patch updates the compute roles so that
they can optionally make use of isolated network
ports on the tenant, storage, and internal_api networks.

 -Multiple networks are created based upon settings in the heat
  resource registry. These nets will either use the noop network (the
  control plane pass-thru default) or create a custom Neutron port on
  each of the configured networks.

 -The ipaddress/subnet of each network is passed passed into the
  NetworkConfig resource which drives os-net-config. This allows the
  deployer to define a custom network template for static IPs, etc
  on each of the networks.

 -The ipaddress is exposed as an output parameter. By exposing
  the individual addresses as outputs we allow Heat to construct
  collections of ports for various services.

Change-Id: Ib07b4b7256ede7fb47ecc4eb5abe64b9144b9aa1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/180821/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry.yaml', 'compute.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/compute-puppet.yaml']",4,eccc6b456e9941a4b9dcf524db0e1bdf6c618a80,networks," ExternalPort: type: OS::TripleO::Compute::Ports::ExternalPort properties: ControlPlaneIP: {get_attr: [NovaCompute, networks, ctlplane, 0]} InternalApiPort: type: OS::TripleO::Compute::Ports::InternalApiPort properties: ControlPlaneIP: {get_attr: [NovaCompute, networks, ctlplane, 0]} StoragePort: type: OS::TripleO::Compute::Ports::StoragePort properties: ControlPlaneIP: {get_attr: [NovaCompute, networks, ctlplane, 0]} StorageMgmtPort: type: OS::TripleO::Compute::Ports::StorageMgmtPort properties: ControlPlaneIP: {get_attr: [NovaCompute, networks, ctlplane, 0]} TenantPort: type: OS::TripleO::Compute::Ports::TenantPort properties: ControlPlaneIP: {get_attr: [NovaCompute, networks, ctlplane, 0]} NetIpMap: type: OS::TripleO::Network::Ports::NetIpMap properties: ExternalIp: {get_attr: [ExternalPort, ip_address]} InternalApiIp: {get_attr: [InternalApiPort, ip_address]} StorageIp: {get_attr: [StoragePort, ip_address]} StorageMgmtIp: {get_attr: [StorageMgmtPort, ip_address]} TenantIp: {get_attr: [TenantPort, ip_address]} ServiceMap: type: OS::TripleO::Network::Ports::ServiceMap properties: ExternalIpSubnet: {get_attr: [ExternalPort, ip_subnet]} InternalApiIpSubnet: {get_attr: [InternalApiPort, ip_subnet]} StorageIpSubnet: {get_attr: [StoragePort, ip_subnet]} StorageMgmtIpSubnet: {get_attr: [StorageMgmtPort, ip_subnet]} TenantIpSubnet: {get_attr: [TenantPort, ip_subnet]} external_ip_address: description: IP address of the server in the external network value: {get_attr: [ExternalPort, ip_address]} internal_api_ip_address: description: IP address of the server in the internal_api network value: {get_attr: [InternalApiPort, ip_address]} storage_ip_address: description: IP address of the server in the storage network value: {get_attr: [StoragePort, ip_address]} storage_mgmt_ip_address: description: IP address of the server in the storage_mgmt network value: {get_attr: [StorageMgmtPort, ip_address]} tenant_ip_address: description: IP address of the server in the tenant network value: {get_attr: [TenantPort, ip_address]}",,130,0
openstack%2Fhorizon~master~I47579c13a39c2c14dc2d6d41d3e0e70132dbc406,openstack/horizon,master,I47579c13a39c2c14dc2d6d41d3e0e70132dbc406,ngReorg - Relocate filters and a validator,MERGED,2015-05-20 18:31:31.000000000,2015-05-26 18:09:33.000000000,2015-05-26 18:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9576}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-05-20 18:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d13bccf17d34db0f375966268d3ee45d51d6da15', 'message': 'ngReorg - Relocate filters and a validator\n\nThis commit moves some filters and a validator into\nthe current framework structure.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I47579c13a39c2c14dc2d6d41d3e0e70132dbc406\nPartial-Bug: #1454880\n'}, {'number': 2, 'created': '2015-05-21 19:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3e6cbfe310e6af8c27995f93a72b55377dc5ed5e', 'message': 'ngReorg - Relocate filters and a validator\n\nThis commit moves some filters and a validator into\nthe current framework structure.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I47579c13a39c2c14dc2d6d41d3e0e70132dbc406\nPartial-Bug: #1454880\n'}, {'number': 3, 'created': '2015-05-21 21:15:05.000000000', 'files': ['horizon/static/framework/util/validators/validators.js', 'horizon/static/horizon/js/angular/directives/forms.js', 'horizon/static/framework/util/filters/filters.spec.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/framework/util/util.module.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/util/filters/filters.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/264fb533429f02e6271178a2711bb5e870bbc72e', 'message': 'ngReorg - Relocate filters and a validator\n\nThis commit moves some filters and a validator into\nthe current framework structure.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I47579c13a39c2c14dc2d6d41d3e0e70132dbc406\nPartial-Bug: #1454880\n'}]",4,184575,264fb533429f02e6271178a2711bb5e870bbc72e,12,4,3,14307,,,0,"ngReorg - Relocate filters and a validator

This commit moves some filters and a validator into
the current framework structure.

This is one step in a larger effort to restructure the Angular
source. See https://review.openstack.org/#/c/176152/ for the
full set of planned changes.

Change-Id: I47579c13a39c2c14dc2d6d41d3e0e70132dbc406
Partial-Bug: #1454880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/75/184575/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/validators/validators.js', 'horizon/static/horizon/js/angular/directives/forms.js', 'horizon/static/framework/util/filters/filters.spec.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/framework/util/util.module.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/util/filters/filters.js']",8,d13bccf17d34db0f375966268d3ee45d51d6da15,bug/1454880," * @name horizon.framework.util.filters * horizon.framework.util.filters provides common filters to be used within Horizon. angular.module('horizon.framework.util.filters', ['horizon.framework.util.i18n'])"," * @name hz.filters * hz.filters provides common filters to be used within Horizon. angular.module('hz.filters', ['horizon.framework.util.i18n'])",94,95
openstack%2Ftripleo-heat-templates~master~I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66,openstack/tripleo-heat-templates,master,I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66,Add isolated network ports to controller roles,MERGED,2015-04-27 16:00:10.000000000,2015-05-26 18:09:28.000000000,2015-05-26 18:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-04-27 16:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/95d82f8d4b60a072afff210e0b9f2ef6ab695fad', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 5 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 2, 'created': '2015-04-27 16:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1a42e9eea1cd98560b3c24f9b1cbf78e7c6a6487', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 5 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 3, 'created': '2015-04-28 18:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5fe005f66f9865002636e7adc523979897db03fe', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 6 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 4, 'created': '2015-04-29 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/672261ddbe5856888a570568745cf92d26ff9d48', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 6 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 5, 'created': '2015-04-29 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/036ff83f4ee0d052349ddf3401fedbae45f0bac4', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 6 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 6, 'created': '2015-05-05 21:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75040e8e58231e32ea286d4405c55d8fefeb9f13', 'message': 'Wire in split out ports to all roles\n\nThis patch updates all of the Overcloud roles so that\nthey can (optionally) make use of using isolated network\nports on each of 6 available overcloud networks.\n\nFor each role:\n\n -a NetworkPorts is created. Based upon settings in the heat resource\n  registry this will either use noop (the control plane default) or\n  create a custom Neutron port on each of the configured networks.\n\n -The ipaddress/subnet is passed passed into the NetworkConfig\n  resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various service.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 7, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ba65a1944ab14ec3d1665cc0882305fb9279f5d0', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 8, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00a4280272d955cc05d8ad4f6ba3bd3c63eb024f', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 9, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06138f52a86de4bae364e9763022e4a747b19cca', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 10, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a45cfdbba41b3e0def3f803f2955d1b34ba2e425', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 11, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f12e4aa0229dba4faee0e3fbc90597c29b76b07f', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 12, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/396209aeb5efe2fd0fcefbf7af036b69e61e8468', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 13, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b18a558dae747c36ff7b1e00b71f93ffcaff7a40', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 14, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a4979ab0385ea7daa26a6547bfea27431a2afed7', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}, {'number': 15, 'created': '2015-05-26 12:51:28.000000000', 'files': ['overcloud-resource-registry.yaml', 'controller.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7418a32a73277d258ceeb06b329973d61aceed7c', 'message': 'Add isolated network ports to controller roles\n\nThis patch updates the controller roles so that\nthey can optionally make use of isolated network\nports on each of 5 available overcloud networks.\n\n -Multiple networks are created based upon settings in the heat\n  resource registry. These nets will either use the noop network (the\n  control plane pass-thru default) or create a custom Neutron port on\n  each of the configured networks.\n\n -The ipaddress/subnet of each network is passed passed into the\n  NetworkConfig resource which drives os-net-config. This allows the\n  deployer to define a custom network template for static IPs, etc\n  on each of the networks.\n\n -The ipaddress is exposed as an output parameter. By exposing\n  the individual addresses as outputs we allow Heat to construct\n  collections of ports for various services.\n\nChange-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66\n'}]",2,177846,7418a32a73277d258ceeb06b329973d61aceed7c,60,7,15,360,,,0,"Add isolated network ports to controller roles

This patch updates the controller roles so that
they can optionally make use of isolated network
ports on each of 5 available overcloud networks.

 -Multiple networks are created based upon settings in the heat
  resource registry. These nets will either use the noop network (the
  control plane pass-thru default) or create a custom Neutron port on
  each of the configured networks.

 -The ipaddress/subnet of each network is passed passed into the
  NetworkConfig resource which drives os-net-config. This allows the
  deployer to define a custom network template for static IPs, etc
  on each of the networks.

 -The ipaddress is exposed as an output parameter. By exposing
  the individual addresses as outputs we allow Heat to construct
  collections of ports for various services.

Change-Id: I9bbd6c8f5b9697ab605bcdb5f84280bed74a8d66
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/177846/8 && git format-patch -1 --stdout FETCH_HEAD,"['net-config-bond.yaml', 'swift-storage.yaml', 'cinder-storage.yaml', 'controller.yaml', 'ceph-storage.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/ceph-storage-puppet.yaml', 'overcloud-resource-registry.yaml', 'net-config-noop.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'net-config-bridge.yaml', 'puppet/controller-puppet.yaml']",15,95d82f8d4b60a072afff210e0b9f2ef6ab695fad,networks," NetworkPorts: type: OS::TripleO::Network::Ports properties: InternalApiIpSubnet: {get_attr: [NetworkPorts, internal_api_ip_subnet]} PublicApiIpSubnet: {get_attr: [NetworkPorts, public_api_ip_subnet]} ClusterMgmtIpSubnet: {get_attr: [NetworkPorts, cluster_mgmt_ip_subnet]} StorageIpSubnet: {get_attr: [NetworkPorts, storage_ip_subnet]} ExternalIpSubnet: {get_attr: [NetworkPorts, external_ip_subnet]} internal_api_ip_address: description: IP address of the server in the internal_api network value: {get_attr: [NetworkPorts, internal_api_ip]} public_api_ip_address: description: IP address of the server in the public_api network value: {get_attr: [NetworkPorts, public_api_ip]} cluster_mgmt_ip_address: description: IP address of the server in the cluster_mgmt network value: {get_attr: [NetworkPorts, cluster_mgmt_ip]} storage_ip_address: description: IP address of the server in the storage network value: {get_attr: [NetworkPorts, storage_ip]} external_ip_address: description: IP address of the server in the external network value: {get_attr: [NetworkPorts, external_ip]}",,307,0
openstack%2Ftripleo-heat-templates~master~I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4,openstack/tripleo-heat-templates,master,I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4,Add isolated net parameters to net-config stacks,MERGED,2015-05-07 01:49:48.000000000,2015-05-26 18:08:59.000000000,2015-05-26 18:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c42c9ccb7d52728c53e5e19cde8038d806eab46a', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 2, 'created': '2015-05-09 12:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bda45698c2ef0890e6fc44012225647c4038a03e', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 3, 'created': '2015-05-12 19:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ac6e3cbee06a601f1bef46f3f6a3491f2f3bc476', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 4, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c545bb29b711fda2441a49a5a6916fe181e41328', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 5, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/72ba32d0c4c7324b7de9fe647457d799fba1ce54', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 6, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ef318aeca1e339b03285cc3bcc0f13ef91dd9f6e', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 7, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/409c96cb351f701f4cba4fb96ee31f4949dfcfcc', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 8, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b527149d11b59ce8aa3f845351f307190bc1d347', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}, {'number': 9, 'created': '2015-05-26 12:51:29.000000000', 'files': ['net-config-bond.yaml', 'net-config-noop.yaml', 'net-config-bridge.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7587446c6e1030bb85a019b13ef3a757b4d5fb79', 'message': 'Add isolated net parameters to net-config stacks\n\nThis patch adds parameters so that we can pass in the\nipaddress/subnet for each of the isolated overcloud\ntraffic nets to os-net-config templates. This\ninterface change will allow deployers to plug\nin a custom version of an os-net-config template\nthat drives isolated network configuration.\n\nChange-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4\n'}]",0,180820,7587446c6e1030bb85a019b13ef3a757b4d5fb79,40,5,9,360,,,0,"Add isolated net parameters to net-config stacks

This patch adds parameters so that we can pass in the
ipaddress/subnet for each of the isolated overcloud
traffic nets to os-net-config templates. This
interface change will allow deployers to plug
in a custom version of an os-net-config template
that drives isolated network configuration.

Change-Id: I35bbe9a0bd81e79f9bfd531fe89c700af8b354c4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/20/180820/2 && git format-patch -1 --stdout FETCH_HEAD,"['net-config-bond.yaml', 'net-config-noop.yaml', 'net-config-bridge.yaml']",3,c42c9ccb7d52728c53e5e19cde8038d806eab46a,networks,parameters: ExternalIpSubnet: description: IP address/subnet on the external network type: string InternalApiIpSubnet: description: IP address/subnet on the internal API network type: string StorageIpSubnet: description: IP address/subnet on the storage network type: string StorageMgmtIpSubnet: description: IP address/subnet on the storage mgmt network type: string TenantIpSubnet: description: IP address/subnet on the tenant network type: string ,,51,0
openstack%2Ftripleo-heat-templates~master~I5175ef48c1960ea0d13fc8518328db53921c70cd,openstack/tripleo-heat-templates,master,I5175ef48c1960ea0d13fc8518328db53921c70cd,Add a ports (ip address) abstraction layer,MERGED,2015-04-27 16:00:10.000000000,2015-05-26 18:08:49.000000000,2015-05-26 18:08:49.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-04-27 16:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7906d13e18f1625316324bc3267fdb254bafcd9d', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 2, 'created': '2015-04-27 16:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f8a25bb9cae5e3303d88980a591632a93c00fd66', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 3, 'created': '2015-04-28 18:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9cf2d4094a2aac1812a71f7e6bf88adbc66b6cc', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 6 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 4, 'created': '2015-04-29 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fef6e9c8bd56077f431fb7409a7777fbecd71ce8', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 6 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 5, 'created': '2015-04-29 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ddccb92f220f4f63db305e09848516da9da76ec', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 6 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 6, 'created': '2015-05-05 21:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a6065bf8d64a5ca44b7c8cb1b0759111006ed2e6', 'message': ""Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 6 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nThe 'ports' template can be used as a convenient way to\ncreate all ports at once. The 'ports' template also\nallows you to use noop to skip port creation and just\nuse the ip_address/subnet of the Control plane if\nyou wish (this is the TripleO default).\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n""}, {'number': 7, 'created': '2015-05-07 01:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/853b0e00e20513efa9b59b6e5e3077f514227a4b', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 8, 'created': '2015-05-14 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/de3922381dec7461476cebb5a691362a8a500f09', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 9, 'created': '2015-05-14 18:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e8d68de574a7041693705402398fc6830ad37fd', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 10, 'created': '2015-05-19 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/121b8a9314f7f82590d78bb907963e3a1839f6d3', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 11, 'created': '2015-05-20 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/19d8fd8d6ee0fb0e11524096a89bbb4c8fda1264', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 12, 'created': '2015-05-22 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8932d873dc1c3ac97390fe3c6a5ce8af5a39a298', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}, {'number': 13, 'created': '2015-05-26 12:51:28.000000000', 'files': ['network/ports/noop.yaml', 'network/ports/external.yaml', 'network/ports/storage.yaml', 'network/ports/tenant.yaml', 'network/ports/internal_api.yaml', 'network/ports/storage_mgmt.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c527d88e9d0ab11b2490713623b2f84f64d71a12', 'message': 'Add a ports (ip address) abstraction layer\n\nThis patch adds a set of templates to create ports on isolated\nnetworks via Heat. There are 5 port templates in total\nwhich are split out according to the available overcloud\nnetworks.\n\nChange-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd\n'}]",16,177845,c527d88e9d0ab11b2490713623b2f84f64d71a12,64,9,13,360,,,0,"Add a ports (ip address) abstraction layer

This patch adds a set of templates to create ports on isolated
networks via Heat. There are 5 port templates in total
which are split out according to the available overcloud
networks.

Change-Id: I5175ef48c1960ea0d13fc8518328db53921c70cd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/45/177845/4 && git format-patch -1 --stdout FETCH_HEAD,"['network/ports/noop.yaml', 'network/ports/external.yaml', 'network/ports/cluster_mgmt.yaml', 'network/ports/ports.yaml', 'network/ports/storage.yaml', 'network/ports/public_api.yaml', 'network/ports/internal_api.yaml']",7,7906d13e18f1625316324bc3267fdb254bafcd9d,networks,"heat_template_version: 2014-10-16 description: > Creates a port on the internal_api network. parameters: InternalApiNetworkName: description: Name of the internal API neutron network default: internal_api type: string ControlPlaneIP: # Here for compatability with no_port.yaml description: IP address on the control plane type: string resources: InternalApiPort: type: OS::Neutron::Port properties: network: {get_param: InternalApiNetworkName} replacement_policy: AUTO outputs: ip_address: description: internal network IP value: {get_attr: [InternalApiPort, fixed_ips, 0, ip_address]} ip_subnet: # FIXME: this assumes a 2 digit subnet CIDR (need more heat functions?) description: IP/Subnet CIDR for the internal network IP value: list_join: - '' - - {get_attr: [InternalApiPort, fixed_ips, 0, ip_address]} - '/' - {get_attr: [InternalApiPort, subnets, 0, cidr, -2]} - {get_attr: [InternalApiPort, subnets, 0, cidr, -1]} ",,276,0
openstack%2Ffuel-library~master~I3066bccec7b5ba8f3e9d377d61e716196210cdb7,openstack/fuel-library,master,I3066bccec7b5ba8f3e9d377d61e716196210cdb7,Change master postgres log directory to /var/log,MERGED,2015-05-25 15:58:28.000000000,2015-05-26 18:07:26.000000000,2015-05-26 18:06:52.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-25 15:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f0a2f498f247c398db0000fb7474a16c3cb6468', 'message': 'Change master postgres log directory to /var/log\n\nAs long as postgres has many options and main postgresql module\ncannot cover them all, write small new type that can optionally\nchange any postgresql option similar to existing OpenStack config\ntypes based on ini_setting\n\nChange-Id: I3066bccec7b5ba8f3e9d377d61e716196210cdb7\nCloses-Bug: #1458545\n'}, {'number': 2, 'created': '2015-05-26 08:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dd03e99f7111841a00df76d582e8b566bfabd190', 'message': 'Change master postgres log directory to /var/log\n\nAs long as postgres has many options and main postgresql module\ncannot cover them all, write small new type that can optionally\nchange any postgresql option similar to existing OpenStack config\ntypes based on ini_setting\n\nChange-Id: I3066bccec7b5ba8f3e9d377d61e716196210cdb7\nCloses-Bug: #1458545\n'}, {'number': 3, 'created': '2015-05-26 12:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f2cd5b3df95a47d41051ddb1c42c2fedf8b16f96', 'message': 'Change master postgres log directory to /var/log\n\nAs long as postgres has many options and main postgresql module\ncannot cover them all, write small new type that can optionally\nchange any postgresql option similar to existing OpenStack config\ntypes based on ini_setting\n\nChange-Id: I3066bccec7b5ba8f3e9d377d61e716196210cdb7\nCloses-Bug: #1458545\n'}, {'number': 4, 'created': '2015-05-26 15:02:18.000000000', 'files': ['deployment/puppet/nailgun/lib/puppet/provider/postgres_config/ini_setting.rb', 'deployment/puppet/nailgun/lib/puppet/type/postgres_config.rb', 'deployment/puppet/nailgun/examples/postgres-only.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e06e0f7503c9cebdc6b177d9a949d45f259ae718', 'message': 'Change master postgres log directory to /var/log\n\nAs long as postgres has many options and main postgresql module\ncannot cover them all, write small new type that can optionally\nchange any postgresql option similar to existing OpenStack config\ntypes based on ini_setting\n\nChange-Id: I3066bccec7b5ba8f3e9d377d61e716196210cdb7\nCloses-Bug: #1458545\n'}]",0,185416,e06e0f7503c9cebdc6b177d9a949d45f259ae718,80,10,4,11827,,,0,"Change master postgres log directory to /var/log

As long as postgres has many options and main postgresql module
cannot cover them all, write small new type that can optionally
change any postgresql option similar to existing OpenStack config
types based on ini_setting

Change-Id: I3066bccec7b5ba8f3e9d377d61e716196210cdb7
Closes-Bug: #1458545
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/16/185416/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/lib/puppet/provider/postgres_config/ini_setting.rb', 'deployment/puppet/nailgun/lib/puppet/type/postgres_config.rb', 'deployment/puppet/nailgun/examples/postgres-only.pp']",3,9f0a2f498f247c398db0000fb7474a16c3cb6468,postgres_config, Class['postgresql::server'] -> Postgres_config<||> Postgres_config { ensure => present } postgres_config { log_directory : value => '/var/log/'; log_filename : value => 'pgsql'; log_rotation_age : value => '1w'; } ,,50,0
openstack%2Fceilometer~master~Ieffa3fddc3c8d3152742455ca46d69bcc7208d69,openstack/ceilometer,master,Ieffa3fddc3c8d3152742455ca46d69bcc7208d69,Update a test to properly anticipate HTTP 405 for RestController,MERGED,2015-05-12 14:11:26.000000000,2015-05-26 18:05:57.000000000,2015-05-12 19:41:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2109}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 8005}, {'_account_id': 8470}, {'_account_id': 9562}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-12 14:11:26.000000000', 'files': ['ceilometer/tests/gabbi/gabbits/meters.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f59da0da65c0e5e32e959e9d654763e1ae35df87', 'message': 'Update a test to properly anticipate HTTP 405 for RestController\n\nThe behavior of RestController is changing (to be more correct):\nhttps://review.openstack.org/#/c/181979.  Until this change hits PyPI and\nglobal-requirements, ceilometer should accept both the old and new behavior as\nvalid.\n\nChange-Id: Ieffa3fddc3c8d3152742455ca46d69bcc7208d69\nCloses-bug: #1450109\n'}]",0,182306,f59da0da65c0e5e32e959e9d654763e1ae35df87,12,17,1,8005,,,0,"Update a test to properly anticipate HTTP 405 for RestController

The behavior of RestController is changing (to be more correct):
https://review.openstack.org/#/c/181979.  Until this change hits PyPI and
global-requirements, ceilometer should accept both the old and new behavior as
valid.

Change-Id: Ieffa3fddc3c8d3152742455ca46d69bcc7208d69
Closes-bug: #1450109
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/06/182306/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/gabbi/gabbits/meters.yaml'],1,f59da0da65c0e5e32e959e9d654763e1ae35df87,bug/1450109," status: ""404 || 405""", status: 404,1,1
openstack%2Fopenstack-manuals~master~Id5216dc23f07e51913feeaf34a0422c880b1f437,openstack/openstack-manuals,master,Id5216dc23f07e51913feeaf34a0422c880b1f437,"Added OpenStackClient commands in manage projects, users and roles section",MERGED,2015-05-08 05:39:07.000000000,2015-05-26 18:01:06.000000000,2015-05-26 18:01:04.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6486}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 7923}, {'_account_id': 9382}, {'_account_id': 10607}, {'_account_id': 10705}]","[{'number': 1, 'created': '2015-05-08 05:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/26d76b1e64385f24ed480bb79f8d9f2967315ded', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 2, 'created': '2015-05-08 06:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f5f3c03bd9e4a3ac883b1091432fa136a5fcd89e', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 3, 'created': '2015-05-11 00:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/38cc662a3bae43c76b9539f8669f926e988ebd57', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 4, 'created': '2015-05-11 07:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d7c949fc8f1bea29ee8200ac63f8b245663d14ce', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 5, 'created': '2015-05-15 01:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59b8aa6e14642b7e10d3ab58beaf17bd6b17868d', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 6, 'created': '2015-05-15 01:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/84f0cf9295f6aed50c48bc287ae9f4daf08ed647', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: 1446236\n'}, {'number': 7, 'created': '2015-05-18 02:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f941f5547d9ea0ad34a796b0a25e95c19b4bdfa5', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: #1446236\n'}, {'number': 8, 'created': '2015-05-18 04:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/25d253e53fe019d51d15d80a14bf53a31d6d87f5', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: #1446236\n'}, {'number': 9, 'created': '2015-05-22 17:57:09.000000000', 'files': ['doc/user-guide-admin/source/manage_projects_users_and_roles.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ee2e0afec5eed1b63b3ef421c41a5aa4db580f8', 'message': 'Added OpenStackClient commands in manage projects, users and roles section\n\nRemoved deprecated keystone CLI commands, and replaced with OpenStackClient commands\n\nChange-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437\nbackport: kilo\nCloses-Bug: #1446236\n'}]",47,181297,1ee2e0afec5eed1b63b3ef421c41a5aa4db580f8,37,10,9,10705,,,0,"Added OpenStackClient commands in manage projects, users and roles section

Removed deprecated keystone CLI commands, and replaced with OpenStackClient commands

Change-Id: Id5216dc23f07e51913feeaf34a0422c880b1f437
backport: kilo
Closes-Bug: #1446236
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/181297/9 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guides/source/adminuser/manage_projects_users_and_roles.rst'],1,26d76b1e64385f24ed480bb79f8d9f2967315ded,bug/1446236,"Before you can run keystone client commands, you must download and install the OpenStackClient and source the OpenStack RC file. For more information, see `Install the OpenStack command-line clients file <http://docs.openstack.org/cli-reference/content/install_clients.html>`__ and `Download and source the OpenStack RC``service create`` $ os service create \``service list`` $ os service list ``service show`` $ os service show 08741d8ed88242ca88d1f61484a0fe3b ``service delete`` $ os service delete 08741d8ed88242ca88d1f61484a0fe3b $ os project list $ os project create --name new-project --description 'my new project' $ os project set PROJECT_ID --disable $ os project set PROJECT_ID --enabled $ os project set PROJECT_ID --name project-new $ os project show PROJECT_ID $ os project delete PROJECT_ID $ os project list $ os user create --project 1a4a0618b306462c9830f876b0bd6af2 --password PASSWORD new-user $ os user set USER_ID --disable $ os user set USER_ID --enabled $ os user set USER_ID --name user-new --email new-user@example.com $ os user delete USER_ID $ os user list $ os role create new-role $ os user list Note the user ID to be assigned to the role. $ os role list Note the role ID to be assigned. $ os project list Note the project ID to be assigned to the role. #. Assign a role to a user-project pair. In this example, assign the $ os role add --user USER_ID --project TENANT_ID ROLE_ID $ os role list --user USER_ID --project TENANT_ID $ os role show ROLE_ID $ os role remove --user USER_ID --project TENANT_ID ROLE_ID $ os role list --user USER_ID --project TENANT_ID","Before you can run keystone client commands, you must download and source an OpenStack RC file. See `Download and source the OpenStack RC``service-create`` $ keystone service-create \``service-list`` $ keystone service-list ``service-get`` $ keystone service-get 08741d8ed88242ca88d1f61484a0fe3b ``service-delete`` $ keystone service-delete 08741d8ed88242ca88d1f61484a0fe3b $ keystone tenant-list $ keystone tenant-create --name new-project --description 'my new project' $ keystone tenant-update PROJECT_ID --enabled false $ keystone tenant-update PROJECT_ID --enabled true $ keystone tenant-update PROJECT_ID --name project-new $ keystone tenant-get PROJECT_ID $ keystone tenant-delete PROJECT_ID $ keystone user-list $ keystone user-create --name new-user --tenant_id 1a4a0618b306462c9830f876b0bd6af2 --pass PASSWORD $ keystone user-update USER_ID --enabled false $ keystone user-update USER_ID --enabled true $ keystone user-update USER_ID --name user-new --email new-user@example.com $ keystone user-delete USER_ID $ keystone role-list $ keystone role-create --name new-role $ keystone user-list Note the ID of the user to which you want to assign the role. $ keystone role-list Note the ID of the role that you want to assign. $ keystone tenant-list Note the ID of the project to which you want to assign the role. #. Assign a role to a user-project pair. In this example, you assign the $ keystone user-role-add --user USER_ID --role ROLE_ID --tenant TENANT_ID $ keystone user-role-list --user USER_ID --tenant TENANT_ID $ keystone role-get ROLE_ID $ keystone user-role-remove --user USER_ID --role ROLE_ID --tenant TENANT_ID $ keystone user-role-list --user USER_ID --tenant TENANT_ID",40,37
openstack%2Fdesignate~master~I90b8f499f23762cbc6333be764439104189238b8,openstack/designate,master,I90b8f499f23762cbc6333be764439104189238b8,Remove unnecessary RestController usage,MERGED,2015-05-12 12:54:10.000000000,2015-05-26 17:56:51.000000000,2015-05-12 14:14:24.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-05-12 12:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/846e0dfbae8a831ed3a810561611db187cc617bd', 'message': ""Remove unnecessary RestController usage.\n\nTasksControllers is just an intermediate path segment, and doesn't need to be\na RestController.  Additionally, this resolves a failing test associated with\na RestController bug fix in pecan [1].\n\n[1] https://review.openstack.org/#/c/181979/\nCloses-Bug: #1334690\n\nChange-Id: I90b8f499f23762cbc6333be764439104189238b8\n""}, {'number': 2, 'created': '2015-05-12 13:28:31.000000000', 'files': ['designate/api/v2/controllers/zones/tasks/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/35b6d607e130a8c2b5db3553e52cf71d93bded2c', 'message': ""Remove unnecessary RestController usage\n\nTasksControllers is just an intermediate path segment, and doesn't need to be\na RestController.  Additionally, this resolves a failing test associated with\na RestController bug fix in pecan [1].\n\n[1] https://review.openstack.org/#/c/181979/\nCloses-Bug: #1334690\n\nChange-Id: I90b8f499f23762cbc6333be764439104189238b8\n""}]",0,182273,35b6d607e130a8c2b5db3553e52cf71d93bded2c,10,5,2,8005,,,0,"Remove unnecessary RestController usage

TasksControllers is just an intermediate path segment, and doesn't need to be
a RestController.  Additionally, this resolves a failing test associated with
a RestController bug fix in pecan [1].

[1] https://review.openstack.org/#/c/181979/
Closes-Bug: #1334690

Change-Id: I90b8f499f23762cbc6333be764439104189238b8
",git fetch https://review.opendev.org/openstack/designate refs/changes/73/182273/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/v2/controllers/zones/tasks/__init__.py'],1,846e0dfbae8a831ed3a810561611db187cc617bd,bug/1334690,class TasksController(object):,from designate.api.v2.controllers import restclass TasksController(rest.RestController):,1,2
openstack%2Fhorizon~master~I87d4ff78b97950248442056ce3ce5af9177042ae,openstack/horizon,master,I87d4ff78b97950248442056ce3ce5af9177042ae,"ngReorg - Align constants, factories and services",MERGED,2015-05-19 22:19:25.000000000,2015-05-26 17:49:22.000000000,2015-05-26 17:49:20.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-05-19 22:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7e94a12f745889e3f236aefaff4d4bba54a75728', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 2, 'created': '2015-05-19 22:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8f681477d5516f39fd7e776bb5c346297e9d7ac1', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 3, 'created': '2015-05-20 00:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2c0abac33cb4c62e9bdb8fa0e7c6bae612f4c232', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 4, 'created': '2015-05-20 00:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/87b4abf018b3aa1e0b0e0f7f26378b080d280068', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 5, 'created': '2015-05-20 15:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f6ab681fefa41cda557877a30b5bb8278e7264af', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 6, 'created': '2015-05-21 17:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/52a3e41da2b5584207620357c2023e9f8ac8c4f8', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}, {'number': 7, 'created': '2015-05-21 21:14:58.000000000', 'files': ['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/widgets.scss', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/flavor/flavor.js', 'horizon/static/framework/widgets/charts/pie-chart.spec.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.js', 'horizon/static/horizon/js/angular/hz.api.module.js', 'horizon/static/framework/widgets/modal/modal.spec.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.scss', 'horizon/static/horizon/js/angular/services/hz.api.nova.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.model.js', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/util/workflow/workflow.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/modal/modal.js', 'horizon/static/horizon/tests/jasmine/utils.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-service.js', 'horizon/static/horizon/js/angular/services/hz.api.config.spec.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.js', 'horizon/static/horizon/js/angular/services/hz.api.cinder.js', 'horizon/templates/horizon/_conf.html', 'horizon/static/horizon/js/angular/services/hz.api.config.js', 'horizon/static/framework/widgets/charts/charts.js', 'horizon/static/horizon/js/angular/services/hz.api.common.spec.js', 'horizon/static/horizon/js/angular/services/hz.api.keystone.js', 'horizon/static/horizon/js/angular/services/hz.api.common.js', 'horizon/static/horizon/js/angular/services/hz.api.policy.js', 'horizon/static/framework/widgets/action-list/button-tooltip.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.spec.js', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/horizon/js/angular/services/hz.api.neutron.js', 'openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.spec.js', 'doc/source/contributing.rst', 'horizon/static/framework/util/workflow/workflow.spec.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.js', 'openstack_dashboard/static/dashboard/launch-instance/flavor/select-flavor-table.js', 'horizon/static/framework/widgets/charts/pie-chart.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.spec.js', 'horizon/static/horizon/js/angular/services/hz.api.security-group.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.js', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/horizon/js/angular/services/hz.api.glance.js', 'horizon/static/horizon/js/angular/horizon.conf.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/horizon/js/angular/services/horizon.utils.js', 'openstack_dashboard/static/dashboard/workflow/workflow.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/660d43badf578543e1177cbe522a45b57e5dc3a6', 'message': 'ngReorg - Align constants, factories and services\n\nThis commit makes injectable names consistent to include\nthe module as a prefix. This reduces confusiong about\nexactly which item is being injected.\n\nIt also simplifies the naming scheme for the Angular-based\nAPI modules.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I87d4ff78b97950248442056ce3ce5af9177042ae\nPartial-Bug: #1454880\n'}]",17,184345,660d43badf578543e1177cbe522a45b57e5dc3a6,29,7,7,14307,,,0,"ngReorg - Align constants, factories and services

This commit makes injectable names consistent to include
the module as a prefix. This reduces confusiong about
exactly which item is being injected.

It also simplifies the naming scheme for the Angular-based
API modules.

This is one step in a larger effort to restructure the Angular
source. See https://review.openstack.org/#/c/176152/ for the
full set of planned changes.

Change-Id: I87d4ff78b97950248442056ce3ce5af9177042ae
Partial-Bug: #1454880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/45/184345/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.spec.js', 'doc/source/contributing.rst', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/flavor/flavor.js', 'horizon/static/framework/util/workflow/workflow.spec.js', 'horizon/static/framework/widgets/charts/pie-chart.spec.js', 'horizon/static/horizon/js/angular/hz.api.module.js', 'horizon/static/framework/widgets/modal/modal.spec.js', 'horizon/static/horizon/js/angular/services/hz.api.nova.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.model.js', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/util/workflow/workflow.js', 'horizon/static/framework/widgets/toast/toast.js', 'openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.js', 'openstack_dashboard/static/dashboard/launch-instance/flavor/select-flavor-table.js', 'horizon/static/framework/widgets/modal/modal.js', 'horizon/static/framework/widgets/charts/pie-chart.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.spec.js', 'horizon/static/horizon/tests/jasmine/utils.spec.js', 'horizon/static/horizon/js/angular/services/hz.api.security-group.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-service.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.js', 'horizon/static/horizon/js/angular/services/hz.api.cinder.js', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/horizon/js/angular/services/hz.api.config.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/horizon/js/angular/services/hz.api.glance.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/horizon/js/angular/services/horizon.utils.js', 'openstack_dashboard/static/dashboard/workflow/workflow.js', 'horizon/static/framework/widgets/charts/charts.js', 'horizon/static/framework/widgets/modal/modal-wait-spinner.js', 'horizon/static/horizon/js/angular/services/hz.api.common.spec.js', 'horizon/static/horizon/js/angular/services/hz.api.keystone.js', 'horizon/static/horizon/js/angular/services/hz.api.common.js', 'horizon/static/horizon/js/angular/services/hz.api.policy.js', 'horizon/static/framework/widgets/action-list/button-tooltip.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/horizon/js/angular/services/hz.api.neutron.js']",45,7e94a12f745889e3f236aefaff4d4bba54a75728,bug/1454880," .service('hz.api.neutron', ['hz.api.common.service', 'horizon.framework.widgets.toast.service', NeutronAPI]);"," .service('neutronAPI', ['apiService', 'toastService', NeutronAPI]);",118,107
openstack%2Ffuel-library~master~Id2cec152c003785c35b627b035f75c9cf0b06233,openstack/fuel-library,master,Id2cec152c003785c35b627b035f75c9cf0b06233,Configure transmit packet steering,MERGED,2015-05-23 00:08:17.000000000,2015-05-26 17:45:39.000000000,2015-05-26 17:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 14168}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-23 00:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/684b7f1282062edd64214ef381177b356e7ca2fb', 'message': 'Configure transmit packet steering\n\nThis commit sets process affinity also for\ntransmit queues thus allowing user to\nbalance the load between CPUs\n\nChange-Id: Id2cec152c003785c35b627b035f75c9cf0b06233\nRelated-bug: #1456587\n'}, {'number': 2, 'created': '2015-05-25 13:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6ee78eb19be1967545a865f923117cbefda02a4d', 'message': 'Configure transmit packet steering\n\nThis commit sets process affinity also for\ntransmit queues thus allowing user to\nbalance the load between CPUs\n\nChange-Id: Id2cec152c003785c35b627b035f75c9cf0b06233\nRelated-bug: #1456587\n'}, {'number': 3, 'created': '2015-05-25 18:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c55da009e7054f42effdb11b5dc2b766373024e9', 'message': 'Configure transmit packet steering\n\nThis commit sets process affinity also for\ntransmit queues thus allowing user to\nbalance the load between CPUs\n\nChange-Id: Id2cec152c003785c35b627b035f75c9cf0b06233\nRelated-bug: #1456587\n'}, {'number': 4, 'created': '2015-05-26 12:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/308c70a8cac5a23ebe3b80bc320c94a7fbfa900a', 'message': 'Configure transmit packet steering\n\nThis commit sets process affinity also for\ntransmit queues thus allowing user to\nbalance the load between CPUs\n\nChange-Id: Id2cec152c003785c35b627b035f75c9cf0b06233\nRelated-bug: #1456587\n'}, {'number': 5, 'created': '2015-05-26 16:14:15.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/netconfig/netconfig.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f9d4504c0d02e67c75c4d91a6385ac028cf4552', 'message': 'Configure transmit packet steering\n\nThis commit sets process affinity also for\ntransmit queues thus allowing user to\nbalance the load between CPUs\n\nChange-Id: Id2cec152c003785c35b627b035f75c9cf0b06233\nRelated-bug: #1456587\n'}]",0,185194,9f9d4504c0d02e67c75c4d91a6385ac028cf4552,100,7,5,8786,,,0,"Configure transmit packet steering

This commit sets process affinity also for
transmit queues thus allowing user to
balance the load between CPUs

Change-Id: Id2cec152c003785c35b627b035f75c9cf0b06233
Related-bug: #1456587
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/94/185194/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/netconfig/netconfig.pp'],1,684b7f1282062edd64214ef381177b356e7ca2fb,bug/1456587," sysfs_config_value { 'xps_cpus' : ensure => 'present', name => ""/etc/sysfs.d/xps_cpus.conf"", value => cpu_affinity_hex($::processorcount), sysfs => '/sys/class/net/*/queues/tx-*/xps_cpus', exclude => '/sys/class/net/lo/*', }",,8,0
openstack%2Ffuel-library~master~I6dd5f62df103f6839b802aaf1b7643b6ba440caa,openstack/fuel-library,master,I6dd5f62df103f6839b802aaf1b7643b6ba440caa,Add sleeps for Ubuntu bridges,MERGED,2015-05-26 12:35:21.000000000,2015-05-26 17:45:03.000000000,2015-05-26 17:44:25.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-26 12:35:21.000000000', 'files': ['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/941f3b9b5b64d8f75c0e3a5b4baa0db7876b9ea1', 'message': 'Add sleeps for Ubuntu bridges\n\nAdd 32 seconds sleep for Ubuntu bridges\nor connectivity tests will fail as\nbridge is not yet brought up\n\nChange-Id: I6dd5f62df103f6839b802aaf1b7643b6ba440caa\nCloses-bug: #1458625\n'}]",4,185574,941f3b9b5b64d8f75c0e3a5b4baa0db7876b9ea1,30,7,1,8786,,,0,"Add sleeps for Ubuntu bridges

Add 32 seconds sleep for Ubuntu bridges
or connectivity tests will fail as
bridge is not yet brought up

Change-Id: I6dd5f62df103f6839b802aaf1b7643b6ba440caa
Closes-bug: #1458625
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/74/185574/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb'],1,941f3b9b5b64d8f75c0e3a5b4baa0db7876b9ea1,bug1458625, #Add sleep before checking for repos #as Ubuntu waits 32 seconds for the #bridge to become ready sleep 32,,4,0
openstack%2Fhorizon~master~I8bca8566db286f70c1def86c5f8fbb6232f6e8bf,openstack/horizon,master,I8bca8566db286f70c1def86c5f8fbb6232f6e8bf,Subnet creation page should indicate required fields,ABANDONED,2015-05-22 18:52:56.000000000,2015-05-26 17:35:31.000000000,,"[{'_account_id': 3}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-05-22 18:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/80835af3af6e8fbd5111a1b20aeb68ca06d3f848', 'message': 'The subnet creation pages should indicate reqiured fields\n\nSteps to reproduce:\n\n1. On the network panel, create a network.\n2. Create a subnet.\n3. In the Subnet modal form, create a subnet without filling out either the subnet name or the allocation pool.\n4. Click create.\n5. Horizon will returns error.\n\nChange-Id: I8bca8566db286f70c1def86c5f8fbb6232f6e8bf\nCloses-bug: 1458021\n'}, {'number': 2, 'created': '2015-05-22 18:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/803981d64084472ad45afd72227e08e6c6ff3514', 'message': 'Subnet creation page should indicate required fields\n\nSteps to reproduce:\n\n1. On the network panel, create a network.\n2. Create a subnet.\n3. In the subnet modal form, create a subnet without filling out either the subnet name or the allocation pool.\n4. Click create.\n5. Horizon returns error.\n\nChange-Id: I8bca8566db286f70c1def86c5f8fbb6232f6e8bf\nCloses-bug: 1458021\n'}, {'number': 3, 'created': '2015-05-22 23:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f08cdfce7c4f62ce989d391b2d08919e7403f5c', 'message': ""Subnet creation page should indicate reqiured fields\n\nSteps to reproduce:\n\n1. On the network panel, create a network.\n2. Create a subnet.\n3. In the Subnet modal form, since the first page doesn't have any require field indication, try to click next\n4. User can't go to the Subnet detail page\n\nThe intend of not allowing user to go to the Subnet Detail page is because user hasn't filled out the Network field. Therefore, it is better to mark that as required.\n\nChange-Id: I8bca8566db286f70c1def86c5f8fbb6232f6e8bf\nCloses-bug: 1458021\n""}, {'number': 4, 'created': '2015-05-22 23:56:26.000000000', 'files': ['openstack_dashboard/dashboards/project/networks/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/90df4f87cfb94ff58078192fec1adb95b2e153d1', 'message': ""Subnet creation page should indicate required fields\n\nSteps to reproduce:\n\n1. On the network panel, create a network.\n2. Create a subnet.\n3. In the Subnet modal form, since the first page doesn't have any require field indication, try to click next\n4. User can't go to the Subnet detail page\n\nThe intend of not allowing user to go to the Subnet Detail page is because user hasn't filled out the Network field. Therefore, it is better to mark that as required.\n\nChange-Id: I8bca8566db286f70c1def86c5f8fbb6232f6e8bf\nCloses-bug: 1458021\n""}]",1,185114,90df4f87cfb94ff58078192fec1adb95b2e153d1,10,3,4,14064,,,0,"Subnet creation page should indicate required fields

Steps to reproduce:

1. On the network panel, create a network.
2. Create a subnet.
3. In the Subnet modal form, since the first page doesn't have any require field indication, try to click next
4. User can't go to the Subnet detail page

The intend of not allowing user to go to the Subnet Detail page is because user hasn't filled out the Network field. Therefore, it is better to mark that as required.

Change-Id: I8bca8566db286f70c1def86c5f8fbb6232f6e8bf
Closes-bug: 1458021
",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/185114/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/networks/workflows.py'],1,80835af3af6e8fbd5111a1b20aeb68ca06d3f848,bug/1458021," required=True) required=True, required=True)"," required=False) required=False, required=False)",3,3
openstack%2Fheat-translator~master~I01abcbef6025a3abf838499e9041180a5fc3789f,openstack/heat-translator,master,I01abcbef6025a3abf838499e9041180a5fc3789f,TOSCA: fix Python34 UnicodeDecodeError,MERGED,2015-05-26 15:33:28.000000000,2015-05-26 17:34:14.000000000,2015-05-26 17:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2015-05-26 15:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/af53f8f51dedd7fe8ba5539eb6d240f08a24288a', 'message': 'TOSCA: fix Python34 UnicodeDecodeError\n\nJust recently Jenkins is failing with UnicodeDecodeError while reading the\ntemplate file.\n\nChange-Id: I01abcbef6025a3abf838499e9041180a5fc3789f\n'}, {'number': 2, 'created': '2015-05-26 17:25:26.000000000', 'files': ['translator/toscalib/utils/yamlparser.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3516ab4fda53a266f9f855782146f027360cef11', 'message': 'TOSCA: fix Python34 UnicodeDecodeError\n\nJust recently Jenkins is failing with UnicodeDecodeError while reading the\ntemplate file.\n\nChange-Id: I01abcbef6025a3abf838499e9041180a5fc3789f\n'}]",0,185645,3516ab4fda53a266f9f855782146f027360cef11,9,2,2,6456,,,0,"TOSCA: fix Python34 UnicodeDecodeError

Just recently Jenkins is failing with UnicodeDecodeError while reading the
template file.

Change-Id: I01abcbef6025a3abf838499e9041180a5fc3789f
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/45/185645/1 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/utils/yamlparser.py'],1,af53f8f51dedd7fe8ba5539eb6d240f08a24288a,,"import sys return yaml.load(f.read().decode('utf-8'), Loader=yaml_loader)"," return yaml.load(f.read(), Loader=yaml_loader)",2,1
openstack%2Fdevstack-gate~master~Icbaf1e0dfc7650e8a6c64ebde137ad0d7d935218,openstack/devstack-gate,master,Icbaf1e0dfc7650e8a6c64ebde137ad0d7d935218,[WIP] Add setting to d-g for Linux Bridge testing,ABANDONED,2015-05-21 17:23:43.000000000,2015-05-26 17:17:24.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-05-21 17:23:43.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/705f77c348b921711e9d4cffd493ad04631c1303', 'message': '[WIP] Add setting to d-g for Linux Bridge testing\n\nChange-Id: Icbaf1e0dfc7650e8a6c64ebde137ad0d7d935218\nDepends-On: Iccba951301d2c09e01b6c1a15ed1e88c8e0db69e\n'}]",0,184832,705f77c348b921711e9d4cffd493ad04631c1303,4,2,1,4656,,,0,"[WIP] Add setting to d-g for Linux Bridge testing

Change-Id: Icbaf1e0dfc7650e8a6c64ebde137ad0d7d935218
Depends-On: Iccba951301d2c09e01b6c1a15ed1e88c8e0db69e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/32/184832/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh']",2,705f77c348b921711e9d4cffd493ad04631c1303,linuxbridge_job,# Set to 1 to run neutron with the linux bridge mechanism driver export DEVSTACK_GATE_NEUTRON_LB=${DEVSTACK_GATE_NEUTRON_LB:-0} ,,8,0
openstack%2Fpython-glanceclient~master~I16555e456dcb2c9719de6c44c01ab68e82ad0590,openstack/python-glanceclient,master,I16555e456dcb2c9719de6c44c01ab68e82ad0590,Fixed doc example,MERGED,2014-10-22 08:02:56.000000000,2015-05-26 17:16:59.000000000,2015-05-26 17:16:57.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 8127}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12000}, {'_account_id': 12561}, {'_account_id': 12807}, {'_account_id': 12814}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-10-22 08:02:56.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f931a20d25cf34a2b425088449d0ab5b1613f790', 'message': 'Fixed doc example\n\nImage.data is a method, not an attribute.\n\nDocImpact\n\nChange-Id: I16555e456dcb2c9719de6c44c01ab68e82ad0590\n'}]",0,130154,f931a20d25cf34a2b425088449d0ab5b1613f790,15,10,1,12084,,,0,"Fixed doc example

Image.data is a method, not an attribute.

DocImpact

Change-Id: I16555e456dcb2c9719de6c44c01ab68e82ad0590
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/54/130154/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,f931a20d25cf34a2b425088449d0ab5b1613f790,doc-fix, for chunk in image.data():, for chunk in image.data:,1,1
openstack%2Fneutron-vpnaas~master~I35cb80411dcd5a7ed7c1fa09912036021d287046,openstack/neutron-vpnaas,master,I35cb80411dcd5a7ed7c1fa09912036021d287046,gate-neutron-vpnaas-pep8 failing for test_cisco_ipsec.py,MERGED,2015-05-23 07:11:08.000000000,2015-05-26 17:16:53.000000000,2015-05-26 17:16:50.000000000,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 10267}, {'_account_id': 10980}, {'_account_id': 14216}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-05-23 07:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/9aaa8b3f49aa3733959c472ecebeb5e5ce5ac504', 'message': 'gate-neutron-vpnaas-pep8 failing for test_cisco_ipsec.py\n\nNew hacking check ""check_python3_xrange"" added for xrange,\nwhich is breaking tests in test_cisco_ipsec.py module.\n\nxrange was replaced with six.moves.range only at the places\nreported by flake8 as error\n\nChange-Id: I35cb80411dcd5a7ed7c1fa09912036021d287046\n'}, {'number': 2, 'created': '2015-05-23 07:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/9d00fc815e9692034fff87fae5da2e06c0138fea', 'message': 'gate-neutron-vpnaas-pep8 failing for test_cisco_ipsec.py\n\nNew hacking check ""check_python3_xrange"" added for xrange,\nwhich is breaking tests in test_cisco_ipsec.py module.\n\nxrange was replaced with six.moves.range only at the places\nreported by flake8 as error\n\nChange-Id: I35cb80411dcd5a7ed7c1fa09912036021d287046\nCloses-bug: #1457796\n'}, {'number': 3, 'created': '2015-05-26 11:29:22.000000000', 'files': ['neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/10a3686ab3f939eec63f72f94a854a9a484baaf0', 'message': 'gate-neutron-vpnaas-pep8 failing for test_cisco_ipsec.py\n\nNew hacking check ""check_python3_xrange"" added for xrange,\nwhich is breaking tests in test_cisco_ipsec.py module.\n\nxrange was replaced with six.moves.range only at the places\nreported by flake8 as error\n\nChange-Id: I35cb80411dcd5a7ed7c1fa09912036021d287046\nCloses-bug: #1457796\n'}]",2,185220,10a3686ab3f939eec63f72f94a854a9a484baaf0,17,9,3,10267,,,0,"gate-neutron-vpnaas-pep8 failing for test_cisco_ipsec.py

New hacking check ""check_python3_xrange"" added for xrange,
which is breaking tests in test_cisco_ipsec.py module.

xrange was replaced with six.moves.range only at the places
reported by flake8 as error

Change-Id: I35cb80411dcd5a7ed7c1fa09912036021d287046
Closes-bug: #1457796
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/20/185220/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py'],1,9aaa8b3f49aa3733959c472ecebeb5e5ce5ac504,,"from six.moves import range (x, ) for x in range(csr_db.MAX_CSR_TUNNELS - 1)] (x, ) for x in range(1, csr_db.MAX_CSR_IKE_POLICIES)] (x, ) for x in range(1, csr_db.MAX_CSR_IPSEC_POLICIES)] (x, ) for x in range(csr_db.MAX_CSR_TUNNELS)] (x, ) for x in range(1, csr_db.MAX_CSR_IKE_POLICIES + 1)] (x, ) for x in range(1, csr_db.MAX_CSR_IPSEC_POLICIES + 1)]"," (x, ) for x in xrange(csr_db.MAX_CSR_TUNNELS - 1)] (x, ) for x in xrange(1, csr_db.MAX_CSR_IKE_POLICIES)] (x, ) for x in xrange(1, csr_db.MAX_CSR_IPSEC_POLICIES)] (x, ) for x in xrange(csr_db.MAX_CSR_TUNNELS)] (x, ) for x in xrange(1, csr_db.MAX_CSR_IKE_POLICIES + 1)] (x, ) for x in xrange(1, csr_db.MAX_CSR_IPSEC_POLICIES + 1)]",8,6
openstack%2Fec2-api~master~Idacf0022953cd267c1d48229e9ead673e6eb3d83,openstack/ec2-api,master,Idacf0022953cd267c1d48229e9ead673e6eb3d83,vpn (temporary),ABANDONED,2015-05-26 10:19:54.000000000,2015-05-26 17:15:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-26 10:19:54.000000000', 'files': ['ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/route_table.py', 'ec2api/api/vpn_connection.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/509340858015f904a53d4c56061a40ff0df2ad54', 'message': 'vpn (temporary)\n\nChange-Id: Idacf0022953cd267c1d48229e9ead673e6eb3d83\n'}]",0,185554,509340858015f904a53d4c56061a40ff0df2ad54,3,1,1,10224,,,0,"vpn (temporary)

Change-Id: Idacf0022953cd267c1d48229e9ead673e6eb3d83
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/54/185554/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/route_table.py', 'ec2api/api/vpn_connection.py']",4,509340858015f904a53d4c56061a40ff0df2ad54,vpn," FILTER_MAP = {'customer-gateway-configuration': ( 'customerGatewayConfiguration'), 'customer-gateway-id': 'customerGatewayId', # bgpAsn 'options': {'staticRoutesOnly': True}, 'customerGatewayConfiguration': ''}"," FILTER_MAP = {'customer-gateway-id': 'customerGatewayId', 'options': {'staticRoutesOnly': True}}",346,12
openstack%2Fswift~master~Id71d2eb3fb8fa15c016ef151aacf95f97196a902,openstack/swift,master,Id71d2eb3fb8fa15c016ef151aacf95f97196a902,Cleanup and extend end to end ssync tests,MERGED,2015-05-01 13:30:48.000000000,2015-05-26 17:12:00.000000000,2015-05-26 17:11:58.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 5600}, {'_account_id': 7847}, {'_account_id': 14619}, {'_account_id': 14967}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-01 13:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0df4090b69b81b9651b74a9bac7e7f2df2fc0310', 'message': 'Cleanup and extend end to end ssync tests\n\nExtends the existing end to end ssync tests with\na test using replication policy.\n\nAlso some cleanup and improvements to the test framework.\n\nChange-Id: Id71d2eb3fb8fa15c016ef151aacf95f97196a902\n'}, {'number': 2, 'created': '2015-05-05 10:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/77cc3a553e1784c94f5593b682b49d4936c22afb', 'message': 'Cleanup and extend end to end ssync tests\n\nExtends the existing end to end ssync tests with\na test using replication policy.\n\nAlso some cleanup and improvements to the test framework e.g. rather\nthan faking the connection between sender and receiver, use a real\nconnection and wrap it to capture traffic for verification.\n\nChange-Id: Id71d2eb3fb8fa15c016ef151aacf95f97196a902\n'}, {'number': 3, 'created': '2015-05-12 14:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3c6d5c3597698d275812a510035a1403a41f6247', 'message': 'Cleanup and extend end to end ssync tests\n\nExtends the existing end to end ssync tests with\na test using replication policy.\n\nAlso some cleanup and improvements to the test framework e.g. rather\nthan faking the connection between sender and receiver, use a real\nconnection and wrap it to capture traffic for verification.\n\nChange-Id: Id71d2eb3fb8fa15c016ef151aacf95f97196a902\n'}, {'number': 4, 'created': '2015-05-13 10:05:42.000000000', 'files': ['test/unit/obj/test_ssync_sender.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/98b725fec639c5501c645ce4e4dc9d12c686f91d', 'message': 'Cleanup and extend end to end ssync tests\n\nExtends the existing end to end ssync tests with\na test using replication policy.\n\nAlso some cleanup and improvements to the test framework e.g. rather\nthan faking the connection between sender and receiver, use a real\nconnection and wrap it to capture traffic for verification.\n\nChange-Id: Id71d2eb3fb8fa15c016ef151aacf95f97196a902\n'}]",14,179379,98b725fec639c5501c645ce4e4dc9d12c686f91d,32,9,4,7847,,,0,"Cleanup and extend end to end ssync tests

Extends the existing end to end ssync tests with
a test using replication policy.

Also some cleanup and improvements to the test framework e.g. rather
than faking the connection between sender and receiver, use a real
connection and wrap it to capture traffic for verification.

Change-Id: Id71d2eb3fb8fa15c016ef151aacf95f97196a902
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/179379/3 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_ssync_sender.py'],1,0df4090b69b81b9651b74a9bac7e7f2df2fc0310,p-ssync-sender-tests,"from swift.common.storage_policy import POLICIES, EC_POLICYfrom swift.common.utils import Timestamp from swift.obj import ssync_sender, diskfile, serverclass TestBaseSsync(BaseTestSender): Provides a framework to test end to end interactions between sender and receiver. The basis for each test is actual diskfile state on either side. The connection between sender and receiver is wrapped to capture ssync traffic for subsequent verification of the protocol. Assertions are made about the final state of the sender and receiver diskfiles. def make_connect_wrapper(self, sender, trace): """""" Make a wrapper function for the ssync_sender.Sender.connect() method that will in turn wrap the HTTConnection.send() and the Sender.readline() so that ssync protocol messages can be captured. """""" orig_connect = sender.connect trace.setdefault('messages', []).append((type, msg.strip())) def make_send_wrapper(send): def wrapped_send(msg): _msg = msg.split('\r\n', 1)[1] _msg = _msg.rsplit('\r\n', 1)[0] add_trace('tx', _msg) send(msg) return wrapped_send def make_readline_wrapper(readline): def wrapped_readline(): data = readline() add_trace('rx', data) bytes_read = trace.setdefault('readline_bytes', 0) trace['readline_bytes'] = bytes_read + len(data) return data return wrapped_readline def wrapped_connect(): orig_connect() sender.connection.send = make_send_wrapper( sender.connection.send) sender.readline = make_readline_wrapper(sender.readline) return wrapped_connect self.rx_ip = '127.0.0.1' sock = eventlet.listen((self.rx_ip, 0)) self.rx_server = eventlet.spawn( eventlet.wsgi.server, sock, self.rx_controller, utils.NullLogger()) self.rx_port = sock.getsockname()[1] self.rx_node = {'replication_ip': self.rx_ip, 'replication_port': self.rx_port, 'device': self.device} self.rx_server.kill() frag_indexes = [None] if frag_indexes is None else frag_indexes lines = list(trace.get('messages', [])) frag_index = None if policy.policy_type == EC_POLICY: frag_index = tx_df._frag_index if frag_index in (rx_node_index, None): # this diskfile should have been sync'd, expected_body = '/a/c/%s___%s' % (o_name, frag_index) # this diskfile should not have been sync'd, @patch_policies(with_ec_default=True) class TestSsyncEC(TestBaseSsync): # to the receiver 'frag_index': frag_index} node = dict(self.rx_node) node.update({'index': rx_node_index}) sender = ssync_sender.Sender(self.daemon, node, job, suffixes) # wrap connection from tx to rx to capture ssync messages... trace = {} sender.connect = self.make_connect_wrapper(sender, trace) sender() results = self._analyze_trace(trace) node = dict(self.rx_node) node.update({'index': rx_node_index}) sender = ssync_sender.Sender(self.daemon, node, job, suffixes) # wrap connection from tx to rx to capture ssync messages... trace = {} sender.connect = self.make_connect_wrapper(sender, trace) sender() results = self._analyze_trace(trace)@patch_policies class TestSsyncReplication(TestBaseSsync): def test_sync(self): policy = POLICIES.default rx_node_index = 0 # create sender side diskfiles... tx_objs = {} rx_objs = {} tx_tombstones = {} rx_tombstones = {} tx_df_mgr = self.daemon._diskfile_router[policy] rx_df_mgr = self.rx_controller._diskfile_router[policy] # o1 and o2 are on tx only t1 = self.ts_iter.next() tx_objs['o1'] = self._create_ondisk_files(tx_df_mgr, 'o1', policy, t1) t2 = self.ts_iter.next() tx_objs['o2'] = self._create_ondisk_files(tx_df_mgr, 'o2', policy, t2) # o3 is on tx and older copy on rx t3a = self.ts_iter.next() rx_objs['o3'] = self._create_ondisk_files(tx_df_mgr, 'o3', policy, t3a) t3b = self.ts_iter.next() tx_objs['o3'] = self._create_ondisk_files(tx_df_mgr, 'o3', policy, t3b) # o4 in sync on rx and tx t4 = self.ts_iter.next() tx_objs['o4'] = self._create_ondisk_files(tx_df_mgr, 'o4', policy, t4) rx_objs['o4'] = self._create_ondisk_files(rx_df_mgr, 'o4', policy, t4) # o5 is a tombstone, missing on receiver t5 = self.ts_iter.next() tx_tombstones['o5'] = self._create_ondisk_files( tx_df_mgr, 'o5', policy, t5) tx_tombstones['o5'][0].delete(t5) # o6 is a tombstone, in sync on tx and rx t6 = self.ts_iter.next() tx_tombstones['o6'] = self._create_ondisk_files( tx_df_mgr, 'o6', policy, t6) tx_tombstones['o6'][0].delete(t6) rx_tombstones['o6'] = self._create_ondisk_files( rx_df_mgr, 'o6', policy, t6) rx_tombstones['o6'][0].delete(t6) # o7 is a tombstone on tx, older data on rx t7a = self.ts_iter.next() rx_objs['o7'] = self._create_ondisk_files(rx_df_mgr, 'o7', policy, t7a) t7b = self.ts_iter.next() tx_tombstones['o7'] = self._create_ondisk_files( tx_df_mgr, 'o7', policy, t7b) tx_tombstones['o7'][0].delete(t7b) suffixes = set() for diskfiles in (tx_objs.values() + tx_tombstones.values()): for df in diskfiles: suffixes.add(os.path.basename(os.path.dirname(df._datadir))) # create ssync sender instance... job = {'device': self.device, 'partition': self.partition, 'policy': policy} node = dict(self.rx_node) node.update({'index': rx_node_index}) sender = ssync_sender.Sender(self.daemon, node, job, suffixes) # fake connection from tx to rx... trace = {} sender.connect = self.make_connect_wrapper(sender, trace) # run the sync protocol... success, in_sync_objs = sender() self.assertEqual(7, len(in_sync_objs)) self.assertTrue(success) # verify protocol results = self._analyze_trace(trace) self.assertEqual(7, len(results['tx_missing'])) self.assertEqual(5, len(results['rx_missing'])) self.assertEqual(5, len(results['tx_updates'])) self.assertFalse(results['rx_updates']) sync_paths = [] for subreq in results.get('tx_updates'): if subreq.get('method') == 'PUT': self.assertTrue( subreq['path'] in ('/a/c/o1', '/a/c/o2', '/a/c/o3')) expected_body = '%s___None' % subreq['path'] self.assertEqual(expected_body, subreq['body']) elif subreq.get('method') == 'DELETE': self.assertTrue(subreq['path'] in ('/a/c/o5', '/a/c/o7')) sync_paths.append(subreq.get('path')) self.assertEqual( ['/a/c/o1', '/a/c/o2', '/a/c/o3', '/a/c/o5', '/a/c/o7'], sorted(sync_paths)) # verify on disk files... self._verify_ondisk_files(tx_objs, policy, rx_node_index) self._verify_tombstones(tx_tombstones, policy) def test_nothing_to_sync(self): job = {'device': self.device, 'partition': self.partition, 'policy': POLICIES.default} node = {'replication_ip': self.rx_ip, 'replication_port': self.rx_port, 'device': self.device, 'index': 0} sender = ssync_sender.Sender(self.daemon, node, job, ['abc']) # wrap connection from tx to rx to capture ssync messages... trace = {} sender.connect = self.make_connect_wrapper(sender, trace) result, in_sync_objs = sender() self.assertTrue(result) self.assertFalse(in_sync_objs) results = self._analyze_trace(trace) self.assertFalse(results['tx_missing']) self.assertFalse(results['rx_missing']) self.assertFalse(results['tx_updates']) self.assertFalse(results['rx_updates']) # Minimal receiver response as read by sender: # 2 * 4098 <-- _ensure_flush() twice # + 23 <-- :MISSING CHECK START\r\n # + 2 <-- \r\n (minimal missing check response) # + 21 <-- :MISSING CHECK END\r\n # + 17 <-- :UPDATES START\r\n # + 15 <-- :UPDATES END\r\n # TOTAL = 8274 self.assertEqual(8274, trace.get('readline_bytes')) ","from swift.common.storage_policy import POLICIESfrom swift.common.swob import Request from swift.common.utils import Timestamp, FileLikeIter from swift.obj import ssync_sender, diskfile, server, ssync_receiver@patch_policies(with_ec_default=True) class TestSsync(BaseTestSender): Test interactions between sender and receiver. The basis for each test is actual diskfile state on either side - the connection between sender and receiver is faked. Assertions are made about the final state of the sender and receiver diskfiles. def make_fake_ssync_connect(self, sender, rx_obj_controller, device, partition, policy): trace = [] trace.append((type, msg.strip())) def start_response(status, headers, exc_info=None): assert(status == '200 OK') class FakeConnection: def __init__(self, trace): self.trace = trace self.queue = [] self.src = FileLikeIter(self.queue) def send(self, msg): msg = msg.split('\r\n', 1)[1] msg = msg.rsplit('\r\n', 1)[0] add_trace('tx', msg) self.queue.append(msg) def close(self): pass def wrap_gen(gen): # Strip response head and tail while True: try: msg = gen.next() if msg: add_trace('rx', msg) msg = '%x\r\n%s\r\n' % (len(msg), msg) yield msg except StopIteration: break def fake_connect(): sender.connection = FakeConnection(trace) headers = {'Transfer-Encoding': 'chunked', 'X-Backend-Storage-Policy-Index': str(int(policy))} env = {'REQUEST_METHOD': 'SSYNC'} path = '/%s/%s' % (device, partition) req = Request.blank(path, environ=env, headers=headers) req.environ['wsgi.input'] = sender.connection.src resp = rx_obj_controller(req.environ, start_response) wrapped_gen = wrap_gen(resp) sender.response = FileLikeIter(wrapped_gen) sender.response.fp = sender.response return fake_connect self.orig_ensure_flush = ssync_receiver.Receiver._ensure_flush ssync_receiver.Receiver._ensure_flush = lambda *args: '' if self.orig_ensure_flush: ssync_receiver.Receiver._ensure_flush = self.orig_ensure_flush frag_indexes = [] if frag_indexes is None else frag_indexes lines = list(trace) frag_index = tx_df._frag_index if frag_index == rx_node_index: # this frag_index should have been sync'd, expected_body = '/a/c/%s___%s' % (o_name, rx_node_index) # this frag_index should not have been sync'd, # to the receiver, and that those frag archives are then removed from # local node. 'frag_index': frag_index, 'purge': True} node = {'index': rx_node_index} self.sender = ssync_sender.Sender(self.daemon, node, job, suffixes) # fake connection from tx to rx... self.sender.connect = self.make_fake_ssync_connect( self.sender, self.rx_controller, self.device, self.partition, policy) self.sender() results = self._analyze_trace(self.sender.connection.trace) node = {'index': rx_node_index} self.sender = ssync_sender.Sender(self.daemon, node, job, suffixes) # fake connection from tx to rx... self.sender.connect = self.make_fake_ssync_connect( self.sender, self.rx_controller, self.device, self.partition, policy) self.sender() results = self._analyze_trace(self.sender.connection.trace)",204,87
openstack%2Fpython-designateclient~master~I2e3886a66ae57e810db1b5b4cb197bc7b8c157ed,openstack/python-designateclient,master,I2e3886a66ae57e810db1b5b4cb197bc7b8c157ed,Log a more informative error upon EndpointNotFound,MERGED,2015-05-21 10:02:54.000000000,2015-05-26 17:09:19.000000000,2015-05-26 17:09:17.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 4894}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-21 10:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/aef5827d889ed556b890c679852ea473de07f5cf', 'message': 'Log a more informative error upon EndpointNotFound\n\nChange-Id: I2e3886a66ae57e810db1b5b4cb197bc7b8c157ed\n'}, {'number': 2, 'created': '2015-05-21 12:59:09.000000000', 'files': ['designateclient/cli/base.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/a6577e297f06b7ef70ac318089d5cd19f2d09fdf', 'message': 'Log a more informative error upon EndpointNotFound\n\nChange-Id: I2e3886a66ae57e810db1b5b4cb197bc7b8c157ed\n'}]",0,184754,a6577e297f06b7ef70ac318089d5cd19f2d09fdf,13,7,2,395,,,0,"Log a more informative error upon EndpointNotFound

Change-Id: I2e3886a66ae57e810db1b5b4cb197bc7b8c157ed
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/54/184754/1 && git format-patch -1 --stdout FETCH_HEAD,['designateclient/cli/base.py'],1,aef5827d889ed556b890c679852ea473de07f5cf,184754," from keystoneclient import exceptions as ks_exceptions except ks_exceptions.EndpointNotFound: self.app.log.error(""No endpoint was found. Missing credentials?"")",,4,0
openstack%2Foslo.messaging~master~I7eb19346d72cb0a4813c964df1435d7f4c79e218,openstack/oslo.messaging,master,I7eb19346d72cb0a4813c964df1435d7f4c79e218,rabbit: smart timeout on missing exchange,MERGED,2015-05-07 08:14:56.000000000,2015-05-26 17:04:32.000000000,2015-05-26 17:04:29.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-07 08:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e9db2944c0f4ac8edc14cccdef456ef66f7e56a5', 'message': 'rabbit: smart timeout on missing exchange\n\nWhen we send a reply and the exchange is missing, they\nno need to wait more that the timeout set by the application.\n\nChange-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218\n'}, {'number': 2, 'created': '2015-05-11 06:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6e5d9a9160d7ef33fce80c2184fecb7a7c9a7f3d', 'message': 'rabbit: smart timeout on missing exchange\n\nWhen we send a reply and the exchange is missing, they\nno need to wait more that the timeout set by the application.\n\nChange-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218\n'}, {'number': 3, 'created': '2015-05-12 08:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f9b49f56f9731495498f878d685656572a0a9564', 'message': 'rabbit: smart timeout on missing exchange\n\nWhen we send a reply and the exchange is missing, they\nno need to wait more that the timeout set by the application.\n\nChange-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218\n'}, {'number': 4, 'created': '2015-05-26 09:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/10df62bf8607cf8669ddb33e53c859d0760989a0', 'message': 'rabbit: smart timeout on missing exchange\n\nWhen we send a reply and the exchange is missing, they\nno need to wait more that the timeout set by the application.\n\nChange-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218\n'}, {'number': 5, 'created': '2015-05-26 15:06:52.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f3d4ba7f6b89e0f4140ffd4f1ad910553288f6f4', 'message': 'rabbit: smart timeout on missing exchange\n\nWhen we send a reply and the exchange is missing, they\nno need to wait more that the timeout set by the application.\n\nChange-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218\n'}]",0,180905,f3d4ba7f6b89e0f4140ffd4f1ad910553288f6f4,24,6,5,2813,,,0,"rabbit: smart timeout on missing exchange

When we send a reply and the exchange is missing, they
no need to wait more that the timeout set by the application.

Change-Id: I7eb19346d72cb0a4813c964df1435d7f4c79e218
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/05/180905/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,e9db2944c0f4ac8edc14cccdef456ef66f7e56a5,sileht/refactor," """"""Publisher that retry if the exchange is missing. # TODO(sileht): use @retrying # NOTE(sileht): no need to wait the application expect a response # before timeout is exshauted duration = (timeout if timeout is None else self.conf.rpc_response_timeout) timer = rpc_common.DecayingTimer(duration=duration)"," """"""Publisher that retry during 60 seconds if the exchange is missing. # TODO(sileht): # * use timeout parameter when available # * use rpc_timeout if not instead of hardcoded 60 # * use @retrying timer = rpc_common.DecayingTimer(duration=60)",8,6
openstack%2Ffuel-docs~master~Ia2f40a5266a974133d32867eb699ceaea817ab71,openstack/fuel-docs,master,Ia2f40a5266a974133d32867eb699ceaea817ab71,enable back button for tabs,MERGED,2015-05-26 14:09:23.000000000,2015-05-26 17:02:03.000000000,2015-05-26 17:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 13695}]","[{'number': 1, 'created': '2015-05-26 14:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5435a6a762d0bc7ada7370dee4017223d4ff5b8b', 'message': 'enable back button for tabs\n\nChange-Id: Ia2f40a5266a974133d32867eb699ceaea817ab71\n'}, {'number': 2, 'created': '2015-05-26 14:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4b4506c7619d22e4cad2bc6a15c4c587c4ce9aa6', 'message': 'enable back button for tabs\n\nChange-Id: Ia2f40a5266a974133d32867eb699ceaea817ab71\n'}, {'number': 3, 'created': '2015-05-26 14:43:49.000000000', 'files': ['_templates/mirantis/static/styles.css', '_templates/mirantis/static/abtest.js'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/18b40a06135521046fbb464049e65ea6b21a8366', 'message': 'enable back button for tabs\n\nChange-Id: Ia2f40a5266a974133d32867eb699ceaea817ab71\n'}]",0,185615,18b40a06135521046fbb464049e65ea6b21a8366,17,4,3,15341,,,0,"enable back button for tabs

Change-Id: Ia2f40a5266a974133d32867eb699ceaea817ab71
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/15/185615/1 && git format-patch -1 --stdout FETCH_HEAD,"['_templates/mirantis/static/styles.css', '_templates/mirantis/static/abtest.js']",2,5435a6a762d0bc7ada7370dee4017223d4ff5b8b,bootstrap-theme," $(guides).find('.section').each(function (i) { for (var i = 0; i < columns.length; i += 4) { columns.slice(i, i + 4).wrapAll(""<div class='row'></div>""); } } function populatePdfs(pdfs) { $(pdfs).each(function () { for (var i = 0; i < columns.length; i += 2) { columns.slice(i, i + 2).wrapAll(""<div class='row'></div>""); } } function populateDownload(download) { $.get(""index_content.html"", function (data) { var homeTitle = $(data).find('.home-title').html(); var home = $(data).find('.what-is-mirantis-openstack').html(); $.get(""eula.html"", function (data) { $.get(""third-party-licenses.html"", function (data) { $(third_party).each(function (i, v) { $('a[data-toggle=""tab""]').on('click', function (e) { history.pushState(null, null, $(this).attr('href')); }); window.addEventListener(""popstate"", function (e) { var activeTab = location.hash ? $('[href=' + location.hash + ']') : $('[href=#home]'); if (activeTab.length) { activeTab.tab('show'); } else { $('.nav-tabs a:first').tab('show'); } }); "," $(guides).find('.section').each(function(i){ for(var i = 0; i < columns.length; i+=4) { columns.slice(i, i+4).wrapAll(""<div class='row'></div>""); } } function populatePdfs(pdfs){ $(pdfs).each(function(){ for(var i = 0; i < columns.length; i+=2) { columns.slice(i, i+2).wrapAll(""<div class='row'></div>""); } } function populateDownload(download){ $.get( ""index_content.html"", function( data ) { var homeTitle = $(data).find('.home-title').html(); var home = $(data).find('.what-is-mirantis-openstack').html(); $.get(""eula.html"", function(data) { $.get(""third-party-licenses.html"", function(data){ $(third_party).each(function(i,v){ ",90,65
openstack%2Fmonasca-api~master~I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c,openstack/monasca-api,master,I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c,Exception handling for duplicate Notification methods,MERGED,2015-05-08 02:50:19.000000000,2015-05-26 17:00:51.000000000,2015-05-26 16:59:25.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12133}, {'_account_id': 14375}, {'_account_id': 14517}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-05-08 02:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f0ae0224d0dfc3da29be06305d959788533a0ac1', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification type for a specific alarm.\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 2, 'created': '2015-05-08 02:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e2858b7016a16f125bf987c295eade40734b3b6a', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification type for a specific alarm.\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 3, 'created': '2015-05-08 02:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c3aebb06da70e03fab6e5da6a98a210aee7bc124', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification type for a specific alarm.\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 4, 'created': '2015-05-08 02:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/92aea3e2cab4efa2ef50714fec416c92ad7da7df', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification type for a specific alarm\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 5, 'created': '2015-05-08 04:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/96f36b621882d16a7e2dad1b4dd49740ed6da346', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification type for a specific alarm\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 6, 'created': '2015-05-11 17:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/d9ffb5528dc1465de4d89ef9361d7c67996acbc7', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 7, 'created': '2015-05-11 17:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/26a1f231cd741ca1da7e6abdfe74eea08675c59b', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 8, 'created': '2015-05-11 18:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/af3b90153ee4bf83cfd02e06139efadd33a246f7', 'message': 'Exception handling for duplicate Notification\nChange implemented to catch duplicate notification\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}, {'number': 9, 'created': '2015-05-11 21:23:47.000000000', 'files': ['java/src/main/java/monasca/api/app/validation/AlarmValidation.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/682781d83c07d2797271ffaf30cda8747adffaf7', 'message': 'Exception handling for duplicate Notification methods\n\nChange-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c\n'}]",12,181281,682781d83c07d2797271ffaf30cda8747adffaf7,28,7,9,14375,,,0,"Exception handling for duplicate Notification methods

Change-Id: I7dbdc08f0f55b7a5cbc9ad5ec6c9dff5807ae65c
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/81/181281/9 && git format-patch -1 --stdout FETCH_HEAD,"['java/src/main/java/monasca/api/infrastructure/persistence/mysql/AlarmDefinitionMySqlRepoImpl.java', 'java/.gitignore', 'java/src/main/java/monasca/api/app/AlarmDefinitionService.java', 'java/src/main/java/monasca/api/resource/AlarmDefinitionResource.java']",4,f0ae0224d0dfc3da29be06305d959788533a0ac1,1523,,,33,4
openstack%2Fpython-monascaclient~master~I87c7a39e4c829f02a48b8a1ab7c74c92aca27144,openstack/python-monascaclient,master,I87c7a39e4c829f02a48b8a1ab7c74c92aca27144,re-authenticates (once) with keystone to handle token expiration,MERGED,2015-05-20 21:20:48.000000000,2015-05-26 16:56:22.000000000,2015-05-26 16:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 12133}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-05-20 21:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/e48cb87d2b759e854c588b6a1c4793dbf3b1b4f7', 'message': 're-authenticates with keystone one time to handle token expiration\n\nChange-Id: I87c7a39e4c829f02a48b8a1ab7c74c92aca27144\n'}, {'number': 2, 'created': '2015-05-20 21:30:44.000000000', 'files': ['client_api_example.py', 'monascaclient/common/http.py', 'monascaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/3048bfce1bc0a87e6d1ba9efdd909b0b3a03c91f', 'message': 're-authenticates (once) with keystone to handle token expiration\n\nChange-Id: I87c7a39e4c829f02a48b8a1ab7c74c92aca27144\n'}]",0,184625,3048bfce1bc0a87e6d1ba9efdd909b0b3a03c91f,10,4,2,12133,,,0,"re-authenticates (once) with keystone to handle token expiration

Change-Id: I87c7a39e4c829f02a48b8a1ab7c74c92aca27144
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/25/184625/1 && git format-patch -1 --stdout FETCH_HEAD,"['client_api_example.py', 'monascaclient/common/http.py', 'monascaclient/shell.py']",3,e48cb87d2b759e854c588b6a1c4793dbf3b1b4f7,expired-token," parser.add_argument( '--key-file', help='Path of client key to use in SSL connection. ' 'This option is not necessary if your key is' ' prepended to your cert file.') raise exc.CommandError( ""User does not have a default project. "" ""You must provide a project id using "" ""--os-project-id or via env[OS_PROJECT_ID], "" ""or you must provide a project name using "" ""--os-project-name or via env[OS_PROJECT_NAME] "" ""and a domain using --os-domain-name, via "" ""env[OS_DOMAIN_NAME], using --os-domain-id or "" ""via env[OS_DOMAIN_ID]"") 'endpoint_type': args.os_endpoint_type, 'auth_url' : args.os_auth_url if args.os_project_name: kwargs['project_name'] = args.os_project_name if args.os_project_id: kwargs['project_id'] = args.os_project_id if args.os_domain_name: kwargs['domain_name'] = args.os_domain_name if args.os_domain_id: kwargs['domain_id'] = args.os_domain_id"," parser.add_argument('--key-file', help='Path of client key to use in SSL connection. ' 'This option is not necessary if your key is' ' prepended to your cert file.') raise exc.CommandError(""User does not have a default project. "" ""You must provide a project id using "" ""--os-project-id or via env[OS_PROJECT_ID], "" ""or you must provide a project name using "" ""--os-project-name or via env[OS_PROJECT_NAME] "" ""and a domain using --os-domain-name, via "" ""env[OS_DOMAIN_NAME], using --os-domain-id or "" ""via env[OS_DOMAIN_ID]"") 'endpoint_type': args.os_endpoint_type",86,29
openstack%2Fmonasca-persister~master~I0073790397957dec9424a88b4dccdbbb1fbfe68e,openstack/monasca-persister,master,I0073790397957dec9424a88b4dccdbbb1fbfe68e,Include dimensions in measurement tags,MERGED,2015-05-15 20:26:00.000000000,2015-05-26 16:55:13.000000000,2015-05-26 16:55:13.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14273}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-05-15 20:26:00.000000000', 'files': ['monasca_persister/persister.py'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/417feb37f5b33e854b0d89e739df427326dd789c', 'message': 'Include dimensions in measurement tags\n\nChange-Id: I0073790397957dec9424a88b4dccdbbb1fbfe68e\n'}]",5,183692,417feb37f5b33e854b0d89e739df427326dd789c,11,6,1,12512,,,0,"Include dimensions in measurement tags

Change-Id: I0073790397957dec9424a88b4dccdbbb1fbfe68e
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/92/183692/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_persister/persister.py'],1,417feb37f5b33e854b0d89e739df427326dd789c,bug/include-dimensions-in-tags," dimensions[dimension_name.encode('utf8')] = ( metric['dimensions'][dimension_name].encode('utf8')) tags = dimensions tags['_tenant_id'] = tenant_id.encode('utf8') tags['_region'] = region.encode('utf8') ""tags"": tags}"," dimensions[dimension_name] = ( metric['dimensions'][dimension_name]) ""tags"": { ""_tenant_id"": tenant_id.encode('utf8'), ""_region"": region.encode('utf8') }}",7,6
openstack%2Fdesignate~master~Ib80971587f0b51c9ccb800d4bd305a11f41d0994,openstack/designate,master,Ib80971587f0b51c9ccb800d4bd305a11f41d0994,Add Akamai Management comamnds,MERGED,2015-05-12 14:14:48.000000000,2015-05-26 16:50:31.000000000,2015-05-26 16:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 4894}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-05-12 14:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/534327876548a8bdfc03fd8dfb36e2565e0acc82', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 2, 'created': '2015-05-12 14:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/9890290fd0529d8038545fdedab210570e7bbf19', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 3, 'created': '2015-05-12 16:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/88c533376ddef2ce655a4924990c81c69bfd11ce', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 4, 'created': '2015-05-12 17:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/1ca1d8c38bcbc56910d695b9fd4061a0954fe541', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 5, 'created': '2015-05-13 07:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e45cbb04bc1b45892e7eeb1b85a30e17e81ae10e', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 6, 'created': '2015-05-13 11:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2a76624d9d111b51c24505779a51dcdcd1f046a9', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}, {'number': 7, 'created': '2015-05-13 12:17:31.000000000', 'files': ['designate/backend/impl_akamai.py', 'designate/manage/akamai.py', 'designate/manage/base.py', 'designate/pool_manager/service.py', 'setup.cfg', 'designate/objects/pool.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/bd8bb4b0e20402414afb294b97517662b72ab2ba', 'message': 'Add Akamai Management comamnds\n\nChange-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994\n'}]",6,182309,bd8bb4b0e20402414afb294b97517662b72ab2ba,20,4,7,395,,,0,"Add Akamai Management comamnds

Change-Id: Ib80971587f0b51c9ccb800d4bd305a11f41d0994
",git fetch https://review.opendev.org/openstack/designate refs/changes/09/182309/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/backend/impl_akamai.py', 'designate/manage/base.py', 'designate/pool_manager/service.py', 'setup.cfg', 'designate/objects/pool.py', 'designate/manage/enhanceddns.py']",6,534327876548a8bdfc03fd8dfb36e2565e0acc82,edns-mgm-cmds,"# Copyright 2015 Hewlett-Packard Development Company, L.P. # # Author: Endre Karlson <endre.karlson@hp.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_config import cfg from oslo_log import log as logging from designate import exceptions from designate import rpc from designate.objects import pool as pool_object from designate.backend import impl_akamai from designate.central import rpcapi as central_rpcapi from designate.manage import base LOG = logging.getLogger(__name__) class EDNSCommands(base.Commands): def __init__(self): super(EDNSCommands, self).__init__() rpc.init(cfg.CONF) self.central_api = central_rpcapi.CentralAPI() self.context.all_tenants = True def _get_config(self, pool_id, target_id): pool = pool_object.Pool.from_config(cfg.CONF, pool_id) target = None for t in pool.targets: if t.id == target_id: target = t else: raise exceptions.ConfigurationError(""Only 1 target supported"") if target is None: raise exceptions.ConfigurationError(""Didn't find configuration."") return pool, target @base.args('pool-id', help=""Pool Target to Migrate"", type=str) @base.args('pool-target-id', help=""Pool Target to Migrate"", type=str) @base.args('zone_name', help=""Zone name"") def debug_zone(self, pool_id, target_id, zone_name): pool, target = self._get_config(pool_id, target_id) edns_client = impl_akamai.EnhancedDNSClient( target.options.get(""username""), target.options.get(""password"")) zone = self.central_api.find_domain(self.context, {""name"": zone_name}) akamai_zone = edns_client.getZone(zone_name) print(""Designate zone\n%s"" % repr(zone)) print(""Akamai Zone:\n%s"" % repr(akamai_zone)) # edns specific commands @base.args('pool-id', help=""Pool Target to Migrate"", type=str) @base.args('pool-target-id', help=""Pool Target to Migrate"", type=str) @base.args('--batch_size', default=20, type=int) def sync_domains(self, pool_id, pool_target_id, batch_size): pool, target = self._get_config(pool_id, pool_target_id) edns_client = impl_akamai.EnhancedDNSClient( target.options.get(""username""), target.options.get(""password"")) LOG.info(""Doing batches of %i"" % batch_size) criterion = {""pool_id"": pool_id} marker = None while (marker is not False): zones = self.central_api.find_domains( self.context, criterion, limit=batch_size, marker=marker) update = [] if len(zones) == 0: LOG.info(""Stopping as there are no more zones."") break else: marker = zones[-1]['id'] for zone in zones: z = impl_akamai.build_zone(edns_client, target, zone) update.append(z) LOG.info('Uploading %d Zones', len(update)) edns_client.setZones(update) ",,142,27
openstack%2Fdesignate~master~If927fc7d70c625faa072dc8905a7e044f08aad33,openstack/designate,master,If927fc7d70c625faa072dc8905a7e044f08aad33,Drop use of 'oslo' namespace package,MERGED,2015-05-25 20:38:21.000000000,2015-05-26 16:50:29.000000000,2015-05-26 16:50:27.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 4894}, {'_account_id': 8174}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-25 20:38:21.000000000', 'files': ['designate/backend/agent_backend/impl_denominator.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/designate/commit/ba90b976197aa314875391caf37abbfbaba1f50c', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: If927fc7d70c625faa072dc8905a7e044f08aad33\n""}]",0,185448,ba90b976197aa314875391caf37abbfbaba1f50c,9,5,1,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: If927fc7d70c625faa072dc8905a7e044f08aad33
",git fetch https://review.opendev.org/openstack/designate refs/changes/48/185448/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/backend/agent_backend/impl_denominator.py', 'setup.cfg']",2,ba90b976197aa314875391caf37abbfbaba1f50c,bp/remove-namespace-packages, designate-rootwrap = oslo_rootwrap.cmd:main, designate-rootwrap = oslo.rootwrap.cmd:main,3,3
openstack%2Fpython-designateclient~master~I13d6c9ed46406fefc8cfa5de46811e4be009f1af,openstack/python-designateclient,master,I13d6c9ed46406fefc8cfa5de46811e4be009f1af,Move all_tenants and edit_managed attributes to designate Client,MERGED,2015-05-22 10:46:29.000000000,2015-05-26 16:50:25.000000000,2015-05-26 16:50:23.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 1106}, {'_account_id': 4894}, {'_account_id': 6550}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 15810}]","[{'number': 1, 'created': '2015-05-22 10:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/ec591a00f141f4b9af83ab6f7322fb15e08cb912', 'message': ""Initialize all_tenants attribute when using an external session\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' attribute:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}, {'number': 2, 'created': '2015-05-22 13:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/39db32293fe8ab0b8e041371c5fc0c0e8b3486f5', 'message': ""Move all_tenants and edit managed attributes to designate Client\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' and 'edit_managed' attributes:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nSame goes for 'edit_managed'.\n\nThis patch moves both attributes from Keystone session to designate\nClient.\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}, {'number': 3, 'created': '2015-05-22 13:40:52.000000000', 'files': ['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py', 'designateclient/cli/base.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/34d14b06d91b3d2e90d6531972bc25b8a8de53ab', 'message': ""Move all_tenants and edit_managed attributes to designate Client\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' and 'edit_managed' attributes:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nSame goes for 'edit_managed'.\n\nThis patch moves both attributes from Keystone session to designate\nClient.\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}]",0,184988,34d14b06d91b3d2e90d6531972bc25b8a8de53ab,17,10,3,6550,,,0,"Move all_tenants and edit_managed attributes to designate Client

Initializing designate client with a pre-existing keystone session
won't work as designate expects keystone session to have the
'all_tenants' and 'edit_managed' attributes:

Example code:

    keystone_session = ksc_session.Session(
      auth=keystone_auth,
      verify=True,
      cert=my_cert
    )

than later:

    self._designate_client = designate_client(
      session=keystone_session,
      region_name=region_name
    )

with that code, wrap_api_call() will raise an exception:

  AttributeError: 'Session' object has no attribute 'all_tenants'

Same goes for 'edit_managed'.

This patch moves both attributes from Keystone session to designate
Client.

Closes-Bug: 1457821
Change-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/88/184988/1 && git format-patch -1 --stdout FETCH_HEAD,['designateclient/v1/__init__.py'],1,ec591a00f141f4b9af83ab6f7322fb15e08cb912,bug/1457821, self.all_tenants = all_tenants if self.all_tenants:," all_tenants=all_tenants, if self.session.session.all_tenants:",3,2
