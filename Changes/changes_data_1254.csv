id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fproject-config~master~I7584ea37f84521d65f327f327ff5e47b096fa230,openstack/project-config,master,I7584ea37f84521d65f327f327ff5e47b096fa230,Grab the html version of console log,MERGED,2014-10-07 06:01:23.000000000,2014-10-07 18:21:43.000000000,2014-10-07 18:21:43.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-10-07 06:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/67c88b7fef5b3c1272d0f7521427395fc0b41a21', 'message': ""Grab the html version of console log\n\nCurrently we are only grabbing the text output from Jenkins. However,\nthis doesn't have timestamps which isn't ideal. We can use the\ninternal url that is used by Jenkins to generate its web page to\nfetch the console logs with timestamps and formatting.\n\nWe need to surround the output in pre tags since os-loganlayze uses\nthat to determine whether to escape the html or not.\n\nChange-Id: I7584ea37f84521d65f327f327ff5e47b096fa230\n""}, {'number': 2, 'created': '2014-10-07 13:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d495808f3f0ae4e02d1efae4c0d18a7c39d9ce30', 'message': ""Grab the html version of console log\n\nCurrently we are only grabbing the text output from Jenkins. However,\nthis doesn't have timestamps which isn't ideal. We can use the\ninternal url that is used by Jenkins to generate its web page to\nfetch the console logs with timestamps and formatting.\n\nWe need to surround the output in pre tags since os-loganlayze uses\nthat to determine whether to escape the html or not.\n\nChange-Id: I7584ea37f84521d65f327f327ff5e47b096fa230\n""}, {'number': 3, 'created': '2014-10-07 18:09:44.000000000', 'files': ['jenkins/scripts/grab_console_log.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ca9b73efba7c4194585ca563a7db118b5c4ea9d3', 'message': ""Grab the html version of console log\n\nCurrently we are only grabbing the text output from Jenkins. However,\nthis doesn't have timestamps which isn't ideal. We can use the\ninternal url that is used by Jenkins to generate its web page to\nfetch the console logs with timestamps and formatting.\n\nWe need to surround the output in pre tags since os-loganlayze uses\nthat to determine whether to escape the html or not.\n\nChange-Id: I7584ea37f84521d65f327f327ff5e47b096fa230\n""}]",4,126471,ca9b73efba7c4194585ca563a7db118b5c4ea9d3,19,6,3,7069,,,0,"Grab the html version of console log

Currently we are only grabbing the text output from Jenkins. However,
this doesn't have timestamps which isn't ideal. We can use the
internal url that is used by Jenkins to generate its web page to
fetch the console logs with timestamps and formatting.

We need to surround the output in pre tags since os-loganlayze uses
that to determine whether to escape the html or not.

Change-Id: I7584ea37f84521d65f327f327ff5e47b096fa230
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/126471/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/grab_console_log.sh', 'jenkins/jobs/macros.yaml']",2,67c88b7fef5b3c1272d0f7521427395fc0b41a21,html_console_log, upload_source: '/tmp/console.html' upload_source: '{upload_source} /tmp/console.html', upload_source: '/tmp/console.txt' upload_source: '{upload_source} /tmp/console.txt',14,3
openstack%2Fproject-config~master~I8daec5d74b9d78de9aeb2c3a1a9e138c1f596a03,openstack/project-config,master,I8daec5d74b9d78de9aeb2c3a1a9e138c1f596a03,Switch all tripleo tests to use Ironic,MERGED,2014-10-07 14:16:02.000000000,2014-10-07 18:15:18.000000000,2014-10-07 18:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-10-07 14:16:02.000000000', 'files': ['jenkins/jobs/tripleo.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c552ba177ee266934aa5c06c7d0f137b2c07c71d', 'message': 'Switch all tripleo tests to use Ironic\n\nNova is about to drop the novabm driver from the tree, we wont be able\nto use it.\n\nSee Ia76e41a8a3b7230701872ae7a1975edc3d9ea847 for novabm removal.\n\nChange-Id: I8daec5d74b9d78de9aeb2c3a1a9e138c1f596a03\n'}]",0,126563,c552ba177ee266934aa5c06c7d0f137b2c07c71d,9,5,1,1926,,,0,"Switch all tripleo tests to use Ironic

Nova is about to drop the novabm driver from the tree, we wont be able
to use it.

See Ia76e41a8a3b7230701872ae7a1975edc3d9ea847 for novabm removal.

Change-Id: I8daec5d74b9d78de9aeb2c3a1a9e138c1f596a03
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/126563/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/tripleo.yaml', 'zuul/layout.yaml']",2,c552ba177ee266934aa5c06c7d0f137b2c07c71d,, - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-f20-nonha - check-tripleo-ironic-overcloud-precise-nonha, - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-undercloud-precise-nonha - check-tripleo-novabm-overcloud-f20-nonha - check-tripleo-novabm-overcloud-precise-nonha,88,171
openstack%2Fkeystone-specs~master~I64c3a37301dc6fcbb8b81fd901abb87d0e0efc70,openstack/keystone-specs,master,I64c3a37301dc6fcbb8b81fd901abb87d0e0efc70,Fetch Policy Based on Endpoint Identity,ABANDONED,2014-07-11 17:04:02.000000000,2014-10-07 18:09:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-11 17:04:02.000000000', 'files': ['specs/juno/fetch-policy-by-endpoint.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/48de094ffd9537cc6642e0cf20358b1e93138fb7', 'message': 'Fetch Policy Based on Endpoint Identity\n\nChange-Id: I64c3a37301dc6fcbb8b81fd901abb87d0e0efc70\n'}]",0,106438,48de094ffd9537cc6642e0cf20358b1e93138fb7,4,1,1,2218,,,0,"Fetch Policy Based on Endpoint Identity

Change-Id: I64c3a37301dc6fcbb8b81fd901abb87d0e0efc70
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/38/106438/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/fetch-policy-by-endpoint.rst'],1,48de094ffd9537cc6642e0cf20358b1e93138fb7,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== `bp fetch-policy-by-endpoint <https://blueprints.launchpad.net/keystone/+spec/fetch-policy-by-endpoint>`_ Instead of only fetching policy based on the policy ID, fetch the policy based on the identity of the endpoint requesting the policy file. Problem Description =================== Policy is currently very static throughout OpenStack deployments. The majority of endpoints use the default policies from the git repositories. One problem is that an endpoint has no way to be able to fetch its policy from Keystone without knowing ahead of time what policy to fetch. Since the majority of endpoints are going to use the same policy file, requiring the modification of each config file to know then name of the policy file to fetch is an administrative burden. Instead, allow each endpoint to request a policy file based on its endpoint identity. In the first implementation, we can always return one single unified policy file. In the future, Keystone can allow much more complex logic to determine which policy file to return based on service, region, or specific endpoint id. .. Stop here! On your first proposal to the specs repo, only include the above sections, so that the community can agree on the problem statement itself. Propose the problem description in the ``specs/next/`` directory. Once the community has accepted the problem description, propose a solution (filling in the sections below) to a release directory (``specs/juno/`` for example). Proposed Change =============== Here is where you describe the change you propose to make. How do you propose to solve this problem? Address the issue at an architectural level, leaving the implementation details for code review. If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Notifications Impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. Other End User Impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-keystoneclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other backends would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in keystone, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Keystone (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,199,0
openstack%2Fsolum~master~I6c674f9471ddfa641490f59b32fb2ea18facef82,openstack/solum,master,I6c674f9471ddfa641490f59b32fb2ea18facef82,Support private git repo's without using Barbican.,MERGED,2014-10-02 18:33:14.000000000,2014-10-07 18:03:49.000000000,2014-10-07 18:03:48.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 9095}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-10-02 18:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/944f7b9df78071d3ebe11c4560a9c0b13f830ee2', 'message': ""WIP: Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nI'm still working on tests, but would love to get feedback\nfor the work so far.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 2, 'created': '2014-10-02 23:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0fdc2be83e689cbb5d115df70ea29de4d5729dbd', 'message': ""WIP: Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nI'm still working on tests, but would love to get feedback\nfor the work so far.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 3, 'created': '2014-10-02 23:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8a123774e9298ae103bb96e38620b0c7a90f561c', 'message': ""WIP: Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nI'm still working on tests, but would love to get feedback\nfor the work so far.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 4, 'created': '2014-10-03 00:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/fd5bf5e993d2370655dc4dc3085046a7965e6b5b', 'message': ""Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 5, 'created': '2014-10-03 14:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/632beede9d4194fa1e1a78c2b0f0eae7597726b2', 'message': ""Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 6, 'created': '2014-10-03 15:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/954eceb2ac500a33c88272845b202575e43805f9', 'message': ""Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\n   not a big concern and the Ops\\Dev team does not want\n   to run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\n   Barbican.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 7, 'created': '2014-10-06 22:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3a0f4e44f97425f64e640da69ac00e2d34153a82', 'message': ""Support private git repo's without using Barbican.\n\nThis patch add's support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecret's get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\nnot a big concern and the Ops\\Dev team does not want\nto run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\nBarbican.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}, {'number': 8, 'created': '2014-10-07 16:14:31.000000000', 'files': ['solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/common/clients.py', 'solum/api/handlers/plan_handler.py', 'etc/solum/solum.conf.sample'], 'web_link': 'https://opendev.org/openstack/solum/commit/e5ba1951a29049ef7a20e93364ad6efc56b160f1', 'message': ""Support private git repo's without using Barbican.\n\nThis patch adds support to run an instance of Solum\nwithout using Barbican for storing private git repo secrets.\nSecrets get stored on the host machines filesystem if the\nconfig value is set to disable using Barbican.\n\nThis feature is great for two uses\n1) Running internal instances of Solum when security is\nnot a big concern and the Ops\\Dev team does not want\nto run an extra OpenStack service.\n\n2) Testing Solum in a vagrant environment without running\nBarbican.\n\nChange-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82\n""}]",22,125734,e5ba1951a29049ef7a20e93364ad6efc56b160f1,25,5,8,9095,,,0,"Support private git repo's without using Barbican.

This patch adds support to run an instance of Solum
without using Barbican for storing private git repo secrets.
Secrets get stored on the host machines filesystem if the
config value is set to disable using Barbican.

This feature is great for two uses
1) Running internal instances of Solum when security is
not a big concern and the Ops\Dev team does not want
to run an extra OpenStack service.

2) Testing Solum in a vagrant environment without running
Barbican.

Change-Id: I6c674f9471ddfa641490f59b32fb2ea18facef82
",git fetch https://review.opendev.org/openstack/solum refs/changes/34/125734/8 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/common/clients.py', 'solum/api/handlers/plan_handler.py', 'etc/solum/solum.conf.sample']",5,944f7b9df78071d3ebe11c4560a9c0b13f830ee2,shelve,# private git repo secrets location (string value) #git_secrets_file=/etc/solum/secrets/git_secrets.db # Stores private repo secrets on the host filesystem # instead of using barbican if True (boolean value) #store_secrets_on_host=False , ,102,15
openstack%2Fpython-ceilometerclient~master~I194cfa38d6a464f7d78b22dbcd6cb1b39fda804f,openstack/python-ceilometerclient,master,I194cfa38d6a464f7d78b22dbcd6cb1b39fda804f,Deleted the token and endpoint on expiry of token of client,ABANDONED,2014-08-27 08:54:56.000000000,2014-10-07 17:57:07.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 10722}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-08-27 08:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/b3e00ab1e0c679526752198a4b0528812cf89c3f', 'message': 'Deleted the token and endpoint on expiry of token of client\n\nImplements: Deleted the token and endpoint of client on token\nexpiration, so function _do_authenticate() in\npython-ceilometerclient/ceilometerclient/client.py will renew\nthe session on token expiry and ceilometer-alarm-evaluator\nwill run continuously without giving error-401.\n\nChange-Id: I194cfa38d6a464f7d78b22dbcd6cb1b39fda804f\nCloses-Bug: #1357343\n'}, {'number': 2, 'created': '2014-09-27 12:34:01.000000000', 'files': ['ceilometerclient/openstack/common/apiclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/64b8b9ffa4ed6844dd035f0fe0beafc490f0f343', 'message': 'Deleted the token and endpoint on expiry of token of client\n\nImplements: Deleted the token and endpoint of client on token\nexpiration, so function _do_authenticate() in\npython-ceilometerclient/ceilometerclient/client.py will renew\nthe session on token expiry and ceilometer-alarm-evaluator\nwill run continuously without giving error-401.\n\nChange-Id: I194cfa38d6a464f7d78b22dbcd6cb1b39fda804f\nCloses-Bug: #1357343\n'}]",3,117141,64b8b9ffa4ed6844dd035f0fe0beafc490f0f343,12,5,2,10722,,,0,"Deleted the token and endpoint on expiry of token of client

Implements: Deleted the token and endpoint of client on token
expiration, so function _do_authenticate() in
python-ceilometerclient/ceilometerclient/client.py will renew
the session on token expiry and ceilometer-alarm-evaluator
will run continuously without giving error-401.

Change-Id: I194cfa38d6a464f7d78b22dbcd6cb1b39fda804f
Closes-Bug: #1357343
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/41/117141/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/openstack/common/apiclient/client.py'],1,b3e00ab1e0c679526752198a4b0528812cf89c3f,ceilometerclient-1357343, if self.auth_plugin.opts.get('token'): self.auth_plugin.opts['token'] = None if self.auth_plugin.opts.get('token'): self.auth_plugin.opts['endpoint'] = None,,4,0
openstack%2Fpython-ceilometerclient~master~I798e34e5e6e9afd92726f1772be9c9de8f4255d3,openstack/python-ceilometerclient,master,I798e34e5e6e9afd92726f1772be9c9de8f4255d3,Update apiclient.client module to renew session after token expiration,ABANDONED,2014-09-27 12:34:01.000000000,2014-10-07 17:56:56.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-09-27 12:34:01.000000000', 'files': ['ceilometerclient/openstack/common/apiclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/4010f5d3ad370c66cc5bf032d30227cf4019d388', 'message': 'Update apiclient.client module to renew session after token expiration\n\nCurrently session is not renewed if token is expired. This bug\nhas roots in the oslo-incubator common code, that has been\nalready fixed. This change updates apiclient.client common module\nto have these modifications in ceilometerclient code.\nCloses-Bug: #1357343\n\nChange-Id: I798e34e5e6e9afd92726f1772be9c9de8f4255d3\n'}]",0,124592,4010f5d3ad370c66cc5bf032d30227cf4019d388,7,4,1,10722,,,0,"Update apiclient.client module to renew session after token expiration

Currently session is not renewed if token is expired. This bug
has roots in the oslo-incubator common code, that has been
already fixed. This change updates apiclient.client common module
to have these modifications in ceilometerclient code.
Closes-Bug: #1357343

Change-Id: I798e34e5e6e9afd92726f1772be9c9de8f4255d3
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/92/124592/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/openstack/common/apiclient/client.py'],1,4010f5d3ad370c66cc5bf032d30227cf4019d388,ceilometerclient-1357343,"from oslo.utils import importutilsfrom ceilometerclient.openstack.common._i18n import _ requests.Session.request (such as `headers`) or `json` kwargs.setdefault(""headers"", {}) `HTTPClient.request` _(""Cannot find endpoint or token for request"")) if self.auth_plugin.opts.get('endpoint'): msg = _(""Invalid %(api_name)s client version '%(version)s'. "" ""Must be one of: %(version_map)s"") % { 'api_name': api_name, 'version': version, 'version_map': ', '.join(version_map.keys())}","from ceilometerclient.openstack.common import importutils' requests.Session.request (such as `headers`) or `json` kwargs.setdefault(""headers"", kwargs.get(""headers"", {}))' `HTTPClient.request` ""Cannot find endpoint or token for request"") if self.auth_plugin.opts.get('token'): msg = ""Invalid %s client version '%s'. must be one of: %s"" % ( (api_name, version, ', '.join(version_map.keys())))",13,8
openstack%2Fproject-config~master~I24fc6607f27f013d63903f6e709a5ce266495287,openstack/project-config,master,I24fc6607f27f013d63903f6e709a5ce266495287,Add facter package to uninstall-puppet macro,MERGED,2014-10-06 16:20:43.000000000,2014-10-07 17:56:32.000000000,2014-10-07 17:56:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4146}, {'_account_id': 6786}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-10-06 16:20:43.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0cc56cee5e289927855e00301e4ce3cdb14c1369', 'message': 'Add facter package to uninstall-puppet macro\n\nAlthough rspec tests for Puppet modules are running in bundler,\nthe system version of facter looks to conflict with rspec tests:\n\n    ArgumentError:\n      Invalid facter option(s) type\n\nThis hypothesis has been confirmed on a system with a similar setup.\nUninstalling the system version of facter fixed the above problem.\n\nChange-Id: I24fc6607f27f013d63903f6e709a5ce266495287\n'}]",0,126344,0cc56cee5e289927855e00301e4ce3cdb14c1369,9,5,1,7156,,,0,"Add facter package to uninstall-puppet macro

Although rspec tests for Puppet modules are running in bundler,
the system version of facter looks to conflict with rspec tests:

    ArgumentError:
      Invalid facter option(s) type

This hypothesis has been confirmed on a system with a similar setup.
Uninstalling the system version of facter fixed the above problem.

Change-Id: I24fc6607f27f013d63903f6e709a5ce266495287
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/126344/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,0cc56cee5e289927855e00301e4ce3cdb14c1369,uninstall_facter," - shell: ""sudo apt-get remove -y --purge facter puppet puppet-common"""," - shell: ""sudo apt-get remove -y --purge puppet puppet-common""",1,1
openstack%2Fproject-config~master~Iac9ee6ef72090ac1496ba0b95d88346e681f8831,openstack/project-config,master,Iac9ee6ef72090ac1496ba0b95d88346e681f8831,Use templates in layout.yaml,MERGED,2014-10-05 17:42:50.000000000,2014-10-07 17:55:37.000000000,2014-10-07 17:55:36.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6609}, {'_account_id': 7069}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-10-05 17:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/522d287f97807091a7cf0b9ef3d01f5d8e8d805d', 'message': ""Use templates in layout.yaml\n\nUse python33-jobs, puppet-check-jobs and pypy-jobs templates where\nmissing and applicable.\n\nRemove extra gate-oslo.vmware-requirements, it's part of\ncheck-requirements template.\n\nChange-Id: Iac9ee6ef72090ac1496ba0b95d88346e681f8831\n""}, {'number': 2, 'created': '2014-10-05 17:58:30.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9423ff5abc433da49974f62412dab96036bdfec3', 'message': ""Use templates in layout.yaml\n\nUse python3-jobs, puppet-check-jobs and pypy-jobs templates where\nmissing and applicable.\n\nRemove extra gate-oslo.vmware-requirements, it's part of\ncheck-requirements template.\n\nChange-Id: Iac9ee6ef72090ac1496ba0b95d88346e681f8831\n""}]",4,126192,9423ff5abc433da49974f62412dab96036bdfec3,15,7,2,6547,,,0,"Use templates in layout.yaml

Use python3-jobs, puppet-check-jobs and pypy-jobs templates where
missing and applicable.

Remove extra gate-oslo.vmware-requirements, it's part of
check-requirements template.

Change-Id: Iac9ee6ef72090ac1496ba0b95d88346e681f8831
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/126192/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,522d287f97807091a7cf0b9ef3d01f5d8e8d805d,layout-cleanup, - name: pypy-jobs - name: pypy-jobs check: - name: pypy-jobs check: - name: pypy-jobs check: - name: pypy-jobs - name: pypy-jobs check: - name: pypy-jobs - name: pypy-jobs check: - name: pypy-jobs check: - name: pypy-jobs - name: pypy-jobs check: - name: pypy-jobs - name: pypy-jobs check: - name: pypy-jobs check: - name: puppet-check-jobs check: - name: pypy-jobs - name: python33-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs - name: pypy-jobs, - gate-python-barbicanclient-pypy - gate-python-barbicanclient-pypy check: - gate-python-ceilometerclient-pypy - gate-python-ceilometerclient-pypy check: - gate-python-cinderclient-pypy - gate-python-cinderclient-pypy check: - gate-python-glanceclient-pypy - gate-python-glanceclient-pypy - gate-python-heatclient-pypy - gate-python-heatclient-pypy check: - gate-python-ironicclient-pypy - gate-python-ironicclient-pypy - gate-python-neutronclient-pypy gate: - gate-python-neutronclient-pypy check: - gate-python-novaclient-pypy - gate-python-novaclient-pypy check: - gate-python-swiftclient-pypy - gate-python-swiftclient-pypy check: - gate-python-troveclient-pypy gate: - gate-python-troveclient-pypy check: - gate-oslo.version-pypy - gate-oslo.version-pypy - gate-oslo.vmware-requirements - gate-requirements-pypy - gate-requirements-pypy check: - gate-hacking-pypy gate: - gate-hacking-pypy check: - gate-pbr-pypy - gate-pbr-pypy check: - gate-puppet-storyboard-puppet-lint - gate-puppet-storyboard-puppet-syntax - gate-puppet-storyboard-puppet-lint - gate-puppet-storyboard-puppet-syntax - gate-release-tools-pypy - gate-release-tools-pypy - gate-cloudbase-init-python33 - gate-cloudbase-init-python33 check: - gate-os-client-config-pypy gate: - gate-os-client-config-pypy - gate-pecan-pypy - gate-pecan-pypy check: - gate-python-openstacksdk-pypy gate: - gate-python-openstacksdk-pypy check: - gate-python-solumclient-pypy gate: - gate-python-solumclient-pypy check: - gate-satori-pypy gate: - gate-satori-pypy - gate-solum-pypy - gate-solum-pypy check: - gate-solum-dashboard-pypy gate: - gate-solum-dashboard-pypy check: - gate-solum-infra-guestagent-pypy gate: - gate-solum-infra-guestagent-pypy,25,69
openstack%2Fproject-config~master~I1909fc2fb225063d29a04bda99cbbc6a82411573,openstack/project-config,master,I1909fc2fb225063d29a04bda99cbbc6a82411573,Fix several HTML issues and prettify syntax,MERGED,2014-10-04 15:59:12.000000000,2014-10-07 17:52:10.000000000,2014-10-07 17:52:09.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-04 15:59:12.000000000', 'files': ['specs/index.html'], 'web_link': 'https://opendev.org/openstack/project-config/commit/54028e4e562b905b2a4bd191fe5c54b4a8692d7f', 'message': 'Fix several HTML issues and prettify syntax\n\nAccording to the markup validation service provided by the W3C there are severl\nHTML issues. This patch fixes all of them and prettifies the syntax.\n\nhttp://validator.w3.org/check?uri=specs.openstack.org&charset=%28detect+automatically%29&doctype=Inline&group=0\n\n* No Character Encoding Found! Falling back to UTF-8.\n* No DOCTYPE found! Checking with default XHTML 1.0\n  Transitional Document Type.\n* No Character encoding declared at document level\n* Line 4, Column 8: element ""HEAD"" undefined\n* Line 5, Column 11: element ""TITLE"" undefined\n* Line 27, Column 38: document type does not allow element ""body"" here\n* Line 206, Column 9: end tag for element ""BODY"" which is not open\n* Line 207, Column 7: end tag for ""div"" omitted, but OMITTAG NO was specified\n* Line 207, Column 7: end tag for ""body"" omitted, but OMITTAG NO was specified\n* Line 207, Column 7: end tag for ""html"" which is not finished\n\nChange-Id: I1909fc2fb225063d29a04bda99cbbc6a82411573\n'}]",0,126149,54028e4e562b905b2a4bd191fe5c54b4a8692d7f,9,5,1,167,,,0,"Fix several HTML issues and prettify syntax

According to the markup validation service provided by the W3C there are severl
HTML issues. This patch fixes all of them and prettifies the syntax.

http://validator.w3.org/check?uri=specs.openstack.org&charset=%28detect+automatically%29&doctype=Inline&group=0

* No Character Encoding Found! Falling back to UTF-8.
* No DOCTYPE found! Checking with default XHTML 1.0
  Transitional Document Type.
* No Character encoding declared at document level
* Line 4, Column 8: element ""HEAD"" undefined
* Line 5, Column 11: element ""TITLE"" undefined
* Line 27, Column 38: document type does not allow element ""body"" here
* Line 206, Column 9: end tag for element ""BODY"" which is not open
* Line 207, Column 7: end tag for ""div"" omitted, but OMITTAG NO was specified
* Line 207, Column 7: end tag for ""body"" omitted, but OMITTAG NO was specified
* Line 207, Column 7: end tag for ""html"" which is not finished

Change-Id: I1909fc2fb225063d29a04bda99cbbc6a82411573
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/126149/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/index.html'],1,54028e4e562b905b2a4bd191fe5c54b4a8692d7f,fix_html_issues,"<!DOCTYPE html PUBLIC ""-//W3C//DTD XHTML 1.0 Strict//EN"" ""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd""> <html lang=""en"" xml:lang=""en"" xmlns=""http://www.w3.org/1999/xhtml""> <head> <meta content=""text/html; charset=UTF-8"" http-equiv=""Content-Type""/> <title> OpenStack Specifications </title> <script src=""http://status.openstack.org/common.js"" type=""text/javascript""> </script> <!-- Google Fonts --> <link href=""http://fonts.googleapis.com/css?family=PT+Sans&amp;subset=latin"" rel=""stylesheet"" type=""text/css""/> </head> <!-- Page Content --> <div class=""container""> <div class=""span-12""> <h3 class=""subhead""> </h3> </div> <div class=""searchArea span-10 last""> <div class=""container""> <div class=""span-12""> </div> <div class=""container""> <div class=""span-12""> <div> </div> </div> <div class=""span-12"" id=""subnav""> <ul class=""subsectionNav""> <li class=""link""> <a> Projects </a> </li> </ul> <!-- This lists follows the naming of http://docs.openstack.org/developer/openstack-projects.html --> <dl> <dd> <a href=""openstack/ironic-specs""> Bare Metal Provisioning Specifications (ironic) </a> <a href=""openstack/nova-specs/""> Compute Service Specifications (nova) </a> <a href=""openstack/sahara-specs/""> Data Processing Service Specifications (sahara) </a> <a href=""openstack/keystone-specs/""> Identity Program Specifications (keystone) </a> <dd> <a href=""openstack/glance-specs/""> Image Service Specifications (glance) </a> </dd> <dd> <a href=""openstack/barbican-specs/""> Key Management Service Specifications (barbican) </a> </dd> <dd> <a href=""openstack/neutron-specs/""> Networking Service Developer Specifications (neutron) </a> </dd> <dd> <a href=""openstack/swift-specs/""> Object Storage Specifications (swift) </a> </dd> <dd> <a href=""openstack/heat-specs/""> Orchestration Specifications (heat) </a> </dd> <dd> <a href=""openstack/zaqar-specs/""> Queue Service Specifications (zaqar) </a> </dd> <dd> <a href=""openstack/ceilometer-specs/""> Telemetry Service Specifications (ceilometer) </a> </dd> <dd> <a href=""openstack/cinder-specs/""> Volume Service Specifications (cinder) </a> </dd> </dl> </div> <div class=""span-12 last-right"" id=""subnav-right""> <ul class=""subsectionNav last-right""> <li class=""link""> <a> Programs </a> </li> </ul> <dl> <dd> <a href=""openstack/oslo-specs/""> Common Libraries Program Specifications (oslo) </a> </dd> <dd> <a href=""openstack/tripleo-specs/""> Deployment Program Specifications </a> </dd> <dd> <a href=""openstack/docs-specs/""> Documentation Program Specifications </a> </dd> <dd> <a href=""openstack-infra/infra-specs/""> Infrastructure Program Specifications </a> </dd> <dd> <a href=""openstack/qa-specs/""> QA Program Specifications </a> </dd> </dl> </div> <script type=""text/javascript""> footer(); </script> </body>","<html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:py=""http://genshi.edgewall.org/"" lang=""en""> <HEAD> <TITLE>OpenStack Specifications</TITLE> <script type=""text/javascript"" src=""http://status.openstack.org/common.js""></script> <!-- Google Fonts --> <link href='http://fonts.googleapis.com/css?family=PT+Sans&amp;subset=latin' rel='stylesheet' type='text/css'/> </HEAD> <!-- Page Content --> <div class=""container""> <div class=""span-12""> <h3 class=""subhead""> </h3> </div> <div class=""searchArea span-10 last""> </div> </div> <div class=""container""> <div class=""span-12""> </div> </div> <div class=""container""> <div class=""span-12""> <div> <div class=""span-12"" id=""subnav""> <ul class=""subsectionNav""> <li class=""link""> <a> Projects </a> </li> </ul> <!-- This lists follows the naming of http://docs.openstack.org/developer/openstack-projects.html --> <dl> <dd> <a href=""openstack/ironic-specs""> Bare Metal Provisioning Specifications (ironic) </a> </dd> <dd> <a href=""openstack/nova-specs/"">Compute Service Specifications (nova)</a> </dd> <dd> <a href=""openstack/sahara-specs/"">Data Processing Service Specifications (sahara)</a> </dd> <dd> <a href=""openstack/keystone-specs/"">Identity Program Specifications (keystone)</a> </dd> <dd> <a href=""openstack/glance-specs/"">Image Service Specifications (glance)</a> </dd> <dd> <a href=""openstack/barbican-specs/"">Key Management Service Specifications (barbican)</a> </dd> <dd> <a href=""openstack/neutron-specs/"">Networking Service Developer Specifications (neutron)</a> </dd> <dd> <a href=""openstack/swift-specs/"">Object Storage Specifications (swift)</a> </dd> <dd> <a href=""openstack/heat-specs/"">Orchestration Specifications (heat)</a> </dd> <dd> <a href=""openstack/zaqar-specs/"">Queue Service Specifications (zaqar)</a> </dd> <dd> <a href=""openstack/ceilometer-specs/"">Telemetry Service Specifications (ceilometer)</a> </dd> <dd> <a href=""openstack/cinder-specs/"">Volume Service Specifications (cinder)</a> </dd> </dl> <div class=""span-12 last-right"" id=""subnav-right""> <ul class=""subsectionNav last-right""> <li class=""link""> <a> Programs </a> </li> </ul> <dl> <dd> <a href=""openstack/oslo-specs/"">Common Libraries Program Specifications (oslo)</a> <a href=""openstack/tripleo-specs/"">Deployment Program Specifications</a> </dd> <dd> <a href=""openstack/docs-specs/"">Documentation Program Specifications</a> <a href=""openstack-infra/infra-specs/"">Infrastructure Program Specifications</a> <a href=""openstack/qa-specs/"">QA Program Specifications</a> </dl> <script type=""text/javascript"">footer();</script> </BODY>",149,119
openstack%2Frequirements~master~Ia0a0c7f78d15c84673e1ad57b1cff2d10c2bd235,openstack/requirements,master,Ia0a0c7f78d15c84673e1ad57b1cff2d10c2bd235,Allow projects to use oslo.middleware,ABANDONED,2014-09-24 12:25:05.000000000,2014-10-07 17:41:35.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-09-24 12:25:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/212fccb456068c262a22ecb78f36a241b7e5182d', 'message': 'Allow projects to use oslo.middleware\n\nChange-Id: Ia0a0c7f78d15c84673e1ad57b1cff2d10c2bd235\n'}, {'number': 2, 'created': '2014-10-03 11:59:13.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3ad7c049b6e0ea0016249913e83c06455d3e95b3', 'message': 'Allow projects to use oslo.middleware\n\nChange-Id: Ia0a0c7f78d15c84673e1ad57b1cff2d10c2bd235\n'}]",0,123712,3ad7c049b6e0ea0016249913e83c06455d3e95b3,11,4,2,5638,,,0,"Allow projects to use oslo.middleware

Change-Id: Ia0a0c7f78d15c84673e1ad57b1cff2d10c2bd235
",git fetch https://review.opendev.org/openstack/requirements refs/changes/12/123712/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,212fccb456068c262a22ecb78f36a241b7e5182d,,oslo.middleware>=0.1.0,,1,0
openstack%2Fproject-config~master~Ib041499f9cc4c52dd7b417b4fe82ef0eb2e11ad5,openstack/project-config,master,Ib041499f9cc4c52dd7b417b4fe82ef0eb2e11ad5,Change paths in rally-jobs according to new layout,MERGED,2014-10-07 15:31:28.000000000,2014-10-07 17:39:33.000000000,2014-10-07 17:39:33.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 15:31:28.000000000', 'files': ['jenkins/jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7cdb4ea85073c0a4901ca24121156c3ef3dec2c2', 'message': 'Change paths in rally-jobs according to new layout\n\nDirectory tests_ci moved to tests/ci\n\nChange-Id: Ib041499f9cc4c52dd7b417b4fe82ef0eb2e11ad5\n'}]",0,126598,7cdb4ea85073c0a4901ca24121156c3ef3dec2c2,7,3,1,7369,,,0,"Change paths in rally-jobs according to new layout

Directory tests_ci moved to tests/ci

Change-Id: Ib041499f9cc4c52dd7b417b4fe82ef0eb2e11ad5
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/126598/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/rally.yaml'],1,7cdb4ea85073c0a4901ca24121156c3ef3dec2c2,move-rally-modules," - shell: ""tests/ci/test_install.sh"" $BASE/new/rally/tests/ci/rally-gate.sh $BASE/new/rally/tests/ci/rally-gate.sh"," - shell: ""tests_ci/test_install.sh"" $BASE/new/rally/tests_ci/rally-gate.sh $BASE/new/rally/tests_ci/rally-gate.sh",3,3
openstack%2Fxstatic-bootstrap-datepicker~master~I6f610b2f7097976f387cc911ae78d2152e08d0ba,openstack/xstatic-bootstrap-datepicker,master,I6f610b2f7097976f387cc911ae78d2152e08d0ba,Version 1.3.0.0,MERGED,2014-08-13 13:52:57.000000000,2014-10-07 17:21:16.000000000,2014-10-07 17:21:16.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4264}, {'_account_id': 6476}, {'_account_id': 11902}]","[{'number': 1, 'created': '2014-08-13 13:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-bootstrap-datepicker/commit/db01e236aa7fb9f1dcefcc49e95e7f9a4e776972', 'message': 'Version 1.3.0.0\n\nChange-Id: I6f610b2f7097976f387cc911ae78d2152e08d0ba\n'}, {'number': 2, 'created': '2014-08-26 11:47:15.000000000', 'files': ['xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.vi.js', 'xstatic/pkg/bootstrap_datepicker/__init__.py', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ca.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.hr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.el.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pt-BR.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.zh-CN.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.tr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sv.js', 'xstatic/pkg/bootstrap_datepicker/data/bootstrap-datepicker.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.es.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ua.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.da.js', 'xstatic/pkg/bootstrap_datepicker/data/datepicker3.css', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.de.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.cy.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.gl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.no.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.kr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pt.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ru.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.rs-latin.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ka.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.id.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ja.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.it.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sq.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.zh-TW.js', 'xstatic/pkg/bootstrap_datepicker/data/datepicker.css', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.lv.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.th.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nl-BE.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.mk.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nb.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.is.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.he.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ms.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.az.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.cs.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ar.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.hu.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.rs.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ro.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.lt.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fi.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.kk.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.et.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sw.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.bg.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fa.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sk.js'], 'web_link': 'https://opendev.org/openstack/xstatic-bootstrap-datepicker/commit/b835e650e09ffdf4fb765ba62276267f097fca2a', 'message': 'Version 1.3.0.0\n\nChange-Id: I6f610b2f7097976f387cc911ae78d2152e08d0ba\n'}]",0,113893,b835e650e09ffdf4fb765ba62276267f097fca2a,12,5,2,8648,,,0,"Version 1.3.0.0

Change-Id: I6f610b2f7097976f387cc911ae78d2152e08d0ba
",git fetch https://review.opendev.org/openstack/xstatic-bootstrap-datepicker refs/changes/93/113893/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.vi.js', 'xstatic/pkg/bootstrap_datepicker/__init__.py', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ca.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.hr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.el.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pt-BR.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.zh-CN.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.tr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sv.js', 'xstatic/pkg/bootstrap_datepicker/data/bootstrap-datepicker.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.es.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ua.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.da.js', 'xstatic/pkg/bootstrap_datepicker/data/datepicker3.css', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.de.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.cy.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.gl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.no.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.kr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pt.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ru.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fr.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.pl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.rs-latin.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ka.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.id.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ja.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.it.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sq.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.zh-TW.js', 'xstatic/pkg/bootstrap_datepicker/data/datepicker.css', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.lv.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.th.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nl-BE.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.mk.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.nb.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.is.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.he.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ms.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sl.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.az.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.cs.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ar.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.hu.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.rs.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.ro.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.lt.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fi.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.kk.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.et.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sw.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.bg.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.fa.js', 'xstatic/pkg/bootstrap_datepicker/data/locales/bootstrap-datepicker.sk.js']",55,db01e236aa7fb9f1dcefcc49e95e7f9a4e776972,bug/113893,"/** * Slovak translation for bootstrap-datepicker * Marek Lichtner <marek@licht.sk> * Fixes by Michal Remi <michal.remis@gmail.com> */ ;(function($){ $.fn.datepicker.dates[""sk""] = { days: [""Nedea"", ""Pondelok"", ""Utorok"", ""Streda"", ""tvrtok"", ""Piatok"", ""Sobota"", ""Nedea""], daysShort: [""Ned"", ""Pon"", ""Uto"", ""Str"", ""tv"", ""Pia"", ""Sob"", ""Ned""], daysMin: [""Ne"", ""Po"", ""Ut"", ""St"", ""t"", ""Pia"", ""So"", ""Ne""], months: [""Janur"", ""Februr"", ""Marec"", ""Aprl"", ""Mj"", ""Jn"", ""Jl"", ""August"", ""September"", ""Oktber"", ""November"", ""December""], monthsShort: [""Jan"", ""Feb"", ""Mar"", ""Apr"", ""Mj"", ""Jn"", ""Jl"", ""Aug"", ""Sep"", ""Okt"", ""Nov"", ""Dec""], today: ""Dnes"" }; }(jQuery)); ",,15233,654
openstack%2Fproject-config~master~I454103b5d5262d4aaeb6671b79892be7993bb2a6,openstack/project-config,master,I454103b5d5262d4aaeb6671b79892be7993bb2a6,Run gate-{name}-docs on infra-publish-jobs,MERGED,2014-09-30 07:46:58.000000000,2014-10-07 17:14:32.000000000,2014-10-07 17:14:32.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-09-30 07:46:58.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5d03341c8e8400febb131148de38111e42536b7a', 'message': ""Run gate-{name}-docs on infra-publish-jobs\n\nThe gate-{name}-docs publishes a draft copy of the docs for reviewers.\nPublished draft documents clearly aren't needed for gate jobs, however\nthis test will ensure that the docs still build correctly when merged.\n\nChange-Id: I454103b5d5262d4aaeb6671b79892be7993bb2a6\n""}]",0,124966,5d03341c8e8400febb131148de38111e42536b7a,13,9,1,7069,,,0,"Run gate-{name}-docs on infra-publish-jobs

The gate-{name}-docs publishes a draft copy of the docs for reviewers.
Published draft documents clearly aren't needed for gate jobs, however
this test will ensure that the docs still build correctly when merged.

Change-Id: I454103b5d5262d4aaeb6671b79892be7993bb2a6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/124966/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5d03341c8e8400febb131148de38111e42536b7a,infra_manual, gate: - 'gate-{name}-docs', gate: - noop,2,2
openstack%2Foslo.utils~master~I4c446952fc904c1231cccbda1cd4d2a4cce5c55f,openstack/oslo.utils,master,I4c446952fc904c1231cccbda1cd4d2a4cce5c55f,Make safe_encode func case-insensitive,MERGED,2014-09-05 21:45:42.000000000,2014-10-07 17:13:23.000000000,2014-10-07 17:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6854}, {'_account_id': 7491}, {'_account_id': 7536}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-09-05 21:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/5d38e790b0898c16dde3dd480492a2796790b160', 'message': ""Make safe_encode func case-insensitive\n\nFunction 'safe_encode ' in 'encodeutils' module treats 'UTF-8' and 'utf-8'\nencodings as different.\nBut it should understand different aliases, that have different text cases.\n\nChange-Id: I4c446952fc904c1231cccbda1cd4d2a4cce5c55f\nCloses-Bug: #1342050\n""}, {'number': 2, 'created': '2014-09-13 20:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/b0315938958cce4af1ec1b22c89fdba56aed2cd6', 'message': ""Make safe_encode func case-insensitive\n\nFunction 'safe_encode ' in 'encodeutils' module treats 'UTF-8' and 'utf-8'\nencodings as different.\nBut it should understand different aliases, that have different text cases.\n\nChange-Id: I4c446952fc904c1231cccbda1cd4d2a4cce5c55f\nCloses-Bug: #1342050\n""}, {'number': 3, 'created': '2014-09-17 21:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4cc229e94a08a81553db823a6f890d99a6b1f425', 'message': ""Make safe_encode func case-insensitive\n\nFunction 'safe_encode ' in 'encodeutils' module treats 'UTF-8' and 'utf-8'\nencodings as different.\nBut it should understand different aliases, that have different text cases.\nIt allows us avoid redundant coding/decoding.\nAlso added unittests.\n\nChange-Id: I4c446952fc904c1231cccbda1cd4d2a4cce5c55f\nCloses-Bug: #1342050\n""}, {'number': 4, 'created': '2014-09-17 21:39:06.000000000', 'files': ['tests/tests_encodeutils.py', 'oslo/utils/encodeutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f02f8df952275f6925460945be75373c8951363f', 'message': ""Make safe_encode func case-insensitive\n\nFunction 'safe_encode ' in 'encodeutils' module treats 'UTF-8' and 'utf-8'\nencodings as different.\nBut it should understand different aliases, that have different text cases.\nIt allows us avoid redundant coding/decoding.\nAlso added unittests.\n\nChange-Id: I4c446952fc904c1231cccbda1cd4d2a4cce5c55f\nCloses-Bug: #1342050\n""}]",2,119489,f02f8df952275f6925460945be75373c8951363f,19,7,4,8851,,,0,"Make safe_encode func case-insensitive

Function 'safe_encode ' in 'encodeutils' module treats 'UTF-8' and 'utf-8'
encodings as different.
But it should understand different aliases, that have different text cases.
It allows us avoid redundant coding/decoding.
Also added unittests.

Change-Id: I4c446952fc904c1231cccbda1cd4d2a4cce5c55f
Closes-Bug: #1342050
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/89/119489/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests_encodeutils.py', 'oslo/utils/encodeutils.py']",2,5d38e790b0898c16dde3dd480492a2796790b160,bug/1342050," # Avoid case issues in comparisons if hasattr(incoming, 'lower'): incoming = incoming.lower() if hasattr(encoding, 'lower'): encoding = encoding.lower() if isinstance(text, six.text_type) and encoding != incoming:"," if isinstance(text, six.text_type):",57,14
openstack%2Ftempest~master~If0662b72d10b91eb4284db04189d7f7cf3783f66,openstack/tempest,master,If0662b72d10b91eb4284db04189d7f7cf3783f66,"DON""T REVIEW",ABANDONED,2014-09-22 21:23:26.000000000,2014-10-07 17:12:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-09-22 21:23:26.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/29e568a9d6ff5aab547eb087e9f1744f75d07422', 'message': 'DON""T REVIEW\n\nChange-Id: If0662b72d10b91eb4284db04189d7f7cf3783f66\n'}]",0,123251,29e568a9d6ff5aab547eb087e9f1744f75d07422,3,1,1,4395,,,0,"DON""T REVIEW

Change-Id: If0662b72d10b91eb4284db04189d7f7cf3783f66
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/123251/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,29e568a9d6ff5aab547eb087e9f1744f75d07422,," pass #delete_thing(*args, **kwargs) #if wait_on_delete: # self.addCleanup(self.servers_client.wait_for_server_termination, # server['id']) #self.addCleanup_with_wait( # waiter_callable=self.servers_client.wait_for_server_termination, # thing_id=server['id'], thing_id_param='server_id', # cleanup_callable=self.delete_wrapper, # cleanup_args=[self.servers_client.delete_server, server['id']])# self.addCleanup(self.delete_wrapper, # _client.delete_security_group_rule, # sg_rule['id'])# self.addCleanup(self.delete_wrapper, # self.security_groups_client.delete_security_group, # secgroup['id'])# self.addCleanup(self.delete_wrapper, network.delete) #self.addCleanup(self.delete_wrapper, subnet.delete)# self.addCleanup(self.delete_wrapper, floating_ip.delete) #self.addCleanup(self.delete_wrapper, sg_rule) #self.addCleanup(self.delete_wrapper, secgroup)"," delete_thing(*args, **kwargs) if wait_on_delete: self.addCleanup(self.servers_client.wait_for_server_termination, server['id']) self.addCleanup_with_wait( waiter_callable=self.servers_client.wait_for_server_termination, thing_id=server['id'], thing_id_param='server_id', cleanup_callable=self.delete_wrapper, cleanup_args=[self.servers_client.delete_server, server['id']]) self.addCleanup(self.delete_wrapper, _client.delete_security_group_rule, sg_rule['id']) self.addCleanup(self.delete_wrapper, self.security_groups_client.delete_security_group, secgroup['id']) self.addCleanup(self.delete_wrapper, network.delete) self.addCleanup(self.delete_wrapper, subnet.delete) self.addCleanup(self.delete_wrapper, floating_ip.delete) self.addCleanup(self.delete_wrapper, sg_rule) self.addCleanup(self.delete_wrapper, secgroup)",21,20
openstack%2Fkolla~master~I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd,openstack/kolla,master,I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd,"use ""crux"" for creating users/endpoints",MERGED,2014-10-03 20:48:07.000000000,2014-10-07 17:10:29.000000000,2014-10-07 04:12:59.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 6836}, {'_account_id': 8745}]","[{'number': 1, 'created': '2014-10-03 20:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3111e959d3fa7f93fad13864db0b0409d19883e8', 'message': 'use ""crux"" for creating users/endpoints\n\nthis patch introduces the ""crux"" tool for creating keystone\nusers, services, and endpoints in an idempotent fashion.  E.g., to\ncreate a user that doesn\'t exist:\n\n    $ crux user-create -n lars -t lars -p secret\n    creating new tenant\n    created tenant lars (d74cec5023c4428da533066bb11943db)\n    creating new user lars\n    created user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nAnd performing the same operation a second time:\n\n    $ crux user-create -n lars -t lars -p secret\n    using existing tenant lars (d74cec5023c4428da533066bb11943db)\n    using existing user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nThe behavior is similar for creating keystone endpoints.\n\nChange-Id: I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd\n'}, {'number': 2, 'created': '2014-10-03 21:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dc03db0673f3875a4cdfecfeeb94276231f6a53f', 'message': 'use ""crux"" for creating users/endpoints\n\nthis patch introduces the ""crux"" [1] tool for creating keystone\nusers, services, and endpoints in an idempotent fashion.  E.g., to\ncreate a user that doesn\'t exist:\n\n    $ crux user-create -n lars -t lars -p secret\n    creating new tenant\n    created tenant lars (d74cec5023c4428da533066bb11943db)\n    creating new user lars\n    created user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nAnd performing the same operation a second time:\n\n    $ crux user-create -n lars -t lars -p secret\n    using existing tenant lars (d74cec5023c4428da533066bb11943db)\n    using existing user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nThe behavior is similar for creating keystone endpoints.\n\n[1]: https://github.com/larsks/crux\n\nChange-Id: I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd\n'}, {'number': 3, 'created': '2014-10-04 15:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f888ca26b564dbd52bcede32124c414ef7f40c3c', 'message': 'use ""crux"" for creating users/endpoints\n\nthis patch introduces the ""crux"" [1] tool for creating keystone\nusers, services, and endpoints in an idempotent fashion.  E.g., to\ncreate a user that doesn\'t exist:\n\n    $ crux user-create -n lars -t lars -p secret\n    creating new tenant\n    created tenant lars (d74cec5023c4428da533066bb11943db)\n    creating new user lars\n    created user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nAnd performing the same operation a second time:\n\n    $ crux user-create -n lars -t lars -p secret\n    using existing tenant lars (d74cec5023c4428da533066bb11943db)\n    using existing user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nThe behavior is similar for creating keystone endpoints.\n\n[1]: https://github.com/larsks/crux\n\nChange-Id: I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd\n'}, {'number': 4, 'created': '2014-10-06 17:26:40.000000000', 'files': ['docker/keystone/start.sh', 'docker/keystone/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9414ab5cadea0cfd958cc7dfc0041eb758f452e6', 'message': 'use ""crux"" for creating users/endpoints\n\nthis patch introduces the ""crux"" [1] tool for creating keystone\nusers, services, and endpoints in an idempotent fashion.  E.g., to\ncreate a user that doesn\'t exist:\n\n    $ crux user-create -n lars -t lars -p secret\n    creating new tenant\n    created tenant lars (d74cec5023c4428da533066bb11943db)\n    creating new user lars\n    created user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nAnd performing the same operation a second time:\n\n    $ crux user-create -n lars -t lars -p secret\n    using existing tenant lars (d74cec5023c4428da533066bb11943db)\n    using existing user lars (adf2c2d92e894a3d90a403c5885f192e)\n\nThe behavior is similar for creating keystone endpoints.\n\n[1]: https://github.com/larsks/crux\n\nChange-Id: I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd\n'}]",3,126067,9414ab5cadea0cfd958cc7dfc0041eb758f452e6,21,6,4,8745,,,0,"use ""crux"" for creating users/endpoints

this patch introduces the ""crux"" [1] tool for creating keystone
users, services, and endpoints in an idempotent fashion.  E.g., to
create a user that doesn't exist:

    $ crux user-create -n lars -t lars -p secret
    creating new tenant
    created tenant lars (d74cec5023c4428da533066bb11943db)
    creating new user lars
    created user lars (adf2c2d92e894a3d90a403c5885f192e)

And performing the same operation a second time:

    $ crux user-create -n lars -t lars -p secret
    using existing tenant lars (d74cec5023c4428da533066bb11943db)
    using existing user lars (adf2c2d92e894a3d90a403c5885f192e)

The behavior is similar for creating keystone endpoints.

[1]: https://github.com/larsks/crux

Change-Id: I694e0c1bdcdde595e1af2ee8ef5d0f239a9ad4cd
",git fetch https://review.opendev.org/openstack/kolla refs/changes/67/126067/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/keystone/start.sh', 'docker/keystone/Dockerfile']",2,3111e959d3fa7f93fad13864db0b0409d19883e8,larsks/crux,RUN yum -y install dnf dnf-plugins-core; yum clean all RUN dnf copr enable -y larsks/crux crux \ ; yum clean all, && yum clean all,23,27
openstack%2Foslo-incubator~master~I6b720c462b8a562e3276f9e64d723bc36fb5c842,openstack/oslo-incubator,master,I6b720c462b8a562e3276f9e64d723bc36fb5c842,Fix custom virtualenv directory for tempest,MERGED,2014-09-16 15:16:27.000000000,2014-10-07 16:55:39.000000000,2014-10-07 16:55:38.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6524}, {'_account_id': 6928}, {'_account_id': 8767}, {'_account_id': 9107}, {'_account_id': 12632}]","[{'number': 1, 'created': '2014-09-16 15:16:27.000000000', 'files': ['tools/install_venv.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3887206823a6ac4d44cfbbcaa3ff39080cf69d00', 'message': 'Fix custom virtualenv directory for tempest\n\nRelated to bug: 1370086\nShell environment is checked with low case,\nbut should be with upper case. See check in script\ntools/with_env.sh.\n\nChange-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842\n'}]",0,121901,3887206823a6ac4d44cfbbcaa3ff39080cf69d00,10,13,1,10969,,,0,"Fix custom virtualenv directory for tempest

Related to bug: 1370086
Shell environment is checked with low case,
but should be with upper case. See check in script
tools/with_env.sh.

Change-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/01/121901/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_venv.py'],1,3887206823a6ac4d44cfbbcaa3ff39080cf69d00,bug/1370086, if os.environ.get('VENV'): venv = os.environ['VENV'], if os.environ.get('venv'): venv = os.environ['venv'],2,2
openstack%2Fceilometer~proposed%2Fjuno~Ib53755112e4757aa53ab60079f3c555e21a72b63,openstack/ceilometer,proposed/juno,Ib53755112e4757aa53ab60079f3c555e21a72b63,Include a 'node' key and value in ipmi metadata,MERGED,2014-10-07 12:04:42.000000000,2014-10-07 16:40:26.000000000,2014-10-07 16:40:26.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 3012}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-07 12:04:42.000000000', 'files': ['ceilometer/ipmi/notifications/ironic.py', 'ceilometer/tests/ipmi/pollsters/test_sensor.py', 'ceilometer/tests/ipmi/pollsters/test_node.py', 'ceilometer/tests/ipmi/notifications/test_ironic.py', 'ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/tests/ipmi/pollsters/base.py', 'ceilometer/ipmi/pollsters/node.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cac21417118c9aa72705088f8d04ff5250d93123', 'message': ""Include a 'node' key and value in ipmi metadata\n\nThe ipmi meters use resource_ids which make it challenging\nto select information for all the sensors of a particular type.\nThis change adds metadata that identifies the physical node on\nwhich a sensor exists.\n\nThere are still remaining issues with the naming of ipmi and\nsensor-related meters that will need to be addressed separately.\n\nCloses-Bug: 1377157\nChange-Id: Ib53755112e4757aa53ab60079f3c555e21a72b63\n(cherry picked from commit 3b20fa08527170aaca38253277feedf0f2d11217)\n""}]",0,126538,cac21417118c9aa72705088f8d04ff5250d93123,9,5,1,2284,,,0,"Include a 'node' key and value in ipmi metadata

The ipmi meters use resource_ids which make it challenging
to select information for all the sensors of a particular type.
This change adds metadata that identifies the physical node on
which a sensor exists.

There are still remaining issues with the naming of ipmi and
sensor-related meters that will need to be addressed separately.

Closes-Bug: 1377157
Change-Id: Ib53755112e4757aa53ab60079f3c555e21a72b63
(cherry picked from commit 3b20fa08527170aaca38253277feedf0f2d11217)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/38/126538/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/ipmi/notifications/ironic.py', 'ceilometer/tests/ipmi/pollsters/test_sensor.py', 'ceilometer/tests/ipmi/pollsters/test_node.py', 'ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/tests/ipmi/notifications/test_ironic.py', 'ceilometer/tests/ipmi/pollsters/base.py', 'ceilometer/ipmi/pollsters/node.py']",7,cac21417118c9aa72705088f8d04ff5250d93123,, metadata = { 'node': CONF.host } resource_metadata=metadata), resource_metadata=None),33,10
openstack%2Fceilometer~proposed%2Fjuno~Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623,openstack/ceilometer,proposed/juno,Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623,clean path in swift middleware,MERGED,2014-10-07 12:03:25.000000000,2014-10-07 16:34:16.000000000,2014-10-07 16:34:15.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-07 12:03:25.000000000', 'files': ['ceilometer/objectstore/swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e6078929fd3235eab7f2b5f136a5c9df347bf94c', 'message': 'clean path in swift middleware\n\nthe path also requires encoding as syslogs still show errors.\n\nCloses-Bug: #1369124\nChange-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623\n(cherry picked from commit dbe8c8b20f4231841d2086fbfd278f3a4cde8324)\n'}]",0,126537,e6078929fd3235eab7f2b5f136a5c9df347bf94c,8,5,1,2284,,,0,"clean path in swift middleware

the path also requires encoding as syslogs still show errors.

Closes-Bug: #1369124
Change-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623
(cherry picked from commit dbe8c8b20f4231841d2086fbfd278f3a4cde8324)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/37/126537/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/objectstore/swift_middleware.py'],1,e6078929fd3235eab7f2b5f136a5c9df347bf94c,,import six.moves.urllib.parse as urlparse path = urlparse.quote(env['PATH_INFO']), path = env['PATH_INFO'],2,1
openstack%2Fceilometer~proposed%2Fjuno~Iaf739dc2deb7d4b09bf477be60de4df8c4fcf5c0,openstack/ceilometer,proposed/juno,Iaf739dc2deb7d4b09bf477be60de4df8c4fcf5c0,Fix OrderedDict usage for Python 2.6,MERGED,2014-10-07 12:06:18.000000000,2014-10-07 16:33:57.000000000,2014-10-07 16:33:56.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 3012}, {'_account_id': 7102}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-07 12:06:18.000000000', 'files': ['ceilometer/ipmi/platform/intel_node_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fc22a04cfbab9a868347bea78a0b55c2b3316ef1', 'message': 'Fix OrderedDict usage for Python 2.6\n\n""import collections"" also works on Python 2.6 but\ncollections.OrderedDict() is not available so the current check is\nwrong. Using a function to get an OrderedDict() instance works fine for\nthat.\n\nCloses-Bug: #1375568\nChange-Id: Iaf739dc2deb7d4b09bf477be60de4df8c4fcf5c0\n(cherry picked from commit 7212f7dc92c1c6fd5d7e36fc270b74efec412d72)\n'}]",0,126539,fc22a04cfbab9a868347bea78a0b55c2b3316ef1,8,5,1,2284,,,0,"Fix OrderedDict usage for Python 2.6

""import collections"" also works on Python 2.6 but
collections.OrderedDict() is not available so the current check is
wrong. Using a function to get an OrderedDict() instance works fine for
that.

Closes-Bug: #1375568
Change-Id: Iaf739dc2deb7d4b09bf477be60de4df8c4fcf5c0
(cherry picked from commit 7212f7dc92c1c6fd5d7e36fc270b74efec412d72)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/39/126539/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/ipmi/platform/intel_node_manager.py'],1,fc22a04cfbab9a868347bea78a0b55c2b3316ef1,," def get_ordereddict(): """"""A fix for py26 not having ordereddict."""""" try: import collections return collections.OrderedDict except AttributeError: import ordereddict return ordereddict.OrderedDict OrderedDict = get_ordereddict()BMC_INFO_TEMPLATE = OrderedDict()NM_STATISTICS_TEMPLATE = OrderedDict()NM_GET_DEVICE_ID_TEMPLATE = OrderedDict()",try: import collections as ordereddict except ImportError: import ordereddictBMC_INFO_TEMPLATE = ordereddict.OrderedDict()NM_STATISTICS_TEMPLATE = ordereddict.OrderedDict()NM_GET_DEVICE_ID_TEMPLATE = ordereddict.OrderedDict(),14,7
openstack%2Fproject-config~master~I635e9fabd3f643803fa00ea4cf26ef2e6fb95526,openstack/project-config,master,I635e9fabd3f643803fa00ea4cf26ef2e6fb95526,Add neutron-drivers team for approving specs.,MERGED,2014-10-07 15:11:11.000000000,2014-10-07 16:30:03.000000000,2014-10-07 16:30:03.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-10-07 15:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/199da70f96cd380bb9b458f0450c51dff1d4dd6f', 'message': 'Add neutron-drivers team for approving specs.\n\nNeutron is creating a separate team to approve specs, this commit\nadds the group in gerrit.\n\nChange-Id: I635e9fabd3f643803fa00ea4cf26ef2e6fb95526\n'}, {'number': 2, 'created': '2014-10-07 15:12:59.000000000', 'files': ['gerrit/acls/openstack/neutron-specs.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/45f565a49d9707076c998724d347f052b90951a3', 'message': 'Add neutron-drivers team for approving specs.\n\nNeutron is creating a separate team to approve specs, this commit\nadds the group in gerrit.\n\nChange-Id: I635e9fabd3f643803fa00ea4cf26ef2e6fb95526\n'}]",0,126588,45f565a49d9707076c998724d347f052b90951a3,8,3,2,105,,,0,"Add neutron-drivers team for approving specs.

Neutron is creating a separate team to approve specs, this commit
adds the group in gerrit.

Change-Id: I635e9fabd3f643803fa00ea4cf26ef2e6fb95526
",git fetch https://review.opendev.org/openstack/project-config refs/changes/88/126588/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/neutron-specs.config'],1,199da70f96cd380bb9b458f0450c51dff1d4dd6f,neutron-drivers,label-Workflow = -1..+1 group neutron-drivers-core,label-Workflow = -1..+1 group neutron-specs-core,1,1
openstack%2Fkolla~master~Ibb0263a133c28a104563df431870a9effe584012,openstack/kolla,master,Ibb0263a133c28a104563df431870a9effe584012,renamed keystone services,MERGED,2014-10-07 01:03:22.000000000,2014-10-07 16:21:55.000000000,2014-10-07 16:21:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-07 01:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c8945ef0f480366443eabab7f03ae6a1cfe30531', 'message': 'renamed keystone services\n\nThis renames the keystone services so that they are named by function,\nrather than port number (which would be confusing if they were running\non a different port).\n\nChange-Id: Ibb0263a133c28a104563df431870a9effe584012\n'}, {'number': 2, 'created': '2014-10-07 15:11:30.000000000', 'files': ['docker/keystone/keystone.json', 'docker/swift/swift-container/start.sh', 'docker/keystone/start.sh', 'docker/glance/glance-registry/start.sh', 'docker/nova-compute/nova-compute/start.sh', 'docker/keystone/keystone-public-service.json', 'docker/glance/glance-base/config-glance.sh', 'docker/cinder/start.sh', 'docker/swift/swift-account/start.sh', 'docker/heat/heat-engine/start.sh', 'docker/swift/swift-object/start.sh', 'docker/keystone/keystone-admin-service.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3c080f9e62ffc6c75c64ba0d86167fbeb2d83a35', 'message': 'renamed keystone services\n\nThis renames the keystone services so that they are named by function,\nrather than port number (which would be confusing if they were running\non a different port).\n\nChange-Id: Ibb0263a133c28a104563df431870a9effe584012\n'}]",0,126453,3c080f9e62ffc6c75c64ba0d86167fbeb2d83a35,12,3,2,8745,,,0,"renamed keystone services

This renames the keystone services so that they are named by function,
rather than port number (which would be confusing if they were running
on a different port).

Change-Id: Ibb0263a133c28a104563df431870a9effe584012
",git fetch https://review.opendev.org/openstack/kolla refs/changes/53/126453/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/keystone/keystone-public-service.json', 'docker/keystone/keystone-admin-service.json']",2,c8945ef0f480366443eabab7f03ae6a1cfe30531,larsks/rename-keystone-services," ""id"": ""keystone-admin"","," ""id"": ""keystonemaster-35357"",",2,2
openstack%2Foslo-incubator~stable%2Ficehouse~Ie0caf32469126dd9feb44867adf27acb6e383958,openstack/oslo-incubator,stable/icehouse,Ie0caf32469126dd9feb44867adf27acb6e383958,Mask passwords in exceptions and error messages,MERGED,2014-10-01 18:53:37.000000000,2014-10-07 16:18:49.000000000,2014-10-07 16:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6601}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-10-01 18:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/35947c3f657323445cb2ff8a19c2949991488c61', 'message': 'Mask passwords in exceptions and error messages\n\nWhen a ProcessExecutionError is thrown by processutils.ssh_execute(),\nthe exception may contain information such as password. Upstream\napplications that just log the message (as several appear to do) could\ninadvertently expose these passwords to a user with read access to the\nlog files. It is therefore considered prudent to invoke\nstrutils.mask_password() on the command, stdout and stderr in the\nexception. A test case has been added to ensure that all three are\nproperly masked.\n\nAn earlier commit (I173dfb865e84eb7dee54a22c76db1e4f125a0a8a) failed\nto address ssh_execute(). This change set addresses ssh_execute.\n\nSubmitted to oslo.concurrency in\nI0db9e98cbeb2a5e6f9ae0074f24717aa91cfc238\n\nOSSA is aware of this change request.\n\nChange-Id: Ie0caf32469126dd9feb44867adf27acb6e383958\nCloses-Bug: #1343604\n(cherry-picked from 6a60f84258c2be3391541dbe02e30b8e836f6c22)\n'}, {'number': 2, 'created': '2014-10-06 14:52:35.000000000', 'files': ['tests/unit/test_processutils.py', 'openstack/common/processutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3cf7961cda18fc2a14d5433f3d142a626ce016c5', 'message': 'Mask passwords in exceptions and error messages\n\nWhen a ProcessExecutionError is thrown by processutils.ssh_execute(),\nthe exception may contain information such as password. Upstream\napplications that just log the message (as several appear to do) could\ninadvertently expose these passwords to a user with read access to the\nlog files. It is therefore considered prudent to invoke\nstrutils.mask_password() on the command, stdout and stderr in the\nexception. A test case has been added to ensure that all three are\nproperly masked.\n\nAn earlier commit (I173dfb865e84eb7dee54a22c76db1e4f125a0a8a) failed\nto address ssh_execute(). This change set addresses ssh_execute.\n\nSubmitted to oslo.concurrency in\nI0db9e98cbeb2a5e6f9ae0074f24717aa91cfc238\n\nOSSA is aware of this change request.\n\nChange-Id: Ie0caf32469126dd9feb44867adf27acb6e383958\nCloses-Bug: #1377981\n(cherry-picked from 6a60f84258c2be3391541dbe02e30b8e836f6c22)\n'}]",0,125458,3cf7961cda18fc2a14d5433f3d142a626ce016c5,17,4,2,9311,,,0,"Mask passwords in exceptions and error messages

When a ProcessExecutionError is thrown by processutils.ssh_execute(),
the exception may contain information such as password. Upstream
applications that just log the message (as several appear to do) could
inadvertently expose these passwords to a user with read access to the
log files. It is therefore considered prudent to invoke
strutils.mask_password() on the command, stdout and stderr in the
exception. A test case has been added to ensure that all three are
properly masked.

An earlier commit (I173dfb865e84eb7dee54a22c76db1e4f125a0a8a) failed
to address ssh_execute(). This change set addresses ssh_execute.

Submitted to oslo.concurrency in
I0db9e98cbeb2a5e6f9ae0074f24717aa91cfc238

OSSA is aware of this change request.

Change-Id: Ie0caf32469126dd9feb44867adf27acb6e383958
Closes-Bug: #1377981
(cherry-picked from 6a60f84258c2be3391541dbe02e30b8e836f6c22)
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/58/125458/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_processutils.py', 'openstack/common/processutils.py']",2,35947c3f657323445cb2ff8a19c2949991488c61,bug/1343604," sanitized_cmd = strutils.mask_password(cmd) LOG.debug('Running cmd (SSH): %s', sanitized_cmd) sanitized_stdout = strutils.mask_password(stdout) sanitized_stderr = strutils.mask_password(stderr) stdout=sanitized_stdout, stderr=sanitized_stderr, cmd=sanitized_cmd) return (sanitized_stdout, sanitized_stderr)"," LOG.debug('Running cmd (SSH): %s', cmd) stdout=stdout, stderr=stderr, cmd=cmd) return (stdout, stderr)",65,5
openstack%2Fkolla~master~I229d04c89aa13cb6cc2e1c33a0a7b21e1c6e9caa,openstack/kolla,master,I229d04c89aa13cb6cc2e1c33a0a7b21e1c6e9caa,use renamed mariadb services,MERGED,2014-10-07 15:00:46.000000000,2014-10-07 16:15:31.000000000,2014-10-07 16:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5792}]","[{'number': 1, 'created': '2014-10-07 15:00:46.000000000', 'files': ['docker/swift/swift-container/start.sh', 'docker/swift/swift-account/start.sh', 'docker/keystone/start.sh', 'docker/glance/glance-registry/start.sh', 'docker/nova-compute/nova-compute/start.sh', 'docker/heat/heat-engine/start.sh', 'docker/swift/swift-object/start.sh', 'docker/glance/glance-base/config-glance.sh', 'docker/cinder/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/068face6fa52d19d421913b9969b291500a39c6d', 'message': ""use renamed mariadb services\n\nThis patch updates all the json files that reference the mariadb service\nvariables to ues the new names.\n\nLabelling things foo-master crept into this repository from the\nkubernetes guestbook example (which has redis-master and redis-slaves).\nWe're not running clustered software at the moment so these labels are\nunnecessary.\n\nChange-Id: I229d04c89aa13cb6cc2e1c33a0a7b21e1c6e9caa\n""}]",0,126578,068face6fa52d19d421913b9969b291500a39c6d,7,3,1,8745,,,0,"use renamed mariadb services

This patch updates all the json files that reference the mariadb service
variables to ues the new names.

Labelling things foo-master crept into this repository from the
kubernetes guestbook example (which has redis-master and redis-slaves).
We're not running clustered software at the moment so these labels are
unnecessary.

Change-Id: I229d04c89aa13cb6cc2e1c33a0a7b21e1c6e9caa
",git fetch https://review.opendev.org/openstack/kolla refs/changes/78/126578/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/swift/swift-container/start.sh', 'docker/swift/swift-account/start.sh', 'docker/keystone/start.sh', 'docker/glance/glance-registry/start.sh', 'docker/nova-compute/nova-compute/start.sh', 'docker/heat/heat-engine/start.sh', 'docker/swift/swift-object/start.sh', 'docker/glance/glance-base/config-glance.sh', 'docker/cinder/start.sh']",9,068face6fa52d19d421913b9969b291500a39c6d,larsks/rename-mariadb-services,mysql -h ${MARIADB_PORT_3306_TCP_ADDR} -u root \,mysql -h ${MARIADBMASTER_PORT_3306_TCP_ADDR} -u root \,11,11
openstack%2Fdevstack~master~I6092c26836320fab607eb9cd07f63189a9ba1ddd,openstack/devstack,master,I6092c26836320fab607eb9cd07f63189a9ba1ddd,Refactor swift config services,MERGED,2014-10-04 06:15:51.000000000,2014-10-07 16:13:03.000000000,2014-10-04 19:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-04 06:15:51.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6c585d739d918ae563a6291a8661fd82b872a93a', 'message': 'Refactor swift config services\n\nMake the sed the command to change the recon_cache_path into the renamed\ngenerate_swift_config_services\n\nChange-Id: I6092c26836320fab607eb9cd07f63189a9ba1ddd\n'}]",0,126124,6c585d739d918ae563a6291a8661fd82b872a93a,9,5,1,866,,,0,"Refactor swift config services

Make the sed the command to change the recon_cache_path into the renamed
generate_swift_config_services

Change-Id: I6092c26836320fab607eb9cd07f63189a9ba1ddd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/24/126124/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,6c585d739d918ae563a6291a8661fd82b872a93a,consolidate-swift-config-services,"function generate_swift_config_services { # Using a sed and not iniset/iniuncomment because we want to a global # modification and make sure it works for new sections. sed -i -e ""s,#[ ]*recon_cache_path .*,recon_cache_path = ${SWIFT_DATA_DIR}/cache,"" ${swift_node_config} generate_swift_config_services ${swift_node_config} ${node_number} $(( OBJECT_PORT_BASE + 10 * (node_number - 1) )) object generate_swift_config_services ${swift_node_config} ${node_number} $(( CONTAINER_PORT_BASE + 10 * (node_number - 1) )) container generate_swift_config_services ${swift_node_config} ${node_number} $(( ACCOUNT_PORT_BASE + 10 * (node_number - 1) )) account","function generate_swift_config { generate_swift_config ${swift_node_config} ${node_number} $(( OBJECT_PORT_BASE + 10 * (node_number - 1) )) object # Using a sed and not iniset/iniuncomment because we want to a global # modification and make sure it works for new sections. sed -i -e ""s,#[ ]*recon_cache_path .*,recon_cache_path = ${SWIFT_DATA_DIR}/cache,"" ${swift_node_config} generate_swift_config ${swift_node_config} ${node_number} $(( CONTAINER_PORT_BASE + 10 * (node_number - 1) )) container sed -i -e ""s,#[ ]*recon_cache_path .*,recon_cache_path = ${SWIFT_DATA_DIR}/cache,"" ${swift_node_config} generate_swift_config ${swift_node_config} ${node_number} $(( ACCOUNT_PORT_BASE + 10 * (node_number - 1) )) account sed -i -e ""s,#[ ]*recon_cache_path .*,recon_cache_path = ${SWIFT_DATA_DIR}/cache,"" ${swift_node_config}",8,9
openstack%2Ffuel-library~master~Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8,openstack/fuel-library,master,Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8,Add ipset package installation,ABANDONED,2014-09-25 10:19:16.000000000,2014-10-07 16:07:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-25 10:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c6a3f937aca6efb4b6d0a04f5aaa3c167eee4b7f', 'message': 'Add ipset package installation\n\nThe ipset package is required for Neutron security groups implementation\n\nChange-Id: Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8\nRelated-bug: #1371585\n'}, {'number': 2, 'created': '2014-09-26 07:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/641433bee876a8e4227c1dc69599f420bd44c560', 'message': 'Add ipset package installation\n\nThe ipset package is required for Neutron security groups implementation\n\nChange-Id: Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8\nRelated-bug: #1371585\n'}, {'number': 3, 'created': '2014-09-30 13:47:34.000000000', 'files': ['deployment/puppet/neutron/manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f9e672c8e37c10122694d781540f47a6efbcdd09', 'message': 'Add ipset package installation\n\n\nThe ipset package is required for Neutron security groups implementation\n\nChange-Id: Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8\nRelated-bug: #1371585\n'}]",0,123998,f9e672c8e37c10122694d781540f47a6efbcdd09,25,8,3,7604,,,0,"Add ipset package installation


The ipset package is required for Neutron security groups implementation

Change-Id: Ie5e89d62b485bd839c71ad60008c8c45b6ab6cc8
Related-bug: #1371585
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/123998/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/firewall/manifests/linux.pp'],1,c6a3f937aca6efb4b6d0a04f5aaa3c167eee4b7f,ipset,"# Installs the `iptables` and `ipset` packages for Linux operating systems # and includes the appropriate sub-class for any distribution specific services # and additional packages. package { 'ipset': ensure => present, } ",# Installs the `iptables` package for Linux operating systems and includes # the appropriate sub-class for any distribution specific services and # additional packages.,7,3
openstack%2Fha-guide~master~I20299226b45bee0af220e21f01da3ff789b80897,openstack/ha-guide,master,I20299226b45bee0af220e21f01da3ff789b80897,"Improve chapter ""HA using active/active - OpenStack network nodes""",MERGED,2014-09-22 19:19:45.000000000,2014-10-07 16:02:31.000000000,2014-10-07 16:02:30.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-22 19:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/bedcb8a6db74b6ea5d57a2f99961736a5f7db50d', 'message': 'Improve XML syntax and formatting of files in ha_aa_network\n\nChange-Id: I20299226b45bee0af220e21f01da3ff789b80897\n'}, {'number': 2, 'created': '2014-09-22 19:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/6f896eb2251de27aa83318c3f00e8a414dc71a7f', 'message': 'Improve XML syntax and formatting of files in ha_aa_network and ch_ha_aa_network.xml\n\nChange-Id: I20299226b45bee0af220e21f01da3ff789b80897\n'}, {'number': 3, 'created': '2014-09-22 19:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/7c82e7f2cbf2c3988eeaf340d5241498c9f26566', 'message': 'Improve files in ha_aa_network and ch_ha_aa_network.xml\n\n* improve XML syntax\n* improve formatting\n* neutron --> Neutron\n* lbaas --> LBaaS\n\nChange-Id: I20299226b45bee0af220e21f01da3ff789b80897\n'}, {'number': 4, 'created': '2014-09-22 20:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/23885970ff6eb7cd7008bf4f29c0eb6c9f908c1a', 'message': 'Improve chapter ""HA using active/active - OpenStack network nodes""\n\n* improve XML syntax\n* improve formatting\n* neutron --> Neutron\n* lbaas --> LBaaS\n\nChange-Id: I20299226b45bee0af220e21f01da3ff789b80897\n'}, {'number': 5, 'created': '2014-09-23 18:53:27.000000000', 'files': ['doc/high-availability-guide/ch_ha_aa_network.xml', 'doc/high-availability-guide/ha_aa_network/section_run_neutron_metadata_agent.xml', 'doc/high-availability-guide/ha_aa_network/section_run_neutron_dhcp_agent.xml', 'doc/high-availability-guide/ha_aa_network/section_run_neutron_l3_agent.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/826b0e63d946860418876320c5db550976de03eb', 'message': 'Improve chapter ""HA using active/active - OpenStack network nodes""\n\n* improve XML syntax\n* improve formatting\n* neutron --> Neutron\n* lbaas --> LBaaS\n\nChange-Id: I20299226b45bee0af220e21f01da3ff789b80897\n'}]",1,123226,826b0e63d946860418876320c5db550976de03eb,13,4,5,167,,,0,"Improve chapter ""HA using active/active - OpenStack network nodes""

* improve XML syntax
* improve formatting
* neutron --> Neutron
* lbaas --> LBaaS

Change-Id: I20299226b45bee0af220e21f01da3ff789b80897
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/26/123226/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/ha_aa_network/section_run_neutron_metadata_agent.xml', 'doc/high-availability-guide/ha_aa_network/section_run_neutron_dhcp_agent.xml', 'doc/high-availability-guide/ha_aa_network/section_run_neutron_l3_agent.xml']",3,bedcb8a6db74b6ea5d57a2f99961736a5f7db50d,syntax_ha_aa_network,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" <title>Run neutron L3 agent</title> <para>The neutron L3 agent is scalable, due to the scheduler that allows distribution of virtual routers across multiple nodes. There is no native feature to make these routers highly available. At this time, the active/passive solution exists to run the Neutron L3 agent in failover mode with <application>Pacemaker</application>. See the <link linkend=""ha-using-active-passive"">active/passive section</link> of this guide.</para> </section>"," <section xmlns=""http://docbook.org/ns/docbook"" <title>Run neutron L3 agent</title> <para>The neutron L3 agent is scalable, due to the scheduler that allows distribution of virtual routers across multiple nodes. There is no native feature to make these routers highly available. At this time, the active/passive solution exists to run the Neutron L3 agent in failover mode with Pacemaker. See the active/passive section of this guide.</para> </section>",29,28
openstack%2Ffuel-library~master~Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e,openstack/fuel-library,master,Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e,Add support vSphere Datastore backend for Glance,MERGED,2014-10-01 15:27:31.000000000,2014-10-07 16:02:19.000000000,2014-10-07 16:02:18.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 12139}]","[{'number': 1, 'created': '2014-10-01 15:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ea2265a5e2fa9d38faee1867f22a32f05232efeb', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 2, 'created': '2014-10-01 15:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/251c84ac27c4a266d853e90d90f08437ce480fa0', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n\nDocImpact\nImplements: blueprint vsphere-glance-backend\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\n'}, {'number': 3, 'created': '2014-10-03 10:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/40a48fe31251634c8d7dfb3e483c96b1d84c3dde', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 4, 'created': '2014-10-03 10:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/03e73c9f2ee8aaac1a6dffcd0feb127b089746c6', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n\nDocImpact\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 5, 'created': '2014-10-03 11:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/91317ef6f6c8cd896e8f3b6bc3f95a6d9acd2d5a', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 6, 'created': '2014-10-03 12:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/995c4cfc809338581c12320e948156795e2fc4d1', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 7, 'created': '2014-10-06 10:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b6f1bfedef11226abf347d8c702f01d721ea16ce', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 8, 'created': '2014-10-06 11:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4d1329a9d7a710a52e10ed46f8dc2ea086527389', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 9, 'created': '2014-10-06 13:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/32ebe0350c5fd8dd226b2713de4f33d7c636145e', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nUpstream vsphere patch id: I88478bf4ec5d9a4c65344fbdc04ac973a31f46ea\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 10, 'created': '2014-10-06 13:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c673716ab28523ecd738760563cd17cb28846b22', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nUpstream vsphere patch id: I88478bf4ec5d9a4c65344fbdc04ac973a31f46ea\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}, {'number': 11, 'created': '2014-10-06 14:53:05.000000000', 'files': ['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/glance/spec/classes/glance_backend_vsphere_spec.rb', 'deployment/puppet/glance/manifests/backend/vsphere.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ce6cb357b0ac94ec35227d5b72fdeab0d073a2df', 'message': 'Add support vSphere Datastore backend for Glance\n\n1. Added Glace parameters for vCenter in classes openstack::controller and\n   openstack::controller_ha\n2. Created class for this type of glance backend\n3. Added Glace parameters for vCenter backend and case for our backend type\n   in class openstack::glance\n4. Added parsing of required parameters from the UI for calsses\n   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha\n5. Disabled Swift installation in HA mode\n\nDocImpact\nUpstream vsphere patch id: I88478bf4ec5d9a4c65344fbdc04ac973a31f46ea\nChange-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e\nImplements: blueprint vsphere-glance-backend\n'}]",2,125388,ce6cb357b0ac94ec35227d5b72fdeab0d073a2df,87,6,11,12139,,,0,"Add support vSphere Datastore backend for Glance

1. Added Glace parameters for vCenter in classes openstack::controller and
   openstack::controller_ha
2. Created class for this type of glance backend
3. Added Glace parameters for vCenter backend and case for our backend type
   in class openstack::glance
4. Added parsing of required parameters from the UI for calsses
   osnailyfacter::cluster_simple and osnailyfacter::cluster_ha
5. Disabled Swift installation in HA mode

DocImpact
Upstream vsphere patch id: I88478bf4ec5d9a4c65344fbdc04ac973a31f46ea
Change-Id: Icbb46da1e486ceebc1f9f0ce7a4db09323e3605e
Implements: blueprint vsphere-glance-backend
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/88/125388/10 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/glance/manifests/backend/vmware.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",6,ea2265a5e2fa9d38faee1867f22a32f05232efeb,bp/vsphere-glance-backend," } elsif ($storage_hash['images_vcenter']) { $glance_backend = 'vmware' glance_vcenter_host => $storage_hash['vc_host'], glance_vcenter_user => $storage_hash['vc_user'], glance_vcenter_password => $storage_hash['vc_password'], glance_vcenter_datacenter => $storage_hash['vc_datacenter'], glance_vcenter_datastore => $storage_hash['vc_datastore'], glance_vcenter_image_dir => $storage_hash['vc_image_dir'], glance_vcenter_use_esx => $storage_hash['vc_images_is_esx'],",,96,0
openstack%2Fha-guide~master~If54a681f59bab71946022be0373b31741bf57fd8,openstack/ha-guide,master,If54a681f59bab71946022be0373b31741bf57fd8,"Improve chapter ""HA using active/active - OpenStack controller nodes""",MERGED,2014-09-22 14:30:27.000000000,2014-10-07 16:02:14.000000000,2014-10-07 16:02:13.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-22 14:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/1c5007a71eb29960db104f3102b805bf554ec404', 'message': 'Improve sections Memcached, API services and schedulers\n\nChange-Id: If54a681f59bab71946022be0373b31741bf57fd8\n'}, {'number': 2, 'created': '2014-09-22 14:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/0fb6d8593563ddf814926c2e655da3460d87cc9d', 'message': 'Improve sections Memcached, API services and schedulers\n\nChange-Id: If54a681f59bab71946022be0373b31741bf57fd8\n'}, {'number': 3, 'created': '2014-09-22 14:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/443ca0e83f4f62db6229e90b0aec2296403efb69', 'message': 'Improve sections Memcached, API services and schedulers\n\nChange-Id: If54a681f59bab71946022be0373b31741bf57fd8\n'}, {'number': 4, 'created': '2014-09-22 15:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e05a90f4d8fe3c6871a43c91883746cf95e038d4', 'message': 'Improve sections Memcached, API services and schedulers\n\nChange-Id: If54a681f59bab71946022be0373b31741bf57fd8\n'}, {'number': 5, 'created': '2014-09-22 20:13:00.000000000', 'files': ['doc/high-availability-guide/ch_ha_aa_controllers.xml', 'doc/high-availability-guide/ha_aa_controllers/section_memcached.xml', 'doc/high-availability-guide/ha_aa_controllers/section_run_openstack_api_and_schedulers.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/ef1ce7753cf20429a4aa327d53f5c53412a99364', 'message': 'Improve chapter ""HA using active/active - OpenStack controller nodes""\n\nChange-Id: If54a681f59bab71946022be0373b31741bf57fd8\n'}]",2,123143,ef1ce7753cf20429a4aa327d53f5c53412a99364,15,5,5,167,,,0,"Improve chapter ""HA using active/active - OpenStack controller nodes""

Change-Id: If54a681f59bab71946022be0373b31741bf57fd8
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/43/123143/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/ha_aa_controllers/section_memcached.xml', 'doc/high-availability-guide/ha_aa_controllers/section_run_openstack_api_and_schedulers.xml']",2,1c5007a71eb29960db104f3102b805bf554ec404,syntax_ha_aa_controllers,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" <title>Run OpenStack API and schedulers</title> <section xml:id=""_api_services""> <title>API services</title> <para>All OpenStack projects have an API service for controlling all the resources in the Cloud. In active/active mode, the most common setup is to scale-out these services on at least two nodes and use load balancing and a virtual IP address (with <application>HAProxy</application> and <application>Keepalived</application> in this setup).</para> <para>To use highly available and scalable API services, we need to ensure that:</para> <itemizedlist> <listitem> <para>You use virtual IP addresses when configuring OpenStack Identity endpoints. </para> </listitem> <listitem> <para>All OpenStack configuration files should refer to virtual IP addresses.</para> </listitem> </itemizedlist> <note> <para>The monitor check is quite simple since it just establishes a TCP connection to the API port. Comparing to the active/passive mode using <application>Corosync</application> and resources agents, we don't check if the service is actually running. That's why all OpenStack API services should be monitored by another tool, for example <application>Nagios</application>.</para> </note> </section> <section xml:id=""_schedulers""> <title>Schedulers</title> <para>OpenStack schedulers are used to determine how to dispatch compute, network and volume requests. The most common setup is to use RabbitMQ as messaging system. Those services are connected to the messaging backend and can scale-out:</para> <itemizedlist> <listitem> <para><systemitem class=""service"">nova-scheduler</systemitem></para> </listitem> <listitem> <para><systemitem class=""service"">nova-conductor</systemitem></para> </listitem> <listitem> <para><systemitem class=""service"">cinder-scheduler</systemitem></para> </listitem> <listitem> <para><systemitem class=""service"">neutron-server</systemitem></para> </listitem> <listitem> <para><systemitem class=""service"">ceilometer-collector</systemitem></para> </listitem> <listitem> <para><systemitem class=""service"">heat-engine</systemitem></para> </listitem> </itemizedlist> <para>Please refer to the <link linkend=""s-rabbitmq"">RabbitMQ section</link> for configuring these services with multiple messaging servers.</para> </section> </section>"," <section xmlns=""http://docbook.org/ns/docbook"" <title>Run OpenStack API and schedulers</title> <section xml:id=""_api_services""> <title>API services</title> <para>All OpenStack projects have an API service for controlling all the resources in the Cloud. In active/active mode, the most common setup is to scale-out these services on at least two nodes and use load balancing and virtual IP (with HAProxy &amp; Keepalived in this setup).</para> <para> <emphasis role=""strong"">Configure API OpenStack services</emphasis> </para> <para>To configure our Cloud using Highly available and scalable API services, we need to ensure that:</para> <itemizedlist> <listitem> <para> You use virtual IPs when configuring OpenStack Identity endpoints. </para> </listitem> <listitem> <para> All OpenStack configuration files should refer to virtual IPs. </para> </listitem> </itemizedlist> <para> <emphasis role=""strong"">In case of failure</emphasis> </para> <para>The monitor check is quite simple since it just establishes a TCP connection to the API port. Comparing to the active/passive mode using Corosync &amp; Resources Agents, we dont check if the service is actually running. Thats why all OpenStack API should be monitored by another tool, for example Nagios, with the goal to detect failures in the Cloud Framework infrastructure.</para> </section> <section xml:id=""_schedulers""> <title>Schedulers</title> <para>OpenStack schedulers are used to determine how to dispatch compute, network and volume requests. The most common setup is to use RabbitMQ as messaging system already documented in this guide. Those services are connected to the messaging backend and can scale-out:</para> <itemizedlist> <listitem> <para> nova-scheduler </para> </listitem> <listitem> <para> nova-conductor </para> </listitem> <listitem> <para> cinder-scheduler </para> </listitem> <listitem> <para> neutron-server </para> </listitem> <listitem> <para> ceilometer-collector </para> </listitem> <listitem> <para> heat-engine </para> </listitem> </itemizedlist> <para>Please refer to the RabbitMQ section for configuring these services with multiple messaging servers.</para> </section> </section>",82,91
openstack%2Fha-guide~master~Ifad4ac4d05e9b3abb1d2b5d7bd0081670df66029,openstack/ha-guide,master,Ifad4ac4d05e9b3abb1d2b5d7bd0081670df66029,"Improve chapter ""HA using active/active - Database""",MERGED,2014-09-22 15:24:53.000000000,2014-10-07 16:02:08.000000000,2014-10-07 16:02:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-22 15:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/89078a18d208c324d26b5697cd318a1351559aac', 'message': 'Improve chapter about databases\n\nChange-Id: Ifad4ac4d05e9b3abb1d2b5d7bd0081670df66029\n'}, {'number': 2, 'created': '2014-09-22 20:11:38.000000000', 'files': ['doc/high-availability-guide/ha_aa_db/section_ha_aa_db_mysql_galera.xml', 'doc/high-availability-guide/ha_aa_db/section_ha_aa_db_galera_monitoring.xml', 'doc/high-availability-guide/ch_ha_aa_db.xml', 'doc/high-availability-guide/ha_aa_db/section_mysql_galera.xml', 'doc/high-availability-guide/ha_aa_db/section_other_ways_to_provide_a_highly_available_database.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/c6af8af4f11d5e9b5b02fa14feb26f3dcf7ec21b', 'message': 'Improve chapter ""HA using active/active - Database""\n\nChange-Id: Ifad4ac4d05e9b3abb1d2b5d7bd0081670df66029\n'}]",0,123159,c6af8af4f11d5e9b5b02fa14feb26f3dcf7ec21b,11,5,2,167,,,0,"Improve chapter ""HA using active/active - Database""

Change-Id: Ifad4ac4d05e9b3abb1d2b5d7bd0081670df66029
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/59/123159/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/ha_aa_db/section_ha_aa_db_mysql_galera.xml', 'doc/high-availability-guide/ha_aa_db/section_ha_aa_db_galera_monitoring.xml', 'doc/high-availability-guide/ch_ha_aa_db.xml', 'doc/high-availability-guide/ha_aa_db/section_mysql_galera.xml', 'doc/high-availability-guide/ha_aa_db/section_other_ways_to_provide_a_highly_available_database.xml']",5,89078a18d208c324d26b5697cd318a1351559aac,syntax_ha_aa_db,," <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""_other_ways_to_provide_a_highly_available_database""> <title>Other ways to provide a highly available database</title> <para>MySQL with Galera is by no means the only way to achieve database HA. MariaDB (<link xlink:href=""https://mariadb.org/"">https://mariadb.org/</link>) and Percona (<link xmlns:xlink=""http://www.w3.org/1999/xlink"" xlink:href=""http://www.percona.com/"">http://www.percona.com/</link>) also work with Galera. You also have the option to use PostgreSQL, which has its own replication, or another database HA option.</para> </section> ",183,219
openstack%2Fopenstack-manuals~master~I81cd29b5bb0d75ced2f319aa1438774a3b133c0a,openstack/openstack-manuals,master,I81cd29b5bb0d75ced2f319aa1438774a3b133c0a,Replace keystone auth_* options with identity_uri,MERGED,2014-10-06 08:36:24.000000000,2014-10-07 16:01:52.000000000,2014-10-07 16:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-10-06 08:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/343f82c7d9c9f06f734a8014ae472051421ce7bf', 'message': 'Remove usage of auth_* options and replace them with auth_uri/identity_uri\n\nChange-Id: I81cd29b5bb0d75ced2f319aa1438774a3b133c0a\n'}, {'number': 2, 'created': '2014-10-07 00:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/17b1289c01d27cb2bed5c8d3888697e1c4dd7fe3', 'message': 'Replace keystone auth_* options with identity_uri\n\nReplaced [keystone_authtoken] auth_* options with identity_uri\noption. This patch supersedes #125847 and no longer conflicts\nwith #120332.\n\nChange-Id: I81cd29b5bb0d75ced2f319aa1438774a3b133c0a\nCo-Authored-By: Matt Kassawara <mkassawara@gmail.com>\n'}, {'number': 3, 'created': '2014-10-07 07:03:01.000000000', 'files': ['doc/install-guide/section_glance-install.xml', 'doc/install-guide/section_debconf-keystone_authtoken.xml', 'doc/install-guide/section_ceilometer-controller.xml', 'doc/common/section_identity-troubleshooting.xml', 'doc/install-guide/section_heat-install.xml', 'doc/install-guide/section_cinder-controller.xml', 'doc/admin-guide-cloud/ch_identity_mgmt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/37009b0b66fab24e745a8c2143beaae2c01b49c8', 'message': 'Replace keystone auth_* options with identity_uri\n\nReplaced [keystone_authtoken] auth_* options with identity_uri\noption. This patch supersedes #125847 and no longer conflicts\nwith #120332.\n\nChange-Id: I81cd29b5bb0d75ced2f319aa1438774a3b133c0a\nCo-Authored-By: Matt Kassawara <mkassawara@gmail.com>\n'}]",0,126236,37009b0b66fab24e745a8c2143beaae2c01b49c8,17,5,3,167,,,0,"Replace keystone auth_* options with identity_uri

Replaced [keystone_authtoken] auth_* options with identity_uri
option. This patch supersedes #125847 and no longer conflicts
with #120332.

Change-Id: I81cd29b5bb0d75ced2f319aa1438774a3b133c0a
Co-Authored-By: Matt Kassawara <mkassawara@gmail.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/36/126236/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/section_neutron-compute-node.xml', 'doc/install-guide/section_glance-install.xml', 'doc/install-guide/section_ceilometer-controller.xml', 'doc/install-guide/section_heat-install.xml', 'doc/install-guide/section_neutron-controller-node.xml', 'doc/install-guide/section_cinder-controller.xml', 'doc/install-guide/section_nova-controller-install.xml', 'doc/install-guide/section_nova-compute-install.xml', 'doc/install-guide/section_debconf-keystone_authtoken.xml', 'doc/common/section_identity-troubleshooting.xml', 'doc/install-guide/section_cinder-node.xml', 'doc/install-guide/section_neutron-network-node.xml', 'doc/admin-guide-cloud/ch_identity_mgmt.xml']",13,343f82c7d9c9f06f734a8014ae472051421ce7bf,remove_auth_parameters,"auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0 identity_uri = http://<replaceable>controller</replaceable>:35357 <note> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> and <literal>auth_uri</literal> options replaces them.</para> </note>auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0 identity_uri = http://<replaceable>controller</replaceable>:35357 <note> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> and <literal>auth_uri</literal> options replaces them.</para> </note>auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0 identity_uri = http://<replaceable>controller</replaceable>:35357 <note> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> and <literal>auth_uri</literal> options replaces them.</para> </note>",auth_host = 127.0.0.1 auth_port = 35357 auth_protocol = http auth_uri = http://127.0.0.1:5000/auth_host = 127.0.0.1 auth_port = 35357 auth_protocol = http auth_uri = http://127.0.0.1:5000/service_port = 5000 service_host = 127.0.0.1 auth_port = 35357 auth_host = 127.0.0.1,85,50
openstack%2Fha-guide~master~I82b89a86503101539db683768824892f52047505,openstack/ha-guide,master,I82b89a86503101539db683768824892f52047505,Describe how to install RabbitMQ on openSUSE,MERGED,2014-09-23 11:08:42.000000000,2014-10-07 16:00:25.000000000,2014-10-07 16:00:24.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-09-23 11:08:42.000000000', 'files': ['doc/high-availability-guide/ha_aa_rabbitmq/section_install_rabbitmq.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/a2013f879fdc2e5561ee0cbc161243a312bda32f', 'message': 'Describe how to install RabbitMQ on openSUSE\n\nChange-Id: I82b89a86503101539db683768824892f52047505\nPartial-Bug: #1372625\n'}]",0,123416,a2013f879fdc2e5561ee0cbc161243a312bda32f,7,3,1,167,,,0,"Describe how to install RabbitMQ on openSUSE

Change-Id: I82b89a86503101539db683768824892f52047505
Partial-Bug: #1372625
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/16/123416/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/high-availability-guide/ha_aa_rabbitmq/section_install_rabbitmq.xml'],1,a2013f879fdc2e5561ee0cbc161243a312bda32f,bug/1372625," <section xml:id=""_on_opensuse_sles""> <title>On openSUSE</title> <screen><prompt>#</prompt> <userinput>zypper install rabbitmq-server</userinput></screen> <para> <link xlink:href=""http://www.rabbitmq.com/install-rpm.html""> Official manual for installing RabbitMQ on openSUSE</link> </para> </section>",,8,0
openstack%2Fha-guide~master~I49cf494fd02d57b6c7f862a3ab09723df83e2579,openstack/ha-guide,master,I49cf494fd02d57b6c7f862a3ab09723df83e2579,"Improve chapter ""HA using active/active - RabbitMQ""",MERGED,2014-09-22 20:08:11.000000000,2014-10-07 15:56:58.000000000,2014-10-07 15:56:57.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6926}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-22 20:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/5abace892e54b60af3d1e0f10e3104065eaee990', 'message': 'Improve chapter ""HA using active/active - RabbitMQ""\n\nChange-Id: I49cf494fd02d57b6c7f862a3ab09723df83e2579\n'}, {'number': 2, 'created': '2014-09-22 20:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e52dc3e47aa3901c86b96f95b99db05b0e50a9d8', 'message': 'Improve chapter ""HA using active/active - RabbitMQ""\n\n* improve XML syntax\n* improve formatting\n\nChange-Id: I49cf494fd02d57b6c7f862a3ab09723df83e2579\n'}, {'number': 3, 'created': '2014-09-23 09:11:05.000000000', 'files': ['doc/high-availability-guide/ha_aa_rabbitmq/section_configure_rabbitmq.xml', 'doc/high-availability-guide/ch_ha_aa_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_openstack_services_to_use_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_openstack_services_to_user_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_install_rabbitmq.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/365e8c30b890b14c87f6b92c661d0f024f2d9c30', 'message': 'Improve chapter ""HA using active/active - RabbitMQ""\n\n* improve XML syntax\n* improve formatting\n\nChange-Id: I49cf494fd02d57b6c7f862a3ab09723df83e2579\n'}]",0,123240,365e8c30b890b14c87f6b92c661d0f024f2d9c30,12,5,3,167,,,0,"Improve chapter ""HA using active/active - RabbitMQ""

* improve XML syntax
* improve formatting

Change-Id: I49cf494fd02d57b6c7f862a3ab09723df83e2579
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/40/123240/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/ha_aa_rabbitmq/section_configure_rabbitmq.xml', 'doc/high-availability-guide/ch_ha_aa_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_openstack_services_to_use_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_openstack_services_to_user_rabbitmq.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_install_rabbitmq.xml']",5,5abace892e54b60af3d1e0f10e3104065eaee990,syntax_ha_aa_rabbitmq,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" <title>Install RabbitMQ</title> <note> <para>This setup has been tested with RabbitMQ <literal>2.7.1</literal>.</para> </note> <section xml:id=""_on_ubuntu_debian""> <title>On Ubuntu / Debian</title> <para>RabbitMQ is packaged on both distros:</para> <screen><prompt>#</prompt> <userinput>apt-get install rabbitmq-server rabbitmq-plugins</userinput></screen> <para> <link xlink:href=""http://www.rabbitmq.com/install-debian.html"">Official manual for installing RabbitMQ on Ubuntu / Debian</link> </para> </section> <section xml:id=""_on_fedora_rhel""> <title>On Fedora / RHEL</title> <para>RabbitMQ is packaged on both distros:</para> <screen><prompt>#</prompt> <userinput>yum install erlang</userinput></screen> <para> <link xlink:href=""http://www.rabbitmq.com/install-rpm.html"">Official manual for installing RabbitMQ on Fedora / RHEL</link> </para> </section> </section>"," <section xmlns=""http://docbook.org/ns/docbook"" <title>Install RabbitMQ</title> <para>This setup has been tested with RabbitMQ 2.7.1.</para> <section xml:id=""_on_ubuntu_debian""> <title>On Ubuntu / Debian</title> <para>RabbitMQ is packaged on both distros:</para> <screen><prompt>#</prompt> <userinput>apt-get install rabbitmq-server rabbitmq-plugins</userinput></screen> <para> <link xlink:href=""http://www.rabbitmq.com/install-debian.html"">Official manual for installing RabbitMQ on Ubuntu / Debian</link> </para> </section> <section xml:id=""_on_fedora_rhel""> <title>On Fedora / RHEL</title> <para>RabbitMQ is packaged on both distros:</para> <screen><prompt>#</prompt> <userinput>yum install erlang</userinput></screen> <para> <link xlink:href=""http://www.rabbitmq.com/install-rpm.html"">Official manual for installing RabbitMQ on Fedora / RHEL</link> </para> </section> </section>",144,118
openstack%2Fsahara~proposed%2Fjuno~I72134bcdf6c42911d07e65952a9a56331d896699,openstack/sahara,proposed/juno,I72134bcdf6c42911d07e65952a9a56331d896699,"Fix HDFS url description, and other various edits",MERGED,2014-10-06 18:45:49.000000000,2014-10-07 15:56:05.000000000,2014-10-07 11:35:13.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/horizon/dashboard.user.guide.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3630ccffb25f66e2efc9297b0ecb852f8d932363', 'message': ""Fix HDFS url description, and other various edits\n\nHDFS url description is wrong as a result of code changes. This was\nthe major motivation for this CR.\n\nAdditional changes\n\n* formatted for 80 characters\n* consistent use of '.' at the end of bullets\n* added mention of Spark\n* adding '.sahara' suffix is no longer necessary\n* some other minor changes\n\nCloses-Bug: 1376457\nChange-Id: I72134bcdf6c42911d07e65952a9a56331d896699\n(cherry picked from commit a718ec7ddf85ef2e1e17868f6e2cd05b1c2762cd)\n""}]",0,126394,3630ccffb25f66e2efc9297b0ecb852f8d932363,21,7,1,8411,,,0,"Fix HDFS url description, and other various edits

HDFS url description is wrong as a result of code changes. This was
the major motivation for this CR.

Additional changes

* formatted for 80 characters
* consistent use of '.' at the end of bullets
* added mention of Spark
* adding '.sahara' suffix is no longer necessary
* some other minor changes

Closes-Bug: 1376457
Change-Id: I72134bcdf6c42911d07e65952a9a56331d896699
(cherry picked from commit a718ec7ddf85ef2e1e17868f6e2cd05b1c2762cd)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/94/126394/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/horizon/dashboard.user.guide.rst'],1,3630ccffb25f66e2efc9297b0ecb852f8d932363,bug/1376457,"This guide assumes that you already have the Sahara service and Horizon dashboard up and running. Don't forget to make sure that Sahara is registered in Keystone. If you require assistance with that, please see the `installation guide <../installation.guide.html>`_.1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Image Registry"" panel 2) From that page, click on the ""Register Image"" button at the top right 3) Choose the image that you'd like to register with Sahara 4) Enter the username of the cloud-init user on the image 5) Click on the tags that you want to add to the image. (A version ie: 1.2.1 and a type ie: vanilla are required for cluster functionality) 6) Click the ""Done"" button to finish the registration1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Node Group Templates"" panel 2) From that page, click on the ""Create Template"" button at the top right 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create""6) Choose the storage location for your instance, this can be either ""Ephemeral Drive"" or ""Cinder Volume"". If you choose ""Cinder Volume"", you will need to add additional configuration 7) Choose which processes should be run for any instances that are spawned from this Node Group Template 8) Click on the ""Create"" button to finish creating your Node Group Template1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Cluster Templates"" panel 2) From that page, click on the ""Create Template"" button at the top right 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create"" 4) Under the ""Details"" tab, you must give your template a name 5) Under the ""Node Groups"" tab, you should add one or more nodes that can be based on one or more templates - To do this, start by choosing a Node Group Template from the dropdown and click the ""+"" button - You can adjust the number of nodes to be spawned for this node group via the text box or the ""-"" and ""+"" buttons - Repeat these steps if you need nodes from additional node group templates 6) Optionally, you can adjust your configuration further by using the ""General Parameters"", ""HDFS Parameters"" and ""MapReduce Parameters"" tabs 7) Click on the ""Create"" button to finish creating your Cluster Template1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Clusters"" panel 2) Click on the ""Launch Cluster"" button at the top right 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create"" 4) Give your cluster a name (required) 5) Choose which cluster template should be used for your cluster 6) Choose the image that should be used for your cluster (if you do not see any options here, see `Registering an Image`_ above) 7) Optionally choose a keypair that can be used to authenticate to your cluster instances 8) Click on the ""Create"" button to start your cluster - Your cluster's status will display on the Clusters table - It will likely take several minutes to reach the ""Active"" state1) From the Data Processing/Clusters page, click on the ""Scale Cluster"" button of the row that contains the cluster that you want to scale 2) You can adjust the numbers of instances for existing Node Group Templates 3) You can also add a new Node Group Template and choose a number of instances to launch - This can be done by selecting your desired Node Group Template from the dropdown and clicking the ""+"" button - Your new Node Group will appear below and you can adjust the number of instances via the text box or the ""+"" and ""-"" buttons 4) To confirm the scaling settings and trigger the spawning/deletion of instances, click on ""Scale""1) From the Data Processing/Data Sources page, click on the ""Create Data Source"" button at the top right 2) Give your Data Source a name 3) Enter the URL of the the Data Source - For a Swift object, enter <container>/<path> (ie: *mycontainer/inputfile*). Sahara will prepend *swift://* for you - For an HDFS object, enter an absolute path, a relative path or a full URL: + */my/absolute/path* indicates an absolute path in the cluster HDFS + *my/path* indicates the path */user/hadoop/my/path* in the cluster HDFS assuming the defined HDFS user is *hadoop* + *hdfs://host:port/path* can be used to indicate any HDFS location 4) Enter the username and password for the Data Source (also see `Additional Notes`_) 5) Enter an optional description 6) Click on ""Create"" 7) Repeat for additional Data SourcesJob Binaries are where you define/upload the source code (mains and libraries) for your job. 1) From the Data Processing/Job Binaries page, click on the ""Create Job Binary"" button at the top right 2) Give your Job Binary a name (this can be different than the actual filename) 3) Choose the type of storage for your Job Binary - For ""Swift"", enter the URL of your binary (<container>/<path>) as well as the username and password (also see `Additional Notes`_) - For ""Internal database"", you can choose from ""Create a script"" or ""Upload a new file"" 4) Enter an optional description 5) Click on ""Create""Jobs are where you define the type of job you'd like to run as well as which ""Job Binaries"" are required 1) From the Data Processing/Jobs page, click on the ""Create Job"" button at the top right 2) Give your Job a name 3) Choose the type of job you'd like to run 4) Choose the main binary from the dropdown - This is required for Hive, Pig, and Spark jobs - Other job types do not use a main binary 5) Enter an optional description for your Job 6) Click on the ""Libs"" tab and choose any libraries needed by your job - MapReduce and Java jobs require at least one library - Other job types may optionally use libraries 7) Click on ""Create""Job Executions are what you get by ""Launching"" a job. You can monitor the status of your job to see when it has completed its run 1) From the Data Processing/Jobs page, find the row that contains the job you want to launch and click on the ""Launch Job"" button at the right side of that row 2) Choose the cluster (already running--see `Launching a Cluster`_ above) on which you would like the job to run 3) Choose the Input and Output Data Sources (Data Sources defined above) 4) If additional configuration is required, click on the ""Configure"" tab - Additional configuration properties can be defined by clicking on the ""Add"" button - An example configuration entry might be mapred.mapper.class for the Name and org.apache.oozie.example.SampleMapper for the Value 5) Click on ""Launch"". To monitor the status of your job, you can navigate to the Sahara/Job Executions panel 6) You can relaunch a Job Execution from the Job Executions page by using the ""Relaunch on New Cluster"" or ""Relaunch on Existing Cluster"" links - Relaunch on New Cluster will take you through the forms to start a new cluster before letting you specify input/output Data Sources and job configuration - Relaunch on Existing Cluster will prompt you for input/output Data Sources as well as allow you to change job configuration before launching the jobThere are sample jobs located in the sahara repository. In this section, we will give a walkthrough on how to run those jobs via the Horizon UI. These steps assume that you already have a cluster up and running (in the ""Active"" state). 1) Sample Pig job - https://github.com/openstack/sahara/tree/master/etc/edp-examples/pig-job - Load the input data file from https://github.com/openstack/sahara/tree/master/etc/edp-examples/pig-job/data/input into swift - Click on Projet/Object Store/Containers and create a container with any name (""samplecontainer"" for our purposes here) - Click on Upload Object and give the object a name (""piginput"" in this case) - Navigate to Data Processing/Data Sources, Click on Create Data Source - Type = Swift, URL samplecontainer/piginput, fill-in the Source username/password fields with your username/password and click ""Create"" - Name = pig-output-ds, Type = Swift, URL = samplecontainer/pigoutput, Source username/password, ""Create"" - Name = example.pig, Storage type = Internal database, click Browse and find example.pig wherever you checked out the sahara project <sahara root>/etc/edp-examples/pig-job - Create another Job Binary: Name = udf.jar, Storage type = Internal database, click Browse and find udf.jar wherever you checked out the sahara project <sahara root>/etc/edp-examples/pig-job - Click on the ""Libs"" tab and choose ""udf.jar"", then hit the ""Choose"" button beneath the dropdown, then click on ""Create"" - To launch your job from the Jobs page, click on the down arrow at the far right of the screen and choose ""Launch on Existing Cluster"" - For the input, choose ""pig-input-ds"", for output choose ""pig-output-ds"". Also choose whichever cluster you'd like to run the job on - For this job, no additional configuration is necessary, so you can just click on ""Launch"" - You will be taken to the ""Job Executions"" page where you can see your job progress through ""PENDING, RUNNING, SUCCEEDED"" phases - When your job finishes with ""SUCCEEDED"", you can navigate back to Object Store/Containers and browse to the samplecontainer to see your output. It should be in the ""pigoutput"" folder 2) Sample Spark job - https://github.com/openstack/sahara/tree/master/etc/edp-examples/edp-spark - Name = sparkexample.jar, Storage type = Internal database, Browse to the location <sahara root>/etc/edp-examples/edp-spark and choose spark-example.jar, Click ""Create"" - Name = sparkexamplejob, Job Type = Spark, Main binary = Choose sparkexample.jar, Click ""Create"" - To launch your job from the Jobs page, click on the down arrow at the far right of the screen and choose ""Launch on Existing Cluster"" - Choose whichever cluster you'd like to run the job on - Under Arguments, click Add and fill in the number of ""Slices"" you want to use for the job. For this example, let's use 100 as the value - You will be taken to the ""Job Executions"" page where you can see your job progress through ""PENDING, RUNNING, SUCCEEDED"" phases - When your job finishes with ""SUCCEEDED"", you can see your results by sshing to the Spark ""master"" node - The output is located at /tmp/spark-edp/<name of job>/<job execution id>. You can do ``cat stdout`` which should display something like ""Pi is roughly 3.14156132"" - It should be noted that for more complex jobs, the input/output may be elsewhere. This particular job just writes to stdout, which is logged in the folder under /tmp1) Throughout the Sahara UI, you will find that if you try to delete an object that you will not be able to delete it if another object depends on it. An example of this would be trying to delete a Job that has an existing Job Execution. In order to be able to delete that job, you would first need to delete any Job Executions that relate to that job. 2) In the examples above, we mention adding your username/password for the Swift Data Sources. It should be noted that it is possible to configure Sahara such that the username/password credentials are *not* required. For more information on that, please refer to: :doc:`Sahara Advanced Configuration Guide <../userdoc/advanced.configuration.guide>`","This guide assumes that you already have Sahara service and the Horizon dashboard up and running. Don't forget to make sure that Sahara is registered in Keystone. If you require assistance with that, please see the `installation guide <../installation.guide.html>`_.1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Image Registry"" panel. 2) From that page, click on the ""Register Image"" button at the top right. 3) Choose the image that you'd like to register as a Hadoop Image 4) Enter the username of the cloud-init user on the image. 5) Click on the tags that you want to add to the image. (A version ie: 1.2.1 and a type ie: vanilla are required for cluster functionality) 6) Click the ""Done"" button to finish the registration.1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Node Group Templates"" panel. 2) From that page, click on the ""Create Template"" button at the top right. 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create"".6) Choose the storage location for your instance, this can be either ""Ephemeral Drive"" or ""Cinder Volume"". If you choose ""Cinder Volume"", you will need to add additional configuration. 7) Choose which processes should be run for any instances that are spawned from this Node Group Template. 8) Click on the ""Create"" button to finish creating your Node Group Template.1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Cluster Templates"" panel. 2) From that page, click on the ""Create Template"" button at the top right. 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create"". 4) Under the ""Details"" tab, you must give your template a name. 5) Under the ""Node Groups"" tab, you should add one or more nodes that can be based on one or more templates. - To do this, start by choosing a Node Group Template from the dropdown and click the ""+"" button. - You can adjust the number of nodes to be spawned for this node group via the text box or the ""-"" and ""+"" buttons. - Repeat these steps if you need nodes from additional node group templates. 6) Optionally, you can adjust your configuration further by using the ""General Parameters"", ""HDFS Parameters"" and ""MapReduce Parameters"" tabs. 7) Click on the ""Create"" button to finish creating your Cluster Template.1) Navigate to the ""Project"" dashboard, then the ""Data Processing"" tab, then click on the ""Clusters"" panel. 2) Click on the ""Launch Cluster"" button at the top right. 3) Choose your desired Plugin name and Version from the dropdowns and click ""Create"". 4) Give your cluster a name. (required) 5) Choose which cluster template should be used for your cluster. 6) Choose the image that should be used for your cluster (if you do not see any options here, see `Registering an Image`_ above). 7) Optionally choose a keypair that can be used to authenticate to your cluster instances. 8) Click on the ""Create"" button to start your cluster. - Your cluster's status will display on the Clusters table. - It will likely take several minutes to reach the ""Active"" state.1) From the Data Processing/Clusters page, click on the ""Scale Cluster"" button of the row that contains the cluster that you want to scale. 2) You can adjust the numbers of instances for existing Node Group Templates. 3) You can also add a new Node Group Template and choose a number of instances to launch. - This can be done by selecting your desired Node Group Template from the dropdown and clicking the ""+"" button. - Your new Node Group will appear below and you can adjust the number of instances via the text box or the +/- buttons. 4) To confirm the scaling settings and trigger the spawning/deletion of instances, click on ""Scale"".1) From the Data Processing/Data Sources page, click on the ""Create Data Source"" button at the top right. 2) Give your Data Source a name. 3) Enter the URL to the Data Source. - For a Swift object, the url will look like <container>.sahara/<path> (ie: mycontainer.sahara/inputfile). The ""swift://"" is automatically added for you. - For an HDFS object, the url will look like <host>/<path> (ie: myhost/user/hadoop/inputfile). The ""hdfs://"" is automatically added for you. 4) Enter the username and password for the Data Source. 5) Enter an optional description. 6) Click on ""Create"". 7) Repeat for additional Data Sources.Job Binaries are where you define/upload the source code (mains and libraries) for your job. 1) From the Data Processing/Job Binaries page, click on the ""Create Job Binary"" button at the top right. 2) Give your Job Binary a name (this can be different than the actual filename). 3) Choose the type of storage for your Job Binary. - For ""Swift"", you will need to enter the URL of your binary (<container>.sahara/<path>) as well as the username and password. - For ""Internal database"", you can choose from ""Create a script"" or ""Upload a new file"". 4) Enter an optional description. 5) Click on ""Create"".Jobs are where you define the type of job you'd like to run as well as which ""Job Binaries"" are required. 1) From the Data Processing/Jobs page, click on the ""Create Job"" button at the top right. 2) Give your Job a name. 3) Choose the type of job you'd like to run (Pig, Hive, MapReduce, Streaming MapReduce, Java Action) 4) Choose the main binary from the dropdown (not applicable for MapReduce or Java Action). 5) Enter an optional description for your Job. 6) Optionally, click on the ""Libs"" tab and add one or more libraries that are required for your job. Each library must be defined as a Job Binary. 7) Click on ""Create"".Job Executions are what you get by ""Launching"" a job. You can monitor the status of your job to see when it has completed its run. 1) From the Data Processing/Jobs page, find the row that contains the job you want to launch and click on the ""Launch Job"" button at the right side of that row. 2) Choose the cluster (already running--see `Launching a Cluster`_ above) on which you would like the job to run. 3) Choose the Input and Output Data Sources (Data Sources defined above). 4) If additional configuration is required, click on the ""Configure"" tab. - Additional configuration properties can be defined by clicking on the ""Add"" button. - An example configuration entry might be mapred.mapper.class for the Name and org.apache.oozie.example.SampleMapper for the Value. 5) Click on ""Launch"". To monitor the status of your job, you can navigate to the Sahara/Job Executions panel. 6) You can relaunch a Job Execution from the Job Executions page by using the ""Relaunch on New Cluster"" or ""Relaunch on Existing Cluster"" links. - Relaunch on New Cluster will take you through the forms to start a new cluster before letting you specify input/output Data Sources and job configuration. - Relaunch on Existing Cluster will prompt you for input/output Data Sources as well as allow you to change job configuration before launching the job.There are sample jobs located in the sahara repository. The instructions there guide you through running the jobs via the command line. In this section, we will give a walkthrough on how to run those jobs via the Horizon UI. These steps assume that you already have a cluster up and running (in the ""Active"" state). 1) Sample Pig job - https://github.com/openstack/sahara/tree/master/etc/edp-examples/pig-job - Load the input data file from https://github.com/openstack/sahara/tree/master/etc/edp-examples/pig-job/data/input into swift - Click on Projet/Object Store/Containers and create a container with any name (""samplecontainer"" for our purposes here). - Click on Upload Object and give the object a name (""piginput"" in this case) - Navigate to Data Processing/Data Sources, Click on Create Data Source. - Type = Swift, URL samplecontainer.sahara/piginput, fill-in the Source username/password fields with your username/password and click ""Create"" - Create another Data Source to use as output for our job. Name = pig-output-ds, Type = Swift, URL = samplecontainer.sahara/pigoutput, Source username/password, ""Create"" - Name = example.pig, Storage type = Internal database, click Browse and find example.pig wherever you checked out the sahara project <sahara root>/etc/edp-examples/pig-job - Create another Job Binary: Name = udf.jar, Storage type = Internal database, click Browse and find udf.jar wherever you checked out the sahara project <sahara root>/etc/edp-examples/pig-job - Click on the ""Libs"" tab and choose ""udf.jar"", then hit the ""Choose"" button beneath the dropdown, then click on ""Create"" - To launch your job from the Jobs page, click on the down arrow at the far right of the screen and choose ""Launch on Existing Cluster"" - For the input, choose ""pig-input-ds"", for output choose ""pig-output-ds"". Also choose whichever cluster you'd like to run the job on. - For this job, no additional configuration is necessary, so you can just click on ""Launch"" - You will be taken to the ""Job Executions"" page where you can see your job progress through ""PENDING, RUNNING, SUCCEEDED"" phases - When your job finishes with ""SUCCEEDED"", you can navigate back to Object Store/Containers and browse to the samplecontainer to see your output. It should be in the ""pigoutput"" folder. 2) Sample Spark job - https://github.com/openstack/sahara/tree/master/etc/edp-examples/edp-spark - Name = sparkexample.jar, Storage type = Internal database, Browse to the location <sahara root>/etc/edp-examples/edp-spark and choose spark-example.jar, Click ""Create"" - Name = sparkexamplejob, Job Type = Spark, Main binary = Choose sparkexample.jar, Click ""Create"" - To launch your job from the Jobs page, click on the down arrow at the far right of the screen and choose ""Launch on Existing Cluster"" - Choose whichever cluster you'd like to run the job on. - Under Arguments, click Add and fill in the number of ""Slices"" you want to use for the job. For this example, let's use 100 as the value - You will be taken to the ""Job Executions"" page where you can see your job progress through ""PENDING, RUNNING, SUCCEEDED"" phases - When your job finishes with ""SUCCEEDED"", you can see your results by sshing to the Spark ""master"" node. - The output is located at /tmp/spark-edp/<name of job>/<job execution id>. You can do ``cat stdout`` which should display something like ""Pi is roughly 3.14156132"" - It should be noted that for more complex jobs, the input/output may be elsewhere. This particular job just writes to stdout, which is logged in the folder under /tmp.1) Throughout the Sahara UI, you will find that if you try to delete an object that you will not be able to delete it if another object depends on it. An example of this would be trying to delete a Job that has an existing Job Execution. In order to be able to delete that job, you would first need to delete any Job Executions that relate to that job. 2) In the examples above, we mention adding your username/password for the Swift Data Sources. It should be noted that it is possible to configure Sahara such that the username/password credentials are *not* required. For more information on that, please refer to: :doc:`Sahara Advanced Configuration Guide <../userdoc/advanced.configuration.guide>`",199,110
openstack%2Ffuel-web~master~I1acb79a368f02635ee9ba8dd2bb39be3980351bf,openstack/fuel-web,master,I1acb79a368f02635ee9ba8dd2bb39be3980351bf,Add support vSphere Datastore backend for Glance,MERGED,2014-09-26 16:06:15.000000000,2014-10-07 15:55:40.000000000,2014-10-07 15:55:39.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 11427}, {'_account_id': 12139}]","[{'number': 1, 'created': '2014-09-26 16:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7b2ab83c8850148e0e6113d1c08b1d7d35058bc1', 'message': 'Add support vSphere Datastore backend for Glance.\n\nAdded new UI parameters in openstack.yaml and decriptions in translation.json.\nImplements: https://blueprints.launchpad.net/fuel/+spec/vsphere-glance-backend\n\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 2, 'created': '2014-09-26 16:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d4c7a14615356db19a4f21160e28c6abfb12bc81', 'message': 'Add support vSphere Datastore backend for Glance.\n\nAdded new UI parameters in openstack.yaml and decriptions in translation.json.\n\nImplements:  blueprint https://blueprints.launchpad.net/fuel/+spec/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 3, 'created': '2014-09-29 11:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d14de9ca19c118f6685aba9bbad63599adbee459', 'message': 'Add support vSphere Datastore backend for Glance.\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 4, 'created': '2014-09-29 12:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a687b30f7a37db1bf9ff65068e247d775f64fd22', 'message': 'Add support vSphere Datastore backend for Glance.\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: blueprint vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 5, 'created': '2014-09-29 12:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/352d167e1c76a4012b73d0ced11508fa52c8aa7e', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: blueprint vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 6, 'created': '2014-09-29 13:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/65a0b2a1390363ecdb1f24c658df146be149eea2', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 7, 'created': '2014-09-29 15:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8f3630daaf8545c68c8af323b6e0a8d8bf4c93f8', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 8, 'created': '2014-10-01 09:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4594026656d45f63259260ea6b6c8ebd6b745eb9', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 9, 'created': '2014-10-01 10:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/815f0c51ab3ac4a7b9a79ee08a3c2f3ac6336d00', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 10, 'created': '2014-10-01 15:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bd2ba3f3a999a5207b3766fe3f67ccffd66cb478', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements:  blueprint vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 11, 'created': '2014-10-01 15:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7926bfb0e63f1b5f21b98a321d1b34c83e21d3c5', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and descriptions in\ntranslation.json.\n\nImplements:  blueprint vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 12, 'created': '2014-10-02 10:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1a2efa8e67c8d8116d1febbb2eaabcb9a05a8690', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and descriptions in\ntranslation.json.\n\nImplements:  blueprint vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 13, 'created': '2014-10-03 12:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/014f2b8b333bb64a5ceff972d771cfee9581d966', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 14, 'created': '2014-10-03 13:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5b68360bb9096ceecb7ec477e0a820a707690fb6', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 15, 'created': '2014-10-06 15:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9ad36c81185731a696c822cc51979432e4ebaeb0', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}, {'number': 16, 'created': '2014-10-06 16:16:55.000000000', 'files': ['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3eeaa6ddbd34426b4070478a8eba881e9a971c9c', 'message': 'Add support vSphere Datastore backend for Glance\n\nAdded new UI parameters in openstack.yaml and decriptions in\ntranslation.json.\n\nImplements: bp/vsphere-glance-backend\nChange-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf\n'}]",19,124452,3eeaa6ddbd34426b4070478a8eba881e9a971c9c,107,8,16,12139,,,0,"Add support vSphere Datastore backend for Glance

Added new UI parameters in openstack.yaml and decriptions in
translation.json.

Implements: bp/vsphere-glance-backend
Change-Id: I1acb79a368f02635ee9ba8dd2bb39be3980351bf
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/52/124452/16 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml']",2,7b2ab83c8850148e0e6113d1c08b1d7d35058bc1,vsphere-glance-backend," images_vcenter: value: false label: ""VMWare vCenter/ESXi datastore for images (Glance)"" description: ""Configures Glance to use the vCenter/ESXi backend to store images. If enabled, this option will prevent Swift from installing."" weight: 35 type: ""checkbox"" restrictions: - ""settings:storage.images_ceph.value == true"" vc_images_is_esx: value: false type: ""checkbox"" label: ""ESXi datastore for images (Glance)"" description: ""Select if you want to use ESXi host as datastore. If not selected, vCenter will be used."" weight: 40 restrictions: - ""settings:storage.images_vcenter.value == false"" vc_host: value: """" label: ""vCenter/ESXi IP"" description: ""IP Address of vCenter/ESXi"" weight: 45 type: ""text"" regex: source: *ipv4_regex error: 'Specify valid IPv4 address' restrictions: - ""settings:storage.images_vcenter.value == false"" vc_user: value: """" label: ""Username"" description: ""vCenter/ESXi admin username"" weight: 50 type: ""text"" regex: source: *non_empty_string error: 'Empty username' restrictions: - ""settings:storage.images_vcenter.value == false"" vc_password: value: """" label: ""Password"" description: ""vCenter/ESXi admin password"" weight: 55 type: ""password"" regex: source: *non_empty_string error: ""Empty password"" restrictions: - ""settings:storage.images_vcenter.value == false"" vc_datastore: value: """" label: ""Datastore name"" description: ""Datastore associated with the datacenter."" weight: 60 type: ""text"" regex: source: *non_empty_string error: 'Empty datastore' restrictions: - ""settings:storage.images_vcenter.value == false"" vc_datacenter: value: """" label: ""Datacanter name"" description: ""Inventory path to a datacenter."" weight: 65 type: ""text"" regex: source: *non_empty_string error: 'Empty datacenter' restrictions: - ""settings:storage.vc_images_is_esx.value != false"" vc_image_dir: value: """" label: ""Datastore Images directory"" description: ""The name of the directory where the glance images will be stored in the VMware datastore."" weight: 70 type: ""text"" regex: source: *non_empty_string error: 'Empty images directory' restrictions: - ""settings:storage.images_vcenter.value == false"" weight: 75 weight: 80 weight: 85 weight: 5 weight: 5 - data: ""vcenter"" label: ""dialog.create_cluster_wizard.storage.vcenter"" bind: - ""settings:storage.images_vcenter.value"": true", weight: 35 weight: 40 weight: 70,93,4
openstack%2Fsahara~proposed%2Fjuno~I82249f8b9fb932c206876c2f6652c0a0b9e0650b,openstack/sahara,proposed/juno,I82249f8b9fb932c206876c2f6652c0a0b9e0650b,Remove line saying that scaling and EDP are not supported for Spark,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 15:51:58.000000000,2014-10-07 11:35:07.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/userdoc/spark_plugin.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ff3bf76318821336810709eb1ff4b88cf94b67c7', 'message': 'Remove line saying that scaling and EDP are not supported for Spark\n\nCloses-Bug: 1376364\nChange-Id: I82249f8b9fb932c206876c2f6652c0a0b9e0650b\n(cherry picked from commit e385e3ed02bddf4db3f0b82c800b2cc0e2c056ba)\n'}]",0,126393,ff3bf76318821336810709eb1ff4b88cf94b67c7,17,7,1,8411,,,0,"Remove line saying that scaling and EDP are not supported for Spark

Closes-Bug: 1376364
Change-Id: I82249f8b9fb932c206876c2f6652c0a0b9e0650b
(cherry picked from commit e385e3ed02bddf4db3f0b82c800b2cc0e2c056ba)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/93/126393/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userdoc/spark_plugin.rst'],1,ff3bf76318821336810709eb1ff4b88cf94b67c7,bug/1376457,,For now scaling and EDP are not supported. ,0,2
openstack%2Ffuel-web~master~Ibbde24e08df56b08a2a39994829bdbe2fad22513,openstack/fuel-web,master,Ibbde24e08df56b08a2a39994829bdbe2fad22513,[React] Node view,ABANDONED,2014-09-15 15:38:17.000000000,2014-10-07 15:40:36.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-09-15 15:38:17.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node.jsx', 'nailgun/static/i18n/translation.json', 'nailgun/static/templates/cluster/node_roles.html', 'nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/node.html', 'nailgun/static/js/models.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1529ba7a628e69abebc791a403a25a4abf88e0c6', 'message': '[React] Node view\n\nRelated to blueprint backbone-to-react\n\nChange-Id: Ibbde24e08df56b08a2a39994829bdbe2fad22513\n'}]",0,121603,1529ba7a628e69abebc791a403a25a4abf88e0c6,8,6,1,8766,,,0,"[React] Node view

Related to blueprint backbone-to-react

Change-Id: Ibbde24e08df56b08a2a39994829bdbe2fad22513
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/03/121603/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node.jsx', 'nailgun/static/i18n/translation.json', 'nailgun/static/templates/cluster/node_roles.html', 'nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/node.html', 'nailgun/static/js/models.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js']",7,1529ba7a628e69abebc791a403a25a4abf88e0c6,bp/backbone-to-react," 'jsx!views/cluster_page_tabs/nodes_tab_screens/node', 'text!templates/cluster/node_group.html'function(utils, models, dialogs, Screen, nodesManagementPanelTemplate, assignRolesPanelTemplate, nodeListTemplate, nodeGroupTemplate) { var NodeListScreen, NodesManagementPanel, AssignRolesPanel, NodeList, NodeGroup; var dialog = new dialogs.DeleteNodesDialog({nodes: nodes}); //var nodeView = new Node({node: node, group: this}); //this.registerSubView(nodeView); //this.$('.nodes-group').append(nodeView.render().el); this.clusterInfo = utils.universalMount(new Node({node: node, group: this}), this.$('.nodes-group'), this);"," 'text!templates/cluster/node_group.html', 'text!templates/cluster/node.html', 'text!templates/cluster/node_roles.html'function(utils, models, dialogViews, Screen, nodesManagementPanelTemplate, assignRolesPanelTemplate, nodeListTemplate, nodeGroupTemplate, nodeTemplate, nodeRoleTemplate) { var NodeListScreen, NodesManagementPanel, AssignRolesPanel, NodeList, NodeGroup, Node; var dialog = new dialogViews.DeleteNodesDialog({nodes: nodes}); var nodeView = new Node({ node: node, group: this }); this.registerSubView(nodeView); this.$('.nodes-group').append(nodeView.render().el); Node = Backbone.View.extend({ template: _.template(nodeTemplate), roleTemplate: _.template(nodeRoleTemplate), templateHelpers: _.pick(utils, 'showDiskSize', 'showMemorySize'), renaming: false, events: { 'click .node-renameable': 'startNodeRenaming', 'keydown .name input': 'onNodeNameInputKeydown', 'click .node-details': 'showNodeDetails', 'click .btn-discard-role-changes': 'discardRoleChanges', 'click .btn-discard-addition': 'discardAddition', 'click .btn-discard-deletion': 'discardDeletion', 'click .btn-view-logs': 'showNodeLogs' }, bindings: { '.role-list': { observe: ['roles', 'pending_roles'], update: function($el) { return $el.html(this.roleTemplate({ deployedRoles: this.sortRoles(this.node.get('roles')), pendingRoles: this.sortRoles(this.node.get('pending_roles')) })); } }, '.node': { attributes: [{ name: 'class', observe: 'checked', onGet: function(value, options) { return value ? 'node checked' : 'node'; } }] }, '.node-checkbox input': { observe: 'checked', attributes: [{ name: 'disabled', observe: 'disabled' }] }, '.node-status-label': { observe: ['status', 'online', 'pending_addition', 'pending_deletion'], onGet: 'formatStatusLabel' }, '.node-box': { attributes: [{ name: 'class', observe: ['status', 'online', 'pending_addition', 'pending_deletion', 'disabled'], onGet: 'formatNodePanelClass' }] }, '.node-status': { attributes: [{ name: 'class', observe: ['status', 'online', 'pending_addition', 'pending_deletion'], onGet: 'formatStatusBlockClass' }] }, '.progress': { attributes: [{ name: 'class', observe: 'status', onGet: function(value, options) { var progressBarClass = value == 'deploying' ? 'progress-success' : value == 'provisioning' ? '' : 'hide'; return 'progress ' + progressBarClass; } }] }, '.bar': { observe: 'progress', update: function($el, value) { value = _.max([value, 3]); $el.css('width', value + '%'); } }, '.node-status i': { observe: 'status', visible: function(value) { return !_.contains(['provisioning', 'deploying'], value); }, attributes: [{ name: 'class', observe: ['status', 'online', 'pending_addition', 'pending_deletion'], onGet: 'formatStatusIconClass' }] }, '.node-button button': { observe: 'cluster', visible: function(value) { return !_.isUndefined(value) && value != ''; }, attributes: [{ name: 'class', observe: ['pending_addition', 'pending_deletion', 'pending_roles'], onGet: 'formatNodeButtonClass' },{ name: 'title', observe: ['pending_addition', 'pending_deletion', 'pending_roles'], onGet: 'formatNodeButtonTitle' }] }, '.node-button i': { attributes: [{ name: 'class', observe: ['pending_addition', 'pending_deletion', 'pending_roles'], onGet: 'formatNodeButtonIcon' }] }, '.name p': { observe: ['name', 'mac'], onGet: function(values) { return values[0] || values[1]; } } }, sortRoles: function(roles) { roles = roles || []; var preferredOrder = this.screen.tab.model.get('release').get('roles'); return roles.sort(function(a, b) { return _.indexOf(preferredOrder, a) - _.indexOf(preferredOrder, b); }); }, defineNodeViewStatus: function() { return !this.node.get('online') ? 'offline' : this.node.get('pending_addition') ? 'pending_addition' : this.node.get('pending_deletion') ? 'pending_deletion' : this.node.get('status'); }, formatNodePanelClass: function(value, options) { var nodeClass = this.node.get('pending_deletion') ? 'node-delete' : this.node.get('pending_addition') ? 'node-new' : this.node.get('online') ? this.node.get('status') : 'node-offline'; return 'node-box ' + nodeClass + (this.node.get('disabled') ? ' disabled' : ''); }, formatStatusIconClass: function(value, options) { var icons = { offline: 'icon-block', pending_addition: 'icon-ok-circle-empty', pending_deletion: 'icon-cancel-circle', ready: 'icon-ok', provisioned: 'icon-install', error: 'icon-attention', discover: 'icon-ok-circle-empty' }; return icons[this.defineNodeViewStatus()] || ''; }, formatStatusBlockClass: function(value, options) { var classes = { offline: 'msg-offline', pending_addition: 'msg-ok', pending_deletion: 'msg-warning', ready: 'msg-ok', provisioning: 'provisioning', provisioned: 'msg-provisioned', deploying: 'deploying', error: 'msg-error', discover: 'msg-discover' }; return 'node-status ' + classes[this.defineNodeViewStatus()]; }, formatStatusLabel: function(value) { var operatingSystem; try { operatingSystem = this.node.collection.cluster.get('release').get('operating_system'); } catch (ignore) {} operatingSystem = operatingSystem || 'OS'; var labels = { offline: $.t('cluster_page.nodes_tab.node.status.offline'), pending_addition: $.t('cluster_page.nodes_tab.node.status.pending_addition'), pending_deletion: $.t('cluster_page.nodes_tab.node.status.pending_deletion'), ready: $.t('cluster_page.nodes_tab.node.status.ready'), provisioning: $.t('cluster_page.nodes_tab.node.status.installing_os', {os: operatingSystem}), provisioned: $.t('cluster_page.nodes_tab.node.status.os_is_installed', {os: operatingSystem}), deploying: $.t('cluster_page.nodes_tab.node.status.installing_openstack'), error: $.t('cluster_page.nodes_tab.node.status.error'), discover: $.t('cluster_page.nodes_tab.node.status.discovered') }; return labels[this.defineNodeViewStatus()] || ''; }, hasChanges: function() { return this.node.get('pending_addition') || this.node.get('pending_deletion') || (this.node.get('pending_roles') && this.node.get('pending_roles').length); }, formatNodeButtonClass: function(value, options) { var btnClass = this.node.get('pending_addition') ? 'addition' : this.node.get('pending_deletion') ? 'deletion' : 'role-changes'; return this.hasChanges() && !(this.screen instanceof this.screen.EditNodesScreen) ? 'btn btn-link btn-discard-node-changes btn-discard-' + btnClass : 'btn btn-link btn-view-logs'; }, formatNodeButtonTitle: function(value, options) { var title = this.node.get('pending_addition') ? $.t('cluster_page.nodes_tab.node.status.discard_addition') : this.node.get('pending_deletion') ? $.t('cluster_page.nodes_tab.node.status.discard_deletion') : $.t('cluster_page.nodes_tab.node.status.discard_role_changes'); return this.hasChanges() && !(this.screen instanceof this.screen.EditNodesScreen) ? title : $.t('cluster_page.nodes_tab.node.status.view_logs'); }, formatNodeButtonIcon: function(value, options) { return this.hasChanges() && !(this.screen instanceof this.screen.EditNodesScreen) ? 'icon-back-in-time' : 'icon-logs'; }, calculateNodeState: function() { this.node.set('disabled', !this.node.isSelectable() || this.screen instanceof this.screen.EditNodesScreen || this.screen.isLocked()); if (this.screen.isLocked()) { this.node.set('checked', false); } }, startNodeRenaming: function() { $('html').on(this.eventNamespace, _.bind(function(e) { // FIXME: 'node-renameable' class usage should be revised if ($(e.target).hasClass('node-name') || $(e.target).hasClass('node-renameable')) { e.preventDefault(); } else { this.endNodeRenaming(); } }, this)); this.renaming = true; this.render(); this.$('.node-name').focus(); }, endNodeRenaming: function() { $('html').off(this.eventNamespace); this.renaming = false; this.render(); }, applyNewNodeName: function() { var name = $.trim(this.$('.node-name').val()); if (name && name != this.node.get('name')) { this.$('.node-name').attr('disabled', true); this.screen.nodes.get(this.node.id).save({name: name}, {patch: true, wait: true}).always(_.bind(this.endNodeRenaming, this)); } else { this.endNodeRenaming(); } }, onNodeNameInputKeydown: function(e) { if (e.which == 13) { this.applyNewNodeName(); } else if (e.which == 27) { this.endNodeRenaming(); } }, showNodeDetails: function(e) { e.preventDefault(); var dialog = new dialogViews.ShowNodeInfoDialog({node: this.node}); app.page.tab.registerSubView(dialog); dialog.render(); }, updateNode: function(data) { this.node.save(data, {patch: true, wait: true}) .done(_.bind(function() { this.screen.tab.model.fetch(); this.screen.tab.model.fetchRelated('nodes'); app.navbar.refresh(); app.page.removeFinishedNetworkTasks(); }, this)) .fail(function() {utils.showErrorDialog({title: $.t('dialog.discard_changes.cant_discard')});}); }, discardRoleChanges: function(e) { e.preventDefault(); var data = {pending_roles: []}; if (this.node.get('pending_addition')) { data.cluster = null; data.pending_addition = false; } this.updateNode(data); }, discardAddition: function(e) { e.preventDefault(); this.updateNode({ cluster_id: null, pending_addition: false, pending_roles: [] }); }, discardDeletion: function(e) { e.preventDefault(); this.updateNode({pending_deletion: false}); }, showNodeLogs: function() { var status = this.node.get('status'); var error = this.node.get('error_type'); var options = {type: 'remote', node: this.node.id}; if (status == 'discover') { options.source = 'bootstrap/messages'; } else if (status == 'provisioning' || status == 'provisioned' || (status == 'error' && error == 'provision')) { options.source = 'install/anaconda'; } else if (status == 'deploying' || status == 'ready' || (status == 'error' && error == 'deploy')) { options.source = 'install/puppet'; } app.navigate('#cluster/' + this.screen.tab.model.id + '/logs/' + utils.serializeTabOptions(options), {trigger: true}); }, beforeTearDown: function() { $('html').off(this.eventNamespace); }, initialize: function(options) { _.defaults(this, options); this.screen = this.group.nodeList.screen; this.eventNamespace = 'click.editnodename' + this.node.id; this.node.on('change:checked', function(node, checked, options) { this.screen.nodes.get(node.id).set('checked', checked); }, this); this.node.set('checked', this.screen instanceof this.screen.EditNodesScreen || this.screen.nodes.get(this.node.id).get('checked') || false); this.node.on('change:status', this.calculateNodeState, this); this.node.on('change:disabled', this.group.calculateSelectAllDisabledState, this.group); if (!(this.screen instanceof this.screen.ClusterNodesScreen)) { this.node.on('change:checked', this.screen.roles.handleChanges, this.screen.roles); } }, render: function() { this.tearDownRegisteredSubViews(); this.$el.html(this.template(_.extend({ node: this.node, renaming: this.renaming, edit: this.screen instanceof this.screen.EditNodesScreen, locked: this.screen.isLocked() }, this.templateHelpers))).i18n(); this.stickit(this.node); this.calculateNodeState(); return this; } }); ",273,407
openstack%2Fnova~master~I67848bff188c057c879864b2987c7b21d4571e37,openstack/nova,master,I67848bff188c057c879864b2987c7b21d4571e37,Validate tenant and user IDs when querying or modifying quotas,ABANDONED,2014-05-02 19:06:13.000000000,2014-10-07 15:34:50.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 136}, {'_account_id': 1501}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-02 19:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b24ec539f57cea534e351c5030cdaa0f1960c598', 'message': ""Validate tenant and user IDs when querying or modifying quotas\n\nThe following patch affects nova quota-show, quota-update, and\nquota-delete.  When a tenant or user is specified in one of the\nquota actions above, they are not checked against keystone to\nvalidate that their IDs are valid.  A user could specify a\ntenant or user name instead of the tenant or user ID.  Since\nno checks are done, an entry is created in nova's\nproject_user_quotas table where the project_id or user_id is\nset to the tenant or user name.  This causes invalid quotas to be\nset and returned if the tenant or user ID does not match what is\nin the project_user_quotas table.  The following patch fixes this\nbug by querying keystone and checking that the tenant and user IDs\npassed in are valid.\n\nChange-Id: I67848bff188c057c879864b2987c7b21d4571e37\nPartial-Bug: #1313935\n""}, {'number': 2, 'created': '2014-08-14 12:43:47.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_quotas.py', 'nova/tests/integrated/test_api_samples.py', 'nova/api/openstack/compute/contrib/quotas.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1090af0746a663c79161a9a4b937995358976d84', 'message': ""Validate tenant and user IDs when querying or modifying quotas\n\nThe following patch affects nova quota-show, quota-update, and\nquota-delete.  When a tenant or user is specified in one of the\nquota actions above, they are not checked against keystone to\nvalidate that their IDs are valid.  A user could specify a\ntenant or user name instead of the tenant or user ID.  Since\nno checks are done, an entry is created in nova's\nproject_user_quotas table where the project_id or user_id is\nset to the tenant or user name.  This causes invalid quotas to be\nset and returned if the tenant or user ID does not match what is\nin the project_user_quotas table.  The following patch fixes this\nbug by querying keystone and checking that the tenant and user IDs\npassed in are valid.\n\nChange-Id: I67848bff188c057c879864b2987c7b21d4571e37\nPartial-Bug: #1313935\n""}]",2,91866,1090af0746a663c79161a9a4b937995358976d84,33,11,2,8247,,,0,"Validate tenant and user IDs when querying or modifying quotas

The following patch affects nova quota-show, quota-update, and
quota-delete.  When a tenant or user is specified in one of the
quota actions above, they are not checked against keystone to
validate that their IDs are valid.  A user could specify a
tenant or user name instead of the tenant or user ID.  Since
no checks are done, an entry is created in nova's
project_user_quotas table where the project_id or user_id is
set to the tenant or user name.  This causes invalid quotas to be
set and returned if the tenant or user ID does not match what is
in the project_user_quotas table.  The following patch fixes this
bug by querying keystone and checking that the tenant and user IDs
passed in are valid.

Change-Id: I67848bff188c057c879864b2987c7b21d4571e37
Partial-Bug: #1313935
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/91866/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_quotas.py', 'nova/tests/integrated/test_api_samples.py', 'nova/api/openstack/compute/contrib/quotas.py']",3,b24ec539f57cea534e351c5030cdaa0f1960c598,bug/1313935,"from keystoneclient.v2_0 import client as keyclientfrom oslo.config import cfgdef keystoneclient(username=None, tenant_name=None, password=None, auth_url=None): """"""Returns a client connected to the Keystone backend."""""" keystone_conf = cfg.CONF.keystone_authtoken keystone_auth_url = ('%s://%s:%s/v2.0/' % (keystone_conf.auth_protocol, keystone_conf.auth_host, keystone_conf.auth_port)) username = username or keystone_conf.admin_user tenant_name = tenant_name or keystone_conf.admin_tenant_name password = password or keystone_conf.admin_password auth_url = auth_url or keystone_auth_url return keyclient.Client(username=username, password=password, tenant_name=tenant_name, auth_url=auth_url) def _get_tenant_by_id(self, id): try: return keystoneclient().tenants.get(id) except Exception: LOG.debug('Unable to find tenant: %r', id) return None def _get_user_by_id(self, id): try: return keystoneclient().users.get(id) except Exception: LOG.debug('Unable to find user: %r', id) return None if not self._get_tenant_by_id(id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid tenant ID"")) if user_id and not self._get_user_by_id(user_id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid user ID"")) if not self._get_tenant_by_id(project_id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid tenant ID"")) if user_id and not self._get_user_by_id(user_id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid user ID"")) # If no tenant is specified, the id passed in is the string 'None' if id != 'None' and not self._get_tenant_by_id(id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid tenant ID"")) if user_id and not self._get_user_by_id(user_id): raise webob.exc.HTTPBadRequest( explanation=_(""Invalid user ID"")) ",,349,8
openstack%2Fnova~proposed%2Fjuno~Ibe278688b118db01c9c3ae1763954adf19c7ee0d,openstack/nova,proposed/juno,Ibe278688b118db01c9c3ae1763954adf19c7ee0d,Fix KeyError for euca-describe-images,MERGED,2014-10-07 11:24:36.000000000,2014-10-07 15:30:12.000000000,2014-10-07 15:30:10.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 4428}]","[{'number': 1, 'created': '2014-10-07 11:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd14d7477711091b22c78981fd404e339cd5730e', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n'}, {'number': 2, 'created': '2014-10-07 12:05:08.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f98c28228b6db5b0796e9669b6bd692b82bbfa6d', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n(cherry picked from commit 1dea1cd710d54d4a2a584590e4ccf59dd3a41faa)\n'}]",0,126520,f98c28228b6db5b0796e9669b6bd692b82bbfa6d,9,4,2,308,,,0,"Fix KeyError for euca-describe-images

EC2 describe images crashes on volume backed instance snapshot which has
several volumes.

Change-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d
Closes-bug: #1370265
(cherry picked from commit 1dea1cd710d54d4a2a584590e4ccf59dd3a41faa)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/126520/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py']",2,fd14d7477711091b22c78981fd404e339cd5730e,, if bdm.get('deviceName') == mappings[i].get('deviceName'):, if bdm['deviceName'] == mappings[i]['deviceName']:,52,1
openstack%2Fceilometer~proposed%2Fjuno~I8f350b9009f0d8c172836b1dd1123e966f887fdb,openstack/ceilometer,proposed/juno,I8f350b9009f0d8c172836b1dd1123e966f887fdb,Fix neutron client to catch 404 exceptions,MERGED,2014-10-07 12:07:27.000000000,2014-10-07 15:30:01.000000000,2014-10-07 15:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 3012}, {'_account_id': 6924}]","[{'number': 1, 'created': '2014-10-07 12:07:27.000000000', 'files': ['ceilometer/neutron_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aa15b2d7ed02822b72f878e889b3a77c97b4a6c5', 'message': ""Fix neutron client to catch 404 exceptions\n\nWhen network services such as lbaas, fwaas or vpnaas are disabled\nin neutron, the discovery continues to poll the api calls and gets\nback a not found exception. The fix here is to catch the exception\nso it doesn't go unhandled.\n\nChange-Id: I8f350b9009f0d8c172836b1dd1123e966f887fdb\nCloses-Bug: #1374012\n(cherry picked from commit b65554eb460a282a2ab0a2dcc0053a8691cb9373)\n""}]",0,126541,aa15b2d7ed02822b72f878e889b3a77c97b4a6c5,7,4,1,2284,,,0,"Fix neutron client to catch 404 exceptions

When network services such as lbaas, fwaas or vpnaas are disabled
in neutron, the discovery continues to poll the api calls and gets
back a not found exception. The fix here is to catch the exception
so it doesn't go unhandled.

Change-Id: I8f350b9009f0d8c172836b1dd1123e966f887fdb
Closes-Bug: #1374012
(cherry picked from commit b65554eb460a282a2ab0a2dcc0053a8691cb9373)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/41/126541/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/neutron_client.py'],1,aa15b2d7ed02822b72f878e889b3a77c97b4a6c5,,from neutronclient.common import exceptions except exceptions.NeutronClientException as e: # handles 404's when services are disabled in neutron LOG.warn(e) return [],,5,0
openstack%2Fnova~master~I1b585cba39913ff4609c6d86dcafc07e6c04e2b8,openstack/nova,master,I1b585cba39913ff4609c6d86dcafc07e6c04e2b8,libvirt: convert conn test case to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-07 15:28:25.000000000,2014-10-07 15:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce4c25708d72f4f122b25b458b69b886c1ab0e67', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 2, 'created': '2014-09-17 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4e73614af2bc3ac20e5d4e5eb01047e0b47cf5e', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/508f16c85e09ad43d0a2c64edb93fcae692ed9d9', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4394c798699da0071bf32d21ce2ec51aea0b34d6', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e150229fcc611a6a66c014d71f2ab014741b7f1', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 6, 'created': '2014-10-01 17:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab642fb35324f4182cd1c314096ebc6966440e2f', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 7, 'created': '2014-10-01 17:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/589b48ba4266f0c0634b35e433cd6c65c3626d0f', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 8, 'created': '2014-10-03 09:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/972d9b665328c550be0ca0c3b3c571d52d554a60', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nUpdates the comment in _get_cpu_numa_config_from_instance to\nbe explicit about which test cases remain to be converted\nafter this change.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}, {'number': 9, 'created': '2014-10-06 16:22:10.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2fc92d9bd7b4e212a3f28e57565a4cf260982f30', 'message': 'libvirt: convert conn test case to avoid DB usage\n\nThe LibvirtConnTestCase uses the database for alot of random\nstuff. With a bunch more mocking, it can be converted to use\nNoDBTestCase which improves perf from 50s to 9s.\n\nUpdates the comment in _get_cpu_numa_config_from_instance to\nbe explicit about which test cases remain to be converted\nafter this change.\n\nCloses-bug: #1369516\nChange-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8\n'}]",0,121876,2fc92d9bd7b4e212a3f28e57565a4cf260982f30,63,13,9,1779,,,0,"libvirt: convert conn test case to avoid DB usage

The LibvirtConnTestCase uses the database for alot of random
stuff. With a bunch more mocking, it can be converted to use
NoDBTestCase which improves perf from 50s to 9s.

Updates the comment in _get_cpu_numa_config_from_instance to
be explicit about which test cases remain to be converted
after this change.

Closes-bug: #1369516
Change-Id: I1b585cba39913ff4609c6d86dcafc07e6c04e2b8
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/121876/9 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,ce4c25708d72f4f122b25b458b69b886c1ab0e67,libvirt-nodb-tests,"class LibvirtConnTestCase(test.NoDBTestCase, sys_meta = { 'instance_type_memory_mb': 2048, 'instance_type_swap': 0, 'instance_type_vcpu_weight': None, 'instance_type_root_gb': 1, 'instance_type_id': 2, 'instance_type_name': u'm1.small', 'instance_type_ephemeral_gb': 0, 'instance_type_rxtx_factor': 1.0, 'instance_type_flavorid': u'1', 'instance_type_vcpus': 1 } 'id': 1, 'uuid': '32dfcb37-5af1-552b-357c-be8c3aa38310', 'memory_kb': '1024000', 'basepath': '/some/path', 'bridge_name': 'br100', 'display_name': ""Acme webserver"", 'vcpus': 2, 'project_id': 'fake', 'bridge': 'br101', 'image_ref': '155d900f-4e14-4e4c-a73d-069cbf4541e6', 'root_gb': 10, 'ephemeral_gb': 20, 'instance_type_id': '5', # m1.small 'extra_specs': {}, 'system_metadata': sys_meta, 'pci_devices': objects.PciDeviceList(), 'numa_topology': None, 'config_drive': None, 'vm_mode': None, 'kernel_id': None, 'ramdisk_id': None, 'os_type': 'linux', 'user_id': '838a72b0-0d54-4827-8fd6-fb1227633ceb', 'ephemeral_key_uuid': None, } return objects.Service(**service_ref) @mock.patch.object(objects.Service, 'get_by_compute_host') def test_set_host_enabled_with_disable(self, mock_svc): svc = self._create_service(host='fake-mini') mock_svc.return_value = svc self.assertTrue(svc.disabled) @mock.patch.object(objects.Service, 'get_by_compute_host') def test_set_host_enabled_with_enable(self, mock_svc): svc = self._create_service(disabled=True, host='fake-mini') mock_svc.return_value = svc self.assertTrue(svc.disabled) @mock.patch.object(objects.Service, 'get_by_compute_host') def test_set_host_enabled_with_enable_state_enabled(self, mock_svc): svc = self._create_service(disabled=False, host='fake-mini') mock_svc.return_value = svc self.assertFalse(svc.disabled) @mock.patch.object(objects.Service, 'get_by_compute_host') def test_set_host_enabled_with_disable_state_disabled(self, mock_svc): svc = self._create_service(disabled=True, host='fake-mini') mock_svc.return_value = svc self.assertTrue(svc.disabled) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config(self, time_mock, mock_save, mock_flavor): flavor = objects.Flavor(name='m1.small', memory_mb=6, vcpus=28, root_gb=496, ephemeral_gb=8128, swap=33550336, extra_specs={}) instance_ref = objects.Instance(**test_instance) mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info, context=ctxt) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_lxc(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_lxc_with_id_maps(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_numa_host_instance_fits(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_numa_host_instance_no_fit(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_non_numa_host_instance_topo(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) instance_ref.numa_topology = instance_topology mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_numa_host_instance_topo(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) instance_ref.numa_topology = instance_topology mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_clock(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_windows(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_two_nics(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_bug_1118829(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_root_device_name(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_block_device(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_lxc_with_attached_volume(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_configdrive(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_virtio_scsi_bus(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_virtio_scsi_bus_bdm(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_vnc(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_vnc_and_tablet(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_spice_and_tablet(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_spice_and_agent(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_serial_console(self, acquire_port, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_serial_console_through_flavor(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw:serial_port_count': 3} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(10, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[9], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""tcp"", cfg.devices[2].type) self.assertEqual(""tcp"", cfg.devices[3].type) self.assertEqual(""tcp"", cfg.devices[4].type) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_serial_console_invalid_flavor(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw:serial_port_count': ""a""} mock_flavor.return_value = flavor self.assertRaises( exception.ImageSerialPortNumberInvalid, conn._get_guest_config, instance_ref, [], {}, disk_info) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_serial_console_image_and_flavor(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw:serial_port_count': 4} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(10, len(cfg.devices), cfg.devices) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[9], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""tcp"", cfg.devices[2].type) self.assertEqual(""tcp"", cfg.devices[3].type) self.assertEqual(""tcp"", cfg.devices[4].type) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_serial_console_invalid_img_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') self, acquire_port, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_type_xen(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_type_xen_pae_hvm(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_type_xen_pae_pvm(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_vnc_and_spice(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_invalid_watchdog_action(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_watchdog_action_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_watchdog_action_flavor(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_watchdog_action': 'none'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(9, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestWatchdog) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""none"", cfg.devices[7].action) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_watchdog_overrides_flavor(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_watchdog_action': 'none'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(9, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestWatchdog) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""pause"", cfg.devices[7].action) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_unsupported_video_driver_through_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_video_driver_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_qga_through_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_video_driver_vram(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_video:ram_max_mb': ""100""} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestChannel) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], self.assertEqual(cfg.devices[5].type, ""spice"") self.assertEqual(cfg.devices[6].type, ""qxl"") self.assertEqual(cfg.devices[6].vram, 64) instance_ref = objects.Instance(**self.test_instance) with contextlib.nested( mock.patch.object(objects.Flavor, 'get_by_id'), mock.patch.object(objects.Instance, 'save'), ) as (mock_flavor, mock_instance): flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor def test_video_driver_ram_above_flavor_limit(self): self.flags(virt_type='kvm', group='libvirt') self.flags(enabled=True, agent_enabled=True, group='spice') instance_ref = objects.Instance(**self.test_instance) instance_type = instance_ref.get_flavor() instance_type.extra_specs = {'hw_video:ram_max_mb': ""50""} conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) image_meta = {""properties"": {""hw_video_model"": ""qxl"", ""hw_video_ram"": ""64""}} with contextlib.nested( mock.patch.object(objects.Flavor, 'get_by_id', return_value=instance_type), mock.patch.object(objects.Instance, 'save')): self.assertRaises(exception.RequestedVRamTooHigh, conn._get_guest_config, instance_ref, [], image_meta, disk_info) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_without_qga_through_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_rng_device(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_rng:allowed': 'True'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertIsNone(cfg.devices[6].backend) self.assertIsNone(cfg.devices[6].rate_bytes) self.assertIsNone(cfg.devices[6].rate_period) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_rng_not_allowed(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_rng_limits(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_rng:allowed': 'True', 'hw_rng:rate_bytes': '1024', 'hw_rng:rate_period': '2'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertIsNone(cfg.devices[6].backend) self.assertEqual(cfg.devices[6].rate_bytes, 1024) self.assertEqual(cfg.devices[6].rate_period, 2) @mock.patch('nova.virt.libvirt.driver.os.path.exists') @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_rng_backend(self, mock_save, mock_flavor, mock_path): mock_path.return_value = True instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_rng:allowed': 'True'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertEqual(cfg.devices[6].backend, '/dev/hw_rng') self.assertIsNone(cfg.devices[6].rate_bytes) self.assertIsNone(cfg.devices[6].rate_period) @mock.patch('nova.virt.libvirt.driver.os.path.exists') @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_rng_dev_not_present(self, mock_save, mock_flavor, mock_path): mock_path.return_value = False instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'hw_rng:allowed': 'True'} mock_flavor.return_value = flavor self.assertRaises(exception.RngDeviceNotExist, conn._get_guest_config, instance_ref, [], image_meta, disk_info) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_cpu_quota(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'quota:cpu_shares': '10000', 'quota:cpu_period': '20000'} mock_flavor.return_value = flavor cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(10000, cfg.cputune.shares) self.assertEqual(20000, cfg.cputune.period) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_bogus_cpu_quota(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {'quota:cpu_shares': 'fishfood', 'quota:cpu_period': '20000'} mock_flavor.return_value = flavor self.assertRaises(ValueError, conn._get_guest_config, instance_ref, [], {}, disk_info) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _test_get_guest_config_sysinfo_serial(self, expected_serial, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor 'id': 1729, service_ref = objects.Service(**service_info) 'id': 1729, compute_ref = objects.ComputeNode(**compute_info) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_pci_passthrough_kvm(self, mock_save, mock_flavor): instance = objects.Instance(**self.test_instance) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor extra_info={}) pci_device = objects.PciDevice(**pci_device_info) pci_list = objects.PciDeviceList() pci_list.objects.append(pci_device) instance.pci_devices = pci_list @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_with_pci_passthrough_xen(self, mock_save, mock_flavor): instance = objects.Instance(**self.test_instance) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor extra_info={}) pci_device = objects.PciDevice(**pci_device_info) pci_list = objects.PciDeviceList() pci_list.objects.append(pci_device) instance.pci_devices = pci_list @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_os_command_line_through_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_os_command_line_without_kernel_id(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_os_command_empty(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_armv7(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_aarch64(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_machine_type_through_image_meta(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_config_machine_type_from_config(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _test_get_guest_config_ppc64(self, device_index, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_none(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_default_kvm(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_default_uml(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_default_lxc(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_host_passthrough(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_host_model(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_config_custom(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_cpu_topology(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_by_default(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_disable(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_period_value(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_qemu(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_xen(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_get_guest_memory_balloon_config_lxc(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor self._check_xml_and_disk_prefix(instance_data, None) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**self.test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**test_instance) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**test_instance) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) instance_ref = objects.Instance(**test_instance) instance_ref.info_cache = objects.InstanceInfoCache( network_info=None) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_multi_nic(self, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _check_xml_and_container(self, instance, mock_save, mock_flavor): instance_ref = objects.Instance(**instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor (lambda t: t.find('.').get('type'), 'lxc'), (lambda t: t.find('./os/type').text, 'exe'), (lambda t: t.find('./devices/filesystem/target').get('dir'), '/')] @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _check_xml_and_disk_prefix(self, instance, prefix, mock_save, mock_flavor): instance_ref = objects.Instance(**instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _check_xml_and_disk_driver(self, image_meta, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') block_device_info, wantConfig, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _check_xml_and_uuid(self, image_meta, mock_save, mock_flavor): instance_ref = objects.Instance(**self.test_instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def _check_xml_and_uri(self, instance, mock_save, mock_flavor, expect_ramdisk=False, expect_kernel=False, rescue=None, expect_xen_hvm=False, xen_only=False): instance_ref = objects.Instance(**instance) flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor expected_result, '%s != %s failed check %d' % (check(tree), expected_result, i)) expected_result, '%s != %s failed common check %d' % (check(tree), expected_result, i)) instance_ref = objects.Instance(**self.test_instance) def test_check_can_live_migrate_dest_all_pass_with_block_migration(self): instance_ref = objects.Instance(**self.test_instance) instance_ref = objects.Instance(**self.test_instance) instance_ref = objects.Instance(**self.test_instance) objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) self.assertEqual(vm_states.ACTIVE, instance_ref.vm_state) self.assertEqual(power_state.RUNNING, instance_ref.power_state) inst_ref = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance_ref = objects.Instance(**self.test_instance) instance_ref = objects.Instance(**self.test_instance) @mock.patch.object(objects.Flavor, 'get_by_id') @mock.patch.object(objects.Instance, 'save') def test_spawn_with_network_info(self, mock_save, mock_flavor): instance = objects.Instance(**instance_ref) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) inst_obj = objects.Instance(**instance_ref) flavor = inst_obj.get_flavor() flavor.extra_specs = {} mock.patch('nova.virt.disk.api.teardown_container'), mock.patch.object(objects.Instance, 'save'), mock.patch.object(objects.Flavor, 'get_by_id', return_value=flavor)): instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**instance_ref) instance = objects.Instance(**instance_ref) instance = objects.Instance(**self.test_instance) self.stubs.Set(pci_manager, 'get_instance_pci_devs', lambda *a: []) self.stubs.Set(pci_manager, 'get_instance_pci_devs', lambda *a: []) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**inst_ref) flavor = instance.get_flavor() flavor.extra_specs = {} mock.patch.object(conn, '_create_domain_and_network'), mock.patch.object(objects.Flavor, 'get_by_id', return_value = flavor), mock.patch.object(objects.Instance, 'save')): @mock.patch.object(objects.Flavor, 'get_by_id') mock_attachDevice, mock_flavor): instance = objects.Instance(**self.test_instance) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor @mock.patch.object(objects.Flavor, 'get_by_id') mock_attachDevice, mock_flavor): instance = objects.Instance(**self.test_instance) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor instance.info_cache = objects.InstanceInfoCache( network_info=network_info) @mock.patch.object(objects.Flavor, 'get_by_id') mock_has_min_version, mock_flavor): instance = objects.Instance(**self.test_instance) flavor = instance.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor instance.info_cache = objects.InstanceInfoCache( network_info=network_info) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) @mock.patch.object(objects.Flavor, 'get_by_id') def _test_attach_detach_interface_get_config(self, method_name, mock_flavor): instance = objects.Instance(**self.test_instance) mock_flavor.return_value = instance.get_flavor() fake_image_meta = {'id': instance['image_ref']} if method_name == ""attach_interface"": self.mox.StubOutWithMock(conn.firewall_driver, 'setup_basic_filtering') conn.firewall_driver.setup_basic_filtering(instance, network_info) expected = conn.vif_driver.get_config(instance, network_info[0], instance.get_flavor(), conn.vif_driver.get_config(instance, network_info[0], conn.attach_interface(instance, fake_image_meta, conn.detach_interface(instance, network_info[0]) instance = objects.Instance(**instance_ref) flavor = instance.get_flavor() flavor.extra_specs = {} with contextlib.nested( mock.patch.object( driver_block_device.DriverVolumeBlockDevice, 'save'), mock.patch.object(objects.Flavor, 'get_by_id', return_value=flavor), mock.patch.object(objects.Instance, 'save')):","from nova.compute import flavorsclass LibvirtConnTestCase(test.TestCase, self.useFixture(test.SampleNetworks()) flavor = db.flavor_get(self.context, 5) sys_meta = flavors.save_flavor_info({}, flavor) 'uuid': '32dfcb37-5af1-552b-357c-be8c3aa38310', 'memory_kb': '1024000', 'basepath': '/some/path', 'bridge_name': 'br100', 'vcpus': 2, 'project_id': 'fake', 'bridge': 'br101', 'image_ref': '155d900f-4e14-4e4c-a73d-069cbf4541e6', 'root_gb': 10, 'ephemeral_gb': 20, 'instance_type_id': '5', # m1.small 'extra_specs': {}, 'system_metadata': sys_meta, ""pci_devices"": []} return db.service_create(context.get_admin_context(), service_ref) def _get_host_disabled(self, host): return db.service_get_by_compute_host(context.get_admin_context(), host)['disabled'] def test_set_host_enabled_with_disable(self): self._create_service(host='fake-mini') self.assertTrue(self._get_host_disabled('fake-mini')) def test_set_host_enabled_with_enable(self): self._create_service(disabled=True, host='fake-mini') self.assertTrue(self._get_host_disabled('fake-mini')) def test_set_host_enabled_with_enable_state_enabled(self): self._create_service(disabled=False, host='fake-mini') self.assertFalse(self._get_host_disabled('fake-mini')) def test_set_host_enabled_with_disable_state_disabled(self): self._create_service(disabled=True, host='fake-mini') self.assertTrue(self._get_host_disabled('fake-mini')) def create_instance_obj(self, context, **params): default_params = self.test_instance default_params['pci_devices'] = objects.PciDeviceList() default_params.update(params) instance = objects.Instance(context, **params) flavor = flavors.get_default_flavor() instance.system_metadata = flavors.save_flavor_info({}, flavor) instance.instance_type_id = flavor['id'] instance.create() return instance def test_get_guest_config(self, time_mock): flavor = objects.Flavor.get_by_id( ctxt, test_instance[""instance_type_id""]) flavor.memory_mb = 6 flavor.vcpus = 28 flavor.root_gb = 496 flavor.ephemeral_gb = 8128 flavor.swap = 33550336 instance_ref = db.instance_create(ctxt, test_instance) with mock.patch.object(objects.Flavor, ""get_by_id"") as flavor_mock: flavor_mock.return_value = flavor cfg = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info, context=ctxt) def test_get_guest_config_lxc(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_lxc_with_id_maps(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_numa_host_instance_fits(self): instance_ref = db.instance_create(self.context, self.test_instance) objects.Flavor, ""get_by_id"", return_value=flavor), mock.patch.object( def test_get_guest_config_numa_host_instance_no_fit(self): instance_ref = db.instance_create(self.context, self.test_instance) objects.Flavor, ""get_by_id"", return_value=flavor), mock.patch.object( def test_get_guest_config_non_numa_host_instance_topo(self): instance_ref = db.instance_create(self.context, self.test_instance) objects.Flavor, ""get_by_id"", return_value=flavor), mock.patch.object( def test_get_guest_config_numa_host_instance_topo(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_clock(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_windows(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_two_nics(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_bug_1118829(self): instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_get(self.context, instance_ref['id']) def test_get_guest_config_with_root_device_name(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_block_device(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_lxc_with_attached_volume(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_configdrive(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_virtio_scsi_bus(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_virtio_scsi_bus_bdm(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_vnc(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_vnc_and_tablet(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_spice_and_tablet(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_spice_and_agent(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_serial_console(self, acquire_port): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_serial_console_through_flavor(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw:serial_port_count': 3} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(10, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[9], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""tcp"", cfg.devices[2].type) self.assertEqual(""tcp"", cfg.devices[3].type) self.assertEqual(""tcp"", cfg.devices[4].type) def test_get_guest_config_serial_console_through_invalid_flavor(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw:serial_port_count': ""a""} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): self.assertRaises( exception.ImageSerialPortNumberInvalid, conn._get_guest_config, instance_ref, [], {}, disk_info) def test_get_guest_config_serial_console_image_meta_and_flavor(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw:serial_port_count': 4} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(10, len(cfg.devices), cfg.devices) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[9], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""tcp"", cfg.devices[2].type) self.assertEqual(""tcp"", cfg.devices[3].type) self.assertEqual(""tcp"", cfg.devices[4].type) def test_get_guest_config_serial_console_through_invalid_img_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) self, acquire_port): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_type_xen(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_type_xen_pae_hvm(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_type_xen_pae_pvm(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_vnc_and_spice(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_invalid_watchdog_action(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_watchdog_action_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_watchdog_action_through_flavor(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_watchdog_action': 'none'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(9, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestWatchdog) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""none"", cfg.devices[7].action) def test_get_guest_config_with_watchdog_action_meta_overrides_flavor(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_watchdog_action': 'none'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(9, len(cfg.devices)) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestInput) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigGuestWatchdog) self.assertIsInstance(cfg.devices[8], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(""pause"", cfg.devices[7].action) def test_unsupported_video_driver_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_video_driver_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_qga_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_video_driver_vram(self): instance_type = objects.Flavor.get_by_id(self.context, 5) instance_type.extra_specs = {'hw_video:ram_max_mb': ""100""} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=instance_type): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestChannel) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[7], self.assertEqual(cfg.devices[5].type, ""spice"") self.assertEqual(cfg.devices[6].type, ""qxl"") self.assertEqual(cfg.devices[6].vram, 64) instance_ref = db.instance_create(self.context, self.test_instance) self.assertRaises(exception.RequestedVRamTooHigh, conn._get_guest_config, instance_ref, [], image_meta, disk_info) def test_video_driver_ram_above_flavor_limit(self): self.flags(virt_type='kvm', group='libvirt') self.flags(enabled=True, agent_enabled=True, group='spice') instance_type = objects.Flavor.get_by_id(self.context, 5) instance_type.extra_specs = {'hw_video:ram_max_mb': ""50""} conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = db.instance_create(self.context, self.test_instance) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) image_meta = {""properties"": {""hw_video_model"": ""qxl"", ""hw_video_ram"": ""64""}} with mock.patch.object(objects.Flavor, 'get_by_id', return_value=instance_type): def test_get_guest_config_without_qga_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_rng_device(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertIsNone(cfg.devices[6].backend) self.assertIsNone(cfg.devices[6].rate_bytes) self.assertIsNone(cfg.devices[6].rate_period) def test_get_guest_config_with_rng_not_allowed(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_with_rng_limits(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_rng:allowed': 'True', 'hw_rng:rate_bytes': '1024', 'hw_rng:rate_period': '2'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertIsNone(cfg.devices[6].backend) self.assertEqual(cfg.devices[6].rate_bytes, 1024) self.assertEqual(cfg.devices[6].rate_period, 2) def test_get_guest_config_with_rng_backend(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} instance_ref = db.instance_create(self.context, self.test_instance) with contextlib.nested(mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor), mock.patch('nova.virt.libvirt.driver.os.path.exists', return_value=True)): cfg = conn._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(len(cfg.devices), 8) self.assertIsInstance(cfg.devices[0], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[1], vconfig.LibvirtConfigGuestDisk) self.assertIsInstance(cfg.devices[2], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[3], vconfig.LibvirtConfigGuestSerial) self.assertIsInstance(cfg.devices[4], vconfig.LibvirtConfigGuestGraphics) self.assertIsInstance(cfg.devices[5], vconfig.LibvirtConfigGuestVideo) self.assertIsInstance(cfg.devices[6], vconfig.LibvirtConfigGuestRng) self.assertIsInstance(cfg.devices[7], vconfig.LibvirtConfigMemoryBalloon) self.assertEqual(cfg.devices[6].model, 'random') self.assertEqual(cfg.devices[6].backend, '/dev/hw_rng') self.assertIsNone(cfg.devices[6].rate_bytes) self.assertIsNone(cfg.devices[6].rate_period) def test_get_guest_config_with_rng_dev_not_present(self): fake_flavor = objects.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} instance_ref = db.instance_create(self.context, self.test_instance) with contextlib.nested(mock.patch.object(objects.Flavor, 'get_by_id', return_value=fake_flavor), mock.patch('nova.virt.libvirt.driver.os.path.exists', return_value=False)): self.assertRaises(exception.RngDeviceNotExist, conn._get_guest_config, instance_ref, [], image_meta, disk_info) def test_get_guest_config_with_cpu_quota(self): fake_flavor = objects.flavor.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'quota:cpu_shares': '10000', 'quota:cpu_period': '20000'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.flavor.Flavor, 'get_by_id', return_value=fake_flavor): cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertEqual(10000, cfg.cputune.shares) self.assertEqual(20000, cfg.cputune.period) def test_get_guest_config_with_bogus_cpu_quota(self): fake_flavor = objects.flavor.Flavor.get_by_id( self.context, self.test_instance['instance_type_id']) fake_flavor.extra_specs = {'quota:cpu_shares': 'fishfood', 'quota:cpu_period': '20000'} instance_ref = db.instance_create(self.context, self.test_instance) with mock.patch.object(objects.flavor.Flavor, 'get_by_id', return_value=fake_flavor): self.assertRaises(ValueError, conn._get_guest_config, instance_ref, [], {}, disk_info) def _test_get_guest_config_sysinfo_serial(self, expected_serial): instance_ref = db.instance_create(self.context, self.test_instance) service_ref = db.service_create(self.context, service_info) compute_ref = db.compute_node_create(self.context, compute_info) def test_get_guest_config_with_pci_passthrough_kvm(self): instance = self.create_instance_obj(self.context) extra_info=jsonutils.dumps({})) db.pci_device_update(self.context, pci_device_info['compute_node_id'], pci_device_info['address'], pci_device_info) instance.refresh() def test_get_guest_config_with_pci_passthrough_xen(self): instance = self.create_instance_obj(self.context) extra_info=jsonutils.dumps({})) db.pci_device_update(self.context, pci_device_info['compute_node_id'], pci_device_info['address'], pci_device_info) instance.refresh() def test_get_guest_config_os_command_line_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_os_command_line_without_kernel_id(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_os_command_empty(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_armv7(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_aarch64(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_machine_type_through_image_meta(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_config_machine_type_from_config(self): instance_ref = db.instance_create(self.context, self.test_instance) def _test_get_guest_config_ppc64(self, device_index): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_none(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_default_kvm(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_default_uml(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_default_lxc(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_host_passthrough(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_host_model(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_config_custom(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_cpu_topology(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_by_default(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_disable(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_period_value(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_qemu(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_xen(self): instance_ref = db.instance_create(self.context, self.test_instance) def test_get_guest_memory_balloon_config_lxc(self): instance_ref = db.instance_create(self.context, self.test_instance) self._check_xml_and_disk_prefix(instance_data) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) instance_ref = db.instance_create(self.context, test_instance) def test_multi_nic(self): instance_data = dict(self.test_instance) instance_ref = db.instance_create(self.context, instance_data) def _check_xml_and_container(self, instance): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, instance) (lambda t: t.find('.').get('type'), 'lxc'), (lambda t: t.find('./os/type').text, 'exe'), (lambda t: t.find('./devices/filesystem/target').get('dir'), '/')] def _check_xml_and_disk_prefix(self, instance, prefix=None): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, instance) def _check_xml_and_disk_driver(self, image_meta): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, self.test_instance) block_device_info, wantConfig): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, self.test_instance) def _check_xml_and_uuid(self, image_meta): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, self.test_instance) def _check_xml_and_uri(self, instance, expect_ramdisk, expect_kernel, rescue=None, expect_xen_hvm=False, xen_only=False): user_context = context.RequestContext(self.user_id, self.project_id) instance_ref = db.instance_create(user_context, instance) db.project_get_networks(context.get_admin_context(), self.project_id)[0] expected_result, '%s != %s failed check %d' % (check(tree), expected_result, i)) expected_result, '%s != %s failed common check %d' % (check(tree), expected_result, i)) db.instance_destroy(user_context, instance_ref['uuid']) instance_ref = db.instance_create(self.context, self.test_instance) db.instance_destroy(self.context, instance_ref['uuid']) def test_check_can_live_migrate_dest_all_pass_with_block_migration(self): instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, self.test_instance) instance_dict = {'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE} instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_update(self.context, instance_ref['uuid'], instance_dict) db.instance_destroy(self.context, instance_ref['uuid']) instance_dict = {'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE} instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_update(self.context, instance_ref['uuid'], instance_dict) db.instance_destroy(self.context, instance_ref['uuid']) instance_dict = {'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE} instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_update(self.context, instance_ref['uuid'], instance_dict) db.instance_destroy(self.context, instance_ref['uuid']) instance_dict = {'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE} instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_update(self.context, instance_ref['uuid'], instance_dict) db.instance_destroy(self.context, instance_ref['uuid']) instance_dict = {'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE} instance_ref = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_update(self.context, instance_ref['uuid'], instance_dict) instance_ref = db.instance_get(self.context, instance_ref['id']) self.assertEqual(vm_states.ACTIVE, instance_ref['vm_state']) self.assertEqual(power_state.RUNNING, instance_ref['power_state']) db.instance_destroy(self.context, instance_ref['uuid']) inst_ref = db.instance_create(self.context, self.test_instance) db.instance_destroy(self.context, inst_ref['uuid']) instance = db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, self.test_instance) instance_ref = db.instance_create(self.context, self.test_instance) db.instance_destroy(self.context, instance_ref['uuid']) instance_ref = db.instance_create(self.context, self.test_instance) db.instance_destroy(self.context, instance_ref['uuid']) def test_spawn_with_network_info(self): flavor = db.flavor_get(self.context, instance_ref['instance_type_id']) sys_meta = flavors.save_flavor_info({}, flavor) instance_ref['system_metadata'] = sys_meta instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) db.instance_destroy(self.context, instance['uuid']) instance = db.instance_create(self.context, instance_ref) db.instance_destroy(self.context, instance['uuid']) instance = db.instance_create(self.context, instance_ref) db.instance_destroy(self.context, instance['uuid']) instance = db.instance_create(self.context, instance_ref) self.addCleanup(db.instance_destroy, self.context, instance['uuid']) inst_obj = objects.Instance.get_by_uuid(self.context, instance['uuid']) mock.patch('nova.virt.disk.api.teardown_container'),): instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, instance_ref) instance = db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, self.test_instance) instance = db.instance_create(self.context, inst_ref) mock.patch.object(conn, '_create_domain_and_network')): mock_attachDevice): instance = db.instance_create(self.context, self.test_instance) mock_attachDevice): instance = db.instance_create(self.context, self.test_instance) instance.info_cache.network_info = network_info mock_has_min_version): instance = db.instance_create(self.context, self.test_instance) instance.info_cache.network_info = network_info instance = db.instance_create(self.context, self.test_instance) instance = self.create_instance_obj(self.context) instance = self.create_instance_obj(self.context) instance = self.create_instance_obj(self.context) instance = self.create_instance_obj(self.context) instance = self.create_instance_obj(self.context) def _test_attach_detach_interface_get_config(self, method_name): test_instance = copy.deepcopy(self.test_instance) test_instance['name'] = ""test"" fake_image_meta = {'id': test_instance['image_ref']} fake_flavor = objects.Flavor.get_by_id( self.context, test_instance['instance_type_id']) expected = conn.vif_driver.get_config(test_instance, network_info[0], fake_flavor, conn.vif_driver.get_config(test_instance, network_info[0], conn.attach_interface(test_instance, fake_image_meta, conn.detach_interface(test_instance, network_info[0]) instance_type = db.flavor_get(self.context, instance_ref['instance_type_id']) sys_meta = flavors.save_flavor_info({}, instance_type) instance_ref['system_metadata'] = sys_meta instance = db.instance_create(self.context, instance_ref) with mock.patch.object( driver_block_device.DriverVolumeBlockDevice, 'save'):",1152,704
openstack%2Fcookbook-openstack-network~master~Iccc37e0fd46323f1f19bee32bda0a7a3ee8c3974,openstack/cookbook-openstack-network,master,Iccc37e0fd46323f1f19bee32bda0a7a3ee8c3974,add a Rakefile to structure test runs,MERGED,2014-09-30 12:47:26.000000000,2014-10-07 15:28:08.000000000,2014-10-07 15:28:07.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:47:26.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/71ddd101ba5a9738deab1605b191d464bfdaf918', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: Iccc37e0fd46323f1f19bee32bda0a7a3ee8c3974\nblueprint: rakefile\n""}]",0,125030,71ddd101ba5a9738deab1605b191d464bfdaf918,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: Iccc37e0fd46323f1f19bee32bda0a7a3ee8c3974
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/30/125030/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,71ddd101ba5a9738deab1605b191d464bfdaf918,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fnova~master~I45e9ae6af3d5c83b54ad1287f2fba44dee30338f,openstack/nova,master,I45e9ae6af3d5c83b54ad1287f2fba44dee30338f,libvirt: convert driver test suite to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-07 15:25:22.000000000,2014-10-07 15:25:20.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45c87dfabaa9437dccf7fa3a1f365dffea624e1f', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 2, 'created': '2014-09-17 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8b91cfaa33ab3a82ff509508e5c1984a053c7cd', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8d9978995d2aec8c165b683c81f248813d1c162', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c7414364ca7d9914d28c7c6193872205a88e0c4', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a44ae0bed83ffeb559733baba5794ba30d79ade0', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 6, 'created': '2014-10-01 17:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/015ce8093175b030404238ff15d9dab354f773f7', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}, {'number': 7, 'created': '2014-10-06 16:22:10.000000000', 'files': ['nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ec44fb4d379e8030d3f5c904bbab857968b30f8f', 'message': 'libvirt: convert driver test suite to avoid DB usage\n\nThe LibvirtDriverTestCase uses the database for creating\ninstances and accessing flavors, which can easily be mocked\nin the tests. This allows it to be converted to NoDBTestCase\nwhich improves perf from 4.6s to 0.8s\n\nPartial-bug: #1369516\nChange-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f\n'}]",2,121875,ec44fb4d379e8030d3f5c904bbab857968b30f8f,57,14,7,1779,,,0,"libvirt: convert driver test suite to avoid DB usage

The LibvirtDriverTestCase uses the database for creating
instances and accessing flavors, which can easily be mocked
in the tests. This allows it to be converted to NoDBTestCase
which improves perf from 4.6s to 0.8s

Partial-bug: #1369516
Change-Id: I45e9ae6af3d5c83b54ad1287f2fba44dee30338f
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/121875/7 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,45c87dfabaa9437dccf7fa3a1f365dffea624e1f,libvirt-nodb-tests,"class LibvirtDriverTestCase(test.NoDBTestCase): sys_meta = { 'instance_type_memory_mb': 512, 'instance_type_swap': 0, 'instance_type_vcpu_weight': None, 'instance_type_root_gb': 1, 'instance_type_id': 2, 'instance_type_name': u'm1.tiny', 'instance_type_ephemeral_gb': 0, 'instance_type_rxtx_factor': 1.0, 'instance_type_flavorid': u'1', 'instance_type_vcpus': 1 } inst['id'] = 1 inst['uuid'] = '52d3b512-1152-431f-a8f7-28f0288a622b' inst['os_type'] = 'linux' inst['instance_type_id'] = 2 return objects.Instance(**inst) self.mox.StubOutWithMock(objects.Flavor, 'get_by_id') fake_flavor = instance.get_flavor() objects.Flavor.get_by_id(mox.IgnoreArg(), 2).AndReturn(fake_flavor) instance = self._create_instance({'config_drive': None})","class LibvirtDriverTestCase(test.TestCase): sys_meta = flavors.save_flavor_info( {}, flavors.get_flavor_by_name('m1.tiny')) type_id = flavors.get_flavor_by_name('m1.tiny')['id'] inst['instance_type_id'] = type_id return db.instance_create(self.context, inst) fake_flavor = objects.Flavor.get_by_id( self.context, instance['instance_type_id']) instance = self._create_instance() instance.config_drive = False",25,10
openstack%2Fheat~master~Ib64da11ed5584c1a2eef98378d3201a6949fac7d,openstack/heat,master,Ib64da11ed5584c1a2eef98378d3201a6949fac7d,Don't send multiple update-cancel messages to an event,MERGED,2014-10-03 19:45:36.000000000,2014-10-07 15:25:10.000000000,2014-10-07 15:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-10-03 19:45:36.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/75242b9c67aafa80b4d4a13cfae6c50ba7f85b79', 'message': ""Don't send multiple update-cancel messages to an event\n\nChange-Id: Ib64da11ed5584c1a2eef98378d3201a6949fac7d\nCloses-Bug: #1376900\n""}]",0,126046,75242b9c67aafa80b4d4a13cfae6c50ba7f85b79,16,5,1,4257,,,0,"Don't send multiple update-cancel messages to an event

Change-Id: Ib64da11ed5584c1a2eef98378d3201a6949fac7d
Closes-Bug: #1376900
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/126046/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,75242b9c67aafa80b4d4a13cfae6c50ba7f85b79,," for event in self.events.pop(stack_id, []):"," for event in self.events.get(stack_id, []):",1,1
openstack%2Fcookbook-openstack-block-storage~master~If366dff9394f416b0704bea89ae50c1c472606bf,openstack/cookbook-openstack-block-storage,master,If366dff9394f416b0704bea89ae50c1c472606bf,add a Rakefile to structure test runs,MERGED,2014-09-30 12:45:58.000000000,2014-10-07 15:24:36.000000000,2014-10-07 15:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:45:58.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/17eff9523c9e922ca9118956ec6441d07c6b2988', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: If366dff9394f416b0704bea89ae50c1c472606bf\nblueprint: rakefile\n""}]",0,125028,17eff9523c9e922ca9118956ec6441d07c6b2988,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: If366dff9394f416b0704bea89ae50c1c472606bf
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/28/125028/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,17eff9523c9e922ca9118956ec6441d07c6b2988,bp/rakefile, - berks-cookbooks/**,,46,11
openstack%2Fnova~master~I93b3725e16adc16457580d5150f3d88a86d614dd,openstack/nova,master,I93b3725e16adc16457580d5150f3d88a86d614dd,Avoid using except Exception in unit test,MERGED,2014-10-06 20:27:10.000000000,2014-10-07 15:23:10.000000000,2014-10-07 00:49:45.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 679}, {'_account_id': 1063}, {'_account_id': 1849}, {'_account_id': 6873}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 20:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8aa8d43d06e659f71a06fb3ca580cd0a49094e2', 'message': 'Avoid using except Exception in unit test\n\nFailed assertions raise AssertionError, which is a subclass of Exception.\nCatching Exception and ignoring it then ends up ignoring any failed\nexceptions caught by the exception handler.\n\nUsing a more specific sentinel exception prevents the ignoring of failed\nassertions from happening\n\nChange-Id: I93b3725e16adc16457580d5150f3d88a86d614dd\nCloses-Bug: 1378088\n'}, {'number': 2, 'created': '2014-10-06 22:36:23.000000000', 'files': ['nova/tests/virt/vmwareapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0110cd7c0da1ba42df891f1d61e9dc2f2e7fe42b', 'message': 'Avoid using except Exception in unit test\n\nFailed assertions raise AssertionError, which is a subclass of Exception.\nCatching Exception and ignoring it then ends up ignoring any failed\nexceptions caught by the exception handler.\n\nUsing a more specific sentinel exception prevents the ignoring of failed\nassertions from happening\n\nChange-Id: I93b3725e16adc16457580d5150f3d88a86d614dd\nCloses-Bug: 1378088\n'}]",1,126410,0110cd7c0da1ba42df891f1d61e9dc2f2e7fe42b,19,9,2,100,,,0,"Avoid using except Exception in unit test

Failed assertions raise AssertionError, which is a subclass of Exception.
Catching Exception and ignoring it then ends up ignoring any failed
exceptions caught by the exception handler.

Using a more specific sentinel exception prevents the ignoring of failed
assertions from happening

Change-Id: I93b3725e16adc16457580d5150f3d88a86d614dd
Closes-Bug: 1378088
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/126410/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_vmops.py'],1,b8aa8d43d06e659f71a06fb3ca580cd0a49094e2,bug/1378088," with mock.patch.object(self._vmops, '_volumeops') as mock: mock.attach_root_volume.side_effect = test.TestingException except test.TestingException:"," with mock.patch.object(self._vmops, '_volumeops') as mock_volumeops: mock_volumeops.attach_root_volume.side_effect = Exception except Exception:",3,3
openstack%2Fcinder~master~Ie0caf32469126dd9feb44867adf27acb6e383958,openstack/cinder,master,Ie0caf32469126dd9feb44867adf27acb6e383958,Sync latest processutils from oslo-incubator,MERGED,2014-10-03 20:05:31.000000000,2014-10-07 15:22:52.000000000,2014-10-07 07:59:49.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9624}, {'_account_id': 9664}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-03 20:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0679c5f2293079548d50a7b94d063553c520007f', 'message': 'Sync latest processutils from oslo-incubator\n\nAn earlier commit (Ia92aab76fa83d01c5fbf6f9d31df2463fc26ba5c) failed\nto address ssh_execute(). This change set addresses ssh_execute.\n\n------------------------------------------------\n\noslo-incubator head:\n\ncommit 4990535fb5f3e2dc9b397e1a18c1b5dda94ef1c4\nMerge: 9f5c700 2a130bf\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Mon Sep 29 23:12:14 2014 +0000\n\n    Merge ""Script to list unreleased changes in all oslo projects""\n\n-----------------------------------------------\n\nThe sync pulls in the following changes (newest to oldest):\n\n6a60f842 - Mask passwords in exceptions and error messages (SSH)\n\n-----------------------------------------------\n\nChange-Id: Ie0caf32469126dd9feb44867adf27acb6e383958\nCloses-Bug: #1343604\n'}, {'number': 2, 'created': '2014-10-03 20:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a28e6da025c655f1896769ad707b11cd789f34cb', 'message': 'Sync latest processutils from oslo-incubator\n\nAn earlier commit (Ia92aab76fa83d01c5fbf6f9d31df2463fc26ba5c) failed\nto address ssh_execute(). This change set addresses ssh_execute.\n\n------------------------------------------------\n\noslo-incubator head:\n\ncommit 4990535fb5f3e2dc9b397e1a18c1b5dda94ef1c4\nMerge: 9f5c700 2a130bf\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Mon Sep 29 23:12:14 2014 +0000\n\n    Merge ""Script to list unreleased changes in all oslo projects""\n\n-----------------------------------------------\n\nThe sync pulls in the following changes (newest to oldest):\n\n6a60f842 - Mask passwords in exceptions and error messages (SSH)\n\n-----------------------------------------------\n\nChange-Id: Ie0caf32469126dd9feb44867adf27acb6e383958\nCloses-Bug: #1343604\n'}, {'number': 3, 'created': '2014-10-06 14:56:24.000000000', 'files': ['cinder/openstack/common/processutils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e4e1f7ea71f9b4c7bd15809c58bc7a1838ed567', 'message': 'Sync latest processutils from oslo-incubator\n\nAn earlier commit (Ia92aab76fa83d01c5fbf6f9d31df2463fc26ba5c) failed\nto address ssh_execute(). This change set addresses ssh_execute.\n\n------------------------------------------------\n\noslo-incubator head:\n\ncommit 4990535fb5f3e2dc9b397e1a18c1b5dda94ef1c4\nMerge: 9f5c700 2a130bf\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Mon Sep 29 23:12:14 2014 +0000\n\n    Merge ""Script to list unreleased changes in all oslo projects""\n\n-----------------------------------------------\n\nThe sync pulls in the following changes (newest to oldest):\n\n6a60f842 - Mask passwords in exceptions and error messages (SSH)\n\n-----------------------------------------------\n\nChange-Id: Ie0caf32469126dd9feb44867adf27acb6e383958\nCloses-Bug: #1377981\n'}]",0,126052,5e4e1f7ea71f9b4c7bd15809c58bc7a1838ed567,23,11,3,9311,,,0,"Sync latest processutils from oslo-incubator

An earlier commit (Ia92aab76fa83d01c5fbf6f9d31df2463fc26ba5c) failed
to address ssh_execute(). This change set addresses ssh_execute.

------------------------------------------------

oslo-incubator head:

commit 4990535fb5f3e2dc9b397e1a18c1b5dda94ef1c4
Merge: 9f5c700 2a130bf
Author: Jenkins <jenkins@review.openstack.org>
Date:   Mon Sep 29 23:12:14 2014 +0000

    Merge ""Script to list unreleased changes in all oslo projects""

-----------------------------------------------

The sync pulls in the following changes (newest to oldest):

6a60f842 - Mask passwords in exceptions and error messages (SSH)

-----------------------------------------------

Change-Id: Ie0caf32469126dd9feb44867adf27acb6e383958
Closes-Bug: #1377981
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/126052/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/openstack/common/processutils.py'],1,0679c5f2293079548d50a7b94d063553c520007f,bug/1343604," sanitized_cmd = strutils.mask_password(cmd) LOG.debug('Running cmd (SSH): %s', sanitized_cmd) sanitized_stdout = strutils.mask_password(stdout) sanitized_stderr = strutils.mask_password(stderr) stdout=sanitized_stdout, stderr=sanitized_stderr, cmd=sanitized_cmd) return (sanitized_stdout, sanitized_stderr)"," LOG.debug('Running cmd (SSH): %s', cmd) stdout=stdout, stderr=stderr, cmd=cmd) return (stdout, stderr)",9,5
openstack%2Fcookbook-openstack-dashboard~master~I4d77e65dac01c138a82f1b11fefb8cc33cd04194,openstack/cookbook-openstack-dashboard,master,I4d77e65dac01c138a82f1b11fefb8cc33cd04194,add a Rakefile to structure test runs,MERGED,2014-09-30 12:49:10.000000000,2014-10-07 15:21:30.000000000,2014-10-07 15:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:49:10.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/e5c9b4b93f0a56cf0458f0e4ed6a205641dcbec0', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: I4d77e65dac01c138a82f1b11fefb8cc33cd04194\nblueprint: rakefile\n""}]",0,125031,e5c9b4b93f0a56cf0458f0e4ed6a205641dcbec0,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: I4d77e65dac01c138a82f1b11fefb8cc33cd04194
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/31/125031/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,e5c9b4b93f0a56cf0458f0e4ed6a205641dcbec0,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fheat~master~Ie0fbe3ec3ab57a2cb9dd5e551db15285b2b423c0,openstack/heat,master,Ie0fbe3ec3ab57a2cb9dd5e551db15285b2b423c0,Clean up signalling events after stack updates,MERGED,2014-10-02 17:54:25.000000000,2014-10-07 15:19:22.000000000,2014-10-07 15:19:22.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-10-02 17:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a983b892aab62b25853a8294018bcc72f685a4e2', 'message': 'Clean up signalling events after stack updates\n\nWe provide an Event object to every stack update in order to signal it that\nwe need to cancel the update; this change ensures that we delete it when\nthe thread is complete.\n\nChange-Id: Ie0fbe3ec3ab57a2cb9dd5e551db15285b2b423c0\nCloses-Bug: #1376857\n'}, {'number': 2, 'created': '2014-10-03 19:45:36.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6f13c2d0a4ff2004654a690c1e84a0c9d40ed577', 'message': 'Clean up signalling events after stack updates\n\nWe provide an Event object to every stack update in order to signal it that\nwe need to cancel the update; this change ensures that we delete it when\nthe thread is complete. Previously we were leaking memory on every update.\n\nChange-Id: Ie0fbe3ec3ab57a2cb9dd5e551db15285b2b423c0\nCloses-Bug: #1376857\n'}]",1,125723,6f13c2d0a4ff2004654a690c1e84a0c9d40ed577,16,5,2,4257,,,0,"Clean up signalling events after stack updates

We provide an Event object to every stack update in order to signal it that
we need to cancel the update; this change ensures that we delete it when
the thread is complete. Previously we were leaking memory on every update.

Change-Id: Ie0fbe3ec3ab57a2cb9dd5e551db15285b2b423c0
Closes-Bug: #1376857
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/125723/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,a983b892aab62b25853a8294018bcc72f685a4e2,," th = self.start_with_acquired_lock(stack, lock, func, *args, **kwargs) return th return th def remove_event(self, stack_id, event): for e in self.events.pop(stack_id, []): if e is not event: self.add_event(e) th = self.thread_group_mgr.start_with_lock(cnxt, current_stack, self.engine_id, current_stack.update, updated_stack, event=event) th.link(self.thread_group_mgr.remove_event, current_stack.id, event)"," self.start_with_acquired_lock(stack, lock, func, *args, **kwargs) self.thread_group_mgr.start_with_lock(cnxt, current_stack, self.engine_id, current_stack.update, updated_stack, event=event)",17,6
openstack%2Fcookbook-openstack-data-processing~master~I9b131f96297a02110ade214006eb06721058d49b,openstack/cookbook-openstack-data-processing,master,I9b131f96297a02110ade214006eb06721058d49b,Add rake tasks to ease tests usage,MERGED,2014-10-01 10:03:08.000000000,2014-10-07 15:18:27.000000000,2014-10-07 15:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-10-01 10:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/ff33fe9b4c510d0d5a65386b552ecd9f47a3b1dc', 'message': 'Add rake tasks to ease tests usage\n\nAdded follwing rake tasks:\n* rake lint - ease use of foodcitric\n* rake style - ease use of rubocop\n* rake unit - ease use of rspec\nAll these rake tasks will make sure all the gem dependencies and cookbooks\nare installed.\n\nChange-Id: I9b131f96297a02110ade214006eb06721058d49b\n'}, {'number': 2, 'created': '2014-10-02 11:58:21.000000000', 'files': ['TESTING.md', 'Rakefile', 'Gemfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/bb0d4699d58c42e142e474895fd3701ed2558c3f', 'message': 'Add rake tasks to ease tests usage\n\nAdded follwing rake tasks:\n* rake lint - ease use of foodcitric\n* rake style - ease use of rubocop\n* rake unit - ease use of rspec\nAll these rake tasks will make sure all the gem dependencies and cookbooks\nare installed.\n\nChange-Id: I9b131f96297a02110ade214006eb06721058d49b\n'}]",0,125306,bb0d4699d58c42e142e474895fd3701ed2558c3f,9,3,2,9548,,,0,"Add rake tasks to ease tests usage

Added follwing rake tasks:
* rake lint - ease use of foodcitric
* rake style - ease use of rubocop
* rake unit - ease use of rspec
All these rake tasks will make sure all the gem dependencies and cookbooks
are installed.

Change-Id: I9b131f96297a02110ade214006eb06721058d49b
",git fetch https://review.opendev.org/openstack/cookbook-openstack-data-processing refs/changes/06/125306/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', 'Rakefile', 'Gemfile']",3,ff33fe9b4c510d0d5a65386b552ecd9f47a3b1dc,initial-commit,"gem 'rake', '~> 10.0'",,54,0
openstack%2Fcookbook-openstack-data-processing~master~I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a,openstack/cookbook-openstack-data-processing,master,I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a,Add initial files,MERGED,2014-09-11 14:32:13.000000000,2014-10-07 15:18:14.000000000,2014-10-07 15:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9548}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-09-11 14:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/0ee5389035dc4d1c2b0180586776c84b52f783b8', 'message': 'Add readme\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 2, 'created': '2014-09-17 09:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/67d1563c4e4dd29b9dcf01f91701bcd940ad0bf5', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 3, 'created': '2014-09-29 13:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/b77f1392f3e77bdfd2ae21ae8ab4a32dc78fabb5', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 4, 'created': '2014-09-30 12:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/bb371b55752983443594a6d740c31444b8eafacf', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 5, 'created': '2014-09-30 13:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/afe19b86136d66d89e41f9f98814baf93e618b51', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 6, 'created': '2014-09-30 13:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/a413786dac4aa39c11585c63b93928527e22245c', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 7, 'created': '2014-09-30 14:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/d1fb06c5029336a79e21b4b2495a9c0d2cac432c', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 8, 'created': '2014-09-30 15:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/61264b1a99b2c40b382aa7c23a1398bf2f83f751', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 9, 'created': '2014-09-30 16:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/7bffec8fa230764651c5161dfcda88504887b3a4', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}, {'number': 10, 'created': '2014-10-02 11:58:21.000000000', 'files': ['TESTING.md', '.gitignore', 'spec/spec_helper.rb', 'Gemfile', '.rubocop.yml', 'metadata.rb', 'Berksfile', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-data-processing/commit/1f8a2baa18a30037861de41daa228b19638d940f', 'message': 'Add initial files\n\nChange-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a\n'}]",11,120792,1f8a2baa18a30037861de41daa228b19638d940f,45,6,10,9548,,,0,"Add initial files

Change-Id: I97fce31ea2a4414b6d001d65b0505c2a90bbfc2a
",git fetch https://review.opendev.org/openstack/cookbook-openstack-data-processing refs/changes/92/120792/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,0ee5389035dc4d1c2b0180586776c84b52f783b8,initial-commit,Description =========== This cookbook installs the OpenStack Data Processing service **Sahara** as part of an OpenStack reference deployment Chef for OpenStack. https://wiki.openstack.org/wiki/Sahara ,,6,0
openstack%2Fceilometer~master~I1bcd678069e000ca74085aea5492535f90a6d274,openstack/ceilometer,master,I1bcd678069e000ca74085aea5492535f90a6d274,Imported Translations from Transifex,MERGED,2014-10-04 06:07:24.000000000,2014-10-07 15:17:58.000000000,2014-10-07 15:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6547}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-04 06:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f09b257d428118c4cb6301bedd9195571a624559', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1bcd678069e000ca74085aea5492535f90a6d274\n'}, {'number': 2, 'created': '2014-10-05 06:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b754eb9d72e5bcf408c5fdaa4abfbbc77405fc36', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1bcd678069e000ca74085aea5492535f90a6d274\n'}, {'number': 3, 'created': '2014-10-06 06:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4775cb2e87464502f4888ffc77234aef265d6c33', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1bcd678069e000ca74085aea5492535f90a6d274\n'}, {'number': 4, 'created': '2014-10-07 06:07:26.000000000', 'files': ['ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-critical.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-critical.po', 'ceilometer/locale/en_US/LC_MESSAGES/ceilometer.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aceefd03e19583b99a023327b7b2e89455bbb72b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1bcd678069e000ca74085aea5492535f90a6d274\n'}]",0,126121,aceefd03e19583b99a023327b7b2e89455bbb72b,19,5,4,11131,,,0,"Imported Translations from Transifex

Change-Id: I1bcd678069e000ca74085aea5492535f90a6d274
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/21/126121/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-critical.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-critical.po', 'ceilometer/locale/en_US/LC_MESSAGES/ceilometer.po']",4,f09b257d428118c4cb6301bedd9195571a624559,transifex/translations,,"# English (United States) translations for ceilometer. # Copyright (C) 2013 ORGANIZATION # This file is distributed under the same license as the ceilometer project. # # Translators: msgid """" msgstr """" ""Project-Id-Version: Ceilometer\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-10-02 06:07+0000\n"" ""PO-Revision-Date: 2012-12-11 06:53+0000\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: English (United States) "" ""(http://www.transifex.com/projects/p/openstack/language/en_US/)\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=utf-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" #: ceilometer/agent.py:108 #, python-format msgid ""Polling pollster %(poll)s in the context of %(src)s"" msgstr """" #: ceilometer/agent.py:127 #, python-format msgid ""Continue after error from %(name)s: %(error)s"" msgstr """" #: ceilometer/agent.py:241 #, python-format msgid ""Unable to discover resources: %s"" msgstr """" #: ceilometer/agent.py:243 #, python-format msgid ""Unknown discovery extension: %s"" msgstr """" #: ceilometer/collector.py:103 #, python-format msgid ""UDP: Cannot decode data sent by %s"" msgstr """" #: ceilometer/collector.py:106 #, python-format msgid ""UDP: Storing %s"" msgstr """" #: ceilometer/collector.py:110 msgid ""UDP: Unable to store meter"" msgstr """" #: ceilometer/notification.py:80 ceilometer/notifier.py:48 #, python-format msgid ""Failed to load any notification handlers for %s"" msgstr """" #: ceilometer/notification.py:92 #, python-format msgid ""Event types from %(name)s: %(type)s (ack_on_error=%(error)s)"" msgstr """" #: ceilometer/notifier.py:39 #, python-format msgid ""loading notification handlers from %s"" msgstr """" #: ceilometer/pipeline.py:233 #, python-format msgid ""Unable to load publisher %s"" msgstr """" #: ceilometer/pipeline.py:252 #, python-format msgid """" ""Pipeline %(pipeline)s: Setup transformer instance %(name)s with parameter"" "" %(param)s"" msgstr """" #: ceilometer/pipeline.py:265 #, python-format msgid ""Pipeline %(pipeline)s: Sample dropped by transformer %(trans)s"" msgstr """" #: ceilometer/pipeline.py:272 #, python-format msgid """" ""Pipeline %(pipeline)s: Exit after error from transformer %(trans)s for "" ""%(smp)s"" msgstr """" #: ceilometer/pipeline.py:292 #, python-format msgid ""Pipeline %(pipeline)s: Transform sample %(smp)s from %(trans)s transformer"" msgstr """" #: ceilometer/pipeline.py:306 #, python-format msgid ""Pipeline %(pipeline)s: Continue after error from publisher %(pub)s"" msgstr """" #: ceilometer/pipeline.py:325 #, python-format msgid ""Pipeline %(pipeline)s: Error flushing transformer %(trans)s"" msgstr """" #: ceilometer/pipeline.py:485 msgid ""detected decoupled pipeline config format"" msgstr """" #: ceilometer/pipeline.py:495 msgid ""detected deprecated pipeline config format"" msgstr """" #: ceilometer/pipeline.py:515 #, python-format msgid ""Pipeline config file: %s"" msgstr """" #: ceilometer/pipeline.py:521 #, python-format msgid ""Pipeline config: %s"" msgstr """" #: ceilometer/plugin.py:66 msgid """" ""get_exchange_topics API of NotificationPlugin isdeprecated, implements "" ""get_targets instead."" msgstr """" #: ceilometer/service.py:104 #, python-format msgid ""%(worker_name)s value of %(workers)s is invalid, must be greater than 0"" msgstr """" #: ceilometer/alarm/rpc.py:56 #, python-format msgid """" ""alarm %(alarm_id)s has no action configured for state transition from "" ""%(previous)s to state %(state)s, skipping the notification."" msgstr """" #: ceilometer/alarm/service.py:93 #, python-format msgid ""initiating evaluation cycle on %d alarms"" msgstr """" #: ceilometer/alarm/service.py:98 msgid ""alarm evaluation cycle failed"" msgstr """" #: ceilometer/alarm/service.py:103 #, python-format msgid ""skipping alarm %s: type unsupported"" msgstr """" #: ceilometer/alarm/service.py:107 #, python-format msgid ""evaluating alarm %s"" msgstr """" #: ceilometer/alarm/service.py:260 #, python-format msgid ""Unable to parse action %(action)s for alarm %(alarm_id)s"" msgstr """" #: ceilometer/alarm/service.py:269 #, python-format msgid ""Action %(scheme)s for alarm %(alarm_id)s is unknown, cannot notify"" msgstr """" #: ceilometer/alarm/service.py:275 #, python-format msgid ""Notifying alarm %(id)s with action %(act)s"" msgstr """" #: ceilometer/alarm/service.py:280 #, python-format msgid ""Unable to notify alarm %s"" msgstr """" #: ceilometer/alarm/service.py:299 msgid ""Unable to notify for an alarm with no action"" msgstr """" #: ceilometer/alarm/evaluator/__init__.py:73 #, python-format msgid ""alarm %(id)s transitioning to %(state)s because %(reason)s"" msgstr """" #: ceilometer/alarm/evaluator/__init__.py:85 msgid ""alarm state update failed"" msgstr """" #: ceilometer/alarm/evaluator/combination.py:36 msgid ""alarm retrieval failed"" msgstr """" #: ceilometer/alarm/evaluator/combination.py:52 #, python-format msgid ""Alarms %(alarm_ids)s are in unknown state"" msgstr """" #: ceilometer/alarm/evaluator/combination.py:74 #, python-format msgid ""Transition to %(state)s due to alarms %(alarm_ids)s in state %(state)s"" msgstr """" #: ceilometer/alarm/evaluator/combination.py:78 #, python-format msgid ""Remaining as %(state)s due to alarms %(alarm_ids)s in state %(state)s"" msgstr """" #: ceilometer/alarm/evaluator/combination.py:99 #: ceilometer/alarm/evaluator/threshold.py:177 #, python-format msgid ""Attempted to evaluate alarm %s, but it is not within its time constraint."" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:63 #, python-format msgid ""query stats from %(start)s to %(now)s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:73 #, python-format msgid ""sanitize stats %s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:82 #, python-format msgid ""excluded weak datapoints with sample counts %s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:91 #, python-format msgid ""pruned statistics to %d"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:96 #, python-format msgid ""stats query %s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:102 msgid ""alarm stats retrieval failed"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:113 #, python-format msgid ""%d datapoints are unknown"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:136 #, python-format msgid """" ""Transition to %(state)s due to %(count)d samples %(disposition)s "" ""threshold, most recent: %(most_recent)s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:140 #, python-format msgid """" ""Remaining as %(state)s due to %(count)d samples %(disposition)s "" ""threshold, most recent: %(most_recent)s"" msgstr """" #: ceilometer/alarm/evaluator/threshold.py:196 #, python-format msgid ""comparing value %(value)s against threshold %(limit)s"" msgstr """" #: ceilometer/alarm/notifier/log.py:31 #, python-format msgid """" ""Notifying alarm %(alarm_id)s from %(previous)s to %(current)s with action"" "" %(action)s because %(reason)s"" msgstr """" #: ceilometer/alarm/notifier/rest.py:66 #, python-format msgid """" ""Notifying alarm %(alarm_id)s from %(previous)s to %(current)s with action"" "" %(action)s because %(reason)s. request-id: %(request_id)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:132 #, python-format msgid ""triggering %s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:133 #, python-format msgid ""known evaluators %s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:136 #, python-format msgid ""per evaluator allocation %s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:146 #, python-format msgid """" ""%(this)s bailing on distribution cycle as older partition detected: "" ""%(older)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:152 #, python-format msgid ""%(verb)s-ing %(alloc)s to %(eval)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:156 #, python-format msgid ""master taking %s for self"" msgstr """" #: ceilometer/alarm/partition/coordination.py:174 #, python-format msgid ""newly deleted alarms %s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:177 msgid ""alarm deletion activity requires rebalance"" msgstr """" #: ceilometer/alarm/partition/coordination.py:202 #, python-format msgid ""%s still warming up"" msgstr """" #: ceilometer/alarm/partition/coordination.py:207 #, python-format msgid ""last heard from %(report)s %(delta)s seconds ago"" msgstr """" #: ceilometer/alarm/partition/coordination.py:212 #, python-format msgid ""%(this)s detects stale evaluator: %(stale)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:217 #, python-format msgid ""%(this)s sees older potential master: %(older)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:219 #, python-format msgid ""%(this)s is master?: %(is_master)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:232 #, python-format msgid ""newly created alarms %s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:243 #, python-format msgid ""%(this)s not overtaken as master? %(still_ahead)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:253 #, python-format msgid ""%s checking mastership status"" msgstr """" #: ceilometer/alarm/partition/coordination.py:260 msgid ""mastership check failed"" msgstr """" #: ceilometer/alarm/partition/coordination.py:270 #, python-format msgid ""%(this)s knows about %(reports)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:276 #, python-format msgid ""%(this)s got assignment: %(alarms)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:283 #, python-format msgid ""%(this)s got allocation: %(alarms)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:289 #, python-format msgid ""%s reporting presence"" msgstr """" #: ceilometer/alarm/partition/coordination.py:293 msgid ""presence reporting failed"" msgstr """" #: ceilometer/alarm/partition/coordination.py:298 #, python-format msgid ""%s has no assigned alarms to evaluate"" msgstr """" #: ceilometer/alarm/partition/coordination.py:302 #, python-format msgid ""%(this)s alarms for evaluation: %(alarms)s"" msgstr """" #: ceilometer/alarm/partition/coordination.py:308 msgid ""assignment retrieval failed"" msgstr """" #: ceilometer/alarm/storage/impl_hbase.py:92 #: ceilometer/storage/impl_hbase.py:155 msgid ""Creating a new in-memory HBase Connection object"" msgstr """" #: ceilometer/alarm/storage/impl_hbase.py:107 #: ceilometer/storage/impl_hbase.py:170 msgid ""Dropping HBase schema..."" msgstr """" #: ceilometer/alarm/storage/impl_hbase.py:114 #: ceilometer/storage/impl_hbase.py:178 msgid ""Cannot disable table but ignoring error"" msgstr """" #: ceilometer/alarm/storage/impl_hbase.py:118 #: ceilometer/storage/impl_hbase.py:182 msgid ""Cannot delete table but ignoring error"" msgstr """" #: ceilometer/alarm/storage/impl_hbase.py:129 #: ceilometer/storage/impl_hbase.py:193 #, python-format msgid ""connecting to HBase on %(host)s:%(port)s"" msgstr """" #: ceilometer/api/app.py:165 #, python-format msgid ""Starting server in PID %s"" msgstr """" #: ceilometer/api/app.py:166 msgid ""Configuration:"" msgstr """" #: ceilometer/api/app.py:170 #, python-format msgid ""serving on 0.0.0.0:%(sport)s, view at http://127.0.0.1:%(vport)s"" msgstr """" #: ceilometer/api/app.py:174 #, python-format msgid ""serving on http://%(host)s:%(port)s"" msgstr """" #: ceilometer/api/middleware.py:108 #, python-format msgid ""Error parsing HTTP response: %s"" msgstr """" #: ceilometer/api/controllers/v2.py:97 #, python-format msgid ""%(entity)s %(id)s Not Found"" msgstr """" #: ceilometer/api/controllers/v2.py:105 #, python-format msgid ""Alarm %s not found"" msgstr """" #: ceilometer/api/controllers/v2.py:107 #, python-format msgid ""Alarm %(alarm_id)s not found in project %(project)s"" msgstr """" #: ceilometer/api/controllers/v2.py:120 #, python-format msgid ""Alarm quota exceeded for user %(u)s on project %(p)s"" msgstr """" #: ceilometer/api/controllers/v2.py:313 #, python-format msgid ""Unable to convert the value %(value)s to the expected data type %(type)s."" msgstr """" #: ceilometer/api/controllers/v2.py:318 #, python-format msgid """" ""The data type %(type)s is not supported. The supported data type list is:"" "" %(supported)s"" msgstr """" #: ceilometer/api/controllers/v2.py:323 #, python-format msgid """" ""Unexpected exception converting %(value)s to the expected data type "" ""%(type)s."" msgstr """" #: ceilometer/api/controllers/v2.py:334 #, python-format msgid ""Not Authorized to access %(aspect)s %(id)s"" msgstr """" #: ceilometer/api/controllers/v2.py:809 msgid ""clamping min timestamp to range"" msgstr """" #: ceilometer/api/controllers/v2.py:814 msgid ""clamping max timestamp to range"" msgstr """" #: ceilometer/api/controllers/v2.py:890 ceilometer/api/controllers/v2.py:1156 msgid ""Limit must be positive"" msgstr """" #: ceilometer/api/controllers/v2.py:973 msgid ""Period must be positive."" msgstr """" #: ceilometer/api/controllers/v2.py:985 #, python-format msgid ""computed value coming from %r"" msgstr """" #: ceilometer/api/controllers/v2.py:1172 msgid ""Sample"" msgstr """" #: ceilometer/api/controllers/v2.py:1337 #, python-format msgid ""Filter expression not valid: %s"" msgstr """" #: ceilometer/api/controllers/v2.py:1352 #, python-format msgid ""Order-by expression not valid: %s"" msgstr """" #: ceilometer/api/controllers/v2.py:1363 msgid ""Limit should be positive"" msgstr """" #: ceilometer/api/controllers/v2.py:1456 #, python-format msgid ""String %s is not a valid isotime"" msgstr """" #: ceilometer/api/controllers/v2.py:1457 #, python-format msgid ""Failed to parse the timestamp value %s"" msgstr """" #: ceilometer/api/controllers/v2.py:1543 msgid ""Resource"" msgstr """" #: ceilometer/api/controllers/v2.py:1618 #, python-format msgid """" ""Alarm when %(meter_name)s is %(comparison_operator)s a %(statistic)s of "" ""%(threshold)s over %(period)s seconds"" msgstr """" #: ceilometer/api/controllers/v2.py:1658 #, python-format msgid ""Combined state of alarms %s"" msgstr """" #: ceilometer/api/controllers/v2.py:1667 msgid ""Alarm combination rule should contain at least two different alarm ids."" msgstr """" #: ceilometer/api/controllers/v2.py:1718 #, python-format msgid ""Timezone %s is not valid"" msgstr """" #: ceilometer/api/controllers/v2.py:1844 msgid ""Time constraint names must be unique for a given alarm."" msgstr """" #: ceilometer/api/controllers/v2.py:1854 #, python-format msgid ""%(rule)s must be set for %(type)s type alarm"" msgstr """" #: ceilometer/api/controllers/v2.py:1858 msgid ""threshold_rule and combination_rule cannot be set at the same time"" msgstr """" #: ceilometer/api/controllers/v2.py:1875 #, python-format msgid ""Unable to parse action %s"" msgstr """" #: ceilometer/api/controllers/v2.py:1878 #, python-format msgid ""Unsupported action %s"" msgstr """" #: ceilometer/api/controllers/v2.py:2041 #, python-format msgid ""Alarm with name=%s exists"" msgstr """" #: ceilometer/api/controllers/v2.py:2048 #, python-format msgid ""Cannot specify alarm %s itself in combination rule"" msgstr """" #: ceilometer/api/controllers/v2.py:2056 #, python-format msgid ""Error while putting alarm: %s"" msgstr """" #: ceilometer/api/controllers/v2.py:2057 ceilometer/api/controllers/v2.py:2208 msgid ""Alarm incorrect"" msgstr """" #: ceilometer/api/controllers/v2.py:2108 msgid ""state invalid"" msgstr """" #: ceilometer/api/controllers/v2.py:2201 #, python-format msgid ""Alarm with name='%s' exists"" msgstr """" #: ceilometer/api/controllers/v2.py:2207 #, python-format msgid ""Error while posting alarm: %s"" msgstr """" #: ceilometer/api/controllers/v2.py:2364 msgid ""operator {} is incorrect"" msgstr """" #: ceilometer/api/controllers/v2.py:2386 #, python-format msgid ""Getting traits for %s"" msgstr """" #: ceilometer/api/controllers/v2.py:2451 msgid ""Event"" msgstr """" #: ceilometer/api/controllers/v2.py:2454 #, python-format msgid ""More than one event with id %s returned from storage driver"" msgstr """" #: ceilometer/central/plugin.py:66 #, python-format msgid ""Skip due to keystone error %s"" msgstr """" #: ceilometer/central/plugin.py:73 #, python-format msgid ""Skipping because %s service is not registered in keystone"" msgstr """" #: ceilometer/cmd/storage.py:39 msgid ""Clearing expired metering data"" msgstr """" #: ceilometer/cmd/storage.py:44 msgid ""Nothing to clean, database time to live is disabled"" msgstr """" #: ceilometer/compute/nova_notifier.py:79 #, python-format msgid ""using provided stats gatherer %r"" msgstr """" #: ceilometer/compute/nova_notifier.py:82 msgid ""making a new stats gatherer"" msgstr """" #: ceilometer/compute/nova_notifier.py:111 #, python-format msgid ""INFO %r"" msgstr """" #: ceilometer/compute/nova_notifier.py:144 #, python-format msgid ""ignoring %s"" msgstr """" #: ceilometer/compute/nova_notifier.py:146 #, python-format msgid ""processing %s"" msgstr """" #: ceilometer/compute/nova_notifier.py:150 #, python-format msgid ""polling final stats for %r"" msgstr """" #: ceilometer/compute/notifications/cpu.py:52 #, python-format msgid ""An error occurred while building %(m)s sample: %(e)s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:34 #, python-format msgid ""checking instance %s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:38 #, python-format msgid ""CPUTIME USAGE: %(instance)s %(time)d"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:52 #: ceilometer/compute/pollsters/cpu.py:83 #: ceilometer/compute/pollsters/disk.py:122 #: ceilometer/compute/pollsters/disk.py:327 #: ceilometer/compute/pollsters/memory.py:47 #: ceilometer/compute/pollsters/net.py:107 #, python-format msgid ""Exception while getting samples %s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:55 #, python-format msgid ""Obtaining CPU time is not implemented for %s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:58 #, python-format msgid ""could not get CPU time for %(id)s: %(e)s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:67 #, python-format msgid ""Checking CPU util for instance %s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:71 #, python-format msgid ""CPU UTIL: %(instance)s %(util)d"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:86 #, python-format msgid ""Obtaining CPU Util is not implemented for %s"" msgstr """" #: ceilometer/compute/pollsters/cpu.py:89 #, python-format msgid ""Could not get CPU Util for %(id)s: %(e)s"" msgstr """" #: ceilometer/compute/pollsters/disk.py:125 #: ceilometer/compute/pollsters/disk.py:330 #: ceilometer/compute/pollsters/net.py:110 #, python-format msgid ""%(inspector)s does not provide data for %(pollster)s"" msgstr """" #: ceilometer/compute/pollsters/disk.py:130 #: ceilometer/compute/pollsters/disk.py:336 #: ceilometer/compute/pollsters/net.py:115 #, python-format msgid ""Ignoring instance %(name)s: %(error)s"" msgstr """" #: ceilometer/compute/pollsters/memory.py:31 #, python-format msgid ""Checking memory usage for instance %s"" msgstr """" #: ceilometer/compute/pollsters/memory.py:35 #, python-format msgid ""MEMORY USAGE: %(instance)s %(usage)f"" msgstr """" #: ceilometer/compute/pollsters/memory.py:50 #, python-format msgid ""Obtaining Memory Usage is not implemented for %s"" msgstr """" #: ceilometer/compute/pollsters/memory.py:53 #, python-format msgid ""Could not get Memory Usage for %(id)s: %(e)s"" msgstr """" #: ceilometer/compute/pollsters/net.py:93 #, python-format msgid ""checking net info for instance %s"" msgstr """" #: ceilometer/compute/virt/inspector.py:231 #, python-format msgid ""Unable to load the hypervisor inspector: %s"" msgstr """" #: ceilometer/compute/virt/hyperv/utilsv2.py:182 #, python-format msgid ""VM %s not found on Hyper-V"" msgstr """" #: ceilometer/compute/virt/hyperv/utilsv2.py:184 #, python-format msgid ""Duplicate VM name found: %s"" msgstr """" #: ceilometer/compute/virt/libvirt/inspector.py:129 #, python-format msgid """" ""Failed to inspect vnics of %(instance_name)s, domain is in state of "" ""SHUTOFF"" msgstr """" #: ceilometer/compute/virt/libvirt/inspector.py:164 #, python-format msgid """" ""Failed to inspect disks of %(instance_name)s, domain is in state of "" ""SHUTOFF"" msgstr """" #: ceilometer/compute/virt/vmware/inspector.py:90 #: ceilometer/compute/virt/vmware/inspector.py:107 #: ceilometer/compute/virt/vmware/inspector.py:139 #: ceilometer/compute/virt/vmware/inspector.py:152 #, python-format msgid ""VM %s not found in VMware Vsphere"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:58 msgid ""XenAPI not installed"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:64 msgid ""Must specify connection_url, and connection_password to use"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:67 msgid ""Unable to log in to XenAPI (is the Dom0 disk full?)"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:74 #, python-format msgid ""Could not connect to XenAPI: %s"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:106 #, python-format msgid ""VM %s not found in XenServer"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:109 #, python-format msgid ""Multiple VM %s found in XenServer"" msgstr """" #: ceilometer/compute/virt/xenapi/inspector.py:130 #, python-format msgid ""Could not get VM %s CPU Utilization"" msgstr """" #: ceilometer/dispatcher/__init__.py:43 #, python-format msgid ""loading dispatchers from %s"" msgstr """" #: ceilometer/dispatcher/__init__.py:51 #, python-format msgid ""Failed to load any dispatchers for %s"" msgstr """" #: ceilometer/dispatcher/database.py:49 #, python-format msgid """" ""metering data %(counter_name)s for %(resource_id)s @ %(timestamp)s: "" ""%(counter_volume)s"" msgstr """" #: ceilometer/dispatcher/database.py:68 #, python-format msgid ""Failed to record metering data: %s"" msgstr """" #: ceilometer/dispatcher/database.py:71 #, python-format msgid ""message signature invalid, discarding message: %r"" msgstr """" #: ceilometer/energy/kwapi.py:89 msgid ""Kwapi endpoint not found"" msgstr """" #: ceilometer/event/converter.py:76 #, python-format msgid ""Plugin specified, but no plugin name supplied for trait %s"" msgstr """" #: ceilometer/event/converter.py:85 #, python-format msgid ""No plugin named %(plugin)s available for trait %(trait)s"" msgstr """" #: ceilometer/event/converter.py:95 #, python-format msgid ""Required field in trait definition not specified: '%s'"" msgstr """" #: ceilometer/event/converter.py:110 #, python-format msgid """" ""Parse error in JSONPath specification '%(jsonpath)s' for %(trait)s: "" ""%(err)s"" msgstr """" #: ceilometer/event/converter.py:116 #, python-format msgid ""Invalid trait type '%(type)s' for trait %(trait)s"" msgstr """" #: ceilometer/event/converter.py:168 #, python-format msgid ""Required field %s not specified"" msgstr """" #: ceilometer/event/converter.py:343 #, python-format msgid ""Dropping Notification %(type)s (uuid:%(msgid)s)"" msgstr """" #: ceilometer/event/converter.py:367 #, python-format msgid ""Event Definitions configuration file: %s"" msgstr """" #: ceilometer/event/converter.py:377 #, python-format msgid """" ""Invalid YAML syntax in Event Definitions file %(file)s at line: %(line)s,"" "" column: %(column)s."" msgstr """" #: ceilometer/event/converter.py:383 #, python-format msgid ""YAML error reading Event Definitions file %(file)s"" msgstr """" #: ceilometer/event/converter.py:390 msgid ""No Event Definitions configuration file found! Using default config."" msgstr """" #: ceilometer/event/converter.py:394 #, python-format msgid ""Event Definitions: %s"" msgstr """" #: ceilometer/event/endpoint.py:38 msgid ""Loading event definitions"" msgstr """" #: ceilometer/event/endpoint.py:64 #, python-format msgid ""Saving event \""%s\"""" msgstr """" #: ceilometer/event/endpoint.py:71 msgid ""Event is not implemented with the storage backend"" msgstr """" #: ceilometer/hardware/discovery.py:73 #, python-format msgid ""Couldn't obtain IP address ofinstance %s"" msgstr """" #: ceilometer/hardware/plugin.py:66 msgid ""Passed resource dict must contain keys resource_id and resource_url."" msgstr """" #: ceilometer/hardware/plugin.py:108 #, python-format msgid ""inspector call failed for %(ident)s host %(host)s: %(err)s"" msgstr """" #: ceilometer/hardware/plugin.py:139 #, python-format msgid ""Can NOT load inspector %(name)s: %(err)s"" msgstr """" #: ceilometer/ipmi/platform/intel_node_manager.py:231 msgid ""Node Manager init failed"" msgstr """" #: ceilometer/ipmi/platform/ipmi_sensor.py:103 msgid ""Wrong sensor type"" msgstr """" #: ceilometer/ipmi/platform/ipmitool.py:42 msgid ""parse IPMI sensor data failed,unknown sensor type"" msgstr """" #: ceilometer/ipmi/platform/ipmitool.py:83 msgid ""parse IPMI sensor data failed,No data retrieved from given input"" msgstr """" #: ceilometer/ipmi/platform/ipmitool.py:105 msgid ""ipmitool output length mismatch"" msgstr """" #: ceilometer/ipmi/platform/ipmitool.py:131 msgid ""running ipmitool failure"" msgstr """" #: ceilometer/network/floatingip.py:57 #, python-format msgid ""FLOATING IP USAGE: %s"" msgstr """" #: ceilometer/network/notifications.py:77 #, python-format msgid ""network notification %r"" msgstr """" #: ceilometer/network/services/fwaas.py:49 #, python-format msgid ""Unknown status %(stat)s received on fw %(id)s,skipping sample"" msgstr """" #: ceilometer/network/services/lbaas.py:64 #, python-format msgid ""Unknown status %(stat)s received on pool %(id)s, skipping sample"" msgstr """" #: ceilometer/network/services/lbaas.py:112 #, python-format msgid ""Unknown status %(stat)s received on vip %(id)s, skipping sample"" msgstr """" #: ceilometer/network/services/lbaas.py:153 #, python-format msgid ""Unknown status %(stat)s received on member %(id)s,skipping sample"" msgstr """" #: ceilometer/network/services/lbaas.py:258 #, python-format msgid ""Ignoring pool %(pool_id)s: %(error)s"" msgstr """" #: ceilometer/network/services/vpnaas.py:50 #, python-format msgid ""Unknown status %(stat)s received on vpn %(id)s,skipping sample"" msgstr """" #: ceilometer/network/statistics/opencontrail/client.py:58 #: ceilometer/network/statistics/opencontrail/client.py:88 #, python-format msgid ""Opencontrail API returned %(status)s %(reason)s"" msgstr """" #: ceilometer/network/statistics/opendaylight/client.py:230 #: ceilometer/tests/network/statistics/opendaylight/test_client.py:142 #, python-format msgid ""OpenDaylitght API returned %(status)s %(reason)s"" msgstr """" #: ceilometer/network/statistics/opendaylight/driver.py:168 msgid ""Request failed to connect to OpenDaylight with NorthBound REST API"" msgstr """" #: ceilometer/objectstore/swift.py:77 msgid ""Swift endpoint not found"" msgstr """" #: ceilometer/openstack/common/gettextutils.py:301 msgid ""Message objects do not support addition."" msgstr """" #: ceilometer/openstack/common/gettextutils.py:311 msgid """" ""Message objects do not support str() because they may contain non-ascii "" ""characters. Please use unicode() or translate() instead."" msgstr """" #: ceilometer/openstack/common/lockutils.py:101 #, python-format msgid ""Unable to acquire lock on `%(filename)s` due to %(exception)s"" msgstr """" #: ceilometer/openstack/common/log.py:290 #, python-format msgid ""Deprecated: %s"" msgstr """" #: ceilometer/openstack/common/log.py:398 #, python-format msgid ""Error loading logging config %(log_config)s: %(err_msg)s"" msgstr """" #: ceilometer/openstack/common/log.py:459 #, python-format msgid ""syslog facility must be one of: %s"" msgstr """" #: ceilometer/openstack/common/log.py:710 #, python-format msgid ""Fatal call to deprecated config: %(msg)s"" msgstr """" #: ceilometer/openstack/common/policy.py:96 msgid ""The JSON file that defines policies."" msgstr """" #: ceilometer/openstack/common/policy.py:99 msgid ""Default rule. Enforced when a requested rule is not found."" msgstr """" #: ceilometer/openstack/common/policy.py:114 #, python-format msgid ""Policy doesn't allow %s to be performed."" msgstr """" #: ceilometer/openstack/common/policy.py:208 #, python-format msgid ""Rules must be an instance of dict or Rules, got %s instead"" msgstr """" #: ceilometer/openstack/common/processutils.py:59 msgid ""Unexpected error while running command."" msgstr """" #: ceilometer/openstack/common/processutils.py:62 #, python-format msgid """" ""%(description)s\n"" ""Command: %(cmd)s\n"" ""Exit code: %(exit_code)s\n"" ""Stdout: %(stdout)r\n"" ""Stderr: %(stderr)r"" msgstr """" #: ceilometer/openstack/common/processutils.py:143 #, python-format msgid ""Got unknown keyword args: %r"" msgstr """" #: ceilometer/openstack/common/processutils.py:148 msgid ""Command requested root, but did not specify a root helper."" msgstr """" #: ceilometer/openstack/common/processutils.py:158 #, python-format msgid ""Running cmd (subprocess): %s"" msgstr """" #: ceilometer/openstack/common/processutils.py:206 #, python-format msgid ""%r failed. Retrying."" msgstr """" #: ceilometer/openstack/common/processutils.py:247 msgid ""Environment not supported over SSH"" msgstr """" #: ceilometer/openstack/common/processutils.py:251 msgid ""process_input not supported over SSH"" msgstr """" #: ceilometer/openstack/common/strutils.py:125 #, python-format msgid ""Unrecognized value '%(val)s', acceptable values are: %(acceptable)s"" msgstr """" #: ceilometer/openstack/common/strutils.py:230 #, python-format msgid ""Invalid unit system: \""%s\"""" msgstr """" #: ceilometer/openstack/common/strutils.py:239 #, python-format msgid ""Invalid string format: %s"" msgstr """" #: ceilometer/publisher/file.py:63 msgid ""The path for the file publisher is required"" msgstr """" #: ceilometer/publisher/file.py:77 msgid ""max_bytes and backup_count should be numbers."" msgstr """" #: ceilometer/publisher/messaging.py:84 #, python-format msgid ""Publishing policy set to %s"" msgstr """" #: ceilometer/publisher/messaging.py:86 #, python-format msgid ""Publishing policy is unknown (%s) force to default"" msgstr """" #: ceilometer/publisher/messaging.py:141 #, python-format msgid ""Publisher max local_queue length is exceeded, dropping %d oldest samples"" msgstr """" #: ceilometer/publisher/messaging.py:152 #, python-format msgid ""Failed to publish %d samples, queue them"" msgstr """" #: ceilometer/publisher/messaging.py:156 #, python-format msgid ""Failed to publish %d samples, dropping them"" msgstr """" #: ceilometer/publisher/udp.py:59 #, python-format msgid ""Publishing sample %(msg)s over UDP to %(host)s:%(port)d"" msgstr """" #: ceilometer/publisher/udp.py:66 msgid ""Unable to send sample over UDP"" msgstr """" #: ceilometer/storage/__init__.py:91 #, python-format msgid ""looking for %(name)r driver in %(namespace)r"" msgstr """" #: ceilometer/storage/impl_hbase.py:292 ceilometer/storage/impl_hbase.py:342 #, python-format msgid ""Query Resource table: %s"" msgstr """" #: ceilometer/storage/impl_hbase.py:335 msgid ""Pagination not implemented"" msgstr """" #: ceilometer/storage/impl_hbase.py:383 #, python-format msgid ""Query Meter Table: %s"" msgstr """" #: ceilometer/storage/impl_hbase.py:531 #: ceilometer/storage/impl_sqlalchemy.py:812 #: ceilometer/storage/pymongo_base.py:144 #, python-format msgid ""Failed to record event: %s"" msgstr """" #: ceilometer/storage/impl_log.py:42 #, python-format msgid ""metering data %(counter_name)s for %(resource_id)s: %(counter_volume)s"" msgstr """" #: ceilometer/storage/impl_log.py:54 #, python-format msgid ""Dropping data with TTL %d"" msgstr """" #: ceilometer/storage/impl_sqlalchemy.py:308 #, python-format msgid ""Unknown metadata type. Key (%s) will not be queryable."" msgstr """" #: ceilometer/storage/impl_sqlalchemy.py:376 #, python-format msgid ""%d samples removed from database"" msgstr """" #: ceilometer/storage/impl_sqlalchemy.py:808 #: ceilometer/storage/pymongo_base.py:140 #, python-format msgid ""Failed to record duplicated event: %s"" msgstr """" #: ceilometer/storage/impl_sqlalchemy.py:827 #, python-format msgid ""Getting events that match filter: %s"" msgstr """" #: ceilometer/storage/impl_sqlalchemy.py:938 #, python-format msgid ""Get traits for %s"" msgstr """" #: ceilometer/storage/hbase/inmemory.py:261 msgid ""Opening in-memory HBase connection"" msgstr """" #: ceilometer/storage/hbase/utils.py:439 #, python-format msgid ""Cannot create table %(table_name)s it already exists. Ignoring error"" msgstr """" #: ceilometer/storage/mongo/utils.py:175 #, python-format msgid ""Connecting to %(db)s on %(nodelist)s"" msgstr """" #: ceilometer/storage/mongo/utils.py:190 #: ceilometer/tests/storage/test_pymongo_base.py:206 #, python-format msgid ""Unable to connect to the database after %(retries)d retries. Giving up."" msgstr """" #: ceilometer/storage/mongo/utils.py:194 #: ceilometer/tests/storage/test_pymongo_base.py:201 #, python-format msgid """" ""Unable to connect to the database server: %(errmsg)s. Trying again in "" ""%(retry_interval)d seconds."" msgstr """" #: ceilometer/transformer/arithmetic.py:57 #, python-format msgid ""Arithmetic transformer must use at least one meter in expression '%s'"" msgstr """" #: ceilometer/transformer/arithmetic.py:79 msgid ""Expression evaluated to a NaN value!"" msgstr """" #: ceilometer/transformer/arithmetic.py:95 #, python-format msgid ""Unable to evaluate expression %(expr)s: %(exc)s"" msgstr """" #: ceilometer/transformer/arithmetic.py:109 #, python-format msgid ""Unable to perform calculation, not all of {%s} are present"" msgstr """" #: ceilometer/transformer/conversions.py:48 #, python-format msgid ""scaling conversion transformer with source: %(source)s target: %(target)s:"" msgstr """" #: ceilometer/transformer/conversions.py:94 #: ceilometer/transformer/conversions.py:116 #, python-format msgid ""handling sample %s"" msgstr """" #: ceilometer/transformer/conversions.py:97 #: ceilometer/transformer/conversions.py:137 #, python-format msgid ""converted to: %s"" msgstr """" #: ceilometer/transformer/conversions.py:139 #, python-format msgid ""dropping sample with no predecessor: %s"" msgstr """" ",4,1401
openstack%2Fpython-manilaclient~master~Ia11cfb33dae1b8833c553eb0ead6399601f2137a,openstack/python-manilaclient,master,Ia11cfb33dae1b8833c553eb0ead6399601f2137a,Fix endless loop of getattr for share-server instance,MERGED,2014-10-07 11:39:34.000000000,2014-10-07 15:15:17.000000000,2014-10-07 15:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-10-07 11:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/a5030900da2ae23b47b5f238e5d40ec4e1c906c2', 'message': ""Fix endless loop of getattr for share-server instance\n\nUse parent method '__getattr' to avoid endless loop.\n\nChange-Id: Ia11cfb33dae1b8833c553eb0ead6399601f2137a\nCloses-Bug: #1378308\n""}, {'number': 2, 'created': '2014-10-07 11:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/92be7c3f03befef2921c4d8ae26f03eacfb13052', 'message': ""Fix endless loop of getattr for share-server instance\n\nUse parent method '__getattr__' to avoid endless loop.\n\nChange-Id: Ia11cfb33dae1b8833c553eb0ead6399601f2137a\nCloses-Bug: #1378308\n""}, {'number': 3, 'created': '2014-10-07 12:11:42.000000000', 'files': ['tests/v1/test_share_servers.py', 'manilaclient/v1/share_servers.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/fc2cd23a7d5a2beb94bc1043f7db0936b28bb563', 'message': ""Fix endless loop of getattr for share-server instance\n\nUse parent method '__getattr__' to avoid endless loop.\n\nChange-Id: Ia11cfb33dae1b8833c553eb0ead6399601f2137a\nCloses-Bug: #1378308\n""}]",6,126528,fc2cd23a7d5a2beb94bc1043f7db0936b28bb563,13,6,3,8851,,,0,"Fix endless loop of getattr for share-server instance

Use parent method '__getattr__' to avoid endless loop.

Change-Id: Ia11cfb33dae1b8833c553eb0ead6399601f2137a
Closes-Bug: #1378308
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/28/126528/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/v1/test_share_servers.py', 'manilaclient/v1/share_servers.py']",2,a5030900da2ae23b47b5f238e5d40ec4e1c906c2,(detached," attr = 'share_network_name' if attr == 'share_network' else attr return super(ShareServer, self).__getattr__(attr)"," if attr == 'share_network': return getattr(self, 'share_network_name') return getattr(self, attr)",34,5
openstack%2Fcookbook-openstack-telemetry~master~If76f6fca62c7cff719e9a631c968a252cf30f10a,openstack/cookbook-openstack-telemetry,master,If76f6fca62c7cff719e9a631c968a252cf30f10a,add a Rakefile to structure test runs,MERGED,2014-09-30 12:52:45.000000000,2014-10-07 15:15:05.000000000,2014-10-07 15:15:05.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:52:45.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/c1f7d4edccdba1db97089ed11aed7a2c6aa58c2e', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: If76f6fca62c7cff719e9a631c968a252cf30f10a\nblueprint: rakefile\n""}]",0,125035,c1f7d4edccdba1db97089ed11aed7a2c6aa58c2e,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: If76f6fca62c7cff719e9a631c968a252cf30f10a
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/35/125035/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,c1f7d4edccdba1db97089ed11aed7a2c6aa58c2e,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fcookbook-openstack-ops-messaging~master~Ie245028db93d6d49eb224747f2c0697c9b6bdcf5,openstack/cookbook-openstack-ops-messaging,master,Ie245028db93d6d49eb224747f2c0697c9b6bdcf5,add a Rakefile to structure test runs,MERGED,2014-09-30 12:56:03.000000000,2014-10-07 15:14:59.000000000,2014-10-07 15:14:59.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:56:03.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/fa0ac9d81e4916470f49929fce94581c5c53b206', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: Ie245028db93d6d49eb224747f2c0697c9b6bdcf5\nblueprint: rakefile\n""}]",0,125039,fa0ac9d81e4916470f49929fce94581c5c53b206,9,4,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: Ie245028db93d6d49eb224747f2c0697c9b6bdcf5
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-messaging refs/changes/39/125039/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,fa0ac9d81e4916470f49929fce94581c5c53b206,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fcookbook-openstack-orchestration~master~Ia4d52047f1f20b4a62fd1c3726389f3ad562a968,openstack/cookbook-openstack-orchestration,master,Ia4d52047f1f20b4a62fd1c3726389f3ad562a968,add a Rakefile to structure test runs,MERGED,2014-09-30 12:57:39.000000000,2014-10-07 15:14:44.000000000,2014-10-07 15:14:43.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:57:39.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/1687a25e39d164cd2f07cd5926ee09a010b67762', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: Ia4d52047f1f20b4a62fd1c3726389f3ad562a968\nblueprint: rakefile\n""}]",0,125041,1687a25e39d164cd2f07cd5926ee09a010b67762,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: Ia4d52047f1f20b4a62fd1c3726389f3ad562a968
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-orchestration refs/changes/41/125041/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,1687a25e39d164cd2f07cd5926ee09a010b67762,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Ffuel-library~master~I29d931c1ee0f9a22bcdddc38b59680285ab68f36,openstack/fuel-library,master,I29d931c1ee0f9a22bcdddc38b59680285ab68f36,Fix Sahara puppet manifests for Fuel 6.0 (Juno),MERGED,2014-09-09 12:12:41.000000000,2014-10-07 15:13:19.000000000,2014-10-07 15:13:18.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-09-09 12:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c1d5c2456eb4557cc06caa0d422bba9131e7a4a5', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\n'}, {'number': 2, 'created': '2014-09-10 09:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c99fd26573c96760389aa490b73985394a20672e', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\n'}, {'number': 3, 'created': '2014-09-12 08:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01e566f64c61bae728e0bd46a70b6c70da3e92b7', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\n'}, {'number': 4, 'created': '2014-09-16 15:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/456b534209b1db248cdd79ad6e10b2f7e38f4c01', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\n'}, {'number': 5, 'created': '2014-09-17 07:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c855dea24bc67614a94abd2ef88e8265ce30e301', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\nblueprint fuel-deploy-juno\n'}, {'number': 6, 'created': '2014-10-02 09:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/acc9a78303c27f62e4d76f9a8f733d1d00f6b992', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\nblueprint fuel-deploy-juno\n'}, {'number': 7, 'created': '2014-10-03 10:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1cb7f2942b7d6f54ce86afc6e0a10ec6f1bce691', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n* add icehouse backward compatibility for dashboard\nand keystone settings\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\nblueprint fuel-deploy-juno\n'}, {'number': 8, 'created': '2014-10-03 12:26:59.000000000', 'files': ['deployment/puppet/sahara/manifests/api.pp', 'deployment/puppet/sahara/manifests/init.pp', 'deployment/puppet/sahara/manifests/params.pp', 'deployment/puppet/sahara/manifests/dashboard.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9633daed11c07ae8c4650155d3ba82f180ac7fc3', 'message': 'Fix Sahara puppet manifests for Fuel 6.0 (Juno)\n\n* change name for sahara service;\n* migrate from custom auth_token middleware config options to\nthe common config options;\n* remove sahara-dashboard installing, because now sahara-dashboard\nis integrated into Horizon Openstack Dashboard;\n* add icehouse backward compatibility for dashboard\nand keystone settings\n\nCloses-bug: #1364934\nChange-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36\nblueprint fuel-deploy-juno\n'}]",0,120072,9633daed11c07ae8c4650155d3ba82f180ac7fc3,54,6,8,7745,,,0,"Fix Sahara puppet manifests for Fuel 6.0 (Juno)

* change name for sahara service;
* migrate from custom auth_token middleware config options to
the common config options;
* remove sahara-dashboard installing, because now sahara-dashboard
is integrated into Horizon Openstack Dashboard;
* add icehouse backward compatibility for dashboard
and keystone settings

Closes-bug: #1364934
Change-Id: I29d931c1ee0f9a22bcdddc38b59680285ab68f36
blueprint fuel-deploy-juno
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/72/120072/6 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/sahara/manifests/api.pp', 'deployment/puppet/sahara/manifests/init.pp', 'deployment/puppet/sahara/manifests/dashboard.pp', 'deployment/puppet/sahara/manifests/params.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",6,c1d5c2456eb4557cc06caa0d422bba9131e7a4a5,bug/1364934," sahara_auth_uri => ""http://${controller_node_address}:5000/v2.0/"", sahara_identity_uri => ""http://${controller_node_address}:35357/"","," use_floating_ips => $::fuel_settings['auto_assign_floating_ip'],",18,134
openstack%2Fsahara~proposed%2Fjuno~I540abe050f1d81e36f4b5dcca547a7e5c3514c84,openstack/sahara,proposed/juno,I540abe050f1d81e36f4b5dcca547a7e5c3514c84,Description of job config hints in new doc page is wrong,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 15:13:03.000000000,2014-10-07 10:14:49.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/devref/edp.spi.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4f23cfefa18332274d88475984491facd79b85f3', 'message': ""Description of job config hints in new doc page is wrong\n\nThe 'configs' field is not a dictionary, it is actually\na list of dictionaries.  Update the description.\n\nCloses-Bug: #1357615\nChange-Id: I540abe050f1d81e36f4b5dcca547a7e5c3514c84\n(cherry picked from commit 61be4ece04d6370086d8b5b9bea4224010ec0d15)\n""}]",0,126392,4f23cfefa18332274d88475984491facd79b85f3,18,8,1,8411,,,0,"Description of job config hints in new doc page is wrong

The 'configs' field is not a dictionary, it is actually
a list of dictionaries.  Update the description.

Closes-Bug: #1357615
Change-Id: I540abe050f1d81e36f4b5dcca547a7e5c3514c84
(cherry picked from commit 61be4ece04d6370086d8b5b9bea4224010ec0d15)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/92/126392/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/edp.spi.rst'],1,4f23cfefa18332274d88475984491facd79b85f3,bug/1376457,"{'job_config': {'configs': [], 'params': {}, 'args': []}} * *args* is a list of strings * *params* contains simple key/value pairs * each item in *configs* is a dictionary with entries for 'name' (required), 'value', and 'description'","{'job_config': {'configs': {}, 'params': {}, 'args': []}}",6,1
openstack%2Ffuel-library~master~I73ffbc0dc3f89c87dc79e2112ba20e2b3b7cf4f8,openstack/fuel-library,master,I73ffbc0dc3f89c87dc79e2112ba20e2b3b7cf4f8,Execute horizon compress on both OS,MERGED,2014-10-02 09:25:45.000000000,2014-10-07 15:12:30.000000000,2014-10-07 15:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-02 09:25:45.000000000', 'files': ['deployment/puppet/horizon/manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/774f9efa016eaa7f80e7a91aa6d994ee0691606c', 'message': 'Execute horizon compress on both OS\n\nCloses-bug: #1375287\n\nblueprint fuel-deploy-juno\n\nChange-Id: I73ffbc0dc3f89c87dc79e2112ba20e2b3b7cf4f8\n'}]",0,125579,774f9efa016eaa7f80e7a91aa6d994ee0691606c,12,7,1,7732,,,0,"Execute horizon compress on both OS

Closes-bug: #1375287

blueprint fuel-deploy-juno

Change-Id: I73ffbc0dc3f89c87dc79e2112ba20e2b3b7cf4f8
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/125579/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/horizon/manifests/init.pp'],1,774f9efa016eaa7f80e7a91aa6d994ee0691606c,bug/1375287," Package['dashboard'] -> Exec['horizon_compress_styles'] Package['dashboard'] ~> Exec['horizon_compress_styles'] File[$::horizon::params::local_settings_path] -> Exec['horizon_compress_styles'] exec { 'horizon_compress_styles': path => '/bin:/usr/bin:/sbin:/usr/sbin', cwd => '/usr/share/openstack-dashboard', command => 'python manage.py compress', refreshonly => true } Exec['horizon_compress_styles'] ~> Service['httpd'] "," #todo: may be need fix Package['dashboard'] -> Exec['horizon_compress_styles'] Package['dashboard'] ~> Exec['horizon_compress_styles'] File[$::horizon::params::local_settings_path] -> Exec['horizon_compress_styles'] exec { 'horizon_compress_styles': path => '/bin:/usr/bin:/sbin:/usr/sbin', cwd => '/usr/share/openstack-dashboard', command => 'python manage.py compress', refreshonly => true } Exec['horizon_compress_styles'] ~> Service['httpd']",11,11
openstack%2Ffuel-main~master~Ia5a564388bf02981c9487d8d3c0489f0e48e42af,openstack/fuel-main,master,Ia5a564388bf02981c9487d8d3c0489f0e48e42af,Remove hardcode version for python-setuptools,MERGED,2014-10-03 08:55:02.000000000,2014-10-07 15:11:51.000000000,2014-10-07 15:11:51.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-03 08:55:02.000000000', 'files': ['requirements-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5b60598d966b0b989363f038e7514d280dd57802', 'message': 'Remove hardcode version for python-setuptools\n\nCloses-bug: #1374455\nblueprint fuel-deploy-juno\n\nChange-Id: Ia5a564388bf02981c9487d8d3c0489f0e48e42af\n'}]",0,125908,5b60598d966b0b989363f038e7514d280dd57802,12,6,1,7745,,,0,"Remove hardcode version for python-setuptools

Closes-bug: #1374455
blueprint fuel-deploy-juno

Change-Id: Ia5a564388bf02981c9487d8d3c0489f0e48e42af
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/08/125908/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-rpm.txt'],1,5b60598d966b0b989363f038e7514d280dd57802,bug/1374455,python-setuptools,python-setuptools-0.6.10-3.el6,1,1
openstack%2Fceilometer~proposed%2Fjuno~I4a0be4a03e6c3590a7cab8f4548a128fdc31d1ca,openstack/ceilometer,proposed/juno,I4a0be4a03e6c3590a7cab8f4548a128fdc31d1ca,Updated from global requirements,MERGED,2014-10-06 16:08:41.000000000,2014-10-07 15:10:44.000000000,2014-10-07 15:10:43.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-06 16:08:41.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0e499f88d1f197aba59107237302009afcc2b500', 'message': 'Updated from global requirements\n\nChange-Id: I4a0be4a03e6c3590a7cab8f4548a128fdc31d1ca\n'}]",0,126336,0e499f88d1f197aba59107237302009afcc2b500,12,6,1,11131,,,0,"Updated from global requirements

Change-Id: I4a0be4a03e6c3590a7cab8f4548a128fdc31d1ca
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/36/126336/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,0e499f88d1f197aba59107237302009afcc2b500,openstack/requirements,pytz,pytz>=2010h,2,2
openstack%2Fcookbook-openstack-database~master~I3acc8abe5209237a17d66bd3376102c9710f6127,openstack/cookbook-openstack-database,master,I3acc8abe5209237a17d66bd3376102c9710f6127,add a Rakefile to structure test runs,MERGED,2014-09-30 12:51:22.000000000,2014-10-07 15:10:03.000000000,2014-10-07 15:10:03.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:51:22.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-database/commit/42d99ea471d8d548063156fa25dda2f18d470ef7', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: I3acc8abe5209237a17d66bd3376102c9710f6127\nblueprint: rakefile\n""}]",0,125033,42d99ea471d8d548063156fa25dda2f18d470ef7,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: I3acc8abe5209237a17d66bd3376102c9710f6127
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-database refs/changes/33/125033/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,42d99ea471d8d548063156fa25dda2f18d470ef7,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fnova~master~Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6,openstack/nova,master,Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6,WIP - ComputeNode removal of Service relationship and FK,ABANDONED,2014-09-08 16:40:26.000000000,2014-10-07 15:08:40.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10937}]","[{'number': 1, 'created': '2014-09-08 16:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8baee63dada499e43d2c754ad7dd22f98fb781d', 'message': 'DO NOT MERGE - Remove service_id FK on ComputeHost\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nHere, we still have an issue with eagerloading in DB API, figuring out\nhow to fix it (joinedload(service))\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 2, 'created': '2014-09-12 13:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56326f25220ee24a5f7f9d44b57a4e75cfe43306', 'message': 'DO NOT MERGE - Remove service_id FK on ComputeHost\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nHere, we still have an issue with eagerloading in DB API, figuring out\nhow to fix it (joinedload(service))\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 3, 'created': '2014-09-16 14:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2686d84fa2feb3791c72f0fe61ef0939f27a458c', 'message': 'DO NOT MERGE - Remove service_id FK on ComputeHost\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nHere, we still have an issue with eagerloading in DB API, figuring out\nhow to fix it (joinedload(service))\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 4, 'created': '2014-09-18 08:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16b8c7bc14e365e45b96909ef6cdbdde54b797af', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nTODO:\n - Unittests to fix\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 5, 'created': '2014-09-18 12:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9683687228c9a5e552388f1c25d6a3e09fe9b63', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nTODO:\n - Unittests to fix\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 6, 'created': '2014-09-18 13:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ae01dc5d3075620ea4aa24f02c0ae72b3c0e9ae', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nTODO:\n - Unittests to fix\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 7, 'created': '2014-09-24 14:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39dc9794e723670cb5b66cc354c1fa1d353e4985', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nTODO:\n - Unittests to fix\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 8, 'created': '2014-09-24 14:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ebb485009c3d632a4e06b67655d38ede5ed9aee', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 9, 'created': '2014-10-06 14:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/092684ca644d59fc0d5d9a7f608daf67e3ff441c', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 10, 'created': '2014-10-06 16:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbc5c8572c06763796453a203735e906a5c9edbe', 'message': 'ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}, {'number': 11, 'created': '2014-10-06 16:19:58.000000000', 'files': ['nova/tests/scheduler/fakes.py', 'nova/tests/objects/test_compute_node.py', 'nova/objects/service.py', 'nova/tests/objects/test_objects.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/db/test_migrations.py', 'nova/tests/objects/test_service.py', 'nova/tests/scheduler/test_weights.py', 'nova/tests/compute/test_compute.py', 'nova/db/sqlalchemy/api.py', 'nova/tests/compute/test_multiple_nodes.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisor_status.py', 'nova/cells/state.py', 'nova/tests/scheduler/ironic_fakes.py', 'nova/objects/compute_node.py', 'nova/tests/api/openstack/compute/contrib/test_hosts.py', 'nova/tests/api/openstack/compute/contrib/test_hypervisors.py', 'nova/tests/scheduler/test_ironic_host_manager.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/compute/manager.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/compute/api.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/conductor/api.py', 'nova/tests/cells/test_cells_manager.py', 'nova/tests/api/openstack/compute/plugins/v3/test_pci.py', 'nova/cells/messaging.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/db/sqlalchemy/migrate_repo/versions/267_remove_service_id_from_compute_node.py', 'nova/conductor/rpcapi.py', 'nova/db/sqlalchemy/models.py', 'nova/tests/integrated/v3/test_pci.py', 'nova/tests/cells/test_cells_state_manager.py', 'nova/api/openstack/compute/contrib/hosts.py', 'nova/tests/api/openstack/compute/contrib/test_extended_hypervisors.py', 'nova/conductor/manager.py', 'nova/compute/resource_tracker.py', 'nova/scheduler/host_manager.py', 'nova/db/sqlalchemy/migrate_repo/versions/266_add_host_in_compute_node.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d0df2eaf9be46d82580df37a50f24dd58b43d4ad', 'message': 'WIP - ComputeNode removal of Service relationship and FK\n\nComputeNode object was having a dependency on Services table thanks to\nservice_id foreign key. Current proposal is to remove that field and\ncreate an host field which would be referring to the service hostname.\n\nCloses-Bug: #1357491\n\nChange-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6\n'}]",34,119807,d0df2eaf9be46d82580df37a50f24dd58b43d4ad,71,13,11,7166,,,0,"WIP - ComputeNode removal of Service relationship and FK

ComputeNode object was having a dependency on Services table thanks to
service_id foreign key. Current proposal is to remove that field and
create an host field which would be referring to the service hostname.

Closes-Bug: #1357491

Change-Id: Ic73f21cf5b0a71c3d4ff9e6689273dc350a1c2a6
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/119807/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/models.py', 'nova/objects/compute_node.py', 'nova/tests/objects/test_compute_node.py', 'nova/objects/service.py', 'nova/db/sqlalchemy/migrate_repo/versions/254_remove_service_id_from_compute_node.py', 'nova/db/sqlalchemy/migrate_repo/versions/253_add_host_in_compute_node.py', 'nova/db/api.py', 'nova/compute/resource_tracker.py', 'nova/db/sqlalchemy/api.py']",9,e8baee63dada499e43d2c754ad7dd22f98fb781d,bug/1357491,"def compute_node_get_by_host(context, host): # FIXME(sbauza): Baremetal driver can have multiple hypervisors per host result = model_query(context, models.ComputeNode, read_deleted='no').\ filter_by(host=host).\ first() if not result: raise exception.ComputeHostNotFound(host=host) return result @require_admin_context",,206,30
openstack%2Frally~master~I57c09d892da4adf863c358a4d63e3543b50d10b7,openstack/rally,master,I57c09d892da4adf863c358a4d63e3543b50d10b7,Reorganize test module structure,MERGED,2014-10-06 18:19:28.000000000,2014-10-07 15:08:25.000000000,2014-10-07 15:08:24.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-10-06 18:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/caf9ea0b68cdc7829a6bdc177c5017fec436d3fc', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  test/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 2, 'created': '2014-10-06 18:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1665f8b7cd3737531ddc6094f509f510e35f5f0e', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  test/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 3, 'created': '2014-10-06 20:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/587af450655e458f956e5e0a3a9d0cffc9fc7a6b', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nAdd testing read me file\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 4, 'created': '2014-10-06 20:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95ea9fedb8d12ef01b9c429d57984ca9b83176ed', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 5, 'created': '2014-10-07 09:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/af7050082e2100584ab632eed230405832d46541', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 6, 'created': '2014-10-07 12:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9cde3ae9db94f6e5251a818013730ed29af478c7', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 7, 'created': '2014-10-07 13:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8b24edf54bb4cb49ec269e3be0c4cbd9aeb2c46e', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 8, 'created': '2014-10-07 13:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6b065bda2f9270083a444a507987888f790a6191', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n rally.hacking      ->  tests/hacking\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\nCo-Authored-By: Andrey Kurilin <akurilin@mirantis.com>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}, {'number': 9, 'created': '2014-10-07 13:50:40.000000000', 'files': ['tests/unit/benchmark/runners/__init__.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'tests/unit/benchmark/wrappers/__init__.py', 'tests/unit/benchmark/scenarios/tempest/test_utils.py', 'tests/ci/test_install.sh', 'tests/unit/benchmark/scenarios/glance/test_utils.py', 'tests/unit/fixtures/__init__.py', 'tests/unit/benchmark/scenarios/requests/__init__.py', 'tests/unit/benchmark/scenarios/designate/__init__.py', 'tests/unit/benchmark/scenarios/keystone/__init__.py', 'tests/unit/benchmark/processing/test_utils.py', 'tests/unit/db/test_api.py', 'tests/unit/benchmark/scenarios/tempest/__init__.py', 'tests/unit/benchmark/context/test_base.py', 'tests/unit/benchmark/runners/test_rps.py', 'tests/unit/cmd/test_manage.py', 'tests/unit/benchmark/__init__.py', 'tests/unit/aas/rest/test_types.py', 'tests/unit/benchmark/scenarios/sahara/test_jobs.py', 'tests/unit/test_fuelclient.py', 'tests/unit/test_hacking.py', 'tests/unit/benchmark/scenarios/quotas/test_utils.py', 'tests/unit/fixtures/import/package/b.py', 'tests/unit/benchmark/scenarios/sahara/test_node_group_templates.py', 'tests/ci/rally-gate/index.html', 'tests/unit/deploy/serverprovider/providers/test_virsh.py', 'tests/unit/benchmark/scenarios/nova/test_servers.py', 'tests/unit/aas/__init__.py', 'tests/unit/benchmark/context/quotas/test_cinder_quotas.py', 'tests/functional/test_cli_task.py', 'tests/unit/benchmark/context/test_volumes.py', 'tests/unit/benchmark/scenarios/ceilometer/__init__.py', 'tests/unit/__init__.py', 'tests/unit/benchmark/context/test_secgroups.py', 'tests/unit/benchmark/scenarios/authenticate/test_authenticate.py', 'tests/unit/benchmark/scenarios/requests/test_http_requests.py', 'tests/hacking/checks.py', 'tests/unit/benchmark/scenarios/ceilometer/test_alarms.py', 'tests/unit/deploy/serverprovider/__init__.py', 'tests/unit/aas/rest/base.py', 'tests/unit/benchmark/scenarios/__init__.py', 'tests/unit/benchmark/context/sahara/test_sahara_edp.py', 'tests/unit/deploy/test_multihost.py', 'tests/hacking/__init__.py', 'tests/unit/benchmark/scenarios/cinder/test_volumes.py', 'tests/unit/benchmark/context/test_tempest.py', 'tests/unit/benchmark/scenarios/cinder/test_utils.py', 'tests/unit/benchmark/scenarios/vm/test_utils.py', 'tests/unit/benchmark/test_validation.py', 'tests/ci/rally-gate.sh', 'tests/unit/benchmark/scenarios/test_utils.py', 'tests/unit/verification/verifiers/fakes.py', 'tests/unit/benchmark/context/cleanup/__init__.py', 'tests/unit/objects/test_endpoint.py', 'tests/unit/deploy/engines/test_existing.py', 'tests/unit/benchmark/scenarios/ceilometer/test_stats.py', 'tests/unit/benchmark/scenarios/neutron/test_network.py', 'tests/unit/cmd/__init__.py', 'tests/unit/cmd/commands/__init__.py', 'tests/unit/db/__init__.py', 'tests/unit/doc/test_task_samples.py', 'tests/unit/benchmark/context/quotas/test_nova_quotas.py', 'tests/unit/benchmark/processing/test_plot.py', 'tests/unit/benchmark/scenarios/heat/__init__.py', 'tests/unit/deploy/serverprovider/providers/test_lxc.py', 'tests/unit/objects/__init__.py', 'tests/ci/README.rst', 'tests/unit/aas/rest/__init__.py', 'tests/unit/test_utils.py', 'tests/unit/benchmark/sla/test_base.py', 'tests/unit/fakes.py', 'tests/unit/benchmark/context/quotas/test_designate_quotas.py', 'tests/unit/verification/verifiers/test_config.py', 'tests/unit/benchmark/scenarios/dummy/__init__.py', 'tests/unit/benchmark/scenarios/test_base.py', 'tests/unit/deploy/test_engine.py', 'tests/unit/test.py', 'tests/functional/test_cli_info.py', 'tests/unit/fixtures/import/broken.py', 'doc/source/index.rst', 'tests/unit/benchmark/context/sahara/test_sahara_cluster.py', 'tests/unit/benchmark/scenarios/tempest/test_tempest.py', 'tests/unit/verification/verifiers/__init__.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/benchmark/context/test_roles.py', 'tests/unit/benchmark/scenarios/heat/test_stacks.py', 'tests/unit/benchmark/scenarios/authenticate/__init__.py', 'tests/unit/benchmark/scenarios/ceilometer/test_utils.py', 'doc/source/user_stories.rst', 'tests/unit/cmd/commands/test_show.py', 'tests/unit/benchmark/scenarios/keystone/test_utils.py', 'tests/unit/deploy/serverprovider/providers/__init__.py', 'tests/unit/cmd/test_envutils.py', 'tests/unit/deploy/serverprovider/providers/test_existing.py', 'tests/unit/benchmark/context/test_users.py', 'tests/unit/benchmark/scenarios/designate/test_basic.py', 'tests/unit/deploy/engines/__init__.py', 'tests/functional/test_cli_deployment.py', 'tests/ci/rally-integrated.sh', 'tests/unit/benchmark/scenarios/neutron/__init__.py', 'tests/unit/benchmark/context/cleanup/test_user_cleanup.py', 'tests/unit/benchmark/context/test_images.py', 'tests/unit/orchestrator/test_api.py', 'tests/unit/orchestrator/__init__.py', 'tests/unit/benchmark/wrappers/test_keystone.py', 'tests/unit/benchmark/sla/__init__.py', 'tests/unit/verification/verifiers/fake_log.xml', 'tests/unit/deploy/test_lxc.py', 'tests/unit/benchmark/test_utils.py', 'tests/unit/objects/test_verification.py', 'tests/unit/verification/verifiers/test_json2html.py', 'tests/unit/benchmark/processing/__init__.py', 'tests/unit/aas/rest/controllers/test_root.py', 'tests/unit/benchmark/scenarios/glance/test_images.py', 'tests/unit/benchmark/scenarios/neutron/test_utils.py', 'tests/unit/benchmark/context/quotas/__init__.py', 'tests/unit/doc/__init__.py', 'tests/unit/cmd/commands/test_info.py', 'tests/unit/benchmark/scenarios/ceilometer/test_queries.py', 'tests/unit/deploy/serverprovider/providers/test_openstack.py', 'tests/unit/benchmark/scenarios/ceilometer/test_resources.py', 'tox.ini', 'tests/unit/deploy/engines/test_devstack.py', 'tests/unit/fixtures/import/package/__init__.py', 'tests/unit/verification/verifiers/test_tempest.py', 'tests/functional/test_cli_show.py', 'tests/unit/benchmark/scenarios/vm/test_vmtasks.py', 'tests/unit/benchmark/runners/test_constant.py', 'tests/unit/rally_scenarios/__init__.py', 'tests/unit/cmd/commands/test_use.py', 'tests/unit/fixtures/import/package/a.py', 'tests/README.rst', 'tests/unit/benchmark/scenarios/sahara/test_utils.py', 'tests/unit/aas/rest/controllers/__init__.py', 'tests/unit/benchmark/context/cleanup/test_utils.py', 'tests/unit/benchmark/scenarios/ceilometer/test_meters.py', 'tests/unit/fixtures/import/__init__.py', 'tests/unit/benchmark/scenarios/sahara/__init__.py', 'tests/functional/test_cli_utils.py', 'tests/unit/benchmark/scenarios/heat/test_utils.py', 'tests/unit/cmd/commands/test_task.py', 'tests/unit/benchmark/context/quotas/test_quotas.py', 'tests/ci/__init__.py', 'tests/unit/benchmark/scenarios/dummy/test_dummy.py', 'tests/unit/benchmark/scenarios/nova/test_utils.py', 'tests/unit/test_fileutils.py', 'tests/hacking/README.rst', 'tests/unit/deploy/engines/test_fuel.py', 'tests/unit/benchmark/scenarios/quotas/test_quotas.py', 'tests/unit/benchmark/runners/test_serial.py', 'tests/unit/benchmark/context/cleanup/test_admin_cleanup.py', 'tests/unit/deploy/__init__.py', 'tests/unit/verification/__init__.py', 'tests/unit/benchmark/context/sahara/test_sahara_image.py', 'tests/unit/benchmark/scenarios/designate/test_utils.py', 'tests/unit/benchmark/scenarios/quotas/__init__.py', 'tests/unit/benchmark/context/quotas/test_neutron_quotas.py', 'tests/unit/benchmark/scenarios/test_authenticate.py', 'tests/unit/benchmark/test_types.py', 'tests/unit/benchmark/scenarios/nova/__init__.py', 'tests/unit/cmd/commands/test_verify.py', 'doc/source/testing.rst', 'tests/unit/benchmark/runners/test_base.py', 'tests/unit/benchmark/context/sahara/__init__.py', 'tests/unit/objects/test_deploy.py', 'tests/unit/objects/test_task.py', 'tests/unit/benchmark/scenarios/glance/__init__.py', 'tests/unit/cmd/test_cliutils.py', 'tests/unit/test_osclients.py', 'tests_ci', '.testr.conf', 'tests/unit/benchmark/scenarios/cinder/__init__.py', 'tests/unit/benchmark/scenarios/vm/__init__.py', 'tests/unit/cmd/commands/test_deployment.py', 'tests/unit/test_sshutils.py', 'tests/unit/benchmark/scenarios/keystone/test_basic.py', 'tests/unit/benchmark/context/test_keypair.py', 'tests/unit/benchmark/context/__init__.py', 'tests/unit/benchmark/scenarios/sahara/test_clusters.py', 'tests/unit/rally_scenarios/test_scenarios.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/f752ac9add30e83f0f092b8067158eea3603137f', 'message': 'Reorganize test module structure\n\nMoved test modules:\n tests/             ->  tests/unit\n test_ci/           ->  tests/ci\n tests_functional   ->  tests/functional\n rally/hacking      ->  tests/hacking\n\nAdd testing read me file\n\nCo-Authored-By: Boris Pavlovic <boris@pavlovic.me>\nCo-Authored-By: Andrey Kurilin <akurilin@mirantis.com>\n\nChange-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7\n'}]",28,126379,f752ac9add30e83f0f092b8067158eea3603137f,29,5,9,7369,,,0,"Reorganize test module structure

Moved test modules:
 tests/             ->  tests/unit
 test_ci/           ->  tests/ci
 tests_functional   ->  tests/functional
 rally/hacking      ->  tests/hacking

Add testing read me file

Co-Authored-By: Boris Pavlovic <boris@pavlovic.me>
Co-Authored-By: Andrey Kurilin <akurilin@mirantis.com>

Change-Id: I57c09d892da4adf863c358a4d63e3543b50d10b7
",git fetch https://review.opendev.org/openstack/rally refs/changes/79/126379/9 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/benchmark/runners/__init__.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'tests/unit/benchmark/wrappers/__init__.py', 'tests/unit/benchmark/scenarios/tempest/test_utils.py', 'tests/ci/test_install.sh', 'tests/unit/benchmark/scenarios/glance/test_utils.py', 'tests/unit/fixtures/__init__.py', 'tests/unit/benchmark/scenarios/requests/__init__.py', 'tests/unit/benchmark/scenarios/designate/__init__.py', 'tests/unit/benchmark/scenarios/keystone/__init__.py', 'tests/unit/benchmark/processing/test_utils.py', 'tests/unit/db/test_api.py', 'tests/unit/benchmark/scenarios/tempest/__init__.py', 'tests/unit/benchmark/context/test_base.py', 'tests/unit/benchmark/runners/test_rps.py', 'tests/unit/cmd/test_manage.py', 'tests/unit/benchmark/__init__.py', 'tests/unit/aas/rest/test_types.py', 'tests/unit/benchmark/scenarios/sahara/test_jobs.py', 'tests/unit/test_fuelclient.py', 'tests/unit/test_hacking.py', 'tests/unit/benchmark/scenarios/quotas/test_utils.py', 'tests/unit/fixtures/import/package/b.py', 'tests/unit/benchmark/scenarios/sahara/test_node_group_templates.py', 'tests/ci/rally-gate/index.html', 'tests/unit/deploy/serverprovider/providers/test_virsh.py', 'tests/unit/benchmark/scenarios/nova/test_servers.py', 'tests/unit/aas/__init__.py', 'tests/unit/benchmark/context/quotas/test_cinder_quotas.py', 'tests/functional/test_cli_task.py', 'tests/unit/benchmark/context/test_volumes.py', 'tests/unit/benchmark/scenarios/ceilometer/__init__.py', 'tests/unit/__init__.py', 'tests/unit/benchmark/context/test_secgroups.py', 'tests/unit/benchmark/scenarios/authenticate/test_authenticate.py', 'tests/unit/benchmark/scenarios/requests/test_http_requests.py', 'tests/unit/benchmark/scenarios/ceilometer/test_alarms.py', 'tests/unit/deploy/serverprovider/__init__.py', 'tests/unit/aas/rest/base.py', 'tests/unit/benchmark/scenarios/__init__.py', 'tests/unit/benchmark/context/sahara/test_sahara_edp.py', 'tests/unit/deploy/test_multihost.py', 'tests/unit/benchmark/scenarios/cinder/test_volumes.py', 'tests/unit/benchmark/context/test_tempest.py', 'tests/unit/benchmark/scenarios/cinder/test_utils.py', 'tests/unit/benchmark/scenarios/vm/test_utils.py', 'tests/unit/benchmark/test_validation.py', 'tests/ci/rally-gate.sh', 'tests/unit/benchmark/scenarios/test_utils.py', 'tests/unit/verification/verifiers/fakes.py', 'tests/unit/benchmark/context/cleanup/__init__.py', 'tests/unit/objects/test_endpoint.py', 'tests/unit/deploy/engines/test_existing.py', 'tests/unit/benchmark/scenarios/ceilometer/test_stats.py', 'tests/unit/benchmark/scenarios/neutron/test_network.py', 'tests/unit/cmd/__init__.py', 'tests/unit/cmd/commands/__init__.py', 'tests/unit/db/__init__.py', 'tests/unit/doc/test_task_samples.py', 'tests/unit/benchmark/context/quotas/test_nova_quotas.py', 'tests/unit/benchmark/processing/test_plot.py', 'tests/unit/benchmark/scenarios/heat/__init__.py', 'tests/unit/deploy/serverprovider/providers/test_lxc.py', 'tests/unit/objects/__init__.py', 'tests/ci/README.rst', 'tests/unit/aas/rest/__init__.py', 'tests/unit/test_utils.py', 'tests/unit/benchmark/sla/test_base.py', 'tests/unit/fakes.py', 'tests/unit/benchmark/context/quotas/test_designate_quotas.py', 'tests/unit/verification/verifiers/test_config.py', 'tests/unit/benchmark/scenarios/dummy/__init__.py', 'tests/unit/benchmark/scenarios/test_base.py', 'tests/unit/deploy/test_engine.py', 'tests/unit/test.py', 'tests/functional/test_cli_info.py', 'tests/unit/fixtures/import/broken.py', 'tests/unit/benchmark/context/sahara/test_sahara_cluster.py', 'tests/unit/benchmark/scenarios/tempest/test_tempest.py', 'tests/unit/verification/verifiers/__init__.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/benchmark/context/test_roles.py', 'tests/unit/benchmark/scenarios/heat/test_stacks.py', 'tests/unit/benchmark/scenarios/authenticate/__init__.py', 'tests/unit/benchmark/scenarios/ceilometer/test_utils.py', 'tests/unit/cmd/commands/test_show.py', 'tests/unit/benchmark/scenarios/keystone/test_utils.py', 'tests/unit/deploy/serverprovider/providers/__init__.py', 'tests/unit/cmd/test_envutils.py', 'tests/unit/deploy/serverprovider/providers/test_existing.py', 'tests/unit/benchmark/context/test_users.py', 'tests/unit/benchmark/scenarios/designate/test_basic.py', 'tests/unit/deploy/engines/__init__.py', 'tests/functional/test_cli_deployment.py', 'tests/ci/rally-integrated.sh', 'tests/unit/benchmark/scenarios/neutron/__init__.py', 'tests/unit/benchmark/context/cleanup/test_user_cleanup.py', 'tests/unit/benchmark/context/test_images.py', 'tests/unit/orchestrator/test_api.py', 'tests/unit/orchestrator/__init__.py', 'tests/unit/benchmark/wrappers/test_keystone.py', 'tests/unit/benchmark/sla/__init__.py', 'tests/unit/verification/verifiers/fake_log.xml', 'tests/unit/deploy/test_lxc.py', 'tests/unit/benchmark/test_utils.py', 'tests/unit/objects/test_verification.py', 'tests/unit/verification/verifiers/test_json2html.py', 'tests/unit/benchmark/processing/__init__.py', 'tests/unit/aas/rest/controllers/test_root.py', 'tests/unit/benchmark/scenarios/glance/test_images.py', 'tests/unit/benchmark/scenarios/neutron/test_utils.py', 'tests/unit/benchmark/context/quotas/__init__.py', 'tests/unit/doc/__init__.py', 'tests/unit/cmd/commands/test_info.py', 'tests/unit/benchmark/scenarios/ceilometer/test_queries.py', 'tests/unit/deploy/serverprovider/providers/test_openstack.py', 'tests/unit/benchmark/scenarios/ceilometer/test_resources.py', 'tox.ini', 'tests/unit/deploy/engines/test_devstack.py', 'tests/unit/fixtures/import/package/__init__.py', 'tests/unit/verification/verifiers/test_tempest.py', 'tests/functional/test_cli_show.py', 'tests/unit/benchmark/scenarios/vm/test_vmtasks.py', 'tests/unit/benchmark/runners/test_constant.py', 'tests/unit/rally_scenarios/__init__.py', 'tests/unit/cmd/commands/test_use.py', 'tests/unit/fixtures/import/package/a.py', 'tests/unit/benchmark/scenarios/sahara/test_utils.py', 'tests/unit/aas/rest/controllers/__init__.py', 'tests/unit/benchmark/context/cleanup/test_utils.py', 'tests/unit/benchmark/scenarios/ceilometer/test_meters.py', 'tests/unit/fixtures/import/__init__.py', 'tests/unit/benchmark/scenarios/sahara/__init__.py', 'tests/functional/test_cli_utils.py', 'tests/unit/benchmark/scenarios/heat/test_utils.py', 'tests/unit/cmd/commands/test_task.py', 'tests/unit/benchmark/context/quotas/test_quotas.py', 'tests/ci/__init__.py', 'tests/unit/benchmark/scenarios/dummy/test_dummy.py', 'tests/unit/benchmark/scenarios/nova/test_utils.py', 'tests/unit/test_fileutils.py', 'tests/unit/deploy/engines/test_fuel.py', 'tests/unit/benchmark/scenarios/quotas/test_quotas.py', 'tests/unit/benchmark/runners/test_serial.py', 'tests/unit/benchmark/context/cleanup/test_admin_cleanup.py', 'tests/unit/deploy/__init__.py', 'tests/unit/verification/__init__.py', 'tests/unit/benchmark/context/sahara/test_sahara_image.py', 'tests/unit/benchmark/scenarios/designate/test_utils.py', 'tests/unit/benchmark/scenarios/quotas/__init__.py', 'tests/unit/benchmark/context/quotas/test_neutron_quotas.py', 'tests/unit/benchmark/scenarios/test_authenticate.py', 'tests/unit/benchmark/test_types.py', 'tests/unit/benchmark/scenarios/nova/__init__.py', 'tests/unit/cmd/commands/test_verify.py', 'tests/unit/benchmark/runners/test_base.py', 'tests/unit/benchmark/context/sahara/__init__.py', 'tests/unit/objects/test_deploy.py', 'tests/unit/objects/test_task.py', 'tests/unit/benchmark/scenarios/glance/__init__.py', 'tests/unit/cmd/test_cliutils.py', 'tests/unit/test_osclients.py', '.testr.conf', 'tests/unit/benchmark/scenarios/cinder/__init__.py', 'tests/unit/benchmark/scenarios/vm/__init__.py', 'tests/unit/cmd/commands/test_deployment.py', 'tests/unit/test_sshutils.py', 'tests/unit/benchmark/scenarios/keystone/test_basic.py', 'tests/unit/benchmark/context/test_keypair.py', 'tests/unit/benchmark/context/__init__.py', 'tests/unit/benchmark/scenarios/sahara/test_clusters.py', 'tests/unit/rally_scenarios/test_scenarios.py']",172,caf9ea0b68cdc7829a6bdc177c5017fec436d3fc,testing,"from tests.unit import test os.path.dirname(__file__), "".."", "".."", "".."", ""rally-scenarios"")","from tests import test os.path.dirname(__file__), "".."", "".."", ""rally-scenarios"")",154,154
openstack%2Fcookbook-openstack-identity~master~I6e007888e1b37a54628ab5c09e62f636a0b622ed,openstack/cookbook-openstack-identity,master,I6e007888e1b37a54628ab5c09e62f636a0b622ed,add a Rakefile to structure test runs,MERGED,2014-09-30 12:21:42.000000000,2014-10-07 15:08:00.000000000,2014-10-07 15:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:21:42.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/31621684b926ae23bf1d650f877ee2f3dbb300ab', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: I6e007888e1b37a54628ab5c09e62f636a0b622ed\nblueprint: rakefile\n""}]",0,125016,31621684b926ae23bf1d650f877ee2f3dbb300ab,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: I6e007888e1b37a54628ab5c09e62f636a0b622ed
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/16/125016/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,31621684b926ae23bf1d650f877ee2f3dbb300ab,bp/rakefile, Include: - berks-cookbooks/**, Includes:,46,11
openstack%2Fcookbook-openstack-ops-database~master~Ia822611f48f27b1027f508004150f83b0a2762f7,openstack/cookbook-openstack-ops-database,master,Ia822611f48f27b1027f508004150f83b0a2762f7,add a Rakefile to structure test runs,MERGED,2014-09-30 12:54:43.000000000,2014-10-07 15:07:28.000000000,2014-10-07 15:07:27.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:54:43.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/55f09a76f9caf8ad5f2f6c001c955d81b91d0727', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: Ia822611f48f27b1027f508004150f83b0a2762f7\nblueprint: rakefile\n""}]",0,125037,55f09a76f9caf8ad5f2f6c001c955d81b91d0727,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: Ia822611f48f27b1027f508004150f83b0a2762f7
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/37/125037/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,55f09a76f9caf8ad5f2f6c001c955d81b91d0727,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fcookbook-openstack-image~master~Iee61f2aecb237102b9caef6e298b0df85c24370b,openstack/cookbook-openstack-image,master,Iee61f2aecb237102b9caef6e298b0df85c24370b,add a Rakefile to structure test runs,MERGED,2014-09-30 12:42:32.000000000,2014-10-07 15:06:09.000000000,2014-10-07 15:06:08.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:42:32.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/d39c346a5dddf7758602a3a1308bc51924ea31fb', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: Iee61f2aecb237102b9caef6e298b0df85c24370b\nblueprint: rakefile\n""}]",0,125023,d39c346a5dddf7758602a3a1308bc51924ea31fb,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: Iee61f2aecb237102b9caef6e298b0df85c24370b
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/23/125023/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,d39c346a5dddf7758602a3a1308bc51924ea31fb,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fcookbook-openstack-object-storage~master~I7fee4e90c2f50e3c8467a0af93118c696400eafb,openstack/cookbook-openstack-object-storage,master,I7fee4e90c2f50e3c8467a0af93118c696400eafb,add a Rakefile to structure test runs,MERGED,2014-09-30 12:44:03.000000000,2014-10-07 14:57:24.000000000,2014-10-07 14:57:24.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-09-30 12:44:03.000000000', 'files': ['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/6950ed521aff442dd2121846c1a630ca21e02d9c', 'message': ""add a Rakefile to structure test runs\n\nHaving a Rakefile will allow us to change the actual test commands on\nour side rather than relying on changes to the openstack-infra\nrepository. This should make it a lot faster to change things, but also\neasier to test since the jenkins jobs are actually run in this\nrepository, not the openstack-infra one.\n\nThis commit defines the jobs we previously had defined in Jenkins and\nuses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,\nrubocop).\n\nThere is also a :clean task to help with deleting the files generated by\nthe other jobs.\n\nAlso changed foodcritic to run on the source cookbook rather than the\none installed by berks, see\ne.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369\n\nChange-Id: I7fee4e90c2f50e3c8467a0af93118c696400eafb\nblueprint: rakefile\n""}]",0,125024,6950ed521aff442dd2121846c1a630ca21e02d9c,7,3,1,2340,,,0,"add a Rakefile to structure test runs

Having a Rakefile will allow us to change the actual test commands on
our side rather than relying on changes to the openstack-infra
repository. This should make it a lot faster to change things, but also
easier to test since the jenkins jobs are actually run in this
repository, not the openstack-infra one.

This commit defines the jobs we previously had defined in Jenkins and
uses 'high-level' naming consistently (i.e. lint, style vs. foodcritic,
rubocop).

There is also a :clean task to help with deleting the files generated by
the other jobs.

Also changed foodcritic to run on the source cookbook rather than the
one installed by berks, see
e.g. https://github.com/berkshelf/berkshelf/issues/931#issuecomment-29668369

Change-Id: I7fee4e90c2f50e3c8467a0af93118c696400eafb
blueprint: rakefile
",git fetch https://review.opendev.org/openstack/cookbook-openstack-object-storage refs/changes/24/125024/1 && git format-patch -1 --stdout FETCH_HEAD,"['TESTING.md', '.gitignore', 'Rakefile', 'Gemfile', '.rubocop.yml']",5,6950ed521aff442dd2121846c1a630ca21e02d9c,bp/rakefile, - berks-cookbooks/**,,45,10
openstack%2Fkolla~master~Ibf4cb2b005cc57bcb11e298dd5109cfe309c9ec3,openstack/kolla,master,Ibf4cb2b005cc57bcb11e298dd5109cfe309c9ec3,"remove ""master"" from mariadb k8s configs",MERGED,2014-10-07 01:05:24.000000000,2014-10-07 14:54:57.000000000,2014-10-07 14:54:56.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-07 01:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5520ddb7c19734c3525cdf1713ad5fe7bf96b811', 'message': 'remove ""master"" from mariadb k8s configs\n\nLabelling things foo-master crept into this repository from the\nkubernetes guestbook example (which has redis-master and redis-slaves).\nWe\'re not running clustered software at the moment so these labels are\nunnecessary.\n\nChange-Id: Ibf4cb2b005cc57bcb11e298dd5109cfe309c9ec3\n'}, {'number': 2, 'created': '2014-10-07 14:40:07.000000000', 'files': ['docker/mariadb/mariadb.json', 'docker/mariadb/mariadb-service.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/863e29a78081cb790ae086c37c32dfd9ecf3e13a', 'message': 'remove ""master"" from mariadb k8s configs\n\nLabelling things foo-master crept into this repository from the\nkubernetes guestbook example (which has redis-master and redis-slaves).\nWe\'re not running clustered software at the moment so these labels are\nunnecessary.\n\nChange-Id: Ibf4cb2b005cc57bcb11e298dd5109cfe309c9ec3\n'}]",0,126454,863e29a78081cb790ae086c37c32dfd9ecf3e13a,14,4,2,8745,,,0,"remove ""master"" from mariadb k8s configs

Labelling things foo-master crept into this repository from the
kubernetes guestbook example (which has redis-master and redis-slaves).
We're not running clustered software at the moment so these labels are
unnecessary.

Change-Id: Ibf4cb2b005cc57bcb11e298dd5109cfe309c9ec3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/126454/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/mariadb/mariadb.json', 'docker/mariadb/mariadb-service.json']",2,5520ddb7c19734c3525cdf1713ad5fe7bf96b811,(detached," ""id"": ""mariadb"", ""name"": ""mariadb"""," ""id"": ""mariadbmaster"", ""name"": ""mariadb-master""",5,5
openstack%2Fkolla~master~Iafdae5d5e38f6910dbf89af5a5f47a9c29df4e5c,openstack/kolla,master,Iafdae5d5e38f6910dbf89af5a5f47a9c29df4e5c,Remove the trailing space in README.md,MERGED,2014-10-07 08:41:05.000000000,2014-10-07 14:50:59.000000000,2014-10-07 14:50:58.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2834}, {'_account_id': 5792}]","[{'number': 1, 'created': '2014-10-07 08:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f7b5b531fb2b7684cd0b6e245aeca63f80ddd058', 'message': 'Remove the trailing space in README.md\n\nChange-Id: Iafdae5d5e38f6910dbf89af5a5f47a9c29df4e5c\n'}, {'number': 2, 'created': '2014-10-07 08:46:08.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/fd0275b659b2f1874eeec574af128abcad6502ea', 'message': 'Remove the trailing space in README.md\n\nChange-Id: Iafdae5d5e38f6910dbf89af5a5f47a9c29df4e5c\n'}]",0,126491,fd0275b659b2f1874eeec574af128abcad6502ea,10,4,2,6348,,,0,"Remove the trailing space in README.md

Change-Id: Iafdae5d5e38f6910dbf89af5a5f47a9c29df4e5c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/91/126491/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,f7b5b531fb2b7684cd0b6e245aeca63f80ddd058,remove_whitespace,Build Docker Images,Build Docker Images ,1,1
openstack%2Ffuel-specs~master~I596dbc8f383816a3b50187ce67e0f252b37dfabb,openstack/fuel-specs,master,I596dbc8f383816a3b50187ce67e0f252b37dfabb,Use vSphere Datastore backend for Glance with vCenter,MERGED,2014-09-26 11:02:13.000000000,2014-10-07 14:33:48.000000000,2014-10-07 14:33:48.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8909}, {'_account_id': 8935}, {'_account_id': 11163}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 12415}]","[{'number': 1, 'created': '2014-09-26 11:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/815f1145f451e3c54a8b0cac310dccf06b3f379c', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 2, 'created': '2014-09-26 11:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a740744b7fc984be702e75948030c4e2c6696023', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 3, 'created': '2014-10-01 11:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/aa0894d907347c5bd0b70cb8cf0c92b0b3e8a9de', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 4, 'created': '2014-10-02 10:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4289d92cbe228f1384bcad885ad694ccb27f262c', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 5, 'created': '2014-10-02 11:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6a0136c7c74a1303159f818f46ac9e14c3d4fe09', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 6, 'created': '2014-10-02 15:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/290e90735e4c2e4db14ceb836fe48e43a1733ce3', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 7, 'created': '2014-10-03 13:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0687836f68079022b85ce32aaa9a5156168bd571', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 8, 'created': '2014-10-03 14:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/7bdefa1f27a50f7d6e1af7ec87883f804f8e8f22', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 9, 'created': '2014-10-03 14:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b90f0f964fda155143147a2a53b73a42e29671bf', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 10, 'created': '2014-10-03 14:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/407ea85d78c448e21f6358b3bf3f216dfb2530a1', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 11, 'created': '2014-10-03 15:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/9ff8c8c3bf816aeb0476cab6dbf157fbac7e54a5', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 12, 'created': '2014-10-03 15:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/3235fb9166af9174f1df2269d1132c37e9e5c178', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}, {'number': 13, 'created': '2014-10-06 10:55:19.000000000', 'files': ['specs/6.0/vsphere-glance-backend.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/136f050aae679cde522663f02bef75d486000906', 'message': 'Use vSphere Datastore backend for Glance with vCenter\n\nChange-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb\nBlueprint: vsphere-glance-backend\n'}]",37,124360,136f050aae679cde522663f02bef75d486000906,50,10,13,12139,,,0,"Use vSphere Datastore backend for Glance with vCenter

Change-Id: I596dbc8f383816a3b50187ce67e0f252b37dfabb
Blueprint: vsphere-glance-backend
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/60/124360/12 && git format-patch -1 --stdout FETCH_HEAD,['specs/6.0/vsphere-glance-backend.rst'],1,815f1145f451e3c54a8b0cac310dccf06b3f379c,bp/vsphere-glance-backend,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Use vSphere Datastore backend for Glance with vCenter ========================================== https://blueprints.launchpad.net/fuel/+spec/vsphere-glance-backend Fuel will be able to deploy OpenStack with vSphere Datastore support as glance backend. Problem description =================== Fuel is not support deploy with vSphere Datastore as glance backend, but OpenStack already supports this feature. [0] [0] http://docs.openstack.org/trunk/config-reference/content/vmware-glance-backend.html Proposed change =============== Add this case in puppet manifetst and add ""vsphere"" option for Glance backend and options to connect to this backend in UI. Alternatives ------------ We can do nothing. Data model impact ----------------- None REST API impact --------------- None Upgrade impact -------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: srogov (Stepan Rogov) Other contributors: None Work Items ---------- * Set up the dev environment with one vCenter. * Writing puppet modules. * Writing UI enhansments. * Testing. Dependencies ============ https://blueprints.launchpad.net/glance/+spec/vmware-datastore-storage-backend Testing ======= Standart OSTF test for this type(Gance + vSphere) deployment. Documentation Impact ==================== The documentation should describe how to set up vCenter data stores for the Image Service backend. References ========== https://blueprints.launchpad.net/glance/+spec/vmware-datastore-storage-backend http://docs.openstack.org/trunk/config-reference/content/vmware-glance-backend.html ",,121,0
openstack%2Foslo-cookiecutter~master~I1bfdb175d5df3a55708f75bc54dc0e2a2e2c234b,openstack/oslo-cookiecutter,master,I1bfdb175d5df3a55708f75bc54dc0e2a2e2c234b,multiprocessing import from requirements/setup.py,MERGED,2014-10-01 18:14:35.000000000,2014-10-07 14:29:09.000000000,2014-10-07 14:29:09.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-10-01 18:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/466504bb4849e295d50efe26c326932e1827be7b', 'message': 'multiprocessing import from requirements/setup.py\n\na mandatory work around from requirements repo.\n\nChange-Id: I1bfdb175d5df3a55708f75bc54dc0e2a2e2c234b\n'}, {'number': 2, 'created': '2014-10-07 12:57:01.000000000', 'files': ['oslo.{{cookiecutter.module_name}}/setup.py'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/4d0bdeba2556e70f2d48d1ba2a0945d72cad7131', 'message': 'multiprocessing import from requirements/setup.py\n\na mandatory work around from requirements repo.\n\nChange-Id: I1bfdb175d5df3a55708f75bc54dc0e2a2e2c234b\n'}]",0,125449,4d0bdeba2556e70f2d48d1ba2a0945d72cad7131,9,3,2,5638,,,0,"multiprocessing import from requirements/setup.py

a mandatory work around from requirements repo.

Change-Id: I1bfdb175d5df3a55708f75bc54dc0e2a2e2c234b
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/49/125449/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo.{{cookiecutter.module_name}}/setup.py'],1,466504bb4849e295d50efe26c326932e1827be7b,,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,8,0
openstack%2Fdib-utils~master~Ibd35556d8a5d5e55360908059a93e48de7982215,openstack/dib-utils,master,Ibd35556d8a5d5e55360908059a93e48de7982215,Add missing LICENSE,MERGED,2014-09-19 00:27:11.000000000,2014-10-07 14:26:40.000000000,2014-10-07 14:26:40.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6449}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-09-19 00:27:11.000000000', 'files': ['LICENSE'], 'web_link': 'https://opendev.org/openstack/dib-utils/commit/8ee133c3e7c8b3a065531118a7574790da1d96a0', 'message': 'Add missing LICENSE\n\nPretty sure this should be required.\n\nChange-Id: Ibd35556d8a5d5e55360908059a93e48de7982215\n'}]",1,122577,8ee133c3e7c8b3a065531118a7574790da1d96a0,11,6,1,7144,,,0,"Add missing LICENSE

Pretty sure this should be required.

Change-Id: Ibd35556d8a5d5e55360908059a93e48de7982215
",git fetch https://review.opendev.org/openstack/dib-utils refs/changes/77/122577/1 && git format-patch -1 --stdout FETCH_HEAD,['LICENSE'],1,8ee133c3e7c8b3a065531118a7574790da1d96a0,license," Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. ""License"" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, ""control"" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""Object"" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""Not a Contribution."" ""Contributor"" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a ""NOTICE"" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets ""[]"" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same ""printed page"" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ",,202,0
openstack%2Fproject-config~master~I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4,openstack/project-config,master,I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4,Add manifest build to groups portal release job,MERGED,2014-10-01 20:25:52.000000000,2014-10-07 14:14:54.000000000,2014-10-07 14:14:53.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6633}]","[{'number': 1, 'created': '2014-10-01 20:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f4c3c6bb1063e9fd5a4efe3a5b6f830f043ff643', 'message': 'Add manifest build to groups portal release job\n\nGenerate a manifest file during groups portal release job\nto enlist the available development and production release\ninformation for third party Drupal deployment tools like drush.\nThe manifest file will be published under\nhttp://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x\nurl.\n\nChange-Id: I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4\n'}, {'number': 2, 'created': '2014-10-02 06:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/53fd9327cb471c442aeecf9c878adacf3686ea81', 'message': 'Add manifest build to groups portal release job\n\nGenerate a manifest file during groups portal release job\nto enlist the available development and production release\ninformation for third party Drupal deployment tools like drush.\nThe manifest file will be published under\nhttp://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x\nurl.\n\nChange-Id: I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4\n'}, {'number': 3, 'created': '2014-10-02 06:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f7e7c1fddc332d2b0586eb143058d92538a4ef6c', 'message': 'Add manifest build to groups portal release job\n\nGenerate a manifest file during groups portal release job\nto enlist the available development and production release\ninformation for third party Drupal deployment tools like drush.\nThe manifest file will be published under\nhttp://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x\nurl.\n\nChange-Id: I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4\n'}, {'number': 4, 'created': '2014-10-06 16:02:10.000000000', 'files': ['jenkins/jobs/groups.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e2939cfaa773def1ecaf7cd51727246f2ff212ae', 'message': 'Add manifest build to groups portal release job\n\nGenerate a manifest file during groups portal release job\nto enlist the available development and production release\ninformation for third party Drupal deployment tools like drush.\nThe manifest file will be published under\nhttp://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x\nurl.\n\nChange-Id: I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4\n'}]",4,125494,e2939cfaa773def1ecaf7cd51727246f2ff212ae,16,7,4,6633,,,0,"Add manifest build to groups portal release job

Generate a manifest file during groups portal release job
to enlist the available development and production release
information for third party Drupal deployment tools like drush.
The manifest file will be published under
http://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x
url.

Change-Id: I48f694cbc2ea46d41a10aafb8b51ebb0a50f7ef4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/94/125494/4 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/groups.yaml'],1,f4c3c6bb1063e9fd5a4efe3a5b6f830f043ff643,groups-release-manifest-build," # build manifest file if [[ ""${COMMITS_SINCE_TAG}"" == """" ]]; then VERSION=7.x-$PROJECT_VER else VERSION=7.x-0.x-dev fi MD5HASH=`cat tarballs/groups-$PROJECT_VER.md5 | awk '{ print $1 }'` OUTFILE=drupal-updates/release-history/groups/7.x MANIFESTURL=http://tarballs.openstack.org/groups/drupal-updates/release-history/groups/7.x mkdir -p drupal-updates/release-history/groups scripts/release-manifest.php --version=$VERSION --releasetar=groups-$PROJECT_VER.tar.gz --md5=$MD5HASH --outfile=$OUTFILE --manifesturl=$MANIFESTURL --verbose --debug - target: 'tarballs/groups/' source: './drupal-updates/**' keep-hierarchy: true copy-after-failure: false",,15,0
openstack%2Foslo.utils~master~Iec3a5cfd6245835c39e7dbe0354abb3353e42d5f,openstack/oslo.utils,master,Iec3a5cfd6245835c39e7dbe0354abb3353e42d5f,Add history/changelog to docs,MERGED,2014-09-10 13:52:19.000000000,2014-10-07 14:13:22.000000000,2014-10-07 14:13:22.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-09-10 13:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/61e48df7a7dbd9b304d425c378b08dcbe94aadef', 'message': 'Add history/changelog to docs\n\nChange-Id: Iec3a5cfd6245835c39e7dbe0354abb3353e42d5f\n'}, {'number': 2, 'created': '2014-10-04 13:05:13.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/c7ef2c25670e0e69f36a97a2307f351bcf0a69a5', 'message': 'Add history/changelog to docs\n\nChange-Id: Iec3a5cfd6245835c39e7dbe0354abb3353e42d5f\n'}]",0,120417,c7ef2c25670e0e69f36a97a2307f351bcf0a69a5,17,7,2,5638,,,0,"Add history/changelog to docs

Change-Id: Iec3a5cfd6245835c39e7dbe0354abb3353e42d5f
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/17/120417/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,61e48df7a7dbd9b304d425c378b08dcbe94aadef,,.. include:: ../../ChangeLog ,,2,0
openstack%2Fglance~proposed%2Fjuno~I49255255df311036d516768afc55475c1f9aad47,openstack/glance,proposed/juno,I49255255df311036d516768afc55475c1f9aad47,Mark custom properties in image schema as non-base,MERGED,2014-10-07 07:12:23.000000000,2014-10-07 14:11:28.000000000,2014-10-07 14:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-10-07 07:12:23.000000000', 'files': ['glance/api/v2/images.py', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0f3b518028196b5c8c36b378928dae31c2c4a6fa', 'message': 'Mark custom properties in image schema as non-base\n\nCurrently it is impossible to determine if given image schema property\nis base or custom one and knowledge of that can be handy in some\nsituations.    Proposed change appends to every custom property special\nkey which determiness that it is not a base property.\n\nChange-Id: I49255255df311036d516768afc55475c1f9aad47\nPartial-Bug: #1371559\n(cherry picked from commit 94c05cbdbb3a78b3df4df8d522555f34d2f0a166)\n'}]",0,126479,0f3b518028196b5c8c36b378928dae31c2c4a6fa,11,3,1,13161,,,0,"Mark custom properties in image schema as non-base

Currently it is impossible to determine if given image schema property
is base or custom one and knowledge of that can be handy in some
situations.    Proposed change appends to every custom property special
key which determiness that it is not a base property.

Change-Id: I49255255df311036d516768afc55475c1f9aad47
Partial-Bug: #1371559
(cherry picked from commit 94c05cbdbb3a78b3df4df8d522555f34d2f0a166)
",git fetch https://review.opendev.org/openstack/glance refs/changes/79/126479/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/images.py', 'glance/tests/unit/v2/test_images_resource.py']",2,0f3b518028196b5c8c36b378928dae31c2c4a6fa,," class TestImageSchemaDeterminePropertyBasis(test_utils.BaseTestCase): def test_custom_property_marked_as_non_base(self): self.config(allow_additional_image_properties=False) custom_image_properties = { 'pants': { 'type': 'string', }, } schema = glance.api.v2.images.get_schema(custom_image_properties) self.assertFalse(schema.properties['pants'].get('is_base', True)) def test_base_property_marked_as_base(self): schema = glance.api.v2.images.get_schema() self.assertTrue(schema.properties['disk_format'].get('is_base', True))",,21,1
openstack%2Fneutron~stable%2Ficehouse~I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a,openstack/neutron,stable/icehouse,I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a,Enforce required config params for ODL driver,MERGED,2014-09-20 08:16:56.000000000,2014-10-07 14:05:57.000000000,2014-10-07 14:05:56.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-09-20 08:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9bd1d50a630d942abc5869caec32f58349794ad2', 'message': 'Enforce required config params for ODL driver\n\nRaise a config error during initialization if\nthere is no URL, username, or password specified\nin the config for the OpenDayLight ML2 driver.\n\nCloses-Bug: #1301432\nChange-Id: I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a\n(cherry picked from commit 2da351af7d2a10a3055020d572d357c56ba2689b)\n'}, {'number': 2, 'created': '2014-09-27 16:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4551513f33f0e1a092f01359db3dbca03b54c491', 'message': 'Enforce required config params for ODL driver\n\nRaise a config error during initialization if\nthere is no URL, username, or password specified\nin the config for the OpenDayLight ML2 driver.\n\nCloses-Bug: #1301432\nChange-Id: I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a\n(cherry picked from commit 2da351af7d2a10a3055020d572d357c56ba2689b)\n'}, {'number': 3, 'created': '2014-09-29 12:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf862b9c4d8361eff3903df2a8460d89bbc09495', 'message': 'Enforce required config params for ODL driver\n\nRaise a config error during initialization if\nthere is no URL, username, or password specified\nin the config for the OpenDayLight ML2 driver.\n\nAlso ensure core plugin deallocation after every\ntest [1] following the previous backport [2].\n\n[1] https://review.openstack.org/#/c/92793/\n[2] https://review.openstack.org/#/c/102329/\n\nCloses-Bug: #1301432\nChange-Id: I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a\n(cherry picked from commit 2da351af7d2a10a3055020d572d357c56ba2689b)\n'}, {'number': 4, 'created': '2014-09-29 22:34:20.000000000', 'files': ['neutron/plugins/ml2/drivers/mechanism_odl.py', 'neutron/tests/unit/ml2/test_mechanism_odl.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/45b01c1c8543d8586633de4d01353f7f3c553a4d', 'message': 'Enforce required config params for ODL driver\n\nRaise a config error during initialization if\nthere is no URL, username, or password specified\nin the config for the OpenDayLight ML2 driver.\n\nAlso ensure core plugin deallocation after every\ntest [1] following the previous backport [2].\n\n[1] https://review.openstack.org/#/c/92793/\n[2] https://review.openstack.org/#/c/102329/\n\nCloses-Bug: #1301432\nChange-Id: I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a\n(cherry picked from commit 2da351af7d2a10a3055020d572d357c56ba2689b)\n'}]",1,122932,45b01c1c8543d8586633de4d01353f7f3c553a4d,134,20,4,11692,,,0,"Enforce required config params for ODL driver

Raise a config error during initialization if
there is no URL, username, or password specified
in the config for the OpenDayLight ML2 driver.

Also ensure core plugin deallocation after every
test [1] following the previous backport [2].

[1] https://review.openstack.org/#/c/92793/
[2] https://review.openstack.org/#/c/102329/

Closes-Bug: #1301432
Change-Id: I65fc94d3eaaade3d1402d1c82d2c1edfa7133d5a
(cherry picked from commit 2da351af7d2a10a3055020d572d357c56ba2689b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/122932/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/mechanism_odl.py', 'neutron/tests/unit/ml2/test_mechanism_odl.py']",2,9bd1d50a630d942abc5869caec32f58349794ad2,bug/1301432," # Set URL/user/pass so init doesn't throw a cfg required error. # They are not used in these tests since sendjson is overwritten. config.cfg.CONF.set_override('url', 'http://127.0.0.1:9999', 'ml2_odl') config.cfg.CONF.set_override('username', 'someuser', 'ml2_odl') config.cfg.CONF.set_override('password', 'somepass', 'ml2_odl') class OpenDayLightMechanismConfigTests(test_plugin.NeutronDbPluginV2TestCase): def _setUp(self): config.cfg.CONF.set_override('mechanism_drivers', ['logger', 'opendaylight'], 'ml2') config.cfg.CONF.set_override('url', 'http://127.0.0.1:9999', 'ml2_odl') config.cfg.CONF.set_override('username', 'someuser', 'ml2_odl') config.cfg.CONF.set_override('password', 'somepass', 'ml2_odl') def test_url_required(self): self._setUp() config.cfg.CONF.set_override('url', None, 'ml2_odl') self.assertRaises(config.cfg.RequiredOptError, self.setUp, PLUGIN_NAME) def test_username_required(self): self._setUp() config.cfg.CONF.set_override('username', None, 'ml2_odl') self.assertRaises(config.cfg.RequiredOptError, self.setUp, PLUGIN_NAME) def test_password_required(self): self._setUp() config.cfg.CONF.set_override('password', None, 'ml2_odl') self.assertRaises(config.cfg.RequiredOptError, self.setUp, PLUGIN_NAME) ",,46,11
openstack%2Ftempest~master~I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35,openstack/tempest,master,I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35,Separate security group rule test for each args,MERGED,2014-09-25 10:24:28.000000000,2014-10-07 14:03:46.000000000,2014-10-07 14:03:45.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-25 10:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/28ec35b9711ea281e54b7bf6ead02532ab222103', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 2, 'created': '2014-09-25 11:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/808324aa0a4b8db63a2b2bb5ff2b2f975b39a36f', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 3, 'created': '2014-09-25 13:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fb49ec6c84fc41b28357a57df4fbf2cd64cddfbc', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 4, 'created': '2014-09-25 15:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3f5bddffd9bca591e7d170d5cc4d641da0620e32', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 5, 'created': '2014-09-26 01:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9845b037ee380b1a9f268b89e51aa7dd39e448ab', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 6, 'created': '2014-09-26 03:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/31ccfc4cefe87884858209cbaf01bec2f2bffa73', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 7, 'created': '2014-09-29 15:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/57be76b4a829fb13a8c05da5c29cb7a8268700eb', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 8, 'created': '2014-10-02 09:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/632689dbae9837bcbc2f65705404d31f7ba0be46', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nThis patch removes success code checks from each test because the code\nis already checked in the client method create_security_group_rule().\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}, {'number': 9, 'created': '2014-10-03 04:00:31.000000000', 'files': ['tempest/api/compute/security_groups/test_security_group_rules.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9dad940851ab5ad4616ab0e7d6cc0b16a79c5ca9', 'message': 'Separate security group rule test for each args\n\nIf passing ""group_id"" argument to ""add security group rule"" API, the\nAPI ignores ""cidr"" argument.\nIn test_security_group_rules_create_with_optional_arguments, both\narguments are specified and that is meaningless.\nThis patch separates it for each purpose.\n\nThis patch removes success code checks from each test because the code\nis already checked in the client method create_security_group_rule().\n\nChange-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35\nRelated-Bug: #1373832\n'}]",4,124003,9dad940851ab5ad4616ab0e7d6cc0b16a79c5ca9,43,8,9,6167,,,0,"Separate security group rule test for each args

If passing ""group_id"" argument to ""add security group rule"" API, the
API ignores ""cidr"" argument.
In test_security_group_rules_create_with_optional_arguments, both
arguments are specified and that is meaningless.
This patch separates it for each purpose.

This patch removes success code checks from each test because the code
is already checked in the client method create_security_group_rule().

Change-Id: I1af1f37eb2d4b4f182d7ab69bcb0e9c37a356e35
Related-Bug: #1373832
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/124003/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/security_groups/test_security_group_rules.py'],1,28ec35b9711ea281e54b7bf6ead02532ab222103,bug/1373832," def test_security_group_rules_create_with_optional_cidr(self): # with optional argument cidr # Creating a Security Group to add rules to it resp, security_group = self.create_security_group() parent_group_id = security_group['id'] # Adding rules to the created Security Group with optional cidr cidr = '10.2.3.124/24' resp, rule = \ self.client.create_security_group_rule(parent_group_id, self.ip_protocol, self.from_port, self.to_port, cidr=cidr) self.assertEqual(200, resp.status) @test.attr(type='smoke') @test.services('network') def test_security_group_rules_create_with_optional_group_id(self): # Positive test: Creation of Security Group rule # with optional argument group_id # should be successful # Adding rules to the created Security Group with optional group_id"," def test_security_group_rules_create_with_optional_arguments(self): # with optional arguments secgroup1 = None secgroup2 = None # Adding rules to the created Security Group with optional arguments cidr = '10.2.3.124/24' cidr=cidr,",26,7
openstack%2Fceilometer~master~I8f816055bb76e67d239de73a57b7cb0baa94dee5,openstack/ceilometer,master,I8f816055bb76e67d239de73a57b7cb0baa94dee5,Implement redesigned separator in names of columns in HBase,MERGED,2014-07-11 13:50:01.000000000,2014-10-07 14:03:20.000000000,2014-10-07 14:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-11 13:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3c6fd8729faa3b5eafa5ad7cf4c4fe6f21e6ff50', 'message': 'Implement not typed separator in names of columns in HBase. \nIt should to avoid from incorrect parsing thru stored  data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 2, 'created': '2014-07-11 15:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d0d1d3851a1ae7ebd19094012195467d96dfd7a', 'message': 'Implement not typed separator in names of columns in HBase.\n\nIt should to avoid from incorrect parsing thru stored  data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 3, 'created': '2014-07-11 15:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a1b61bcb2148e5129d457ff64717de01866c0ce3', 'message': 'Implement not typed separator in names of columns in HBase\n\nIt should to avoid from incorrect parsing thru stored  data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 4, 'created': '2014-07-16 14:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2283000ca134f768b495d9ebde31f7a8fd5932ef', 'message': 'Implement not typed separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 5, 'created': '2014-07-21 11:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2afb18b6dc98b8d5fdea1088e157b8fdc824f17a', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 6, 'created': '2014-07-22 11:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bde880a572381e7e60ce280aee5108883b7ef4c4', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5\n'}, {'number': 7, 'created': '2014-07-23 09:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f8e94ec4473f34e15b43fa70a36bd45698ad2aea', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 8, 'created': '2014-07-28 10:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4960df905f8eff38cc390838aa890e9b796be482', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 9, 'created': '2014-07-29 09:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e5d6e7adcad3769c6f952c27abe5cbc1ff8920d', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 10, 'created': '2014-07-30 08:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d781ecc7457fb5631bd2a642e4f7e6e089bcf6d8', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 11, 'created': '2014-07-31 10:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d0b2878dfe8d851589441286920c3dd6e184a7a6', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 12, 'created': '2014-08-01 15:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1b9726056997d98ee7f7ecbd8dbfff6349f807a6', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 13, 'created': '2014-08-04 10:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8a7352e460b4cbd8c555e16312442dcb8ef631fb', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis is needed to avoid from incorrect parsing thru stored data in HBase.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 14, 'created': '2014-08-04 15:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bb6080d0e84345efd8d797f9faffc0a5e848a1d4', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in \nHBase. Now we are using separators ""_!+"" to construct the ""key"", but we\ndon\'t  restrict any character inside the names of metrics, so it could be a\nreason of incorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 15, 'created': '2014-08-05 08:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6e0087b9f363127835430493a8371470de63b091', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in \nHBase. Now we are using separators ""_!+"" to construct the ""key"", but we\ndon\'t  restrict any character inside the names of metrics, so it could be a\nreason of incorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 16, 'created': '2014-08-29 05:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c711b6f01fb5145741830bf5c60258a555edcff', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in\nHBase. Now we are using separators ""_!+"" to construct the ""key"", but we\ndon\'t  restrict any character inside the names of metrics, so it could be a\nreason of incorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5\n'}, {'number': 17, 'created': '2014-09-24 13:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/24d23d50a217d457c8a0c1a347e6600b2b49bcf8', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5\n'}, {'number': 18, 'created': '2014-10-01 15:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/50a15d6babb9ab929ee5cea767e11bdf9b181342', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 19, 'created': '2014-10-03 14:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/06619d498132655a87d226a1ccc3d77c5197791a', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 20, 'created': '2014-10-06 14:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e71e82c01e6a732fe95334e28de73f3523932ed2', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5'}, {'number': 21, 'created': '2014-10-07 09:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/11488134eec72163e862bb439d7f373d735a0098', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and new method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5\n'}, {'number': 22, 'created': '2014-10-07 10:03:30.000000000', 'files': ['ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/alarm/storage/impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d71753f4aba52cf9fc359aabd8763d5801fab968', 'message': 'Implement redesigned separator in names of columns in HBase\n\nThis change improves constructing ""keys"" for stored data in HBase. Now\nwe are using separators ""_!+"" to construct the ""key"", but we don\'t restrict\nany character inside the names of metrics, so it could be a reason of\nincorrect parsing of stored data.\n\nIn this patch only one separator "":"" is used, and method ""prepare_key""\nhelps to avoid incorrect parsing by ""quoting"" columns and rows names.\n\nCloses-bug: #1328114\nChange-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5\n'}]",28,106376,d71753f4aba52cf9fc359aabd8763d5801fab968,158,13,22,10987,,,0,"Implement redesigned separator in names of columns in HBase

This change improves constructing ""keys"" for stored data in HBase. Now
we are using separators ""_!+"" to construct the ""key"", but we don't restrict
any character inside the names of metrics, so it could be a reason of
incorrect parsing of stored data.

In this patch only one separator "":"" is used, and method ""prepare_key""
helps to avoid incorrect parsing by ""quoting"" columns and rows names.

Closes-bug: #1328114
Change-Id: I8f816055bb76e67d239de73a57b7cb0baa94dee5
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/76/106376/21 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/utils.py']",2,3c6fd8729faa3b5eafa5ad7cf4c4fe6f21e6ff50,bug/1328114,"SEPARATOR = chr(0x00) q.append(u""RowFilter ( = , 'regexstring:\d*%s%s')"" % (SEPARATOR, event_filter.message_id)) res_q = (u""SingleColumnValueFilter "" u""('f', '%s%s%d', %s, 'binary:%s', true, true)"" % (trait_name, SEPARATOR, DTYPE_NAMES[k], OP_SIGN[op], filter_value = start_rts + SEPARATOR + source if source else start_rts filter_value = end_rts + SEPARATOR + source if source else end_rts end_row = u""%s%s%s"" % (some_id, SEPARATOR, rts_start) start_row = u""%s%s%s"" % (some_id, SEPARATOR, rts_end) return u""{1}{0}{2}{0}{3}{0}{4}{0}{5}"".format(SEPARATOR, rts, source, c_name, c_type, c_unit)"," q.append(""RowFilter ( = , 'regexstring:\d*_%s')"" % event_filter.message_id) res_q = (""SingleColumnValueFilter "" ""('f', '%s+%d', %s, 'binary:%s', true, true)"" % (trait_name, DTYPE_NAMES[k], OP_SIGN[op], filter_value = start_rts + '+' + source if source else start_rts filter_value = end_rts + '+' + source if source else end_rts end_row = ""%s_%s"" % (some_id, rts_start) start_row = ""%s_%s"" % (some_id, rts_end) return ""%s+%s+%s!%s!%s"" % (rts, source, c_name, c_type, c_unit)",28,22
openstack%2Fnova~stable%2Ficehouse~Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985,openstack/nova,stable/icehouse,Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985,libvirt: Handle unsupported host capabilities,MERGED,2014-05-20 15:54:48.000000000,2014-10-07 14:03:05.000000000,2014-10-07 14:03:02.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 1313}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 6773}, {'_account_id': 8213}, {'_account_id': 8412}, {'_account_id': 8543}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 10618}, {'_account_id': 11692}]","[{'number': 1, 'created': '2014-05-20 15:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d67921a5239adda9773f7203e56a0a91ce72043', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 2, 'created': '2014-05-31 00:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61e54e38040a3fc159cd7775d1f22cab62fb3d5e', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 3, 'created': '2014-08-26 09:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/928d8cb1286a0065c6eb448f0fae2c107a1d40d9', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 4, 'created': '2014-08-29 07:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dca2ebf11ed77e7ff02651a49bb71021192b331b', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 5, 'created': '2014-08-29 12:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86dca4b7c4274097c6626aeb9c93b03078481d4b', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 6, 'created': '2014-09-16 10:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aaee6a5aeae8d2c6798ca5803226cd62504a1f06', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}, {'number': 7, 'created': '2014-10-03 04:46:33.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8141e7aecdccaa55d92b8174633d0cfc97845412', 'message': 'libvirt: Handle unsupported host capabilities\n\nNeither libvirt-xen nor libvirt-lxc support\nVIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error\ncode that is returned by libvirt.\n\nThe existing code was performing this check improperly by trying to\ncatch an enum value; instead, we need to catch the `libvirtError`\nexception and then check its return code.\n\nCo-Authored-By: Rick Harris <rconradharris@gmail.com>\nCo-Authored-By: Andrew Melton <andrew.melton@rackspace.com>\nCloses-Bug: 1297962\nChange-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985\n(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)\n'}]",13,94409,8141e7aecdccaa55d92b8174633d0cfc97845412,56,15,7,24,,,0,"libvirt: Handle unsupported host capabilities

Neither libvirt-xen nor libvirt-lxc support
VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES so check for the proper error
code that is returned by libvirt.

The existing code was performing this check improperly by trying to
catch an enum value; instead, we need to catch the `libvirtError`
exception and then check its return code.

Co-Authored-By: Rick Harris <rconradharris@gmail.com>
Co-Authored-By: Andrew Melton <andrew.melton@rackspace.com>
Closes-Bug: 1297962
Change-Id: Ie8bf5c9d1f2a27c387f8b2f54a9bb729fa2f0985
(cherry picked from commit 5fc157e0f5245eb79be90cbc8ed545c396fd38af)
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/94409/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,6d67921a5239adda9773f7203e56a0a91ce72043,bug/1297962,"from nova.openstack.common.gettextutils import _LW except libvirt.libvirtError as ex: error_code = ex.get_error_code() if error_code == libvirt.VIR_ERR_NO_SUPPORT: LOG.warn(_LW(""URI %(uri)s does not support full set"" "" of host capabilities: "" ""%(error)s""), {'uri': self.uri(), 'error': ex}) else: raise", except libvirt.VIR_ERR_NO_SUPPORT: # Note(yjiang5): ignore if libvirt has no support pass,45,3
openstack%2Ffuel-devops~master~Ifc912183aceb3ee3fe328805eda69c6057567087,openstack/fuel-devops,master,Ifc912183aceb3ee3fe328805eda69c6057567087,Workaround for virtualbox snapshot lookup,MERGED,2014-10-02 15:01:05.000000000,2014-10-07 14:01:09.000000000,2014-10-07 14:01:09.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 12141}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-02 15:01:05.000000000', 'files': ['devops/driver/libvirt/libvirt_driver.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/7346289f233298f238d7eb3291b46b1092fbdf87', 'message': 'Workaround for virtualbox snapshot lookup\n\nChange-Id: Ifc912183aceb3ee3fe328805eda69c6057567087\nCloses-Bug: #1376778\n'}]",2,125661,7346289f233298f238d7eb3291b46b1092fbdf87,13,6,1,12141,,,0,"Workaround for virtualbox snapshot lookup

Change-Id: Ifc912183aceb3ee3fe328805eda69c6057567087
Closes-Bug: #1376778
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/61/125661/1 && git format-patch -1 --stdout FETCH_HEAD,['devops/driver/libvirt/libvirt_driver.py'],1,7346289f233298f238d7eb3291b46b1092fbdf87,snapshot_lookup_fix, return name in ret.snapshotListNames()," try: ret.snapshotLookupByName(name, 0) return True except libvirt.libvirtError as e: if e.get_error_code() == libvirt.VIR_ERR_NO_DOMAIN_SNAPSHOT: return False else: raise",1,8
openstack%2Fpython-ceilometerclient~master~I20c9aa2b7866fe583978cfd2e3ce9da6796df268,openstack/python-ceilometerclient,master,I20c9aa2b7866fe583978cfd2e3ce9da6796df268,Update apiclient.client module to renew session after token expiration,ABANDONED,2014-09-30 13:50:37.000000000,2014-10-07 13:59:59.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 8871}, {'_account_id': 10722}]","[{'number': 1, 'created': '2014-09-30 13:50:37.000000000', 'files': ['ceilometerclient/openstack/common/apiclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/90efb067831ef474fccc086aff5b0023479611c8', 'message': 'Update apiclient.client module to renew session after token expiration\n\nCurrently session is not renewed if token is expired. This bug\nhas roots in the oslo-incubator common code, that has been\nalready fixed. This change updates apiclient.client common module\nto have these modifications in ceilometerclient code.\nCloses-Bug: #1357343\n\nChange-Id: I20c9aa2b7866fe583978cfd2e3ce9da6796df268\n'}]",0,125058,90efb067831ef474fccc086aff5b0023479611c8,10,5,1,10722,,,0,"Update apiclient.client module to renew session after token expiration

Currently session is not renewed if token is expired. This bug
has roots in the oslo-incubator common code, that has been
already fixed. This change updates apiclient.client common module
to have these modifications in ceilometerclient code.
Closes-Bug: #1357343

Change-Id: I20c9aa2b7866fe583978cfd2e3ce9da6796df268
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/58/125058/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/openstack/common/apiclient/client.py'],1,90efb067831ef474fccc086aff5b0023479611c8,ceilometerclient-1357343,"from oslo.utils import importutilsfrom ceilometerclient.openstack.common._i18n import _ requests.Session.request (such as `headers`) or `json` kwargs.setdefault(""headers"", {}) `HTTPClient.request` _(""Cannot find endpoint or token for request"")) if self.auth_plugin.opts.get('token'): self.auth_plugin.opts['token'] = None if self.auth_plugin.opts.get('endpoint'): self.auth_plugin.opts['endpoint'] = None msg = _(""Invalid %(api_name)s client version '%(version)s'. "" ""Must be one of: %(version_map)s"") % { 'api_name': api_name, 'version': version, 'version_map': ', '.join(version_map.keys())}","from ceilometerclient.openstack.common import importutils' requests.Session.request (such as `headers`) or `json` kwargs.setdefault(""headers"", kwargs.get(""headers"", {}))' `HTTPClient.request` ""Cannot find endpoint or token for request"") msg = ""Invalid %s client version '%s'. must be one of: %s"" % ( (api_name, version, ', '.join(version_map.keys())))",16,7
openstack%2Fnova~stable%2Ficehouse~I5aaecc57504c4aea3c049610ef188978c25cfdc4,openstack/nova,stable/icehouse,I5aaecc57504c4aea3c049610ef188978c25cfdc4,libvirt: Make `fakelibvirt.libvirtError` match,MERGED,2014-09-29 22:50:07.000000000,2014-10-07 13:57:16.000000000,2014-10-07 13:57:13.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9569}, {'_account_id': 9656}, {'_account_id': 10618}, {'_account_id': 11692}]","[{'number': 1, 'created': '2014-09-29 22:50:07.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/df9ead9af4fbcc3f4b4220c29666fd0addd2b263', 'message': 'libvirt: Make `fakelibvirt.libvirtError` match\n\nWhen test code uses `libvirtError`, it may refer to\n`libvirt.libvirtError` or `fakelibvirt.libvirtError` depending on\nwhether `libvirt-python` is installed.\n\nThe existing code had incompatible `__init__` singatures between the\ntwo, meaning that a test could pass locally but fail when run on\nJenkins.\n\nThe solution is to make `fakelibvirt.libvirtError` match libvirt 1.2.3\nexactly.\n\nA convenience function, `make_libvirtError`, is introduced so that\nexceptions can still be created in one shot.\n\nChange-Id: I5aaecc57504c4aea3c049610ef188978c25cfdc4\nCloses-Bug: 1305186\n(cherry picked from commit 78156a7650237bd4875fbbf9cad8db87348f333f)\n'}]",4,124918,df9ead9af4fbcc3f4b4220c29666fd0addd2b263,20,8,1,11692,,,0,"libvirt: Make `fakelibvirt.libvirtError` match

When test code uses `libvirtError`, it may refer to
`libvirt.libvirtError` or `fakelibvirt.libvirtError` depending on
whether `libvirt-python` is installed.

The existing code had incompatible `__init__` singatures between the
two, meaning that a test could pass locally but fail when run on
Jenkins.

The solution is to make `fakelibvirt.libvirtError` match libvirt 1.2.3
exactly.

A convenience function, `make_libvirtError`, is introduced so that
exceptions can still be created in one shot.

Change-Id: I5aaecc57504c4aea3c049610ef188978c25cfdc4
Closes-Bug: 1305186
(cherry picked from commit 78156a7650237bd4875fbbf9cad8db87348f333f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/124918/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/virt/libvirt/fakelibvirt.py']",2,df9ead9af4fbcc3f4b4220c29666fd0addd2b263,bug/1305186," """"""This class was copied and slightly modified from `libvirt-python:libvirt-override.py`. Since a test environment will use the real `libvirt-python` version of `libvirtError` if it's installed and not this fake, we need to maintain strict compatability with the original class, including `__init__` args and instance-attributes. To create a libvirtError instance you should: # Create an unsupported error exception exc = libvirtError('my message') exc.err = (libvirt.VIR_ERR_NO_SUPPORT,) self.err is a tuple of form: (error_code, error_domain, error_message, error_level, str1, str2, str3, int1, int2) Alternatively, you can use the `make_libvirtError` convenience function to allow you to specify these attributes in one shot. """""" def __init__(self, defmsg, conn=None, dom=None, net=None, pool=None, vol=None): Exception.__init__(self, defmsg) self.err = None if self.err is None: return None return self.err[0] if self.err is None: return None return self.err[1] def get_error_message(self): if self.err is None: return None return self.err[2] def get_error_level(self): if self.err is None: return None return self.err[3] def get_str1(self): if self.err is None: return None return self.err[4] def get_str2(self): if self.err is None: return None return self.err[5] def get_str3(self): if self.err is None: return None return self.err[6] def get_int1(self): if self.err is None: return None return self.err[7] def get_int2(self): if self.err is None: return None return self.err[8] raise make_libvirtError( libvirtError, ""Invalid XML."", error_code=VIR_ERR_XML_DETAIL, error_domain=VIR_FROM_DOMAIN) raise make_libvirtError( libvirtError, ""Migration always fails for fake libvirt!"", error_code=VIR_ERR_INTERNAL_ERROR, error_domain=VIR_FROM_QEMU) raise make_libvirtError( libvirtError, ""AFFECT_LIVE only allowed for running domains!"", error_code=VIR_ERR_INTERNAL_ERROR, error_domain=VIR_FROM_QEMU) raise make_libvirtError( libvirtError, ""libvirt error: no connection driver "" ""available for No connection for URI %s"" % uri, error_code=5, error_domain=0) raise make_libvirtError( libvirtError, 'Domain not found: no domain with matching id %d' % id, error_code=VIR_ERR_NO_DOMAIN, error_domain=VIR_FROM_QEMU) raise make_libvirtError( libvirtError, 'Domain not found: no domain with matching name ""%s""' % name, error_code=VIR_ERR_NO_DOMAIN, error_domain=VIR_FROM_QEMU) raise make_libvirtError( libvirtError, ""invalid argument: Invalid cpu number"", error_code=VIR_ERR_INTERNAL_ERROR, error_domain=VIR_FROM_QEMU) raise make_libvirtError( libvirtError, ""no nwfilter with matching name %s"" % name, error_code=VIR_ERR_NO_NWFILTER, error_domain=VIR_FROM_NWFILTER)def make_libvirtError(error_class, msg, error_code=None, error_domain=None, error_message=None, error_level=None, str1=None, str2=None, str3=None, int1=None, int2=None): """"""Convenience function for creating `libvirtError` exceptions which allow you to specify arguments in constructor without having to manipulate the `err` tuple directly. We need to pass in `error_class` to this function because it may be `libvirt.libvirtError` or `fakelibvirt.libvirtError` depending on whether `libvirt-python` is installed. """""" exc = error_class(msg) exc.err = (error_code, error_domain, error_message, error_level, str1, str2, str3, int1, int2) return exc "," def __init__(self, msg, error_code=VIR_ERR_INTERNAL_ERROR, error_domain=VIR_FROM_QEMU): self.error_code = error_code self.error_domain = error_domain Exception(self, msg) return self.error_code return self.error_domain raise libvirtError(""Invalid XML."", VIR_ERR_XML_DETAIL, VIR_FROM_DOMAIN) raise libvirtError(""Migration always fails for fake libvirt!"") raise libvirtError(""AFFECT_LIVE only allowed for running domains!"") raise libvirtError(""libvirt error: no connection driver "" ""available for No connection for URI %s"" % uri, 5, 0) raise libvirtError('Domain not found: no domain with matching ' 'id %d' % id, VIR_ERR_NO_DOMAIN, VIR_FROM_QEMU) raise libvirtError('Domain not found: no domain with matching ' 'name ""%s""' % name, VIR_ERR_NO_DOMAIN, VIR_FROM_QEMU) raise libvirtError(""invalid argument: Invalid cpu number"") raise libvirtError(""no nwfilter with matching name %s"" % name, VIR_ERR_NO_NWFILTER, VIR_FROM_NWFILTER)",124,25
openstack%2Ftempest~master~I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299,openstack/tempest,master,I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299,Drop unused safe_setup decorator,MERGED,2014-09-18 21:17:52.000000000,2014-10-07 13:56:08.000000000,2014-10-07 13:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cfed92290ad8d65e2e176ccc272239335149683', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 2, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/191a2fe640329cb4e922a08201bad87ac1a848cc', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 3, 'created': '2014-10-02 13:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0ddf3007e520ae16111dd244a9b5cff0c326a06e', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 4, 'created': '2014-10-03 18:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6070557f59e630ebc3d6d8c05e241cb70386bcba', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 5, 'created': '2014-10-04 08:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/30a5fbd71a9baf83c41064a475755cbff4fdfacd', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 6, 'created': '2014-10-04 10:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b07a9f687d5d1d875c223684545fdd438e5187b5', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 7, 'created': '2014-10-06 20:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/947c4636f2d30b55813103a939ba4523fad48874', 'message': 'Drop unused safe_setup decorator\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 8, 'created': '2014-10-06 21:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5334558f72b43219797f3d9b56d3695b6abfedcb', 'message': 'Drop unused safe_setup decorator\n\nThe safe_setup decorator was introduced so that tests could\nenforce tearDownClass being called in case of failures during\nthe setUpClass.\n\nWith the implementation of bp resource-cleanup, the test base\nclass automatically provides this facility for all tests,\nso the safe_setup decorator is not needed anymore.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 9, 'created': '2014-10-07 09:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f33fafeefe67f715817fe55b7f255b3b2ec00095', 'message': 'Drop unused safe_setup decorator\n\nThe safe_setup decorator was introduced so that tests could\nenforce tearDownClass being called in case of failures during\nthe setUpClass.\n\nWith the implementation of bp resource-cleanup, the test base\nclass automatically provides this facility for all tests,\nso the safe_setup decorator is not needed anymore.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}, {'number': 10, 'created': '2014-10-07 09:31:35.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c27feb8552dc9203f08992d8c6f0176538f0bf0a', 'message': 'Drop unused safe_setup decorator\n\nThe safe_setup decorator was introduced so that tests could\nenforce tearDownClass being called in case of failures during\nthe setUpClass.\n\nWith the implementation of bp resource-cleanup, the test base\nclass automatically provides this facility for all tests,\nso the safe_setup decorator is not needed anymore.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299\n'}]",0,122531,c27feb8552dc9203f08992d8c6f0176538f0bf0a,37,7,10,1921,,,0,"Drop unused safe_setup decorator

The safe_setup decorator was introduced so that tests could
enforce tearDownClass being called in case of failures during
the setUpClass.

With the implementation of bp resource-cleanup, the test base
class automatically provides this facility for all tests,
so the safe_setup decorator is not needed anymore.

Partially-implements bp resource-cleanup

Change-Id: I3a4f34324420ee3a3ecc9a5e4e33d6ae27f64299
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/122531/9 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,7cfed92290ad8d65e2e176ccc272239335149683,bp/resource-cleanup,,"def safe_setup(f): """"""A decorator used to wrap the setUpClass for cleaning up resources when setUpClass failed. Deprecated, see: http://specs.openstack.org/openstack/qa-specs/specs/resource-cleanup.html """""" @functools.wraps(f) def decorator(cls): try: f(cls) except Exception as se: etype, value, trace = sys.exc_info() if etype is cls.skipException: LOG.info(""setUpClass skipped: %s:"" % se) else: LOG.exception(""setUpClass failed: %s"" % se) try: cls.tearDownClass() except Exception as te: LOG.exception(""tearDownClass failed: %s"" % te) try: raise etype(value), None, trace finally: del trace # for avoiding circular refs return decorator ",0,29
openstack%2Ftooz~master~Iff28ad972fdcec2784a868ae44beef5a2fa20b4e,openstack/tooz,master,Iff28ad972fdcec2784a868ae44beef5a2fa20b4e,Adjust the timeout to reflect the repeated retries,MERGED,2014-10-07 05:51:59.000000000,2014-10-07 13:50:07.000000000,2014-10-07 13:50:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-10-07 05:51:59.000000000', 'files': ['tooz/drivers/ipc.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/6fac8c9819b74f624215a57c3db25670985aad20', 'message': 'Adjust the timeout to reflect the repeated retries\n\nWhen a acquisition retry is triggered the timeout should\nbe adjusted to reflect the prior attempt instead of restarting\nfrom its initial timeout value.\n\nThis makes it so that a acquire() request that ends up spinning\nwith a timeout of say 5 seconds will not repeatly spin for an\ninfinite number of 5 seconds, but instead will actually stop being\nacquired after 5 seconds is reached.\n\nChange-Id: Iff28ad972fdcec2784a868ae44beef5a2fa20b4e\n'}]",0,126469,6fac8c9819b74f624215a57c3db25670985aad20,7,3,1,1297,,,0,"Adjust the timeout to reflect the repeated retries

When a acquisition retry is triggered the timeout should
be adjusted to reflect the prior attempt instead of restarting
from its initial timeout value.

This makes it so that a acquire() request that ends up spinning
with a timeout of say 5 seconds will not repeatly spin for an
infinite number of 5 seconds, but instead will actually stop being
acquired after 5 seconds is reached.

Change-Id: Iff28ad972fdcec2784a868ae44beef5a2fa20b4e
",git fetch https://review.opendev.org/openstack/tooz refs/changes/69/126469/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/ipc.py'],1,6fac8c9819b74f624215a57c3db25670985aad20,,"import time start_time = None start_time = None start_time = time.time() if start_time is not None: elapsed = max(0.0, time.time() - start_time) if elapsed >= timeout: # Ran out of time... return False adjusted_timeout = timeout - elapsed else: adjusted_timeout = timeout try: self._lock.acquire(timeout=adjusted_timeout)", try: self._lock.acquire(timeout=timeout),13,1
openstack%2Ftooz~master~I57e55ab268158e5c36c525b716d225edfacd0863,openstack/tooz,master,I57e55ab268158e5c36c525b716d225edfacd0863,Add home-page field,MERGED,2014-10-06 09:45:53.000000000,2014-10-07 13:48:06.000000000,2014-10-07 13:48:06.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-10-06 09:45:53.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tooz/commit/13c23cffa0c32319d89e7f0715c0cda9c1ad742f', 'message': 'Add home-page field\n\nChange-Id: I57e55ab268158e5c36c525b716d225edfacd0863\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}]",0,126243,13c23cffa0c32319d89e7f0715c0cda9c1ad742f,7,3,1,1669,,,0,"Add home-page field

Change-Id: I57e55ab268158e5c36c525b716d225edfacd0863
Signed-off-by: Julien Danjou <julien@danjou.info>
",git fetch https://review.opendev.org/openstack/tooz refs/changes/43/126243/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,13c23cffa0c32319d89e7f0715c0cda9c1ad742f,jd/url,home-page = https://launchpad.net/python-tooz,,1,0
openstack%2Ftooz~master~If309ff6ea6793546b5aeb3b15b1a2602edf29c85,openstack/tooz,master,If309ff6ea6793546b5aeb3b15b1a2602edf29c85,ipc: do not delete the lock if we never acquired it,MERGED,2014-10-06 09:55:10.000000000,2014-10-07 13:46:17.000000000,2014-10-07 13:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-10-06 09:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/3c3c72b8322bd0501adce230012d8832fada8719', 'message': ""ipc: do not delete the lock if we never acquired it\n\n- process A acquire()\n- process B release() -> delete the lock\n- process B acquire() -> recreate it!\n\nIt's unlikely someone will try to to release before acquiring, but\nbetter be safe than sorry.\n\nChange-Id: If309ff6ea6793546b5aeb3b15b1a2602edf29c85\n""}, {'number': 2, 'created': '2014-10-06 09:58:25.000000000', 'files': ['tooz/drivers/ipc.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/5701d38698b42a392ac06cd3557cffb04fbc6e85', 'message': ""ipc: do not delete the lock if we never acquired it\n\n- process A acquire()\n- process B release() -> delete the lock\n- process B acquire() -> recreate it!\n\nIt's unlikely someone will try to to release before acquiring, but\nbetter be safe than sorry.\n\nChange-Id: If309ff6ea6793546b5aeb3b15b1a2602edf29c85\n""}]",0,126245,5701d38698b42a392ac06cd3557cffb04fbc6e85,8,3,2,1669,,,0,"ipc: do not delete the lock if we never acquired it

- process A acquire()
- process B release() -> delete the lock
- process B acquire() -> recreate it!

It's unlikely someone will try to to release before acquiring, but
better be safe than sorry.

Change-Id: If309ff6ea6793546b5aeb3b15b1a2602edf29c85
",git fetch https://review.opendev.org/openstack/tooz refs/changes/45/126245/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/ipc.py'],1,3c3c72b8322bd0501adce230012d8832fada8719,jd/ipc-release-lock-at-exit, self._lock_acquired = False self._lock_acquired = True if self._lock is not None and self._lock_acquired:, if self._lock is not None:,3,1
openstack%2Fkolla~master~Id18b9f9757306cf3f06e6221a21a9f600db1bd2e,openstack/kolla,master,Id18b9f9757306cf3f06e6221a21a9f600db1bd2e,Validate JSON,MERGED,2014-10-07 08:03:02.000000000,2014-10-07 13:44:21.000000000,2014-10-07 13:44:21.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-07 08:03:02.000000000', 'files': ['docker/mariadb/mariadb.json', 'docker/rabbitmq/rabbitmq.json', 'docker/heat/heat.json', 'docker/swift/swift.json', 'docker/glance/glance.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e35b376994df3794f49afa6dc9a43df9f0d2bff8', 'message': ""Validate JSON\n\nLet's get that quickly so we can add a gate. There was some respacing\nalong the way (used http://jsonlint.com)\n\nChange-Id: Id18b9f9757306cf3f06e6221a21a9f600db1bd2e\n""}]",0,126484,e35b376994df3794f49afa6dc9a43df9f0d2bff8,7,3,1,866,,,0,"Validate JSON

Let's get that quickly so we can add a gate. There was some respacing
along the way (used http://jsonlint.com)

Change-Id: Id18b9f9757306cf3f06e6221a21a9f600db1bd2e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/84/126484/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/mariadb/mariadb.json', 'docker/rabbitmq/rabbitmq.json', 'docker/heat/heat.json', 'docker/swift/swift.json', 'docker/glance/glance.json']",5,e35b376994df3794f49afa6dc9a43df9f0d2bff8,validate-json," ""id"": ""glance"", ""desiredState"": { ""manifest"": { ""version"": ""v1beta1"", ""id"": ""glance-1"", ""containers"": [ { ""name"": ""glance-registry"", ""image"": ""kollaglue/fedora-rdo-glance-registry"", ""ports"": [ { ""containerPort"": 9191 } ], ""env"": [ { ""name"": ""DB_ROOT_PASSWORD"", ""value"": ""password"" }, { ""name"": ""GLANCE_DB_PASSWORD"", ""value"": ""glancedbpassword"" }, { ""name"": ""KEYSTONE_ADMIN_TOKEN"", ""value"": ""ADMINTOKEN"" } ] }, { ""name"": ""glance-api"", ""image"": ""kollaglue/fedora-rdo-glance-api"", ""ports"": [ { ""containerPort"": 9292 } ], ""env"": [ { ""name"": ""DB_ROOT_PASSWORD"", ""value"": ""password"" }, { ""name"": ""GLANCE_DB_PASSWORD"", ""value"": ""glancedbpassword"" }, { ""name"": ""KEYSTONE_ADMIN_TOKEN"", ""value"": ""ADMINTOKEN"" } ] } ] } }, ""labels"": { ""name"": ""glance-master"" }"," ""id"": ""glance"", ""desiredState"": { ""manifest"": { ""version"": ""v1beta1"", ""id"": ""glance-1"", ""containers"": [ { ""name"": ""glance-registry"", ""image"": ""kollaglue/fedora-rdo-glance-registry"", ""ports"": [ {""containerPort"": 9191}, ], ""env"": [ { ""name"": ""DB_ROOT_PASSWORD"", ""value"": ""password"" }, { ""name"": ""GLANCE_DB_PASSWORD"", ""value"": ""glancedbpassword"" }, { ""name"": ""KEYSTONE_ADMIN_TOKEN"", ""value"": ""ADMINTOKEN"" } ] }, { ""name"": ""glance-api"", ""image"": ""kollaglue/fedora-rdo-glance-api"", ""ports"": [ {""containerPort"": 9292} ], ""env"": [ { ""name"": ""DB_ROOT_PASSWORD"", ""value"": ""password"" }, { ""name"": ""GLANCE_DB_PASSWORD"", ""value"": ""glancedbpassword"" }, { ""name"": ""KEYSTONE_ADMIN_TOKEN"", ""value"": ""ADMINTOKEN"" } ] }, ] } }, ""labels"": { ""name"": ""glance-master"" }",242,220
openstack%2Fironic~master~Ic52c49ac6c8631f81eb50b69a5bdb56a113a72b4,openstack/ironic,master,Ic52c49ac6c8631f81eb50b69a5bdb56a113a72b4,Validate the power interface before deployment,MERGED,2014-10-07 11:27:59.000000000,2014-10-07 13:39:54.000000000,2014-10-07 13:39:54.000000000,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-10-07 11:27:59.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ae2f9699e00f4c3ff97ba271a91412e48f9e757f', 'message': 'Validate the power interface before deployment\n\nThis patch makes the do_node_deploy() validate the drivers power interface\nbefore start deploying a node because powering the node on/off is part\nof the deployment.\n\nChange-Id: Ic52c49ac6c8631f81eb50b69a5bdb56a113a72b4\nCloses-Bug: #1378301\n'}]",0,126523,ae2f9699e00f4c3ff97ba271a91412e48f9e757f,8,3,1,6773,,,0,"Validate the power interface before deployment

This patch makes the do_node_deploy() validate the drivers power interface
before start deploying a node because powering the node on/off is part
of the deployment.

Change-Id: Ic52c49ac6c8631f81eb50b69a5bdb56a113a72b4
Closes-Bug: #1378301
",git fetch https://review.opendev.org/openstack/ironic refs/changes/23/126523/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py']",2,ae2f9699e00f4c3ff97ba271a91412e48f9e757f,bug/1378301-validate-power-interface," task.driver.power.validate(task) ""RPC do_node_deploy failed to validate deploy or "" ""power info. Error: %(msg)s"") % {'msg': e})"," ""RPC do_node_deploy failed to validate deploy info. "" ""Error: %(msg)s"") % {'msg': e})",12,4
openstack%2Fironic~master~I8c3574b03903a23c10ef2afcb793c6766a486007,openstack/ironic,master,I8c3574b03903a23c10ef2afcb793c6766a486007,Cleans up some Sphinx rST warnings in Ironic,MERGED,2014-10-01 07:02:53.000000000,2014-10-07 13:31:18.000000000,2014-10-07 13:31:17.000000000,"[{'_account_id': 3}, {'_account_id': 1105}, {'_account_id': 3099}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-10-01 07:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f4840aac0cfa060bbdb028937bea754f83e52d78', 'message': ""Cleans up some Sphinx rST warnings in Ironic\n\nThe astrisk character in rST formated docstrings should be quoted\nwith a backslash, unless it's being used to make emphasis or strong text.\n\nChange-Id: I8c3574b03903a23c10ef2afcb793c6766a486007\nPartial-Bug: 1277282\n""}, {'number': 2, 'created': '2014-10-07 01:28:25.000000000', 'files': ['ironic/api/controllers/v1/types.py', 'ironic/drivers/utils.py', 'ironic/drivers/base.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/conductor/task_manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/56fed1198fd42953f827521748c6be475d9f4fa4', 'message': 'Cleans up some Sphinx rST warnings in Ironic\n\nThe names of parameters in docstrings should not have leading astrisk\ncharacters, because it confuses the rST parser.\n\nChange-Id: I8c3574b03903a23c10ef2afcb793c6766a486007\nPartial-Bug: 1277282\n'}]",0,125273,56fed1198fd42953f827521748c6be475d9f4fa4,19,7,2,1105,,,0,"Cleans up some Sphinx rST warnings in Ironic

The names of parameters in docstrings should not have leading astrisk
characters, because it confuses the rST parser.

Change-Id: I8c3574b03903a23c10ef2afcb793c6766a486007
Partial-Bug: 1277282
",git fetch https://review.opendev.org/openstack/ironic refs/changes/73/125273/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/types.py', 'ironic/drivers/utils.py', 'ironic/drivers/base.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/conductor/task_manager.py']",5,f4840aac0cfa060bbdb028937bea754f83e52d78,bug/1277282, :param \*args: additional args passed to the callable object. :param \*\*kwargs: additional kwargs passed to the callable object., :param *args: additional args passed to the callable object. :param **kwargs: additional kwargs passed to the callable object.,8,8
openstack%2Fbarbican~master~I4d51142a872abc86b29420d806538512f47eade2,openstack/barbican,master,I4d51142a872abc86b29420d806538512f47eade2,Use canonical cover name for coverage,MERGED,2014-10-01 14:40:34.000000000,2014-10-07 13:29:16.000000000,2014-10-07 13:29:16.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-01 14:40:34.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c429be7caf19845b8d9418719e8696c602d7c44c', 'message': 'Use canonical cover name for coverage\n\nThe OpenStack infra jobs expect a tox environement called\n""cover"" for coverage, fix tox.ini for it.\n\nChange-Id: I4d51142a872abc86b29420d806538512f47eade2\n'}]",0,125362,c429be7caf19845b8d9418719e8696c602d7c44c,10,6,1,6547,,,0,"Use canonical cover name for coverage

The OpenStack infra jobs expect a tox environement called
""cover"" for coverage, fix tox.ini for it.

Change-Id: I4d51142a872abc86b29420d806538512f47eade2
",git fetch https://review.opendev.org/openstack/barbican refs/changes/62/125362/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c429be7caf19845b8d9418719e8696c602d7c44c,fix-coverage,[testenv:cover],[testenv:coverage],1,1
openstack%2Fproject-config~master~I9e67f51e765b17ce650c9a7dcb9aac8c83a9002e,openstack/project-config,master,I9e67f51e765b17ce650c9a7dcb9aac8c83a9002e,Add Kolla PEP8 job,MERGED,2014-10-07 08:03:39.000000000,2014-10-07 13:28:02.000000000,2014-10-07 13:28:02.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 08:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/30d7e6eff997c7b47c9f468082fed155b1084c82', 'message': 'Add Kolla PEP8 job\n\nChange-Id: I9e67f51e765b17ce650c9a7dcb9aac8c83a9002e\n'}, {'number': 2, 'created': '2014-10-07 08:56:20.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cdcf4515ab574b02c904c427e9f6e1676af30512', 'message': 'Add Kolla PEP8 job\n\nChange-Id: I9e67f51e765b17ce650c9a7dcb9aac8c83a9002e\n'}]",0,126485,cdcf4515ab574b02c904c427e9f6e1676af30512,11,4,2,866,,,0,"Add Kolla PEP8 job

Change-Id: I9e67f51e765b17ce650c9a7dcb9aac8c83a9002e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/126485/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,30d7e6eff997c7b47c9f468082fed155b1084c82,add-kolla-pep8, - gate-kolla-pep8,,1,0
openstack%2Ffuel-web~master~Ibf1660624d3441c249b319fa69eb3775c9716b9c,openstack/fuel-web,master,Ibf1660624d3441c249b319fa69eb3775c9716b9c,Revoke token from keystone after user logout,MERGED,2014-10-03 11:23:11.000000000,2014-10-07 13:16:15.000000000,2014-10-07 13:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-10-03 11:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c03b6054c91f10ee24ab99baabcc1fea79b31025', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 2, 'created': '2014-10-03 14:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/eda4a6503d5e21113cc0ba3d7dc81a5edb16ff09', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 3, 'created': '2014-10-06 06:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/21503fbe81da7192be04bdbd61db39b37e60c252', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 4, 'created': '2014-10-06 08:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd62e1f42c013770a0d276a7db72d8ff2460f545', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 5, 'created': '2014-10-06 10:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c17d53fe293d3c9b13c2cfb92506347a042a044d', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 6, 'created': '2014-10-06 11:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1ceac34bdf959cbb0fab538a4e1b2804e132702a', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 7, 'created': '2014-10-06 11:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c3393d21a767ea8c3522a50fd2a56c17a9bb53d4', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 8, 'created': '2014-10-06 13:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4dcacc51301e7d47785e76a71c05d4975bbd02e2', 'message': 'Revoke token from keystone after user logout\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}, {'number': 9, 'created': '2014-10-07 11:34:34.000000000', 'files': ['nailgun/ui_tests/test_login_logout.js', 'nailgun/static/js/keystone_client.js', 'nailgun/static/js/app.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1b8b0f92448c7d630eed0ff69146e7befc772fc2', 'message': 'Revoke token from keystone after user logout\n\nAlso, add test_login_logout.js\n\nChange-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c\nCloses-Bug: #1375622\n'}]",7,125933,1b8b0f92448c7d630eed0ff69146e7befc772fc2,60,7,9,13445,,,0,"Revoke token from keystone after user logout

Also, add test_login_logout.js

Change-Id: Ibf1660624d3441c249b319fa69eb3775c9716b9c
Closes-Bug: #1375622
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/33/125933/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/ui_tests/test_login_logout.js', 'nailgun/static/js/keystone_client.js', 'nailgun/static/js/app.js']",3,c03b6054c91f10ee24ab99baabcc1fea79b31025,bug/1375622," var defer; if(!this.user) { defer = $.Deferred().resolve(); } else if (this.version.get('auth_required') && this.user.get('authenticated')) { defer = this.keystoneClient.deauthenticate().always(_.bind(function() { this.user.set('authenticated', false); this.user.unset('username'); this.user.unset('password'); }, this)); } else { defer = $.Deferred().resolve(); } defer.always(function() {"," if (this.version.get('auth_required') && this.user.get('authenticated')) { this.user.set('authenticated', false); this.user.unset('username'); this.user.unset('password'); delete app.keystoneClient.userId; delete app.keystoneClient.username; delete app.keystoneClient.password; delete app.keystoneClient.token; delete app.keystoneClient.tokenUpdateTime; } _.defer(function() {",104,10
openstack%2Fproject-config~master~I8833c2421ff28454134854dd8570743f5b33248e,openstack/project-config,master,I8833c2421ff28454134854dd8570743f5b33248e,Enable Keystone extensions for OSC functional jobs,MERGED,2014-10-06 18:23:47.000000000,2014-10-07 13:09:48.000000000,2014-10-07 13:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-06 18:23:47.000000000', 'files': ['jenkins/jobs/osc-functional.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a05cf62abb7129dcc96310e887eaa7a57b2adbd2', 'message': ""Enable Keystone extensions for OSC functional jobs\n\nDevstack already has code to setup extensions for Keystone;\nOpenStackClient has command support for these extensions.\nLet's enable these extensions in DevStack before firing it up,\nso we can add functional tests for them.\n\nChange-Id: I8833c2421ff28454134854dd8570743f5b33248e\n""}]",0,126380,a05cf62abb7129dcc96310e887eaa7a57b2adbd2,8,3,1,6482,,,0,"Enable Keystone extensions for OSC functional jobs

Devstack already has code to setup extensions for Keystone;
OpenStackClient has command support for these extensions.
Let's enable these extensions in DevStack before firing it up,
so we can add functional tests for them.

Change-Id: I8833c2421ff28454134854dd8570743f5b33248e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/126380/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/osc-functional.yaml'],1,a05cf62abb7129dcc96310e887eaa7a57b2adbd2,add_extensions," export KEYSTONE_EXTENSIONS=oauth1,federation",,1,0
openstack%2Fproject-config~master~I36fd522261363494f07b57e40f0d9b943cf08841,openstack/project-config,master,I36fd522261363494f07b57e40f0d9b943cf08841,Add check for ordering of jenkins/jobs/projects.yaml,MERGED,2014-10-03 17:55:41.000000000,2014-10-07 13:09:41.000000000,2014-10-07 13:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-10-03 17:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/285ef1286b8ee89f71e372c3d8aeaaa133c4cdf7', 'message': ""Add check for ordering of jenkins/jobs/projects.yaml\n\nExample output of test:\n$ tools/jenkins-projects-checks.py\nChecking section 'OpenStack server projects'\nChecking section 'OpenStack client projects'\nChecking section 'oslo libraries'\nChecking section 'Other OpenStack projects'\n  Wrong alphabetical order: tempest, qa-specs\nChecking section 'OpenStack API projects'\nChecking section 'OpenStack documentation projects'\nChecking section 'OpenStack development projects'\nChecking section 'OpenStack infrastructure projects'\nChecking section 'Stackforge projects'\nFound errors in jenkins/jobs/projects.yaml!\n\nThis patch fixes the order so that it passes and enables the check.\n\nChange-Id: I36fd522261363494f07b57e40f0d9b943cf08841\n""}, {'number': 2, 'created': '2014-10-03 19:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3c88f8693f0e6167c6ce0e945c82c4b1c47e1265', 'message': ""Add check for ordering of jenkins/jobs/projects.yaml\n\nExample output of test:\n$ tools/jenkins-projects-checks.py\nChecking section 'OpenStack server projects'\nChecking section 'OpenStack client projects'\nChecking section 'oslo libraries'\nChecking section 'Other OpenStack projects'\n  Wrong alphabetical order: tempest, qa-specs\nChecking section 'OpenStack API projects'\nChecking section 'OpenStack documentation projects'\nChecking section 'OpenStack development projects'\nChecking section 'OpenStack infrastructure projects'\nChecking section 'Stackforge projects'\nFound errors in jenkins/jobs/projects.yaml!\n\nThis patch fixes the order so that it passes.\nIt also creates a new job to test this.\n\nChange-Id: I36fd522261363494f07b57e40f0d9b943cf08841\n""}, {'number': 3, 'created': '2014-10-06 20:18:32.000000000', 'files': ['jenkins/jobs/infra.yaml', 'tools/jenkins-projects-checks.py', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9836ea535723f5387b50a97921c75482a77e7110', 'message': ""Add check for ordering of jenkins/jobs/projects.yaml\n\nExample output of test:\n$ tools/jenkins-projects-checks.py\nChecking section 'OpenStack server projects'\nChecking section 'OpenStack client projects'\nChecking section 'oslo libraries'\nChecking section 'Other OpenStack projects'\n  Wrong alphabetical order: tempest, qa-specs\nChecking section 'OpenStack API projects'\nChecking section 'OpenStack documentation projects'\nChecking section 'OpenStack development projects'\nChecking section 'OpenStack infrastructure projects'\nChecking section 'Stackforge projects'\nFound errors in jenkins/jobs/projects.yaml!\n\nThis patch fixes the order so that it passes.\nIt also creates a new job to test this.\n\nChange-Id: I36fd522261363494f07b57e40f0d9b943cf08841\n""}]",2,126026,9836ea535723f5387b50a97921c75482a77e7110,16,7,3,6547,,,0,"Add check for ordering of jenkins/jobs/projects.yaml

Example output of test:
$ tools/jenkins-projects-checks.py
Checking section 'OpenStack server projects'
Checking section 'OpenStack client projects'
Checking section 'oslo libraries'
Checking section 'Other OpenStack projects'
  Wrong alphabetical order: tempest, qa-specs
Checking section 'OpenStack API projects'
Checking section 'OpenStack documentation projects'
Checking section 'OpenStack development projects'
Checking section 'OpenStack infrastructure projects'
Checking section 'Stackforge projects'
Found errors in jenkins/jobs/projects.yaml!

This patch fixes the order so that it passes.
It also creates a new job to test this.

Change-Id: I36fd522261363494f07b57e40f0d9b943cf08841
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/126026/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/jenkins-projects-checks.py', 'jenkins/jobs/projects.yaml', 'tox.ini']",3,285ef1286b8ee89f71e372c3d8aeaaa133c4cdf7,sort-projects.yaml, {toxinidir}/tools/jenkins-projects-checks.py,,65,7
openstack%2Fproject-config~master~Idae1fd13a7db1d2ff2bdbf59c2f17f8af73fc8e6,openstack/project-config,master,Idae1fd13a7db1d2ff2bdbf59c2f17f8af73fc8e6,Delete delete-project-gerrit-plugin jobs,MERGED,2014-10-02 13:39:11.000000000,2014-10-07 13:09:22.000000000,2014-10-07 13:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-02 13:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/89e64e748fa6f4bc41a1e7ce2353249b83c98af0', 'message': 'Delete delete-project-gerrit-plugin jobs\n\nThis is not used at all, thus remove it from our queues.\n\nChange-Id: Idae1fd13a7db1d2ff2bdbf59c2f17f8af73fc8e6\nNote: this currently fails in the periodic queue.\n'}, {'number': 2, 'created': '2014-10-03 18:58:23.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1fa03ddd69fbee5e3268afd60a612cd7d195b6ee', 'message': 'Delete delete-project-gerrit-plugin jobs\n\nThis is not used at all, thus remove it from our queues.\n\nChange-Id: Idae1fd13a7db1d2ff2bdbf59c2f17f8af73fc8e6\nNote: this currently fails in the periodic queue.\n'}]",0,125636,1fa03ddd69fbee5e3268afd60a612cd7d195b6ee,14,6,2,6547,,,0,"Delete delete-project-gerrit-plugin jobs

This is not used at all, thus remove it from our queues.

Change-Id: Idae1fd13a7db1d2ff2bdbf59c2f17f8af73fc8e6
Note: this currently fails in the periodic queue.
",git fetch https://review.opendev.org/openstack/project-config refs/changes/36/125636/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,89e64e748fa6f4bc41a1e7ce2353249b83c98af0,drop-periodic-gerrit-plugin-delete-project,, - periodic-gerrit-plugin-delete-project-gerrit-plugin,0,14
openstack%2Foslo.db~master~Id73d7afb7ba8142422b3102b43522940bf818a99,openstack/oslo.db,master,Id73d7afb7ba8142422b3102b43522940bf818a99,Support building wheels (PEP-427),ABANDONED,2014-10-02 20:19:36.000000000,2014-10-07 12:59:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-10-02 20:19:36.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/10d53a679a116e4f63e3dd382fd463278822b07d', 'message': 'Support building wheels (PEP-427)\n\nUniversal is used to identify pure-Python module(by bdist_wheel). For\nthese, it is sufficient to build a wheel with _any_ Python ABI version\nand publish that to PyPI (by whatever means).\n\nChange-Id: Id73d7afb7ba8142422b3102b43522940bf818a99\n'}]",1,125762,10d53a679a116e4f63e3dd382fd463278822b07d,5,3,1,5638,,,0,"Support building wheels (PEP-427)

Universal is used to identify pure-Python module(by bdist_wheel). For
these, it is sufficient to build a wheel with _any_ Python ABI version
and publish that to PyPI (by whatever means).

Change-Id: Id73d7afb7ba8142422b3102b43522940bf818a99
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/62/125762/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,10d53a679a116e4f63e3dd382fd463278822b07d,, [wheel] universal = 1,,3,0
openstack%2Foslo.config~master~If7abf6bbf7eaf8a152f57d19dba071f125c4686f,openstack/oslo.config,master,If7abf6bbf7eaf8a152f57d19dba071f125c4686f,Add history/changelog to docs,ABANDONED,2014-09-10 13:52:56.000000000,2014-10-07 12:56:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-09-10 13:52:56.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/486e83c3955cbbfcfa796d5ca463aafdd972d066', 'message': 'Add history/changelog to docs\n\nChange-Id: If7abf6bbf7eaf8a152f57d19dba071f125c4686f\n'}]",1,120419,486e83c3955cbbfcfa796d5ca463aafdd972d066,7,3,1,5638,,,0,"Add history/changelog to docs

Change-Id: If7abf6bbf7eaf8a152f57d19dba071f125c4686f
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/19/120419/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,486e83c3955cbbfcfa796d5ca463aafdd972d066,,.. include:: ../../ChangeLog ,,2,0
openstack%2Foslo.messaging~master~Ib44640570017651da1326d4843c53d808d44c3af,openstack/oslo.messaging,master,Ib44640570017651da1326d4843c53d808d44c3af,Add history/changelog to docs,ABANDONED,2014-09-10 13:54:32.000000000,2014-10-07 12:52:11.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-09-10 13:54:32.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b6302ecf0e00618130ceae60edcefdf11b77e93f', 'message': 'Add history/changelog to docs\n\nChange-Id: Ib44640570017651da1326d4843c53d808d44c3af\n'}]",2,120421,b6302ecf0e00618130ceae60edcefdf11b77e93f,6,4,1,5638,,,0,"Add history/changelog to docs

Change-Id: Ib44640570017651da1326d4843c53d808d44c3af
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/21/120421/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,b6302ecf0e00618130ceae60edcefdf11b77e93f,,.. include:: ../../ChangeLog ,,2,0
openstack%2Ftrove~master~Idd89d151c2ee3945108cb58b1544587fcb47cece,openstack/trove,master,Idd89d151c2ee3945108cb58b1544587fcb47cece,Add support to detect SUSE,MERGED,2014-07-21 14:57:57.000000000,2014-10-07 12:44:39.000000000,2014-10-07 12:44:39.000000000,"[{'_account_id': 3}, {'_account_id': 2340}, {'_account_id': 2424}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9750}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-07-21 14:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f0bf863dc513c9c191374b370210af2e0068438a', 'message': 'Add support to detect SUSE\n\nThis patch extends `get_os()` to check /etc/SuSE-release and report the\noperative system is SUSE.\n\nChange-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece\n'}, {'number': 2, 'created': '2014-08-07 16:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d80fc5964ebba21770541240f4916b31b84ab4ab', 'message': 'Add support to detect SUSE\n\nThis patch extends `get_os()` to check /etc/SuSE-release and report the\noperative system is SUSE.\n\nChange-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece\n'}, {'number': 3, 'created': '2014-08-14 16:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d879672c630a02a88923644a44b329977c0b1d01', 'message': 'Add support to detect SUSE\n\nThis patch extends `get_os()` to check /etc/SuSE-release and report the\noperative system is SUSE.\n\nChange-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece\n'}, {'number': 4, 'created': '2014-09-11 08:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7a9733d3b9cee2ab806704d04473a85ff92d371a', 'message': 'Add support to detect SUSE\n\nThis patch extends `get_os()` to check /etc/SuSE-release and report the\noperative system is SUSE.\n\nblueprint: suse-support\n\nChange-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece\n'}, {'number': 5, 'created': '2014-09-11 08:58:53.000000000', 'files': ['trove/guestagent/common/operating_system.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/67c6228255406ab048e1356be2f8433288964edf', 'message': 'Add support to detect SUSE\n\nThis patch extends `get_os()` to check /etc/SuSE-release and report the\noperative system is SUSE.\n\nblueprint: suse-support\n\nChange-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece\n'}]",1,108394,67c6228255406ab048e1356be2f8433288964edf,54,12,5,2424,,,0,"Add support to detect SUSE

This patch extends `get_os()` to check /etc/SuSE-release and report the
operative system is SUSE.

blueprint: suse-support

Change-Id: Idd89d151c2ee3945108cb58b1544587fcb47cece
",git fetch https://review.opendev.org/openstack/trove refs/changes/94/108394/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/common/operating_system.py'],1,f0bf863dc513c9c191374b370210af2e0068438a,bp/suse-support,"SUSE = 'suse' elif os.path.isfile(""/etc/SuSE-release""): return SUSE",,3,0
openstack%2Fproject-config~master~Iae6e25668f8f858d4ee3af7fe0dbd61a04674627,openstack/project-config,master,Iae6e25668f8f858d4ee3af7fe0dbd61a04674627,Add post docs job for os-cloud-config,MERGED,2014-10-07 05:09:54.000000000,2014-10-07 12:36:32.000000000,2014-10-07 12:36:31.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 05:09:54.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/73b6192d16ee7093efcc530b99aa8bb5179c4248', 'message': ""Add post docs job for os-cloud-config\n\nIt turns out when I71045243e35045483c3c8163f12f7ae6238d00f4 landed,\nos-cloud-config no longer ran docs jobs during 'post', which I\nthought was okay, since the 'gate' docs job would publish them. It\nturns out it does not, so add it back.\n\nChange-Id: Iae6e25668f8f858d4ee3af7fe0dbd61a04674627\n""}]",0,126467,73b6192d16ee7093efcc530b99aa8bb5179c4248,7,3,1,9369,,,0,"Add post docs job for os-cloud-config

It turns out when I71045243e35045483c3c8163f12f7ae6238d00f4 landed,
os-cloud-config no longer ran docs jobs during 'post', which I
thought was okay, since the 'gate' docs job would publish them. It
turns out it does not, so add it back.

Change-Id: Iae6e25668f8f858d4ee3af7fe0dbd61a04674627
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/126467/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,73b6192d16ee7093efcc530b99aa8bb5179c4248,post-docs-job-os-c-c, - os-cloud-config-docs,,1,0
openstack%2Ftraining-guides~master~Icec21b82cd788bdebbde342e34e9ccb2c98c00c0,openstack/training-guides,master,Icec21b82cd788bdebbde342e34e9ccb2c98c00c0,Added reference to programs.yaml file and wiki pages,MERGED,2014-10-06 19:32:27.000000000,2014-10-07 12:23:41.000000000,2014-10-07 12:23:40.000000000,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 7007}, {'_account_id': 9178}]","[{'number': 1, 'created': '2014-10-06 19:32:27.000000000', 'files': ['doc/upstream-training/03-technical-committee.rst', 'doc/upstream-training/theme/css/screen.css'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2f8db11624f974e06b42ee63e3728a9d1ed8e1cb', 'message': 'Added reference to programs.yaml file and wiki pages\n\nFixed small css issue where anchors wrapping would look weird\n\nChange-Id: Icec21b82cd788bdebbde342e34e9ccb2c98c00c0\n'}]",0,126400,2f8db11624f974e06b42ee63e3728a9d1ed8e1cb,8,4,1,287,,,0,"Added reference to programs.yaml file and wiki pages

Fixed small css issue where anchors wrapping would look weird

Change-Id: Icec21b82cd788bdebbde342e34e9ccb2c98c00c0
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/00/126400/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/upstream-training/03-technical-committee.rst', 'doc/upstream-training/theme/css/screen.css']",2,2f8db11624f974e06b42ee63e3728a9d1ed8e1cb,programs.yaml, text-decoration: underline;, text-decoration: none; border-bottom: 2px solid #3f3f3f;,5,2
openstack%2Fzaqar~master~I8c5e39e09352ba13b3fe2bf2d04a1dac93ac6509,openstack/zaqar,master,I8c5e39e09352ba13b3fe2bf2d04a1dac93ac6509,Move the module reference to the top,MERGED,2014-10-03 09:46:24.000000000,2014-10-07 12:12:17.000000000,2014-10-07 12:12:16.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}]","[{'number': 1, 'created': '2014-10-03 09:46:24.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4ef3b28f92a3428a800c0cd1cabdab5ef0b01438', 'message': 'Move the module reference to the top\n\nInstead of having to scroll down to the bottom to read the module\nreference, it\'d be better to make it available for developers before\nthey get into the ""how contribute section"". This way, we can keep zaqar\nand openstack sections grouped respectively.\n\nChange-Id: I8c5e39e09352ba13b3fe2bf2d04a1dac93ac6509\n'}]",0,125918,4ef3b28f92a3428a800c0cd1cabdab5ef0b01438,7,3,1,6159,,,0,"Move the module reference to the top

Instead of having to scroll down to the bottom to read the module
reference, it'd be better to make it available for developers before
they get into the ""how contribute section"". This way, we can keep zaqar
and openstack sections grouped respectively.

Change-Id: I8c5e39e09352ba13b3fe2bf2d04a1dac93ac6509
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/18/125918/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,4ef3b28f92a3428a800c0cd1cabdab5ef0b01438,,"Modules reference ================= Zaqar is composed of two layers: .. toctree:: :maxdepth: 1 transport storage The **transport drivers** are responsible for interacting with Zaqar clients. Every query made by clients is processed by the transport layer, which is in charge of passing this information to the backend and then returning the response in a format understandable by the client. The **storage drivers** are responsible for interacting with the storage backends and, that way, store or retrieve the data coming from the transport layer. In order to keep these layers decoupled, we have established that **checks should be performed in the appropriate layer**. In other words, transport drivers must guarantee that the incoming data is well-formed and storage drivers must enforce their data model stays consistent. ","Modules reference ================= Zaqar is composed of two layers: .. toctree:: :maxdepth: 1 transport storage The **transport drivers** are responsible for interacting with Zaqar clients. Every query made by clients is processed by the transport layer, which is in charge of passing this information to the backend and then returning the response in a format understandable by the client. The **storage drivers** are responsible for interacting with the storage backends and, that way, store or retrieve the data coming from the transport layer. In order to keep these layers decoupled, we have established that **checks should be performed in the appropriate layer**. In other words, transport drivers must guarantee that the incoming data is well-formed and storage drivers must enforce their data model stays consistent. ",24,24
openstack%2Fmurano-dashboard~proposed%2Fjuno~I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4,openstack/murano-dashboard,proposed/juno,I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4,Remove font-awesome resources from muranodashboard/static,MERGED,2014-10-07 09:26:52.000000000,2014-10-07 11:58:20.000000000,2014-10-07 11:58:19.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-07 09:26:52.000000000', 'files': ['muranodashboard/static/muranodashboard/fonts/FontAwesome.otf', 'muranodashboard/static/muranodashboard/css/font-awesome.min.css', 'muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.eot', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.woff', 'muranodashboard/templates/catalog/app_details.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.svg', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.ttf'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5057fafb1ce7820d94d0b610aac070aed24becc4', 'message': 'Remove font-awesome resources from muranodashboard/static\n\n... because horizon packages them as xstatic package, muranodashboard\ncan get them as horizon static resources, no need to keep a separate\ncopy of them.\n\nChange-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4\n'}]",0,126497,5057fafb1ce7820d94d0b610aac070aed24becc4,9,4,1,8040,,,0,"Remove font-awesome resources from muranodashboard/static

... because horizon packages them as xstatic package, muranodashboard
can get them as horizon static resources, no need to keep a separate
copy of them.

Change-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/97/126497/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/static/muranodashboard/fonts/FontAwesome.otf', 'muranodashboard/static/muranodashboard/css/font-awesome.min.css', 'muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.eot', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.woff', 'muranodashboard/templates/catalog/app_details.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.svg', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.ttf']",8,5057fafb1ce7820d94d0b610aac070aed24becc4,,,,2,420
openstack%2Ffuel-library~stable%2F5.0~I6979d9b54c1e9fed2f1629ebc1edc741f2136b56,openstack/fuel-library,stable/5.0,I6979d9b54c1e9fed2f1629ebc1edc741f2136b56,Fix '/etc/init.d/supervisord status',ABANDONED,2014-08-14 12:16:51.000000000,2014-10-07 11:53:51.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-14 12:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/18272cbd9cf98a59a4f6004d720be6708a659a27', 'message': 'Fix \'/etc/init.d/supervisord status\'\n\n""service supervisord status"" reports wrong status (servise is up)\neven when supervisor is down. It uses ""supervisorctl status"" which\nreturns exit code ""0"" when supervisor is down. We\'re adding\nadditional check for status() function to fix this.\n\nCloses-bug: #1356805\n\nChange-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56\n'}, {'number': 2, 'created': '2014-08-14 13:19:21.000000000', 'files': ['deployment/puppet/nailgun/files/supervisor-init'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f5d9d50eec8108e7e7f5b0e73d0f47c55bec0d6', 'message': 'Fix \'/etc/init.d/supervisord status\'\n\n""service supervisord status"" reports wrong status (servise is up)\neven when supervisor is down. It uses ""supervisorctl status"" which\nreturns exit code ""0"" when supervisor is down. We\'re adding\nadditional check for status() function to fix this.\n\nCloses-bug: #1356805\n\nChange-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56\n'}]",0,114219,9f5d9d50eec8108e7e7f5b0e73d0f47c55bec0d6,21,6,2,9387,,,0,"Fix '/etc/init.d/supervisord status'

""service supervisord status"" reports wrong status (servise is up)
even when supervisor is down. It uses ""supervisorctl status"" which
returns exit code ""0"" when supervisor is down. We're adding
additional check for status() function to fix this.

Closes-bug: #1356805

Change-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/19/114219/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/files/supervisor-init'],1,18272cbd9cf98a59a4f6004d720be6708a659a27,, /usr/bin/supervisorctl status && ps -p `cat /var/run/supervisord.pid` &>/dev/null, /usr/bin/supervisorctl status,1,1
openstack%2Fopenstack-manuals~master~I2d3ca22316fb8191ddb3c926211deb00be51e322,openstack/openstack-manuals,master,I2d3ca22316fb8191ddb3c926211deb00be51e322,Installation Guide improvements- cinder node section,MERGED,2014-09-10 07:37:54.000000000,2014-10-07 11:52:47.000000000,2014-10-07 11:52:46.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 9515}, {'_account_id': 10705}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-09-10 07:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/22fd92ec4ee4ba729a98b7eeff6eba7656a86127', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 2, 'created': '2014-09-12 05:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fda2f8ef9839adc80a893902c6f2741cd6dbd1fd', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 3, 'created': '2014-09-15 06:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/90c2d8aa41c1be37c373b6fe240c3cf729b0474e', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 4, 'created': '2014-09-15 10:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f721db72db9403cce12e05628c3074c71733468d', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 5, 'created': '2014-09-18 02:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8b1ce97ef24b72266b05a1667e0014eac4477d18', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 6, 'created': '2014-09-19 00:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/894aa948e84b8f959518362d7262124d64146d5f', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 7, 'created': '2014-09-30 01:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b25723d6f7927065cd2c6219f1eb54c305cfa3dd', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 8, 'created': '2014-09-30 04:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/92bf4e76f0a6329787b911c251b2a7bf56bb2d32', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 9, 'created': '2014-09-30 04:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5a7b8c97e19052b293bfab66dc5b99744c205871', 'message': 'Improve Installation Guide - celiometer service node\n\nReordered instructions in the celiometer service node section\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 10, 'created': '2014-10-02 02:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/090720d8e2231c0334201fc1b4d91ff6be7cd37f', 'message': 'Installation Guide improvements- cinder node section\n\n1. Reordered instructions in the cinder node section\n2. Removed openstack-config commands\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 11, 'created': '2014-10-07 00:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/009e3ce95642637a43a7c617387ab7f282dad663', 'message': 'Installation Guide improvements- cinder node section\n\n1. Reordered instructions in the cinder node section\n2. Removed openstack-config commands\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}, {'number': 12, 'created': '2014-10-07 04:06:45.000000000', 'files': ['doc/install-guide/section_cinder-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6508a4827b23ed062c72291f58f265403d0bc242', 'message': 'Installation Guide improvements- cinder node section\n\n1. Reordered instructions in the cinder node section\n2. Removed openstack-config commands\n\nChange-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322\nImplements: blueprint installation-guide-improvements\n'}]",21,120332,6508a4827b23ed062c72291f58f265403d0bc242,44,7,12,10705,,,0,"Installation Guide improvements- cinder node section

1. Reordered instructions in the cinder node section
2. Removed openstack-config commands

Change-Id: I2d3ca22316fb8191ddb3c926211deb00be51e322
Implements: blueprint installation-guide-improvements
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/120332/10 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_cinder-node.xml'],1,22fd92ec4ee4ba729a98b7eeff6eba7656a86127,bp/installation-guide-improvements," configure a Block Storage service node, which contains the disk that serves volumes.</para> This procedure uses LVM as an example.</para> <title>To configure the operating system</title> /> to synchronize the time from the controller node.</para> </procedure> <procedure> <title>To create a LVM</title> <para>Create a LVM</para> <para>Install the LVM packages:</para> assumes a second disk <literal>/dev/sdb</literal> is being used <para>In the <literal>devices</literal> section in the <filename>/etc/lvm/lvm.conf</filename> file, add a filter entry to prevent LVM from scanning devices used by virtual </step> </procedure> <procedure> <title>Install and configure Block Storage service node components</title> <para>Install the packages for the Block Storage service:</para> <screen os=""debian;ubuntu""><prompt>#</prompt> <userinput>apt-get install cinder-volume</userinput></screen> <screen os=""centos;fedora;rhel""><prompt>#</prompt> <userinput>yum install openstack-cinder-volume targetcli</userinput></screen> <step os=""centos;fedora;rhel""> <para>Start the target service:</para> <screen><prompt>#</prompt> <userinput>service target start</userinput></screen> </step> <step os=""centos;fedora;rhel""> <para>Enable the target service:</para> <screen><prompt>#</prompt> <userinput>chkconfig target on</userinput></screen> <step os=""centos;fedora;rhel;opensuse;sles""> <para >Copy the <screen os=""centos;fedora;rhel;opensuse;sles""><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf DEFAULT \ </step> <step> <para>Edit the file, and complete the following actions:</para> <substeps> <step os=""ubuntu""> <para>Add this section for keystone credentials:</para> <programlisting language=""ini"">... <para>In the <literal>[DEFAULT]</literal> section, configure RabbitMQ message broker access:</para> ... rpc_backend = rabbit rabbit_host = <replaceable>controller</replaceable> rabbit_port = 5672 rabbit_userid = guest rabbit_password = <replaceable>RABBIT_PASS</replaceable></programlisting> <para>Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for the <literal>guest</literal> account in RabbitMQ.</para> <step os=""centos;fedora;opensuse;rhel;sles""> broker:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rpc_backend rabbit</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_host <replaceable>controller</replaceable></userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_port 5672</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_password <replaceable>RABBIT_PASS</replaceable></userinput></screen> <para>Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for RabbitMQ:</para> </step> <step os=""centos;fedora;opensuse;rhel;sles;ubuntu""> <para>Configure Block Storage to use your MySQL database, by adding the following key to the <literal>[database]</literal>section:</para> <screen os=""centos;fedora;opensuse;rhel;sles""><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ database connection mysql://cinder:<replaceable>CINDER_DBPASS</replaceable>@<replaceable>controller</replaceable>/cinder</userinput></screen> ... connection = mysql://cinder:<replaceable>CINDER_DBPASS</replaceable>@<replaceable>controller</replaceable>/cinder</programlisting> <para>Replace <replaceable>CINDER_DBPASS</replaceable> with the password you chose for the Block Storage database.</para> <para>In some distributions, the <filename>/etc/cinder/cinder.conf</filename> file does not include the <literal>[database]</literal> section header. You must add this section header to the end of the file <para>In the <literal>[DEFAULT]</literal> section, configure Block Storage to use the Image Service by updating the <option>glance_host</option> option:</para> DEFAULT glance_host <replaceable>controller</replaceable></userinput></screen> <programlisting os=""debian;ubuntu"" language=""ini"">[DEFAULT] ... glance_host = <replaceable>controller</replaceable></programlisting> <step os=""centos;fedora;rhel""> <para>Configure Block Storage to use the lioadm iscsi_helper:</para> <screen os=""centos;fedora;rhel""> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT iscsi_helper lioadm</userinput></screen> </step> </substeps> </step> </procedure> <procedure> <title>To finalize installation</title> <step os=""ubuntu""> <para>By default, the Ubuntu packages create an SQLite database. Because this configuration uses a SQL database server, remove the SQLite database file:</para> <screen><prompt>#</prompt> <userinput>rm -f /var/lib/cinder/cinder.sqlite</userinput></screen> </step>"," configure a second system to be a Block Storage service node. This node contains the disk that serves volumes.</para> This example uses LVM.</para> /> to synchronize from the controller node.</para> <para>Install the required LVM packages, if they are not already installed:</para> assumes a second disk <literal>/dev/sdb</literal> that is used <para>Add a filter entry to the <literal>devices</literal> section in the <filename>/etc/lvm/lvm.conf</filename> file to keep LVM from scanning devices used by virtual </step> <para>After you configure the operating system, install the appropriate packages for the Block Storage service:</para> <screen os=""ubuntu;debian""><prompt>#</prompt> <userinput>apt-get install cinder-volume</userinput></screen> <screen os=""centos;rhel;fedora""><prompt>#</prompt> <userinput>yum install openstack-cinder-volume targetcli</userinput></screen> <step os=""fedora;rhel;centos""> <para>Start and enable the target service.</para> <screen><prompt>#</prompt> <userinput>service target start</userinput> <prompt>#</prompt> <userinput>chkconfig target on</userinput></screen> <step os=""fedora;rhel;centos;opensuse;sles;ubuntu""> <para os=""fedora;rhel;centos;opensuse;sles"">Copy the <screen os=""fedora;rhel;centos;opensuse;sles""><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf DEFAULT \ <para os=""ubuntu"">Edit the file and add this section for keystone credentials:</para> <programlisting os=""ubuntu"" language=""ini"">... <step os=""fedora;rhel;centos""> <para>Configure Block Storage to use the lioadm iscsi_helper:</para> <screen os=""fedora;rhel;centos""> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT iscsi_helper lioadm</userinput></screen> </step> <para>Configure Block Storage to use the RabbitMQ message broker.</para> <para>In the <literal>[DEFAULT]</literal> configuration section of the <filename>/etc/cinder/cinder.conf</filename> file, set these configuration keys and replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for RabbitMQ:</para>... rpc_backend = rabbit rabbit_host = <replaceable>controller</replaceable> rabbit_port = 5672 rabbit_userid = guest rabbit_password = <replaceable>RABBIT_PASS</replaceable></programlisting> <step os=""sles;opensuse;rhel;centos;fedora""> broker. Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for RabbitMQ:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rpc_backend rabbit</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_host <replaceable>controller</replaceable></userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_port 5672</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ DEFAULT rabbit_password <replaceable>RABBIT_PASS</replaceable></userinput></screen> </step> <step os=""ubuntu;rhel;centos;fedora;opensuse;sles""> <para>Configure Block Storage to use your MySQL database. Edit the <filename>/etc/cinder/cinder.conf</filename> file and add the following key to the <literal>[database]</literal> section. Replace <replaceable>CINDER_DBPASS</replaceable> with the password you chose for the Block Storage database:</para> <screen os=""rhel;centos;fedora;opensuse;sles""><prompt>#</prompt> <userinput>openstack-config --set /etc/cinder/cinder.conf \ database connection mysql://cinder:<replaceable>CINDER_DBPASS</replaceable>@<replaceable>controller</replaceable>/cinder</userinput></screen>... connection = mysql://cinder:<replaceable>CINDER_DBPASS</replaceable>@<replaceable>controller</replaceable>/cinder</programlisting> <para>In some distributions, the <filename>/etc/cinder/cinder.conf</filename> file does not include the <literal>[database]</literal> section header. You must add this section header to the end of the file <para>Configure Block Storage to use the Image Service. Block Storage needs access to images to create bootable volumes. Edit the <filename>/etc/cinder/cinder.conf</filename> file and update the <option>glance_host</option> option in the <literal>[DEFAULT]</literal> section:</para> DEFAULT glance_host <replaceable>controller</replaceable></userinput></screen> <programlisting os=""ubuntu;debian"" language=""ini"">[DEFAULT] ... glance_host = <replaceable>controller</replaceable></programlisting>",98,79
openstack%2Ftempest~master~Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75,openstack/tempest,master,Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75,Hacking rule to forbid resource unsafe fixtures,MERGED,2014-09-15 13:27:39.000000000,2014-10-07 11:49:19.000000000,2014-10-07 11:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/321fb4485475d0db170a24a03f1e7245480b1fbc', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 2, 'created': '2014-09-16 11:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f4dc044de441e01eed8a78b86f15a7423b359d0', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 3, 'created': '2014-09-16 14:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf174af94b39d1c4ac080dd68b3e8709fe88641f', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 4, 'created': '2014-09-16 21:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0578023791d439b2a8a2419aff5221d794776ff4', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 5, 'created': '2014-09-17 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/03b203f84535a7b9af605eaecd702ef58bd7481d', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 6, 'created': '2014-09-17 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/282a175805d86479d7a9ee0fbdba1e9232f4b37c', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 7, 'created': '2014-09-17 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c8007820f12d20a71fa008c00476060a84b383db', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 8, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/210539564c176d7e46ecda398486084fdd88ee9e', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 9, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e210682d573509a227eb80f824f3e1c49de6b42d', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 10, 'created': '2014-10-02 13:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a74d4c9faf81a10f4333f41562ff4dedb267614e', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 11, 'created': '2014-10-03 18:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2a6c5b7cec9f5a042b4c990726932e829e892d35', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 12, 'created': '2014-10-04 08:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b901d5909f92d68382c99347cae16c10944c7181', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 13, 'created': '2014-10-04 10:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e28cff6b7b78ee05cb4943aa6bbc8e918cb54e06', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nForbid overriding setUpClass and tearDownClass except for\ntempest/test.py where the test base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 14, 'created': '2014-10-06 20:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c08a5b8d033c8060931a36420948f8522f74019', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nExtend the existing T105, which was missing checks for\ntearDownClass anyways. Forbid overriding setUpClass\nand tearDownClass except for tempest/test.py where the\ntest base class is defined.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 15, 'created': '2014-10-07 09:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/369b0ce8aa0e7b5398854f58121b0ed271549287', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nExtend the existing T105, which was missing checks for\ntearDownClass anyways. Forbid overriding setUpClass\nand tearDownClass except for tempest/test.py where the\ntest base class is defined.\n\nTo be able to enforce the rule, fixing setUpClass\nwhich was added with new tests before this patch could\nmerge.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}, {'number': 16, 'created': '2014-10-07 09:31:35.000000000', 'files': ['tempest/api/network/test_security_groups_negative.py', 'tempest/api/network/test_security_groups.py', 'tempest/tests/test_hacking.py', 'tempest/tests/common/utils/test_misc.py', 'tempest/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/41fa16d21441e3f65b698a1253e7fe5c8b164cc4', 'message': 'Hacking rule to forbid resource unsafe fixtures\n\nExtend the existing T105, which was missing checks for\ntearDownClass anyways. Forbid overriding setUpClass\nand tearDownClass except for tempest/test.py where the\ntest base class is defined.\n\nTo be able to enforce the rule, fixing setUpClass\nwhich was added with new tests before this patch could\nmerge.\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75\n'}]",5,121554,41fa16d21441e3f65b698a1253e7fe5c8b164cc4,65,9,16,1921,,,0,"Hacking rule to forbid resource unsafe fixtures

Extend the existing T105, which was missing checks for
tearDownClass anyways. Forbid overriding setUpClass
and tearDownClass except for tempest/test.py where the
test base class is defined.

To be able to enforce the rule, fixing setUpClass
which was added with new tests before this patch could
merge.

Partially-implements bp resource-cleanup

Change-Id: Ib4d98c2ff8776ea1379a044b5a30fb02e351ce75
",git fetch https://review.opendev.org/openstack/tempest refs/changes/54/121554/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/common/utils/test_misc.py', 'tempest/hacking/checks.py']",2,321fb4485475d0db170a24a03f1e7245480b1fbc,bp/resource-cleanup,"SETUP_TEARDOWN_CLASS_DEFINITION = re.compile(r'^\s*def (setUp|tearDown)Class')def no_setup_teardown_class(physical_line, filename): if pep8.noqa(physical_line): return if 'tempest/test.py' not in filename: if SETUP_TEARDOWN_CLASS_DEFINITION.match(physical_line): return (physical_line.find('def'), 'T109: setUpClass and tearDownClass can not be used in ' 'in tests') register(no_setup_teardown_class)",,17,3
openstack%2Fceilometer~master~I5232c5dad17730b76a1b3ee864d8d973ba1b8749,openstack/ceilometer,master,I5232c5dad17730b76a1b3ee864d8d973ba1b8749,[HBase] Add migration script for new row separate design,MERGED,2014-08-20 12:17:22.000000000,2014-10-07 11:41:02.000000000,2014-10-07 11:41:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-08-20 12:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dd87bce9ca15af9b835f1ca30338db9f83d0283e', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 2, 'created': '2014-08-28 10:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/259ec6a8c05eda8102e20bdde2516a69aa072644', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 3, 'created': '2014-09-18 15:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/83c62b430a75d4a6c7666c45e5dd26e07d51fbf5', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 4, 'created': '2014-09-23 08:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cb6a395d52cc4805e7c5bc01b133e92d098c233f', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 5, 'created': '2014-09-23 10:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1511c2135b2022d695fe2836f3423567fc203ecf', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 6, 'created': '2014-10-01 15:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ac4075a4bfde9a624586b7b7e328b8bcccfac988', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 7, 'created': '2014-10-03 14:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6dd7cbbe63c9e23c4f96fd3464a7202b15f82ce8', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}, {'number': 8, 'created': '2014-10-07 09:08:17.000000000', 'files': ['ceilometer/storage/hbase/migration.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/inmemory.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/alarm/storage/impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3643ca5b3bcb5f29c32a16515f9c94d5c1b4093b', 'message': '[HBase] Add migration script for new row separate design\n\nAdd migration for HBase data for compatibility with\nnew row format which presented in CR\nhttps://review.openstack.org/#/c/106376/\n\nChange-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749\n'}]",19,115615,3643ca5b3bcb5f29c32a16515f9c94d5c1b4093b,49,12,8,7729,,,0,"[HBase] Add migration script for new row separate design

Add migration for HBase data for compatibility with
new row format which presented in CR
https://review.openstack.org/#/c/106376/

Change-Id: I5232c5dad17730b76a1b3ee864d8d973ba1b8749
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/15/115615/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/inmemory.py', 'ceilometer/alarm/storage/impl_hbase.py']",3,dd87bce9ca15af9b835f1ca30338db9f83d0283e,hbase_migrations," self.migrate_alarm_history_table() def migrate_alarm_history_table(self): with self.conn_pool.connection() as conn: alarm_h_table = conn.table(self.ALARM_HISTORY_TABLE) alarm_h_filter = ""RowFilter(=, 'regexstring:\\w*_\\d{19}')"" gen = alarm_h_table.scan(filter=alarm_h_filter) for row, data in gen: alarm_h_table.delete(row) row_parts = row.rsplit('_', 1) alarm_h_table.put(hbase_utils.prepare_key(*row_parts), data)",,73,1
openstack%2Fceilometer~master~Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623,openstack/ceilometer,master,Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623,clean path in swift middleware,MERGED,2014-09-29 22:39:17.000000000,2014-10-07 11:34:59.000000000,2014-10-07 11:34:59.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-09-29 22:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d6fc2d41456315b799eb7b63eafe2fb04582072f', 'message': 'test\n\nblah blah\n\nChange-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623\n'}, {'number': 2, 'created': '2014-09-30 02:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d6df14a7582ebfc5db4bf5e60cdf474416150193', 'message': 'clean path in swift middleware\n\nthe path also requires encoding as syslogs still show errors.\n\nCloses-Bug: #1369124\nChange-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623\n'}, {'number': 3, 'created': '2014-09-30 02:13:04.000000000', 'files': ['ceilometer/objectstore/swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dbe8c8b20f4231841d2086fbfd278f3a4cde8324', 'message': 'clean path in swift middleware\n\nthe path also requires encoding as syslogs still show errors.\n\nCloses-Bug: #1369124\nChange-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623\n'}]",0,124916,dbe8c8b20f4231841d2086fbfd278f3a4cde8324,11,9,3,6537,,,0,"clean path in swift middleware

the path also requires encoding as syslogs still show errors.

Closes-Bug: #1369124
Change-Id: Ie4d19a5a7dd5ce29e10c6e082bfcb33e6e641623
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/16/124916/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/objectstore/swift_middleware.py'],1,d6fc2d41456315b799eb7b63eafe2fb04582072f,middleware-error,"import urllib2 path = urllib2.quote(env.get('SCRIPT_NAME', '') + env['PATH_INFO'])", path = env['PATH_INFO'],2,1
openstack%2Fsahara-image-elements~proposed%2Fjuno~Iecef82bec8eb8d10218c5ad2b763ccabb41053ad,openstack/sahara-image-elements,proposed/juno,Iecef82bec8eb8d10218c5ad2b763ccabb41053ad,Add tools/gate/build-images script,MERGED,2014-10-07 06:29:39.000000000,2014-10-07 11:18:27.000000000,2014-10-07 06:34:32.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-07 06:29:39.000000000', 'files': ['tools/gate/build-images'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/51c33744acf87bbedc68fecf7f44d96e15bf90bd', 'message': ""Add tools/gate/build-images script\n\nIt will simplify configuring and tuning for our upcoming images\ngating. In gate job we'll just exec this script and it will do\nall the things we need. Let's start just with the building all\nimages for the specified plugin.\n\nChange-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad\n(cherry picked from commit 8f38712e1f62d3e0e7bb50133c029f57825dec2c)\n""}]",0,126476,51c33744acf87bbedc68fecf7f44d96e15bf90bd,7,3,1,6786,,,0,"Add tools/gate/build-images script

It will simplify configuring and tuning for our upcoming images
gating. In gate job we'll just exec this script and it will do
all the things we need. Let's start just with the building all
images for the specified plugin.

Change-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad
(cherry picked from commit 8f38712e1f62d3e0e7bb50133c029f57825dec2c)
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/76/126476/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/gate/build-images'],1,51c33744acf87bbedc68fecf7f44d96e15bf90bd,,#!/bin/bash -xe PLUGIN=$1 sudo ./diskimage-create/diskimage-create.sh -p $PLUGIN ,,5,0
openstack%2Fopenstack-manuals~master~I28e1a2523a4c88383ecb878e67f6e15d0a6408fb,openstack/openstack-manuals,master,I28e1a2523a4c88383ecb878e67f6e15d0a6408fb,Rework the HOT hello world section,MERGED,2014-10-06 19:47:58.000000000,2014-10-07 11:18:21.000000000,2014-10-07 11:18:20.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-10-06 19:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9a7e6acc2f1cabebf54d4edd4849965c78ff025b', 'message': 'Rework the HOT hello world section\n\nThis patch mostly brings editing changes, the samples are the same.\n\nRename hot_guide.rst to hello_world.rst.\n\nChange-Id: I28e1a2523a4c88383ecb878e67f6e15d0a6408fb\n'}, {'number': 2, 'created': '2014-10-07 11:00:04.000000000', 'files': ['doc/hot-guide/source/hello_world.rst', 'doc/hot-guide/source/hot_guide.rst', 'doc/hot-guide/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ad169d475ccbad2c98864cee6bb894edfbd79b6', 'message': 'Rework the HOT hello world section\n\nThis patch mostly brings editing changes, the samples are the same.\n\nRename hot_guide.rst to hello_world.rst.\n\nChange-Id: I28e1a2523a4c88383ecb878e67f6e15d0a6408fb\n'}]",6,126406,3ad169d475ccbad2c98864cee6bb894edfbd79b6,13,4,2,7923,,,0,"Rework the HOT hello world section

This patch mostly brings editing changes, the samples are the same.

Rename hot_guide.rst to hello_world.rst.

Change-Id: I28e1a2523a4c88383ecb878e67f6e15d0a6408fb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/126406/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/hot-guide/source/hello_world.rst', 'doc/hot-guide/source/hot_guide.rst', 'doc/hot-guide/source/index.rst']",3,9a7e6acc2f1cabebf54d4edd4849965c78ff025b,hot-hello-world, hello_world, hot_guide,235,236
openstack%2Fmurano-agent~master~Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c,openstack/murano-agent,master,Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c,"TEST COMMIT, DO NOT MERGE",ABANDONED,2014-10-02 12:10:48.000000000,2014-10-07 11:09:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-10-02 12:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/4d73a3cb7566f2a6ef30dce97361537c5d164cdb', 'message': 'TEST COMMIT, DO NOT MERGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 2, 'created': '2014-10-02 12:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/964b46327b245c3148f04486ed7383eb27bccd24', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 3, 'created': '2014-10-02 12:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/61d55c6ec3a4cf1d03ad5310a3eb75d39cc8ec6a', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 4, 'created': '2014-10-02 12:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/52b88f6ea42b86d39732aa1fc4d972c8cfb00eed', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 5, 'created': '2014-10-02 13:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/796cf35ea16a461adabbba0bfe2d9f0bc2ab754a', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 6, 'created': '2014-10-02 13:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/e0ddf56851f46f23e845cdab68f09d58b71499d2', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 7, 'created': '2014-10-02 13:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/12761823f576f2c31b4818f4208e26a39f6e7549', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 8, 'created': '2014-10-02 14:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/b2ef39237586e64d771b5b0b645c3cff0afbbc6f', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 9, 'created': '2014-10-02 14:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/ef4d4d97110d9ed36270deed9020f2efc1eb5151', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 10, 'created': '2014-10-02 14:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/e2c3318835885adc622ca197506e6896c909f912', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 11, 'created': '2014-10-03 07:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/d80f5c64a4e145fed79b1bce3493c5ea650eeed9', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 12, 'created': '2014-10-03 08:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/cf62579f3c33ac7884572d6b73e7ecb2c416057b', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 13, 'created': '2014-10-03 09:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/9fe0c244069f27fe44a97c405c621dc415b84759', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 14, 'created': '2014-10-03 12:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/d55a583c2f225c02aa2a07fabd64c345e16d0180', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 15, 'created': '2014-10-03 12:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/d9425738246b6d4d0e0e2f0b8075e81b2f2ee8e9', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 16, 'created': '2014-10-03 12:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/c460c5acb84b4fae0c81c2c5d68149afd49f9d6f', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}, {'number': 17, 'created': '2014-10-06 09:16:45.000000000', 'files': ['testcommit.txt', 'contrib/elements/murano-agent/install.d/05-murano-agent'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/0a0f3f7e49408366b59269db9924ff21478db6b8', 'message': 'TEST COMMIT, DO NOT MERGE\n\nTEST MESSAGE\n\nChange-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c\n'}]",0,125609,0a0f3f7e49408366b59269db9924ff21478db6b8,92,3,17,8824,,,0,"TEST COMMIT, DO NOT MERGE

TEST MESSAGE

Change-Id: Ic9ce5995e2a07a932aebb4b819f3cb33df99bf8c
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/09/125609/17 && git format-patch -1 --stdout FETCH_HEAD,['testcommit.txt'],1,4d73a3cb7566f2a6ef30dce97361537c5d164cdb,,TESTCOMMIT ,,1,0
openstack%2Ffuel-library~master~I759e109c08f3f88802f012e5b9e0f8bd46af2981,openstack/fuel-library,master,I759e109c08f3f88802f012e5b9e0f8bd46af2981,Drop UDP as well as TCP,ABANDONED,2014-07-24 16:42:49.000000000,2014-10-07 10:34:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-24 16:42:49.000000000', 'files': ['deployment/puppet/openstack/manifests/firewall.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0015c662b1fb2c372d58af753ed7705de46f6aa2', 'message': 'Drop UDP as well as TCP\n\nChange-Id: I759e109c08f3f88802f012e5b9e0f8bd46af2981\nCloses-Bug: 1347580\n'}]",0,109344,0015c662b1fb2c372d58af753ed7705de46f6aa2,10,3,1,9037,,,0,"Drop UDP as well as TCP

Change-Id: I759e109c08f3f88802f012e5b9e0f8bd46af2981
Closes-Bug: 1347580
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/44/109344/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/firewall.pp'],1,0015c662b1fb2c372d58af753ed7705de46f6aa2,bug/1347580," proto => 'all',",,1,0
openstack%2Fnova~master~I1f63cfbd534c20c634c23287d3263d5e0893766c,openstack/nova,master,I1f63cfbd534c20c634c23287d3263d5e0893766c,Imported Translations from Transifex,MERGED,2014-10-02 06:11:59.000000000,2014-10-07 10:28:38.000000000,2014-10-07 10:28:37.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6547}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 06:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d9c686e5192b7c200381f948e8a8f261f055677', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}, {'number': 2, 'created': '2014-10-03 06:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02d61077dc0c152737f830a10aa5d80ba36441ef', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}, {'number': 3, 'created': '2014-10-04 06:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73c2f8140c90b642828318f7153dbbebb4f7fa77', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}, {'number': 4, 'created': '2014-10-05 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd3cadaf2e4859ba66cd17ce59c65c4895562e48', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}, {'number': 5, 'created': '2014-10-06 06:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23eb0fe1baa1b2893a0e201389225b9404b09d37', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}, {'number': 6, 'created': '2014-10-07 06:12:40.000000000', 'files': ['nova/locale/nova.pot', 'nova/locale/ja/LC_MESSAGES/nova-log-error.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-error.po', 'nova/locale/pt_BR/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-warning.po', 'nova/locale/en_GB/LC_MESSAGES/nova-log-error.po', 'nova/locale/en_AU/LC_MESSAGES/nova-log-info.po', 'nova/locale/de/LC_MESSAGES/nova-log-info.po', 'nova/locale/es/LC_MESSAGES/nova-log-warning.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova-log-error.po', 'nova/locale/nova-log-warning.pot', 'nova/locale/en_US/LC_MESSAGES/nova.po'], 'web_link': 'https://opendev.org/openstack/nova/commit/b390e21d35a7d96cea58a34509931d8013c8edb3', 'message': 'Imported Translations from Transifex\n\nChange-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c\n'}]",0,125558,b390e21d35a7d96cea58a34509931d8013c8edb3,41,8,6,11131,,,0,"Imported Translations from Transifex

Change-Id: I1f63cfbd534c20c634c23287d3263d5e0893766c
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/125558/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/nova.pot', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po']",3,9d9c686e5192b7c200381f948e8a8f261f055677,transifex/translations,"""POT-Creation-Date: 2014-10-02 06:10+0000\n"" ""PO-Revision-Date: 2014-10-02 03:07+0000\n""#: nova/context.py:60#: nova/context.py:105#: nova/crypto.py:211#: nova/crypto.py:400#: nova/exception.py:1761 #, python-format msgid ""The token '%(token)s' is invalid or has expired"" msgstr """" #: nova/api/ec2/__init__.py:90#: nova/api/ec2/__init__.py:161#: nova/api/ec2/__init__.py:189#: nova/api/ec2/__init__.py:194#: nova/api/ec2/__init__.py:230 nova/api/ec2/__init__.py:246#: nova/api/ec2/__init__.py:306#: nova/api/ec2/__init__.py:404#: nova/api/ec2/__init__.py:523#: nova/api/openstack/wsgi.py:230 nova/api/openstack/wsgi.py:611#: nova/api/openstack/wsgi.py:616#: nova/api/openstack/wsgi.py:897#: nova/api/openstack/wsgi.py:900 nova/api/openstack/wsgi.py:926#: nova/api/openstack/wsgi.py:904#: nova/api/openstack/wsgi.py:923#: nova/api/openstack/wsgi.py:935#: nova/api/openstack/compute/servers.py:1200#: nova/api/openstack/compute/contrib/floating_ips_bulk.py:115#: nova/api/openstack/compute/contrib/floating_ips_bulk.py:143#: nova/tests/api/openstack/compute/test_servers.py:2830#: nova/compute/api.py:2944#: nova/compute/api.py:2964#: nova/compute/api.py:2967#: nova/compute/api.py:2970#: nova/compute/api.py:3177#: nova/compute/api.py:3482#: nova/compute/api.py:3515#: nova/compute/api.py:3550#: nova/compute/api.py:3638 nova/tests/compute/test_keypairs.py:137#: nova/compute/api.py:3644 nova/tests/compute/test_keypairs.py:127#: nova/compute/api.py:3732#: nova/compute/api.py:3742#: nova/compute/api.py:3762#: nova/compute/api.py:3765#: nova/compute/api.py:3777#: nova/compute/api.py:3790#: nova/compute/api.py:3852#: nova/compute/api.py:3857#: nova/compute/api.py:3870#: nova/compute/api.py:3946 nova/compute/api.py:4029#: nova/compute/api.py:3962#: nova/compute/api.py:3965#: nova/compute/api.py:3980#: nova/compute/api.py:4036#: nova/compute/manager.py:4540#: nova/compute/manager.py:4565#: nova/compute/manager.py:4576#: nova/compute/manager.py:4770#: nova/compute/manager.py:4794#: nova/compute/manager.py:4806 nova/tests/compute/test_compute.py:11061#: nova/compute/manager.py:5024#: nova/compute/manager.py:5104#: nova/compute/manager.py:5106#: nova/compute/manager.py:5131#: nova/compute/manager.py:5336#: nova/compute/manager.py:5389#: nova/compute/manager.py:5394#: nova/compute/manager.py:5403#: nova/compute/manager.py:5413#: nova/compute/manager.py:5418#: nova/compute/manager.py:5436#: nova/compute/manager.py:5447#: nova/compute/manager.py:5497#: nova/compute/manager.py:5546#: nova/compute/manager.py:5568#: nova/compute/manager.py:5689#: nova/compute/manager.py:5769#: nova/compute/manager.py:5782#: nova/compute/manager.py:5834#: nova/compute/manager.py:5850#: nova/compute/manager.py:5856#: nova/compute/manager.py:5884#: nova/compute/manager.py:5898#: nova/compute/manager.py:5928#: nova/compute/manager.py:5932#: nova/compute/manager.py:5958#: nova/compute/manager.py:5967 nova/compute/resource_tracker.py:436#: nova/compute/manager.py:6009#: nova/compute/manager.py:6015#: nova/compute/manager.py:6024#: nova/compute/manager.py:6029#: nova/compute/manager.py:6033#: nova/compute/manager.py:6043#: nova/compute/manager.py:6047#: nova/compute/manager.py:6079#: nova/compute/manager.py:6089#: nova/compute/rpcapi.py:58#: nova/compute/rpcapi.py:60#: nova/console/websocketproxy.py:66#: nova/console/websocketproxy.py:71#: nova/console/websocketproxy.py:83#: nova/console/websocketproxy.py:94#: nova/tests/api/openstack/compute/test_servers.py:2910#: nova/tests/api/openstack/compute/test_servers.py:2915#: nova/tests/api/openstack/compute/test_servers.py:2920#: nova/tests/compute/test_compute.py:1940 #: nova/tests/compute/test_compute.py:1980 #: nova/tests/compute/test_compute.py:5843#: nova/tests/compute/test_compute.py:1910 #: nova/tests/compute/test_compute.py:1948#: nova/tests/compute/test_compute.py:5854#: nova/tests/compute/test_compute.py:6478#: nova/tests/compute/test_compute.py:11269#: nova/tests/db/test_migrations.py:1025#: nova/tests/integrated/api/client.py:38#: nova/tests/integrated/api/client.py:49#: nova/tests/integrated/api/client.py:57#: nova/tests/integrated/api/client.py:65#: nova/tests/integrated/api/client.py:143#: nova/virt/hyperv/vmops.py:337 nova/virt/vmwareapi/vmops.py:507#: nova/virt/hyperv/vmops.py:340 nova/virt/vmwareapi/vmops.py:511#: nova/virt/hyperv/vmops.py:361 nova/virt/vmwareapi/vmops.py:536#: nova/virt/ironic/client_wrapper.py:73#: nova/virt/ironic/client_wrapper.py:111#: nova/virt/ironic/driver.py:300#: nova/virt/ironic/driver.py:323#: nova/virt/ironic/driver.py:348#: nova/virt/ironic/driver.py:604#: nova/virt/ironic/driver.py:626#: nova/virt/ironic/driver.py:696#: nova/virt/ironic/driver.py:909#: nova/virt/ironic/driver.py:1032#: nova/virt/vmwareapi/vm_util.py:226#: nova/virt/vmwareapi/vm_util.py:1055#: nova/virt/vmwareapi/vm_util.py:1149#: nova/virt/vmwareapi/vm_util.py:1161#: nova/virt/vmwareapi/vm_util.py:1351#: nova/virt/vmwareapi/vmops.py:735#: nova/virt/vmwareapi/vmops.py:763#: nova/virt/vmwareapi/vmops.py:790#: nova/virt/vmwareapi/vmops.py:813#: nova/virt/vmwareapi/vmops.py:856#: nova/virt/vmwareapi/vmops.py:860#: nova/virt/vmwareapi/vmops.py:878#: nova/virt/vmwareapi/vmops.py:898#: nova/virt/vmwareapi/vmops.py:998#: nova/virt/vmwareapi/vmops.py:1057#: nova/virt/vmwareapi/vmops.py:1133 nova/virt/xenapi/vmops.py:1584#: nova/virt/vmwareapi/vmops.py:1137 nova/virt/xenapi/vmops.py:1588#: nova/virt/vmwareapi/vmops.py:1437#: nova/virt/vmwareapi/vmops.py:1447#: nova/virt/vmwareapi/vmops.py:1529","""POT-Creation-Date: 2014-09-30 06:38+0000\n"" ""PO-Revision-Date: 2014-09-29 22:56+0000\n""#: nova/context.py:64#: nova/context.py:109#: nova/crypto.py:209#: nova/crypto.py:396#: nova/api/ec2/__init__.py:89#: nova/api/ec2/__init__.py:160#: nova/api/ec2/__init__.py:188#: nova/api/ec2/__init__.py:193#: nova/api/ec2/__init__.py:229 nova/api/ec2/__init__.py:245#: nova/api/ec2/__init__.py:305#: nova/api/ec2/__init__.py:403#: nova/api/ec2/__init__.py:522#: nova/api/openstack/wsgi.py:230 nova/api/openstack/wsgi.py:635#: nova/api/openstack/wsgi.py:640#: nova/api/openstack/wsgi.py:921#: nova/api/openstack/wsgi.py:924 nova/api/openstack/wsgi.py:950#: nova/api/openstack/wsgi.py:928#: nova/api/openstack/wsgi.py:947#: nova/api/openstack/wsgi.py:959#: nova/api/openstack/compute/servers.py:1197#: nova/api/openstack/compute/contrib/floating_ips_bulk.py:117#: nova/api/openstack/compute/contrib/floating_ips_bulk.py:145#: nova/tests/api/openstack/compute/test_servers.py:2834#: nova/compute/api.py:2946#: nova/compute/api.py:2966#: nova/compute/api.py:2969#: nova/compute/api.py:2972#: nova/compute/api.py:3179#: nova/compute/api.py:3484#: nova/compute/api.py:3517#: nova/compute/api.py:3552#: nova/compute/api.py:3640 nova/tests/compute/test_keypairs.py:137#: nova/compute/api.py:3646 nova/tests/compute/test_keypairs.py:127#: nova/compute/api.py:3734#: nova/compute/api.py:3744#: nova/compute/api.py:3764#: nova/compute/api.py:3767#: nova/compute/api.py:3779#: nova/compute/api.py:3792#: nova/compute/api.py:3854#: nova/compute/api.py:3859#: nova/compute/api.py:3872#: nova/compute/api.py:3948 nova/compute/api.py:4031#: nova/compute/api.py:3964#: nova/compute/api.py:3967#: nova/compute/api.py:3982#: nova/compute/api.py:4038#: nova/compute/manager.py:4536#: nova/compute/manager.py:4561#: nova/compute/manager.py:4572#: nova/compute/manager.py:4766#: nova/compute/manager.py:4790#: nova/compute/manager.py:4802 nova/tests/compute/test_compute.py:11062#: nova/compute/manager.py:5020#: nova/compute/manager.py:5100#: nova/compute/manager.py:5102#: nova/compute/manager.py:5127#: nova/compute/manager.py:5332#: nova/compute/manager.py:5385#: nova/compute/manager.py:5390#: nova/compute/manager.py:5399#: nova/compute/manager.py:5409#: nova/compute/manager.py:5414#: nova/compute/manager.py:5432#: nova/compute/manager.py:5443#: nova/compute/manager.py:5493#: nova/compute/manager.py:5542#: nova/compute/manager.py:5564#: nova/compute/manager.py:5685#: nova/compute/manager.py:5765#: nova/compute/manager.py:5778#: nova/compute/manager.py:5830#: nova/compute/manager.py:5846#: nova/compute/manager.py:5852#: nova/compute/manager.py:5880#: nova/compute/manager.py:5894#: nova/compute/manager.py:5924#: nova/compute/manager.py:5928#: nova/compute/manager.py:5954#: nova/compute/manager.py:5963 nova/compute/resource_tracker.py:436#: nova/compute/manager.py:6005#: nova/compute/manager.py:6011#: nova/compute/manager.py:6020#: nova/compute/manager.py:6025#: nova/compute/manager.py:6029#: nova/compute/manager.py:6039#: nova/compute/manager.py:6043#: nova/compute/manager.py:6075#: nova/compute/manager.py:6085#: nova/compute/rpcapi.py:57#: nova/compute/rpcapi.py:59#: nova/console/websocketproxy.py:50 msgid ""Invalid Token"" msgstr ""Seal no vlida"" #: nova/console/websocketproxy.py:52#: nova/console/websocketproxy.py:57#: nova/console/websocketproxy.py:69#: nova/console/websocketproxy.py:80#: nova/tests/api/openstack/compute/test_servers.py:2914#: nova/tests/api/openstack/compute/test_servers.py:2919#: nova/tests/api/openstack/compute/test_servers.py:2924#: nova/tests/compute/test_compute.py:1938 #: nova/tests/compute/test_compute.py:1978 #: nova/tests/compute/test_compute.py:5841#: nova/tests/compute/test_compute.py:1908 #: nova/tests/compute/test_compute.py:1946#: nova/tests/compute/test_compute.py:5852#: nova/tests/compute/test_compute.py:6476#: nova/tests/compute/test_compute.py:11270#: nova/tests/db/test_migrations.py:1021#: nova/tests/integrated/api/client.py:39#: nova/tests/integrated/api/client.py:50#: nova/tests/integrated/api/client.py:58#: nova/tests/integrated/api/client.py:66#: nova/tests/integrated/api/client.py:108 #, python-format msgid ""Doing %(method)s on %(relative_url)s"" msgstr ""Realizando %(method)s en %(relative_url)s"" #: nova/tests/integrated/api/client.py:111 #, python-format msgid ""Body: %s"" msgstr ""Cuerpo: %s"" #: nova/tests/integrated/api/client.py:171#: nova/virt/hyperv/vmops.py:337 nova/virt/vmwareapi/vmops.py:508#: nova/virt/hyperv/vmops.py:340 nova/virt/vmwareapi/vmops.py:512#: nova/virt/hyperv/vmops.py:361 nova/virt/vmwareapi/vmops.py:537#: nova/virt/ironic/client_wrapper.py:75#: nova/virt/ironic/client_wrapper.py:113#: nova/virt/ironic/driver.py:292#: nova/virt/ironic/driver.py:315#: nova/virt/ironic/driver.py:340#: nova/virt/ironic/driver.py:587#: nova/virt/ironic/driver.py:609#: nova/virt/ironic/driver.py:679#: nova/virt/ironic/driver.py:864#: nova/virt/ironic/driver.py:987#: nova/virt/vmwareapi/vm_util.py:227#: nova/virt/vmwareapi/vm_util.py:1057#: nova/virt/vmwareapi/vm_util.py:1151#: nova/virt/vmwareapi/vm_util.py:1163#: nova/virt/vmwareapi/vm_util.py:1353#: nova/virt/vmwareapi/vmops.py:736#: nova/virt/vmwareapi/vmops.py:764#: nova/virt/vmwareapi/vmops.py:791#: nova/virt/vmwareapi/vmops.py:814#: nova/virt/vmwareapi/vmops.py:846#: nova/virt/vmwareapi/vmops.py:850#: nova/virt/vmwareapi/vmops.py:868#: nova/virt/vmwareapi/vmops.py:888#: nova/virt/vmwareapi/vmops.py:988#: nova/virt/vmwareapi/vmops.py:1047#: nova/virt/vmwareapi/vmops.py:1123 nova/virt/xenapi/vmops.py:1584#: nova/virt/vmwareapi/vmops.py:1127 nova/virt/xenapi/vmops.py:1588#: nova/virt/vmwareapi/vmops.py:1425#: nova/virt/vmwareapi/vmops.py:1435#: nova/virt/vmwareapi/vmops.py:1517",455,483
openstack%2Fnova~proposed%2Fjuno~I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5,openstack/nova,proposed/juno,I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5,Fix the os_networks display to show cidr properly,MERGED,2014-10-02 23:10:31.000000000,2014-10-07 10:28:22.000000000,2014-10-07 10:28:20.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5170}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-10-02 23:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe6329921c2f189c017744184f6c64322b25c43d', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n(cherry picked from commit c53b759660c39f647dd218ba0a4175bdfb74e58b)\n'}, {'number': 2, 'created': '2014-10-03 02:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe95a8836fef2786e396e3303a771b024477223c', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n(cherry picked from commit ee852d4a774ed67979805b8a5b90d9a86ae90d6d)\n'}, {'number': 3, 'created': '2014-10-06 22:55:29.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/api/openstack/compute/contrib/os_networks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0aeffa12a62604ee3238323d969345e41937b642', 'message': ""Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPAddress\nfields in Network objects are dumped as lists by the jsonutils\nextension. We therefore must explicitly convert these object\nfield values to string.\n\nThe tests are updated to use objects so that we pick up bugs\nlike this in the future. Incorrect assertEqual parameter order\nis fixed in the tests too since these are comparing dicts and\nit's not fun debugging a MismatchError when the reference/actual\nvalues are backwards.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\nCo-authored-by: Matt Riedemann <mriedem@us.ibm.com>\n(cherry picked from commit da25467aafce9b62dd3fdff9d6cd84121fbee17e)\n""}]",0,125815,0aeffa12a62604ee3238323d969345e41937b642,14,4,3,67,,,0,"Fix the os_networks display to show cidr properly

Converting network_get and network_get_all to use objects broke
the display of the os_networks extension, because IPAddress
fields in Network objects are dumped as lists by the jsonutils
extension. We therefore must explicitly convert these object
field values to string.

The tests are updated to use objects so that we pick up bugs
like this in the future. Incorrect assertEqual parameter order
is fixed in the tests too since these are comparing dicts and
it's not fun debugging a MismatchError when the reference/actual
values are backwards.

Change-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5
Closes-Bug: #1376945
Co-authored-by: Matt Riedemann <mriedem@us.ibm.com>
(cherry picked from commit da25467aafce9b62dd3fdff9d6cd84121fbee17e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/125815/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/api/openstack/compute/contrib/os_networks.py']",2,fe6329921c2f189c017744184f6c64322b25c43d,bug/1376945," result = [network_dict(context, net_ref.obj_to_primitive()['nova_object.data'], self.extended) return {'network': network_dict( context, network.obj_to_primitive()['nova_object.data'], self.extended)}"," result = [network_dict(context, net_ref, self.extended) return {'network': network_dict(context, network, self.extended)}",24,8
openstack%2Fnova~proposed%2Fjuno~I00f6325cb554bc5e34d9f0fe651af39630f35b5d,openstack/nova,proposed/juno,I00f6325cb554bc5e34d9f0fe651af39630f35b5d,Disable libvirt NUMA topology support if libvirt < 1.0.4,MERGED,2014-10-06 13:41:48.000000000,2014-10-07 10:28:05.000000000,2014-10-07 10:28:02.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-10-06 13:41:48.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0251b53966eaa9e724377a300ea247367fd778c7', 'message': ""Disable libvirt NUMA topology support if libvirt < 1.0.4\n\nIf you're not at a new enough version of libvirt, the compute service\nfails on startup because VirtNUMATopologyCellUsage is not fully\npopulated.\n\nThis add a min version check before trying to get host NUMA topology\ninformation.\n\nCloses-Bug: #1376307\n\nChange-Id: I00f6325cb554bc5e34d9f0fe651af39630f35b5d\n(cherry picked from commit 8ba0d9188d492028fcf4e65f908aa2d3db571952)\n""}]",0,126299,0251b53966eaa9e724377a300ea247367fd778c7,6,2,1,6873,,,0,"Disable libvirt NUMA topology support if libvirt < 1.0.4

If you're not at a new enough version of libvirt, the compute service
fails on startup because VirtNUMATopologyCellUsage is not fully
populated.

This add a min version check before trying to get host NUMA topology
information.

Closes-Bug: #1376307

Change-Id: I00f6325cb554bc5e34d9f0fe651af39630f35b5d
(cherry picked from commit 8ba0d9188d492028fcf4e65f908aa2d3db571952)
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/126299/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py']",2,0251b53966eaa9e724377a300ea247367fd778c7,," mock.patch.object(conn, '_has_min_version', return_value=True), mock.patch.object(conn, '_has_min_version', return_value=True), ) as (get_by_id_mock, has_min_version_mock, get_host_cap_mock, mock.patch.object(conn, '_has_min_version', return_value=True), mock.patch.object(conn, '_has_min_version', return_value=True), mock.patch.object(conn, '_has_min_version', return_value=True), with contextlib.nested( mock.patch.object(conn, '_has_min_version', return_value=True), mock.patch.object(conn, '_get_host_capabilities', return_value=caps) ) as (has_min_version, get_caps): self.assertIsNone(conn._get_host_numa_topology()) get_caps.assert_called_once_with() def test_get_host_numa_topology_not_supported(self): # Tests that libvirt isn't new enough to support numa topology. conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with mock.patch.object(conn, '_has_min_version', return_value=False):"," ) as (get_by_id_mock, get_host_cap_mock, with mock.patch.object( conn, '_get_host_capabilities', return_value=caps):",23,3
openstack%2Fnova~proposed%2Fjuno~Idb9ac6c1ec5dcea52ce8e028f5cce08da1779321,openstack/nova,proposed/juno,Idb9ac6c1ec5dcea52ce8e028f5cce08da1779321,Destroy orig VM during resize if triggered by user,MERGED,2014-10-05 06:36:05.000000000,2014-10-07 10:27:47.000000000,2014-10-07 10:27:45.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 8247}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-10-05 06:36:05.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5065aeca1b4acad513c07e3832ec0e12de2e6568', 'message': ""Destroy orig VM during resize if triggered by user\n\nPatch I7598afbf0dc3c527471af34224003d28e64daaff introduces a\nMinesweeper failure, due to the fact that it doesn't distinguish\nbetween destroy operation triggered by the user and by the revert\nresize.\n\nThis patch fixes the issue by checking the task state. If the task\nstate is revert_resize, the original VM doesn't get deleted.\n\nCloses-Bug: #1376492\n\nChange-Id: Idb9ac6c1ec5dcea52ce8e028f5cce08da1779321\n(cherry picked from commit e464bc518e8590d59c2741948466777982ca3319)\n""}]",0,126177,5065aeca1b4acad513c07e3832ec0e12de2e6568,9,4,1,1653,,,0,"Destroy orig VM during resize if triggered by user

Patch I7598afbf0dc3c527471af34224003d28e64daaff introduces a
Minesweeper failure, due to the fact that it doesn't distinguish
between destroy operation triggered by the user and by the revert
resize.

This patch fixes the issue by checking the task state. If the task
state is revert_resize, the original VM doesn't get deleted.

Closes-Bug: #1376492

Change-Id: Idb9ac6c1ec5dcea52ce8e028f5cce08da1779321
(cherry picked from commit e464bc518e8590d59c2741948466777982ca3319)
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/126177/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",2,5065aeca1b4acad513c07e3832ec0e12de2e6568,1376492," def _destroy_instance_without_vm_ref(self, resize_exists=False, task_state=None): def fake_vm_ref_from_name(session, vm_name): if resize_exists: return 'fake-ref' fake_vm_ref_from_name), '_call_method'), mock.patch.object(self.conn._vmops, '_destroy_instance') ) as (mock_get, mock_call, mock_destroy): self.instance.task_state = task_state if resize_exists: if task_state == task_states.RESIZE_REVERTING: expected = 1 else: expected = 2 else: expected = 1 self.assertEqual(expected, mock_destroy.call_count) def test_destroy_instance_without_vm_ref(self): self._destroy_instance_without_vm_ref() def test_destroy_instance_without_vm_ref_with_resize(self): self._destroy_instance_without_vm_ref(resize_exists=True) def test_destroy_instance_without_vm_ref_with_resize_revert(self): self._destroy_instance_without_vm_ref(resize_exists=True, task_state=task_states.RESIZE_REVERTING) "," def test_destroy_instance_without_vm_ref(self): return_value=None), '_call_method') ) as (mock_get, mock_call): mock_get.assert_called_with(self.conn._vmops._session, self.instance['uuid']) expected_args = [((self.conn._vmops._session, self.instance['uuid'] + '-orig'),), ((self.conn._vmops._session, self.instance['uuid']),)] # one for VM named uuid-orig, one for VM named uuid self.assertEqual(expected_args, mock_get.call_args_list) self.assertEqual(2, mock_get.call_count)",46,24
openstack%2Ffuel-library~master~If98ff6d13d5d229127e5218c99d788b759e3027f,openstack/fuel-library,master,If98ff6d13d5d229127e5218c99d788b759e3027f,Set non-empty external-id for bridges by default,MERGED,2014-09-16 15:12:43.000000000,2014-10-07 10:26:26.000000000,2014-10-07 10:26:25.000000000,"[{'_account_id': 3}, {'_account_id': 6502}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-09-16 15:12:43.000000000', 'files': ['deployment/puppet/l23network/manifests/l2/bridge.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e4a9fd00dfa6d2d2e189ab716e4736dc71c7801e', 'message': 'Set non-empty external-id for bridges by default\n\nSet external-id for bridges to their names by default.\nOVS-agent monitors external bridges only if their external-id\nmatches their names\n\nChange-Id: If98ff6d13d5d229127e5218c99d788b759e3027f\nCloses-bug: #1323608\n'}]",0,121898,e4a9fd00dfa6d2d2e189ab716e4736dc71c7801e,11,5,1,7604,,,0,"Set non-empty external-id for bridges by default

Set external-id for bridges to their names by default.
OVS-agent monitors external bridges only if their external-id
matches their names

Change-Id: If98ff6d13d5d229127e5218c99d788b759e3027f
Closes-bug: #1323608
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/121898/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/l23network/manifests/l2/bridge.pp'],1,e4a9fd00dfa6d2d2e189ab716e4736dc71c7801e,bug/1323608," $external_ids = ""bridge-id=${name}"","," $external_ids = '',",1,1
openstack%2Ffuel-library~master~I4a6a7b78d58fd17ea133421bc326fe2d3d65b409,openstack/fuel-library,master,I4a6a7b78d58fd17ea133421bc326fe2d3d65b409,Import the camptocamp openssl module version 0.3.1.,MERGED,2014-09-16 12:20:13.000000000,2014-10-07 10:19:46.000000000,2014-10-07 10:19:45.000000000,"[{'_account_id': 3}, {'_account_id': 6794}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-09-16 12:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e17fb9f8624adfd792ee8177ac67418ff2822d9', 'message': 'Import the camptocamp openssl module version 0.3.1.\n\nIt is a new module that will be used to manage SSL keys and\ncertificates. It allows:\n  - The generation of SSL keys,\n  - The generation of SSL certificate from private key\n  - The generation of SSL certificate signing request\n\nChange-Id: I4a6a7b78d58fd17ea133421bc326fe2d3d65b409\nImplements: blueprint ssl-endpoints\n'}, {'number': 2, 'created': '2014-09-17 15:29:45.000000000', 'files': ['deployment/puppet/openssl/spec/unit/puppet/provider/x509_cert/openssl_spec.rb', 'deployment/puppet/openssl/spec/unit/puppet/type/x509_cert_spec.rb', 'deployment/puppet/openssl/manifests/packages.pp', 'deployment/puppet/openssl/README.md', 'deployment/puppet/openssl/spec/.rspec', 'deployment/puppet/openssl/lib/puppet/provider/ssl_pkey/openssl.rb', 'deployment/puppet/openssl/manifests/config.pp', 'deployment/puppet/openssl/spec/unit/puppet/type/ssl_pkey_spec.rb', 'deployment/puppet/openssl/lib/puppet/type/x509_cert.rb', 'deployment/puppet/openssl/manifests/certificate/x509.pp', 'deployment/puppet/openssl/Gemfile', 'deployment/puppet/openssl/lib/puppet/provider/x509_cert/openssl.rb', 'deployment/puppet/openssl/spec/spec_helper.rb', 'deployment/puppet/openssl/lib/puppet/parser/functions/cert_date_valid.rb', 'deployment/puppet/openssl/manifests/export/pkcs12.pp', 'deployment/puppet/openssl/spec/unit/puppet/provider/ssl_pkey/openssl_spec.rb', 'deployment/puppet/openssl/CHANGELOG', 'deployment/puppet/openssl/lib/puppet/provider/x509_request/openssl.rb', 'deployment/puppet/openssl/spec/unit/puppet/type/x509_request_spec.rb', 'deployment/puppet/openssl/spec/defines/openssl_certificate_x509_spec.rb', 'deployment/puppet/openssl/Rakefile', 'deployment/puppet/openssl/spec/fixtures/manifests/site.pp', 'deployment/puppet/openssl/checksums.json', 'deployment/puppet/openssl/spec/classes/openssl_spec.rb', 'deployment/puppet/openssl/LICENSE', 'deployment/puppet/openssl/tests/x509_cert.pp', 'deployment/puppet/openssl/manifests/init.pp', 'deployment/puppet/openssl/lib/puppet/type/x509_request.rb', 'deployment/puppet/openssl/manifests/params.pp', 'deployment/puppet/openssl/spec/unit/puppet/provider/x509_request/openssl_spec.rb', 'deployment/puppet/openssl/Modulefile', 'deployment/puppet/openssl/templates/cert.cnf.erb', 'deployment/puppet/openssl/lib/puppet/type/ssl_pkey.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/316d7636e9d264920ae3502296c196b9c9d24ca5', 'message': 'Import the camptocamp openssl module version 0.3.1.\n\nIt is a new module that will be used to manage SSL keys and\ncertificates. It allows:\n  - The generation of SSL keys,\n  - The generation of SSL certificate from private key\n  - The generation of SSL certificate signing request\n\nChange-Id: I4a6a7b78d58fd17ea133421bc326fe2d3d65b409\nImplements: blueprint ssl-endpoints\n'}]",0,121821,316d7636e9d264920ae3502296c196b9c9d24ca5,19,5,2,6904,,,0,"Import the camptocamp openssl module version 0.3.1.

It is a new module that will be used to manage SSL keys and
certificates. It allows:
  - The generation of SSL keys,
  - The generation of SSL certificate from private key
  - The generation of SSL certificate signing request

Change-Id: I4a6a7b78d58fd17ea133421bc326fe2d3d65b409
Implements: blueprint ssl-endpoints
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/21/121821/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openssl/spec/unit/puppet/provider/x509_cert/openssl_spec.rb', 'deployment/puppet/openssl/spec/unit/puppet/type/x509_cert_spec.rb', 'deployment/puppet/openssl/manifests/packages.pp', 'deployment/puppet/openssl/README.md', 'deployment/puppet/openssl/spec/.rspec', 'deployment/puppet/openssl/lib/puppet/provider/ssl_pkey/openssl.rb', 'deployment/puppet/openssl/manifests/config.pp', 'deployment/puppet/openssl/spec/unit/puppet/type/ssl_pkey_spec.rb', 'deployment/puppet/openssl/lib/puppet/type/x509_cert.rb', 'deployment/puppet/openssl/manifests/certificate/x509.pp', 'deployment/puppet/openssl/Gemfile', 'deployment/puppet/openssl/lib/puppet/provider/x509_cert/openssl.rb', 'deployment/puppet/openssl/spec/spec_helper.rb', 'deployment/puppet/openssl/lib/puppet/parser/functions/cert_date_valid.rb', 'deployment/puppet/openssl/manifests/export/pkcs12.pp', 'deployment/puppet/openssl/spec/unit/puppet/provider/ssl_pkey/openssl_spec.rb', 'deployment/puppet/openssl/CHANGELOG', 'deployment/puppet/openssl/lib/puppet/provider/x509_request/openssl.rb', 'deployment/puppet/openssl/spec/unit/puppet/type/x509_request_spec.rb', 'deployment/puppet/openssl/spec/defines/openssl_certificate_x509_spec.rb', 'deployment/puppet/openssl/Rakefile', 'deployment/puppet/openssl/spec/fixtures/manifests/site.pp', 'deployment/puppet/openssl/checksums.json', 'deployment/puppet/openssl/spec/classes/openssl_spec.rb', 'deployment/puppet/openssl/LICENSE', 'deployment/puppet/openssl/tests/x509_cert.pp', 'deployment/puppet/openssl/manifests/init.pp', 'deployment/puppet/openssl/lib/puppet/type/x509_request.rb', 'deployment/puppet/openssl/manifests/params.pp', 'deployment/puppet/openssl/spec/unit/puppet/provider/x509_request/openssl_spec.rb', 'deployment/puppet/openssl/Modulefile', 'deployment/puppet/openssl/templates/cert.cnf.erb', 'deployment/puppet/openssl/lib/puppet/type/ssl_pkey.rb']",33,9e17fb9f8624adfd792ee8177ac67418ff2822d9,bp/ssl-endpoints-ca-management,"require 'pathname' Puppet::Type.newtype(:ssl_pkey) do desc 'An SSL private key' ensurable newparam(:path, :namevar => true) do desc 'The path to the key' validate do |value| path = Pathname.new(value) unless path.absolute? raise ArgumentError, ""Path must be absolute: #{path}"" end end end newparam(:authentication) do desc ""The authentication algorithm: 'rsa' or 'dsa'"" newvalues /[dr]sa/ defaultto :rsa end newparam(:size) do desc 'The key size' newvalues /\d+/ defaultto 2048 end newparam(:password) do desc 'The optional password for the key' end end ",,2502,0
openstack%2Fnova~proposed%2Fjuno~Idd7d5a055600dda663f9c56b39883510f8688b12,openstack/nova,proposed/juno,Idd7d5a055600dda663f9c56b39883510f8688b12,move integrated api client to requests library,MERGED,2014-10-04 10:32:41.000000000,2014-10-07 10:14:35.000000000,2014-10-07 10:14:34.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 7166}]","[{'number': 1, 'created': '2014-10-04 10:32:41.000000000', 'files': ['nova/tests/integrated/test_extensions.py', 'nova/tests/integrated/v3/test_shelve.py', 'nova/tests/integrated/test_xml.py', 'nova/tests/integrated/v3/test_lock_server.py', 'nova/tests/integrated/api/client.py', 'nova/tests/integrated/api_samples_test_base.py', 'nova/tests/integrated/v3/test_servers.py', 'nova/tests/integrated/v3/test_flavor_extraspecs.py', 'nova/tests/integrated/v3/test_migrations.py', 'nova/tests/integrated/v3/test_rescue.py', 'nova/tests/integrated/v3/test_create_backup.py', 'nova/tests/integrated/v3/test_quota_sets.py', 'nova/tests/integrated/v3/test_multinic.py', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/integrated/v3/test_admin_password.py', 'nova/tests/integrated/v3/test_admin_actions.py', 'nova/tests/integrated/v3/test_agents.py', 'nova/tests/integrated/v3/test_suspend_server.py', 'nova/tests/integrated/v3/test_volumes.py', 'nova/tests/integrated/v3/test_pause_server.py', 'nova/tests/integrated/v3/test_server_groups.py', 'nova/tests/integrated/v3/test_console_auth_tokens.py', 'nova/tests/integrated/v3/test_deferred_delete.py', 'nova/tests/integrated/v3/test_extended_volumes.py', 'nova/tests/integrated/v3/test_server_metadata.py', 'nova/tests/integrated/v3/test_consoles.py', 'nova/tests/integrated/v3/test_services.py', 'nova/tests/integrated/v3/test_attach_interfaces.py', 'nova/tests/integrated/v3/test_extension_info.py', 'nova/tests/integrated/v3/test_migrate_server.py', 'nova/tests/integrated/v3/test_flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7caf12e258f01bf0811302bbe0d47dd40b56e6f0', 'message': ""move integrated api client to requests library\n\nThe integrated api client previously did the HTTPConnection /\nHTTPSConnection url parsing dance. In python 2.x HTTPSConnection\ndoesn't care about SSL certs at all. While not actually an issue for\nthese tests, it does mean we keep around an example in the code that\nuses HTTPSConnection, which will prevent us from creating a hacking\nrule to keep those out once the other 4 actual security issues with\nHTTPSConnection are removed.\n\nChange-Id: Idd7d5a055600dda663f9c56b39883510f8688b12\nRelated-Bug: #1188189\n(cherry picked from commit 777a5870c9f29949e6af704bfa03c2e204065ab1)\n""}]",0,126138,7caf12e258f01bf0811302bbe0d47dd40b56e6f0,8,3,1,2750,,,0,"move integrated api client to requests library

The integrated api client previously did the HTTPConnection /
HTTPSConnection url parsing dance. In python 2.x HTTPSConnection
doesn't care about SSL certs at all. While not actually an issue for
these tests, it does mean we keep around an example in the code that
uses HTTPSConnection, which will prevent us from creating a hacking
rule to keep those out once the other 4 actual security issues with
HTTPSConnection are removed.

Change-Id: Idd7d5a055600dda663f9c56b39883510f8688b12
Related-Bug: #1188189
(cherry picked from commit 777a5870c9f29949e6af704bfa03c2e204065ab1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/126138/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/test_extensions.py', 'nova/tests/integrated/v3/test_shelve.py', 'nova/tests/integrated/test_xml.py', 'nova/tests/integrated/v3/test_lock_server.py', 'nova/tests/integrated/api/client.py', 'nova/tests/integrated/api_samples_test_base.py', 'nova/tests/integrated/v3/test_servers.py', 'nova/tests/integrated/v3/test_flavor_extraspecs.py', 'nova/tests/integrated/v3/test_migrations.py', 'nova/tests/integrated/v3/test_rescue.py', 'nova/tests/integrated/v3/test_create_backup.py', 'nova/tests/integrated/v3/test_quota_sets.py', 'nova/tests/integrated/v3/test_multinic.py', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/integrated/v3/test_admin_password.py', 'nova/tests/integrated/v3/test_admin_actions.py', 'nova/tests/integrated/v3/test_agents.py', 'nova/tests/integrated/v3/test_suspend_server.py', 'nova/tests/integrated/v3/test_volumes.py', 'nova/tests/integrated/v3/test_pause_server.py', 'nova/tests/integrated/v3/test_server_groups.py', 'nova/tests/integrated/v3/test_console_auth_tokens.py', 'nova/tests/integrated/v3/test_deferred_delete.py', 'nova/tests/integrated/v3/test_extended_volumes.py', 'nova/tests/integrated/v3/test_server_metadata.py', 'nova/tests/integrated/v3/test_consoles.py', 'nova/tests/integrated/v3/test_services.py', 'nova/tests/integrated/v3/test_attach_interfaces.py', 'nova/tests/integrated/v3/test_extension_info.py', 'nova/tests/integrated/v3/test_migrate_server.py', 'nova/tests/integrated/v3/test_flavor_manage.py']",31,7caf12e258f01bf0811302bbe0d47dd40b56e6f0,," self.assertEqual(response.status_code, 202) self.assertEqual(response.content, '')"," self.assertEqual(response.status, 202) self.assertEqual(response.read(), '')",173,201
openstack%2Ffuel-library~master~Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b,openstack/fuel-library,master,Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b,Fixed issue with max size for Swift objects,MERGED,2014-09-25 09:46:29.000000000,2014-10-07 10:14:20.000000000,2014-10-07 10:14:20.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6904}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7227}, {'_account_id': 7468}, {'_account_id': 7562}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-25 09:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ff18ded3dc404e4c70a610a9d38c6fa73ee9df0d', 'message': ""Fixed issue with max size for swift objects\n\nFixed issue with max size of object, which Glance\nshould store in swift without slicing.\nDefault value doesn't work when user attempts to make\na snapshots with size > 300 Mb.\n\nChange-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b\nCloses-Bug: #1373813\n""}, {'number': 2, 'created': '2014-09-25 14:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/852c560ef6d210621c4151f0cd65501381263f2b', 'message': ""Fixed issue with max size for swift objects\n\nFixed issue with max size of object, which Glance\nshould store in swift without slicing.\nDefault value doesn't work when user attempts to make\na snapshots with size > 300 Mb.\n\nChange-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b\nCloses-Bug: #1373813\n""}, {'number': 3, 'created': '2014-09-25 14:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c7823db257e5cf5daff359eb5ea1dcc56e8eac4e', 'message': ""Fixed issue with max size for Swift objects\n\nFixed issue with max size of object, which Glance\nshould store in Swift without slicing.\nDefault value doesn't work when user attempts to make\na snapshots with size > 300 Mb.\n\nChange-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b\nCloses-Bug: #1373813\n""}, {'number': 4, 'created': '2014-09-26 00:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d61271ae5be1fc44c741b7e90e8a9413603cd56', 'message': ""Fixed issue with max size for Swift objects\n\nFixed issue with max size of object, which Glance\nshould store in Swift without slicing.\nDefault value doesn't work when user attempts to make\na snapshots with size > 300 Mb.\n\nChange-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b\nCloses-Bug: #1373813\n""}, {'number': 5, 'created': '2014-09-30 11:21:08.000000000', 'files': ['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/glance/spec/classes/glance_backend_swift_spec.rb', 'deployment/puppet/glance/manifests/backend/swift.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5efc17969ab66b54f5daf9472d8cad30fce9c9be', 'message': ""Fixed issue with max size for Swift objects\n\nFixed issue with max size of object, which Glance\nshould store in Swift without slicing.\nDefault value doesn't work when user attempts to make\na snapshots with size > 300 Mb.\n\nChange-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b\nCloses-Bug: #1373813\n""}]",4,123992,5efc17969ab66b54f5daf9472d8cad30fce9c9be,44,18,5,7227,,,0,"Fixed issue with max size for Swift objects

Fixed issue with max size of object, which Glance
should store in Swift without slicing.
Default value doesn't work when user attempts to make
a snapshots with size > 300 Mb.

Change-Id: Ic3b3120605f1e1536a34bedc4ad5c0c2f4c8510b
Closes-Bug: #1373813
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/92/123992/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/glance/spec/classes/glance_backend_swift_spec.rb'],1,ff18ded3dc404e4c70a610a9d38c6fa73ee9df0d,bug/1373813, should contain_glance_api_config('DEFAULT/swift_store_large_object_size').with_value('200'),,1,0
openstack%2Ftripleo-ci~master~I2803c073d9cf7f3416c6623f19f6a879fdade61d,openstack/tripleo-ci,master,I2803c073d9cf7f3416c6623f19f6a879fdade61d,"Perform heat stack-show, event-list on test fail",MERGED,2014-10-06 16:46:07.000000000,2014-10-07 10:12:49.000000000,2014-10-07 10:12:49.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8411}, {'_account_id': 8532}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-10-06 16:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b2b0a2e1610ccf1d12bbbd88dceae80602752e4c', 'message': 'Perform heat stack-show on test failure\n\nThis is very useful information for debugging.\n\nChange-Id: I2803c073d9cf7f3416c6623f19f6a879fdade61d\n'}, {'number': 2, 'created': '2014-10-06 16:52:38.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7a49c7bd828986e17b7c39624d3be73d885840ba', 'message': 'Perform heat stack-show, event-list on test fail\n\nThis is very useful information for debugging.\n\nChange-Id: I2803c073d9cf7f3416c6623f19f6a879fdade61d\n'}]",0,126350,7a49c7bd828986e17b7c39624d3be73d885840ba,15,8,2,10035,,,0,"Perform heat stack-show, event-list on test fail

This is very useful information for debugging.

Change-Id: I2803c073d9cf7f3416c6623f19f6a879fdade61d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/126350/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,b2b0a2e1610ccf1d12bbbd88dceae80602752e4c,feature/stack-show-on-fail, heat stack-show $TRIPLEO_TEST,,1,0
openstack%2Ffuel-library~master~Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4,openstack/fuel-library,master,Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4,Set container time to UTC,MERGED,2014-09-22 12:52:49.000000000,2014-10-07 10:12:11.000000000,2014-10-07 10:12:11.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-09-22 12:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/82e65f76e50750bbf34e7f0182e352f05eb81132', 'message': 'Set container time to UTC\n\nCreate new class docker::container for\nrelated tweaks necessary to apply to all\nDocker containers.\n\nChange-Id: Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4\nCloses-bug: #1372439\n'}, {'number': 2, 'created': '2014-09-22 15:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/98a932f5fe2151ba51ff12ecec87d84da9a0d5cb', 'message': 'Set container time to UTC\n\nCreate new class docker::container for\nrelated tweaks necessary to apply to all\nDocker containers.\n\nChange-Id: Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4\nCloses-bug: #1372439\n'}, {'number': 3, 'created': '2014-09-23 08:34:06.000000000', 'files': ['deployment/puppet/nailgun/examples/rsyslog-only.pp', 'deployment/puppet/nailgun/examples/nginx-only.pp', 'deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/examples/astute-only.pp', 'deployment/puppet/nailgun/examples/rabbitmq-only.pp', 'deployment/puppet/docker/manifests/container.pp', 'deployment/puppet/nailgun/examples/ostf-only.pp', 'deployment/puppet/nailgun/examples/postgres-only.pp', 'deployment/puppet/nailgun/examples/keystone-only.pp', 'deployment/puppet/nailgun/examples/cobbler-only.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b4aaee7e238b6e2913e01fe3eec1c8b2575c4a52', 'message': 'Set container time to UTC\n\nCreate new class docker::container for\nrelated tweaks necessary to apply to all\nDocker containers.\n\nChange-Id: Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4\nCloses-bug: #1372439\n'}]",2,123116,b4aaee7e238b6e2913e01fe3eec1c8b2575c4a52,28,8,3,7195,,,0,"Set container time to UTC

Create new class docker::container for
related tweaks necessary to apply to all
Docker containers.

Change-Id: Ibba7bf58da0aac1d760d3550edb9a9508d71b1c4
Closes-bug: #1372439
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/16/123116/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/examples/rsyslog-only.pp', 'deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/examples/nginx-only.pp', 'deployment/puppet/nailgun/examples/astute-only.pp', 'deployment/puppet/nailgun/examples/rabbitmq-only.pp', 'deployment/puppet/docker/manifests/container.pp', 'deployment/puppet/nailgun/examples/ostf-only.pp', 'deployment/puppet/nailgun/examples/postgres-only.pp', 'deployment/puppet/nailgun/examples/keystone-only.pp', 'deployment/puppet/nailgun/examples/cobbler-only.pp']",10,82e65f76e50750bbf34e7f0182e352f05eb81132,container-tweaks, class { 'docker::container': },,30,1
openstack%2Fnova~proposed%2Fjuno~I0b8e6319a4cc39876b1e396ef705f0fc5def1e44,openstack/nova,proposed/juno,I0b8e6319a4cc39876b1e396ef705f0fc5def1e44,Fix unsafe SSL connection on TrustedFilter,MERGED,2014-10-04 10:32:41.000000000,2014-10-07 10:10:20.000000000,2014-10-07 10:10:18.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 7166}]","[{'number': 1, 'created': '2014-10-04 10:32:41.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cc88417637e4967860619e8d7e43f5d28957fcda', 'message': ""Fix unsafe SSL connection on TrustedFilter\n\nTrustedFilter was using httplib which doesn't check for CAs.\nHere the change is using Requests and verifies local CAs by default (or another\none if provided)\nThis effort is related to CVE 2013-2255.\n\nSecurityImpact\n\nCloses-Bug: #1373993\n\nChange-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44\n(cherry picked from commit 30871e8702737edbbfbcbbb5f21858873b37685c)\n""}]",0,126137,cc88417637e4967860619e8d7e43f5d28957fcda,8,3,1,2750,,,0,"Fix unsafe SSL connection on TrustedFilter

TrustedFilter was using httplib which doesn't check for CAs.
Here the change is using Requests and verifies local CAs by default (or another
one if provided)
This effort is related to CVE 2013-2255.

SecurityImpact

Closes-Bug: #1373993

Change-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44
(cherry picked from commit 30871e8702737edbbfbcbbb5f21858873b37685c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/126137/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py']",2,cc88417637e4967860619e8d7e43f5d28957fcda,,"import requests cfg.BoolOpt('attestation_insecure_ssl', default=False, help='Disable SSL cert verification for Attestation service') # If the CA file is not provided, let's check the cert if verification # asked self.verify = (not CONF.trusted_computing.attestation_insecure_ssl and self.ca_file or True) self.cert = (self.cert_file, self.key_file) action_url = ""https://%s:%d%s/%s"" % (self.host, self.port, self.api_url, action_url) try: res = requests.request(method, action_url, data=body, headers=headers, cert=self.cert, verify=self.verify) status_code = res.status_code # pylint: disable=E1101 if status_code in (requests.codes.OK, requests.codes.CREATED, requests.codes.ACCEPTED, requests.codes.NO_CONTENT): try: return requests.codes.OK, jsonutils.loads(res.text) except ValueError: return requests.codes.OK, res.text except requests.exceptions.RequestException: return status, res","import httplib import socket import ssl class HTTPSClientAuthConnection(httplib.HTTPSConnection): """"""Class to make a HTTPS connection, with support for full client-based SSL Authentication """""" def __init__(self, host, port, key_file, cert_file, ca_file, timeout=None): httplib.HTTPSConnection.__init__(self, host, key_file=key_file, cert_file=cert_file) self.host = host self.port = port self.key_file = key_file self.cert_file = cert_file self.ca_file = ca_file self.timeout = timeout def connect(self): """"""Connect to a host on a given (SSL) port. If ca_file is pointing somewhere, use it to check Server Certificate. Redefined/copied and extended from httplib.py:1105 (Python 2.6.x). This is needed to pass cert_reqs=ssl.CERT_REQUIRED as parameter to ssl.wrap_socket(), which forces SSL to check server certificate against our client certificate. """""" sock = socket.create_connection((self.host, self.port), self.timeout) self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ca_certs=self.ca_file, cert_reqs=ssl.CERT_REQUIRED) action_url = ""%s/%s"" % (self.api_url, action_url) try: c = HTTPSClientAuthConnection(self.host, self.port, key_file=self.key_file, cert_file=self.cert_file, ca_file=self.ca_file) c.request(method, action_url, body, headers) res = c.getresponse() status_code = res.status if status_code in (httplib.OK, httplib.CREATED, httplib.ACCEPTED, httplib.NO_CONTENT): return httplib.OK, res except (socket.error, IOError): if status == httplib.OK: data = res.read() return status, jsonutils.loads(data) else: return status, None",28,57
openstack%2Ftripleo-image-elements~master~Ie27327286524ed93326ae49c7ca420809fb553a1,openstack/tripleo-image-elements,master,Ie27327286524ed93326ae49c7ca420809fb553a1,Change initial state and failback policy for VIP,MERGED,2014-10-03 16:27:42.000000000,2014-10-07 10:08:00.000000000,2014-10-07 10:08:00.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-10-03 16:27:42.000000000', 'files': ['elements/keepalived/os-apply-config/etc/keepalived/keepalived.conf', 'elements/keepalived/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e1e739049b8db8d34a16a9e1806b4cc78fd7853b', 'message': 'Change initial state and failback policy for VIP\n\nThis change is to reduce VIP transition.\nThe current defaults cause the VIP to automatically\nfailback to a higher priority controller or one with\na higher IP if priorities are the same ( which they are\nby default) This change enables nopreempt by default,\nthereby disabling automatic failback when a higher priority\ncontroller becomes available.  It also changes the\ndefault initial state to BACKUP (required for nopreempt).\n\nThere are also two new configurables:\n\n   keepalived.state        - BACKUP\n   keepalived.preempt      - false\n\nUse keepalived.state=MASTER,keepalived.preempt=true for\noriginal behaviour.\n\nChange-Id: Ie27327286524ed93326ae49c7ca420809fb553a1\n'}]",0,126009,e1e739049b8db8d34a16a9e1806b4cc78fd7853b,8,3,1,1872,,,0,"Change initial state and failback policy for VIP

This change is to reduce VIP transition.
The current defaults cause the VIP to automatically
failback to a higher priority controller or one with
a higher IP if priorities are the same ( which they are
by default) This change enables nopreempt by default,
thereby disabling automatic failback when a higher priority
controller becomes available.  It also changes the
default initial state to BACKUP (required for nopreempt).

There are also two new configurables:

   keepalived.state        - BACKUP
   keepalived.preempt      - false

Use keepalived.state=MASTER,keepalived.preempt=true for
original behaviour.

Change-Id: Ie27327286524ed93326ae49c7ca420809fb553a1
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/09/126009/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/keepalived/os-apply-config/etc/keepalived/keepalived.conf', 'elements/keepalived/README.md']",2,e1e739049b8db8d34a16a9e1806b4cc78fd7853b,, # initial state MASTER|BACKUP state: BACKUP # enable/disable autofailback on higher # priority ip being available preempt: false ,,15,1
openstack%2Ftripleo-incubator~master~I40ac243a5c9d97264accbefe4ce96497914b6b01,openstack/tripleo-incubator,master,I40ac243a5c9d97264accbefe4ce96497914b6b01,Wait for memory and vcpus from hypervisor stats,MERGED,2014-09-25 16:35:12.000000000,2014-10-07 10:07:08.000000000,2014-10-07 10:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-09-25 16:35:12.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e14e05e51351b4273023c57e3b9149063774ac56', 'message': 'Wait for memory and vcpus from hypervisor stats\n\nBuilding on what was added in I43d72cc0d2c1ded70af28d9861aa6e28838795bf,\nthis makes use of the new memory and vcpu parameters in\nwait_for_hypervisor_stats to make sure that the script checks the\ncorrect memory amount and vcpu count are available.\n\nChange-Id: I40ac243a5c9d97264accbefe4ce96497914b6b01\n'}]",3,124105,e14e05e51351b4273023c57e3b9149063774ac56,14,8,1,7144,,,0,"Wait for memory and vcpus from hypervisor stats

Building on what was added in I43d72cc0d2c1ded70af28d9861aa6e28838795bf,
this makes use of the new memory and vcpu parameters in
wait_for_hypervisor_stats to make sure that the script checks the
correct memory amount and vcpu count are available.

Change-Id: I40ac243a5c9d97264accbefe4ce96497914b6b01
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/05/124105/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,e14e05e51351b4273023c57e3b9149063774ac56,hypervisor-stats,"expected_memory=$(jq "".nodes | map(.memory | tonumber) | add"" $TE_DATAFILE) expected_vcpus=$(jq "".nodes | map(.cpu | tonumber) | add"" $TE_DATAFILE) wait_for 60 1 wait_for_hypervisor_stats $expected_nodes $expected_memory $expected_vcpus",wait_for 60 1 wait_for_hypervisor_stats $expected_nodes,3,1
openstack%2Ffuel-web~master~I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a,openstack/fuel-web,master,I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a,[React] Assign Roles panel,MERGED,2014-09-17 14:57:59.000000000,2014-10-07 10:06:23.000000000,2014-10-07 10:06:21.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-09-17 14:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e4e62227042722baa5b86473eb955e6f448e865d', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 2, 'created': '2014-09-19 13:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4ad6bd1d7a739a085833dd01d3edf43bdb1795e1', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 3, 'created': '2014-09-22 09:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e9fb795ccc9799e03220eae7ba8bceb1d8009071', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 4, 'created': '2014-09-22 09:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d09705a9284ecc8b2d1b711fe968793467efb3dc', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 5, 'created': '2014-09-22 11:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a96a4b97b08cc8eed724917cf3200eca235d9a0f', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 6, 'created': '2014-09-22 11:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5172d956ad14ec787a4444b03dff9ca66f0a3dfe', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 7, 'created': '2014-09-23 06:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/342a000122466dbdc4a65c3d51d135557d9f8f36', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 8, 'created': '2014-09-29 15:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2d50797518112e1af9e95fd6057de603eb7ed156', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 9, 'created': '2014-10-01 11:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/063ed51cf7c2113008aa7d53558bc6b0ed05fc8b', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 10, 'created': '2014-10-02 12:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0150458cf84c6814db4c34f5329a7cdf0fe7cef3', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 11, 'created': '2014-10-06 12:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ce76db6a2de8abcf68a75bbbc59de2fbc5676b8d', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 12, 'created': '2014-10-06 12:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8da3cc827e127e5d8dbcd0d198e4b276361ccb2f', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}, {'number': 13, 'created': '2014-10-06 15:07:36.000000000', 'files': ['nailgun/static/i18n/translation.json', 'nailgun/static/templates/cluster/assign_roles_panel.html', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/css/styles.less', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/nodes_tab_subviews.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js', 'nailgun/static/js/views/controls.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2310883595b242f19c0038c50f45d7d3bc62219b', 'message': '[React] Assign Roles panel\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a\n'}]",10,122173,2310883595b242f19c0038c50f45d7d3bc62219b,89,7,13,8766,,,0,"[React] Assign Roles panel

Related to blueprint backbone-to-react

Change-Id: I8a3c5a873dc5766a868e2b80ceacd0a3cbb1df2a
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/73/122173/12 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/css/styles.less', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/nodes_tab_subviews.jsx', 'nailgun/static/js/models.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js']",6,e4e62227042722baa5b86473eb955e6f448e865d,bp/backbone-to-react," 'jsx!views/cluster_page_tabs/nodes_tab_screens/nodes_tab_subviews',function(utils, models, dialogs, panels, Screen, nodesManagementPanelTemplate, nodeListTemplate, nodeGroupTemplate, nodeTemplate, nodeRoleTemplate) { var NodeListScreen, NodesManagementPanel, NodeList, NodeGroup, Node; this.nodes.on('change:pending_roles', function(node, roles, options) { this.actualizePendingRoles(node, roles, options); this.calculateApplyButtonState(); }, this); this.$el.append($('<div/>').addClass('roles-panel')); this.roles = utils.universalMount(new panels.RolesPanel({ cluster: this.model, nodes: this.nodes }), this.$('.roles-panel'), this); var dialog = new dialogs.DeleteNodesDialog({nodes: nodes}); var dialog = new dialogs.ShowNodeInfoDialog({node: this.node}); this.node.on('change:checked', this.screen.roles.assignRoles, this.screen.roles);"," 'text!templates/cluster/assign_roles_panel.html',function(utils, models, dialogViews, Screen, nodesManagementPanelTemplate, assignRolesPanelTemplate, nodeListTemplate, nodeGroupTemplate, nodeTemplate, nodeRoleTemplate) { var NodeListScreen, NodesManagementPanel, AssignRolesPanel, NodeList, NodeGroup, Node; this.nodes.on('change:pending_roles', this.actualizePendingRoles, this); this.roles = new AssignRolesPanel(options); this.registerSubView(this.roles); this.$el.append(this.roles.render().el); var dialog = new dialogViews.DeleteNodesDialog({nodes: nodes}); AssignRolesPanel = Backbone.View.extend({ template: _.template(assignRolesPanelTemplate), className: 'roles-panel', handleChanges: function() { this.nodes = new models.Nodes(this.screen.nodes.where({checked: true})); this.assignRoles(); this.checkForConflicts(); this.screen.calculateApplyButtonState(); }, assignRoles: function() { _.each(this.collection.where({indeterminate: false}), function(role) { _.each(this.nodes.filter(function(node) {return !node.hasRole(role.get('name'), true);}), function(node) { var pending_roles = role.get('checked') ? _.uniq(_.union(node.get('pending_roles'), role.get('name'))) : _.difference(node.get('pending_roles'), role.get('name')); node.set({pending_roles: pending_roles}, {assign: true}); }); }, this); }, isRoleSelected: function(roleName) { return this.collection.filter(function(role) {return role.get('name') == roleName && (role.get('checked') || role.get('indeterminate'));}).length; }, isControllerSelectable: function(role) { var allocatedController = this.cluster.get('nodes').filter(function(node) {return !node.get('pending_deletion') && node.hasRole('controller') && !_.contains(this.nodes.pluck('id'), node.id);}, this); return role.get('name') != 'controller' || this.cluster.get('mode') != 'multinode' || ((this.isRoleSelected('controller') || this.screen.nodes.where({checked: true}).length <= 1) && !allocatedController.length); }, isMongoSelectable: function(role) { var deployedNodes = this.cluster.get('nodes').filter(function(node) { return node.hasRole('mongo', true) && !node.get('pending_deletion'); }); return role.get('name') != 'mongo' || !deployedNodes.length; }, isZabbixSelectable: function(role) { var allocatedZabbix = this.cluster.get('nodes').filter(function(node) {return !node.get('pending_deletion') && node.hasRole('zabbix-server') && !_.contains(this.nodes.pluck('id'), node.id);}, this); return role.get('name') != 'zabbix-server' || ((this.isRoleSelected('zabbix-server') || this.screen.nodes.where({checked: true}).length <= 1) && !allocatedZabbix.length); }, getListOfIncompatibleRoles: function(roles) { var forbiddenRoles = []; _.each(roles, function(role) { forbiddenRoles = _.union(forbiddenRoles, this.conflictingRoles[role.get('name')]); }, this); return _.uniq(forbiddenRoles); }, checkForConflicts: function(e) { this.collection.each(function(role) { var conflict = ''; var disabled = !this.screen.nodes.length || this.loading.state() == 'pending'; // checking if role is unavailable if (!disabled && role.get('unavailable')) { disabled = true; conflict = role.get('unavailabityReason'); } // checking if role conflict with another role if (!disabled) { var selectedRoles = this.collection.filter(function(role) {return role.get('checked') || role.get('indeterminate');}); var roleConflictsWithAnotherRole = _.contains(this.getListOfIncompatibleRoles(selectedRoles), role.get('name')); if (roleConflictsWithAnotherRole) { disabled = true; conflict = $.t('cluster_page.nodes_tab.incompatible_roles_warning'); } } // checking controller role conditions if (!disabled && !this.isControllerSelectable(role)) { disabled = true; conflict = $.t('cluster_page.nodes_tab.one_controller_restriction'); } // checking mongo role restriction if (!disabled && !this.isMongoSelectable(role)) { disabled = true; conflict = $.t('cluster_page.nodes_tab.mongo_restriction'); } // checking zabbix role conditions if (!disabled && !this.isZabbixSelectable(role)) { disabled = true; conflict = $.t('cluster_page.nodes_tab.one_zabbix_restriction'); } role.set({disabled: disabled, conflict: conflict}); }, this); if (this.screen.nodeList) { var controllerNode = this.nodes.filter(function(node) {return node.hasRole('controller');})[0]; var zabbixNode = this.nodes.filter(function(node) {return node.hasRole('zabbix-server');})[0]; _.each(this.screen.nodes.where({checked: false}), function(node) { var isControllerAssigned = this.cluster.get('mode') == 'multinode' && this.isRoleSelected('controller') && controllerNode && controllerNode.id != node.id; var isZabbixAssigned = this.isRoleSelected('zabbix-server') && zabbixNode && zabbixNode.id != node.id; var disabled = isControllerAssigned || isZabbixAssigned || !node.isSelectable() || this.screen instanceof this.screen.EditNodesScreen || this.screen.isLocked(); node.set('disabled', disabled); var filteredNode = this.screen.nodeList.filteredNodes.get(node.id); if (filteredNode) { filteredNode.set('disabled', disabled); } }, this); this.screen.nodeList.calculateSelectAllDisabledState(); _.invoke(this.screen.nodeList.subViews, 'calculateSelectAllDisabledState', this); } }, getRoleData: function(role) { return this.cluster.get('release').get('roles_metadata')[role]; }, checkRolesAvailability: function() { this.collection.each(function(role) { var unavailable = false; var visible = true; var unavailabityReasons = []; var dependencies = this.getRoleData(role.get('name')).depends; if (dependencies) { var configModels = { cluster: this.cluster, settings: this.settings, version: app.version, default: this.settings }; _.each(_.map(dependencies, utils.expandRestriction), function(dependency) { if (!utils.evaluateExpression(dependency.condition, configModels).value) { unavailable = true; unavailabityReasons.push(dependency.warning); if (dependency.action == 'hide') { visible = false; } } }); } // FIXME(vk): hack for vCenter, do not allow ceph and controllers // has to be removed when we describe it in role metadata if (this.settings.get('common.libvirt_type.value') == 'vcenter') { if (role.get('name') == 'compute') { unavailable = true; unavailabityReasons.push('Computes cannot be used with vCenter'); } else if (role.get('name') == 'ceph-osd') { unavailable = true; unavailabityReasons.push('Ceph cannot be used with vCenter'); } } if (unavailable) { role.set({unavailable: true, unavailabityReason: unavailabityReasons.join(' ')}); } role.set({visible: visible}); }, this); }, initialize: function(options) { _.defaults(this, options); this.cluster = this.screen.tab.model; this.collection = new Backbone.Collection(_.map(this.cluster.get('release').get('roles'), function(role) { var roleData = this.getRoleData(role); var nodesWithRole = this.nodes.filter(function(node) {return node.hasRole(role);}); return { name: role, label: roleData.name, description: roleData.description, disabled: false, unavailable: false, visible: true, conflict: '', checked: !!nodesWithRole.length && nodesWithRole.length == this.nodes.length, indeterminate: !!nodesWithRole.length && nodesWithRole.length != this.nodes.length }; }, this)); this.collection.on('change:checked', this.handleChanges, this); this.settings = this.cluster.get('settings'); (this.loading = this.settings.fetch({cache: true})).done(_.bind(function() { this.processConflictingRoles(); this.checkRolesAvailability(); this.checkForConflicts(); }, this)); }, processConflictingRoles: function() { var rolesMetadata = this.cluster.get('release').get('roles_metadata'); this.conflictingRoles = {}; _.each(rolesMetadata, function(roleData, roleName) { var conflicts = roleData.conflicts; if (conflicts) { this.conflictingRoles[roleName] = _.uniq(_.union(this.conflictingRoles[roleName], conflicts)); _.each(conflicts, function(conflict) { this.conflictingRoles[conflict] = this.conflictingRoles[conflict] || []; this.conflictingRoles[conflict].push(roleName); }, this); } }, this); }, stickitRole: function (role) { var bindings = {}; bindings['input[name=' + role.get('name') + ']'] = { observe: 'checked', visible: function() { return role.get('visible'); }, visibleFn: function($el, isVisible) { $el.parents('.role-container').toggle(isVisible); }, onSet: function(value) { role.set('indeterminate', false); return value; }, attributes: [{ name: 'disabled', observe: 'disabled' },{ name: 'indeterminate', observe: 'indeterminate' }] }; bindings['.role-conflict.' + role.get('name')] = 'conflict'; return this.stickit(role, bindings); }, render: function() { this.$el.html(this.template({roles: this.collection})).i18n(); this.collection.each(this.stickitRole, this); this.checkForConflicts(); return this; } }); var dialog = new dialogViews.ShowNodeInfoDialog({node: this.node}); this.node.on('change:checked', this.screen.roles.handleChanges, this.screen.roles);",213,229
openstack%2Ftripleo-image-elements~master~I7faa97243c9a686badd8d11ec001480ecab4af50,openstack/tripleo-image-elements,master,I7faa97243c9a686badd8d11ec001480ecab4af50,Secure the MySQL bind-address on the seed,MERGED,2014-10-06 16:37:25.000000000,2014-10-07 09:59:52.000000000,2014-10-07 09:59:52.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}]","[{'number': 1, 'created': '2014-10-06 16:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8171e57e666d19e73ba550dd404c44d71cde6d3f', 'message': 'Secure the MySQL bind-address on the seed\n\nThe MySQL bind-address on the seed should be set to\nlocalhost for security.  Introduce a mysql.bind_address\nto configure this for the seed. (mysql.local_bind sets\nthe bind address to the local IP for the overcloud)\n\nChange-Id: I7faa97243c9a686badd8d11ec001480ecab4af50\n'}, {'number': 2, 'created': '2014-10-06 17:01:08.000000000', 'files': ['elements/mysql-common/os-apply-config/mnt/state/etc/mysql/my.cnf', 'elements/seed-stack-config/config.json'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/43c472d146f2f370518181b220131ccfa1d32971', 'message': 'Secure the MySQL bind-address on the seed\n\nThe MySQL bind-address on the seed should be set to\nlocalhost for security.  Introduce a mysql.bind_address\nto configure this for the seed. (mysql.local_bind sets\nthe bind address to the local IP for the overcloud)\n\nChange-Id: I7faa97243c9a686badd8d11ec001480ecab4af50\n'}]",0,126348,43c472d146f2f370518181b220131ccfa1d32971,12,3,2,1872,,,0,"Secure the MySQL bind-address on the seed

The MySQL bind-address on the seed should be set to
localhost for security.  Introduce a mysql.bind_address
to configure this for the seed. (mysql.local_bind sets
the bind address to the local IP for the overcloud)

Change-Id: I7faa97243c9a686badd8d11ec001480ecab4af50
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/48/126348/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql-common/os-apply-config/mnt/state/etc/mysql/my.cnf', 'elements/seed-stack-config/config.json']",2,8171e57e666d19e73ba550dd404c44d71cde6d3f,," ""bind_address"" : ""127.0.0.1""",,6,0
openstack%2Fceilometer~master~Idb1dade44a06c71fb5e64ca875b71633def110a5,openstack/ceilometer,master,Idb1dade44a06c71fb5e64ca875b71633def110a5,Eliminate unnecessary search for test cases,MERGED,2014-09-12 04:05:13.000000000,2014-10-07 09:59:32.000000000,2014-10-07 09:59:31.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 10987}, {'_account_id': 12119}]","[{'number': 1, 'created': '2014-09-12 04:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d2295e6f5c083612820bbb61f3d94af425eb07b7', 'message': 'Eliminate unnecessary search for test cases\n\nAs all unit tests lie in `ceilometer/ceilometer/tests`, the test_command should use `ceilometer/tests` instead of `ceilometer`.\n\nChange-Id: Idb1dade44a06c71fb5e64ca875b71633def110a5\nCloses-Bug: 1368509\n'}, {'number': 2, 'created': '2014-09-16 06:22:47.000000000', 'files': ['.testr.conf'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dd772619e8722612a68f0b27787e6cc662e7654a', 'message': 'Eliminate unnecessary search for test cases\n\nAs all unit tests lie in `ceilometer/ceilometer/tests`,\nthe test_command should use `ceilometer/tests` instead of `ceilometer`.\n\nChange-Id: Idb1dade44a06c71fb5e64ca875b71633def110a5\nCloses-Bug: 1368509\n'}]",0,120969,dd772619e8722612a68f0b27787e6cc662e7654a,23,9,2,12119,,,0,"Eliminate unnecessary search for test cases

As all unit tests lie in `ceilometer/ceilometer/tests`,
the test_command should use `ceilometer/tests` instead of `ceilometer`.

Change-Id: Idb1dade44a06c71fb5e64ca875b71633def110a5
Closes-Bug: 1368509
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/69/120969/2 && git format-patch -1 --stdout FETCH_HEAD,['.testr.conf'],1,d2295e6f5c083612820bbb61f3d94af425eb07b7,bug/1368509, ${PYTHON:-python} -m subunit.run discover ceilometer/tests -t . $LISTOPT $IDOPTION, ${PYTHON:-python} -m subunit.run discover ceilometer -t . $LISTOPT $IDOPTION,1,1
openstack%2Ffuel-web~master~Ia545dd90fd7e8b3b2de7280088bd07c689b1adb7,openstack/fuel-web,master,Ia545dd90fd7e8b3b2de7280088bd07c689b1adb7,provide UI control for NSX plugin 'replication_mode' setting,MERGED,2014-10-03 12:53:23.000000000,2014-10-07 09:58:08.000000000,2014-10-07 09:58:08.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-10-03 12:53:23.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0ba6bf46f0f8ec598aa6b061ebf843f756b125ba', 'message': ""provide UI control for NSX plugin 'replication_mode' setting\n\n- NSX cluster can operate without NSX Service nodes, but this requires\n  configuration of `replication_mode' setting, so lets add an\n  opportunity for user to specify that his NSX cluster runs in testing\n  mode (without Service nodes).\n\nChange-Id: Ia545dd90fd7e8b3b2de7280088bd07c689b1adb7\nPartial-bug: #1365043\n""}]",0,125961,0ba6bf46f0f8ec598aa6b061ebf843f756b125ba,9,5,1,11427,,,0,"provide UI control for NSX plugin 'replication_mode' setting

- NSX cluster can operate without NSX Service nodes, but this requires
  configuration of `replication_mode' setting, so lets add an
  opportunity for user to specify that his NSX cluster runs in testing
  mode (without Service nodes).

Change-Id: Ia545dd90fd7e8b3b2de7280088bd07c689b1adb7
Partial-bug: #1365043
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/125961/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,0ba6bf46f0f8ec598aa6b061ebf843f756b125ba,bug/1365043," replication_mode: description: """" label: ""NSX cluster has Service nodes"" value: true type: ""checkbox"" weight: 90",,6,0
openstack%2Ftempest-lib~master~Ie16fdf75b69006cf48ad9b2649c4bf3659901b80,openstack/tempest-lib,master,Ie16fdf75b69006cf48ad9b2649c4bf3659901b80,Remove unused method and variable in base.py,MERGED,2014-09-26 05:26:49.000000000,2014-10-07 09:28:50.000000000,2014-10-07 09:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-09-26 05:26:49.000000000', 'files': ['tempest_lib/base.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/0915a0026bbaecc95e0b414576a182d6492a7680', 'message': 'Remove unused method and variable in base.py\n\nbase.py was migrated and simplified by\n commit: 45da2a78dc9d560b021ae3fa90d9b7e45b6c9b51\nBut there are some unused codes in it. This commit just removes them.\n\nChange-Id: Ie16fdf75b69006cf48ad9b2649c4bf3659901b80\n'}]",0,124275,0915a0026bbaecc95e0b414576a182d6492a7680,7,3,1,5689,,,0,"Remove unused method and variable in base.py

base.py was migrated and simplified by
 commit: 45da2a78dc9d560b021ae3fa90d9b7e45b6c9b51
But there are some unused codes in it. This commit just removes them.

Change-Id: Ie16fdf75b69006cf48ad9b2649c4bf3659901b80
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/75/124275/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest_lib/base.py'],1,0915a0026bbaecc95e0b414576a182d6492a7680,remove-unnecessary-method,,"at_exit_set = set() def validate_tearDownClass(): if at_exit_set: LOG.error(""tearDownClass does not call the super's "" ""tearDownClass in these classes: \n"" + str(at_exit_set)) at_exit_set.discard(cls) at_exit_set.add(self.__class__)",0,11
openstack%2Ftempest-lib~master~I9e681b99b8b6df84ae986974ac733a380e127605,openstack/tempest-lib,master,I9e681b99b8b6df84ae986974ac733a380e127605,Remove a duplicate ignore rule of pep8,MERGED,2014-09-10 06:23:56.000000000,2014-10-07 09:22:00.000000000,2014-10-07 09:22:00.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-09-10 06:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/d2ae17dac3ed2164ff47c296e3b89b2d7d9c5432', 'message': ""Remove a duplicate ignore rule of pep8\n\nThere are two E123 declarations in tox.ini. However, we don't need two.\nThis commit removes one.\n\nChange-Id: I9e681b99b8b6df84ae986974ac733a380e127605\n""}, {'number': 2, 'created': '2014-09-26 05:51:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/482d357607bcf39a344ba253a9467bde0435dc4e', 'message': ""Remove a duplicate ignore rule of pep8\n\nThere are two E123 declarations in tox.ini. However, we don't need the\nduplication. This commit removes one.\n\nChange-Id: I9e681b99b8b6df84ae986974ac733a380e127605\n""}]",2,120321,482d357607bcf39a344ba253a9467bde0435dc4e,24,4,2,5689,,,0,"Remove a duplicate ignore rule of pep8

There are two E123 declarations in tox.ini. However, we don't need the
duplication. This commit removes one.

Change-Id: I9e681b99b8b6df84ae986974ac733a380e127605
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/21/120321/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d2ae17dac3ed2164ff47c296e3b89b2d7d9c5432,remove-dup-ignores,"# E125 skipped as it is invalid PEP-8.ignore = E125,H803,H402,E123,E129,H305","# E123, E125 skipped as they are invalid PEP-8.ignore = E123,E125,H803,H402,E123,E129,H305",2,2
openstack%2Fopenstack-manuals~master~Icebca21e9242da78e95297c43a3d2cd6aa17689f,openstack/openstack-manuals,master,Icebca21e9242da78e95297c43a3d2cd6aa17689f,Update the swift tables in the config reference,MERGED,2014-10-07 05:08:35.000000000,2014-10-07 09:09:30.000000000,2014-10-07 09:09:29.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 05:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0bb933c7ddd4db25c8fb150ade8074e2f37f6f43', 'message': 'Update the swift tables in the config reference\n\nChange-Id: Icebca21e9242da78e95297c43a3d2cd6aa17689f\n'}, {'number': 2, 'created': '2014-10-07 07:01:48.000000000', 'files': ['doc/common/tables/swift-conf-changes.xml', 'doc/common/tables/swift-proxy-server-filter-proxy-logging.xml', 'doc/common/tables/swift-proxy-server-DEFAULT.xml', 'doc/common/tables/swift-object-server-app-object-server.xml', 'doc/common/tables/swift-object-expirer-filter-proxy-logging.xml', 'doc/common/tables/swift-proxy-server-filter-keystoneauth.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/442c606f2820869f1ef61bbd02e03d2ffa43b7d9', 'message': 'Update the swift tables in the config reference\n\nChange-Id: Icebca21e9242da78e95297c43a3d2cd6aa17689f\n'}]",0,126466,442c606f2820869f1ef61bbd02e03d2ffa43b7d9,9,3,2,7923,,,0,"Update the swift tables in the config reference

Change-Id: Icebca21e9242da78e95297c43a3d2cd6aa17689f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/66/126466/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/tables/swift-conf-changes.xml', 'doc/common/tables/swift-proxy-server-DEFAULT.xml', 'doc/common/tables/swift-object-server-app-object-server.xml', 'doc/common/tables/swift-proxy-server-filter-keystoneauth.xml']",4,0bb933c7ddd4db25c8fb150ade8074e2f37f6f43,swift-ref, <td>allow_names_in_acls = true</td> <td>No help text available for this option.</td> </tr> <tr> <td>default_domain_id = default</td> <td>No help text available for this option.</td> </tr> <tr>,,31,2
openstack%2Fironic~master~I762c0176fccde9da6d82f0470e735c10c4bcc8f7,openstack/ironic,master,I762c0176fccde9da6d82f0470e735c10c4bcc8f7,Sync ironic/openstack/common/policy.py with oslo.,ABANDONED,2014-09-18 04:56:20.000000000,2014-10-07 09:08:41.000000000,,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 6618}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 11042}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-09-18 04:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5142101158897f5f122b9a9691da9582d3cfbb3', 'message': 'Fix typo to show correct log message\n\nFix typo in ironic/openstack/common/policy.py to show correct log.\n\nChange-Id: I762c0176fccde9da6d82f0470e735c10c4bcc8f7\n'}, {'number': 2, 'created': '2014-09-24 01:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/baeba9496776195f7af8f4700d65257ce5b76e3a', 'message': 'Fix typo to show correct log message\n\nSync ironic/openstack/common/policy.py with oslo.\n\nChange-Id: I762c0176fccde9da6d82f0470e735c10c4bcc8f7\n'}, {'number': 3, 'created': '2014-09-24 02:15:11.000000000', 'files': ['ironic/openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/629f5f9a946a1b426a4e013951afe333ed846a35', 'message': 'Sync ironic/openstack/common/policy.py with oslo.\n\nChange-Id: I762c0176fccde9da6d82f0470e735c10c4bcc8f7\n'}]",2,122316,629f5f9a946a1b426a4e013951afe333ed846a35,47,9,3,6348,,,0,"Sync ironic/openstack/common/policy.py with oslo.

Change-Id: I762c0176fccde9da6d82f0470e735c10c4bcc8f7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/16/122316/3 && git format-patch -1 --stdout FETCH_HEAD,['ironic/openstack/common/policy.py'],1,d5142101158897f5f122b9a9691da9582d3cfbb3,log_typo," LOG.exception(_(""Failed to understand rule %(rule)s"") % locals())"," LOG.exception(_(""Failed to understand rule %(rule)r"") % locals())",1,1
openstack%2Fglance~proposed%2Fjuno~Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4,openstack/glance,proposed/juno,Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4,Include Metadata Defs Concepts in Dev Docs,MERGED,2014-10-07 04:44:52.000000000,2014-10-07 09:06:09.000000000,2014-10-07 09:06:08.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-07 04:44:52.000000000', 'files': ['doc/source/index.rst', 'doc/source/metadefs-concepts.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/60ff6fd0efb6615b9df3adbd7913f1a3fa615acf', 'message': ""Include Metadata Defs Concepts in Dev Docs\n\nThe http://docs.openstack.org/developer/glance/\nsite currently doesn't include the Juno Metadata\nDefinitions concepts.  This patch adds\nan overview of the concepts to this site.\n\nThis provides a synopis of the concepts in:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nDocImpact\nCloses-Bug: 1367432\nRelated-Bug: 1367908\nRelated-Bug: 1363615\nRelated-Bug: 1366286\nRelated-Bug: 1363383\nChange-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4\n(cherry picked from commit 0aab5e271667990afb1a2522c7c9c61fa7211e0b)\n""}]",0,126462,60ff6fd0efb6615b9df3adbd7913f1a3fa615acf,7,3,1,7665,,,0,"Include Metadata Defs Concepts in Dev Docs

The http://docs.openstack.org/developer/glance/
site currently doesn't include the Juno Metadata
Definitions concepts.  This patch adds
an overview of the concepts to this site.

This provides a synopis of the concepts in:
https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst

DocImpact
Closes-Bug: 1367432
Related-Bug: 1367908
Related-Bug: 1363615
Related-Bug: 1366286
Related-Bug: 1363383
Change-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4
(cherry picked from commit 0aab5e271667990afb1a2522c7c9c61fa7211e0b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/62/126462/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/metadefs-concepts.rst']",2,60ff6fd0efb6615b9df3adbd7913f1a3fa615acf,,".. Copyright (c) 2014 Hewlett-Packard Development Company, L.P. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Metadata Definition Concepts ============================ The metadata definition service was added to Glance in the Juno release of OpenStack. It provides a common API for vendors, admins, services, and users to meaningfully **define** available key / value pair metadata that can be used on different types of resources (images, artifacts, volumes, flavors, aggregates, etc). A definition includes a property's key, its description, its constraints, and the resource types to which it can be associated. This catalog does not store the values for specific instance properties. For example, a definition of a virtual CPU topology property for the number of cores will include the base key to use (for example, cpu_cores), a description, and value constraints like requiring it to be an integer. So, a user, potentially through Horizon, would be able to search this catalog to list the available properties they can add to a flavor or image. They will see the virtual CPU topology property in the list and know that it must be an integer. When the user adds the property its key and value will be stored in the service that owns that resource (for example, Nova for flavors and in Glance for images). The catalog also includes any additional prefix required when the property is applied to different types of resources, such as ""hw_"" for images and ""hw:"" for flavors. So, on an image, the user would know to set the property as ""hw_cpu_cores=1"". Terminology ----------- Background ~~~~~~~~~~ The term *metadata* can become very overloaded and confusing. This catalog is about the additional metadata that is passed as arbitrary key / value pairs or tags across various artifacts and OpenStack services. Below are a few examples of the various terms used for metadata across OpenStack services today: +-------------------------+---------------------------+----------------------+ | Nova | Cinder | Glance | +=========================+===========================+======================+ | Flavor | Volume & Snapshot | Image & Snapshot | | + *extra specs* | + *image metadata* | + *properties* | | Host Aggregate | + *metadata* | + *tags* | | + *metadata* | VolumeType | | | Instances | + *extra specs* | | | + *metadata* | + *qos specs* | | | + *tags* | | | +-------------------------+---------------------------+----------------------+ Catalog Concepts ~~~~~~~~~~~~~~~~ The below figure illustrates the concept terminology used in the metadata definitions catalog:: A namespace is associated with 0 to many resource types, making it visible to the API / UI for applying to that type of resource. RBAC Permissions are managed at a namespace level. +----------------------------------------------+ | Namespace | | | | +-----------------------------------------+ | | | Object Definition | | | | | | +--------------------+ | | +-------------------------------------+ | | +--> | Resource Type: | | | | Property Definition A (key=integer) | | | | | e.g. Nova Flavor | | | +-------------------------------------+ | | | +--------------------+ | | | | | | | +-------------------------------------+ | | | | | | Property Definition B (key=string) | | | | +--------------------+ | | +-------------------------------------+ | +--+--> | Resource Type: | | | | | | | e.g. Glance Image | | +-----------------------------------------+ | | +--------------------+ | | | | +-------------------------------------+ | | | | Property Definition C (key=boolean) | | | +--------------------+ | +-------------------------------------+ | +--> | Resource Type: | | | | e.g. Cinder Volume | +----------------------------------------------+ +--------------------+ Properties may be defined standalone or within the context of an object. Catalog Terminology ~~~~~~~~~~~~~~~~~~~ The following terminology is used within the metadata definition catalog. **Namespaces** Metadata definitions are contained in namespaces. - Specify the access controls (CRUD) for everything defined in it. Allows for admin only, different projects, or the entire cloud to define and use the definitions in the namespace - Associates the contained definitions to different types of resources **Properties** A property describes a single property and its primitive constraints. Each property can ONLY be a primitive type: * string, integer, number, boolean, array Each primitive type is described using simple JSON schema notation. This means NO nested objects and no definition referencing. **Objects** An object describes a group of one to many properties and their primitive constraints. Each property in the group can ONLY be a primitive type: * string, integer, number, boolean, array Each primitive type is described using simple JSON schema notation. This means NO nested objects. The object may optionally define required properties under the semantic understanding that a user who uses the object should provide all required properties. **Resource Type Association** Resource type association specifies the relationship between resource types and the namespaces that are applicable to them. This information can be used to drive UI and CLI views. For example, the same namespace of objects, properties, and tags may be used for images, snapshots, volumes, and flavors. Or a namespace may only apply to images. Resource types should be aligned with Heat resource types whenever possible. http://docs.openstack.org/developer/heat/template_guide/openstack.html It is important to note that the same base property key can require different prefixes depending on the target resource type. The API provides a way to retrieve the correct property based on the target resource type. Below are a few examples: The desired virtual CPU topology can be set on both images and flavors via metadata. The keys have different prefixes on images than on flavors. On flavors keys are prefixed with ``hw:``, but on images the keys are prefixed with ``hw_``. For more: https://github.com/openstack/nova-specs/blob/master/specs/juno/virt-driver-vcpu-topology.rst Another example is the AggregateInstanceExtraSpecsFilter and scoped properties (e.g. properties with something:something=value). For scoped / namespaced properties, the AggregateInstanceExtraSpecsFilter requires a prefix of ""aggregate_instance_extra_specs:"" to be used on flavors but not on the aggregate itself. Otherwise, the filter will not evaluate the property during scheduling. So, on a host aggregate, you may see: companyx:fastio=true But then when used on the flavor, the AggregateInstanceExtraSpecsFilter needs: aggregate_instance_extra_specs:companyx:fastio=true In some cases, there may be multiple different filters that may use the same property with different prefixes. In this case, the correct prefix needs to be set based on which filter is enabled. ",,191,1
openstack%2Fneutron~stable%2Ficehouse~I531d7ffab074b01adfe186d2c3df43ca978359cd,openstack/neutron,stable/icehouse,I531d7ffab074b01adfe186d2c3df43ca978359cd,Provide way to reserve dhcp port during failovers,MERGED,2014-10-03 09:57:28.000000000,2014-10-07 09:05:56.000000000,2014-10-07 09:05:54.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 5209}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-03 09:57:28.000000000', 'files': ['neutron/common/constants.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/common/utils.py', 'neutron/db/agentschedulers_db.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1386415271bd7e478a12e132f67a42aed2f41dae', 'message': ""Provide way to reserve dhcp port during failovers\n\nThis change provides a way to save the dhcp port when failing\nover a network from one dhcp agent to another.  When a\ndhcp-agent-network-remove is issued, the dhcp port device_id is\nmarked as reserved which causes it to not be deleted. When a\nsubsequent dhcp-agent-network-add is issued, the reserved port\nis used and the device_id is corrected.  This is desirable\nin order to maintain the dhcp port ip address so that dns doesn't\nget impacted. Unit test added.\n\nCloses-Bug: #1288923\n(cherry picked from d5c0a37999f9e3a611a322baacabebc06b13283b)\nConflicts:\n\tneutron/common/utils.py\n\tneutron/tests/unit/test_db_plugin.py\n\nChange-Id: I531d7ffab074b01adfe186d2c3df43ca978359cd\n""}]",0,125919,1386415271bd7e478a12e132f67a42aed2f41dae,34,20,1,8788,,,0,"Provide way to reserve dhcp port during failovers

This change provides a way to save the dhcp port when failing
over a network from one dhcp agent to another.  When a
dhcp-agent-network-remove is issued, the dhcp port device_id is
marked as reserved which causes it to not be deleted. When a
subsequent dhcp-agent-network-add is issued, the reserved port
is used and the device_id is corrected.  This is desirable
in order to maintain the dhcp port ip address so that dns doesn't
get impacted. Unit test added.

Closes-Bug: #1288923
(cherry picked from d5c0a37999f9e3a611a322baacabebc06b13283b)
Conflicts:
	neutron/common/utils.py
	neutron/tests/unit/test_db_plugin.py

Change-Id: I531d7ffab074b01adfe186d2c3df43ca978359cd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/125919/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/common/utils.py', 'neutron/db/agentschedulers_db.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py']",7,1386415271bd7e478a12e132f67a42aed2f41dae,bug/1288923," with mock.patch('uuid.uuid5') as uuid5: uuid5.return_value = '1ae5f96c-c527-5079-82ea-371a01645457' dh = dhcp.DeviceManager(cfg.CONF, cfg.CONF.root_helper, None) uuid5.called_once_with(uuid.NAMESPACE_DNS, cfg.CONF.host) self.assertEqual(dh.get_device_id(fake_net), expected)"," with mock.patch('socket.gethostname') as get_host: with mock.patch('uuid.uuid5') as uuid5: uuid5.return_value = '1ae5f96c-c527-5079-82ea-371a01645457' get_host.return_value = 'localhost' dh = dhcp.DeviceManager(cfg.CONF, cfg.CONF.root_helper, None) self.assertEqual(dh.get_device_id(fake_net), expected) uuid5.assert_called_once_with(uuid.NAMESPACE_DNS, 'localhost')",75,11
openstack%2Fglance~master~I252758fd633662de9659a402c5e3d7e3ce1fae0f,openstack/glance,master,I252758fd633662de9659a402c5e3d7e3ce1fae0f,hacking: upgrade to 0.9.x serie,MERGED,2014-06-12 15:56:30.000000000,2014-10-07 08:59:25.000000000,2014-10-07 08:59:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 9751}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-06-12 15:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/07b97f1362b268573e258c47c5dd89dc8f40bcca', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 2, 'created': '2014-06-13 09:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/22a4c2669c1e05997e11a117fa2b5919dce878ae', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 3, 'created': '2014-06-16 09:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fd002f016ec55fce07157bbd6d2b1c53f3d4472d', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 4, 'created': '2014-06-16 11:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a83940a6f79f8886a489719679ce3c6ce976140e', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 5, 'created': '2014-07-15 14:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/88fbf9f8db3df6807d8dd4c489012b875e16917e', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 6, 'created': '2014-08-01 13:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/34b60b378f4527b213cfe19b5c8042f944a56afa', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 7, 'created': '2014-08-04 12:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/69be699477ef25878aaf2361ef303c402e31a27b', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 8, 'created': '2014-08-19 13:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dd09b339dbfbec9f7d67d6fc4c73d125fa6bff9d', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 9, 'created': '2014-08-21 10:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3169ee8f13f517d30b4cffa24412cdc735c18b32', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 10, 'created': '2014-08-25 15:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/412a2bc424113af9930d2bef1755b9c0961529c1', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 11, 'created': '2014-09-10 14:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/37ac7792ef2ea3d87973fe5fe952b8f3659056ff', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 12, 'created': '2014-10-01 10:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dd46ac4a435b3f55c04916ef39a8bc417b5fe15b', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 13, 'created': '2014-10-01 15:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5f1f836d1b8e911bd7bc883d9b5653fe70dc9f73', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 14, 'created': '2014-10-06 11:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/261de00988eeac9bb798f79e9c2955d871a6b212', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}, {'number': 15, 'created': '2014-10-06 12:43:37.000000000', 'files': ['glance/tests/unit/test_migrations.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/tests/unit/test_glance_replicator.py', 'test-requirements.txt', 'glance/api/v2/model/metadef_property_type.py', 'glance/cmd/registry.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/functional/test_bin_glance_cache_manage.py', 'glance/tests/unit/api/test_cmd.py', 'glance/tests/unit/utils.py', 'glance/api/common.py', 'glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py', 'glance/tests/utils.py', 'glance/db/sqlalchemy/migrate_repo/versions/__init__.py', 'glance/gateway.py', 'glance/common/swift_store_utils.py', 'tools/colorizer.py', 'glance/tests/functional/v1/test_api.py', 'glance/tests/unit/test_domain.py', 'glance/tests/unit/api/middleware/test_cache_manage.py', 'glance/common/scripts/utils.py', 'glance/common/wsgi.py', 'glance/image_cache/prefetcher.py', 'glance/api/v2/image_data.py', 'glance/api/authorization.py', 'glance/api/v2/tasks.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/api/v2/image_tags.py', 'glance/api/policy.py', 'glance/notifier.py', 'glance/domain/proxy.py', 'glance/tests/unit/common/test_wsgi.py', 'glance/tests/functional/v2/test_images.py', 'glance/opts.py', 'glance/tests/functional/test_cache_middleware.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v2/image_members.py', 'glance/cmd/control.py', 'glance/common/scripts/__init__.py', 'glance/db/sqlalchemy/metadata.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/db/sqlalchemy/metadef_api/object.py', 'glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py', 'glance/tests/functional/__init__.py', 'glance/api/v1/controller.py', 'glance/scrubber.py', 'glance/context.py', 'glance/tests/functional/v1/test_misc.py', 'glance/tests/stubs.py', 'glance/api/v2/model/metadef_namespace.py', 'glance/tests/functional/test_glance_manage.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/api/middleware/context.py', 'glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py', 'glance/db/sqlalchemy/migrate_repo/__init__.py', 'glance/tests/unit/common/scripts/image_import/test_main.py', 'glance/common/auth.py', 'glance/tests/unit/test_db_metadef.py', 'glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py', 'glance/db/sqlalchemy/metadef_api/property.py', 'glance/tests/unit/test_image_cache.py', 'glance/tests/unit/v2/test_registry_client.py', 'glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py', 'glance/api/v2/model/metadef_resource_type.py', 'glance/tests/integration/v2/test_tasks_api.py', 'glance/api/v1/upload_utils.py', 'glance/db/sqlalchemy/models.py', 'glance/image_cache/drivers/sqlite.py', 'glance/tests/unit/common/scripts/test_scripts_utils.py', 'glance/tests/unit/api/test_common.py', 'glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py', 'glance/tests/functional/test_api.py', 'glance/tests/unit/test_db.py', 'glance/api/v2/images.py', 'glance/tests/functional/v2/test_metadef_resourcetypes.py', 'glance/tests/unit/test_image_cache_client.py', 'glance/common/scripts/image_import/main.py', 'glance/tests/functional/v2/test_metadef_objects.py', 'glance/cmd/api.py', 'glance/api/property_protections.py', 'glance/image_cache/drivers/xattr.py', 'tox.ini', 'glance/tests/functional/db/base.py', 'glance/db/simple/api.py', 'glance/db/sqlalchemy/api.py', 'glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py', 'glance/api/v2/model/metadef_object.py', 'glance/tests/unit/test_store_image.py', 'glance/api/v1/images.py', 'glance/tests/functional/db/base_metadef.py', 'glance/tests/integration/legacy_functional/test_v1_api.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/tests/functional/store_utils.py', 'glance/cmd/replicator.py', 'glance/tests/unit/test_quota.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/unit/v2/test_image_members_resource.py', 'glance/common/utils.py', 'glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py', 'glance/quota/__init__.py', 'glance/api/v2/schemas.py', 'glance/db/sqlalchemy/metadef_api/namespace.py', 'glance/tests/functional/test_logging.py', 'glance/tests/unit/api/test_cmd_cache_manage.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/fadbef85113ea6f2ca014f12a20f87d0f1e16cd8', 'message': 'hacking: upgrade to 0.9.x serie\n\nChange-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f\n'}]",109,99698,fadbef85113ea6f2ca014f12a20f87d0f1e16cd8,77,11,15,1669,,,0,"hacking: upgrade to 0.9.x serie

Change-Id: I252758fd633662de9659a402c5e3d7e3ce1fae0f
",git fetch https://review.opendev.org/openstack/glance refs/changes/98/99698/13 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_migrations.py', 'glance/context.py', 'glance/tests/functional/store/test_cinder.py', 'glance/tests/functional/v1/test_misc.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/tests/unit/test_glance_replicator.py', 'test-requirements.txt', 'glance/tests/stubs.py', 'glance/tests/functional/store/test_http.py', 'glance/tests/functional/test_glance_manage.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/api/middleware/context.py', 'glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py', 'glance/cmd/registry.py', 'glance/tests/functional/test_bin_glance_cache_manage.py', 'glance/tests/unit/api/test_cmd.py', 'glance/db/sqlalchemy/migrate_repo/__init__.py', 'glance/api/common.py', 'glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py', 'glance/tests/unit/test_swift_store.py', 'glance/common/auth.py', 'glance/tests/utils.py', 'glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py', 'glance/db/sqlalchemy/migrate_repo/versions/__init__.py', 'glance/tests/unit/test_image_cache.py', 'glance/tests/unit/v2/test_registry_client.py', 'glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py', 'glance/tests/integration/v2/test_tasks_api.py', 'glance/gateway.py', 'glance/api/v1/upload_utils.py', 'tools/colorizer.py', 'glance/db/sqlalchemy/models.py', 'glance/image_cache/drivers/sqlite.py', 'glance/store/cinder.py', 'glance/tests/functional/v1/test_api.py', 'glance/tests/unit/api/test_common.py', 'glance/tests/unit/test_cinder_store.py', 'glance/tests/unit/test_domain.py', 'glance/tests/unit/api/middleware/test_cache_manage.py', 'glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py', 'glance/tests/functional/test_api.py', 'glance/tests/unit/test_db.py', 'glance/common/wsgi.py', 'glance/api/v2/images.py', 'glance/tests/unit/test_image_cache_client.py', 'glance/cmd/api.py', 'glance/api/property_protections.py', 'glance/image_cache/drivers/xattr.py', 'glance/tests/unit/test_scrubber.py', 'tox.ini', 'glance/api/v2/image_data.py', 'glance/api/authorization.py', 'glance/store/__init__.py', 'glance/store/gridfs.py', 'glance/tests/functional/db/base.py', 'glance/db/simple/api.py', 'glance/api/v2/tasks.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py', 'glance/tests/unit/test_store_image.py', 'glance/tests/unit/test_filesystem_store.py', 'glance/tests/functional/store/test_s3.py', 'glance/notifier.py', 'glance/api/v1/images.py', 'glance/tests/functional/store/test_rbd.py', 'glance/tests/integration/legacy_functional/test_v1_api.py', 'glance/tests/unit/common/test_wsgi.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/tests/functional/store/__init__.py', 'glance/tests/functional/test_cache_middleware.py', 'glance/tests/unit/v1/test_api.py', 'glance/tests/functional/store_utils.py', 'glance/tests/unit/test_s3_store.py', 'glance/api/v2/image_members.py', 'glance/cmd/control.py', 'glance/tests/unit/test_quota.py', 'glance/store/rbd.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/unit/v2/test_image_members_resource.py', 'glance/common/utils.py', 'glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py', 'glance/tests/functional/store/test_swift.py', 'glance/tests/unit/test_gridfs_store.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py', 'glance/tests/functional/__init__.py', 'glance/store/filesystem.py', 'glance/tests/functional/test_logging.py', 'glance/scrubber.py', 'glance/tests/unit/api/test_cmd_cache_manage.py']",95,07b97f1362b268573e258c47c5dd89dc8f40bcca,jd/pep8, # options.forced set to False and queue confirmation set to False. # options.forced set to False and queue confirmation set to True. # options.forced set to False and delete confirmation set to False. # options.forced set to False and delete confirmation set to True. # options.forced set to False and delete confirmation set to False. # options.forced set to False and delete confirmation set to True. # options.forced set to False and delete confirmation set to False. # options.forced set to False and delete confirmation set to True. # options.forced set to False and delete confirmation set to False. # options.forced set to False and delete confirmation set to True., #options.forced set to False and queue confirmation set to False. #options.forced set to False and queue confirmation set to True. #options.forced set to False and delete confirmation set to False. #options.forced set to False and delete confirmation set to True. #options.forced set to False and delete confirmation set to False. #options.forced set to False and delete confirmation set to True. #options.forced set to False and delete confirmation set to False. #options.forced set to False and delete confirmation set to True. #options.forced set to False and delete confirmation set to False. #options.forced set to False and delete confirmation set to True.,502,588
openstack%2Fheat~master~I1319fa08b1f9f026d795fe24325d3d36836b1575,openstack/heat,master,I1319fa08b1f9f026d795fe24325d3d36836b1575,Docs - update JEOS building instructions,MERGED,2014-10-03 21:01:50.000000000,2014-10-07 08:55:04.000000000,2014-10-07 08:55:03.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}]","[{'number': 1, 'created': '2014-10-03 21:01:50.000000000', 'files': ['doc/source/getting_started/jeos_building.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/dc24d21695eee85d6913ad002d290af163cdf372', 'message': 'Docs - update JEOS building instructions\n\nAs dib-utils has been split from diskimage-builder, the instructions are\nno longer complete.\n\nInstead advise users to install diskimage-builder from Github with pip,\nsolving the dependency problem.\n\nChange-Id: I1319fa08b1f9f026d795fe24325d3d36836b1575\n'}]",0,126071,dc24d21695eee85d6913ad002d290af163cdf372,8,3,1,9542,,,0,"Docs - update JEOS building instructions

As dib-utils has been split from diskimage-builder, the instructions are
no longer complete.

Instead advise users to install diskimage-builder from Github with pip,
solving the dependency problem.

Change-Id: I1319fa08b1f9f026d795fe24325d3d36836b1575
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/126071/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/getting_started/jeos_building.rst'],1,dc24d21695eee85d6913ad002d290af163cdf372,update-jeos-docs,Install the tool (preferably in a virtualenv) and fetch the elements:: pip install git+https://github.com/openstack/diskimage-builder.git disk-image-create vm fedora heat-cfntools -a amd64 -o fedora-heat-cfntools disk-image-create vm ubuntu heat-cfntools -a i386 -o ubuntu-heat-cfntools pip install git+https://git.openstack.org/openstack/diskimage-builder.git disk-image-create vm \,Fetch the tool and elements:: git clone https://github.com/openstack/diskimage-builder.git diskimage-builder/bin/disk-image-create vm fedora heat-cfntools -a amd64 -o fedora-heat-cfntools diskimage-builder/bin/disk-image-create vm ubuntu heat-cfntools -a i386 -o ubuntu-heat-cfntools git clone https://git.openstack.org/openstack/diskimage-builder.git diskimage-builder/bin/disk-image-create vm \,6,6
openstack%2Fhorizon~master~I3238e62e56ebbdabb7844a4d5aab1597ae9ca8f0,openstack/horizon,master,I3238e62e56ebbdabb7844a4d5aab1597ae9ca8f0,Imported Translations from Transifex,MERGED,2014-10-07 06:03:40.000000000,2014-10-07 08:54:54.000000000,2014-10-07 08:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-10-07 06:03:40.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4dbf0bcb85da1b1ea6b6083fcdf7d03c2abe7e6d', 'message': 'Imported Translations from Transifex\n\nChange-Id: I3238e62e56ebbdabb7844a4d5aab1597ae9ca8f0\n'}]",0,126472,4dbf0bcb85da1b1ea6b6083fcdf7d03c2abe7e6d,7,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I3238e62e56ebbdabb7844a4d5aab1597ae9ca8f0
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/126472/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",14,4dbf0bcb85da1b1ea6b6083fcdf7d03c2abe7e6d,transifex/translations,"""POT-Creation-Date: 2014-10-06 21:13-0500\n"" ""PO-Revision-Date: 2014-10-06 15:00+0000\n""#: api/neutron.py:207#: api/neutron.py:853#: api/neutron.py:890#: api/neutron.py:1029#: api/neutron.py:1047#: api/neutron.py:1062#: dashboards/admin/info/tables.py:170 dashboards/admin/instances/tables.py:95 #: dashboards/admin/instances/tables.py:138#: dashboards/project/images/images/forms.py:193#: dashboards/project/loadbalancers/tables.py:270#: dashboards/project/vpn/tables.py:232 dashboards/project/vpn/tables.py:262 #: dashboards/project/vpn/tables.py:282 dashboards/project/vpn/tables.py:300#: dashboards/project/images/images/forms.py:41 #: dashboards/project/images/images/forms.py:194#: dashboards/project/loadbalancers/tables.py:272#: dashboards/project/vpn/tables.py:264 dashboards/project/vpn/workflows.py:30#: dashboards/admin/instances/tables.py:172#: dashboards/project/volumes/volumes/tables.py:371 usage/quotas.py:74#: dashboards/project/images/images/forms.py:99 #: dashboards/project/images/images/forms.py:232#: dashboards/admin/instances/tables.py:134#: dashboards/admin/instances/tables.py:151#: dashboards/project/loadbalancers/tables.py:277 #: dashboards/project/loadbalancers/tables.py:311#: dashboards/project/vpn/tables.py:242 dashboards/project/vpn/tables.py:269#: dashboards/admin/instances/tables.py:98#: dashboards/admin/instances/tables.py:140#: dashboards/admin/instances/tables.py:41 msgid ""Migrate Instance"" msgid_plural ""Migrate Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/instances/tables.py:49 msgid ""Scheduled migration (pending confirmation) of Instance"" msgid_plural ""Scheduled migration (pending confirmation) of Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/instances/tables.py:66#: dashboards/admin/instances/tables.py:93 #: dashboards/admin/instances/tables.py:127#: dashboards/admin/instances/tables.py:94#: dashboards/admin/instances/tables.py:96#: dashboards/admin/instances/tables.py:97#: dashboards/admin/instances/tables.py:99#: dashboards/admin/instances/tables.py:100#: dashboards/admin/instances/tables.py:142#: dashboards/project/loadbalancers/tables.py:302#: dashboards/admin/instances/tables.py:145#: dashboards/admin/instances/tables.py:156#: dashboards/admin/instances/tables.py:163#: dashboards/admin/instances/tables.py:165#: dashboards/admin/networks/forms.py:235#: dashboards/project/networks/forms.py:39#: dashboards/admin/networks/forms.py:236#: dashboards/admin/networks/forms.py:237#: dashboards/admin/networks/forms.py:249 #: dashboards/project/networks/forms.py:49#: dashboards/admin/networks/forms.py:254 #: dashboards/project/networks/forms.py:54#: dashboards/project/loadbalancers/tables.py:310#: dashboards/project/access_and_security/floating_ips/workflows.py:37 #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:196 #: dashboards/project/volumes/volumes/tables.py:423 msgid ""Instance"" msgstr ""Instance"" #: dashboards/project/loadbalancers/tables.py:337#: dashboards/project/loadbalancers/tables.py:327#: dashboards/project/loadbalancers/tables.py:276#: dashboards/project/images/images/forms.py:45#: dashboards/project/images/images/forms.py:47 #: dashboards/project/images/images/forms.py:54 #: dashboards/project/images/images/forms.py:60#: dashboards/project/images/images/forms.py:48 #: dashboards/project/images/images/forms.py:65 #: dashboards/project/images/images/forms.py:70#: dashboards/project/images/images/forms.py:55#: dashboards/project/images/images/forms.py:66#: dashboards/project/images/images/forms.py:76 #: dashboards/project/images/images/forms.py:214#: dashboards/project/images/images/forms.py:81 #: dashboards/project/images/images/forms.py:209#: dashboards/project/images/images/forms.py:83 #: dashboards/project/images/images/forms.py:216#: dashboards/project/images/images/forms.py:85 #: dashboards/project/images/images/forms.py:218#: dashboards/project/images/images/forms.py:91 #: dashboards/project/images/images/forms.py:224#: dashboards/project/images/images/forms.py:93 #: dashboards/project/images/images/forms.py:226#: dashboards/project/images/images/forms.py:100 #: dashboards/project/images/images/forms.py:233#: dashboards/project/images/images/forms.py:143#: dashboards/project/images/images/forms.py:146#: dashboards/project/images/images/forms.py:184#: dashboards/project/images/images/forms.py:188#: dashboards/project/images/images/forms.py:198#: dashboards/project/images/images/forms.py:204#: dashboards/project/images/images/forms.py:246#: dashboards/project/images/images/forms.py:273#: dashboards/project/loadbalancers/tables.py:274msgstr ""Volume size must be greater than 0""#: dashboards/project/loadbalancers/tables.py:308#: dashboards/project/loadbalancers/tables.py:334#: dashboards/project/loadbalancers/tables.py:335#: dashboards/project/loadbalancers/tables.py:31#: dashboards/project/loadbalancers/tables.py:40#: dashboards/project/loadbalancers/tables.py:58#: dashboards/project/loadbalancers/tables.py:67#: dashboards/project/loadbalancers/tables.py:81 msgid ""Delete VIP"" msgid_plural ""Delete VIPs"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:89 msgid ""Scheduled deletion of VIP"" msgid_plural ""Scheduled deletion of VIPs"" msgstr[0] """" msgstr[1] """"msgid ""Delete Pool"" msgid_plural ""Delete Pools"" msgstr[0] """" msgstr[1] """"msgid ""Scheduled deletion of Pool"" msgid_plural ""Scheduled deletion of Pools"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:134 msgid ""Delete Monitor"" msgid_plural ""Delete Monitors"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:142 msgid ""Scheduled deletion of Monitor"" msgid_plural ""Scheduled deletion of Monitors"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:155 msgid ""Delete Member"" msgid_plural ""Delete Members"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:163 msgid ""Scheduled deletion of Member"" msgid_plural ""Scheduled deletion of Members"" msgstr[0] """" msgstr[1] """" #: dashboards/project/loadbalancers/tables.py:171#: dashboards/project/loadbalancers/tables.py:183#: dashboards/project/loadbalancers/tables.py:200#: dashboards/project/loadbalancers/tables.py:212#: dashboards/project/loadbalancers/tables.py:233#: dashboards/project/loadbalancers/tables.py:249#: dashboards/project/loadbalancers/tables.py:256#: dashboards/project/loadbalancers/tables.py:273#: dashboards/project/loadbalancers/tables.py:275#: dashboards/project/vpn/tables.py:265 dashboards/project/vpn/workflows.py:32#: dashboards/project/loadbalancers/tables.py:278 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:18 msgid ""VIP"" msgstr ""VIP"" #: dashboards/project/loadbalancers/tables.py:283 #: dashboards/project/loadbalancers/tabs.py:29 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:38 msgid ""Pools"" msgstr ""Pools"" #: dashboards/project/loadbalancers/tables.py:306#: dashboards/project/loadbalancers/tables.py:315 #: dashboards/project/loadbalancers/tabs.py:49 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:39 msgid ""Members"" msgstr ""Members"" #: dashboards/project/loadbalancers/tables.py:332#: dashboards/project/loadbalancers/tables.py:336#: dashboards/project/loadbalancers/tables.py:341 #: dashboards/project/loadbalancers/tabs.py:69 msgid ""Monitors"" msgstr ""Monitors"" #: dashboards/project/loadbalancers/workflows.py:620 #: dashboards/project/loadbalancers/workflows.py:683 msgid ""Monitor"" msgstr ""Monitor"" #: dashboards/project/vpn/tables.py:266 dashboards/project/vpn/workflows.py:31msgstr ""Specify \""Network Address\""""#: dashboards/project/volumes/backups/tables.py:49 #, python-format msgid ""Scheduled deletion of %(data_type)s"" msgstr ""Scheduled deletion of %(data_type)s"" #: dashboards/project/volumes/volumes/tables.py:444#: dashboards/project/volumes/volumes/tables.py:388 msgid ""Detach Volume"" msgid_plural ""Detach Volumes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/volumes/volumes/tables.py:397 msgid ""Detaching Volume"" msgid_plural ""Detaching Volumes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/volumes/volumes/tables.py:425#: dashboards/project/volumes/volumes/tables.py:434#: dashboards/project/vpn/tables.py:285 dashboards/project/vpn/tables.py:303#: dashboards/project/vpn/tables.py:288 dashboards/project/vpn/tables.py:306#: dashboards/project/vpn/tables.py:32 dashboards/project/vpn/workflows.py:192#: dashboards/project/vpn/tables.py:41 dashboards/project/vpn/workflows.py:289#: dashboards/project/vpn/tables.py:50 dashboards/project/vpn/workflows.py:93#: dashboards/project/vpn/tables.py:59 dashboards/project/vpn/workflows.py:474#: dashboards/project/vpn/tables.py:73 msgid ""Delete VPN Service"" msgid_plural ""Delete VPN Services"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:81 msgid ""Scheduled deletion of VPN Service"" msgid_plural ""Scheduled deletion of VPN Services"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:99 msgid ""Delete IKE Policy"" msgid_plural ""Delete IKE Policies"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:107 msgid ""Scheduled deletion of IKE Policy"" msgid_plural ""Scheduled deletion of IKE Policies"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:125 msgid ""Delete IPSec Policy"" msgid_plural ""Delete IPSec Policies"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:133 msgid ""Scheduled deletion of IPSec Policy"" msgid_plural ""Scheduled deletion of IPSec Policies"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:151 msgid ""Delete IPSec Site Connection"" msgid_plural ""Delete IPSec Site Connections"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:159 msgid ""Scheduled deletion of IPSec Site Connection"" msgid_plural ""Scheduled deletion of IPSec Site Connections"" msgstr[0] """" msgstr[1] """" #: dashboards/project/vpn/tables.py:167#: dashboards/project/vpn/tables.py:183#: dashboards/project/vpn/tables.py:197#: dashboards/project/vpn/tables.py:211#: dashboards/project/vpn/tables.py:235 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:19 msgid ""VPN Service"" msgstr ""VPN Service"" #: dashboards/project/vpn/tables.py:237 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:23 msgid ""IKE Policy"" msgstr ""IKE Policy"" #: dashboards/project/vpn/tables.py:239 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:27 msgid ""IPSec Policy"" msgstr ""IPSec Policy"" #: dashboards/project/vpn/tables.py:248 dashboards/project/vpn/tabs.py:31 msgid ""IPSec Site Connections"" msgstr ""IPSec Site Connections"" #: dashboards/project/vpn/tables.py:275 dashboards/project/vpn/tabs.py:51 msgid ""VPN Services"" msgstr ""VPN Services"" #: dashboards/project/vpn/tables.py:289 dashboards/project/vpn/tables.py:307#: dashboards/project/vpn/tables.py:293 dashboards/project/vpn/tabs.py:71 msgid ""IKE Policies"" msgstr ""IKE Policies"" #: dashboards/project/vpn/tables.py:311 dashboards/project/vpn/tabs.py:91 msgid ""IPSec Policies"" msgstr ""IPSec Policies"" ","""POT-Creation-Date: 2014-10-04 19:24-0500\n"" ""PO-Revision-Date: 2014-10-04 04:46+0000\n""#: api/neutron.py:206#: api/neutron.py:852#: api/neutron.py:889#: api/neutron.py:1022#: api/neutron.py:1040#: api/neutron.py:1055#: dashboards/admin/info/tables.py:170 dashboards/admin/instances/tables.py:82 #: dashboards/admin/instances/tables.py:125#: dashboards/project/images/images/forms.py:195#: dashboards/project/loadbalancers/tables.py:221#: dashboards/project/vpn/tables.py:183 dashboards/project/vpn/tables.py:213 #: dashboards/project/vpn/tables.py:233 dashboards/project/vpn/tables.py:251#: dashboards/project/images/images/forms.py:43 #: dashboards/project/images/images/forms.py:198#: dashboards/project/loadbalancers/tables.py:223#: dashboards/project/vpn/tables.py:215 dashboards/project/vpn/workflows.py:30#: dashboards/admin/instances/tables.py:37 #: dashboards/admin/instances/tables.py:159#: dashboards/project/volumes/volumes/tables.py:371 #: dashboards/project/volumes/volumes/tables.py:385 usage/quotas.py:74#: dashboards/admin/networks/forms.py:233#: dashboards/project/networks/forms.py:37#: dashboards/project/images/images/forms.py:101 #: dashboards/project/images/images/forms.py:237#: dashboards/admin/instances/tables.py:121#: dashboards/admin/instances/tables.py:138#: dashboards/project/loadbalancers/tables.py:228 #: dashboards/project/loadbalancers/tables.py:262#: dashboards/project/vpn/tables.py:193 dashboards/project/vpn/tables.py:220#: dashboards/admin/instances/tables.py:85#: dashboards/admin/instances/tables.py:127#: dashboards/admin/instances/tables.py:34 msgid ""Migrate"" msgstr ""Migrate"" #: dashboards/admin/instances/tables.py:35 msgid ""Scheduled migration (pending confirmation) of"" msgstr ""Scheduled migration (pending confirmation) of"" #: dashboards/admin/instances/tables.py:36 #: dashboards/project/access_and_security/floating_ips/workflows.py:37 #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:196 #: dashboards/project/volumes/volumes/tables.py:410 msgid ""Instance"" msgstr ""Instance"" #: dashboards/admin/instances/tables.py:53#: dashboards/admin/instances/tables.py:80 #: dashboards/admin/instances/tables.py:114#: dashboards/admin/instances/tables.py:81#: dashboards/admin/instances/tables.py:83#: dashboards/admin/instances/tables.py:84#: dashboards/admin/instances/tables.py:86#: dashboards/admin/instances/tables.py:87#: dashboards/admin/instances/tables.py:129#: dashboards/project/loadbalancers/tables.py:253#: dashboards/admin/instances/tables.py:132#: dashboards/admin/instances/tables.py:143#: dashboards/admin/instances/tables.py:150#: dashboards/admin/instances/tables.py:152#: dashboards/admin/networks/forms.py:238#: dashboards/project/networks/forms.py:42#: dashboards/admin/networks/forms.py:239#: dashboards/admin/networks/forms.py:240#: dashboards/admin/networks/forms.py:251 #: dashboards/project/networks/forms.py:51#: dashboards/admin/networks/forms.py:256 #: dashboards/project/networks/forms.py:56#: dashboards/project/volumes/volumes/tables.py:384#: dashboards/project/volumes/volumes/tables.py:383#: dashboards/project/loadbalancers/tables.py:91 #: dashboards/project/loadbalancers/tables.py:261#: dashboards/project/loadbalancers/tables.py:288#: dashboards/project/loadbalancers/tables.py:75 #: dashboards/project/loadbalancers/tables.py:89 #: dashboards/project/loadbalancers/tables.py:104 #: dashboards/project/loadbalancers/tables.py:113 #: dashboards/project/vpn/tables.py:67 dashboards/project/vpn/tables.py:81 #: dashboards/project/vpn/tables.py:95 dashboards/project/vpn/tables.py:109#: dashboards/project/loadbalancers/tables.py:278#: dashboards/project/loadbalancers/tables.py:227#: dashboards/project/images/images/forms.py:47#: dashboards/project/images/images/forms.py:49 #: dashboards/project/images/images/forms.py:56 #: dashboards/project/images/images/forms.py:62#: dashboards/project/images/images/forms.py:50 #: dashboards/project/images/images/forms.py:67 #: dashboards/project/images/images/forms.py:72#: dashboards/project/images/images/forms.py:57#: dashboards/project/images/images/forms.py:68#: dashboards/project/images/images/forms.py:78 #: dashboards/project/images/images/forms.py:219#: dashboards/project/images/images/forms.py:83 #: dashboards/project/images/images/forms.py:214#: dashboards/project/images/images/forms.py:85 #: dashboards/project/images/images/forms.py:221#: dashboards/project/images/images/forms.py:87 #: dashboards/project/images/images/forms.py:223#: dashboards/project/images/images/forms.py:93 #: dashboards/project/images/images/forms.py:229#: dashboards/project/images/images/forms.py:95 #: dashboards/project/images/images/forms.py:231#: dashboards/project/images/images/forms.py:102 #: dashboards/project/images/images/forms.py:238#: dashboards/project/images/images/forms.py:145#: dashboards/project/images/images/forms.py:148#: dashboards/project/images/images/forms.py:186#: dashboards/project/images/images/forms.py:190#: dashboards/project/images/images/forms.py:203#: dashboards/project/images/images/forms.py:209#: dashboards/project/images/images/forms.py:251#: dashboards/project/images/images/forms.py:278#: dashboards/project/loadbalancers/tables.py:225msgstr """"#: dashboards/project/loadbalancers/tables.py:259#: dashboards/project/loadbalancers/tables.py:285#: dashboards/project/loadbalancers/tables.py:286#: dashboards/project/loadbalancers/tables.py:30#: dashboards/project/loadbalancers/tables.py:39#: dashboards/project/loadbalancers/tables.py:57#: dashboards/project/loadbalancers/tables.py:66#: dashboards/project/loadbalancers/tables.py:76 #: dashboards/project/loadbalancers/tables.py:90 #: dashboards/project/loadbalancers/tables.py:105 #: dashboards/project/loadbalancers/tables.py:114 #: dashboards/project/volumes/backups/tables.py:49 #: dashboards/project/vpn/tables.py:68 dashboards/project/vpn/tables.py:82 #: dashboards/project/vpn/tables.py:96 dashboards/project/vpn/tables.py:110 #, python-format msgid ""Scheduled deletion of %(data_type)s"" msgstr ""Scheduled deletion of %(data_type)s"" #: dashboards/project/loadbalancers/tables.py:77 #: dashboards/project/loadbalancers/tables.py:229 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:18 msgid ""VIP"" msgstr ""VIP"" #: dashboards/project/loadbalancers/tables.py:78 msgid ""VIPs"" msgstr ""VIPs"" #: dashboards/project/loadbalancers/tables.py:92 #: dashboards/project/loadbalancers/tables.py:234 #: dashboards/project/loadbalancers/tabs.py:29 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:38 msgid ""Pools"" msgstr ""Pools"" #: dashboards/project/loadbalancers/tables.py:106 #: dashboards/project/loadbalancers/workflows.py:620 #: dashboards/project/loadbalancers/workflows.py:683 msgid ""Monitor"" msgstr ""Monitor""#: dashboards/project/loadbalancers/tables.py:292 #: dashboards/project/loadbalancers/tabs.py:69 msgid ""Monitors"" msgstr ""Monitors""msgid ""Member"" msgstr ""Member"" #: dashboards/project/loadbalancers/tables.py:116 #: dashboards/project/loadbalancers/tables.py:266 #: dashboards/project/loadbalancers/tabs.py:49 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:39 msgid ""Members"" msgstr ""Members"" #: dashboards/project/loadbalancers/tables.py:122#: dashboards/project/loadbalancers/tables.py:134#: dashboards/project/loadbalancers/tables.py:151#: dashboards/project/loadbalancers/tables.py:163#: dashboards/project/loadbalancers/tables.py:184#: dashboards/project/loadbalancers/tables.py:200#: dashboards/project/loadbalancers/tables.py:207#: dashboards/project/loadbalancers/tables.py:224#: dashboards/project/loadbalancers/tables.py:226#: dashboards/project/vpn/tables.py:216 dashboards/project/vpn/workflows.py:32#: dashboards/project/loadbalancers/tables.py:257#: dashboards/project/loadbalancers/tables.py:283#: dashboards/project/loadbalancers/tables.py:287#: dashboards/project/vpn/tables.py:217 dashboards/project/vpn/workflows.py:31msgstr """"#: dashboards/project/volumes/volumes/tables.py:431#: dashboards/project/volumes/volumes/tables.py:382 msgid ""Detach"" msgstr ""Detach"" #: dashboards/project/volumes/volumes/tables.py:412#: dashboards/project/volumes/volumes/tables.py:421#: dashboards/project/vpn/tables.py:236 dashboards/project/vpn/tables.py:254#: dashboards/project/vpn/tables.py:239 dashboards/project/vpn/tables.py:257#: dashboards/project/vpn/tables.py:31 dashboards/project/vpn/workflows.py:192#: dashboards/project/vpn/tables.py:40 dashboards/project/vpn/workflows.py:289#: dashboards/project/vpn/tables.py:49 dashboards/project/vpn/workflows.py:93#: dashboards/project/vpn/tables.py:58 dashboards/project/vpn/workflows.py:474#: dashboards/project/vpn/tables.py:69 dashboards/project/vpn/tables.py:186 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:19 msgid ""VPN Service"" msgstr ""VPN Service"" #: dashboards/project/vpn/tables.py:70 dashboards/project/vpn/tables.py:226 #: dashboards/project/vpn/tabs.py:51 msgid ""VPN Services"" msgstr ""VPN Services"" #: dashboards/project/vpn/tables.py:83 dashboards/project/vpn/tables.py:188 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:23 msgid ""IKE Policy"" msgstr ""IKE Policy"" #: dashboards/project/vpn/tables.py:84 dashboards/project/vpn/tables.py:244 #: dashboards/project/vpn/tabs.py:71 msgid ""IKE Policies"" msgstr ""IKE Policies"" #: dashboards/project/vpn/tables.py:97 dashboards/project/vpn/tables.py:190 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:27 msgid ""IPSec Policy"" msgstr ""IPSec Policy"" #: dashboards/project/vpn/tables.py:98 dashboards/project/vpn/tables.py:262 #: dashboards/project/vpn/tabs.py:91 msgid ""IPSec Policies"" msgstr ""IPSec Policies"" #: dashboards/project/vpn/tables.py:111 msgid ""IPSec Site Connection"" msgstr ""IPSec Site Connection"" #: dashboards/project/vpn/tables.py:112 dashboards/project/vpn/tables.py:199 #: dashboards/project/vpn/tabs.py:31 msgid ""IPSec Site Connections"" msgstr ""IPSec Site Connections"" #: dashboards/project/vpn/tables.py:118#: dashboards/project/vpn/tables.py:134#: dashboards/project/vpn/tables.py:148#: dashboards/project/vpn/tables.py:162#: dashboards/project/vpn/tables.py:240 dashboards/project/vpn/tables.py:258",4281,3405
openstack%2Fkeystone~proposed%2Fjuno~Icc5646c143a234127a8b4ac8a74342ef3dca7e80,openstack/keystone,proposed/juno,Icc5646c143a234127a8b4ac8a74342ef3dca7e80,Validates controller methods exist when specified,MERGED,2014-10-06 14:34:06.000000000,2014-10-07 08:50:52.000000000,2014-10-07 08:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-06 14:34:06.000000000', 'files': ['keystone/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ae1879a79e338e7323935fd17896ba8a4e84fb9', 'message': 'Validates controller methods exist when specified\n\nIt was possible to specify an invalid controller method in a router.\nThis will not cause an error until runtime. This change catches the\nerror much earlier in the application lifecycle. In fact with this\nchange errors should not be able to pass unit tests even if there is\nno specific test for the behavior.\n\nRelated-bug: #1377304\nChange-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80\n'}]",0,126308,4ae1879a79e338e7323935fd17896ba8a4e84fb9,10,6,1,4,,,0,"Validates controller methods exist when specified

It was possible to specify an invalid controller method in a router.
This will not cause an error until runtime. This change catches the
error much earlier in the application lifecycle. In fact with this
change errors should not be able to pass unit tests even if there is
no specific test for the behavior.

Related-bug: #1377304
Change-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80
",git fetch https://review.opendev.org/openstack/keystone refs/changes/08/126308/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/wsgi.py'],1,4ae1879a79e338e7323935fd17896ba8a4e84fb9,bug/1377304," getattr(controller, get_head_action) # ensure the attribute exists getattr(controller, get_action) # ensure the attribute exists getattr(controller, head_action) # ensure the attribute exists getattr(controller, put_action) # ensure the attribute exists getattr(controller, post_action) # ensure the attribute exists getattr(controller, patch_action) # ensure the attribute exists getattr(controller, delete_action) # ensure the attribute exists getattr(controller, get_post_action) # ensure the attribute exists",,8,0
openstack%2Fkeystone~proposed%2Fjuno~I3b91d8023d31555893fb944da73633a69d8e286f,openstack/keystone,proposed/juno,I3b91d8023d31555893fb944da73633a69d8e286f,Fixes an error deleting an endpoint group project,MERGED,2014-10-06 14:34:06.000000000,2014-10-07 08:50:43.000000000,2014-10-07 08:50:42.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-10-06 14:34:06.000000000', 'files': ['keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/contrib/endpoint_filter/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5caf29ad5d90a65d3b10dc55bb101c96b543e4f8', 'message': ""Fixes an error deleting an endpoint group project\n\nDeleting a endpoint group project fails because the router specifies\na controller method that doesn't exist. This returns a 500 error to\nthe user for what should be a successful operation.\n\nChange-Id: I3b91d8023d31555893fb944da73633a69d8e286f\nCloses-bug: #1377304\n""}]",0,126307,5caf29ad5d90a65d3b10dc55bb101c96b543e4f8,9,5,1,4,,,0,"Fixes an error deleting an endpoint group project

Deleting a endpoint group project fails because the router specifies
a controller method that doesn't exist. This returns a 500 error to
the user for what should be a successful operation.

Change-Id: I3b91d8023d31555893fb944da73633a69d8e286f
Closes-bug: #1377304
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/126307/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/contrib/endpoint_filter/controllers.py']",2,5caf29ad5d90a65d3b10dc55bb101c96b543e4f8,bug/1377304," @controller.protected() def remove_endpoint_group_from_project(self, context, endpoint_group_id, project_id): """"""Remove the endpoint group from associated project."""""" self.assignment_api.get_project(project_id) self.endpoint_filter_api.get_endpoint_group(endpoint_group_id) self.endpoint_filter_api.remove_endpoint_group_from_project( endpoint_group_id, project_id) "," def remove_endpoint_group_from_project(self, context, endpoint_group_id, project_id): """"""Remove the endpoint group from associated project."""""" self.assignment_api.get_project(project_id) self.endpoint_filter_api.get_endpoint_group(endpoint_group_id) self.endpoint_filter_api.remove_endpoint_group_from_project( endpoint_group_id, project_id) @controller.protected()",23,9
openstack%2Fglance~proposed%2Fjuno~I681747b6579a2284f23bf154889a61c639b0616d,openstack/glance,proposed/juno,I681747b6579a2284f23bf154889a61c639b0616d,Specify the MetadefNamespace.namespace column is not nullable,MERGED,2014-10-07 05:15:35.000000000,2014-10-07 08:50:34.000000000,2014-10-07 08:50:33.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-10-07 05:15:35.000000000', 'files': ['glance/db/sqlalchemy/models_metadef.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/be38189310e38a18f841f27808d469e01ba7f696', 'message': 'Specify the MetadefNamespace.namespace column is not nullable\n\nThe metadef_namespaces table definition indicates the namespace\ncolumn as not accepting nulls. The related MetadefNamespace ORM class\nshould also indicate that the namespace column does not accept nulls\nwith ""nullable=False"" in the column definition.\n\nChange-Id: I681747b6579a2284f23bf154889a61c639b0616d\nCloses-Bug: 1367619\n(cherry picked from commit 10e858d57be5e04615f390b3060c8aeadaeed954)\n'}]",0,126468,be38189310e38a18f841f27808d469e01ba7f696,5,2,1,10383,,,0,"Specify the MetadefNamespace.namespace column is not nullable

The metadef_namespaces table definition indicates the namespace
column as not accepting nulls. The related MetadefNamespace ORM class
should also indicate that the namespace column does not accept nulls
with ""nullable=False"" in the column definition.

Change-Id: I681747b6579a2284f23bf154889a61c639b0616d
Closes-Bug: 1367619
(cherry picked from commit 10e858d57be5e04615f390b3060c8aeadaeed954)
",git fetch https://review.opendev.org/openstack/glance refs/changes/68/126468/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/db/sqlalchemy/models_metadef.py'],1,be38189310e38a18f841f27808d469e01ba7f696,," namespace = Column(String(80), nullable=False)", namespace = Column(String(80)),1,1
openstack%2Fglance~proposed%2Fjuno~I26965a549daf9340621b0f18a1b845b39bac4bd8,openstack/glance,proposed/juno,I26965a549daf9340621b0f18a1b845b39bac4bd8,Make compute-trust.json compatible with TrustFilter,MERGED,2014-10-07 04:45:33.000000000,2014-10-07 08:48:41.000000000,2014-10-07 08:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2537}, {'_account_id': 6549}, {'_account_id': 12299}]","[{'number': 1, 'created': '2014-10-07 04:45:33.000000000', 'files': ['etc/metadefs/compute-trust.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/3c0ff8d94562bf42d4092db0aaad04fb5cc93fe3', 'message': 'Make compute-trust.json compatible with TrustFilter\n\nCurrent properties inside compute-trust.json does not match\nwith how TrustFilter in nova works. JSON provides True/False\nboolean values but TrustFilter expects trusted/untrusted/unknown\nstring values. This patch repairs compute-trust.json to be\ncompatible with TrustFilter.\n\nChange-Id: I26965a549daf9340621b0f18a1b845b39bac4bd8\nCloses-Bug: #1369581\n(cherry picked from commit 39e90f29d93f991d95092de5f93a239be1b3ca3b)\n'}]",0,126463,3c0ff8d94562bf42d4092db0aaad04fb5cc93fe3,5,5,1,7665,,,0,"Make compute-trust.json compatible with TrustFilter

Current properties inside compute-trust.json does not match
with how TrustFilter in nova works. JSON provides True/False
boolean values but TrustFilter expects trusted/untrusted/unknown
string values. This patch repairs compute-trust.json to be
compatible with TrustFilter.

Change-Id: I26965a549daf9340621b0f18a1b845b39bac4bd8
Closes-Bug: #1369581
(cherry picked from commit 39e90f29d93f991d95092de5f93a239be1b3ca3b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/63/126463/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/metadefs/compute-trust.json'],1,3c0ff8d94562bf42d4092db0aaad04fb5cc93fe3,," ""description"": ""Trusted compute pools with Intel Trusted Execution Technology (Intel TXT) support IT compliance by protecting virtualized data centers - private, public, and hybrid clouds against attacks toward hypervisor and BIOS, firmware, and other pre-launch software components. The Nova trust scheduling filter must be enabled and configured with the trust attestation service in order to use this feature."", ""description"": ""Select to ensure that node has been attested by Intel Trusted Execution Technology (Intel TXT). The Nova trust scheduling filter must be enabled and configured with the trust attestation service in order to use this feature."", ""type"": ""string"", ""enum"": [ ""trusted"", ""untrusted"", ""unknown"" ] } } }"," ""description"": ""Trusted compute pools with Intel Trusted Execution Technology (Intel TXT) support IT compliance by protecting virtualized data centers - private, public, and hybrid clouds against attacks toward hypervisor and BIOS, firmware, and other pre-launch software components."", ""description"": ""Select to ensure that node has been attested by Intel Trusted Execution Technology (Intel TXT)."", ""type"": ""boolean"" } } } ",9,4
openstack%2Fhorizon~master~Ib8d51b49ac51092a3d7db6d889f4427167e5adb0,openstack/horizon,master,Ib8d51b49ac51092a3d7db6d889f4427167e5adb0,show correct link to compute instances in stack resource overview tab,MERGED,2014-08-21 23:08:50.000000000,2014-10-07 08:47:09.000000000,2014-10-07 08:47:08.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 7187}, {'_account_id': 13039}]","[{'number': 1, 'created': '2014-08-21 23:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2dbcdff23c84c1dc3e001ebf38cb029f139039ed', 'message': 'show correct link to compute instances in stack resource overview tab\n\nThere are two related fixes in the stacks resource overview page.\nFirst, any resource types for which horizon does not have a link for\nwere getting a URL of ""None"" in the uuid field, and with this\nchange the link is suppressed if it is None. The second part involves\nadding compute resources to the resource mappings, so that the uuid\nfield for those links to the instance detail page.\n\nChange-Id: Ib8d51b49ac51092a3d7db6d889f4427167e5adb0\n'}, {'number': 2, 'created': '2014-08-21 23:13:27.000000000', 'files': ['openstack_dashboard/dashboards/project/stacks/templates/stacks/_resource_overview.html', 'openstack_dashboard/dashboards/project/stacks/mappings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e8f5dc442c68d9ac206ae3a09bf5c18fe8125430', 'message': 'show correct link to compute instances in stack resource overview tab\n\nThere are two related fixes in the stacks resource overview page.\nFirst, any resource types for which horizon does not have a link for\nwere getting a URL of ""None"" in the uuid field, and with this\nchange the link is suppressed if it is None. The second part involves\nadding compute resources to the resource mappings, so that the uuid\nfield for those links to the instance detail page.\n\nChange-Id: Ib8d51b49ac51092a3d7db6d889f4427167e5adb0\nCloses-Bug: 1322162\n'}]",0,116128,e8f5dc442c68d9ac206ae3a09bf5c18fe8125430,10,5,2,12606,,,0,"show correct link to compute instances in stack resource overview tab

There are two related fixes in the stacks resource overview page.
First, any resource types for which horizon does not have a link for
were getting a URL of ""None"" in the uuid field, and with this
change the link is suppressed if it is None. The second part involves
adding compute resources to the resource mappings, so that the uuid
field for those links to the instance detail page.

Change-Id: Ib8d51b49ac51092a3d7db6d889f4427167e5adb0
Closes-Bug: 1322162
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/116128/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/stacks/templates/stacks/_resource_overview.html', 'openstack_dashboard/dashboards/project/stacks/mappings.py']",2,2dbcdff23c84c1dc3e001ebf38cb029f139039ed,bug/1322162," ""OS::Nova::Server"": { 'link': 'horizon:project:instances:detail'},",,6,0
openstack%2Fglance~proposed%2Fjuno~Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602,openstack/glance,proposed/juno,Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602,Nova instance config drive Metadata Definition,MERGED,2014-10-07 04:42:48.000000000,2014-10-07 08:42:31.000000000,2014-10-07 08:42:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2537}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-10-07 04:42:48.000000000', 'files': ['etc/metadefs/compute-instance-data.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/5601f7fcdc4482ba27908e156e350095be1e0805', 'message': 'Nova instance config drive Metadata Definition\n\nA nova Juno FFE landed to support setting the\nimg_config_drive property on images to require images\nto be booted with a config drive. The Glance Metadata\nDefinitions should include this property.\n\nSee Nova Blueprint:\nhttps://blueprints.launchpad.net/nova/+spec/config-drive-image-property\n\nChange-Id: Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602\nCloses-bug: 1367981\n(cherry picked from commit 0dd620c7bd7f07935e1cea5d0bfab2a41f754d1b)\n'}]",0,126461,5601f7fcdc4482ba27908e156e350095be1e0805,5,4,1,7665,,,0,"Nova instance config drive Metadata Definition

A nova Juno FFE landed to support setting the
img_config_drive property on images to require images
to be booted with a config drive. The Glance Metadata
Definitions should include this property.

See Nova Blueprint:
https://blueprints.launchpad.net/nova/+spec/config-drive-image-property

Change-Id: Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602
Closes-bug: 1367981
(cherry picked from commit 0dd620c7bd7f07935e1cea5d0bfab2a41f754d1b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/61/126461/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/metadefs/compute-instance-data.json'],1,5601f7fcdc4482ba27908e156e350095be1e0805,,"{ ""namespace"": ""OS::Compute::InstanceData"", ""display_name"": ""Instance Config Data"", ""description"": ""Instances can perform self-configuration based on data made available to the running instance. These properties affect instance configuration."", ""visibility"": ""public"", ""protected"": true, ""resource_type_associations"": [ { ""name"": ""OS::Glance::Image"" }, { ""name"": ""OS::Cinder::Volume"", ""properties_target"": ""image"" } ], ""properties"": { ""img_config_drive"": { ""title"": ""Config Drive"", ""description"": ""Set this property on images to mandatory to require Nova to use a config drive when booting the image. OpenStack can be configured to write metadata to a special configuration drive that will be attached to the instance when it boots. The instance can retrieve any information from the config drive. One use case for the config drive is to pass network configuration information to the instance. See also: http://docs.openstack.org/user-guide/content/config-drive.html"", ""type"": ""string"", ""enum"": [ ""optional"", ""mandatory"" ] } } } ",,27,0
openstack%2Fglance~proposed%2Fjuno~Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6,openstack/glance,proposed/juno,Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6,Add missing metadefs for Aggregate Filters,MERGED,2014-10-07 04:41:34.000000000,2014-10-07 08:38:04.000000000,2014-10-07 08:38:04.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2537}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-10-07 04:41:34.000000000', 'files': ['etc/metadefs/compute-aggr-disk-filter.json', 'etc/metadefs/compute-aggr-num-instances.json', 'etc/metadefs/compute-aggr-iops-filter.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/94eac77743635face04ee5bad69d57d2f7e97eb6', 'message': 'Add missing metadefs for Aggregate Filters\n\nThe below spec implemented in Juno added numerous properties\nthat can be added to Host Aggregates. The Metadata\nDefinitions catalog should include them.\n\nhttps://github.com/openstack/nova-specs/blob/master/specs/juno/per-aggregate-filters.rst\n\nChange-Id: Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6\nCloses-bug: 1368032\n(cherry picked from commit 313d4f272cbeabfdcb39de4bcb441749f56fb4d4)\n'}]",0,126460,94eac77743635face04ee5bad69d57d2f7e97eb6,5,4,1,7665,,,0,"Add missing metadefs for Aggregate Filters

The below spec implemented in Juno added numerous properties
that can be added to Host Aggregates. The Metadata
Definitions catalog should include them.

https://github.com/openstack/nova-specs/blob/master/specs/juno/per-aggregate-filters.rst

Change-Id: Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6
Closes-bug: 1368032
(cherry picked from commit 313d4f272cbeabfdcb39de4bcb441749f56fb4d4)
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/126460/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/metadefs/compute-aggr-disk-filter.json', 'etc/metadefs/compute-aggr-num-instances.json', 'etc/metadefs/compute-aggr-iops-filter.json']",3,94eac77743635face04ee5bad69d57d2f7e97eb6,,"{ ""namespace"": ""OS::Compute::AggregateIoOpsFilter"", ""display_name"": ""IO Ops per Host"", ""description"": ""Properties related to the Nova scheduler filter AggregateIoOpsFilter. Filters aggregate hosts based on the number of instances currently changing state. Hosts in the aggregate with too many instances changing state will be filtered out. The filter must be enabled in the Nova scheduler to use these properties."", ""visibility"": ""public"", ""protected"": true, ""resource_type_associations"": [ { ""name"": ""OS::Nova::Aggregate"" } ], ""properties"": { ""max_io_ops_per_host"": { ""title"": ""Maximum IO Operations per Host"", ""description"": ""Prevents hosts in the aggregate that have this many or more instances currently in build, resize, snapshot, migrate, rescue or unshelve to be scheduled for new instances."", ""type"": ""integer"", ""readonly"": false, ""default"": 8, ""minimum"": 1 } }, ""objects"": [] } ",,65,0
openstack%2Fheat~master~Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63,openstack/heat,master,Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63,Add OS::Ironic::Port resource,ABANDONED,2014-07-02 15:16:35.000000000,2014-10-07 08:32:52.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-02 15:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/29bc8f04a0b98db76081c765bb81b0106ef18732', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 2, 'created': '2014-07-03 13:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d660f03c226b50bd1060b67d9d678726a1ee49b6', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 3, 'created': '2014-07-16 21:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/92ca33fb4b57cb5f623b664dde0da7f30f30bf1d', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 4, 'created': '2014-07-17 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/da0f71cd7ffedf0923f29f5cab67ec4aae874747', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 5, 'created': '2014-07-17 12:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/df0f0575172e6bd6d97c3b1813e7a6ccd164c6df', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 6, 'created': '2014-07-23 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ac1a1d115ffc1c083d7608a1474a6a9505d9fd75', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 7, 'created': '2014-07-24 19:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6f1fb750e953bd126d6f41251db345d011c59687', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}, {'number': 8, 'created': '2014-07-25 18:26:05.000000000', 'files': ['contrib/ironic/ironic/tests/test_port.py', 'contrib/ironic/ironic/resources/port.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e2a7bc5608a631c83436e552272d2d13f731d9d5', 'message': 'Add OS::Ironic::Port resource\n\nAdds initial support for Ironic ports\n\nblueprint: ironic-resource\nChange-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63\n'}]",0,104224,e2a7bc5608a631c83436e552272d2d13f731d9d5,25,1,8,4328,,,0,"Add OS::Ironic::Port resource

Adds initial support for Ironic ports

blueprint: ironic-resource
Change-Id: Idc9eaaf1206e4b92fa151b2d5fe7087435c5eb63
",git fetch https://review.opendev.org/openstack/heat refs/changes/24/104224/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/ironic/ironic/tests/test_port.py', 'contrib/ironic/ironic/resources/port.py']",2,29bc8f04a0b98db76081c765bb81b0106ef18732,bp/ironic-resource,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from ironicclient import exc as ironic_ex from heat.engine import properties from .. import clients # noqa from . import ironic # noqa from heat.openstack.common.gettextutils import _ from heat.openstack.common import log as logging LOG = logging.getLogger(__name__) class IronicPort(ironic.IronicResource): PROPERTIES = ( NODE, ADDRESS, EXTRA ) = ( 'node', 'address', 'extra' ) properties_schema = { NODE: properties.Schema( properties.Schema.STRING, _(""Node the port belongs to.""), update_allowed=True), ADDRESS: properties.Schema( properties.Schema.STRING, _(""MAC address for the port.""), required=True), EXTRA: properties.Schema( properties.Schema.MAP, description=_(""The port metadata""), update_allowed=True) } def handle_create(self): prop_key_map = {self.NODE: 'node_uuid'} kwargs = self.prepare_properties(self.properties, prop_key_map) port = self.ironic().port.create(**kwargs) self.resource_id_set(port.uuid) def handle_delete(self): if not self.resource_id: return try: self.ironic().port.delete(self.resource_id) except ironic_ex.NotFound: pass return self._delete_task() def _show_resource(self): return self.ironic().port.get( self.resource_id) def resource_mapping(): return { 'OS::Ironic::Port': IronicPort, } def available_resource_mapping(): if not clients.ironic_client: return {} return resource_mapping() ",,166,0
openstack%2Fheat~master~I55f86b7a634bbac3683124c3d3f389ee8a687f97,openstack/heat,master,I55f86b7a634bbac3683124c3d3f389ee8a687f97,Add OS::Ironic::Node resource,ABANDONED,2014-07-02 15:16:35.000000000,2014-10-07 08:32:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-02 15:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f51e91ec9e0673615fd5144ec475afedcb833fc4', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 2, 'created': '2014-07-03 13:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ffb7fd6c3dfef683cff711c4a39517fb7789f070', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 3, 'created': '2014-07-16 21:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8d619a688b91632a21270b3b6c47ff4997e9e679', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 4, 'created': '2014-07-17 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/37398d49e78cd2d3b9d3ca3799082bb4b45e63c4', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 5, 'created': '2014-07-17 12:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ec896bf52fbd5fcfae89dfdb38014bcb7b1694d', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 6, 'created': '2014-07-23 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b7bf3755a5d2b55de1f8b96c704cd5f078d1c56e', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 7, 'created': '2014-07-24 19:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9080e3b4add634b035a1c7c1f94d730e93d115d5', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}, {'number': 8, 'created': '2014-07-25 18:26:05.000000000', 'files': ['contrib/ironic/ironic/resources/node.py', 'contrib/ironic/ironic/tests/test_node.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/11ab43391b7ab83633ea1be93cca0d7385789912', 'message': 'Add OS::Ironic::Node resource\n\nAdds initial support for Ironic nodes.\n\nblueprint: ironic-resource\nChange-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97\n'}]",3,104223,11ab43391b7ab83633ea1be93cca0d7385789912,29,4,8,4328,,,0,"Add OS::Ironic::Node resource

Adds initial support for Ironic nodes.

blueprint: ironic-resource
Change-Id: I55f86b7a634bbac3683124c3d3f389ee8a687f97
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/104223/8 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/ironic/ironic/resources/node.py', 'contrib/ironic/ironic/tests/test_node.py']",2,f51e91ec9e0673615fd5144ec475afedcb833fc4,bp/ironic-resource,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import ironicclient.exc as ironic_ex import mock from heat.common import template_format from heat.engine import parser from heat.engine import resource from heat.engine import scheduler from heat.engine import template from heat.tests.common import HeatTestCase from heat.tests import utils from .. import clients # noqa from ..resources import node # noqa node_template = ''' heat_template_version: 2013-05-23 resources: node: type: OS::Ironic::Node properties: driver: pxe_ssh ''' class IronicNodeTest(HeatTestCase): def setUp(self): super(IronicNodeTest, self).setUp() self.ctx = utils.dummy_context() # For unit testing purpose. Register resource provider # explicitly. resource._register_class(""OS::Ironic::Node"", node.IronicNode) t = template_format.parse(node_template) self.stack = parser.Stack( self.ctx, 'node_test_stack', template.Template(t) ) self.node = self.stack['node'] def test_resource_mapping(self): mapping = node.resource_mapping() self.assertEqual(1, len(mapping)) self.assertIn('OS::Ironic::Node', mapping) self.assertIsInstance(self.node, node.IronicNode) @mock.patch.object(clients.Clients, 'ironic') def test_node_handle_create(self, fake_client): node_id = '19e45ebf-30ac-43e3-8192-bc1a79d39eb9' val = mock.Mock() val.uuid = node_id fake_client.return_value.node.create.return_value = val self.node.handle_create() self.assertEqual(node_id, self.node.resource_id) @mock.patch.object(clients.Clients, 'ironic') def test_node_handle_delete(self, fake_client): returns = ['ok', ironic_ex.NotFound()] def side_effect(*args): result = returns.pop(0) if isinstance(result, Exception): raise result return result node_id = '19e45ebf-30ac-43e3-8192-bc1a79d39eb9' self.assertIsNone(self.node.handle_delete()) self.node.resource_id = node_id fake_client.return_value.node.delete.side_effect = side_effect self.assertIsNone(scheduler.TaskRunner(self.node.handle_delete)()) exc = ironic_ex.NotFound fake_client.return_value.node.delete.side_effect = exc self.assertIsNone(scheduler.TaskRunner(self.node.handle_delete)()) ",,174,0
openstack%2Fheat~master~I9932637dceca6e33565754a5723b44365cae159c,openstack/heat,master,I9932637dceca6e33565754a5723b44365cae159c,Add OS::Ironic::Chassis resource,ABANDONED,2014-06-27 13:58:06.000000000,2014-10-07 08:32:22.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6899}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-06-27 13:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/37dcc5f6c46e901803b618c30f5678e3213b9b99', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 2, 'created': '2014-07-02 15:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c1568caa7275b8bb4a15ca5b6904596d157195bf', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 3, 'created': '2014-07-03 13:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e6ed5a662c2a449d00376fbe9bfdb1f2597d41c', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 4, 'created': '2014-07-16 21:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a26673c904604ad3fab72773bebb699ad6e23930', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 5, 'created': '2014-07-17 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/21a0217c38f9383b913a9d06741b1fd95f6867a4', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 6, 'created': '2014-07-17 12:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/704340beb22757e8a3a86b5ad4f05aebe25f0969', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 7, 'created': '2014-07-23 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/278ff40d65bb1d516baf66142335b1ba537730cb', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 8, 'created': '2014-07-24 19:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b307c48f8d3444d7ec2f4025d1c21f7251759be1', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}, {'number': 9, 'created': '2014-07-25 18:26:06.000000000', 'files': ['contrib/ironic/ironic/resources/chassis.py', 'contrib/ironic/ironic/tests/test_chassis.py', 'contrib/ironic/ironic/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ef78dc2082bbccb866b400f8c6f75e205c4fddf0', 'message': 'Add OS::Ironic::Chassis resource\n\nAdds initial support for Ironic (in contrib), with one resource\nwhich exposes the chassis API.\n\nChange-Id: I9932637dceca6e33565754a5723b44365cae159c\nblueprint: ironic-resource\n'}]",8,103133,ef78dc2082bbccb866b400f8c6f75e205c4fddf0,45,7,9,4328,,,0,"Add OS::Ironic::Chassis resource

Adds initial support for Ironic (in contrib), with one resource
which exposes the chassis API.

Change-Id: I9932637dceca6e33565754a5723b44365cae159c
blueprint: ironic-resource
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/103133/8 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/ironic/ironic/tests/__init__.py', 'contrib/ironic/ironic/resources/chassis.py', 'contrib/ironic/ironic/resources/__init__.py', 'contrib/ironic/requirements.txt', 'contrib/ironic/ironic/clients.py', 'contrib/ironic/ironic/__init__.py', 'contrib/ironic/README.md']",7,37dcc5f6c46e901803b618c30f5678e3213b9b99,bp/ironic-resource,"Ironic plugin for OpenStack Heat ================================ This plugin enable using Ironic baremetal service via resources in a Heat template. ### 1. Install the Ironic plugin in Heat NOTE: Heat scans several directories to find plugins. The list of directories is specified in the configuration file ""heat.conf"" with the ""plugin_dirs"" directive. To install the Ironic plugin, one needs to first make sure the python-ironicclient package is installed - pip install -r requirements.txt, and copy the plugin folder, e.g. ironic to wherever plugin_dirs points to. ### 2. Restart heat Only the process ""heat-engine"" needs to be restarted to load the newly installed plugin. ",,149,0
openstack%2Fheat~master~I032824d92232aea1e02d7488951547dc677a92ac,openstack/heat,master,I032824d92232aea1e02d7488951547dc677a92ac,Add Ironic resource base class,ABANDONED,2014-07-02 15:16:35.000000000,2014-10-07 08:32:02.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6498}, {'_account_id': 7404}, {'_account_id': 9542}, {'_account_id': 10035}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-02 15:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/375f41e187cf053ce42ee54c562facdb20a739ce', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 2, 'created': '2014-07-03 13:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1c42d07a92a666741c4d2ec229d50b9a7cb8faa5', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 3, 'created': '2014-07-16 21:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/714db7822e0cddb7d8ca012db3af4ce842d0d1aa', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 4, 'created': '2014-07-17 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/801424d3105c6382898b46618d01fecf67b7c0a0', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 5, 'created': '2014-07-23 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef52e9298c5b4d3b06ab3a2f4e97d087b779ad27', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 6, 'created': '2014-07-24 19:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e6dabef9e7f17ba9ae46fcb0062c2664af1b9b3f', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}, {'number': 7, 'created': '2014-07-25 18:26:05.000000000', 'files': ['contrib/ironic/ironic/tests/__init__.py', 'contrib/ironic/ironic/resources/__init__.py', 'contrib/ironic/ironic/resources/ironic.py', 'contrib/ironic/requirements.txt', 'contrib/ironic/ironic/tests/test_ironic_base.py', 'contrib/ironic/ironic/clients.py', 'contrib/ironic/ironic/__init__.py', 'contrib/ironic/README.md'], 'web_link': 'https://opendev.org/openstack/heat/commit/1c0d00036b60aa3e69ecc0916bee04a471e53559', 'message': 'Add Ironic resource base class\n\nAdds initial support for Ironic (in contrib), a base and client class\nto be used by ironic resource plugins.\n\nblueprint: ironic-resource\nChange-Id: I032824d92232aea1e02d7488951547dc677a92ac\n'}]",8,104222,1c0d00036b60aa3e69ecc0916bee04a471e53559,40,9,7,4328,,,0,"Add Ironic resource base class

Adds initial support for Ironic (in contrib), a base and client class
to be used by ironic resource plugins.

blueprint: ironic-resource
Change-Id: I032824d92232aea1e02d7488951547dc677a92ac
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/104222/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/ironic/ironic/tests/__init__.py', 'contrib/ironic/ironic/resources/__init__.py', 'contrib/ironic/ironic/resources/ironic.py', 'contrib/ironic/requirements.txt', 'contrib/ironic/ironic/clients.py', 'contrib/ironic/ironic/tests/test_ironic_base.py', 'contrib/ironic/ironic/__init__.py', 'contrib/ironic/README.md']",8,375f41e187cf053ce42ee54c562facdb20a739ce,bp/ironic-resource,"Ironic plugin for OpenStack Heat ================================ This plugin enable using Ironic baremetal service via resources in a Heat template. ### 1. Install the Ironic plugin in Heat NOTE: Heat scans several directories to find plugins. The list of directories is specified in the configuration file ""heat.conf"" with the ""plugin_dirs"" directive. To install the Ironic plugin, one needs to first make sure the python-ironicclient package is installed - pip install -r requirements.txt, and copy the plugin folder, e.g. ironic to wherever plugin_dirs points to. ### 2. Restart heat Only the process ""heat-engine"" needs to be restarted to load the newly installed plugin. ",,314,0
openstack%2Fheat-specs~master~I20db33039643b9d78d2872864cac0d84a3fdebba,openstack/heat-specs,master,I20db33039643b9d78d2872864cac0d84a3fdebba,Spec for Ironic Heat (contrib) resources,ABANDONED,2014-09-11 13:02:52.000000000,2014-10-07 08:30:43.000000000,,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 217}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6773}, {'_account_id': 7144}, {'_account_id': 9542}, {'_account_id': 12870}]","[{'number': 1, 'created': '2014-09-11 13:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/9eb09dde703246ab1d4c15708c2c98634d6bf365', 'message': ""Spec for Ironic Heat (contrib) resources\n\nAn initial spec for the proposed Ironic resources, attempting to\nclarify the use-case and figure out what's missing to enable the\nready-state work which they aim to enable.\n\nChange-Id: I20db33039643b9d78d2872864cac0d84a3fdebba\nblueprint: ironic-resource\n""}, {'number': 2, 'created': '2014-09-11 13:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/4af1bc2de44ddd6981565c3fba2af3061db576f7', 'message': ""Spec for Ironic Heat (contrib) resources\n\nAn initial spec for the proposed Ironic resources, attempting to\nclarify the use-case and figure out what's missing to enable the\nready-state work which they aim to enable.\n\nCo-Authored-By: Victor Lowther <Victor_Lowther@dell.com>\nCo-Authored-By: Angus Thomas <athomas@redhat.com>\nblueprint: ironic-resource\nChange-Id: I20db33039643b9d78d2872864cac0d84a3fdebba\n""}, {'number': 3, 'created': '2014-09-11 13:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ad13e558defc9ace199e1970575faf5f135fd865', 'message': ""Spec for Ironic Heat (contrib) resources\n\nAn initial spec for the proposed Ironic resources, attempting to\nclarify the use-case and figure out what's missing to enable the\nready-state work which they aim to enable.\n\nCo-Authored-By: Victor Lowther <Victor_Lowther@dell.com>\nCo-Authored-By: Angus Thomas <athomas@redhat.com>\nblueprint: ironic-resource\nChange-Id: I20db33039643b9d78d2872864cac0d84a3fdebba\n""}, {'number': 4, 'created': '2014-09-11 16:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/bc5efac7f477b8f78780e5d6134438f7d04f0fd4', 'message': ""Spec for Ironic Heat (contrib) resources\n\nAn initial spec for the proposed Ironic resources, attempting to\nclarify the use-case and figure out what's missing to enable the\nready-state work which they aim to enable.\n\nCo-Authored-By: Victor Lowther <Victor_Lowther@dell.com>\nCo-Authored-By: Angus Thomas <athomas@redhat.com>\nblueprint: ironic-resource\nChange-Id: I20db33039643b9d78d2872864cac0d84a3fdebba\n""}, {'number': 5, 'created': '2014-09-11 16:27:26.000000000', 'files': ['specs/ironic-resources.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/00455318db03fcba92c089a3d1a154cf213fb3b9', 'message': ""Spec for Ironic Heat (contrib) resources\n\nAn initial spec for the proposed Ironic resources, attempting to\nclarify the use-case and figure out what's missing to enable the\nready-state work which they aim to enable.\n\nCo-Authored-By: Victor Lowther <Victor_Lowther@dell.com>\nCo-Authored-By: Angus Thomas <athomas@redhat.com>\nblueprint: ironic-resource\nChange-Id: I20db33039643b9d78d2872864cac0d84a3fdebba\n""}]",2,120778,00455318db03fcba92c089a3d1a154cf213fb3b9,25,12,5,4328,,,0,"Spec for Ironic Heat (contrib) resources

An initial spec for the proposed Ironic resources, attempting to
clarify the use-case and figure out what's missing to enable the
ready-state work which they aim to enable.

Co-Authored-By: Victor Lowther <Victor_Lowther@dell.com>
Co-Authored-By: Angus Thomas <athomas@redhat.com>
blueprint: ironic-resource
Change-Id: I20db33039643b9d78d2872864cac0d84a3fdebba
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/78/120778/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/ironic-resources.rst'],1,9eb09dde703246ab1d4c15708c2c98634d6bf365,bp/ironic-resource,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============================= The title of your blueprint ============================= https://blueprints.launchpad.net/heat/+spec/ironic-resource Add (contrib) resources which enable heat to interact directly with the Ironic API, rather than only via nova. Problem description =================== Ironic provides an (admin only) API which is used for the purposes of registering real hardware with the service, such that it may be made available via nova for baremetal boot. There are also some vendor-specific operations which are possible via Ironic, via integration with the various out-of-band management interfaces provided by some hardware, e.g DRAC/ILO, there are efforts underway to expose some of this functionality via the Ironic API: https://blueprints.launchpad.net/ironic/+spec/drac-raid-mgmt https://blueprints.launchpad.net/ironic/+spec/drac-management-driver https://blueprints.launchpad.net/ironic/+spec/drac-hw-discovery The primary use-case is TripleO, and in the undercloud, there are no users who aren't admins. The only actors present to use any of the undercloud components, including Heat, are admins, so whereas mostly Heat avoids adding admin-only resources, in this case the admin restriction is not a problem, and is consistent with some other contrib resources we already have (e.g the nova flavor resource, which we made live in contrib because of the admin-only restriction) In some cases, ordering is important when interacting with the out-of-band interfaces, and it may also be desirable to be able to transparently converge versions to a known state: 1. Aligning firmware and BIOS versions to a known version 2. Customizing BIOS configuration to suit the expected role of the node 2. Configuring node physical storage to suit the expecte role of the node The idea is to leverage Heat, which would interact with the Ironic API directly, as a pre-deployment step (before booting any baremetal boxes, e.g prior to a TripleO deployment), such that all out-of-band management actions can be completed, within the same model as is used for the actual deployment itself (e.g a Heat template). This would mean we can encapsulate all pre-deploy steps in a Heat template, e.g a provider resource which contains Ironic resources relating to the registered hardware. This would enable a single Heat resource to change state to ""CREATE_COMPLETE"" when the underlying hardware is correctly configured and in a ""ready state"", such that the actual hardware boot and software deployment may proceed. Here's an example use-case for a nova-compute node: 1. Update all relevant firmware to either whatever site policy dictates or the latest available version. 2. Force the NX bit on, force all virtualization options on, and otherwise tune the BIOS to perform best with virtualization workloads of the type you expect the machine to host. 3. Create the appropriate RAID arrays for local machine storage. 4. Resource marked CREATE_COMPLETE, so the undercloud can proceed and build nodes. Nodes dedicated to storage have the same general pattern, except: 1. All hardware vitualization options are turned off, and the BIOS is tuned to perform best with IO intensive workloads. 2. If there was a RAID controller, it was placed into JBOD mode, or configured to have all single-disk RAID 0 arrays otherwise. Optimally, it would be a good idea to put the OS on a RAID 1. The idea is to leverage Heat, which would interact with the Ironic API directly, as a pre-deployment step (before booting any baremetal boxes, e.g prior to a TripleO deployment), such that all out-of-band management actions can be completed, within the same model as is used for the actual deployment itself (e.g a Heat template). This would mean we can encapsulate all pre-deploy steps in a Heat template, e.g a provider resource which contains Ironic resources relating to the registered hardware. This would enable a single Heat resource to change state to ""CREATE_COMPLETE"" when the underlying hardware is correctly configured and in a ""ready state"", such that the actual hardware boot and software deployment may proceed. e.g: 1. Nodes boot and register as nodes with Ironic (autodiscovery step) 2. Undercloud takes a manifest of registered nodes, generates a Heat adopt template 3. Heat adopts the Ironic nodes (they become controlled via OS::Ironic::Node resources) 4. Heat orchestrates the configuration steps required to align the required settings for various roles. This will need to include setting some role-specific metadata on the node so it can be selected by the nova scheduler for a specific role (e.g compute, storage or whatever) via scheduler hints. Proposed change =============== Implement Ironic resources exposing the Ironic API via (optional) Heat resource plugins. This is the same as we currently do for all integrated (which are defaulted to enabled), and incubated (always optional, defaulted to disabled) projects, basically a thin wrapper resource around the underlying ReST API. There are draft resources for Chassis, Node and Port posted already: https://review.openstack.org/#/q/status:open+project:openstack/heat+branch:master+topic:bp/ironic-resource,n,z Alternatives ------------ Don't implement the resources and rely on scripts which directly interact with the Ironic API, prior to any orchestration via Heat. Implementation ============== Assignee(s) ----------- Primary assignee: Steven Hardy (shardy) Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- - Node resource - Chassis resource - Port resource These map to the Ironic API resources available, although the validity of Chassis has been questioned. Personally I'd rather expose the whole API unless some subset is due to be imminently deprecated or removed. Dependencies ============ None, but it may not be an obviously-useful feature until some of the related drac integration lands in Ironic, as well as completing autodiscovery and figuring out the adopt/update-converge and node tagging steps mentioned above. ",,126,0
openstack%2Fopenstack-manuals~master~I77bef35cc29ef0e8a9bb11d3020d013c104826a0,openstack/openstack-manuals,master,I77bef35cc29ef0e8a9bb11d3020d013c104826a0,Add PureStorage storage volume driver installation guide,MERGED,2014-10-02 03:03:28.000000000,2014-10-07 08:30:17.000000000,2014-10-07 08:30:17.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10068}, {'_account_id': 13461}]","[{'number': 1, 'created': '2014-10-02 03:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a8013a25b3ce3b9b6fa7e3a1e68a47bada6cc2e', 'message': 'Add PureStorage storage volume driver installation guide\n\nThis patch adds PureStorage storage volume driver installation guide.\n\nDocImpact\nImplements: blueprint add-pure-block-storage-driver-doc\n\nChange-Id: I77bef35cc29ef0e8a9bb11d3020d013c104826a0\n'}, {'number': 2, 'created': '2014-10-02 08:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d77b7013f068095f6c27e2e24ac392024dbcc27', 'message': 'Add PureStorage storage volume driver installation guide\n\nThis patch adds PureStorage storage volume driver installation guide.\n\nDocImpact\nImplements: blueprint add-pure-block-storage-driver-doc\n\nChange-Id: I77bef35cc29ef0e8a9bb11d3020d013c104826a0\n'}, {'number': 3, 'created': '2014-10-03 02:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/418f3b28e77efce85cedd3d0b1bfaf361ac03ef2', 'message': 'Add PureStorage storage volume driver installation guide\n\nThis patch adds PureStorage storage volume driver installation guide.\n\nDocImpact\nImplements: blueprint add-pure-block-storage-driver-doc\n\nChange-Id: I77bef35cc29ef0e8a9bb11d3020d013c104826a0\n'}, {'number': 4, 'created': '2014-10-06 23:17:10.000000000', 'files': ['doc/config-reference/block-storage/section_volume-drivers.xml', 'doc/config-reference/block-storage/drivers/pure-storage-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dee462b8bcd85dec73ca1c78e738dfe4fd974f9e', 'message': 'Add PureStorage storage volume driver installation guide\n\nThis patch adds PureStorage storage volume driver installation guide.\n\nDocImpact\nImplements: blueprint add-pure-block-storage-driver-doc\n\nChange-Id: I77bef35cc29ef0e8a9bb11d3020d013c104826a0\n'}]",65,125547,dee462b8bcd85dec73ca1c78e738dfe4fd974f9e,20,7,4,13461,,,0,"Add PureStorage storage volume driver installation guide

This patch adds PureStorage storage volume driver installation guide.

DocImpact
Implements: blueprint add-pure-block-storage-driver-doc

Change-Id: I77bef35cc29ef0e8a9bb11d3020d013c104826a0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/125547/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/section_volume-drivers.xml', 'doc/config-reference/block-storage/drivers/pure-storage-driver.xml']",2,0a8013a25b3ce3b9b6fa7e3a1e68a47bada6cc2e,bp/add-pure-block-storage-driver-doc,"<?xml version=""1.0""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xml:id=""pure-storage-driver"" version=""5.0""> <title>Pure Storage volume driver</title> <?dbhtml stop-chunking?> <section xml:id=""pure-storage-driver-release-notes""> <title>Release Notes</title> <para>Pure Storage volume driver for OpenStack Cinder </para> <para>Version 1.0.0b1</para> <para> This is the Pure Storage FlashArray volume driver for OpenStack Cinder. It allows users to attach and detach volumes from instances, using iSCSI for connectivity between the node hosting the instance and the FlashArray. It allows for user-initiated creation and deletion of volumes and snapshots, creating volumes from images, snapshots, and other volumes, creating images from volumes, and extending volumes to larger sizes. Administrators can migrate volumes between FlashArrays. </para> <para>Thanks to thin provisioning, users can create volumes of practically any size. With Purity's built-in deduplication, cloning volumes from existing volumes and snapshots occurs practically instantly and uses up very little additional space on the array. </para> <para><emphasis role=""bold"">Release compatibility: </emphasis></para> <para>This release is compatible with Purity FlashArrays that support the REST API, (Purity 3.4.0 and newer) and that are capable of iSCSI connectivity. This release supports installation with OpenStack clusters running the Juno version that use the KVM or QEMU hypervisors together with OpenStack Nova's libvirt compute driver. </para> <para><emphasis role=""bold"">Limitations and known issues: </emphasis></para> <para>If you do not set up the nodes hosting instances to use multipathing, all iSCSI connectivity will use a single physical 10-gigabit Ethernet port on the array. In addition to significantly limiting the available bandwidth, this means you do not have the high-availability and non-disruptive upgrade benefits provided by FlashArray. </para> <para>Workaround: You must set up multipathing from your hosts.</para> <para>In the default configuration, Cinder does not provision volumes on a backend whose available raw space is less than the logical size of the new volume. Due to Purity's data reduction technology, such a volume could actually fit in the backend, and thus Cinder's default configuration does not take advantage of all available space. </para> <para>Workaround: Turn off the CapacityFilter.</para> </section> <section xml:id=""pure-storage-driver-supported-operations""> <title>Supported operations</title> <itemizedlist> <listitem> <para>Create, delete, attach, detach, clone and extend volumes.</para> </listitem> <listitem> <para>Create a volume from snapshot.</para> </listitem> <listitem> <para>Create and delete volume snapshots.</para> </listitem> </itemizedlist> </section> <section xml:id=""pure-storage-driver-configure""> <title>Configure OpenStack and Purity</title> <para>Configuration involves steps both to Purity and to your OpenStack cluster. </para> <para><emphasis role=""bold"">Note</emphasis>: These instructions assume that the <systemitem class=""service"" >cinder-api</systemitem> and <systemitem class=""service"" >cinder-scheduler</systemitem> services are installed and configured in your OpenStack cluster.</para> <section xml:id=""pure-storage-driver-configure-cinder""> <title>Configure the Cinder Volume Service</title> <para>In these steps, edit the cinder.conf file to configure Cinder volume service for the following:</para> <itemizedlist> <listitem> <para>Enable multipathing</para> </listitem> <listitem> <para>Register the Pure Storage FlashArray Volume Driver for OpenStack Cinder</para> </listitem> <listitem> <para>Register the Pure Storage FlashArray as a backend</para> </listitem> </itemizedlist> <section xml:id=""pure-storage-driver-configure-cinder-puretoken""> <title>Copy the API Token from Purity</title> <para>The Cinder volume service configuration requires an API token from Purity. Actions performed by the volume driver use this token for authorization. Also, Purity logs the volume driver's actions as being performed by the user who owns this API token. </para> <para>If you created a Purity user account that is dedicated to managing your OpenStack Cinder volumes, copy the API token from that user account. </para> <para>Use the appropriate create or list command below to display and copy the Purity API token. </para> <para><emphasis role=""bold"">To create a new API token: </emphasis></para> <programlisting>pureadmin create --api-token &lt;USER&gt;</programlisting> <para>The following is example output. Copy the API token (902fdca3-7e3f-d2e4-d6a6-24c2285fe1d9 in this example) to use in the next step. </para> <para> <screen>pureadmin create --api-token pureuser Name API Token Created pureuser 902fdca3-7e3f-d2e4-d6a6-24c2285fe1d9 2014-08-04 14:50:30 </screen> </para> <para><emphasis role=""bold"">To list an existing API token: </emphasis></para> <programlisting>pureadmin list --api-token --expose &lt;USER&gt;</programlisting> <para>The output is the same as shown for the example above.</para> </section> <section xml:id=""pure-storage-driver-configure-cinder-conf""> <title>Edit the Cinder Volume Service Configuration File</title> <para>The following sample <filename>/etc/cinder/cinder.conf</filename> configuration lists the relevant settings for a typical Block Storage service using a single Pure Storage array:</para> <example> <title>Default (single-instance) configuration</title> <programlisting language=""ini""> [DEFAULT] .... enabled_backends=puredriver-1 default_volume_type=puredriver-1 .... [puredriver-1] volume_backend_name=puredriver-1 volume_driver=cinder.volume.drivers.pure.PureISCSIDriver san_ip=<replaceable>IP_PURE_MGMT</replaceable> pure_api_token=<replaceable>PURE_API_TOKEN</replaceable> </programlisting> </example> <para>In this example, replace the following variables accordingly:</para> <variablelist> <varlistentry> <term>IP_PURE_MGMT</term> <listitem> <para>The IP address of the Pure Storage array's management interface or a domain name that resolves to that IP address.</para> </listitem> </varlistentry> <varlistentry> <term>PURE_API_TOKEN</term> <listitem> <para>The Purity Authorization token that the volume driver uses to perform volume management on the Pure Storage array.</para> </listitem> </varlistentry> </variablelist> </section> </section> <section xml:id=""pure-storage-driver-configure-purity""> <title>Create Purity Host Objects</title> <para>Before using the volume driver, first create a host in Purity for each OpenStack iSCSI initiator IQN that will connect to the FlashArray. </para> <para><emphasis role=""bold"">Note</emphasis> : Your configuration of Purity hosts controls OpenStack's access to your FlashArray. </para> <para>For every node that the driver runs on and every compute node that will connect to the FlashArray check the file /etc/iscsi/initiatorname.iscsi . For each IQN in that file, copy the IQN string and create a Purity host for that IQN. </para> <para>Run the following command to create a Purity host for an IQN: </para> <programlisting>purehost create --iqnlist &lt;IQN&gt; &lt;HOST&gt;</programlisting> <para><emphasis role=""bold"">Note</emphasis>: Do not specify multiple IQNs with the --iqnlist option. Each FlashArray host must be configured to a single OpenStack IQN. </para> </section> </section> </section> ",,152,0
openstack%2Ftrove~master~I68f6c5f2fdb210afcbad504df4cf0588400fc42a,openstack/trove,master,I68f6c5f2fdb210afcbad504df4cf0588400fc42a,Rename 'slave' to 'replica',ABANDONED,2014-09-03 03:01:25.000000000,2014-10-07 08:22:01.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9746}, {'_account_id': 9749}, {'_account_id': 10215}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-09-03 03:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/08bb3f9cc9218255626be8798842bcf39cc9b8f9', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 2, 'created': '2014-09-04 14:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dfcd711289eba02ecd99b24c9c230bbdcfb234fa', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 3, 'created': '2014-09-04 14:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/241b5a91536a772619b1977a860fc38177d641af', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 4, 'created': '2014-09-04 15:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f795ea7b9349911ab73e1f59d9981b974169f909', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 5, 'created': '2014-09-05 18:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d76d8233d872b1db1ba3e6b6df9a5e372aec85be', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 6, 'created': '2014-09-17 01:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5f59930f356ac8951c644708922941df10000710', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 7, 'created': '2014-09-17 15:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6d5b540414fa6dac168b83aea935d00563d0cdf1', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 8, 'created': '2014-09-23 18:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8156b3fb2575b776b58d45f138d8824b0fbad0ce', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\n\nConflicts:\n\ttrove/taskmanager/manager.py\n\ttrove/taskmanager/models.py\n\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 9, 'created': '2014-09-24 18:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7435182a0ce655182d1d090d95c98d1a5fc98678', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nRelated-Bug: 1360310\n\nConflicts:\n\ttrove/taskmanager/manager.py\n\ttrove/taskmanager/models.py\n\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 10, 'created': '2014-09-24 23:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/abcc1b3c7b83b8e8cdbf395bff15e9bee0caa0d6', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nCloses-Bug: 1373668\n\nConflicts:\n\ttrove/taskmanager/manager.py\n\ttrove/taskmanager/models.py\n\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a""}, {'number': 11, 'created': '2014-09-29 14:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a9fcd5eae95641e9633942f16f3bc5fafabfe8fb', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nCloses-Bug: 1373668\n\nConflicts:\n\ttrove/taskmanager/manager.py\n\ttrove/taskmanager/models.py\n\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}, {'number': 12, 'created': '2014-10-01 17:29:02.000000000', 'files': ['trove/guestagent/datastore/mysql/manager.py', 'trove/guestagent/datastore/mongodb/manager.py', 'trove/tests/fakes/guestagent.py', 'trove/guestagent/datastore/cassandra/manager.py', 'trove/instance/models.py', 'trove/instance/service.py', 'trove/tests/api/replication.py', 'trove/guestagent/strategies/replication/mysql_binlog.py', 'trove/guestagent/datastore/couchbase/manager.py', 'trove/common/exception.py', 'trove/tests/unittests/guestagent/test_mysql_manager.py', 'trove/taskmanager/manager.py', 'trove/tests/unittests/instance/test_instance_views.py', 'trove/common/apischema.py', 'trove/guestagent/strategies/replication/base.py', 'trove/db/sqlalchemy/migrate_repo/versions/034_rename_slave_to_replica.py', 'trove/tests/unittests/cluster/test_cluster_views.py', 'trove/guestagent/datastore/redis/manager.py', 'trove/instance/views.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/taskmanager/api.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/tests/api/instances.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/da0946a29e684223eb3ea62c53224be10d7db4e5', 'message': ""Rename 'slave' to 'replica'\n\nRemove all references to the terms 'slave' and 'master, except in code\nthat is specific to MySQL. Use the terms 'replica' and 'replication\nsource' instead.\n\nAdd a db migration to rename the instances.slave_of_id column to\nreplica_of_id.\n\nUpdate apischema.py to reflect support for replicas.\n\nCo-Authored-By: Doug Shelley <doug@parelastic.com>\nDepends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97\nCloses-Bug: 1373668\n\nChange-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a\n""}]",10,118521,da0946a29e684223eb3ea62c53224be10d7db4e5,92,9,12,9749,,,0,"Rename 'slave' to 'replica'

Remove all references to the terms 'slave' and 'master, except in code
that is specific to MySQL. Use the terms 'replica' and 'replication
source' instead.

Add a db migration to rename the instances.slave_of_id column to
replica_of_id.

Update apischema.py to reflect support for replicas.

Co-Authored-By: Doug Shelley <doug@parelastic.com>
Depends-On: Id22d18a84a4ac104ff8af09959e8eb2ae0102e97
Closes-Bug: 1373668

Change-Id: I68f6c5f2fdb210afcbad504df4cf0588400fc42a
",git fetch https://review.opendev.org/openstack/trove refs/changes/21/118521/7 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/exception.py', 'trove/guestagent/datastore/mysql/manager.py', 'trove/tests/unittests/guestagent/test_mysql_manager.py', 'trove/guestagent/datastore/mongodb/manager.py', 'trove/tests/fakes/guestagent.py', 'trove/guestagent/datastore/cassandra/manager.py', 'trove/instance/models.py', 'trove/taskmanager/manager.py', 'trove/tests/unittests/instance/test_instance_views.py', 'trove/guestagent/strategies/replication/base.py', 'trove/instance/service.py', 'trove/guestagent/datastore/redis/manager.py', 'trove/instance/views.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/db/sqlalchemy/migrate_repo/versions/032_rename_slave_to_replica.py', 'trove/taskmanager/api.py', 'trove/taskmanager/models.py', 'trove/tests/api/replication.py', 'trove/guestagent/api.py', 'trove/guestagent/strategies/replication/mysql_binlog.py', 'trove/tests/api/instances.py', 'trove/guestagent/datastore/couchbase/manager.py']",22,08bb3f9cc9218255626be8798842bcf39cc9b8f9,bug/1373668," def attach_replica(self, context, snapshot, replica_config): operation='attach_replica', datastore=MANAGER) def detach_replica(self, context): operation='detach_replica', datastore=MANAGER)"," def attach_replication_slave(self, context, snapshot, slave_config): LOG.debug(""Attaching replication slave."") operation='attach_replication_slave', datastore=MANAGER) def detach_replication_slave(self, context): LOG.debug(""Detaching replication slave."") operation='detach_replication_slave', datastore=MANAGER) LOG.debug(""Demoting replication slave."")",214,160
openstack%2Fnova~master~I0b8e6319a4cc39876b1e396ef705f0fc5def1e44,openstack/nova,master,I0b8e6319a4cc39876b1e396ef705f0fc5def1e44,Fix unsafe SSL connection on TrustedFilter,MERGED,2014-09-29 11:38:05.000000000,2014-10-07 08:19:36.000000000,2014-10-04 11:27:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6802}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-29 11:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ebea924befd0866bc43ce31d600bb9993ff777f', 'message': ""Fix unsafe SSL connection on TrustedFilter\n\nTrustedFilter was using httplib which doesn't check for CAs.\nHere the change is using Requests and verifies local CAs by default (or another\none if provided)\n\nCloses-Bug: #1373993\n\nChange-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44\n""}, {'number': 2, 'created': '2014-09-29 11:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ae94df588a012db3c49e817ca097e043672471b', 'message': ""Fix unsafe SSL connection on TrustedFilter\n\nTrustedFilter was using httplib which doesn't check for CAs.\nHere the change is using Requests and verifies local CAs by default (or another\none if provided)\n\nCloses-Bug: #1373993\n\nChange-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44\n""}, {'number': 3, 'created': '2014-09-30 14:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/517594e92c35f82576bfc8080ebb9904329216f8', 'message': ""Fix unsafe SSL connection on TrustedFilter\n\nTrustedFilter was using httplib which doesn't check for CAs.\nHere the change is using Requests and verifies local CAs by default (or another\none if provided)\n\nCloses-Bug: #1373993\n\nChange-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44\n""}, {'number': 4, 'created': '2014-09-30 14:43:41.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/30871e8702737edbbfbcbbb5f21858873b37685c', 'message': ""Fix unsafe SSL connection on TrustedFilter\n\nTrustedFilter was using httplib which doesn't check for CAs.\nHere the change is using Requests and verifies local CAs by default (or another\none if provided)\nThis effort is related to CVE 2013-2255.\n\nSecurityImpact\n\nCloses-Bug: #1373993\n\nChange-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44\n""}]",10,124714,30871e8702737edbbfbcbbb5f21858873b37685c,37,15,4,7166,,,0,"Fix unsafe SSL connection on TrustedFilter

TrustedFilter was using httplib which doesn't check for CAs.
Here the change is using Requests and verifies local CAs by default (or another
one if provided)
This effort is related to CVE 2013-2255.

SecurityImpact

Closes-Bug: #1373993

Change-Id: I0b8e6319a4cc39876b1e396ef705f0fc5def1e44
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/124714/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py']",2,5ebea924befd0866bc43ce31d600bb9993ff777f,bug/1373993,"import requests cfg.BoolOpt('attestation_insecure_ssl', default=False, help='Disable SSL cert verification for Attestation service') # If the CA file is not provided, let's check the cert if verification # asked self.verify = CONF.trusted_computing.attestation_insecure_ssl \ and self.ca_file or True self.cert = (self.cert_file, self.key_file) action_url = ""https://%s:%d%s/%s"" % (self.host, self.port, self.api_url, action_url) try: res = requests.request(method, action_url, data=body, headers=headers, cert=self.cert, verify=self.verify) status_code = res.status_code if status_code in (requests.codes.OK, requests.codes.CREATED, requests.codes.ACCEPTED, requests.codes.NO_CONTENT): try: return requests.codes.OK, jsonutils.loads(res.text) except ValueError: return requests.codes.OK, res.text except requests.exceptions.RequestException: return status, res","import httplib import socket import ssl class HTTPSClientAuthConnection(httplib.HTTPSConnection): """"""Class to make a HTTPS connection, with support for full client-based SSL Authentication """""" def __init__(self, host, port, key_file, cert_file, ca_file, timeout=None): httplib.HTTPSConnection.__init__(self, host, key_file=key_file, cert_file=cert_file) self.host = host self.port = port self.key_file = key_file self.cert_file = cert_file self.ca_file = ca_file self.timeout = timeout def connect(self): """"""Connect to a host on a given (SSL) port. If ca_file is pointing somewhere, use it to check Server Certificate. Redefined/copied and extended from httplib.py:1105 (Python 2.6.x). This is needed to pass cert_reqs=ssl.CERT_REQUIRED as parameter to ssl.wrap_socket(), which forces SSL to check server certificate against our client certificate. """""" sock = socket.create_connection((self.host, self.port), self.timeout) self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ca_certs=self.ca_file, cert_reqs=ssl.CERT_REQUIRED) action_url = ""%s/%s"" % (self.api_url, action_url) try: c = HTTPSClientAuthConnection(self.host, self.port, key_file=self.key_file, cert_file=self.cert_file, ca_file=self.ca_file) c.request(method, action_url, body, headers) res = c.getresponse() status_code = res.status if status_code in (httplib.OK, httplib.CREATED, httplib.ACCEPTED, httplib.NO_CONTENT): return httplib.OK, res except (socket.error, IOError): if status == httplib.OK: data = res.read() return status, jsonutils.loads(data) else: return status, None",27,57
openstack%2Fproject-config~master~I5a7982094de6811e51592154cb9f4fe5057764c0,openstack/project-config,master,I5a7982094de6811e51592154cb9f4fe5057764c0,Add validate-json gate,ABANDONED,2014-10-03 18:52:05.000000000,2014-10-07 08:04:40.000000000,,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-03 18:52:05.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b6b6ad335e790787238b41bf71ce0ca8d9f204f5', 'message': 'Add validate-json gate\n\nWe just add a tox to validate json for kolla, adding this instead of the\nnoop.\n\nChange-Id: I5a7982094de6811e51592154cb9f4fe5057764c0\n'}]",1,126038,b6b6ad335e790787238b41bf71ce0ca8d9f204f5,6,3,1,866,,,0,"Add validate-json gate

We just add a tox to validate json for kolla, adding this instead of the
noop.

Change-Id: I5a7982094de6811e51592154cb9f4fe5057764c0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/38/126038/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b6b6ad335e790787238b41bf71ce0ca8d9f204f5,, - name: gate-kolla-validate-json-python27, - name: noop-jobs,1,1
openstack%2Fsahara~proposed%2Fjuno~Ib37e4476258cc4547d4a27847c89a9611bff05bc,openstack/sahara,proposed/juno,Ib37e4476258cc4547d4a27847c89a9611bff05bc,Removing extraneous Swift information from Features,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:01:13.000000000,2014-10-07 08:01:13.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/userdoc/features.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0d94b67fca6b0c5776ddcfe0f3e5b489afe376ea', 'message': 'Removing extraneous Swift information from Features\n\nChanges\n* removing repeated information from Features page for Swift integration\n* refactoring features.rst to 80 columns\n\nChange-Id: Ib37e4476258cc4547d4a27847c89a9611bff05bc\nCloses-Bug: #1376309\n(cherry picked from commit eb529ca4f2dd153d494c4e02dd302998b3d6f43b)\n'}]",0,126391,0d94b67fca6b0c5776ddcfe0f3e5b489afe376ea,11,6,1,8411,,,0,"Removing extraneous Swift information from Features

Changes
* removing repeated information from Features page for Swift integration
* refactoring features.rst to 80 columns

Change-Id: Ib37e4476258cc4547d4a27847c89a9611bff05bc
Closes-Bug: #1376309
(cherry picked from commit eb529ca4f2dd153d494c4e02dd302998b3d6f43b)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/91/126391/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userdoc/features.rst'],1,0d94b67fca6b0c5776ddcfe0f3e5b489afe376ea,bug/1376457,"The mechanism of cluster scaling is designed to enable user to change the number of running instances without creating a new cluster. User may change number of instances in existing Node Groups or add new Node Groups.In order to leverage Swift within Hadoop, including using Swift data sources from within EDP, Hadoop requires the application of a patch. For additional information about using Swift with Sahara, including patching Hadoop and configuring Sahara, please refer to the :doc:`hadoop-swift` documentation.Cinder is a block storage service that can be used as an alternative for an ephemeral drive. Using Cinder volumes increases reliability of data which is important for HDFS service. User can set how many volumes will be attached to each node in a Node Group and the size of each volume.OpenStack Cluster may use Nova Network or Neutron as a networking service. Sahara supports both, but when deployed, a special configuration for networking should be set explicitly. By default Sahara will behave as if Nova Network is used. If OpenStack Cluster uses Neutron, then ``use_neutron`` option should be set to ``True`` in Sahara configuration file. In addition, if the OpenStack Cluster supports network namespaces, set the ``use_namespaces`` option to ``True``Sahara needs to access instances through ssh during a Cluster setup. To establish a connection Sahara may use both: fixed and floating IP of an Instance. By default ``use_floating_ips`` parameter is set to ``True``, so Sahara will use Floating IP of an Instance to connect. In this case, user has two options for how to make all instances* Nova Network may be configured to assign floating IPs automatically by setting ``auto_assign_floating_ip`` to ``True`` in ``nova.conf``Note: When using floating IPs for management (``use_floating_ip=True``) **every** instance in the Cluster should have a floating IP,If ``use_floating_ips`` parameter is set to ``False`` Sahara will use Instances' fixed IPs for management. In this case the node where Sahara is running should have access to Instances' fixed IP network. When OpenStack uses Neutron for networking, user will be able to choose fixed IP network for all instances in a Cluster.One of the problems in Hadoop running on OpenStack is that there is no ability to control where machine is actually running. We cannot be sure that two new virtual machines are started on different physical machines. As a result, any replication with clusterAnti-affinity feature provides an ability to explicitly tell Sahara to run specified processes on different compute nodes. This is especially useful for Hadoop datanode process to make HDFS replicas reliable.Sahara may use `OpenStack Orchestration engine <https://wiki.openstack.org/wiki/Heat>`_ (aka Heat) to provision nodes for Hadoop cluster.","The mechanism of cluster scaling is designed to enable user to change the number of running instances without creating a new cluster. User may change number of instances in existing Node Groups or add new Node Groups.In order to leverage Swift within Hadoop, including using Swift data sources from within EDP, Hadoop requires the application of a patch. For additional information about this patch and configuration, please refer to :doc:`hadoop-swift`. Sahara automatically sets information about the Swift filesystem implementation, location awareness, URL and tenant name for authorization. The only required information that is still needed to be set is username and password to access Swift. These parameters need to be explicitly set prior to launching the job. E.g. : .. sourcecode:: console $ hadoop distcp -D fs.swift.service.sahara.username=admin \ -D fs.swift.service.sahara.password=swordfish \ swift://integration.sahara/temp swift://integration.sahara/temp1 How to compose a swift URL? The template is: ``swift://${container}.${provider}/${object}``. We don't need to point out the account because it will be automatically determined from tenant name from configs. Actually, account=tenant. ${provider} was designed to provide an opportunity to work with several Swift installations. E.g. it is possible to read data from one Swift installation and write it to another one. But as for now, Sahara automatically generates configs only for one Swift installation with name ""sahara"". Currently user can only enable/disable Swift for a Hadoop cluster. But there is a blueprint about making Swift access more configurable: https://blueprints.launchpad.net/sahara/+spec/swift-configuration-through-rest-and-uiCinder is a block storage service that can be used as an alternative for an ephemeral drive. Using Cinder volumes increases reliability of data which is important for HDFS service. User can set how many volumes will be attached to each node in a Node Group and the size of each volume.OpenStack Cluster may use Nova Network or Neutron as a networking service. Sahara supports both, but when deployed, a special configuration for networking should be set explicitly. By default Sahara will behave as if Nova Network is used. If OpenStack Cluster uses Neutron, then ``use_neutron`` option should be set to ``True`` in Sahara configuration file. In addition, if the OpenStack Cluster supports network namespaces, set the ``use_namespaces`` option to ``True``Sahara needs to access instances through ssh during a Cluster setup. To establish a connection Sahara may use both: fixed and floating IP of an Instance. By default ``use_floating_ips`` parameter is set to ``True``, so Sahara will use Floating IP of an Instance to connect. In this case, user has two options for how to make all instances* Nova Network may be configured to assign floating IPs automatically by setting ``auto_assign_floating_ip`` to ``True`` in ``nova.conf``Note: When using floating IPs for management (``use_floating_ip=True``) **every** instance in the Cluster should have a floating IP,If ``use_floating_ips`` parameter is set to ``False`` Sahara will use Instances' fixed IPs for management. In this case the node where Sahara is running should have access to Instances' fixed IP network. When OpenStack uses Neutron for networking, user will be able to choose fixed IP network for all instances in a Cluster.One of the problems in Hadoop running on OpenStack is that there is no ability to control where machine is actually running. We cannot be sure that two new virtual machines are started on different physical machines. As a result, any replication with clusterAnti-affinity feature provides an ability to explicitly tell Sahara to run specified processes on different compute nodes. This is especially useful for Hadoop datanode process to make HDFS replicas reliable.Sahara may use `OpenStack Orchestration engine <https://wiki.openstack.org/wiki/Heat>`_ (aka Heat) to provision nodes for Hadoop cluster.",49,47
openstack%2Fsahara~proposed%2Fjuno~Ie53888975ce436439cc808b2fdc45dff66bae1a9,openstack/sahara,proposed/juno,Ie53888975ce436439cc808b2fdc45dff66bae1a9,Update the Elastic Data Processing (EDP) documentation page,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:01:07.000000000,2014-10-07 08:01:06.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/userdoc/edp.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9e3fbb654d3530b11d3e6c1fb652028e631e5859', 'message': 'Update the Elastic Data Processing (EDP) documentation page\n\n* Add description of MapReduce.Streaming job type\n* Add description of Spark job type\n* Add reference to advanced configuration for Swfit proxy\n* Note that .sahara suffix is added to Swift URLs automatically\n* A few minor changes\n\nCloses-Bug: 1374574\nCloses-Bug: 1374606\nChange-Id: Ie53888975ce436439cc808b2fdc45dff66bae1a9\n(cherry picked from commit 7973db35e61b0c2d686798cb2de50d281713b03b)\n'}]",0,126390,9e3fbb654d3530b11d3e6c1fb652028e631e5859,18,9,1,8411,,,0,"Update the Elastic Data Processing (EDP) documentation page

* Add description of MapReduce.Streaming job type
* Add description of Spark job type
* Add reference to advanced configuration for Swfit proxy
* Note that .sahara suffix is added to Swift URLs automatically
* A few minor changes

Closes-Bug: 1374574
Closes-Bug: 1374606
Change-Id: Ie53888975ce436439cc808b2fdc45dff66bae1a9
(cherry picked from commit 7973db35e61b0c2d686798cb2de50d281713b03b)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/90/126390/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userdoc/edp.rst'],1,9e3fbb654d3530b11d3e6c1fb652028e631e5859,bug/1376457,"Sahara's Elastic Data Processing facility or :dfn:`EDP` allows the execution of jobs on clusters created from Sahara. EDP supports: * Hive, Pig, MapReduce, MapReduce.Streaming and Java job types on Hadoop clusters * Spark jobs on Spark standalone clusters* access to input and output data sources in + HDFS for all job types + Swift for all types excluding Spark and Hive Sahara EDP uses a collection of simple objects to define and execute jobs. These objects are stored in the Sahara database when theyA :dfn:`Job Binary` object stores a URL to a single script or Jar file and any credentials needed to retrieve the file. The file itself may be stored in the Sahara internal database or in Swift.Sahara requires credentials (username and password) to access files stored in Swift unless Swift proxy users are configured as described in :doc:`../userdoc/advanced.configuration.guide`. The Swift service must be running in the same OpenStack installation referenced by Sahara.A :dfn:`Job` object specifies the type of the job and lists all of the individual Job Binary objects that are required for execution. An individual Job Binary may be referenced by multiple Jobs. A Job object specifies a main binary and/or supporting libraries depending on its type: +-------------------------+-------------+-----------+ | Job type | Main binary | Libraries | +=========================+=============+===========+ | ``Hive`` | required | optional | +-------------------------+-------------+-----------+ | ``Pig`` | required | optional | +-------------------------+-------------+-----------+ | ``MapReduce`` | not used | required | +-------------------------+-------------+-----------+ | ``MapReduce.Streaming`` | not used | optional | +-------------------------+-------------+-----------+ | ``Java`` | not used | required | +-------------------------+-------------+-----------+ | ``Spark`` | required | optional | +-------------------------+-------------+-----------+To execute Hadoop jobs, Sahara generates an Oozie workflow and submits it to the Oozie server running on the cluster. Familiarity with Oozie is not necessary for using Sahara but it may be beneficial to the user. A link to the Oozie web console can be found in the Sahara web UI in the cluster details. For Spark jobs, Sahara uses the *spark-submit* shell script and executes the Spark job from the master node. Logs of spark jobs run by Sahara can be found on the master node under the */tmp/spark-edp* directory.(Steps 4 and 5 do not apply to Java or Spark job types. See `Additional Details for Java jobs`_ and `Additional Details for Spark jobs`_) +--------------------------+--------------+------------+-----------+ | Job type | Configration | Parameters | Arguments | | | Values | | | +==========================+==============+============+===========+ | ``Hive`` | Yes | Yes | No | +--------------------------+--------------+------------+-----------+ | ``Pig`` | Yes | Yes | Yes | +--------------------------+--------------+------------+-----------+ | ``MapReduce`` | Yes | No | No | +--------------------------+--------------+------------+-----------+ | ``MapReduce.Streaming`` | Yes | No | No | +--------------------------+--------------+------------+-----------+ | ``Java`` | Yes | No | Yes | +--------------------------+--------------+------------+-----------+ | ``Spark`` | Yes | No | Yes | +--------------------------+--------------+------------+-----------+ * :dfn:`Configuration values` are key/value pairs. + Other configuration values may be read at runtime by Hadoop jobs + Currently additional configuration values are not available to Spark jobs at runtime* :dfn:`Arguments` are strings passed as command line arguments to a shell or main programIf Swift proxy users are not configured (see :doc:`../userdoc/advanced.configuration.guide`) and a job is run with data sources in Swift, Sahara will automatically generate Swift username and password configuration values based on the credentials in the data sources. If the input and output data sources are both in Swift, it is expected that they specify the same credentials.If the job type is MapReduce, the mapper and reducer classes *must* be specified as configuration values. Note, the UI will not prompt the user for these required values, they must be added manually with the ``Configure`` tab. Make sure to add these values with the correct names:Additional Details for MapReduce.Streaming jobs +++++++++++++++++++++++++++++++++++++++++++++++ **Important!** If the job type is MapReduce.Streaming, the streaming mapper and reducer classes *must* be specified. In this case, the UI *will* prompt the user to enter mapper and reducer values on the form and will take care of adding them to the job configuration with the appropriate names. If using the python client, however, be certain to add these values to the job configuration manually with the correct names: +-------------------------+---------------+ | Name | Example Value | +=========================+===============+ | edp.streaming.mapper | /bin/cat | +-------------------------+---------------+ | edp.streaming.reducer | /usr/bin/wc | +-------------------------+---------------+Java jobs use two special configuration values:Additional Details for Spark jobs +++++++++++++++++++++++++++++++++ Spark jobs use a special configuration value: * ``edp.java.main_class`` (required) Specifies the class containing the Java or Scala main method: + ``main(String[] args)`` for Java + ``main(args: Array[String]`` for Scala A Spark job will execute the ``main`` method of the specified main class. Values may be passed to the main method through the ``args`` array. Any arguments set during job launch will be passed to the program as commandline arguments by *spark-submit*. Data Source objects are not used with Spark job types. Instead, any input or output paths must be passed to the ``main`` method as arguments. Remember that Swift paths are not supported for Spark jobs currently. The ``edp-spark`` example bundled with Sahara contains a Spark program for estimating Pi. Sahara Swift URLs passed to running jobs as input or output sources include a "".sahara"" suffix on the container, for example:You may notice these Swift URLs in job logs, however, you do not need to add the suffix to the containers yourself. Sahara will add the suffix if necessary, so when using the UI or the python client you may write the above URL simply as: ``swift://container/object`` This indicates a file object in the Sahara database which has the given uuid as a key When a Hadoop job is executed, binaries are first uploaded to a cluster node and then moved from the node local filesystem to HDFS. Therefore, there must be an instance of HDFS available to the nodes in the Sahara cluster.Requirements for EDP support depend on the EDP job type and plugin used for the cluster. For example a Vanilla Sahara cluster must run at least one instance of these processes","Sahara's Elastic Data Processing facility or :dfn:`EDP` allows the execution of Hadoop jobs on clusters created from Sahara. EDP supports: * Hive, Pig, MapReduce, and Java job types* access to input and output data sources in Swift or HDFSSahara EDP uses a collection of simple objects to define and execute Hadoop jobs. These objects are stored in the Sahara database when theyA :dfn:`Job Binary` object stores a URL to a single Pig script, Hive script, or Jar file and any credentials needed to retrieve the file. The file itself may be stored in the Sahara internal database or in Swift.Sahara requires credentials (username and password) to access files stored in Swift. The Swift service must be running in the same OpenStack installation referenced by Sahara.A :dfn:`Job` object specifies the type of the job and lists all of the individual Job Binary objects that are required for execution. An individual Job Binary may be referenced by multiple Jobs. A Job object specifies a main binary and/or supporting libraries depending on its type. +----------------+-------------+-----------+ | Job type | Main binary | Libraries | +================+=============+===========+ | ``Hive`` | required | optional | +----------------+-------------+-----------+ | ``Pig`` | required | optional | +----------------+-------------+-----------+ | ``MapReduce`` | not used | required | +----------------+-------------+-----------+ | ``Java`` | not used | required | +----------------+-------------+-----------+To execute the job, Sahara generates a workflow and submits it to the Oozie server running on the cluster. Familiarity with Oozie is not necessary for using Sahara but it may be beneficial to the user. A link to the Oozie web console can be found in the Sahara web UI in the cluster details.(Steps 4 and 5 do not apply to Java job types. See `Additional Details for Java jobs`_) +----------------+--------------+------------+-----------+ | Job type | Configration | Parameters | Arguments | | | Values | | | +================+==============+============+===========+ | ``Hive`` | Yes | Yes | No | +----------------+--------------+------------+-----------+ | ``Pig`` | Yes | Yes | Yes | +----------------+--------------+------------+-----------+ | ``MapReduce`` | Yes | No | No | +----------------+--------------+------------+-----------+ | ``Java`` | Yes | No | Yes | +----------------+--------------+------------+-----------+ * :dfn:`Configuration values` are key/value pairs. They set options for EDP, Oozie or Hadoop. + The Oozie and Hadoop configuration values may be read by running jobs* :dfn:`Arguments` are strings passed to the pig shell or to a Java ``main()`` method.If a job is run with data sources in Swift, Sahara will automatically generate Swift username and password configuration values based on the credentials in the data sources. If the input and output data sources are both in Swift, it is expected that they specify the same credentials.If the job type is MapReduce, the mapper and reducer classes *must* be specified as configuration values:Java jobs use two configuration values that do not apply to other job types:Sahara Swift URLs have the form:When a job is executed, binaries are first uploaded to a job tracker and then moved from the job tracker's local filesystem to HDFS. Therefore, there must be an instance of HDFS available to the nodes in the Sahara cluster.Requirements for EDP support depend on EDP job type and plugin used for the cluster. For example Vanilla Sahara cluster must run at least one instance of these processes",105,42
openstack%2Fsahara~proposed%2Fjuno~I57dae10da9460deb2a332025cc3a0ea37ae233ee,openstack/sahara,proposed/juno,I57dae10da9460deb2a332025cc3a0ea37ae233ee,Add documentation on the EDP job engine SPI,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:01:00.000000000,2014-10-07 08:01:00.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['doc/source/devref/edp.spi.rst', 'doc/source/devref/plugin.spi.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/360aedfb323fb888acc4745b262eb7746d14ef27', 'message': 'Add documentation on the EDP job engine SPI\n\nCloses-Bug: 1357615\nChange-Id: I57dae10da9460deb2a332025cc3a0ea37ae233ee\n(cherry picked from commit 62ba37a8c415f1c422f010c96c0d553ff788d343)\n'}]",0,126389,360aedfb323fb888acc4745b262eb7746d14ef27,11,7,1,8411,,,0,"Add documentation on the EDP job engine SPI

Closes-Bug: 1357615
Change-Id: I57dae10da9460deb2a332025cc3a0ea37ae233ee
(cherry picked from commit 62ba37a8c415f1c422f010c96c0d553ff788d343)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/89/126389/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/edp.spi.rst', 'doc/source/devref/plugin.spi.rst']",2,360aedfb323fb888acc4745b262eb7746d14ef27,bug/1376457,".. _get_edp_engine: get_edp_engine(cluster, job_type) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Returns an EDP job engine object that supports the specified job_type on the given cluster, or None if there is no support. The EDP job engine object returned must implement the interface described in :doc:`edp.spi`. The job_type is a String matching one of the job types listed in :ref:`edp_spi_job_types`. *Returns*: an EDP job engine object or None ",,215,2
openstack%2Fsahara~proposed%2Fjuno~I16c57dc0ab4d169245bac42e72657880137a287e,openstack/sahara,proposed/juno,I16c57dc0ab4d169245bac42e72657880137a287e,Imported Translations from Transifex,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:00:46.000000000,2014-10-07 08:00:46.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 10670}, {'_account_id': 11131}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9fa0c5473d29c5eeeef3a23e7c9bbf651b0fb788', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16c57dc0ab4d169245bac42e72657880137a287e\n(cherry picked from commit 2637625a1e4fdb7f1391022b7ec43524301adfee)\n'}]",0,126388,9fa0c5473d29c5eeeef3a23e7c9bbf651b0fb788,11,7,1,8411,,,0,"Imported Translations from Transifex

Change-Id: I16c57dc0ab4d169245bac42e72657880137a287e
(cherry picked from commit 2637625a1e4fdb7f1391022b7ec43524301adfee)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/88/126388/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po']",29,9fa0c5473d29c5eeeef3a23e7c9bbf651b0fb788,bug/1376457,,"# Translations template for sahara. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the sahara project. # # Translators: # Carsten Duch <cad@teuto.net>, 2014 msgid """" msgstr """" ""Project-Id-Version: Sahara\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-09-05 06:08+0000\n"" ""PO-Revision-Date: 2014-07-16 14:42+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: German (http://www.transifex.com/projects/p/sahara/language/"" ""de/)\n"" ""Language: de\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" #: sahara/main.py:76 #, python-format msgid ""Starting Sahara %s"" msgstr """" #: sahara/main.py:169 #, python-format msgid ""Loading '%s' infrastructure engine"" msgstr """" #: sahara/main.py:177 #, python-format msgid ""Loading '%s' remote"" msgstr """" #: sahara/main.py:183 #, python-format msgid ""Loading '%s' ops"" msgstr """" #: sahara/api/middleware/auth_valid.py:54 #, python-format msgid ""Incorrect path: %s"" msgstr """" #: sahara/openstack/common/lockutils.py:82 #, python-format msgid ""Created lock path: %s"" msgstr ""Sperrpfad erzeugt: %s"" #: sahara/openstack/common/lockutils.py:251 #, python-format msgid ""Failed to remove file %(file)s"" msgstr ""Lschen der Datei %(file)s fehlgeschlagen"" #: sahara/openstack/common/periodic_task.py:126 #, python-format msgid ""Skipping periodic task %(task)s because its interval is negative"" msgstr """" ""berspringe periodische Aufgabe %(task)s weil der Intervall negativ ist"" #: sahara/openstack/common/periodic_task.py:131 #, python-format msgid ""Skipping periodic task %(task)s because it is disabled"" msgstr ""berspringe periodische Aufgabe %(task)s weil sie deaktiviert ist"" #: sahara/plugins/base.py:106 #, python-format msgid ""Plugin '%(plugin_name)s' loaded %(entry_point)s"" msgstr """" #: sahara/plugins/cdh/deploy.py:292 msgid ""Cloudera Manager has been started"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:69 #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:330 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:309 msgid ""Install of Hadoop stack successful."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:178 msgid ""Provisioning Cluster via Ambari Server: {0} ..."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:247 msgid ""Using \""{0}\"" as admin user for scaling of cluster"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:330 #, python-format msgid ""AmbariPlugin: decommission_nodes called for HDP version = %s"" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:69 msgid ""{0}: Installing rpm's ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:81 msgid ""{0}: Unable to install rpm's from repo, checking for local install."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:91 msgid ""{0}: Installing swift integration ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:99 msgid """" ""{0}: Unable to install swift integration from source, checking for local rpm."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:126 msgid ""{0}: Installing ambari-server ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:130 msgid ""Running Ambari Server setup ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:156 msgid ""Starting Ambari ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:180 msgid ""{0}: Installing Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:192 msgid ""{0}: Starting Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:312 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:291 msgid ""Installing required Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:368 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:352 msgid ""Finalizing Ambari cluster state."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:385 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:369 msgid ""Starting Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:386 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:370 #, python-format msgid """" ""Cluster name: %(cluster_name)s, Ambari server address: %(server_address)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:407 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:391 msgid ""Successfully started Hadoop cluster '{0}'."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:434 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:418 msgid ""Successfully changed state of Hadoop components "" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:462 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:446 msgid ""Starting Hadoop components while scaling up"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:463 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:447 #, python-format msgid ""Cluster name %(cluster_name)s, Ambari server ip %(ip)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:519 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:503 msgid ""Waiting for all Ambari agents to register with server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:532 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:516 #, python-format msgid ""Registered Hosts: %(current_number)s of %(final_number)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:541 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:525 msgid ""Waiting to connect to ambari server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:623 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:713 msgid ""HTTP session is not cached"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:917 msgid ""Creating Hue ini property tree from configuration named {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1017 #, python-format msgid ""Merging configuration properties: %(source)s -> %(destination)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1061 msgid ""Installing Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1066 msgid ""Setting Hue configuration on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1072 msgid ""Uninstalling Shell, if it is installed on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1081 msgid ""Creating initial Hue user on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1086 msgid ""(Re)starting Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1177 msgid """" ""Missing HDFS client from Hue node... adding it since it is required for Hue"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1183 msgid """" ""Missing HIVE client from Hue node... adding it since it is required for "" ""Beeswax and HCatalog"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:642 msgid ""AmbariClient: decommission post request succeeded!"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:660 #, python-format msgid """" ""AmbariClient: number of hosts waiting for decommissioning to complete = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:669 #, python-format msgid ""AmbariClient: decommission status request ok, result = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:679 #, python-format msgid ""AmbariClient: node = %(node)s is now in adminState = %(admin_state)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:687 msgid ""AmbariClient: sleeping for 5 seconds"" msgstr """" #: sahara/plugins/spark/config_helper.py:221 #: sahara/plugins/vanilla/v1_2_1/config_helper.py:227 #, python-format msgid ""Applying config: %s"" msgstr """" #: sahara/plugins/spark/plugin.py:112 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:128 #, python-format msgid ""Hadoop services in cluster %s have been started"" msgstr """" #: sahara/plugins/spark/plugin.py:124 #, python-format msgid ""Spark service at '%s' has been started"" msgstr """" #: sahara/plugins/spark/plugin.py:127 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:158 #, python-format msgid ""Cluster %s has been started successfully"" msgstr """" #: sahara/plugins/spark/plugin.py:380 #, python-format msgid ""Spark master service at '%s' has been restarted"" msgstr """" #: sahara/plugins/vanilla/hadoop2/config.py:300 msgid """" ""Node group awareness is not implemented in YARN yet so "" ""enable_hypervisor_awareness set to False explicitly"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:147 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:166 #, python-format msgid ""Waiting %s datanodes to start up"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:152 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:171 #, python-format msgid ""Datanodes on cluster %s has been started"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:160 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:179 #, python-format msgid ""Stop waiting datanodes on cluster %s since it has been deleted"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:139 #, python-format msgid ""Oozie service at '%s' has been started"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:154 #, python-format msgid ""Hive Metastore server at %s has been started"" msgstr """" #: sahara/service/direct_engine.py:314 #, python-format msgid ""Cluster '%s': all instances are active"" msgstr """" #: sahara/service/direct_engine.py:351 sahara/service/heat_engine.py:146 #, python-format msgid ""Cluster '%(name)s' creation rollback (reason: %(reason)s)"" msgstr """" #: sahara/service/direct_engine.py:359 sahara/service/heat_engine.py:163 #, python-format msgid ""Cluster '%(name)s' scaling rollback (reason: %(reason)s)"" msgstr """" #: sahara/service/engine.py:77 #, python-format msgid ""Cluster '%s': all instances have IPs assigned"" msgstr """" #: sahara/service/engine.py:87 #, python-format msgid ""Cluster '%s': all instances are accessible"" msgstr """" #: sahara/service/ops.py:115 sahara/service/ops.py:134 #, python-format msgid ""Cluster with %s was deleted. Canceling current operation."" msgstr """" #: sahara/service/periodic.py:96 #, python-format msgid ""Terminating transient cluster %(cluster)s with id %(id)s"" msgstr """" #: sahara/service/periodic.py:103 #, python-format msgid """" ""Failed to terminate transient cluster %(cluster)s with id %(id)s: %(error)s."" msgstr """" #: sahara/swift/swift_helper.py:50 #, python-format msgid ""Swift would be integrated with the following params: %s"" msgstr """" #: sahara/topology/topology_helper.py:154 #, python-format msgid ""Vm awareness will add following configs in core-site params: %s"" msgstr """" #: sahara/topology/topology_helper.py:162 #, python-format msgid ""Vm awareness will add following configs in map-red params: %s"" msgstr """" #: sahara/utils/general.py:74 #, python-format msgid ""Cluster status has been changed: id=%(id)s, New status=%(status)s"" msgstr """" #: sahara/utils/rpc.py:121 msgid ""Notifications disabled"" msgstr """" #: sahara/utils/rpc.py:123 msgid ""Notifications enabled"" msgstr """" #: sahara/utils/timing.py:56 #, python-format msgid ""Exception raised by invocation of %(name)s: %(info)s"" msgstr """" ",36,12742
openstack%2Fsahara~proposed%2Fjuno~I4eb0d00766066f0d387e632b0217e11cfed552c5,openstack/sahara,proposed/juno,I4eb0d00766066f0d387e632b0217e11cfed552c5,Fix working Spark with cinder volumes,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:00:40.000000000,2014-10-07 08:00:40.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/plugin.py', 'sahara/tests/unit/plugins/spark/test_config_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ef312384f1a9fb202d2e2a784c9d9ece0cdcd93f', 'message': 'Fix working Spark with cinder volumes\n\nChange-Id: I4eb0d00766066f0d387e632b0217e11cfed552c5\nCloses-bug: #1376790\n(cherry picked from commit 5aca5fe75aa94fe548fc0d481ad0a8edf7375d4f)\n'}]",0,126387,ef312384f1a9fb202d2e2a784c9d9ece0cdcd93f,15,7,1,8411,,,0,"Fix working Spark with cinder volumes

Change-Id: I4eb0d00766066f0d387e632b0217e11cfed552c5
Closes-bug: #1376790
(cherry picked from commit 5aca5fe75aa94fe548fc0d481ad0a8edf7375d4f)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/87/126387/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/plugin.py', 'sahara/tests/unit/plugins/spark/test_config_helper.py']",3,ef312384f1a9fb202d2e2a784c9d9ece0cdcd93f,bug/1376457,"# Copyright (c) 2014 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from sahara.plugins.spark import config_helper as c_helper from sahara.tests.unit import base as test_base class ConfigHelperUtilsTest(test_base.SaharaTestCase): def test_make_hadoop_path(self): storage_paths = ['/mnt/one', '/mnt/two'] paths = c_helper.make_hadoop_path(storage_paths, '/spam') expected = ['/mnt/one/spam', '/mnt/two/spam'] self.assertEqual(expected, paths) ",,34,3
openstack%2Fsahara~proposed%2Fjuno~Icbc950cc9e5f31871ea96dd1c7846fafdad444f4,openstack/sahara,proposed/juno,Icbc950cc9e5f31871ea96dd1c7846fafdad444f4,Fix scaling with Heat and Neutron,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:00:34.000000000,2014-10-07 08:00:34.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['sahara/resources/neutron-port.heat', 'sahara/tests/unit/resources/test_serialize_resources_aa.heat', 'sahara/tests/unit/resources/test_serialize_resources_use_neutron.heat'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e092be6b135f79bf35f0835681c3764db056095f', 'message': 'Fix scaling with Heat and Neutron\n\nCloses-bug: #1376829\n\nChange-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4\n(cherry picked from commit 4e9c29facbf6898047539a5a9405fd0a775ccfd7)\n'}]",0,126386,e092be6b135f79bf35f0835681c3764db056095f,15,7,1,8411,,,0,"Fix scaling with Heat and Neutron

Closes-bug: #1376829

Change-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4
(cherry picked from commit 4e9c29facbf6898047539a5a9405fd0a775ccfd7)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/86/126386/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/resources/neutron-port.heat', 'sahara/tests/unit/resources/test_serialize_resources_aa.heat', 'sahara/tests/unit/resources/test_serialize_resources_use_neutron.heat']",3,e092be6b135f79bf35f0835681c3764db056095f,bug/1376457," ""network_id"" : ""private_net"", ""replacement_policy"": ""AUTO"" ""network_id"" : ""private_net"", ""replacement_policy"": ""AUTO""} "," ""network_id"" : ""private_net"" ""network_id"" : ""private_net""}",14,8
openstack%2Fsahara~proposed%2Fjuno~Id1d6f7bf29fd5b8d7734d3358b6e34f06bf084da,openstack/sahara,proposed/juno,Id1d6f7bf29fd5b8d7734d3358b6e34f06bf084da,Fixed volumes configuration in spark plugin,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:00:28.000000000,2014-10-07 08:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['sahara/plugins/spark/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a0ba4d5c373cdbf859ffe0c3faba2ef132077d84', 'message': 'Fixed volumes configuration in spark plugin\n\nOnly current node group config should influence on data location.\n\nChange-Id: Id1d6f7bf29fd5b8d7734d3358b6e34f06bf084da\nCloses-Bug: #1375920\n(cherry picked from commit b3223ad8928fca39488e4b249146d108c1e15b8f)\n'}]",0,126385,a0ba4d5c373cdbf859ffe0c3faba2ef132077d84,15,6,1,8411,,,0,"Fixed volumes configuration in spark plugin

Only current node group config should influence on data location.

Change-Id: Id1d6f7bf29fd5b8d7734d3358b6e34f06bf084da
Closes-Bug: #1375920
(cherry picked from commit b3223ad8928fca39488e4b249146d108c1e15b8f)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/85/126385/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/spark/plugin.py'],1,a0ba4d5c373cdbf859ffe0c3faba2ef132077d84,bug/1376457," storage_paths = instance.node_group.storage_paths() dn_path = c_helper.extract_hadoop_path(storage_paths, '/dfs/dn') nn_path = c_helper.extract_hadoop_path(storage_paths, '/dfs/nn') hdfs_dir_cmd = ('sudo mkdir -p %(nn_path)s %(dn_path)s &&' 'sudo chown -R hdfs:hadoop %(nn_path)s %(dn_path)s &&' 'sudo chmod 755 %(nn_path)s %(dn_path)s' % {""nn_path"": nn_path, ""dn_path"": dn_path})"," for ng in cluster.node_groups: dn_path = c_helper.extract_hadoop_path(ng.storage_paths(), '/dfs/dn') nn_path = c_helper.extract_hadoop_path(ng.storage_paths(), '/dfs/nn') hdfs_dir_cmd = (('sudo mkdir -p %s %s;' 'sudo chown -R hdfs:hadoop %s %s;' 'sudo chmod 755 %s %s;') % (nn_path, dn_path, nn_path, dn_path, nn_path, dn_path))",8,11
openstack%2Fsahara~proposed%2Fjuno~I275fa07a02f4729f2fc20fcd1f0ea65f3c4d50b2,openstack/sahara,proposed/juno,I275fa07a02f4729f2fc20fcd1f0ea65f3c4d50b2,Fixed cinder check for non-admin user,MERGED,2014-10-06 18:45:49.000000000,2014-10-07 08:00:22.000000000,2014-10-07 08:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 18:45:49.000000000', 'files': ['sahara/service/validations/base.py', 'sahara/utils/openstack/keystone.py', 'sahara/tests/unit/service/validation/utils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3ec1f6fc2261cf2591901ebc8a77d43135148a38', 'message': ""Fixed cinder check for non-admin user\n\nIt could happen that user doesn't have privileges to perform\nlist_services. Sahara should use admin user for that.\n\nRefactored keystone client creation to give admin user\naccess to keystone via API v2.\n\nChange-Id: I275fa07a02f4729f2fc20fcd1f0ea65f3c4d50b2\nCloses-Bug: #1375806\nCloses-Bug: #1376336\n(cherry picked from commit 46ab3f5bfe4c19c3fc028158af705ebde595f355)\n""}]",0,126384,3ec1f6fc2261cf2591901ebc8a77d43135148a38,15,6,1,8411,,,0,"Fixed cinder check for non-admin user

It could happen that user doesn't have privileges to perform
list_services. Sahara should use admin user for that.

Refactored keystone client creation to give admin user
access to keystone via API v2.

Change-Id: I275fa07a02f4729f2fc20fcd1f0ea65f3c4d50b2
Closes-Bug: #1375806
Closes-Bug: #1376336
(cherry picked from commit 46ab3f5bfe4c19c3fc028158af705ebde595f355)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/84/126384/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/validations/base.py', 'sahara/utils/openstack/keystone.py', 'sahara/tests/unit/service/validation/utils.py']",3,3ec1f6fc2261cf2591901ebc8a77d43135148a38,bug/1376457," keystone_p = mock.patch(""sahara.utils.openstack.keystone._client"")"," keystone_p = mock.patch(""sahara.utils.openstack.keystone.client"")",26,28
openstack%2Fmistral~master~I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb,openstack/mistral,master,I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb,Fix dataflow work,MERGED,2014-10-03 11:19:31.000000000,2014-10-07 07:45:59.000000000,2014-10-07 07:45:59.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-10-03 11:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8fc9deacf35b1644569a8004dcd70fd836214050', 'message': 'Fix dataflow work\n\n * Unit test\n\nChange-Id: I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb\n'}, {'number': 2, 'created': '2014-10-03 11:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9c8bfb34631f6e6a45b3b80595cfae58188ada18', 'message': 'Fix dataflow work\n\n * Unit test\n\nCloses-bug: #1376682\n\nChange-Id: I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb\n'}, {'number': 3, 'created': '2014-10-06 07:27:39.000000000', 'files': ['mistral/workflow/data_flow.py', 'mistral/tests/unit/engine1/test_dataflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/17d180956cd9579e971fcce3ac42faf51ed80112', 'message': 'Fix dataflow work\n\n * Unit test\n\nCloses-bug: #1376682\n\nChange-Id: I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb\n'}]",1,125932,17d180956cd9579e971fcce3ac42faf51ed80112,13,4,3,7700,,,0,"Fix dataflow work

 * Unit test

Closes-bug: #1376682

Change-Id: I6fdd6f9cc705bf016646d5bd5fcf98bec450cadb
",git fetch https://review.opendev.org/openstack/mistral refs/changes/32/125932/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/data_flow.py', 'mistral/tests/unit/engine1/test_dataflow.py']",2,8fc9deacf35b1644569a8004dcd70fd836214050,bug/1376682,"# Copyright 2014 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from oslo.config import cfg from mistral.db.v2 import api as db_api from mistral.engine import states from mistral.openstack.common import log as logging from mistral.services import workbooks as wb_service from mistral.tests.unit.engine1 import base LOG = logging.getLogger(__name__) # Use the set_default method to set value otherwise in certain test cases # the change in value is not permanent. cfg.CONF.set_default('auth_enable', False, group='pecan') WORKBOOK = """""" --- version: '2.0' name: wb workflows: wf1: type: direct tasks: task1: action: std.echo output=""Hi,"" publish: hi: $ on-success: - task2 task2: action: std.echo output=""Morpheus"" publish: username: $ on-success: - task3 task3: action: std.echo output=""{$.hi} {$.username}!"" publish: result: $ """""" class DataFlowEngineTest(base.EngineTestCase): def test_trivial_dataflow(self): wb_service.create_workbook_v2({'definition': WORKBOOK}) # Start workflow. exec_db = self.engine.start_workflow('wb.wf1', {}) self._await( lambda: self.is_execution_success(exec_db.id), ) # Note: We need to reread execution to access related tasks. exec_db = db_api.get_execution(exec_db.id) self.assertEqual(states.SUCCESS, exec_db.state) tasks = exec_db.tasks task3 = self._assert_single_item(tasks, name='task3') self.assertEqual(states.SUCCESS, task3.state) self.assertDictEqual( { 'task': { 'task3': 'Hi, Morpheus!', }, 'result': 'Hi, Morpheus!', }, task3.output ) ",,93,0
openstack%2Fglance~master~I49255255df311036d516768afc55475c1f9aad47,openstack/glance,master,I49255255df311036d516768afc55475c1f9aad47,Mark custom properties in image schema as non-base,MERGED,2014-09-24 14:02:19.000000000,2014-10-07 07:12:24.000000000,2014-10-02 00:51:53.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8127}, {'_account_id': 12114}, {'_account_id': 12814}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-09-24 14:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/183ad21ab1242e207b55cfae4c06cafb8c0469d7', 'message': 'Mark custom properties in image schema as non-base\n\nCurrently it is impossible to determine if given image schema property\nis base or custom one and knowledge of that can be handy in some\nsituations.    Proposed change appends to every custom property special\nkey which determiness that it is not a base property.\n\nChange-Id: I49255255df311036d516768afc55475c1f9aad47\nPartial-Bug: #1371559\n'}, {'number': 2, 'created': '2014-09-25 12:23:46.000000000', 'files': ['glance/api/v2/images.py', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/94c05cbdbb3a78b3df4df8d522555f34d2f0a166', 'message': 'Mark custom properties in image schema as non-base\n\nCurrently it is impossible to determine if given image schema property\nis base or custom one and knowledge of that can be handy in some\nsituations.    Proposed change appends to every custom property special\nkey which determiness that it is not a base property.\n\nChange-Id: I49255255df311036d516768afc55475c1f9aad47\nPartial-Bug: #1371559\n'}]",2,123738,94c05cbdbb3a78b3df4df8d522555f34d2f0a166,21,9,2,13161,,,0,"Mark custom properties in image schema as non-base

Currently it is impossible to determine if given image schema property
is base or custom one and knowledge of that can be handy in some
situations.    Proposed change appends to every custom property special
key which determiness that it is not a base property.

Change-Id: I49255255df311036d516768afc55475c1f9aad47
Partial-Bug: #1371559
",git fetch https://review.opendev.org/openstack/glance refs/changes/38/123738/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,183ad21ab1242e207b55cfae4c06cafb8c0469d7,bug/1371559, custom_properties = json.loads(schema_data) for property_value in custom_properties.values(): property_value['is_base'] = False return custom_properties, return json.loads(schema_data),4,1
openstack%2Fsahara~proposed%2Fjuno~I7871400b2342a4cd1a8910ae5121b1bfdc46078d,openstack/sahara,proposed/juno,I7871400b2342a4cd1a8910ae5121b1bfdc46078d,Adding support for oslo.rootwrap to namespace access,ABANDONED,2014-10-06 23:11:56.000000000,2014-10-07 06:49:52.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 23:11:56.000000000', 'files': ['etc/sahara/sahara.conf.sample', 'etc/sahara/rootwrap.conf', 'sahara/config.py', 'etc/sudoers.d/sahara-rootwrap', 'requirements.txt', 'sahara/cli/sahara_rootwrap.py', 'sahara/utils/ssh_remote.py', 'sahara/utils/openstack/neutron.py', 'doc/source/userdoc/features.rst', 'etc/sahara/rootwrap.d/sahara.filters', 'setup.cfg', 'doc/source/userdoc/advanced.configuration.guide.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a023c05d8be3cff890b7d8e6a0084fab0db546cc', 'message': 'Adding support for oslo.rootwrap to namespace access\n\nChanges\n* adding configuration options for rootwrap\n* refactoring ssh connection to use rootwrap as a proxy when requested\n* adding documentation for rootwrap configuration\n* adding default rootwrap filters file\n* adding default sudoers conf file for sahara user\n* adding default rootwrap conf file for sahara-rootwrap\n* adding sahara-rootwrap cli script\n* adding requirement for oslo.rootwrap\n\nChange-Id: I7871400b2342a4cd1a8910ae5121b1bfdc46078d\nCloses-Bug: #1271349\n(cherry picked from commit 43785e6e9edc21678fc43f2cf4f7516d19469199)\n'}]",0,126431,a023c05d8be3cff890b7d8e6a0084fab0db546cc,15,7,1,8411,,,0,"Adding support for oslo.rootwrap to namespace access

Changes
* adding configuration options for rootwrap
* refactoring ssh connection to use rootwrap as a proxy when requested
* adding documentation for rootwrap configuration
* adding default rootwrap filters file
* adding default sudoers conf file for sahara user
* adding default rootwrap conf file for sahara-rootwrap
* adding sahara-rootwrap cli script
* adding requirement for oslo.rootwrap

Change-Id: I7871400b2342a4cd1a8910ae5121b1bfdc46078d
Closes-Bug: #1271349
(cherry picked from commit 43785e6e9edc21678fc43f2cf4f7516d19469199)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/31/126431/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/sahara/sahara.conf.sample', 'etc/sahara/rootwrap.conf', 'sahara/config.py', 'etc/sudoers.d/sahara-rootwrap', 'requirements.txt', 'sahara/cli/sahara_rootwrap.py', 'sahara/utils/ssh_remote.py', 'sahara/utils/openstack/neutron.py', 'doc/source/userdoc/features.rst', 'etc/sahara/rootwrap.d/sahara.filters', 'setup.cfg', 'doc/source/userdoc/advanced.configuration.guide.rst']",12,a023c05d8be3cff890b7d8e6a0084fab0db546cc,bug/1271349," Namespaces and non-root users ----------------------------- In cases where namespaces are being used to access cluster VMs via private IPs, rootwrap functionality is provided to allow users other than ``root`` access to the namespace related OS facilities. To use rootwrap the following configuration property is required to be set: .. sourcecode:: cfg [DEFAULT] use_rootwrap=True Assuming you elect to leverage the default rootwrap command (``sahara-rootwrap``), you will need to perform the following additional setup steps: * Copy the provided sudoers configuration file from the local project file ``etc/sudoers.d/sahara-rootwrap`` to the system specific location, usually ``/etc/sudoers.d``. This file is setup to allow a user named ``sahara`` access to the rootwrap script. It contains the following: .. sourcecode:: cfg sahara ALL = (root) NOPASSWD: /usr/bin/sahara-rootwrap /etc/sahara/rootwrap.conf * * Copy the provided rootwrap configuration file from the local project file ``etc/sahara/rootwrap.conf`` to the system specific location, usually ``/etc/sahara``. This file contains the default configuration for rootwrap. * Copy the provided rootwrap filers file from the local project file ``etc/sahara/rootwrap.d/sahara.filters`` to the location specified in the rootwrap configuration file, usually ``/etc/sahara/rootwrap.d``. This file contains the filters that will allow the ``sahara`` user to acces the ``ip netns exec``, ``nc``, and ``kill`` commands through the rootwrap. It should look similar to the followings: .. sourcecode:: cfg [Filters] ip: IpNetnsExecFilter, ip, root nc: CommandFilter, nc, root kill: CommandFilter, kill, root If you wish to use a rootwrap command other than ``sahara-rootwrap`` you can set the following configuration property in your sahara configuration file: .. sourcecode:: cfg [DEFAULT] rootwrap_command='sudo sahara-rootwrap /etc/sahara/rootwrap.conf' For more information on rootwrap please refer to the `official Rootwrap documentation <https://wiki.openstack.org/wiki/Rootwrap>`_",,188,22
openstack%2Fopenstack-manuals~master~I01c3b171717ea02afc6e6d584da69f39b5c31252,openstack/openstack-manuals,master,I01c3b171717ea02afc6e6d584da69f39b5c31252,Imported Translations from Transifex,MERGED,2014-10-07 06:09:05.000000000,2014-10-07 06:39:52.000000000,2014-10-07 06:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 06:09:05.000000000', 'files': ['doc/image-guide/locale/image-guide.pot', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/446e6766a2250dcd15bd9b46f534752906554eb3', 'message': 'Imported Translations from Transifex\n\nChange-Id: I01c3b171717ea02afc6e6d584da69f39b5c31252\n'}]",0,126473,446e6766a2250dcd15bd9b46f534752906554eb3,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I01c3b171717ea02afc6e6d584da69f39b5c31252
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/73/126473/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/image-guide/locale/image-guide.pot', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po']",3,446e6766a2250dcd15bd9b46f534752906554eb3,transifex/translations,"""POT-Creation-Date: 2014-10-06 16:27+0000\n"" ""PO-Revision-Date: 2014-10-07 03:50+0000\n""#: ./doc/image-guide/section_glance-image-metadata.xml71(title) msgid ""Volume-from-Image properties"" msgstr ""Volume-from-Image "" #: ./doc/image-guide/section_glance-image-metadata.xml72(para) msgid """" ""When creating Block Storage volumes from images, also consider your "" ""configured image properties. If you alter the core image properties, you "" ""should also update your Block Storage configuration. Amend "" ""<option>glance_core_properties</option> in the "" ""<filename>/etc/cinder/cinder.conf</filename> file on all controller nodes to"" "" match the core properties you have set in the Image service."" msgstr ""Block Storage Block Storage  <filename>/etc/cinder/cinder.conf</filename>  <option>glance_core_properties</option> Image Service "" ","""POT-Creation-Date: 2014-09-20 05:29+0000\n"" ""PO-Revision-Date: 2014-09-20 04:50+0000\n""",41,5
openstack%2Fsahara-image-elements~master~Iecef82bec8eb8d10218c5ad2b763ccabb41053ad,openstack/sahara-image-elements,master,Iecef82bec8eb8d10218c5ad2b763ccabb41053ad,Add tools/gate/build-images script,MERGED,2014-10-06 20:42:51.000000000,2014-10-07 06:29:39.000000000,2014-10-07 06:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-10-06 20:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/ba6ceef7ac54a4cd1d3a20066a58eb3687f50c4f', 'message': ""Add tools/gate/build-images script\n\nIt will simplify configuring and tuning for our upcoming images\ngating. In gate job we'll just exec this script and it will do\nall the things we need. Let's start just with the building all\nimages for the specified plugin.\n\nChange-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad\n""}, {'number': 2, 'created': '2014-10-06 20:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d164ffc91b00cf7a929074f75a254ab6f9c9b79a', 'message': ""Add tools/gate/build-images script\n\nIt will simplify configuring and tuning for our upcoming images\ngating. In gate job we'll just exec this script and it will do\nall the things we need. Let's start just with the building all\nimages for the specified plugin.\n\nChange-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad\n""}, {'number': 3, 'created': '2014-10-06 21:26:09.000000000', 'files': ['tools/gate/build-images'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/8f38712e1f62d3e0e7bb50133c029f57825dec2c', 'message': ""Add tools/gate/build-images script\n\nIt will simplify configuring and tuning for our upcoming images\ngating. In gate job we'll just exec this script and it will do\nall the things we need. Let's start just with the building all\nimages for the specified plugin.\n\nChange-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad\n""}]",1,126411,8f38712e1f62d3e0e7bb50133c029f57825dec2c,24,6,3,6786,,,0,"Add tools/gate/build-images script

It will simplify configuring and tuning for our upcoming images
gating. In gate job we'll just exec this script and it will do
all the things we need. Let's start just with the building all
images for the specified plugin.

Change-Id: Iecef82bec8eb8d10218c5ad2b763ccabb41053ad
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/11/126411/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/gate/build-images'],1,ba6ceef7ac54a4cd1d3a20066a58eb3687f50c4f,,#!/bin/bash -xe PLUGIN=$1 ./diskimage-create/diskimage-create.sh -p $1 ,,5,0
openstack%2Fopenstack-doc-tools~master~I71b6960801163c2d2c52253d0c9a45ec2bf02b0d,openstack/openstack-doc-tools,master,I71b6960801163c2d2c52253d0c9a45ec2bf02b0d,Fix extract_swift_flags.py,MERGED,2014-10-07 05:08:18.000000000,2014-10-07 06:22:51.000000000,2014-10-07 06:22:51.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-07 05:08:18.000000000', 'files': ['autogenerate_config_docs/extract_swift_flags.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/ecc3744a72f4dc9b832710fb7e1ab5f5a0568328', 'message': 'Fix extract_swift_flags.py\n\nThe renaming of the swift-conf-changes.xml in the openstack-manual\nrepository broke a test in the extract_swift_flags.py script. This patch\nchanges the test to make the script work again.\n\nChange-Id: I71b6960801163c2d2c52253d0c9a45ec2bf02b0d\n'}]",0,126465,ecc3744a72f4dc9b832710fb7e1ab5f5a0568328,6,2,1,7923,,,0,"Fix extract_swift_flags.py

The renaming of the swift-conf-changes.xml in the openstack-manual
repository broke a test in the extract_swift_flags.py script. This patch
changes the test to make the script work again.

Change-Id: I71b6960801163c2d2c52253d0c9a45ec2bf02b0d
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/65/126465/1 && git format-patch -1 --stdout FETCH_HEAD,['autogenerate_config_docs/extract_swift_flags.py'],1,ecc3744a72f4dc9b832710fb7e1ab5f5a0568328,, if optfile.endswith('/swift-conf-changes.xml'):, if '/swift-conf-changes-' in optfile:,1,1
openstack%2Fheat~master~I96050295f48109bd370168f0a5c66e93e506da3e,openstack/heat,master,I96050295f48109bd370168f0a5c66e93e506da3e,Unit test autoscaling._calculate_new_capacity,MERGED,2014-09-03 21:51:27.000000000,2014-10-07 06:19:23.000000000,2014-10-07 06:19:22.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8246}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-09-03 21:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a0d5af5f1a836044fabbcb39e13fb333c2b9da4c', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\n'}, {'number': 2, 'created': '2014-09-04 03:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8ee615a40fb1a77eda5b0e358e3d5776833d4156', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 3, 'created': '2014-09-17 10:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/69f5fc378d969992e4a4662675d9f9d34095dac8', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 4, 'created': '2014-09-18 01:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bf6a8fc2e7f63b78903d6e69de3309ed26f6bb75', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 5, 'created': '2014-09-22 06:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d03763a993f9b6dcac93905239c42d58052ba1ee', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 6, 'created': '2014-09-25 12:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/63338d1d5b5438b86050785a47e51166c4b1f9a1', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 7, 'created': '2014-10-02 05:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/efb1c6911d3ed0c9a2f49d494d9001d181dda051', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}, {'number': 8, 'created': '2014-10-07 03:29:52.000000000', 'files': ['heat/tests/autoscaling/test_new_capacity.py', 'heat/tests/test_autoscaling.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/499e9d3d84cea86de39fb12a70a0e4e9fbb09bb0', 'message': 'Unit test autoscaling._calculate_new_capacity\n\nThis is so we can reduce the complexity in test_autoscaling.py\n\nChange-Id: I96050295f48109bd370168f0a5c66e93e506da3e\npart of blueprint decouple-nested\n'}]",3,118907,499e9d3d84cea86de39fb12a70a0e4e9fbb09bb0,36,6,8,4328,,,0,"Unit test autoscaling._calculate_new_capacity

This is so we can reduce the complexity in test_autoscaling.py

Change-Id: I96050295f48109bd370168f0a5c66e93e506da3e
part of blueprint decouple-nested
",git fetch https://review.opendev.org/openstack/heat refs/changes/07/118907/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/autoscaling/test_new_capacity.py', 'heat/tests/test_autoscaling.py']",2,a0d5af5f1a836044fabbcb39e13fb333c2b9da4c,bp/decouple-nested,," def test_scaling_group_adjust(self): t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) # start with 3 properties = t['Resources']['WebServerGroup']['Properties'] properties['DesiredCapacity'] = '3' self._stub_lb_reload(3) now = timeutils.utcnow() self._stub_meta_expected(now, 'ExactCapacity : 3') self._stub_create(3) self.m.ReplayAll() rsrc = self.create_scaling_group(t, stack, 'WebServerGroup') self.assertEqual(3, len(rsrc.get_instance_names())) # reduce to 1 self._stub_lb_reload(1) self._stub_delete(2) self.stub_ImageConstraint_validate(num=1) self._stub_meta_expected(now, 'ChangeInCapacity : -2') self._stub_scale_notification(adjust=-2, groupname=rsrc.FnGetRefId(), start_capacity=3, end_capacity=1) self.m.ReplayAll() rsrc.adjust(-2) self.assertEqual(1, len(rsrc.get_instance_names())) # raise to 3 self._stub_lb_reload(3) self._stub_meta_expected(now, 'ChangeInCapacity : 2') self._stub_create(2) self._stub_scale_notification(adjust=2, groupname=rsrc.FnGetRefId(), start_capacity=1, end_capacity=3) self.m.ReplayAll() rsrc.adjust(2) self.assertEqual(3, len(rsrc.get_instance_names())) # set to 2 self._stub_lb_reload(2) self._stub_delete(1) self.stub_ImageConstraint_validate(num=2) self._stub_meta_expected(now, 'ExactCapacity : 2') self._stub_scale_notification(adjust=2, groupname=rsrc.FnGetRefId(), adjust_type='ExactCapacity', start_capacity=3, end_capacity=2) self.m.ReplayAll() rsrc.adjust(2, 'ExactCapacity') self.assertEqual(2, len(rsrc.get_instance_names())) self.m.VerifyAll() def test_scaling_group_truncate_adjustment(self): t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) # Create initial group, 2 instances properties = t['Resources']['WebServerGroup']['Properties'] properties['DesiredCapacity'] = '2' self._stub_lb_reload(2) now = timeutils.utcnow() self._stub_meta_expected(now, 'ExactCapacity : 2') self._stub_create(2) self.m.ReplayAll() rsrc = self.create_scaling_group(t, stack, 'WebServerGroup') stack.resources['WebServerGroup'] = rsrc self.assertEqual(2, len(rsrc.get_instance_names())) # raise above the max self._stub_lb_reload(5) self._stub_meta_expected(now, 'ChangeInCapacity : 4') self._stub_create(3) self.m.ReplayAll() rsrc.adjust(4) self.assertEqual(5, len(rsrc.get_instance_names())) # lower below the min self._stub_lb_reload(1) self._stub_delete(4) self.stub_ImageConstraint_validate(num=1) self._stub_meta_expected(now, 'ChangeInCapacity : -5') self.m.ReplayAll() rsrc.adjust(-5) self.assertEqual(1, len(rsrc.get_instance_names())) # no change rsrc.adjust(0) self.assertEqual(1, len(rsrc.get_instance_names())) rsrc.delete() self.m.VerifyAll() def _do_test_scaling_group_percent(self, decrease, lowest, increase, create, highest): t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) # Create initial group, 2 instances properties = t['Resources']['WebServerGroup']['Properties'] properties['DesiredCapacity'] = '2' self._stub_lb_reload(2) self._stub_create(2) now = timeutils.utcnow() self._stub_meta_expected(now, 'ExactCapacity : 2') self.m.ReplayAll() rsrc = self.create_scaling_group(t, stack, 'WebServerGroup') stack.resources['WebServerGroup'] = rsrc self.assertEqual(2, len(rsrc.get_instance_names())) # reduce by decrease % self._stub_lb_reload(lowest) adjust = 'PercentChangeInCapacity : %d' % decrease self._stub_meta_expected(now, adjust) self._stub_delete(2 - lowest) self.stub_ImageConstraint_validate(num=1) self.m.ReplayAll() rsrc.adjust(decrease, 'PercentChangeInCapacity') self.assertEqual(lowest, len(rsrc.get_instance_names())) # raise by increase % self._stub_lb_reload(highest) adjust = 'PercentChangeInCapacity : %d' % increase self._stub_meta_expected(now, adjust) self._stub_create(create) self.m.ReplayAll() rsrc.adjust(increase, 'PercentChangeInCapacity') self.assertEqual(highest, len(rsrc.get_instance_names())) rsrc.delete() def test_scaling_group_percent(self): self._do_test_scaling_group_percent(-50, 1, 200, 2, 3) def test_scaling_group_percent_round_up(self): self._do_test_scaling_group_percent(-33, 1, 33, 1, 2) def test_scaling_group_percent_round_down(self): self._do_test_scaling_group_percent(-66, 1, 225, 2, 3) def test_scaling_policy_up(self): t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) # Create initial group self._stub_lb_reload(1) now = timeutils.utcnow() self._stub_meta_expected(now, 'ExactCapacity : 1') self._stub_create(1) self.m.ReplayAll() rsrc = self.create_scaling_group(t, stack, 'WebServerGroup') stack.resources['WebServerGroup'] = rsrc self.assertEqual(1, len(rsrc.get_instance_names())) # Scale up one self._stub_lb_reload(2) self._stub_meta_expected(now, 'ChangeInCapacity : 1', 2) self._stub_create(1) self.m.ReplayAll() up_policy = self.create_scaling_policy(t, stack, 'WebServerScaleUpPolicy') alarm_url = up_policy.FnGetAtt('AlarmUrl') self.assertIsNotNone(alarm_url) up_policy.signal() self.assertEqual(2, len(rsrc.get_instance_names())) rsrc.delete() self.m.VerifyAll() def test_scaling_policy_down(self): t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) # Create initial group, 2 instances properties = t['Resources']['WebServerGroup']['Properties'] properties['DesiredCapacity'] = '2' self._stub_lb_reload(2) now = timeutils.utcnow() self._stub_meta_expected(now, 'ExactCapacity : 2') self._stub_create(2) self.m.ReplayAll() rsrc = self.create_scaling_group(t, stack, 'WebServerGroup') stack.resources['WebServerGroup'] = rsrc self.assertEqual(2, len(rsrc.get_instance_names())) # Scale down one self._stub_lb_reload(1) self._stub_delete(1) self.stub_ImageConstraint_validate(num=1) self._stub_meta_expected(now, 'ChangeInCapacity : -1', 2) self.m.ReplayAll() down_policy = self.create_scaling_policy(t, stack, 'WebServerScaleDownPolicy') down_policy.signal() self.assertEqual(1, len(rsrc.get_instance_names())) rsrc.delete() self.m.VerifyAll() ",78,199
openstack%2Fheat~master~Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63,openstack/heat,master,Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63,Move TestInstanceGroup to test_instance_group.py,MERGED,2014-09-03 21:51:27.000000000,2014-10-07 06:19:14.000000000,2014-10-07 06:19:13.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-03 21:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b38d24931ba9e56b15691ab0425820fe4d94ad5e', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\n'}, {'number': 2, 'created': '2014-09-04 03:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8d15c6c107104a808f771702c89a84fcd1e7f097', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 3, 'created': '2014-09-17 10:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1fb48a439748349bcaaa3cbc8b403fc386956017', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 4, 'created': '2014-09-18 01:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/15c5ccbc1d03d6b7517eb265de9f4e7ee2e00eca', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 5, 'created': '2014-09-22 06:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dc90da583e2daa3c1f9876894cdba1776ebe6382', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 6, 'created': '2014-09-25 12:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eed5985f6aa7b7ae9d080361547e2e34fbaf8963', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 7, 'created': '2014-10-02 05:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ba9afd2801e007721afa4da9333b07f6c049bf71', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}, {'number': 8, 'created': '2014-10-07 03:29:52.000000000', 'files': ['heat/tests/test_autoscaling.py', 'heat/tests/autoscaling/inline_templates.py', 'heat/tests/autoscaling/__init__.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2da12886235fe94dc03b1703fda59945f912b04c', 'message': 'Move TestInstanceGroup to test_instance_group.py\n\nChange-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63\npart of blueprint decouple-nested\n'}]",0,118906,2da12886235fe94dc03b1703fda59945f912b04c,49,8,8,4328,,,0,"Move TestInstanceGroup to test_instance_group.py

Change-Id: Ib3bbadf3a868c6c82e30c63750a6ec76f873fc63
part of blueprint decouple-nested
",git fetch https://review.opendev.org/openstack/heat refs/changes/06/118906/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_autoscaling.py', 'heat/tests/autoscaling/__init__.py', 'heat/tests/autoscaling/inline_templates.py', 'heat/tests/test_instance_group.py']",4,b38d24931ba9e56b15691ab0425820fe4d94ad5e,bp/decouple-nested,"import mock from heat.engine.resources import autoscaling as ascfrom heat.tests.autoscaling import inline_templates from heat.tests import commonclass InstanceGroupTest(common.HeatTestCase): class TestChildTemplate(common.HeatTestCase): params = {'KeyName': 'test', 'ImageId': 'foo'} def setUp(self): super(TestChildTemplate, self).setUp() t = template_format.parse(inline_templates.as_template) stack = utils.parse_stack(t, params=self.params) defn = rsrc_defn.ResourceDefinition('ig', 'OS::Heat::InstanceGroup', {'Size': 2, 'LaunchConfigurationName': 'foo'}) self.instance_group = asc.InstanceGroup('ig', defn, stack) def test_child_template(self): self.instance_group._create_template = mock.Mock(return_value='tpl') self.assertEqual('tpl', self.instance_group.child_template()) self.instance_group._create_template.assert_called_once_with(2) def test_child_params(self): self.instance_group._environment = mock.Mock(return_value='env') self.assertEqual('env', self.instance_group.child_params())","from heat.tests.common import HeatTestCaseclass InstanceGroupTest(HeatTestCase): def setUp(self): super(InstanceGroupTest, self).setUp() ",106,91
openstack%2Fheat~master~I4bb0f47abe629433fa6ca0b76fa579aec715530a,openstack/heat,master,I4bb0f47abe629433fa6ca0b76fa579aec715530a,Refactor AWS::EC2::SecurityGroup resource,MERGED,2014-08-22 15:05:23.000000000,2014-10-07 06:01:43.000000000,2014-10-07 06:01:42.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-08-22 15:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b920b2bd4a40331972e22fa177ff9c241a239a1', 'message': 'Refactor AWS SecurityGroup and tests\n\nSplit rule creation out from from rule creation as separate methods.\nSimilar split in tests - group mocks for rules creation as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 2, 'created': '2014-08-27 14:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dddc0abc7f6f154bcd9b3e2deb13b7b4d652d2e8', 'message': 'Refactor AWS SecurityGroup and tests\n\nSplit rule creation out from from rule creation as separate methods.\nSimilar split in tests - group mocks for rules creation as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 3, 'created': '2014-09-01 09:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e02b82baa8207bdcba54fbf2371e664f2e55eebd', 'message': 'Refactor AWS SecurityGroup and tests\n\nSplit rule creation out from from rule creation as separate methods.\nSimilar split in tests - group mocks for rules creation as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 4, 'created': '2014-09-08 11:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/78e46a5655deff2e7a3f1f824f4d2b4e48b573fa', 'message': 'Refactor AWS SecurityGroup and tests\n\nRefactor rule create/delete out from group create/delete as separate methods.\nSimilar split in tests - refactor mocks for rules creation/deletion\nto separate methods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 5, 'created': '2014-09-12 19:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/adfb475fecd78905f8ca85199e29c69610eaa7e5', 'message': 'Refactor AWS::EC2::SecurityGroup resource\n\nRefactor rules create/delete out from group create/delete as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 6, 'created': '2014-09-16 20:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3f6cac156ec8901c5e225b2027fb2f6dbecebb2f', 'message': 'Refactor AWS::EC2::SecurityGroup resource\n\nRefactor rules create/delete out from group create/delete as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 7, 'created': '2014-09-17 09:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/298b1f56a1616a038a109698420e607e91e8eafc', 'message': 'Refactor AWS::EC2::SecurityGroup resource\n\nRefactor rules create/delete out from group create/delete as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}, {'number': 8, 'created': '2014-10-06 15:00:43.000000000', 'files': ['heat/engine/resources/security_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/96af0cda3765bc1720e2b52c3757c0d09970c310', 'message': 'Refactor AWS::EC2::SecurityGroup resource\n\nRefactor rules create/delete out from group create/delete as separate\nmethods.\n\nChange-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a\n'}]",2,116304,96af0cda3765bc1720e2b52c3757c0d09970c310,39,6,8,9542,,,0,"Refactor AWS::EC2::SecurityGroup resource

Refactor rules create/delete out from group create/delete as separate
methods.

Change-Id: I4bb0f47abe629433fa6ca0b76fa579aec715530a
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/116304/7 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/security_group.py', 'heat/tests/test_security_group.py']",2,1b920b2bd4a40331972e22fa177ff9c241a239a1,bp/handle-update-for-security-groups," def stubout_nova_create_security_group(self): return sg_name def stubout_nova_get_security_group(self, sg_name): description='', rules=[{ ""from_port"": 22, ""to_port"": 22, 'from_port': 80, 'to_port': 80, def stubout_nova_delete_security_group_rules(self, sg_name): self.stubout_nova_get_security_group(sg_name) def stubout_neutron_create_security_group(self): neutronclient.Client.delete_security_group_rule('aaaa-1').AndReturn( None) neutronclient.Client.delete_security_group_rule('aaaa-2').AndReturn( None) def stubout_neutron_get_security_group(self): 'port_range_max': 22, 'port_range_min': 22 'port_range_max': 80, 'port_range_min': 80 'port_range_max': 22, 'port_range_min': 22 def stubout_neutron_delete_security_group_rules(self): self.stubout_neutron_get_security_group() def test_security_group_nova(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = self.stubout_nova_create_security_group() # delete script self.stubout_nova_delete_security_group_rules(sg_name) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) stack.delete() self.m.VerifyAll() def test_security_group_nova_bad_source_group(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) nova_sg.SecurityGroupManager.list().AndReturn([NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], )]) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.create( sg_name, 'HTTP and SSH access').AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[])) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndReturn(None) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn(None) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": 22, ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": 22, ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': 80, 'group': {}, 'ip_protocol': 'tcp', 'to_port': 80, 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndReturn(None) nova_sgr.SecurityGroupRuleManager.delete(131).AndReturn(None) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova_bad_source_group) sg = stack['the_sg'] self.assertEqual(sg.FAILED, sg.status) self.assertIn('not found', sg.status_reason) stack.delete() self.m.VerifyAll() def test_security_group_nova_exception(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.list().AndReturn([ NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[], ), NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], ) ]) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndRaise( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', None, None, None, 1).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'icmp', None, None, None, '1').AndReturn( fakes.fake_exception(400, 'Rule already exists')) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": 22, ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": 22, ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': 80, 'group': {}, 'ip_protocol': 'tcp', 'to_port': 80, 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'tcp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 132 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'icmp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 133 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(131).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(132).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(133).AndRaise( fakes.fake_exception()) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) nova_sg.SecurityGroupManager.get(2).AndRaise( fakes.fake_exception()) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) scheduler.TaskRunner(sg.delete)() sg.state_set(sg.CREATE, sg.COMPLETE, 'to delete again') sg.resource_id = 2 stack.delete() self.m.VerifyAll() def test_security_group_nova_with_egress_rules(self): t = template_format.parse(self.test_template_nova_with_egress) stack = self.parse_stack(t) sg = stack['the_sg'] self.assertRaises(exception.EgressRuleNotAllowed, sg.validate) def test_security_group_neutron(self): #create script self.stubout_neutron_create_security_group() # delete script self.stubout_neutron_delete_security_group_rules() 'port_range_max': 22, 'port_range_min': 22 'port_range_max': 80, 'port_range_min': 80 'port_range_max': 22, 'port_range_min': 22"," def test_security_group_nova(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) # delete script description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""to_port"": '22', 'from_port': '80', 'to_port': '80', nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) stack.delete() self.m.VerifyAll() def test_security_group_nova_bad_source_group(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) nova_sg.SecurityGroupManager.list().AndReturn([NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], )]) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.create( sg_name, 'HTTP and SSH access').AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[])) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndReturn(None) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn(None) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": '22', ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': '80', 'group': {}, 'ip_protocol': 'tcp', 'to_port': '80', 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndReturn(None) nova_sgr.SecurityGroupRuleManager.delete(131).AndReturn(None) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova_bad_source_group) sg = stack['the_sg'] self.assertEqual(sg.FAILED, sg.status) self.assertIn('not found', sg.status_reason) stack.delete() self.m.VerifyAll() def test_security_group_client_exception(self): #create script nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.list().AndReturn([ NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[], ), NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], ) ]) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndRaise( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', None, None, None, 1).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'icmp', None, None, None, '1').AndReturn( fakes.fake_exception(400, 'Rule already exists')) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": '22', ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': '80', 'group': {}, 'ip_protocol': 'tcp', 'to_port': '80', 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'tcp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 132 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'icmp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 133 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(131).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(132).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(133).AndRaise( fakes.fake_exception()) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) nova_sg.SecurityGroupManager.get(2).AndRaise( fakes.fake_exception()) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) scheduler.TaskRunner(sg.delete)() sg.state_set(sg.CREATE, sg.COMPLETE, 'to delete again') sg.resource_id = 2 stack.delete() self.m.VerifyAll() def test_security_group_nova_with_egress_rules(self): t = template_format.parse(self.test_template_nova_with_egress) stack = self.parse_stack(t) sg = stack['the_sg'] self.assertRaises(exception.EgressRuleNotAllowed, sg.validate) def test_security_group_neutron(self): #create script neutronclient.Client.delete_security_group_rule('aaaa-1').AndReturn( None) neutronclient.Client.delete_security_group_rule('aaaa-2').AndReturn( None) # delete script 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '80', 'port_range_min': '80' 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '80', 'port_range_min': '80' 'port_range_max': '22', 'port_range_min': '22'",324,306
openstack%2Fheat~master~Ia32639147f12e2a3026b2d8c3efb499d8cea6765,openstack/heat,master,Ia32639147f12e2a3026b2d8c3efb499d8cea6765,Unittests: refactor AWS::EC2::SecurityGroup tests,MERGED,2014-09-12 19:26:58.000000000,2014-10-07 06:01:34.000000000,2014-10-07 06:01:32.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}]","[{'number': 1, 'created': '2014-09-12 19:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e7b7c5d5f2908acdb5369bf611e2d7db027ca45a', 'message': 'Unittests: refactor AWS::EC2::SecurityGroup tests\n\nRefactor mocks for rule creation into separate helper methods.\n\nChange-Id: Ia32639147f12e2a3026b2d8c3efb499d8cea6765\n'}, {'number': 2, 'created': '2014-09-16 20:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f43767ed94037ec4756b8be061a487ca7f2820bb', 'message': 'Unittests: refactor AWS::EC2::SecurityGroup tests\n\nRefactor mocks for rule creation into separate helper methods.\n\nChange-Id: Ia32639147f12e2a3026b2d8c3efb499d8cea6765\n'}, {'number': 3, 'created': '2014-09-17 09:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/da582dc16e603c67bae509745c2f3e68fd7808d6', 'message': 'Unittests: refactor AWS::EC2::SecurityGroup tests\n\nRefactor mocks for rule creation into separate helper methods.\n\nChange-Id: Ia32639147f12e2a3026b2d8c3efb499d8cea6765\n'}, {'number': 4, 'created': '2014-10-06 15:00:43.000000000', 'files': ['heat/tests/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/8156b2b0e09bbd6c4a27626ea1500d073a89b2a4', 'message': 'Unittests: refactor AWS::EC2::SecurityGroup tests\n\nRefactor mocks for rule creation into separate helper methods.\n\nChange-Id: Ia32639147f12e2a3026b2d8c3efb499d8cea6765\n'}]",0,121207,8156b2b0e09bbd6c4a27626ea1500d073a89b2a4,20,5,4,9542,,,0,"Unittests: refactor AWS::EC2::SecurityGroup tests

Refactor mocks for rule creation into separate helper methods.

Change-Id: Ia32639147f12e2a3026b2d8c3efb499d8cea6765
",git fetch https://review.opendev.org/openstack/heat refs/changes/07/121207/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_security_group.py'],1,e7b7c5d5f2908acdb5369bf611e2d7db027ca45a,bp/handle-update-for-security-groups," def stubout_nova_create_security_group(self): return sg_name def stubout_nova_get_security_group(self, sg_name): description='', rules=[{ ""from_port"": 22, ""to_port"": 22, 'from_port': 80, 'to_port': 80, def stubout_nova_delete_security_group_rules(self, sg_name): self.stubout_nova_get_security_group(sg_name) def stubout_neutron_create_security_group(self): neutronclient.Client.delete_security_group_rule('aaaa-1').AndReturn( None) neutronclient.Client.delete_security_group_rule('aaaa-2').AndReturn( None) def stubout_neutron_get_security_group(self): 'port_range_max': 22, 'port_range_min': 22 'port_range_max': 80, 'port_range_min': 80 'port_range_max': 22, 'port_range_min': 22 def stubout_neutron_delete_security_group_rules(self): self.stubout_neutron_get_security_group() def test_security_group_nova(self): #create script #nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = self.stubout_nova_create_security_group() # delete script self.stubout_nova_delete_security_group_rules(sg_name) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) stack.delete() self.m.VerifyAll() def test_security_group_nova_bad_source_group(self): #create script self.mock_no_neutron() nova.NovaClientPlugin._create().AndReturn(self.fc) nova_sg.SecurityGroupManager.list().AndReturn([NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], )]) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.create( sg_name, 'HTTP and SSH access').AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[])) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndReturn(None) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn(None) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": 22, ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": 22, ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': 80, 'group': {}, 'ip_protocol': 'tcp', 'to_port': 80, 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndReturn(None) nova_sgr.SecurityGroupRuleManager.delete(131).AndReturn(None) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova_bad_source_group) sg = stack['the_sg'] self.assertEqual(sg.FAILED, sg.status) self.assertIn('not found', sg.status_reason) stack.delete() self.m.VerifyAll() def test_security_group_nova_exception(self): #create script self.mock_no_neutron() nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.list().AndReturn([ NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[], ), NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], ) ]) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndRaise( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', None, None, None, 1).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'icmp', None, None, None, '1').AndReturn( fakes.fake_exception(400, 'Rule already exists')) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": 22, ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": 22, ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': 80, 'group': {}, 'ip_protocol': 'tcp', 'to_port': 80, 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'tcp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 132 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'icmp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 133 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(131).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(132).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(133).AndRaise( fakes.fake_exception()) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) nova_sg.SecurityGroupManager.get(2).AndRaise( fakes.fake_exception()) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) scheduler.TaskRunner(sg.delete)() sg.state_set(sg.CREATE, sg.COMPLETE, 'to delete again') sg.resource_id = 2 stack.delete() self.m.VerifyAll() def test_security_group_nova_with_egress_rules(self): self.mock_no_neutron() t = template_format.parse(self.test_template_nova_with_egress) stack = self.parse_stack(t) sg = stack['the_sg'] self.assertRaises(exception.EgressRuleNotAllowed, sg.validate) def test_security_group_neutron(self): #create script self.stubout_neutron_create_security_group() # delete script self.stubout_neutron_delete_security_group_rules() 'port_range_max': 22, 'port_range_min': 22 'port_range_max': 80, 'port_range_min': 80 'port_range_max': 22, 'port_range_min': 22"," def test_security_group_nova(self): # delete script description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""to_port"": '22', 'from_port': '80', 'to_port': '80', nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) stack.delete() self.m.VerifyAll() def test_security_group_nova_bad_source_group(self): #create script self.mock_no_neutron() nova.NovaClientPlugin._create().AndReturn(self.fc) nova_sg.SecurityGroupManager.list().AndReturn([NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], )]) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.create( sg_name, 'HTTP and SSH access').AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[])) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndReturn(None) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn(None) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": '22', ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': '80', 'group': {}, 'ip_protocol': 'tcp', 'to_port': '80', 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndReturn(None) nova_sgr.SecurityGroupRuleManager.delete(131).AndReturn(None) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova_bad_source_group) sg = stack['the_sg'] self.assertEqual(sg.FAILED, sg.status) self.assertIn('not found', sg.status_reason) stack.delete() self.m.VerifyAll() def test_security_group_client_exception(self): #create script self.mock_no_neutron() nova.NovaClientPlugin._create().AndReturn(self.fc) sg_name = utils.PhysName('test_stack', 'the_sg') nova_sg.SecurityGroupManager.list().AndReturn([ NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[], ), NovaSG( id=1, name='test', description='FAKE_SECURITY_GROUP', rules=[], ) ]) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '22', '22', '0.0.0.0/0', None).AndRaise( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', '80', '80', '0.0.0.0/0', None).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'tcp', None, None, None, 1).AndReturn( fakes.fake_exception(400, 'Rule already exists')) nova_sgr.SecurityGroupRuleManager.create( 2, 'icmp', None, None, None, '1').AndReturn( fakes.fake_exception(400, 'Rule already exists')) # delete script nova_sg.SecurityGroupManager.get(2).AndReturn(NovaSG( id=2, name=sg_name, description='HTTP and SSH access', rules=[{ ""from_port"": '22', ""group"": {}, ""ip_protocol"": ""tcp"", ""to_port"": '22', ""parent_group_id"": 2, ""ip_range"": { ""cidr"": ""0.0.0.0/0"" }, 'id': 130 }, { 'from_port': '80', 'group': {}, 'ip_protocol': 'tcp', 'to_port': '80', 'parent_group_id': 2, 'ip_range': { 'cidr': '0.0.0.0/0' }, 'id': 131 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'tcp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 132 }, { 'from_port': None, 'group': { 'tenant_id': 'f18ca530cc05425e8bac0a5ff92f7e88', 'name': 'test' }, 'ip_protocol': 'icmp', 'to_port': None, 'parent_group_id': 2, 'ip_range': {}, 'id': 133 }] )) nova_sgr.SecurityGroupRuleManager.delete(130).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(131).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(132).AndRaise( fakes.fake_exception()) nova_sgr.SecurityGroupRuleManager.delete(133).AndRaise( fakes.fake_exception()) nova_sg.SecurityGroupManager.delete(2).AndReturn(None) nova_sg.SecurityGroupManager.get(2).AndRaise( fakes.fake_exception()) self.m.ReplayAll() stack = self.create_stack(self.test_template_nova) sg = stack['the_sg'] self.assertResourceState(sg, utils.PhysName('test_stack', 'the_sg')) scheduler.TaskRunner(sg.delete)() sg.state_set(sg.CREATE, sg.COMPLETE, 'to delete again') sg.resource_id = 2 stack.delete() self.m.VerifyAll() def test_security_group_nova_with_egress_rules(self): self.mock_no_neutron() t = template_format.parse(self.test_template_nova_with_egress) stack = self.parse_stack(t) sg = stack['the_sg'] self.assertRaises(exception.EgressRuleNotAllowed, sg.validate) def test_security_group_neutron(self): #create script neutronclient.Client.delete_security_group_rule('aaaa-1').AndReturn( None) neutronclient.Client.delete_security_group_rule('aaaa-2').AndReturn( None) # delete script 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '80', 'port_range_min': '80' 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '22', 'port_range_min': '22' 'port_range_max': '80', 'port_range_min': '80' 'port_range_max': '22', 'port_range_min': '22'",242,220
openstack%2Fglance~master~I681747b6579a2284f23bf154889a61c639b0616d,openstack/glance,master,I681747b6579a2284f23bf154889a61c639b0616d,Specify the MetadefNamespace.namespace column is not nullable,MERGED,2014-09-10 07:53:40.000000000,2014-10-07 05:15:36.000000000,2014-10-07 03:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 10383}, {'_account_id': 12299}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-09-10 07:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/63bf29e7ebca996c8feb37cafbec7e4256ab1953', 'message': 'Specify the MetadefNamespace.namespace column is not nullable.\n\nThe metadef_namespaces table definition indicates the namespace\ncolumn as not accepting nulls. The related MetadefNamespace ORM class\nshould also indicate that the namespace column does not accept nulls\nwith ""nullable=False"" in the column definition.\n\nChange-Id: I681747b6579a2284f23bf154889a61c639b0616d\nCloses-Bug: 1367619\n'}, {'number': 2, 'created': '2014-09-12 01:21:31.000000000', 'files': ['glance/db/sqlalchemy/models_metadef.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/10e858d57be5e04615f390b3060c8aeadaeed954', 'message': 'Specify the MetadefNamespace.namespace column is not nullable\n\nThe metadef_namespaces table definition indicates the namespace\ncolumn as not accepting nulls. The related MetadefNamespace ORM class\nshould also indicate that the namespace column does not accept nulls\nwith ""nullable=False"" in the column definition.\n\nChange-Id: I681747b6579a2284f23bf154889a61c639b0616d\nCloses-Bug: 1367619\n'}]",0,120334,10e858d57be5e04615f390b3060c8aeadaeed954,24,9,2,10383,,,0,"Specify the MetadefNamespace.namespace column is not nullable

The metadef_namespaces table definition indicates the namespace
column as not accepting nulls. The related MetadefNamespace ORM class
should also indicate that the namespace column does not accept nulls
with ""nullable=False"" in the column definition.

Change-Id: I681747b6579a2284f23bf154889a61c639b0616d
Closes-Bug: 1367619
",git fetch https://review.opendev.org/openstack/glance refs/changes/34/120334/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/db/sqlalchemy/models_metadef.py'],1,63bf29e7ebca996c8feb37cafbec7e4256ab1953,bug/1367619," namespace = Column(String(80), nullable=False)", namespace = Column(String(80)),1,1
openstack%2Fglance~master~I26965a549daf9340621b0f18a1b845b39bac4bd8,openstack/glance,master,I26965a549daf9340621b0f18a1b845b39bac4bd8,Make compute-trust.json compatible with TrustFilter,MERGED,2014-09-15 14:28:33.000000000,2014-10-07 04:45:33.000000000,2014-10-02 11:59:51.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 11600}, {'_account_id': 12231}, {'_account_id': 12299}, {'_account_id': 13024}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-09-15 14:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/196399ef496c903b8b628cb9b92851649df23d4d', 'message': 'Make compute-trust.json compatible with TrustFilter\n\nCurrent properties inside compute-trust.json does not match\nwith how TrustFilter in nova works. JSON provides True/False\nboolean values but TrustFilter expects trusted/untrusted/unknown\nstring values. This patch repairs compute-trust.json to be\ncompatible with TrustFilter.\n\nChange-Id: I26965a549daf9340621b0f18a1b845b39bac4bd8\nCloses-Bug: #1369581\n'}, {'number': 2, 'created': '2014-09-22 06:56:24.000000000', 'files': ['etc/metadefs/compute-trust.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/39e90f29d93f991d95092de5f93a239be1b3ca3b', 'message': 'Make compute-trust.json compatible with TrustFilter\n\nCurrent properties inside compute-trust.json does not match\nwith how TrustFilter in nova works. JSON provides True/False\nboolean values but TrustFilter expects trusted/untrusted/unknown\nstring values. This patch repairs compute-trust.json to be\ncompatible with TrustFilter.\n\nChange-Id: I26965a549daf9340621b0f18a1b845b39bac4bd8\nCloses-Bug: #1369581\n'}]",0,121587,39e90f29d93f991d95092de5f93a239be1b3ca3b,19,10,2,12299,,,0,"Make compute-trust.json compatible with TrustFilter

Current properties inside compute-trust.json does not match
with how TrustFilter in nova works. JSON provides True/False
boolean values but TrustFilter expects trusted/untrusted/unknown
string values. This patch repairs compute-trust.json to be
compatible with TrustFilter.

Change-Id: I26965a549daf9340621b0f18a1b845b39bac4bd8
Closes-Bug: #1369581
",git fetch https://review.opendev.org/openstack/glance refs/changes/87/121587/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/metadefs/compute-trust.json'],1,196399ef496c903b8b628cb9b92851649df23d4d,bug/1369581," ""type"": ""string"", ""enum"": [ ""trusted"", ""untrusted"", ""unknown"" ]"," ""type"": ""boolean""",6,1
openstack%2Fglance~master~Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4,openstack/glance,master,Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4,Include Metadata Defs Concepts in Dev Docs,MERGED,2014-09-09 21:35:16.000000000,2014-10-07 04:44:52.000000000,2014-10-03 23:39:18.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 8759}, {'_account_id': 8959}]","[{'number': 1, 'created': '2014-09-09 21:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8c5253e8007bddc7d2bcb6056eabbc5b7d36688f', 'message': ""Include Metadata Defs Concepts in Dev Docs\n\nThe http://docs.openstack.org/developer/glance/\nsite currently doesn't include the Juno Metadata\nDefinitions concepts.  This patch adds\nan overview of the concepts to this site.\n\nOther patches will update the API and install.\nCloses-bug: 1367432\n\nChange-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4\n""}, {'number': 2, 'created': '2014-09-10 04:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ebd60cdc930a9cdbf42a88c7285fa3cb3aeaf9f9', 'message': ""Include Metadata Defs Concepts in Dev Docs\n\nThe http://docs.openstack.org/developer/glance/\nsite currently doesn't include the Juno Metadata\nDefinitions concepts.  This patch adds\nan overview of the concepts to this site.\n\nOther patches will update the API and install.\nCloses-bug: 1367432\n\nChange-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4\n""}, {'number': 3, 'created': '2014-09-11 16:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/aefbc6d0e6a2b7e6860a01b473b2dc17456c916f', 'message': ""Include Metadata Defs Concepts in Dev Docs\n\nThe http://docs.openstack.org/developer/glance/\nsite currently doesn't include the Juno Metadata\nDefinitions concepts.  This patch adds\nan overview of the concepts to this site.\n\nOther patches will update the API and install.\nCloses-bug: 1367432\n\nChange-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4\n""}, {'number': 4, 'created': '2014-09-29 21:49:43.000000000', 'files': ['doc/source/index.rst', 'doc/source/metadefs-concepts.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/0aab5e271667990afb1a2522c7c9c61fa7211e0b', 'message': ""Include Metadata Defs Concepts in Dev Docs\n\nThe http://docs.openstack.org/developer/glance/\nsite currently doesn't include the Juno Metadata\nDefinitions concepts.  This patch adds\nan overview of the concepts to this site.\n\nThis provides a synopis of the concepts in:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nDocImpact\nCloses-Bug: 1367432\nRelated-Bug: 1367908\nRelated-Bug: 1363615\nRelated-Bug: 1366286\nRelated-Bug: 1363383\nChange-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4\n""}]",12,120246,0aab5e271667990afb1a2522c7c9c61fa7211e0b,40,9,4,7665,,,0,"Include Metadata Defs Concepts in Dev Docs

The http://docs.openstack.org/developer/glance/
site currently doesn't include the Juno Metadata
Definitions concepts.  This patch adds
an overview of the concepts to this site.

This provides a synopis of the concepts in:
https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst

DocImpact
Closes-Bug: 1367432
Related-Bug: 1367908
Related-Bug: 1363615
Related-Bug: 1366286
Related-Bug: 1363383
Change-Id: Iad4d388cbbf2f63fa243d04d35032de0cb0bc1b4
",git fetch https://review.opendev.org/openstack/glance refs/changes/46/120246/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/metadefs-concepts.rst', 'doc/source/images/metadefs-concepts.png']",3,8c5253e8007bddc7d2bcb6056eabbc5b7d36688f,bug/1367432,,,148,1
openstack%2Fglance~master~Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602,openstack/glance,master,Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602,Nova instance config drive Metadata Definition,MERGED,2014-09-11 01:08:13.000000000,2014-10-07 04:42:48.000000000,2014-10-07 03:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 8959}]","[{'number': 1, 'created': '2014-09-11 01:08:13.000000000', 'files': ['etc/metadefs/compute-instance-data.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/0dd620c7bd7f07935e1cea5d0bfab2a41f754d1b', 'message': 'Nova instance config drive Metadata Definition\n\nA nova Juno FFE landed to support setting the\nimg_config_drive property on images to require images\nto be booted with a config drive. The Glance Metadata\nDefinitions should include this property.\n\nSee Nova Blueprint:\nhttps://blueprints.launchpad.net/nova/+spec/config-drive-image-property\n\nChange-Id: Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602\nCloses-bug: 1367981\n'}]",0,120665,0dd620c7bd7f07935e1cea5d0bfab2a41f754d1b,12,6,1,7665,,,0,"Nova instance config drive Metadata Definition

A nova Juno FFE landed to support setting the
img_config_drive property on images to require images
to be booted with a config drive. The Glance Metadata
Definitions should include this property.

See Nova Blueprint:
https://blueprints.launchpad.net/nova/+spec/config-drive-image-property

Change-Id: Iffc4d4f00f3677ed1fa41233ef6cfbc5c46d8602
Closes-bug: 1367981
",git fetch https://review.opendev.org/openstack/glance refs/changes/65/120665/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/metadefs/compute-instance-data.json'],1,0dd620c7bd7f07935e1cea5d0bfab2a41f754d1b,bug/1367981,"{ ""namespace"": ""OS::Compute::InstanceData"", ""display_name"": ""Instance Config Data"", ""description"": ""Instances can perform self-configuration based on data made available to the running instance. These properties affect instance configuration."", ""visibility"": ""public"", ""protected"": true, ""resource_type_associations"": [ { ""name"": ""OS::Glance::Image"" }, { ""name"": ""OS::Cinder::Volume"", ""properties_target"": ""image"" } ], ""properties"": { ""img_config_drive"": { ""title"": ""Config Drive"", ""description"": ""Set this property on images to mandatory to require Nova to use a config drive when booting the image. OpenStack can be configured to write metadata to a special configuration drive that will be attached to the instance when it boots. The instance can retrieve any information from the config drive. One use case for the config drive is to pass network configuration information to the instance. See also: http://docs.openstack.org/user-guide/content/config-drive.html"", ""type"": ""string"", ""enum"": [ ""optional"", ""mandatory"" ] } } } ",,27,0
openstack%2Fglance~master~Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6,openstack/glance,master,Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6,Add missing metadefs for Aggregate Filters,MERGED,2014-09-11 05:27:16.000000000,2014-10-07 04:41:34.000000000,2014-10-07 03:51:46.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-09-11 05:27:16.000000000', 'files': ['etc/metadefs/compute-aggr-disk-filter.json', 'etc/metadefs/compute-aggr-num-instances.json', 'etc/metadefs/compute-aggr-iops-filter.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/313d4f272cbeabfdcb39de4bcb441749f56fb4d4', 'message': 'Add missing metadefs for Aggregate Filters\n\nThe below spec implemented in Juno added numerous properties\nthat can be added to Host Aggregates. The Metadata\nDefinitions catalog should include them.\n\nhttps://github.com/openstack/nova-specs/blob/master/specs/juno/per-aggregate-filters.rst\n\nChange-Id: Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6\nCloses-bug: 1368032\n'}]",0,120688,313d4f272cbeabfdcb39de4bcb441749f56fb4d4,12,6,1,7665,,,0,"Add missing metadefs for Aggregate Filters

The below spec implemented in Juno added numerous properties
that can be added to Host Aggregates. The Metadata
Definitions catalog should include them.

https://github.com/openstack/nova-specs/blob/master/specs/juno/per-aggregate-filters.rst

Change-Id: Id37028b4b24ab5f6b0c4547a3c1af47bd76e61f6
Closes-bug: 1368032
",git fetch https://review.opendev.org/openstack/glance refs/changes/88/120688/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/metadefs/compute-aggr-disk-filter.json', 'etc/metadefs/compute-aggr-num-instances.json', 'etc/metadefs/compute-aggr-iops-filter.json']",3,313d4f272cbeabfdcb39de4bcb441749f56fb4d4,bug/1368032,"{ ""namespace"": ""OS::Compute::AggregateIoOpsFilter"", ""display_name"": ""IO Ops per Host"", ""description"": ""Properties related to the Nova scheduler filter AggregateIoOpsFilter. Filters aggregate hosts based on the number of instances currently changing state. Hosts in the aggregate with too many instances changing state will be filtered out. The filter must be enabled in the Nova scheduler to use these properties."", ""visibility"": ""public"", ""protected"": true, ""resource_type_associations"": [ { ""name"": ""OS::Nova::Aggregate"" } ], ""properties"": { ""max_io_ops_per_host"": { ""title"": ""Maximum IO Operations per Host"", ""description"": ""Prevents hosts in the aggregate that have this many or more instances currently in build, resize, snapshot, migrate, rescue or unshelve to be scheduled for new instances."", ""type"": ""integer"", ""readonly"": false, ""default"": 8, ""minimum"": 1 } }, ""objects"": [] } ",,65,0
openstack%2Fheat~master~Ic890faa48ef0e1139a45f6fe8d4e44ef5faa4441,openstack/heat,master,Ic890faa48ef0e1139a45f6fe8d4e44ef5faa4441,Write conf file containing integration test creds,ABANDONED,2014-10-06 22:49:52.000000000,2014-10-07 04:40:03.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-06 22:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6cb4b8ca58ba39e864cc54fb5b5aa3447a743283', 'message': 'Write conf file containing integration test creds\n\nRather than relying on sourced credentials, write out a configuration\nfile containing the credentials to be used for running the integration\ntests.\n\nChange-Id: Ic890faa48ef0e1139a45f6fe8d4e44ef5faa4441\n'}, {'number': 2, 'created': '2014-10-06 23:10:01.000000000', 'files': ['heat_integrationtests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/4bcf4892584bdbd54459b36926c94d47b3514c63', 'message': 'Write conf file containing integration test creds\n\nRather than relying on sourced credentials, write out a configuration\nfile containing the credentials to be used for running the integration\ntests.\n\nChange-Id: Ic890faa48ef0e1139a45f6fe8d4e44ef5faa4441\n'}]",0,126426,4bcf4892584bdbd54459b36926c94d47b3514c63,6,1,2,4571,,,0,"Write conf file containing integration test creds

Rather than relying on sourced credentials, write out a configuration
file containing the credentials to be used for running the integration
tests.

Change-Id: Ic890faa48ef0e1139a45f6fe8d4e44ef5faa4441
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/126426/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/post_test_hook.sh'],1,6cb4b8ca58ba39e864cc54fb5b5aa3447a743283,bp/functional-tests, # write out configuration containing test credentials source /opt/stack/new/devstack/accrc/demo/demo PYTHONPATH=. python -m heat_integrationtests.common.config \ heat_integrationtests/common/config.py \ > heat_integrationtests/heat_integrationtests.conf ,source /opt/stack/new/devstack/accrc/demo/demo,7,1
openstack%2Fceilometer~master~I6b23531daa8541b073d27ea4efcac16af3d6a106,openstack/ceilometer,master,I6b23531daa8541b073d27ea4efcac16af3d6a106,Provide __repr__ for SampleFilter,MERGED,2014-09-13 13:58:26.000000000,2014-10-07 04:26:58.000000000,2014-10-07 04:26:57.000000000,"[{'_account_id': 3}, {'_account_id': 144}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8052}]","[{'number': 1, 'created': '2014-09-13 13:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/db46453548de0380c26b879efd3f638d1e9dd247', 'message': 'Provide __repr__ for SampleFilter\n\nIt is convenient for logging to be able to print it\n\nChange-Id: I6b23531daa8541b073d27ea4efcac16af3d6a106\n'}, {'number': 2, 'created': '2014-09-14 23:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4cb358a9d4a3fcd9a3ce27cf8522ac6ad915f2a2', 'message': 'Provide __repr__ for SampleFilter\n\nThis is convenient for logging\n\nChange-Id: I6b23531daa8541b073d27ea4efcac16af3d6a106\n'}, {'number': 3, 'created': '2014-09-16 13:51:08.000000000', 'files': ['ceilometer/storage/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/56d9d661b64e36f278a9ecf302acc9b10ae00235', 'message': 'Provide __repr__ for SampleFilter\n\nImplement __repr__ for SamplerFilter, so that when we log it we get a more\nuseful representation printed to the screen, without having to log each\nindividual field.\n\nChange-Id: I6b23531daa8541b073d27ea4efcac16af3d6a106\n'}]",1,121354,56d9d661b64e36f278a9ecf302acc9b10ae00235,27,11,3,144,,,0,"Provide __repr__ for SampleFilter

Implement __repr__ for SamplerFilter, so that when we log it we get a more
useful representation printed to the screen, without having to log each
individual field.

Change-Id: I6b23531daa8541b073d27ea4efcac16af3d6a106
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/54/121354/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/__init__.py'],1,db46453548de0380c26b879efd3f638d1e9dd247,samplefilter_repr," def __repr__(self): return (""<SampleFilter(user: %s,"" "" project: %s,"" "" start: %s,"" "" start_timestamp_op: %s,"" "" end: %s,"" "" end_timestamp_op: %s,"" "" resource: %s,"" "" meter: %s,"" "" source: %s,"" "" metaquery: %s,"" "" message_id: %s)>"" % (self.user, self.project, self.start, self.start_timestamp_op, self.end, self.end_timestamp_op, self.resource, self.meter, self.source, self.metaquery, self.message_id)) ",,24,0
openstack%2Fceilometer~master~I0d6f4203b2b6de1dc22a156aa67526a067e48cbb,openstack/ceilometer,master,I0d6f4203b2b6de1dc22a156aa67526a067e48cbb,Fix help strings,MERGED,2014-09-02 17:48:46.000000000,2014-10-07 04:26:34.000000000,2014-10-07 04:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6547}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 9562}, {'_account_id': 9581}, {'_account_id': 10106}]","[{'number': 1, 'created': '2014-09-02 17:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/42ccd1f9d6a4497e8e6a8a670cd157d432dd756c', 'message': 'Fix help strings\n\nFor consistency, add ""."" at end of help strings, fix grammar and\ncapitalization.\n\nChange-Id: I0d6f4203b2b6de1dc22a156aa67526a067e48cbb\n'}, {'number': 2, 'created': '2014-09-02 17:59:36.000000000', 'files': ['ceilometer/coordination.py', 'ceilometer/hardware/discovery.py', 'ceilometer/collector.py', 'ceilometer/data_processing/notifications.py', 'ceilometer/profiler/notifications.py', 'ceilometer/compute/virt/vmware/inspector.py', 'ceilometer/compute/virt/xenapi/inspector.py', 'ceilometer/api/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fbf14a42bfc3d4b905ccffc6890d0bb86acddb5d', 'message': 'Fix help strings\n\nFor consistency, add ""."" at end of help strings, fix grammar and\ncapitalization. Remove ""(float)"" from heartbeat since the description\nwill include the type.\n\nChange-Id: I0d6f4203b2b6de1dc22a156aa67526a067e48cbb\n'}]",0,118417,fbf14a42bfc3d4b905ccffc6890d0bb86acddb5d,16,9,2,6547,,,0,"Fix help strings

For consistency, add ""."" at end of help strings, fix grammar and
capitalization. Remove ""(float)"" from heartbeat since the description
will include the type.

Change-Id: I0d6f4203b2b6de1dc22a156aa67526a067e48cbb
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/17/118417/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/collector.py', 'ceilometer/hardware/discovery.py', 'ceilometer/compute/virt/vmware/inspector.py', 'ceilometer/compute/virt/xenapi/inspector.py', 'ceilometer/api/__init__.py']",5,42ccd1f9d6a4497e8e6a8a670cd157d432dd756c,fix-help," 'or have a DNS server, otherwise it will delay the ' 'response from the API.')"," 'or have dns server, otherwise it will delay the ' 'response from api.')",15,14
openstack%2Fnova~master~I44902b0402115d1b6e833975e6c2f020ac5ab7c3,openstack/nova,master,I44902b0402115d1b6e833975e6c2f020ac5ab7c3,Port extended_ips/extended_ips_mac extension to V2.1,MERGED,2014-09-12 01:34:02.000000000,2014-10-07 04:26:18.000000000,2014-10-07 04:26:15.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-12 01:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae244760486cca7582d4a70727d7525b3b29c142', 'message': 'Port extended_ips/extended_ips_mac extension to V2.1\n\nThis patch port extended_ips/extended_ips_mac extension to V2.1\n\nThere are difference between V2 and V3 server show/index &\nserver address index API response listed below-\n\n\'address\' field of V2->V3 API response-\n""OS-EXT-IPS:type"" -> ""type""\n""OS-EXT-IPS-MAC:mac_addr"" -> ""mac_addr""\n\nReverting those attribute same as V2 to work with V2.1\n\nChange-Id: I44902b0402115d1b6e833975e6c2f020ac5ab7c3\n'}, {'number': 2, 'created': '2014-09-12 02:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c46cb2eff21c46ea09ce0b12d892d32e3cdf5752', 'message': 'Port extended_ips/extended_ips_mac extension to V2.1\n\nThis patch port extended_ips/extended_ips_mac extension to V2.1\n\nThere are difference between V2 and V3 server show/index &\nserver address index API response listed below-\n\n\'address\' field of V2->V3 API response-\n""OS-EXT-IPS:type"" -> ""type""\n""OS-EXT-IPS-MAC:mac_addr"" -> ""mac_addr""\n\nReverting those attribute same as V2 to work with V2.1\n\nCloses-Bug: #1368495\n\nChange-Id: I44902b0402115d1b6e833975e6c2f020ac5ab7c3\n'}, {'number': 3, 'created': '2014-09-12 04:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b5b3dbd857ee84fc72dded6e14bd033fd6686ad', 'message': 'Port extended_ips/extended_ips_mac extension to V2.1\n\nThis patch port extended_ips/extended_ips_mac extension to V2.1\n\nThere are difference between V2 and V3 server show/index &\nserver address index API response listed below-\n\n\'address\' field of V2->V3 API response-\n""OS-EXT-IPS:type"" -> ""type""\n""OS-EXT-IPS-MAC:mac_addr"" -> ""mac_addr""\n\nReverting those attribute same as V2 to work with V2.1\n\nCloses-Bug: #1368495\n\nChange-Id: I44902b0402115d1b6e833975e6c2f020ac5ab7c3\n'}, {'number': 4, 'created': '2014-09-26 01:04:50.000000000', 'files': ['doc/v3/api_samples/os-config-drive/server-config-drive-get-resp.json', 'doc/v3/api_samples/os-extended-status/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/server-get-resp.json.tpl', 'doc/v3/api_samples/server-ips/server-ips-network-resp.json', 'doc/v3/api_samples/all_extensions/servers-details-resp.json', 'doc/v3/api_samples/server-ips/server-ips-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-action-rebuild-resp.json', 'doc/v3/api_samples/os-extended-availability-zone/server-get-resp.json', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'doc/v3/api_samples/os-server-usage/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/all_extensions/server-get-resp.json.tpl', 'doc/v3/api_samples/servers/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/servers/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/server-ips/server-ips-resp.json.tpl', 'doc/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json', 'doc/v3/api_samples/os-server-usage/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/servers-details-resp.json', 'nova/tests/integrated/v3/api_samples/os-pci/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-volumes/servers-detail-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'doc/v3/api_samples/servers/servers-details-resp.json', 'doc/v3/api_samples/os-access-ips/server-put-resp.json', 'nova/tests/integrated/v3/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'doc/v3/api_samples/all_extensions/server-get-resp.json', 'doc/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json', 'doc/v3/api_samples/os-security-groups/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-pci/servers-detail-resp.json.tpl', 'doc/v3/api_samples/os-security-groups/server-get-resp.json', 'doc/v3/api_samples/os-pci/servers-detail-resp.json', 'doc/v3/api_samples/os-extended-server-attributes/server-get-resp.json', 'nova/tests/api/openstack/compute/contrib/test_extended_ips_mac.py', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/api/openstack/compute/contrib/test_extended_ips.py', 'nova/tests/integrated/v3/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-security-groups/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-status/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-preserve-ephemeral-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-put-resp.json.tpl', 'doc/v3/api_samples/servers/server-action-rebuild-resp.json', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-get-resp.json', 'doc/v3/api_samples/os-extended-volumes/server-get-resp.json', 'doc/v3/api_samples/os-pci/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-get-resp.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'doc/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/server-ips/server-ips-network-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/api/openstack/compute/views/addresses.py', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/a5147669f4d584fdbee10b4a2c77b93b31ef3108', 'message': 'Port extended_ips/extended_ips_mac extension to V2.1\n\nThis patch port extended_ips/extended_ips_mac extension to V2.1\n\nThere are difference between V2 and V3 server show/index &\nserver address index API response listed below-\n\n\'address\' field of V2->V3 API response-\n""OS-EXT-IPS:type"" -> ""type""\n""OS-EXT-IPS-MAC:mac_addr"" -> ""mac_addr""\n\nReverting those attribute same as V2 to work with V2.1\n\nCloses-Bug: #1368495\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I44902b0402115d1b6e833975e6c2f020ac5ab7c3\n'}]",0,120961,a5147669f4d584fdbee10b4a2c77b93b31ef3108,26,8,4,8556,,,0,"Port extended_ips/extended_ips_mac extension to V2.1

This patch port extended_ips/extended_ips_mac extension to V2.1

There are difference between V2 and V3 server show/index &
server address index API response listed below-

'address' field of V2->V3 API response-
""OS-EXT-IPS:type"" -> ""type""
""OS-EXT-IPS-MAC:mac_addr"" -> ""mac_addr""

Reverting those attribute same as V2 to work with V2.1

Closes-Bug: #1368495
Partially implements blueprint v2-on-v3-api

Change-Id: I44902b0402115d1b6e833975e6c2f020ac5ab7c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/120961/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/v3/api_samples/os-config-drive/server-config-drive-get-resp.json', 'doc/v3/api_samples/os-extended-status/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/server-get-resp.json.tpl', 'doc/v3/api_samples/server-ips/server-ips-network-resp.json', 'doc/v3/api_samples/all_extensions/servers-details-resp.json', 'doc/v3/api_samples/server-ips/server-ips-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-action-rebuild-resp.json', 'doc/v3/api_samples/os-extended-availability-zone/server-get-resp.json', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'doc/v3/api_samples/os-server-usage/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/all_extensions/server-get-resp.json.tpl', 'doc/v3/api_samples/servers/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/servers/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/server-ips/server-ips-resp.json.tpl', 'doc/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json', 'doc/v3/api_samples/os-server-usage/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/servers-details-resp.json', 'nova/tests/integrated/v3/api_samples/os-pci/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-volumes/servers-detail-resp.json', 'doc/v3/api_samples/servers/servers-details-resp.json', 'doc/v3/api_samples/os-access-ips/server-put-resp.json', 'nova/tests/integrated/v3/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'doc/v3/api_samples/all_extensions/server-get-resp.json', 'doc/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json', 'doc/v3/api_samples/os-security-groups/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-pci/servers-detail-resp.json.tpl', 'doc/v3/api_samples/os-security-groups/server-get-resp.json', 'doc/v3/api_samples/os-pci/servers-detail-resp.json', 'doc/v3/api_samples/os-extended-server-attributes/server-get-resp.json', 'nova/tests/api/openstack/compute/contrib/test_extended_ips_mac.py', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/api/openstack/compute/contrib/test_extended_ips.py', 'nova/tests/integrated/v3/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-security-groups/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-status/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-preserve-ephemeral-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-put-resp.json.tpl', 'doc/v3/api_samples/servers/server-action-rebuild-resp.json', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-get-resp.json', 'doc/v3/api_samples/os-extended-volumes/server-get-resp.json', 'doc/v3/api_samples/os-pci/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-get-resp.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'doc/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/server-ips/server-ips-network-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/api/openstack/compute/views/addresses.py', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-resp.json.tpl']",62,ae244760486cca7582d4a70727d7525b3b29c142,bp/v2-on-v3-api," ""OS-EXT-IPS-MAC:mac_addr"": ""aa:bb:cc:dd:ee:ff"", ""OS-EXT-IPS:type"": ""fixed"""," ""mac_addr"": ""aa:bb:cc:dd:ee:ff"", ""type"": ""fixed""",162,136
openstack%2Fkolla~master~Ic923c6a772f1bdf36b97b05a1d04de9e5b841ddd,openstack/kolla,master,Ic923c6a772f1bdf36b97b05a1d04de9e5b841ddd,added hautoproxy auto-configuring haproxy,MERGED,2014-10-06 17:59:40.000000000,2014-10-07 04:18:27.000000000,2014-10-07 04:18:26.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-10-06 17:59:40.000000000', 'files': ['docker/hautoproxy/start.py', 'docker/hautoproxy/Dockerfile', 'docker/hautoproxy/haproxy.cfg.tmpl', 'docker/hautoproxy/build'], 'web_link': 'https://opendev.org/openstack/kolla/commit/154e2781d9debe5417bdec14689ace88eb4ea3e3', 'message': 'added hautoproxy auto-configuring haproxy\n\nThis image configures haproxy to forward connections for all available\nkubernetes services.  It is meant to be run alongside other contains in\na kubernetes pod to provide access to ""remote"" services at a consistent\naddress so that keystone api endpoints can be configured in a sane\nfashion.\n\nChange-Id: Ic923c6a772f1bdf36b97b05a1d04de9e5b841ddd\n'}]",0,126373,154e2781d9debe5417bdec14689ace88eb4ea3e3,7,3,1,8745,,,0,"added hautoproxy auto-configuring haproxy

This image configures haproxy to forward connections for all available
kubernetes services.  It is meant to be run alongside other contains in
a kubernetes pod to provide access to ""remote"" services at a consistent
address so that keystone api endpoints can be configured in a sane
fashion.

Change-Id: Ic923c6a772f1bdf36b97b05a1d04de9e5b841ddd
",git fetch https://review.opendev.org/openstack/kolla refs/changes/73/126373/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/hautoproxy/start.py', 'docker/hautoproxy/Dockerfile', 'docker/hautoproxy/haproxy.cfg.tmpl', 'docker/hautoproxy/build']",4,154e2781d9debe5417bdec14689ace88eb4ea3e3,larsks/add-hautoproxy,../../tools/build-docker-image,,100,0
openstack%2Fheat~master~Ic9474e329b9cef1e96b693f10c320b612f580283,openstack/heat,master,Ic9474e329b9cef1e96b693f10c320b612f580283,Move test_server_cfn_init from tempest to heat,MERGED,2014-07-29 23:07:18.000000000,2014-10-07 04:11:13.000000000,2014-10-07 04:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-29 23:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89d6f662927719276bcad44beba2076d9d947c9f', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Implement a check_skip method\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 2, 'created': '2014-07-31 00:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aea649d9c547025578ea1a69bcf6cb734d2afbd6', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 3, 'created': '2014-08-04 00:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/237639b4e00c0f33dc59f894a2775035a51f3ae0', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 4, 'created': '2014-08-06 04:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dfa912facfe83e9ae8ac08720ffe9f6b18801bc5', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 5, 'created': '2014-08-06 23:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10af3058361f5bb26cda278a57f7db5d61f9dfc3', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 6, 'created': '2014-08-11 02:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74fc352c81a85b10b88f4d3e2c5935864be4ac0f', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 7, 'created': '2014-08-12 23:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48cea66685dc367b92687ff328feafdc4bb03978', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 8, 'created': '2014-08-13 23:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ad31d777fdc7eae4c54436ff37ca6caa896ab2c1', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 9, 'created': '2014-08-24 22:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2ea74e05f9a27ba1a73c6629d3a3b21d24cc1413', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 10, 'created': '2014-08-24 23:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f06627e2b2269206163325e48066fc1fa34b99d0', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 11, 'created': '2014-08-27 23:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/04b9214f9abcaec40112502c4860f91062033989', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 12, 'created': '2014-08-28 04:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/de06721087f09407a1a9d64b1e834583c8db08f7', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the functional_tests CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 13, 'created': '2014-08-29 03:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d28c892ac184d07550a0221f64dab259f91930a', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 14, 'created': '2014-09-01 23:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4599c21329e783cedabb7ee962e5eda56141294c', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 15, 'created': '2014-09-17 02:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e797e77645bc3387f7d83b190bfd87263a96a01', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 16, 'created': '2014-09-23 21:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/117b5700987a300a69f8d9d53fecf3054371e8b3', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 17, 'created': '2014-10-06 22:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/feac6cafc473ea2906c8385bb9e3b50e025b2630', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 18, 'created': '2014-10-06 23:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c203380d3615bcc7942263adfb0ff59b10fb5645', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}, {'number': 19, 'created': '2014-10-06 23:51:24.000000000', 'files': ['heat_integrationtests/scenario/test_server_cfn_init.py', 'heat_integrationtests/scenario/__init__.py', 'heat_integrationtests/scenario/test_server_cfn_init.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/6a03d60c36f0ca2a5f4c1131d06308c0f1a4f8d9', 'message': 'Move test_server_cfn_init from tempest to heat\n\nThe only changes required to move this test have been:\n* Change the imports\n* Use the DEFAULT CONF group for conf options\n\nChange-Id: Ic9474e329b9cef1e96b693f10c320b612f580283\nPartial-Blueprint: functional-tests\n'}]",0,110497,6a03d60c36f0ca2a5f4c1131d06308c0f1a4f8d9,77,15,19,4571,,,0,"Move test_server_cfn_init from tempest to heat

The only changes required to move this test have been:
* Change the imports
* Use the DEFAULT CONF group for conf options

Change-Id: Ic9474e329b9cef1e96b693f10c320b612f580283
Partial-Blueprint: functional-tests
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/110497/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/functional/test_server_cfn_init.py', 'heat/tests/functional/cfn_init_signal.yaml']",2,89d6f662927719276bcad44beba2076d9d947c9f,bp/functional-tests,"HeatTemplateFormatVersion: '2012-12-12' Description: | Template which uses a wait condition to confirm that a minimal cfn-init and cfn-signal has worked Parameters: key_name: Type: String flavor: Type: String image: Type: String network: Type: String timeout: Type: Number Resources: CfnUser: Type: AWS::IAM::User SmokeSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: Enable only ping and SSH access SecurityGroupIngress: - {CidrIp: 0.0.0.0/0, FromPort: '-1', IpProtocol: icmp, ToPort: '-1'} - {CidrIp: 0.0.0.0/0, FromPort: '22', IpProtocol: tcp, ToPort: '22'} SmokeKeys: Type: AWS::IAM::AccessKey Properties: UserName: {Ref: CfnUser} SmokeServer: Type: OS::Nova::Server Metadata: AWS::CloudFormation::Init: config: files: /tmp/smoke-status: content: smoke test complete /etc/cfn/cfn-credentials: content: Fn::Replace: - SmokeKeys: {Ref: SmokeKeys} SecretAccessKey: 'Fn::GetAtt': [SmokeKeys, SecretAccessKey] - | AWSAccessKeyId=SmokeKeys AWSSecretKey=SecretAccessKey mode: '000400' owner: root group: root Properties: image: {Ref: image} flavor: {Ref: flavor} key_name: {Ref: key_name} security_groups: - {Ref: SmokeSecurityGroup} networks: - uuid: {Ref: network} user_data: Fn::Replace: - WaitHandle: {Ref: WaitHandle} - | #!/bin/bash -v /opt/aws/bin/cfn-init /opt/aws/bin/cfn-signal -e 0 --data ""`cat /tmp/smoke-status`"" \ --id smoke_status ""WaitHandle"" WaitHandle: Type: AWS::CloudFormation::WaitConditionHandle WaitCondition: Type: AWS::CloudFormation::WaitCondition DependsOn: SmokeServer Properties: Handle: {Ref: WaitHandle} Timeout: {Ref: timeout} Outputs: WaitConditionStatus: Description: Contents of /tmp/smoke-status on SmokeServer Value: Fn::GetAtt: [WaitCondition, Data] SmokeServerIp: Description: IP address of server Value: Fn::GetAtt: [SmokeServer, first_address] ",,213,0
openstack%2Fheat~master~Id6c8072c28949e8c25b46d3d24546bd660c77017,openstack/heat,master,Id6c8072c28949e8c25b46d3d24546bd660c77017,Preserve env when calling tox,MERGED,2014-10-06 23:51:24.000000000,2014-10-07 04:11:04.000000000,2014-10-07 04:11:03.000000000,"[{'_account_id': 3}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-10-06 23:51:24.000000000', 'files': ['heat_integrationtests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/c1caf40032cf6fb3bb56bf6b31ec2abea84dcea9', 'message': 'Preserve env when calling tox\n\nThis will run the integration tests with the sourced credentials.\n\nChange-Id: Id6c8072c28949e8c25b46d3d24546bd660c77017\n'}]",0,126439,c1caf40032cf6fb3bb56bf6b31ec2abea84dcea9,7,2,1,4571,,,0,"Preserve env when calling tox

This will run the integration tests with the sourced credentials.

Change-Id: Id6c8072c28949e8c25b46d3d24546bd660c77017
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/126439/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/post_test_hook.sh'],1,c1caf40032cf6fb3bb56bf6b31ec2abea84dcea9,bp/functional-tests,sudo -E tox -eintegration,sudo tox -eintegration,1,1
openstack%2Fsahara~master~I6b9f7d858f0f01e62efae04e11cbf8818ca8df61,openstack/sahara,master,I6b9f7d858f0f01e62efae04e11cbf8818ca8df61,Parallel testing EDP jobs,MERGED,2014-07-31 13:56:32.000000000,2014-10-07 03:52:01.000000000,2014-10-07 03:52:01.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-07-31 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c8bbf50b7656ff049386d6757056cda415b50837', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 2, 'created': '2014-08-01 09:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/87913a9f4c95ee3f96f11bcb9c93c568862f33fb', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 3, 'created': '2014-08-01 13:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dc0cf5f3bac9d8e40eb3de06791251872a6f53d8', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 4, 'created': '2014-08-04 13:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/eadc3f2ca8a51007b09806ff316675275bece489', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 5, 'created': '2014-08-04 13:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0dcba21fa1d02b00ed32a5ba213f0df1687c0d22', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 6, 'created': '2014-08-05 11:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e900152b68ce54dfb91076291126f0035dba69b3', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 7, 'created': '2014-08-06 11:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d1380b742150560fecaf9e45dd429d2ff7a89409', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 8, 'created': '2014-08-06 12:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7895dd17c03c5e9ab2c8a58433486c5d4fdab65a', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 9, 'created': '2014-08-11 11:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fd629e83c641162c7a542f13e6b9c17e6899d079', 'message': '[WIP] Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 10, 'created': '2014-08-13 06:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3cb56ab08f94a28151b704e5f6c8cfca3be93523', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 11, 'created': '2014-08-13 07:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/07eff1bbd615d0e0461b29bd8b9c2a944e01da16', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 12, 'created': '2014-08-13 13:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b6417344572fce8b3d0c7a01a909ad8d431a6190', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 13, 'created': '2014-08-18 11:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d80ac932137fa6b89346b63b12cc3ced19cf7bd8', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 14, 'created': '2014-08-18 14:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b86f7cce2b505f2e246df59f3915e45ce211f849', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 15, 'created': '2014-08-22 10:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4d585f4217fb03e51956aa313b82bbc27ca100db', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 16, 'created': '2014-08-22 11:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e00cf4aadce33ddcfa13ef7f4b9dfaeeb1f65c94', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 17, 'created': '2014-09-09 09:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/67b6df97095570c47c60f11c2dc36ba3684bd79b', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 18, 'created': '2014-09-09 12:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/705770b8d88539425a9f1bf814b9e2f45abe08ce', 'message': 'Parallel testing EDP jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 19, 'created': '2014-10-02 13:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b960126a701e123e993cd52444c7d6abbac28f4f', 'message': 'Parallel testing EDP jobs\n\nimplements bp: parallel-testing-edp-jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}, {'number': 20, 'created': '2014-10-03 06:47:07.000000000', 'files': ['sahara/tests/integration/tests/gating/test_spark_gating.py', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_two_gating.py', 'sahara/tests/integration/tests/gating/test_hdp2_gating.py', 'sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/tests/gating/test_transient_gating.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3686b03da1f0858d6801dbb0cba412286ceb77b4', 'message': 'Parallel testing EDP jobs\n\nimplements bp: parallel-testing-edp-jobs\n\nChange-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61\n'}]",7,110969,3686b03da1f0858d6801dbb0cba412286ceb77b4,262,13,20,7710,,,0,"Parallel testing EDP jobs

implements bp: parallel-testing-edp-jobs

Change-Id: I6b9f7d858f0f01e62efae04e11cbf8818ca8df61
",git fetch https://review.opendev.org/openstack/sahara refs/changes/69/110969/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/integration/tests/edp.py'],1,c8bbf50b7656ff049386d6757056cda415b50837,bp/parallel-testing-edp-jobs," self.addCleanup(self._delete_job, job_execution, job_id, job_binary_list + lib_binary_list, job_binary_internal_list, input_id, output_id) self.addCleanup(self.delete_swift_container, swift, container_name) #self.delete_swift_container(swift, container_name) #self._delete_job( # job_execution, job_id, job_binary_list + lib_binary_list, # job_binary_internal_list, input_id, output_id #) pass"," self.delete_swift_container(swift, container_name) self._delete_job( job_execution, job_id, job_binary_list + lib_binary_list, job_binary_internal_list, input_id, output_id )",11,5
openstack%2Fsahara~master~I3a98549ff8a369ea202095e8070f65483e0bd099,openstack/sahara,master,I3a98549ff8a369ea202095e8070f65483e0bd099,Make versions list sorted for Vanilla and HDP,MERGED,2014-10-06 08:17:07.000000000,2014-10-07 03:51:50.000000000,2014-10-07 03:51:49.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-10-06 08:17:07.000000000', 'files': ['sahara/plugins/hdp/versions/versionhandlerfactory.py', 'sahara/utils/general.py', 'sahara/plugins/vanilla/versionfactory.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9d58c11db84c5edad0526060e9e3b922efb5788b', 'message': 'Make versions list sorted for Vanilla and HDP\n\nRight now the list is not sorted. Probably the versions order in\nthe list is OS dependent. In my case 2.3.0 came before 1.2.1 in UI,\nwhich is not pretty.\n\nThe natural ordering is applied to handle cases like 2.2 < 2.13\n(lexicographical order will return that 2.2 > 2.13)\n\nChange-Id: I3a98549ff8a369ea202095e8070f65483e0bd099\n'}]",0,126233,9d58c11db84c5edad0526060e9e3b922efb5788b,17,9,1,7109,,,0,"Make versions list sorted for Vanilla and HDP

Right now the list is not sorted. Probably the versions order in
the list is OS dependent. In my case 2.3.0 came before 1.2.1 in UI,
which is not pretty.

The natural ordering is applied to handle cases like 2.2 < 2.13
(lexicographical order will return that 2.2 > 2.13)

Change-Id: I3a98549ff8a369ea202095e8070f65483e0bd099
",git fetch https://review.opendev.org/openstack/sahara refs/changes/33/126233/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/hdp/versions/versionhandlerfactory.py', 'sahara/utils/general.py', 'sahara/plugins/vanilla/versionfactory.py']",3,9d58c11db84c5edad0526060e9e3b922efb5788b,,from sahara.utils import general versions = ( versions.sort(key=general.natural_sort_key) VersionFactory.versions = versions , VersionFactory.versions = (,25,5
openstack%2Fheat~master~I9a719031b8966966e2232722013506a8fa104ad5,openstack/heat,master,I9a719031b8966966e2232722013506a8fa104ad5,Provide support status info for OS::Glance::Image,MERGED,2014-10-03 04:46:25.000000000,2014-10-07 03:51:38.000000000,2014-10-07 03:51:37.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7923}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-10-03 04:46:25.000000000', 'files': ['heat/engine/resources/glance_image.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9af1be3297228939783a4908abff21f80b5f0e38', 'message': 'Provide support status info for OS::Glance::Image\n\nChange-Id: I9a719031b8966966e2232722013506a8fa104ad5\n'}]",0,125874,9af1be3297228939783a4908abff21f80b5f0e38,10,5,1,7923,,,0,"Provide support status info for OS::Glance::Image

Change-Id: I9a719031b8966966e2232722013506a8fa104ad5
",git fetch https://review.opendev.org/openstack/heat refs/changes/74/125874/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/glance_image.py'],1,9af1be3297228939783a4908abff21f80b5f0e38,glance-image-juno,from heat.engine import support support_status = support.SupportStatus(version='2014.2') ,,3,0
openstack%2Fheat~master~I3bd4a78c812d79f4d1d9b7118495db49b72ae7eb,openstack/heat,master,I3bd4a78c812d79f4d1d9b7118495db49b72ae7eb,update docs to use correct stack list command,MERGED,2014-10-03 22:14:12.000000000,2014-10-07 03:51:29.000000000,2014-10-07 03:51:28.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8328}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-10-03 22:14:12.000000000', 'files': ['doc/source/getting_started/standalone.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/814c5e5dd2531f442aecfed2e19e30ccdc6ea7ae', 'message': 'update docs to use correct stack list command\n\nChange-Id: I3bd4a78c812d79f4d1d9b7118495db49b72ae7eb\n'}]",0,126088,814c5e5dd2531f442aecfed2e19e30ccdc6ea7ae,10,5,1,10816,,,0,"update docs to use correct stack list command

Change-Id: I3bd4a78c812d79f4d1d9b7118495db49b72ae7eb
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/126088/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/getting_started/standalone.rst'],1,814c5e5dd2531f442aecfed2e19e30ccdc6ea7ae,stack-list-doc-fix, heat stack-list, heat list,1,1
openstack%2Fdevstack~master~I25557cb2b0a1384ee11d3e1ae7d424828e766e50,openstack/devstack,master,I25557cb2b0a1384ee11d3e1ae7d424828e766e50,Add Nova v2.1 API endpoint,MERGED,2014-09-19 02:05:53.000000000,2014-10-07 03:51:06.000000000,2014-10-07 03:51:05.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1501}, {'_account_id': 2903}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 11080}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-09-19 02:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/76fbdeb2da73c0bdc21228d10b43ad91c0d91311', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}, {'number': 2, 'created': '2014-09-19 02:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/701996419247b740385afcef79563d9625aeab5c', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}, {'number': 3, 'created': '2014-09-22 00:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c0565ae5f55f27d1478ba6c443c62be297979645', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\nIn addition, this patch removes Nova v3 API endpoint because the API\nhas disappeared in Juno cycle.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}, {'number': 4, 'created': '2014-09-25 00:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0c476ebd13aa439aebadf4cea8071364846861bc', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}, {'number': 5, 'created': '2014-09-25 00:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d1b4b5c78d9146932f2cdf7228fdbe02cf7e0c03', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}, {'number': 6, 'created': '2014-09-25 02:10:24.000000000', 'files': ['files/default_catalog.templates', 'lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3feaa383ce07c1cf0f5c8760e326aab96b55ddbf', 'message': 'Add Nova v2.1 API endpoint\n\nIn Juno cycle, we started to implement Nova v2.1 API and most part\nhas been implemented now.\nFor using/testing the API, this patch adds the endpoint setting to\ndevstack.\n\nChange-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50\n'}]",0,122590,3feaa383ce07c1cf0f5c8760e326aab96b55ddbf,44,14,6,6167,,,0,"Add Nova v2.1 API endpoint

In Juno cycle, we started to implement Nova v2.1 API and most part
has been implemented now.
For using/testing the API, this patch adds the endpoint setting to
devstack.

Change-Id: I25557cb2b0a1384ee11d3e1ae7d424828e766e50
",git fetch https://review.opendev.org/openstack/devstack refs/changes/90/122590/6 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,76fbdeb2da73c0bdc21228d10b43ad91c0d91311,add-nova-v2.1-api," local nova_v21_service=$(get_or_create_service ""novav21"" \ ""computev21"" ""Nova Compute Service V2.1"") get_or_create_endpoint $nova_v21_service \ ""$REGION_NAME"" \ ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v2.1/\$(tenant_id)s"" \ ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v2.1/\$(tenant_id)s"" \ ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v2.1/\$(tenant_id)s"" ",,8,0
openstack%2Fdevstack~master~I5027cfad07af0de7ff39f424601d6f7ec5dcadae,openstack/devstack,master,I5027cfad07af0de7ff39f424601d6f7ec5dcadae,Source functions from stackrc,MERGED,2014-10-03 20:28:57.000000000,2014-10-07 03:43:01.000000000,2014-10-04 19:57:36.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5805}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 20:28:57.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0e4cd038287bcf36ff31c4e7b22266051198b44c', 'message': 'Source functions from stackrc\n\nstackrc now requires GITREPO, GITBRANCH, GITDIR and has been\ndependent on functions for a while (is_package_installed).  Ensure\nwe source the required functions file when stackrc is loaded.  Avoids\nunexpected issues in grenade where they may or may not have been loaded\ndepending on the configuration.\n\nCloses-bug: #1377274\n\nChange-Id: I5027cfad07af0de7ff39f424601d6f7ec5dcadae\n'}]",0,126059,0e4cd038287bcf36ff31c4e7b22266051198b44c,10,6,1,1420,,,0,"Source functions from stackrc

stackrc now requires GITREPO, GITBRANCH, GITDIR and has been
dependent on functions for a while (is_package_installed).  Ensure
we source the required functions file when stackrc is loaded.  Avoids
unexpected issues in grenade where they may or may not have been loaded
depending on the configuration.

Closes-bug: #1377274

Change-Id: I5027cfad07af0de7ff39f424601d6f7ec5dcadae
",git fetch https://review.opendev.org/openstack/devstack refs/changes/59/126059/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,0e4cd038287bcf36ff31c4e7b22266051198b44c,source_functions_stackrc,# Source required devstack functions and globals source $RC_DIR/functions ,,3,0
openstack%2Fnova-specs~master~Ib8b259f69c9072520acecba167b7b31707bcadaa,openstack/nova-specs,master,Ib8b259f69c9072520acecba167b7b31707bcadaa,Add v2-on-v3-api spec,MERGED,2014-10-07 00:50:36.000000000,2014-10-07 03:18:01.000000000,2014-10-07 01:26:36.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-10-07 00:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/112ff2ea9765f45b2ca72245eff2911aa09239e8', 'message': 'Add v2-on-v3-api spec\n\nPreviously-approved: juno\nPart of blueprint v2-on-v3-api\n\nChange-Id: Ib8b259f69c9072520acecba167b7b31707bcadaa\n'}, {'number': 2, 'created': '2014-10-07 00:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/05a05c4da599aafebad0bf2b61c1f6166602d29f', 'message': 'Add v2-on-v3-api spec\n\nPreviously-approved: juno\nPart of blueprint v2-on-v3-api\n\nChange-Id: Ib8b259f69c9072520acecba167b7b31707bcadaa\n'}, {'number': 3, 'created': '2014-10-07 01:04:14.000000000', 'files': ['doc/source/index.rst', 'specs/kilo/approved/v2-on-v3-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5f452082f9fe4a265a99b87c03374d7f505b4ea9', 'message': 'Add v2-on-v3-api spec\n\nNote that this change includes an addition to the doc\nindex which is needed to bootstrap the approved directory\nfor Kilo. Without the change a sphinx warning about\nthe new spec rst file not being included anywhere causes the\nbuild to fail. And applying the change with an empty approved\ndirectory the pattern match fails and the build fails\n\nPreviously-approved: juno\nPart of blueprint v2-on-v3-api\n\nChange-Id: Ib8b259f69c9072520acecba167b7b31707bcadaa\n'}]",0,126452,5f452082f9fe4a265a99b87c03374d7f505b4ea9,12,4,3,5292,,,0,"Add v2-on-v3-api spec

Note that this change includes an addition to the doc
index which is needed to bootstrap the approved directory
for Kilo. Without the change a sphinx warning about
the new spec rst file not being included anywhere causes the
build to fail. And applying the change with an empty approved
directory the pattern match fails and the build fails

Previously-approved: juno
Part of blueprint v2-on-v3-api

Change-Id: Ib8b259f69c9072520acecba167b7b31707bcadaa
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/52/126452/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/approved/v2-on-v3-api.rst', 'specs/kilo/approved/v2-on-v3-api.rst~']",2,112ff2ea9765f45b2ca72245eff2911aa09239e8,bp/v2-on-v3-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Implement the v2.1 API on the V3 API codebase ============================================= https://blueprints.launchpad.net/nova/+spec/v2-on-v3-api Implement v2 compatible API based on v3 API infrastructure. Problem description =================== On v3 API development, we have improved API infrastructure such as API plugin loading, input validation, policy check, etc. In addition, to fix inconsistent interfaces of v2 API, we have made a significant number of backwards incompatible changes of the Nova API (Change success status codes, API attribute names, and API URLs). There is a comprehensive description of the problems with the v2 API for users, operators and developers here: http://ozlabs.org/~cyeoh/V3_API.html However, there have been intensive discussions over the future of Nova and the maintenance overhead implications from having to support two APIs such as v2 and v3 simultaneously for a long period of time. Proposed change =============== Through a lot of discussions, we have understood the advantages of v3 API infrastructure (API plugin loading, input validation, policy check, etc). However, their backwards incompatible interfaces seem a little premature at this time, because now we aren't sure that current v3 API is the best. That means we cannot be sure that any more backwards incompatible changes are unnecessary even if switching to current v3 API. This spec proposes the removal of backwards incompatible changes from v3 code. That means current v3 consistent interfaces would go back to v2 inconsistent ones like:: --- a/nova/api/openstack/compute/plugins/v3/servers.py +++ b/nova/api/openstack/compute/plugins/v3/servers.py @@ -752,7 +752,7 @@ class ServersController(wsgi.Controller): The field image_ref is mandatory when no block devices have been defined and must be a proper uuid when present. """""" - image_href = server_dict.get('image_ref') + image_href = server_dict.get('imageRef') This proposal is painful for v3 API developers because they have worked hard to make consistent interfaces over a year and v3 interfaces are exactly better than v2 ones. However, through the discussions, we have known that backwards incompatible changes are very painful for users and we must pay attention to these changes. On this spec, we would provide v2 compatible API with the other v3 advantages as the first step. After this spec, we will provide consistent interfaces by defining API rules step by step. These rules will prevent the same backwards incompatible changes and keep consistent interfaces even if adding a lot of new APIs in the future. However, that is out of scope from this spec now. It is also agreed that we wont implement proxies for other OpenStack APIs such as glance, cinder or neutron as part of the initial v2.1 implementation. These will instead be added later, but before the removal of the original v2 code. Alternatives ------------ Through these discussions, we got an idea that we could support both v2 API and v3 API on the top of the v3 API codebase. On this idea, nova translates a v2 request to v3 request and passes it to v3 API method. After v3 API method operation, nova translates its v3 response to v2 response again and returns it to a client. However, there was an intensive discussion against this idea also because it would be difficult to debug API problems due to many translations when we have a lot of backwards incompatible changes in the long term. Data model impact ----------------- None REST API impact --------------- The V2.1 REST API presented will be identical to the V2 API except as noted above. Note however that V2.1 will not support the XML version of the V2 API, only the JSON one. However the XML version of the V2 API is currently marked as deprecated. Security impact --------------- Better up front input validation will reduce the ability for malicious user input to exploit security bugs. Notifications impact -------------------- None Other end user impact --------------------- Potentially it may be advantageous if python novaclient could talk to /v2.1 instead of /v2 but code changes may not be required to change this. It may be simpler just to do this through keystone configuration. The API itself remains identical. Performance Impact ------------------ More stringent input validation also means more work that is needed to be done in the API layer but overall this is a good thing. Other deployer impact --------------------- If the deployer wanted to export the API as /v2 rather than /v2.1 then they would need to modify the api-paste.ini file (a couple of line change to disable the original V2 API and use the APIRouterV21 as the /v2 API. The long term goal would be to deprecate and eventually remove the original V2 API code when deployers and users are satisfied that v2.1 satisfies their requirements. The process which we would use is: * V2.1 fully implemented with Tempest verification (including extra verification that is being added in terms of response data) * Verification from multiple sources (cloud providers, users etc) that V2.1 is compatible with V2 * This could be done in various ways * Keystone changes so /v2.1 is advertised instead of /v2 * Exporting the V2.1 as /v2 * Combined with the possibility of putting V2.1 input validation into a log rather than reject mode. * V2.1 is in an openstack release for N versions * After widespread confirmation that the V2.1 API is compatible, V2 would be marked as deprecated Developer impact ---------------- Long term advantages for developers are: * All the API implementations are on the new API framework * Reduction in maintenance overhead of supporting two major API versions * Have a better framework for handling future backwards incompatible changes. In the short term while the old V2 API code exists there will still be a dual maintenance overhead. Implementation ============== Assignee(s) ----------- Primary assignee: cyeoh-0 Other contributors: oomichi Alex Xu Work Items ---------- * Change v3 success status codes to v2 ones. * Change v3 API routings to v2 ones. * Handle API URLs include a project id. * Change the API resource paths. (e.g: /keypairs(v3) -> /os-keypairs(v2)) * Change action names. (e.g: migrate_live(v3) -> os-migrateLive(v2)) * Change v3 API attribute names to v2 ones. * Change the API parsers of v3 code. * Change the API schemas of input validation. * Change v3 API behaviors to v2 ones. On some APIs, there are different behaviors. For example, v3 ""create a private flavor"" API adds a flavor access for its own project automatically, but v2 one doesn't. The following work item is not mandatory and it is one of wishlist. * Change v3 plugin code path. e.g:: nova/api/openstack/compute/plugins/v3/servers.py -> nova/api/openstack/compute/plugins/servers.py Dependencies ============ None Testing ======= Tempest has already contained a lot of v2 API tests, and that is a good test coverage now. For this v2.1 API, we need to run v2 API tests for both current v2 and v2.1 in parallel. As an idea, we will add v2.1 API tests by inheriting from the existing v2 API test classes and executing them against /v2.1. A spec for this idea has been already proposed: https://review.openstack.org/#/c/96661/ Documentation Impact ==================== The documentation for the v2 API will essentially remain the same as the API will not change except for improvements in input validation. There will need to be some updates on possible error status codes. Longer term the improved infrastructure for input validation and the development of JSON schema for response validation will make it much easier to automate the generation of documentation for v2 rather relying on the current mostly manual process. References ========== * Juno Mid-Cycle meetup https://etherpad.openstack.org/p/juno-nova-mid-cycle-meetup * Juno design summit discussion https://etherpad.openstack.org/p/juno-nova-v2-on-v3-api-poc * Mailing list discussions about the Nova V3 API and the maintenance overhead * http://lists.openstack.org/pipermail/openstack-dev/2014-March/028724.html * http://lists.openstack.org/pipermail/openstack-dev/2014-February/027896.html * Etherpad page which discusses the V2 on V3 Proof of Concept and keeps track of the ongoing work. * https://etherpad.openstack.org/p/NovaV2OnV3POC * Document about the problems with the V2 API * http://ozlabs.org/~cyeoh/V3_API.html * Document describing the current differences between the V2 and V3 API * https://wiki.openstack.org/wiki/NovaAPIv2tov3 ",,539,0
openstack%2Fneutron~master~If4e77c445e9b855ff77deea6c8df4a0b3cf249d4,openstack/neutron,master,If4e77c445e9b855ff77deea6c8df4a0b3cf249d4,Allow reading a tenant router's external IP,MERGED,2014-09-23 15:35:05.000000000,2014-10-07 02:33:46.000000000,2014-10-07 02:33:45.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2031}, {'_account_id': 4149}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 11825}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-23 15:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b69badb0c52cc711cb6cd83f465d69e4964c1871', 'message': ""Allow reading a tenant router's external IP\n\nAdds an external IPs field to the external gateway information\nfor a router so the external IP address of the router can be\nread by the tenant.\n\nDocImpact\n\nCloses-Bug: #1255142\nChange-Id: If4e77c445e9b855ff77deea6c8df4a0b3cf249d4\n""}, {'number': 2, 'created': '2014-09-23 15:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f4b11b5b7f5aa766875ce677c9a4a778e2c5e53', 'message': ""Allow reading a tenant router's external IP\n\nAdds an external IPs field to the external gateway information\nfor a router so the external IP address of the router can be\nread by the tenant.\n\nDocImpact\n\nCloses-Bug: #1255142\nChange-Id: If4e77c445e9b855ff77deea6c8df4a0b3cf249d4\n""}, {'number': 3, 'created': '2014-10-01 23:59:26.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_gwmode_db.py', 'neutron/extensions/l3.py', 'neutron/extensions/l3_ext_gw_mode.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7baaa068ed1d3c8b02717232edef60ba1b655f6', 'message': ""Allow reading a tenant router's external IP\n\nAdds an external IPs field to the external gateway information\nfor a router so the external IP address of the router can be\nread by the tenant.\n\nDocImpact\n\nCloses-Bug: #1255142\nChange-Id: If4e77c445e9b855ff77deea6c8df4a0b3cf249d4\n""}]",6,123483,c7baaa068ed1d3c8b02717232edef60ba1b655f6,91,37,3,7787,,,0,"Allow reading a tenant router's external IP

Adds an external IPs field to the external gateway information
for a router so the external IP address of the router can be
read by the tenant.

DocImpact

Closes-Bug: #1255142
Change-Id: If4e77c445e9b855ff77deea6c8df4a0b3cf249d4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/123483/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_gwmode_db.py', 'neutron/extensions/l3.py', 'neutron/extensions/l3_ext_gw_mode.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/db/l3_db.py', 'etc/policy.json']",7,b69badb0c52cc711cb6cd83f465d69e4964c1871,bug/1255142," ""create_router:external_gateway_info:external_fixed_ips"": ""rule:admin_only"", ""update_router:external_gateway_info:external_fixed_ips"": ""rule:admin_only"", ",,54,9
openstack%2Fneutron~master~I589cdda0674fdf8fa20d92c2609e1ba6966125d8,openstack/neutron,master,I589cdda0674fdf8fa20d92c2609e1ba6966125d8,Fix setup of Neutron core plugin in VPNaaS UT,MERGED,2014-10-03 06:10:23.000000000,2014-10-07 02:29:26.000000000,2014-10-07 02:29:24.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-03 06:10:23.000000000', 'files': ['neutron/tests/unit/db/vpn/test_db_vpnaas.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/623aa30b33692f8b1d1d12859281d23163829835', 'message': 'Fix setup of Neutron core plugin in VPNaaS UT\n\nOne of the VPNaaS unit test setup routines creates\nand extension manager but passes it a class but it\nshould be passing an instance of that class.\n\nChange-Id: I589cdda0674fdf8fa20d92c2609e1ba6966125d8\n'}]",5,125882,623aa30b33692f8b1d1d12859281d23163829835,35,21,1,7787,,,0,"Fix setup of Neutron core plugin in VPNaaS UT

One of the VPNaaS unit test setup routines creates
and extension manager but passes it a class but it
should be passing an instance of that class.

Change-Id: I589cdda0674fdf8fa20d92c2609e1ba6966125d8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/125882/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/db/vpn/test_db_vpnaas.py'],1,623aa30b33692f8b1d1d12859281d23163829835,forgot_to_construct, self.core_plugin = TestVpnCorePlugin(), self.core_plugin = TestVpnCorePlugin,1,1
openstack%2Fopenstacksdk~master~I74eb27fcfd6553fc1ae68f9b3be155f77966d283,openstack/openstacksdk,master,I74eb27fcfd6553fc1ae68f9b3be155f77966d283,compute/v2 limits_absolute resource,MERGED,2014-08-26 15:58:38.000000000,2014-10-07 01:29:59.000000000,2014-10-07 01:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-26 15:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4f65a78fe8ef34d9f6da73bb0152810dbf10af55', 'message': 'compute/v2 limits_absolute resource\n\nChange-Id: I74eb27fcfd6553fc1ae68f9b3be155f77966d283\n'}, {'number': 2, 'created': '2014-10-02 20:28:23.000000000', 'files': ['openstack/tests/compute/v2/test_limits_absolute.py', 'openstack/compute/v2/limits_absolute.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/747c18c1463b62293e23b0265e5be4aacc8f6cf1', 'message': 'compute/v2 limits_absolute resource\n\nChange-Id: I74eb27fcfd6553fc1ae68f9b3be155f77966d283\n'}]",3,116932,747c18c1463b62293e23b0265e5be4aacc8f6cf1,11,3,2,8736,,,0,"compute/v2 limits_absolute resource

Change-Id: I74eb27fcfd6553fc1ae68f9b3be155f77966d283
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/32/116932/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/compute/v2/test_limits_absolute.py', 'openstack/compute/v2/limits_absolute.py']",2,4f65a78fe8ef34d9f6da73bb0152810dbf10af55,limits_absolute,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six from openstack.compute import compute_service from openstack import resource class LimitsAbsolute(resource.Resource): resource_key = 'limits_absolute' resources_key = 'limits_absolutes' base_path = '/limits' service = compute_service.ComputeService() # capabilities allow_list = True # Properties name = resource.prop('name') value = resource.prop('value') @classmethod def list(cls, session, path_args=None, **params): url = cls.base_path resp = session.get(url, service=cls.service, params=params).body resp = resp['limits']['absolute'] return [cls.existing(name=key, value=value) for key, value in six.iteritems(resp)] ",,117,0
openstack%2Fhorizon~master~If2f762fe665b9a88153a77a658f52bcd56185c53,openstack/horizon,master,If2f762fe665b9a88153a77a658f52bcd56185c53,Warn OPENSTACK_QUANTUM_NETWORK setting as deprecated,MERGED,2014-10-04 18:54:51.000000000,2014-10-07 01:27:28.000000000,2014-10-07 01:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 9981}, {'_account_id': 11880}, {'_account_id': 13161}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-10-04 18:54:51.000000000', 'files': ['openstack_dashboard/api/neutron.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/530e5fee789ce5ed19d90a6b4901f01e8efde5ff', 'message': 'Warn OPENSTACK_QUANTUM_NETWORK setting as deprecated\n\nChange-Id: If2f762fe665b9a88153a77a658f52bcd56185c53\nCloses-Bug: #1377498\n'}]",0,126164,530e5fee789ce5ed19d90a6b4901f01e8efde5ff,11,7,1,841,,,0,"Warn OPENSTACK_QUANTUM_NETWORK setting as deprecated

Change-Id: If2f762fe665b9a88153a77a658f52bcd56185c53
Closes-Bug: #1377498
",git fetch https://review.opendev.org/openstack/horizon refs/changes/64/126164/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/neutron.py'],1,530e5fee789ce5ed19d90a6b4901f01e8efde5ff,bug/1377498,"import warnings if hasattr(settings, 'OPENSTACK_QUANTUM_NETWORK'): warnings.warn( 'OPENSTACK_QUANTUM_NETWORK setting is deprecated and will be ' 'removed in the near future. ' 'Please use OPENSTACK_NEUTRON_NETWORK instead.', DeprecationWarning)",,7,0
openstack%2Fkeystone~proposed%2Fjuno~Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,openstack/keystone,proposed/juno,Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,Ensure sql upgrade tests can run with non-sqlite databases.,MERGED,2014-10-06 14:54:07.000000000,2014-10-07 01:26:57.000000000,2014-10-07 01:26:56.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-10-06 14:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a5962ea3954e58e23cd2be4d8c01d876bee27e0', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This patch has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 2, 'created': '2014-10-06 16:32:23.000000000', 'files': ['keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/079c6ad6c911226251fa2a601a27296cfe15e0b3', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This patch has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}]",0,126314,079c6ad6c911226251fa2a601a27296cfe15e0b3,13,5,2,4,,,0,"Ensure sql upgrade tests can run with non-sqlite databases.

This patch fixes the issues that were preventing the running of
live sql upgrade tests (either by running test_sql_upgrade directly
or via test_sql_livetest), namely:

- Dropping the tables that were in existence before the current
  scope of migration in an order that is FK friendly
- Fixing an issue where the tables were being dropped in the
  wrong order in the downgrade of federation
- Ensuring we don't hold sessions open over upgrade/downgrade
  steps in our test methods

Limitations:

- This patch has not been tested with DB2

Closes-Bug: 1363047
Closes-Bug: 1375937
Change-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634
",git fetch https://review.opendev.org/openstack/keystone refs/changes/14/126314/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py']",2,9a5962ea3954e58e23cd2be4d8c01d876bee27e0,bug/1363047," tables = ['federation_protocol', 'identity_provider']"," tables = ['identity_provider', 'federation_protocol']",78,18
openstack%2Fdiskimage-builder~master~I2177db2e64d4d9c21deeac7cf017919888a2d524,openstack/diskimage-builder,master,I2177db2e64d4d9c21deeac7cf017919888a2d524,Move dpkg manifest creation to finalise,MERGED,2014-09-29 15:08:43.000000000,2014-10-07 01:21:28.000000000,2014-10-07 01:21:28.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 6969}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-09-29 15:08:43.000000000', 'files': ['elements/dpkg/finalise.d/99-write-dpkg-manifest'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4d65e44472837417f484460c8b6e1990cea45997', 'message': 'Move dpkg manifest creation to finalise\n\nAs some finalise steps can install packages we need to generate the\ndpkg manifest after that has occurred.\n\nChange-Id: I2177db2e64d4d9c21deeac7cf017919888a2d524\n'}]",0,124765,4d65e44472837417f484460c8b6e1990cea45997,10,5,1,215,,,0,"Move dpkg manifest creation to finalise

As some finalise steps can install packages we need to generate the
dpkg manifest after that has occurred.

Change-Id: I2177db2e64d4d9c21deeac7cf017919888a2d524
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/65/124765/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dpkg/finalise.d/99-write-dpkg-manifest'],1,4d65e44472837417f484460c8b6e1990cea45997,,,,0,0
openstack%2Fhorizon~stable%2Ficehouse~I91a0bdd13384098cd2e306413bfc103c99bbc418,openstack/horizon,stable/icehouse,I91a0bdd13384098cd2e306413bfc103c99bbc418,Add missing Disk unit to Overview Usage,ABANDONED,2014-08-06 18:44:38.000000000,2014-10-07 01:19:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2424}, {'_account_id': 6825}, {'_account_id': 8090}, {'_account_id': 9531}, {'_account_id': 9576}, {'_account_id': 9656}, {'_account_id': 11880}]","[{'number': 1, 'created': '2014-08-06 18:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c3ade9e3ac5ab38fffbd52801eb86098c35742ea', 'message': 'Add missing Disk unit to Overview Usage\n\nAdded unit to the Summary table and the csv report\n\nConflicts:\n\n\topenstack_dashboard/dashboards/admin/overview/tests.py\n\topenstack_dashboard/dashboards/admin/projects/tests.py\n\topenstack_dashboard/dashboards/project/overview/templates/overview/usage.csv\n\nChange-Id: I91a0bdd13384098cd2e306413bfc103c99bbc418\nCloses-Bug: #1346389\n(cherry picked from commit https://review.openstack.org/#/c/109147/)\n'}, {'number': 2, 'created': '2014-08-06 19:03:26.000000000', 'files': ['openstack_dashboard/dashboards/admin/overview/templates/overview/usage.csv', 'openstack_dashboard/dashboards/admin/overview/tests.py', 'openstack_dashboard/dashboards/project/overview/templates/overview/usage.csv', 'openstack_dashboard/usage/tables.py', 'openstack_dashboard/dashboards/project/overview/views.py', 'openstack_dashboard/dashboards/admin/projects/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6923e2d282ae78d1d211a3b1731eef07fd524d7b', 'message': 'Add missing Disk unit to Overview Usage\n\nAdded unit to the Summary table and the csv report\n\nConflicts:\n\n\topenstack_dashboard/dashboards/admin/overview/tests.py\n\topenstack_dashboard/dashboards/admin/projects/tests.py\n\topenstack_dashboard/dashboards/project/overview/templates/overview/usage.csv\n\nChange-Id: I91a0bdd13384098cd2e306413bfc103c99bbc418\nCloses-Bug: #1346389\n(cherry picked from commit https://review.openstack.org/#/c/109147/)\n'}]",0,112380,6923e2d282ae78d1d211a3b1731eef07fd524d7b,18,9,2,9622,,,0,"Add missing Disk unit to Overview Usage

Added unit to the Summary table and the csv report

Conflicts:

	openstack_dashboard/dashboards/admin/overview/tests.py
	openstack_dashboard/dashboards/admin/projects/tests.py
	openstack_dashboard/dashboards/project/overview/templates/overview/usage.csv

Change-Id: I91a0bdd13384098cd2e306413bfc103c99bbc418
Closes-Bug: #1346389
(cherry picked from commit https://review.openstack.org/#/c/109147/)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/112380/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/overview/templates/overview/usage.csv', 'openstack_dashboard/dashboards/admin/overview/tests.py', 'openstack_dashboard/dashboards/project/overview/templates/overview/usage.csv', 'openstack_dashboard/dashboards/project/overview/views.py', 'openstack_dashboard/usage/tables.py', 'openstack_dashboard/dashboards/admin/projects/tests.py']",6,c3ade9e3ac5ab38fffbd52801eb86098c35742ea,icehouse-bug/1346389," hdr = ('Instance Name,VCPUs,RAM (MB),Disk (GB),Usage (Hours),' 'Uptime (Seconds),State')"," hdr = ('Instance Name,VCPUs,Ram (MB),Disk (GB),Usage (Hours),' 'Uptime(Seconds),State')",14,13
openstack%2Fdiskimage-builder~master~Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9,openstack/diskimage-builder,master,Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9,Save extended attributes when creating tar,MERGED,2014-10-01 17:17:10.000000000,2014-10-07 01:16:34.000000000,2014-10-07 01:16:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7471}, {'_account_id': 8399}]","[{'number': 1, 'created': '2014-10-01 17:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/743ad9c30bebac7cd6fe1b5ad1552c3342f77d01', 'message': ""Save extended attributes when creating tar\n\nThe way redhat-common's extract-image script was creating the base\ntarball caused file capabilities to get dropped, which meant that\nthings like ping in RHEL 7 images was unusable for regular users.\nThis change adds the necessary options to the tar call to maintain\nas many extended attributes as possible.\n\nbz reference: https://bugzilla.redhat.com/show_bug.cgi?id=1144149\n\nChange-Id: Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9\n""}, {'number': 2, 'created': '2014-10-02 22:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c0073f55eb5216b3c718d760149ec5f88b90b069', 'message': ""Save extended attributes when creating tar\n\nThe way redhat-common's extract-image script was creating the base\ntarball caused file capabilities to get dropped, which meant that\nthings like ping in RHEL 7 images was unusable for regular users.\nThis change adds the necessary options to the tar call to maintain\nas many extended attributes as possible.\n\n--acls is intentionally omitted because it seems to cause\npermission problems in the resulting images.  Since that isn't\nnecessary to fix the ping issue it should be fine to drop those.\n\nbz reference: https://bugzilla.redhat.com/show_bug.cgi?id=1144149\n\nChange-Id: Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9\n""}, {'number': 3, 'created': '2014-10-03 22:59:55.000000000', 'files': ['elements/redhat-common/bin/extract-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/edd74778912db5d4ae261f17d2ea8695d9e9ee0a', 'message': ""Save extended attributes when creating tar\n\nThe way redhat-common's extract-image script was creating the base\ntarball caused file capabilities to get dropped, which meant that\nthings like ping in RHEL 7 images was unusable for regular users.\nThis change adds the necessary options to the tar call to maintain\nas many extended attributes as possible.\n\n--acls and --selinux are intentionally omitted, and the selinux\nxattrs are filtered out because all of those items cause issues\nin our chroot environment.  We restore selinux attributes at the\nend of the build anyway so that shouldn't be a problem.\n\nbz reference: https://bugzilla.redhat.com/show_bug.cgi?id=1144149\n\nChange-Id: Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9\n""}]",1,125428,edd74778912db5d4ae261f17d2ea8695d9e9ee0a,28,7,3,6928,,,0,"Save extended attributes when creating tar

The way redhat-common's extract-image script was creating the base
tarball caused file capabilities to get dropped, which meant that
things like ping in RHEL 7 images was unusable for regular users.
This change adds the necessary options to the tar call to maintain
as many extended attributes as possible.

--acls and --selinux are intentionally omitted, and the selinux
xattrs are filtered out because all of those items cause issues
in our chroot environment.  We restore selinux attributes at the
end of the build anyway so that shouldn't be a problem.

bz reference: https://bugzilla.redhat.com/show_bug.cgi?id=1144149

Change-Id: Ibff99ce9bde01bc5ecf95dc3a5d3e2cebe5015b9
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/28/125428/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/redhat-common/bin/extract-image'],1,743ad9c30bebac7cd6fe1b5ad1552c3342f77d01,ext-attrs, sudo chroot $WORKING/mnt bin/tar --xattrs --xattrs-include='*' --acls --selinux -cz . > $WORKING/tmp.tar sudo tar -C $TARGET_ROOT --numeric-owner --xattrs --xattrs-include='*' --acls --selinux -xzf $CACHED_TAR, sudo chroot $WORKING/mnt bin/tar -cz . > $WORKING/tmp.tar sudo tar -C $TARGET_ROOT --numeric-owner -xzf $CACHED_TAR,2,2
openstack%2Fheat~master~Ibdeded33a32ddef07df572ce7d44b5a51afc5df7,openstack/heat,master,Ibdeded33a32ddef07df572ce7d44b5a51afc5df7,Implement check for Rackspace resources,MERGED,2014-08-27 21:41:41.000000000,2014-10-07 01:00:55.000000000,2014-10-07 01:00:54.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 9189}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-08-27 21:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d99083af7406abfbccb591cf1d76b7197e0ba47d', 'message': 'Implement check for Rackspace resources\n\nSince stack-check has been accepted, this patch implements handle_check\nfor all Rackspace resources.\n\nImplements: blueprint stack-check\nChange-Id: Ibdeded33a32ddef07df572ce7d44b5a51afc5df7\n'}, {'number': 2, 'created': '2014-09-11 16:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8dab6064c49bd082e2c7715ba1bb3b5a1523ab2d', 'message': 'Implement check for Rackspace resources\n\nSince stack-check has been accepted, this patch implements handle_check\nfor all Rackspace resources.\n\nImplements: blueprint stack-check\nChange-Id: Ibdeded33a32ddef07df572ce7d44b5a51afc5df7\n'}, {'number': 3, 'created': '2014-10-06 15:05:11.000000000', 'files': ['contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'contrib/rackspace/rackspace/tests/test_rackspace_dns.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/eeb9bb122e50912c56275a3b907a00931b363061', 'message': 'Implement check for Rackspace resources\n\nSince stack-check has been accepted, this patch implements handle_check\nfor all Rackspace resources.\n\nImplements: blueprint stack-check\nChange-Id: Ibdeded33a32ddef07df572ce7d44b5a51afc5df7\n'}]",0,117357,eeb9bb122e50912c56275a3b907a00931b363061,18,9,3,9189,,,0,"Implement check for Rackspace resources

Since stack-check has been accepted, this patch implements handle_check
for all Rackspace resources.

Implements: blueprint stack-check
Change-Id: Ibdeded33a32ddef07df572ce7d44b5a51afc5df7
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/117357/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'contrib/rackspace/rackspace/tests/test_rackspace_dns.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py']",8,d99083af7406abfbccb591cf1d76b7197e0ba47d,bp/stack-check, def handle_check(self): self.cloud_dns().get(self.resource_id) ,,97,2
openstack%2Fneutron~master~I33701d4dc9bf61595e44a49050c405ebca779091,openstack/neutron,master,I33701d4dc9bf61595e44a49050c405ebca779091,Add admin tenant name to nova notifier,MERGED,2014-07-01 19:23:05.000000000,2014-10-07 00:58:32.000000000,2014-10-07 00:58:30.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2031}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8276}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10073}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10652}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-07-01 19:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aad86b474d4c4e2bdd8f7dbad65b3359d1132c14', 'message': 'Add admin tenant name to nova notifier\n\nThis change introduces the ability to use the nova admin\ntenant name with the nova notifier in place of the nova\nadmin tenant id which may not be available when the neutron\nservice is being configured as is the case with tripleo\ninstallations where the neutron service is configured and\nstarted before the nova admin tenant has been configured in\nkeystone and thus does not have a known id.\n\nDocImpact\nIntroduces the nova_admin_tenant_name configuration entry as\nan optional configurable value in neutron.conf.\n\nChange-Id: I33701d4dc9bf61595e44a49050c405ebca779091\nCloses-Bug: #1331566\n'}, {'number': 2, 'created': '2014-07-03 13:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ed3142b48b074b19948142834fb3dff401b03c1', 'message': 'Add admin tenant name to nova notifier\n\nThis change introduces the ability to use the nova admin\ntenant name with the nova notifier in place of the nova\nadmin tenant id which may not be available when the neutron\nservice is being configured as is the case with tripleo\ninstallations where the neutron service is configured and\nstarted before the nova admin tenant has been configured in\nkeystone and thus does not have a known id.\n\nDocImpact\nIntroduces the nova_admin_tenant_name configuration entry as\nan optional configurable value in neutron.conf.\n\nChange-Id: I33701d4dc9bf61595e44a49050c405ebca779091\nCloses-Bug: #1331566\n'}, {'number': 3, 'created': '2014-09-30 18:19:35.000000000', 'files': ['etc/neutron.conf', 'neutron/common/config.py', 'neutron/notifiers/nova.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf92bbead9b25ee40a3336bd76110b3733a4f7ee', 'message': 'Add admin tenant name to nova notifier\n\nThis change introduces the ability to use the nova admin\ntenant name with the nova notifier in place of the nova\nadmin tenant id which may not be available when the neutron\nservice is being configured as is the case with tripleo\ninstallations where the neutron service is configured and\nstarted before the nova admin tenant has been configured in\nkeystone and thus does not have a known id.\n\nDocImpact\nIntroduces the nova_admin_tenant_name configuration entry as\nan optional configurable value in neutron.conf.  If the\nnova_admin_tenant_name is configured and the nova_admin_tenanat_id\nis not configured, a performance impact may be seen because\nkeystone will become involved in communication between neutron\nand nova.\n\nChange-Id: I33701d4dc9bf61595e44a49050c405ebca779091\nCloses-Bug: #1331566\n'}]",9,103978,cf92bbead9b25ee40a3336bd76110b3733a4f7ee,82,31,3,10652,,,0,"Add admin tenant name to nova notifier

This change introduces the ability to use the nova admin
tenant name with the nova notifier in place of the nova
admin tenant id which may not be available when the neutron
service is being configured as is the case with tripleo
installations where the neutron service is configured and
started before the nova admin tenant has been configured in
keystone and thus does not have a known id.

DocImpact
Introduces the nova_admin_tenant_name configuration entry as
an optional configurable value in neutron.conf.  If the
nova_admin_tenant_name is configured and the nova_admin_tenanat_id
is not configured, a performance impact may be seen because
keystone will become involved in communication between neutron
and nova.

Change-Id: I33701d4dc9bf61595e44a49050c405ebca779091
Closes-Bug: #1331566
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/103978/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron.conf', 'neutron/common/config.py', 'neutron/notifiers/nova.py']",3,aad86b474d4c4e2bdd8f7dbad65b3359d1132c14,bug/1331566," if cfg.CONF.nova_admin_tenant_id is not None: bypass_url = ""%s/%s"" % (cfg.CONF.nova_url, cfg.CONF.nova_admin_tenant_id) else: bypass_url = None project_id=cfg.CONF.nova_admin_tenant_name,"," bypass_url = ""%s/%s"" % (cfg.CONF.nova_url, cfg.CONF.nova_admin_tenant_id) project_id=None,",14,3
openstack%2Fneutron~master~I2171a164f3f77bccd89895d73c1c8d67f7190488,openstack/neutron,master,I2171a164f3f77bccd89895d73c1c8d67f7190488,Retry getting the list of service plugins,MERGED,2014-09-15 09:58:21.000000000,2014-10-07 00:47:22.000000000,2014-10-07 00:47:20.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1926}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 6796}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-15 09:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d03ccad3a0ce6f31592820706c237a52b071937', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Keep\nretrying this call to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 2, 'created': '2014-09-15 11:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/132a15c1fc038d41cebd6d026cb8661135f8ac6f', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Keep\nretrying this call to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 3, 'created': '2014-09-16 09:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc177165d8c688bb22e96cf8eee362365f9e4f42', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Keep\nretrying this call to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 4, 'created': '2014-09-18 07:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/087eb27e2aec6245821ee197435e123291438a7b', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Retry upto\n2 more times to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 5, 'created': '2014-09-18 12:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db1fc0f62523562ea1c11b023fc422b3516484ca', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Retry upto\n4 more times to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 6, 'created': '2014-09-19 13:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/315d9249455a976a1ebb71fe29d7f93284ca401d', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Retry upto\n4 more times to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}, {'number': 7, 'created': '2014-09-23 13:06:54.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e7f0b56d74fbfbb08a3b7a0d2da4cefb6fe2aa67', 'message': ""Retry getting the list of service plugins\n\nOn systems that start both neutron-server and neutron-l3-agent together,\nthere is a chance that the first call to neutron will timeout. Retry upto\n4 more times to avoid the l3 agent exiting on startup.\n\nThis should make the l3 agent a little more robust on startup but still\nnot ideal, ideally it wouldn't exit and retry periodically.\n\nChange-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488\nCloses-Bug: #1353953\nCloses-Bug: #1368152\nCloses-Bug: #1368795\n""}]",63,121492,e7f0b56d74fbfbb08a3b7a0d2da4cefb6fe2aa67,183,38,7,1926,,,0,"Retry getting the list of service plugins

On systems that start both neutron-server and neutron-l3-agent together,
there is a chance that the first call to neutron will timeout. Retry upto
4 more times to avoid the l3 agent exiting on startup.

This should make the l3 agent a little more robust on startup but still
not ideal, ideally it wouldn't exit and retry periodically.

Change-Id: I2171a164f3f77bccd89895d73c1c8d67f7190488
Closes-Bug: #1353953
Closes-Bug: #1368152
Closes-Bug: #1368795
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/121492/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,1d03ccad3a0ce6f31592820706c237a52b071937,l3-retry,"from oslo import messaging # This is the first place where we contact neutron-server on startup # so keep retrying until it is ready to respond while 1: try: self.neutron_service_plugins = ( self.plugin_rpc.get_service_plugin_list(self.context)) break except n_rpc.RemoteError as e: LOG.warning(_('l3-agent cannot check service plugins ' 'enabled at the neutron server when startup ' 'due to RPC error. It happens when the server ' 'does not support this RPC API. If the error ' 'is UnsupportedVersion you can ignore ' 'this warning. Detail message: %s'), e) self.neutron_service_plugins = None break except messaging.MessagingTimeout as e: LOG.warning(_('l3-agent cannot check service plugins enabled ' 'at the neutron server when startup. The ' 'neutron server failed to respond in a timely ' 'manner. Retrying. Detail message: %s'), e)"," try: self.neutron_service_plugins = ( self.plugin_rpc.get_service_plugin_list(self.context)) except n_rpc.RemoteError as e: LOG.warning(_('l3-agent cannot check service plugins ' 'enabled at the neutron server when startup ' 'due to RPC error. It happens when the server ' 'does not support this RPC API. If the error ' 'is UnsupportedVersion you can ignore ' 'this warning. Detail message: %s'), e) self.neutron_service_plugins = None",22,11
openstack%2Fnova~master~Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787,openstack/nova,master,Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787,nova-net: add more useful logging before raising FixedIpLimitExceeded,MERGED,2014-10-06 19:33:39.000000000,2014-10-07 00:41:01.000000000,2014-10-07 00:40:59.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 19:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23852533117b26ef84cf394aeb5965e490b7f936', 'message': ""nova-net: add more useful logging before raising FixedIpLimitExceeded\n\nThe OverQuota exception that we get back from the DB API contains some\nuseful information about the quota limits for the project and resource\nand the current usage, so we can log that before raising\nFixedIpLimitExceeded. Also logs the actual project ID passed to\nquotas.reserve rather than context.project_id since it's possible those\nare different.\n\nThis should help us figure out if we're leaking resources in gate runs.\n\nRelated-Bug: #1353962\n\nChange-Id: Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787\n""}, {'number': 2, 'created': '2014-10-06 19:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8cc7bc4afab66c4977c5f709e6216d97a20e085', 'message': ""nova-net: add more useful logging before raising FixedIpLimitExceeded\n\nThe OverQuota exception that we get back from the DB API contains some\nuseful information about the quota limits for the project and resource\nand the current usage, so we can log that before raising\nFixedIpLimitExceeded. Also logs the actual project ID passed to\nquotas.reserve rather than context.project_id since it's possible those\nare different.\n\nThis should help us figure out if we're leaking resources in gate runs.\n\nRelated-Bug: #1353962\n\nChange-Id: Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787\n""}, {'number': 3, 'created': '2014-10-06 20:32:45.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/044b18e7f02c588738bc21c43ad8066c9fcd7426', 'message': ""nova-net: add more useful logging before raising FixedIpLimitExceeded\n\nThe OverQuota exception that we get back from the DB API contains some\nuseful information about the quota limits for the project and resource\nand the current usage, so we can log that before raising\nFixedIpLimitExceeded. Also logs the actual project ID passed to\nquotas.reserve rather than context.project_id since it's possible those\nare different.\n\nThis should help us figure out if we're leaking resources in gate runs.\n\nRelated-Bug: #1353962\n\nChange-Id: Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787\n""}]",2,126401,044b18e7f02c588738bc21c43ad8066c9fcd7426,16,7,3,6873,,,0,"nova-net: add more useful logging before raising FixedIpLimitExceeded

The OverQuota exception that we get back from the DB API contains some
useful information about the quota limits for the project and resource
and the current usage, so we can log that before raising
FixedIpLimitExceeded. Also logs the actual project ID passed to
quotas.reserve rather than context.project_id since it's possible those
are different.

This should help us figure out if we're leaking resources in gate runs.

Related-Bug: #1353962

Change-Id: Ia8a6d2336ddbbe28178be8d3ce4d97e6d4ab3787
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/126401/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,23852533117b26ef84cf394aeb5965e490b7f936,bug/1353962," reserve.side_effect = exception.OverQuota(overs='testing', quotas={'fixed_ips': 10}, headroom={'fixed_ips': 0})", reserve.side_effect = exception.OverQuota(overs='testing'),13,4
openstack%2Ftrove~master~I126c0b89c170b325d85b3f09afca399b4f5de9e8,openstack/trove,master,I126c0b89c170b325d85b3f09afca399b4f5de9e8,Removing dependency on trove models in the guest agent,MERGED,2014-09-29 15:29:35.000000000,2014-10-07 00:26:28.000000000,2014-10-07 00:26:28.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-09-29 15:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6e69d4fdd7733d97342ddf01037144532f9ac706', 'message': 'Removing dependancy on trove models in the guest agent.\n\nCloses Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 2, 'created': '2014-09-29 15:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8a47808a570adff4bbd1ac734ea7f081f6898982', 'message': 'Removing dependancy on trove models in the guest agent.\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 3, 'created': '2014-09-29 17:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5144576e041c52ba3c294300728431d9677a984e', 'message': 'Removing dependency on trove models in the guest agent\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 4, 'created': '2014-09-29 21:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ef0b7c0e31daa898ecb41f8bf93d4e55d7e2435f', 'message': 'Removing dependency on trove models in the guest agent\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 5, 'created': '2014-09-30 14:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6761ae3cb30c7dc1221abb37734dcc136ef041cb', 'message': 'Removing dependency on trove models in the guest agent\n\nReasons:\n - The guest agent is importing backup models and agent\n   heartbeat, this triggers the all of the trove database setup\n   logic which bloats the guest process on the host.\n\n - Moving the state to its own module and removing an unused function\n   decreases the memory usage by about 15 - 20 megs.\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 6, 'created': '2014-10-03 19:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/aa2de3ffc156b9ea49eaac1a17ad7d9913647476', 'message': 'Removing dependency on trove models in the guest agent\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}, {'number': 7, 'created': '2014-10-03 20:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c6f4426de50543f3b5b3ece8756d6f9192501ee8', 'message': 'Removing dependency on trove models in the guest agent\n\nReasons:\n - The guest agent is importing backup models and agent\n   heartbeat, this triggers the all of the trove database\n   setup logic which bloats the guest process on the host.\n\n - Moving the state to its own module and removing an unused\n   function decreases the memory usage by about 15 - 20 megs.\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8'}, {'number': 8, 'created': '2014-10-06 15:21:41.000000000', 'files': ['trove/tests/unittests/backup/test_backup_models.py', 'trove/tests/api/mgmt/instances_actions.py', 'trove/tests/fakes/guestagent.py', 'trove/backup/state.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/guestagent/datastore/service.py', 'trove/tests/unittests/taskmanager/test_models.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/backup/models.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/tests/unittests/conductor/test_methods.py', 'trove/guestagent/backup/backupagent.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/0007a5076aa795fc354b122ae591980c9413f054', 'message': 'Removing dependency on trove models in the guest agent\n\nReasons:\n - The guest agent is importing backup models and agent\n   heartbeat, this triggers the all of the trove database\n   setup logic which bloats the guest process on the host.\n\n - Moving the state to its own module and removing an unused\n   function decreases the memory usage by about 15 - 20 megs.\n\nCloses-Bug: #1375311\nChange-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8\n'}]",2,124777,0007a5076aa795fc354b122ae591980c9413f054,76,11,8,6268,,,0,"Removing dependency on trove models in the guest agent

Reasons:
 - The guest agent is importing backup models and agent
   heartbeat, this triggers the all of the trove database
   setup logic which bloats the guest process on the host.

 - Moving the state to its own module and removing an unused
   function decreases the memory usage by about 15 - 20 megs.

Closes-Bug: #1375311
Change-Id: I126c0b89c170b325d85b3f09afca399b4f5de9e8
",git fetch https://review.opendev.org/openstack/trove refs/changes/77/124777/4 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/backup/test_backup_models.py', 'trove/tests/api/mgmt/instances_actions.py', 'trove/tests/fakes/guestagent.py', 'trove/backup/state.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/guestagent/datastore/service.py', 'trove/tests/unittests/taskmanager/test_models.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/backup/models.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/tests/unittests/conductor/test_methods.py', 'trove/guestagent/backup/backupagent.py']",13,6e69d4fdd7733d97342ddf01037144532f9ac706,bug/1375311,from trove.backup.state import BackupState,from trove.backup.models import BackupState,58,73
openstack%2Fopenstack-manuals~master~Ifec948423c865754f69d47f9f964402ee1ee1733,openstack/openstack-manuals,master,Ifec948423c865754f69d47f9f964402ee1ee1733,Update keystone_authtoken keys in the Installation Guide,ABANDONED,2014-10-03 01:25:46.000000000,2014-10-07 00:14:18.000000000,,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2014-10-03 01:25:46.000000000', 'files': ['doc/install-guide/object-storage/section_object-storage-install-config-proxy-node.xml', 'doc/install-guide/section_heat-install.xml', 'doc/install-guide/section_cinder-controller.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8e1fc978a21a9be495e983dbc77a85c3c8dbf4c5', 'message': 'Update keystone_authtoken keys in the Installation Guide\n\nReplaced auth_host, auth_port and auth_protocol keys with identity_uri and auth_uri keys\n\nChange-Id: Ifec948423c865754f69d47f9f964402ee1ee1733\nPartial-bug: 1301034\nImplements: blueprint installation-guide-improvements\n'}]",5,125847,8e1fc978a21a9be495e983dbc77a85c3c8dbf4c5,4,2,1,10705,,,0,"Update keystone_authtoken keys in the Installation Guide

Replaced auth_host, auth_port and auth_protocol keys with identity_uri and auth_uri keys

Change-Id: Ifec948423c865754f69d47f9f964402ee1ee1733
Partial-bug: 1301034
Implements: blueprint installation-guide-improvements
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/125847/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/object-storage/section_object-storage-install-config-proxy-node.xml', 'doc/install-guide/section_heat-install.xml', 'doc/install-guide/section_cinder-controller.xml']",3,8e1fc978a21a9be495e983dbc77a85c3c8dbf4c5,bug/1301034,identity_uri = http://<replaceable>controller</replaceable>:35357,auth_host = <replaceable>controller</replaceable>,4,5
openstack%2Fceilometer~master~I9b82ceee096b00c21c3b230dc67701bc40629968,openstack/ceilometer,master,I9b82ceee096b00c21c3b230dc67701bc40629968,Fix a response header bug in the error middleware,MERGED,2014-04-12 15:06:17.000000000,2014-10-07 00:11:32.000000000,2014-04-13 17:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2109}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 7478}, {'_account_id': 8005}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-04-12 15:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f3dd58712435f99ca06e0f904626b67534ba33f6', 'message': ""Fix a bug in the error middleware that breaks ceilometer running under Apache.\n\nCoerce the Content-Length of the custom error message to a string, not an\ninteger.  Some pure Python WSGI servers aren't strict and violate the WSGI\nspecification by automatically converting the value to a string.  Apache,\nhowever, *is* strict, and considers this a 500 Internal Error.\n\nFixes bug 1306963\n\nChange-Id: I9b82ceee096b00c21c3b230dc67701bc40629968\n""}, {'number': 2, 'created': '2014-04-12 17:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c1eeb8571caf5318ee4ae9d6720783db3dcf1a2', 'message': ""Fix a bug in the error middleware that breaks ceilometer running under Apache\n\nCoerce the Content-Length of the custom error message to a string, not an\ninteger.  Some pure Python WSGI servers aren't strict and violate the WSGI\nspecification by automatically converting the value to a string.  Apache,\nhowever, *is* strict, and considers this a 500 Internal Error\n\nFixes bug 1306963\n\nChange-Id: I9b82ceee096b00c21c3b230dc67701bc40629968\n""}, {'number': 3, 'created': '2014-04-12 17:43:07.000000000', 'files': ['ceilometer/api/middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/381d9ba941e93386000dd29b9426358efb7713f7', 'message': ""Fix a response header bug in the error middleware\n\nCoerce the Content-Length of the custom error message to a string, not an\ninteger.  Some pure Python WSGI servers aren't strict and violate the WSGI\nspecification by automatically converting the value to a string.  Apache,\nhowever, *is* strict, and considers this a 500 Internal Error\n\nFixes bug 1306963\n\nChange-Id: I9b82ceee096b00c21c3b230dc67701bc40629968\n""}]",0,87084,381d9ba941e93386000dd29b9426358efb7713f7,20,8,3,8005,,,0,"Fix a response header bug in the error middleware

Coerce the Content-Length of the custom error message to a string, not an
integer.  Some pure Python WSGI servers aren't strict and violate the WSGI
specification by automatically converting the value to a string.  Apache,
however, *is* strict, and considers this a 500 Internal Error

Fixes bug 1306963

Change-Id: I9b82ceee096b00c21c3b230dc67701bc40629968
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/84/87084/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/middleware.py'],1,f3dd58712435f99ca06e0f904626b67534ba33f6,bug/1306963," state['headers'].append(('Content-Length', str(len(body[0]))))"," state['headers'].append(('Content-Length', len(body[0])))",1,1
openstack%2Fgrenade~master~I42f272a07524bd1ae3f004803ca070a7fcf70c5c,openstack/grenade,master,I42f272a07524bd1ae3f004803ca070a7fcf70c5c,Ensure log directory has correct ownership.,MERGED,2014-10-03 10:16:30.000000000,2014-10-07 00:07:50.000000000,2014-10-07 00:07:50.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 3153}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-03 10:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/990f381e89c94f96def189faa1ef486589a8f4ec', 'message': ""Ensure log directory has correct ownership.\n\nOtherwise grenade.sh can't start on a mostly clean system.\n\nChange-Id: I42f272a07524bd1ae3f004803ca070a7fcf70c5c\n""}, {'number': 2, 'created': '2014-10-03 11:59:33.000000000', 'files': ['grenade.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/87e785e0e11c9e180635b82598fdaee513f812c3', 'message': ""Ensure log directory has correct ownership.\n\nOtherwise grenade.sh can't start on a mostly clean system.\n\nChange-Id: I42f272a07524bd1ae3f004803ca070a7fcf70c5c\n""}]",0,125924,87e785e0e11c9e180635b82598fdaee513f812c3,13,5,2,11564,,,0,"Ensure log directory has correct ownership.

Otherwise grenade.sh can't start on a mostly clean system.

Change-Id: I42f272a07524bd1ae3f004803ca070a7fcf70c5c
",git fetch https://review.opendev.org/openstack/grenade refs/changes/24/125924/1 && git format-patch -1 --stdout FETCH_HEAD,['grenade.sh'],1,990f381e89c94f96def189faa1ef486589a8f4ec,cd/no-stop-in-upgrade, sudo chown -R `whoami` $LOGDIR sudo chown -R `whoami` $SCREEN_LOGDIR,,2,0
openstack%2Fgrenade~master~Idc307f53845ec0b531973f8eeed84453fc1a04bb,openstack/grenade,master,Idc307f53845ec0b531973f8eeed84453fc1a04bb,grenade.sh: destroy javelin resources by the end,MERGED,2014-09-10 01:15:51.000000000,2014-10-07 00:07:44.000000000,2014-10-07 00:07:43.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 3153}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-09-10 01:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/4993128fc068ed8b6bd2f1d44bffb28b092f6761', 'message': 'grenade.sh: destroy javelin resources by the end\n\nWhen the upgrade runs successfully, destroy the resources to cleanup the\nsetup at the end of the process.\n\nDo not merge now, for testing only.\n\nChange-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 2, 'created': '2014-09-12 12:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/584db9827a947ce0bc8b27dbb8af215c3cbbecca', 'message': 'grenade.sh: destroy javelin resources by the end\n\nWhen the upgrade runs successfully, destroy the resources to cleanup the\nsetup at the end of the process.\n\nDo not merge now, for testing only.\n\nChange-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 3, 'created': '2014-09-29 19:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/67d44f31cac9d585fd8904e4f0ff466dc76069d9', 'message': 'grenade.sh: destroy javelin resources by the end\n\nWhen the upgrade runs successfully, destroy the resources to cleanup the\nsetup at the end of the process.\n\nDo not merge now, for testing only.\n\nChange-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 4, 'created': '2014-10-02 12:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/f6f31fd40b70714216a764fb4f04845fb49e8a8c', 'message': 'grenade.sh: destroy javelin resources by the end\n\nWhen the upgrade runs successfully, destroy the resources to cleanup the\nsetup at the end of the process.\n\nChange-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>'}, {'number': 5, 'created': '2014-10-03 12:35:15.000000000', 'files': ['grenade.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/3df2b3253895a4a44cec9456cc3bbe82654f1eeb', 'message': 'grenade.sh: destroy javelin resources by the end\n\nWhen the upgrade runs successfully, destroy the resources to cleanup the\nsetup at the end of the process.\n\nChange-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb\n'}]",2,120295,3df2b3253895a4a44cec9456cc3bbe82654f1eeb,24,5,5,3153,,,0,"grenade.sh: destroy javelin resources by the end

When the upgrade runs successfully, destroy the resources to cleanup the
setup at the end of the process.

Change-Id: Idc307f53845ec0b531973f8eeed84453fc1a04bb
",git fetch https://review.opendev.org/openstack/grenade refs/changes/95/120295/4 && git format-patch -1 --stdout FETCH_HEAD,['grenade.sh'],1,4993128fc068ed8b6bd2f1d44bffb28b092f6761,javelin-destruction," # Cleanup all resources created by javelin echo_summary ""Cleanip Javelin project"" (source $BASE_DEVSTACK_DIR/openrc admin admin; javelin2 -m destroy -r $GRENADE_DIR/resources.yaml -d $BASE_DEVSTACK_DIR -c $JAVELIN_CONF)",,5,0
openstack%2Fheat~master~Ieea739bc45dcc365ccb6f09d0e848e310d327134,openstack/heat,master,Ieea739bc45dcc365ccb6f09d0e848e310d327134,"Revert ""Hard delete backup stack after successful update.""",MERGED,2014-10-03 21:57:05.000000000,2014-10-07 00:06:59.000000000,2014-10-07 00:06:58.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-03 21:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55b8cc9fe977dacbc0ac506ae648e8e038d62df6', 'message': 'Revert ""Hard delete backup stack after successful update.""\n\nThis reverts commit 7cf6e52cacd2382b44b9255e9a5ed13271841261.\n\nThis change appears to be the cause of many Tempest test breakages.  Prior\nto this a new raw_template entry was created in the database after an\nupdate, and the pointer to the new raw_template and the stack status were\nchanged atomically. Now those two pieces of data are being updated\nseparately... it seems like it is possible for Postgres to return the new\nversion of the stack on one call followed by the old version of the\ntemplate on another call. Tempest is observing the stack status change to\nUPDATE_COMPLETE but then still getting data from the old template when\ndoing a resource list immediately after.\n\nChange-Id: Ieea739bc45dcc365ccb6f09d0e848e310d327134\nPartial-Bug: #1370865\n'}, {'number': 2, 'created': '2014-10-06 20:47:15.000000000', 'files': ['heat/db/api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/db/sqlalchemy/models.py', 'heat/tests/test_sqlalchemy_api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ce22b59b62f8f0e7136a2a7d675ca72a992a0543', 'message': 'Revert ""Hard delete backup stack after successful update.""\n\nThis reverts commit 7cf6e52cacd2382b44b9255e9a5ed13271841261.\n\nThis change appears to be the cause of many Tempest test breakages.  Prior\nto this a new raw_template entry was created in the database after an\nupdate, and the pointer to the new raw_template and the stack status were\nchanged atomically. Now those two pieces of data are being updated\nseparately... it seems like it is possible for the database to return the\nnew version of the stack on one call followed by the old version of the\ntemplate on another call. Tempest is observing the stack status change to\nUPDATE_COMPLETE but then still getting data from the old template when\ndoing a resource list immediately after.\n\nChange-Id: Ieea739bc45dcc365ccb6f09d0e848e310d327134\nPartial-Bug: #1370865\n'}]",0,126084,ce22b59b62f8f0e7136a2a7d675ca72a992a0543,21,6,2,4257,,,0,"Revert ""Hard delete backup stack after successful update.""

This reverts commit 7cf6e52cacd2382b44b9255e9a5ed13271841261.

This change appears to be the cause of many Tempest test breakages.  Prior
to this a new raw_template entry was created in the database after an
update, and the pointer to the new raw_template and the stack status were
changed atomically. Now those two pieces of data are being updated
separately... it seems like it is possible for the database to return the
new version of the stack on one call followed by the old version of the
template on another call. Tempest is observing the stack status change to
UPDATE_COMPLETE but then still getting data from the old template when
doing a resource list immediately after.

Change-Id: Ieea739bc45dcc365ccb6f09d0e848e310d327134
Partial-Bug: #1370865
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/126084/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/db/sqlalchemy/models.py', 'heat/tests/test_sqlalchemy_api.py']",5,55b8cc9fe977dacbc0ac506ae648e8e038d62df6,,," def test_stack_delete_hard(self): stack = create_stack(self.ctx, self.template, self.user_creds) stack_id = stack.id resource = create_resource(self.ctx, stack) template_id = stack.raw_template.id db_api.stack_delete_hard(self.ctx, stack_id) self.assertIsNone(db_api.stack_get(self.ctx, stack_id, show_deleted=False)) self.assertRaises(exception.NotFound, db_api.stack_delete, self.ctx, stack_id) # Even soft-delete aware should not find it self.assertIsNone(db_api.stack_get(self.ctx, stack_id, show_deleted=True)) # Testing child resources deletion self.assertRaises(exception.NotFound, db_api.resource_get, self.ctx, resource.id) # Testing raw_template deletion self.assertRaises(exception.NotFound, db_api.raw_template_get, self.ctx, template_id) def test_stack_delete_hard_deletes_events(self): stack = create_stack(self.ctx, self.template, self.user_creds) stack_id = stack.id values = [ {'stack_id': stack_id, 'resource_name': 'res1'}, {'stack_id': stack_id, 'resource_name': 'res2'}, ] [create_event(self.ctx, **val) for val in values] db_api.stack_delete_hard(self.ctx, stack_id) events = db_api.event_get_all_by_stack(self.ctx, stack_id) self.assertEqual(0, len(events)) ",3,72
openstack%2Fproject-config~master~Ib77229e7cc358059a6b3d6bcae0016959741db9d,openstack/project-config,master,Ib77229e7cc358059a6b3d6bcae0016959741db9d,Trigger requirements run for requirements-py3.txt,MERGED,2014-10-05 17:55:30.000000000,2014-10-07 00:05:00.000000000,2014-10-07 00:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-10-05 17:55:30.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a0f68fb468ff3766eba3294cc0d797c6a8b761ce', 'message': 'Trigger requirements run for requirements-py3.txt\n\nThe gate-.*requirements jobs are only triggered if certain files change.\nSome projects have requirements-py3.txt or test-requirements-py3.txt.\nInclude as triggers all versions that the file update.py from the global\nrequirements repository handles.\n\nChange-Id: Ib77229e7cc358059a6b3d6bcae0016959741db9d\n'}]",0,126193,a0f68fb468ff3766eba3294cc0d797c6a8b761ce,7,3,1,6547,,,0,"Trigger requirements run for requirements-py3.txt

The gate-.*requirements jobs are only triggered if certain files change.
Some projects have requirements-py3.txt or test-requirements-py3.txt.
Include as triggers all versions that the file update.py from the global
requirements repository handles.

Change-Id: Ib77229e7cc358059a6b3d6bcae0016959741db9d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/93/126193/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,a0f68fb468ff3766eba3294cc0d797c6a8b761ce,requirements3," - '^.*requirements-py[2,3].txt$'",,1,0
openstack%2Fproject-config~master~I75299f7ef186bae4596ce2c6b5579b7e82813255,openstack/project-config,master,I75299f7ef186bae4596ce2c6b5579b7e82813255,Further coverage cleanup,MERGED,2014-10-04 18:39:56.000000000,2014-10-07 00:04:52.000000000,2014-10-07 00:04:52.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6554}, {'_account_id': 6609}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-10-04 18:39:56.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/56d5f4ddfd0794fe03a3dbb4b4af81f3ce4d2f52', 'message': ""Further coverage cleanup\n\nDelete coverage jobs that are not setup properly at all, those that will\nalways fail. Examples are missing environments, missing scripts or\nmissing installed packages.\n\nI did not delete jobs that were successfull but didn't collect any data\nor those that failed for any reason.\n\nChange-Id: I75299f7ef186bae4596ce2c6b5579b7e82813255\n""}]",0,126155,56d5f4ddfd0794fe03a3dbb4b4af81f3ce4d2f52,9,5,1,6547,,,0,"Further coverage cleanup

Delete coverage jobs that are not setup properly at all, those that will
always fail. Examples are missing environments, missing scripts or
missing installed packages.

I did not delete jobs that were successfull but didn't collect any data
or those that failed for any reason.

Change-Id: I75299f7ef186bae4596ce2c6b5579b7e82813255
",git fetch https://review.opendev.org/openstack/project-config refs/changes/55/126155/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,56d5f4ddfd0794fe03a3dbb4b4af81f3ce4d2f52,coverage,, post: - ceilometer-coverage post: - taskflow-coverage - diskimage-builder-coverage - heat-cfntools-coverage - os-refresh-config-coverage - tempest-lib-coverage - bugdaystats-coverage - reviewday-coverage post: - entropy-coverage post: - monasca-agent-coverage post: - monasca-notification-coverage post: - monasca-persister-coverage post: - monasca-statsd-coverage post: - refstack-coverage,0,22
openstack%2Fnova-specs~master~I7338e20decea674cebec2ccdf38ba6cc27bf9631,openstack/nova-specs,master,I7338e20decea674cebec2ccdf38ba6cc27bf9631,Make blueprint URL in all-in-list-operator render correctly,MERGED,2014-08-25 17:43:18.000000000,2014-10-07 00:03:51.000000000,2014-10-07 00:03:51.000000000,"[{'_account_id': 3}, {'_account_id': 2271}]","[{'number': 1, 'created': '2014-08-25 17:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/103e1356fb524d60f7357047a5e0935e89769e05', 'message': ""Make blueprint URL in all-in-list-operator render correctly\n\nDue to the 80 character line limit the original blueprint URL, was\nwrapped and didn't render properly.\n\nChange-Id: I7338e20decea674cebec2ccdf38ba6cc27bf9631\n""}, {'number': 2, 'created': '2014-10-06 23:23:35.000000000', 'files': ['specs/juno/approved/add-all-in-list-operator-to-extra-spec-ops.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0901895f8fb6e152f2d9a370c94fabdac5ec4f5c', 'message': ""Make blueprint URL in all-in-list-operator render correctly\n\nDue to the 80 character line limit the original blueprint URL, was\nwrapped and didn't render properly.\n\nChange-Id: I7338e20decea674cebec2ccdf38ba6cc27bf9631\n""}]",0,116687,0901895f8fb6e152f2d9a370c94fabdac5ec4f5c,10,2,2,1849,,,0,"Make blueprint URL in all-in-list-operator render correctly

Due to the 80 character line limit the original blueprint URL, was
wrapped and didn't render properly.

Change-Id: I7338e20decea674cebec2ccdf38ba6cc27bf9631
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/87/116687/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-all-in-list-operator-to-extra-spec-ops.rst'],1,103e1356fb524d60f7357047a5e0935e89769e05,bp/URL,`https://blueprints.launchpad.net/nova/+spec/add-all-in-list-<https://blueprints.launchpad.net/nova/+spec/add-all-in-list- operator-to-extra-spec-ops>`_,https://blueprints.launchpad.net/nova/+spec/add-all-in-list-,3,1
openstack%2Fproject-config~master~I485f8095ecd21b4c78a0ed23f2f23a1e072f2e97,openstack/project-config,master,I485f8095ecd21b4c78a0ed23f2f23a1e072f2e97,Increase timeout for sahara-buildimages,MERGED,2014-10-06 23:22:25.000000000,2014-10-06 23:56:38.000000000,2014-10-06 23:56:38.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-10-06 23:22:25.000000000', 'files': ['jenkins/jobs/sahara.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ffd6fbe1e30cd7d977be160e374fbb1b29849b6f', 'message': ""Increase timeout for sahara-buildimages\n\nIt's working not super fast right now, so, we need to increase\ntimeout for buidling images from defaults 30 minutes.\n\nChange-Id: I485f8095ecd21b4c78a0ed23f2f23a1e072f2e97\n""}]",0,126434,ffd6fbe1e30cd7d977be160e374fbb1b29849b6f,8,4,1,6786,,,0,"Increase timeout for sahara-buildimages

It's working not super fast right now, so, we need to increase
timeout for buidling images from defaults 30 minutes.

Change-Id: I485f8095ecd21b4c78a0ed23f2f23a1e072f2e97
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/126434/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/sahara.yaml'],1,ffd6fbe1e30cd7d977be160e374fbb1b29849b6f,, wrappers: - build-timeout: timeout: 120 - timestamps ,,5,0
openstack%2Fheat-translator~master~Ice602153c9b04ed11be48c6fec83fad8bda1c83a,openstack/heat-translator,master,Ice602153c9b04ed11be48c6fec83fad8bda1c83a,Provide implementation to parse monitoring template in TOSCA library,MERGED,2014-09-16 19:27:28.000000000,2014-10-06 23:47:36.000000000,2014-10-06 23:47:35.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 9591}, {'_account_id': 10856}, {'_account_id': 11355}]","[{'number': 1, 'created': '2014-09-16 19:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/333aacaa4a91c0697301ac742fb088542d5f60bf', 'message': 'Partially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nProvide implementation to parse monitoring template in TOSCA library. The\ntemplate deploys nodejs, nginx, monbodb, elasticsearch, logstash and kibana\nas well collectd and rsyslog.\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 2, 'created': '2014-09-16 19:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2d0cb51b5fa153113b85296de6c6fde3cbef874e', 'message': 'Provide implementation to parse monitoring template in TOSCA library.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog.\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 3, 'created': '2014-09-17 13:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/613804d26e95b7e6ab17dc954da3e060d8d6c2ba', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 4, 'created': '2014-09-25 03:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/670c1a25d36fddb49f92da25b697ae823b01fcfb', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 5, 'created': '2014-09-25 17:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/365f3c64fb278dd9ae3534a17a13901b77d0eff8', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 6, 'created': '2014-09-25 19:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/5cc5fb97b63887ce4aa258bdf75f81a1ff5d6dff', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 7, 'created': '2014-09-25 19:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e388e4190b18468824da72d69d658efc6a528bcb', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 8, 'created': '2014-09-26 22:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d54e941b57294aba7ae71772536346bc196bcb87', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 9, 'created': '2014-09-27 21:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d55f2d071cfdaa7642ecee53dfb311861402e23f', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 10, 'created': '2014-09-27 21:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1d51cb402e9d655a38ec3fe4588cb4239db2715f', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 11, 'created': '2014-09-28 01:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1ca4c2b935253b7a779edd109b9719b23954992e', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 12, 'created': '2014-10-02 00:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d7b31a07b63dd5a30115cf019f40a7fc8841758d', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}, {'number': 13, 'created': '2014-10-02 18:28:16.000000000', 'files': ['translator/toscalib/elements/TOSCA_definition.yaml', 'translator/toscalib/elements/relationshiptype.py', 'translator/toscalib/tests/artifacts/nodejs/create.sh', 'translator/toscalib/tests/artifacts/nodejs/pre_configure_source.sh', 'translator/toscalib/tests/artifacts/nodejs/start.sh', 'translator/toscalib/tests/data/custom_types/nodejs.yaml', 'translator/toscalib/tests/artifacts/nodejs/config.sh', 'translator/toscalib/tests/data/tosca_elk.yaml', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/elements/statefulentitytype.py', 'translator/toscalib/tests/artifacts/mongodb/start.sh', 'translator/toscalib/elements/entitytype.py', 'translator/toscalib/tests/artifacts/mongodb/config.sh', 'translator/toscalib/tests/artifacts/mongodb/create.sh', 'translator/toscalib/tests/test_toscatpl.py', 'translator/toscalib/elements/nodetype.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d0b410a4f711446e5df57c4d0fb2637823323497', 'message': 'Provide implementation to parse monitoring template in TOSCA library\n\nThe template deploys nodejs, nginx, monbodb, elasticsearch, logstash and\nkibana as well collectd and rsyslog. The current patch covers nodejs and\nmongodb.\n\nPartially implements: blueprint enable-monitoring\nCloses-Bug: #1369109\n\nChange-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a\n'}]",35,121960,d0b410a4f711446e5df57c4d0fb2637823323497,64,6,13,6456,,,0,"Provide implementation to parse monitoring template in TOSCA library

The template deploys nodejs, nginx, monbodb, elasticsearch, logstash and
kibana as well collectd and rsyslog. The current patch covers nodejs and
mongodb.

Partially implements: blueprint enable-monitoring
Closes-Bug: #1369109

Change-Id: Ice602153c9b04ed11be48c6fec83fad8bda1c83a
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/60/121960/13 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/elements/TOSCA_definition.yaml', 'translator/toscalib/elements/relationshiptype.py', 'translator/toscalib/tests/data/custom_types/nodejs.yaml', 'translator/toscalib/tests/artifacts/nodejs/nodejs_create.sh', 'translator/toscalib/tests/artifacts/nodejs/nodejs_pre_config.sh', 'translator/toscalib/tests/data/custom_types/mongodb.yaml', 'translator/toscalib/tests/data/tosca_elk.yaml', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/artifacts/nodejs/nodejs_config.sh', 'translator/toscalib/tests/artifacts/mongodb/mongodb_config.sh', 'translator/toscalib/tests/artifacts/mongodb/mongodb_start.sh', 'translator/toscalib/tests/artifacts/mongodb/mongodb_create.sh', 'translator/toscalib/elements/entitytype.py', 'translator/toscalib/tests/test_toscatpl.py', 'translator/toscalib/elements/nodetype.py', 'translator/toscalib/tests/artifacts/nodejs/nodejs_start.sh']",16,333aacaa4a91c0697301ac742fb088542d5f60bf,bp/enable-monitoring,#!/bin/bash start nodeapp,,258,18
openstack%2Fnova-specs~master~Ia44ed986502be7252068f6bf2301e87ff75d1283,openstack/nova-specs,master,Ia44ed986502be7252068f6bf2301e87ff75d1283,Fix typo: June->Juno,MERGED,2014-10-06 23:37:06.000000000,2014-10-06 23:46:02.000000000,2014-10-06 23:46:01.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2271}]","[{'number': 1, 'created': '2014-10-06 23:37:06.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/67833f47c473bc2b1acf472aa20eff19c732f57b', 'message': 'Fix typo: June->Juno\n\nChange-Id: Ia44ed986502be7252068f6bf2301e87ff75d1283\n'}]",0,126436,67833f47c473bc2b1acf472aa20eff19c732f57b,7,3,1,6786,,,0,"Fix typo: June->Juno

Change-Id: Ia44ed986502be7252068f6bf2301e87ff75d1283
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/36/126436/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,67833f47c473bc2b1acf472aa20eff19c732f57b,,Juno implemented specs:,June implemented specs:,1,1
openstack%2Fnova~stable%2Ficehouse~Ie50b97c31580da7fc38c6891d1f3646b91f8aa10,openstack/nova,stable/icehouse,Ie50b97c31580da7fc38c6891d1f3646b91f8aa10,Raise descriptive error for over volume quota,MERGED,2014-09-09 18:20:15.000000000,2014-10-06 23:39:41.000000000,2014-10-06 23:39:38.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 2472}, {'_account_id': 5170}, {'_account_id': 7878}, {'_account_id': 8213}, {'_account_id': 8871}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-09-09 18:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e2fba4db26354b47809e4ee2ffb36296f7206f5', 'message': 'Raise descriptive error for over volume quota\n\nIf you attempt to create a new instance booting from an image and you\nwere over your quota on cinder, the nova manager would see that as an\ninvalid block device. This raises a more descriptive error message in\nthe logs.\n\nCloses-bug: #1013417\nChange-Id: Ie50b97c31580da7fc38c6891d1f3646b91f8aa10\n(cherry picked from commit 4711ff3adff2b4c9a54f5fb4448ace6558f82f6b)\n'}, {'number': 2, 'created': '2014-10-03 17:35:56.000000000', 'files': ['nova/volume/cinder.py', 'nova/compute/manager.py', 'nova/tests/volume/test_cinder.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5ec3cd30242350c1d0e759d8000e778c8cc1b48b', 'message': 'Raise descriptive error for over volume quota\n\nIf you attempt to create a new instance booting from an image and you\nwere over your quota on cinder, the nova manager would see that as an\ninvalid block device. This raises a more descriptive error message in\nthe logs.\n\nCloses-bug: #1013417\nChange-Id: Ie50b97c31580da7fc38c6891d1f3646b91f8aa10\n(cherry picked from commit 4711ff3adff2b4c9a54f5fb4448ace6558f82f6b)\n'}]",1,120172,5ec3cd30242350c1d0e759d8000e778c8cc1b48b,21,10,2,7878,,,0,"Raise descriptive error for over volume quota

If you attempt to create a new instance booting from an image and you
were over your quota on cinder, the nova manager would see that as an
invalid block device. This raises a more descriptive error message in
the logs.

Closes-bug: #1013417
Change-Id: Ie50b97c31580da7fc38c6891d1f3646b91f8aa10
(cherry picked from commit 4711ff3adff2b4c9a54f5fb4448ace6558f82f6b)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/120172/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/volume/cinder.py', 'nova/compute/manager.py', 'nova/tests/volume/test_cinder.py', 'nova/tests/compute/test_compute.py']",4,9e2fba4db26354b47809e4ee2ffb36296f7206f5,," @mock.patch.object(cinder.API, 'create', side_effect=exception.OverQuota(overs='volumes')) def test_prep_block_device_over_quota_failure(self, mock_create): instance = self._create_fake_instance() bdms = [ block_device.BlockDeviceDict({ 'boot_index': 0, 'guest_format': None, 'connection_info': None, 'device_type': u'disk', 'source_type': 'image', 'destination_type': 'volume', 'volume_size': 1, 'image_id': 1, 'device_name': '/dev/vdb', })] self.assertRaises(exception.InvalidBDM, compute_manager.ComputeManager()._prep_block_device, self.context, instance, bdms) mock_create.assert_called_once() @mock.patch('nova.compute.manager.ComputeManager._prep_block_device', side_effect=exception.OverQuota(overs='volumes')) def test_setup_block_device_over_quota_fail(self, mock_prep_block_dev): """"""block device mapping over quota failure test. Make sure when we're over volume quota according to Cinder client, the appropriate exception is raised and the instances to ERROR state, keep the task state. """""" instance = self._create_fake_instance() self.assertRaises(exception.OverQuota, self.compute.run_instance, self.context, instance=instance, request_spec={}, filter_properties={}, requested_networks=[], injected_files=None, admin_password=None, is_first_time=True, node=None, legacy_bdm_in_spec=False) #check state is failed even after the periodic poll self._assert_state({'vm_state': vm_states.ERROR, 'task_state': None}) self.compute.periodic_tasks(context.get_admin_context()) self._assert_state({'vm_state': vm_states.ERROR, 'task_state': None}) mock_prep_block_dev.assert_called_once() ",,65,0
openstack%2Ftempest~master~If53b3a7d299f01f7c45739f5b2f023fbdb73aa45,openstack/tempest,master,If53b3a7d299f01f7c45739f5b2f023fbdb73aa45,Remove setUpClass added after cleanup,MERGED,2014-10-04 08:39:44.000000000,2014-10-06 23:36:33.000000000,2014-10-06 23:36:32.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-04 08:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/30ebe08051a4b1044422009b704ab9595d2664af', 'message': 'Remove setUpClass added after cleanup\n\nAfter the cleanup of setUpClass a new one managed to sneak\nin. Removing it now, and enforcing the hacking rule in next\npatchset.\n\nChange-Id: If53b3a7d299f01f7c45739f5b2f023fbdb73aa45\n'}, {'number': 2, 'created': '2014-10-04 10:52:18.000000000', 'files': ['tempest/api/compute/security_groups/test_security_group_rules.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7dbf0ee253a85768103d67b58b6f3814b9b6a431', 'message': 'Remove setUpClass added after cleanup\n\nAfter the cleanup of setUpClass a new one managed to sneak\nin. Removing it now, and enforcing the hacking rule in next\npatchset.\n\nChange-Id: If53b3a7d299f01f7c45739f5b2f023fbdb73aa45\n'}]",0,126134,7dbf0ee253a85768103d67b58b6f3814b9b6a431,15,7,2,1921,,,0,"Remove setUpClass added after cleanup

After the cleanup of setUpClass a new one managed to sneak
in. Removing it now, and enforcing the hacking rule in next
patchset.

Change-Id: If53b3a7d299f01f7c45739f5b2f023fbdb73aa45
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/126134/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/security_groups/test_security_group_rules.py'],1,30ebe08051a4b1044422009b704ab9595d2664af,bp/resource-cleanup,," @classmethod def setUpClass(self): super(SecurityGroupRulesTestJSON, self).setUpClass()",0,4
openstack%2Fneutron~master~I6c344b21a69f85f2885a72377171f70309b26775,openstack/neutron,master,I6c344b21a69f85f2885a72377171f70309b26775,Raise exception if ipv6 prefix is inappropriate for address mode,MERGED,2014-08-24 21:20:35.000000000,2014-10-06 23:34:01.000000000,2014-10-06 23:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6635}, {'_account_id': 6685}, {'_account_id': 6695}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9411}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10257}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-08-24 21:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e1ef7021cff1ef28c3f3b66d43f352a3c63b89c', 'message': 'Raise exception if ipv6 prefix is too big for slaac address mode\n\nPer rfc4862 section 5.5.3, the maximum prefix to use with\nslaac ipv6 address mode is 64.\nThe patch adds corresponding validation and fixes unit tests\nappropriately.\n\nChange-Id: I6c344b21a69f85f2885a72377171f70309b26775\nCloses-Bug: #1357084\n'}, {'number': 2, 'created': '2014-08-25 08:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e248554ebf2ffe49cfc29ee5013aac6bc260f57', 'message': 'Raise exception if ipv6 prefix is too big for slaac address mode\n\nPer rfc4862 section 5.5.3, the maximum prefix to use with\nslaac ipv6 address mode is 64.\nThe patch adds corresponding validation and fixes unit tests\nappropriately.\n\nChange-Id: I6c344b21a69f85f2885a72377171f70309b26775\nCloses-Bug: #1357084\n'}, {'number': 3, 'created': '2014-09-10 12:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48b0ed9daae6d1e52a7104bf2e489291ef03ec5b', 'message': 'Raise exception if ipv6 prefix is inappropriate for address mode\n\nAddress prefix to use with slaac and stateless ipv6 address modes\nshould be equal to 64 in order to work properly.\nThe patch adds corresponding validation and fixes unit tests\naccordingly.\n\nChange-Id: I6c344b21a69f85f2885a72377171f70309b26775\nCloses-Bug: #1357084\n'}, {'number': 4, 'created': '2014-09-10 14:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/05c7f814773fd9aced6768b8bc54fa59227ecdaf', 'message': 'Raise exception if ipv6 prefix is inappropriate for address mode\n\nAddress prefix to use with slaac and stateless ipv6 address modes\nshould be equal to 64 in order to work properly.\nThe patch adds corresponding validation and fixes unit tests\naccordingly.\n\nChange-Id: I6c344b21a69f85f2885a72377171f70309b26775\nCloses-Bug: #1357084\n'}, {'number': 5, 'created': '2014-09-28 18:12:05.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d8911115e1b722da2f1e92f444e53b22223ee32', 'message': 'Raise exception if ipv6 prefix is inappropriate for address mode\n\nAddress prefix to use with slaac and stateless ipv6 address modes\nshould be equal to 64 in order to work properly.\nThe patch adds corresponding validation and fixes unit tests\naccordingly.\n\nChange-Id: I6c344b21a69f85f2885a72377171f70309b26775\nCloses-Bug: #1357084\n'}]",20,116525,0d8911115e1b722da2f1e92f444e53b22223ee32,150,38,5,6072,,,0,"Raise exception if ipv6 prefix is inappropriate for address mode

Address prefix to use with slaac and stateless ipv6 address modes
should be equal to 64 in order to work properly.
The patch adds corresponding validation and fixes unit tests
accordingly.

Change-Id: I6c344b21a69f85f2885a72377171f70309b26775
Closes-Bug: #1357084
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/116525/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py']",3,4e1ef7021cff1ef28c3f3b66d43f352a3c63b89c,bug/1357084," self._validate_slaac_applicable(subnet) def _validate_slaac_applicable(self, subnet): # check that slaac is only available if prefix is less than 64 # per RFC 4862, section 5.5.3 if subnet['ipv6_address_mode'] == constants.IPV6_SLAAC: if int(subnet['cidr'].split('/')[1]) > 64: raise n_exc.InvalidInput( error_message=_('Invalid cidr for slaac address mode'))",,31,10
openstack%2Ftempest~master~I1f09b25d6d6d1c966a0635509d670c55d9415468,openstack/tempest,master,I1f09b25d6d6d1c966a0635509d670c55d9415468,Remove Resp status code checks in stress tests,MERGED,2014-10-02 08:32:50.000000000,2014-10-06 23:31:43.000000000,2014-10-06 23:31:42.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 08:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/212c3989ee6fceea99ecb6e74c19e4c51efbf45f', 'message': 'Remove Resp status code checks in stress tests\n\nAs response code checks is done at client side,\ntests case do not need to check the same again.\n\nThis patch removes status code checks in stress tests.\nAll removed status code checks are present on client side.\n\nPartially Implements blueprint: client-checks-success\n\nChange-Id: I1f09b25d6d6d1c966a0635509d670c55d9415468\n'}, {'number': 2, 'created': '2014-10-03 00:40:02.000000000', 'files': ['tempest/stress/actions/volume_attach_delete.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/stress/actions/server_create_destroy.py', 'tempest/stress/actions/volume_attach_verify.py', 'tempest/stress/actions/volume_create_delete.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/51e84f441f68214683c49c20b31a4d655d275c01', 'message': 'Remove Resp status code checks in stress tests\n\nAs response code checks is done at client side,\ntests case do not need to check the same again.\n\nThis patch removes status code checks in stress tests.\nAll removed status code checks are present on client side.\n\nPartially Implements blueprint: client-checks-success\n\nChange-Id: I1f09b25d6d6d1c966a0635509d670c55d9415468\n'}]",3,125570,51e84f441f68214683c49c20b31a4d655d275c01,14,6,2,8556,,,0,"Remove Resp status code checks in stress tests

As response code checks is done at client side,
tests case do not need to check the same again.

This patch removes status code checks in stress tests.
All removed status code checks are present on client side.

Partially Implements blueprint: client-checks-success

Change-Id: I1f09b25d6d6d1c966a0635509d670c55d9415468
",git fetch https://review.opendev.org/openstack/tempest refs/changes/70/125570/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/actions/volume_attach_delete.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/stress/actions/server_create_destroy.py', 'tempest/stress/actions/volume_attach_verify.py', 'tempest/stress/actions/volume_create_delete.py']",5,212c3989ee6fceea99ecb6e74c19e4c51efbf45f,bp/client-checks-success," _, volume = volumes_client.create_volume(size=1, display_name=name) volumes_client.delete_volume(vol_id)"," resp, volume = volumes_client.create_volume(size=1, display_name=name) assert(resp.status == 200) resp, _ = volumes_client.delete_volume(vol_id) assert(resp.status == 202)",29,48
openstack%2Fkeystone~master~Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,openstack/keystone,master,Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634,Ensure sql upgrade tests can run with non-sqlite databases.,MERGED,2014-09-30 23:20:51.000000000,2014-10-06 23:31:08.000000000,2014-10-06 23:31:07.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-09-30 23:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2735eae0b96edeb8d9d06bcf2a2a8abc7b24adef', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This current version still does not work with Postgresql, due to\n  an issue with exceptions not being raised/caught correctly in\n  test_upgrade_region_unique_description(). This is being\n  investigated\n- This version has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 2, 'created': '2014-09-30 23:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f997544f0c8877fa4b92f66b325235eb33acb142', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This current version still does not work with Postgresql, due to\n  an issue with exceptions not being raised/caught correctly in\n  test_upgrade_region_unique_description(). This is being\n  investigated\n- This version has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 3, 'created': '2014-10-01 02:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/070a547f0674f1663c8a00fad8f84e93a73db63f', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This current version still does not work with Postgresql, due to\n  an issue with exceptions not being raised/caught correctly in\n  test_upgrade_region_unique_description(). This is being\n  investigated\n- This version has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 4, 'created': '2014-10-01 09:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/162f2ecc3b3cc5f6cb2db251954cfe98845bbbc5', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This current version still does not work with Postgresql, due to\n  an issue with exceptions not being raised/caught correctly in\n  test_upgrade_region_unique_description(). This is being\n  investigated\n- This version has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 5, 'created': '2014-10-01 09:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9de141fcdc543f9093e094c59bd8ee77e194840', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This patch has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}, {'number': 6, 'created': '2014-10-06 16:15:31.000000000', 'files': ['keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ff970f4e6215ff11dead4ad1b8abada644b50b31', 'message': ""Ensure sql upgrade tests can run with non-sqlite databases.\n\nThis patch fixes the issues that were preventing the running of\nlive sql upgrade tests (either by running test_sql_upgrade directly\nor via test_sql_livetest), namely:\n\n- Dropping the tables that were in existence before the current\n  scope of migration in an order that is FK friendly\n- Fixing an issue where the tables were being dropped in the\n  wrong order in the downgrade of federation\n- Ensuring we don't hold sessions open over upgrade/downgrade\n  steps in our test methods\n\nLimitations:\n\n- This patch has not been tested with DB2\n\nCloses-Bug: 1363047\nCloses-Bug: 1375937\nChange-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634\n""}]",3,125228,ff970f4e6215ff11dead4ad1b8abada644b50b31,23,6,6,5707,,,0,"Ensure sql upgrade tests can run with non-sqlite databases.

This patch fixes the issues that were preventing the running of
live sql upgrade tests (either by running test_sql_upgrade directly
or via test_sql_livetest), namely:

- Dropping the tables that were in existence before the current
  scope of migration in an order that is FK friendly
- Fixing an issue where the tables were being dropped in the
  wrong order in the downgrade of federation
- Ensuring we don't hold sessions open over upgrade/downgrade
  steps in our test methods

Limitations:

- This patch has not been tested with DB2

Closes-Bug: 1363047
Closes-Bug: 1375937
Change-Id: Ied4741a9646b57bc6f2ddcdc8a380ea55b2a9634
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/125228/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py']",3,2735eae0b96edeb8d9d06bcf2a2a8abc7b24adef,bug/1363047," tables = ['federation_protocol', 'identity_provider']"," tables = ['identity_provider', 'federation_protocol']",74,19
openstack%2Fnova-specs~master~Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8,openstack/nova-specs,master,Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8,Re-organize juno specs,MERGED,2014-09-17 09:51:39.000000000,2014-10-06 23:06:28.000000000,2014-10-06 23:06:28.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-09-17 09:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4fd12ce061f0a16441437e3a0f088ccb7413d064', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 2, 'created': '2014-09-17 09:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/af5b160a66b728491c5ac5e64b09ed6d183831eb', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 3, 'created': '2014-09-17 10:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/be5e3bb91c5bdfe420fc1f32ee606c5f2ba4bcf9', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 4, 'created': '2014-09-17 10:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a3a1cd94218d3e4f1b933ef743a4dab67a6d182c', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 5, 'created': '2014-09-17 23:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2647394b37bdc2caca7c75e5426c63fa41ee7127', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 6, 'created': '2014-09-18 00:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e37e78ef462fb5028b313f468dee328e44fbe6c2', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 7, 'created': '2014-09-18 01:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f975089332518afd55d869d0e98829e96ea16fb1', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 8, 'created': '2014-09-18 04:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c8d97a6fd941e6b56e49f68d22f66a9c4430e6da', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 9, 'created': '2014-09-18 06:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f039e1cccd49357f3ef33a71a84190858e847a4c', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 10, 'created': '2014-09-18 11:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6a22497681d5c27776cfdcf2d0717386989ceadd', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic.\n\nFor spec filenames where there was more than one review which\nproposed adding that file, I have added -proposal-[12345] to the\nend of the filename.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 11, 'created': '2014-09-30 00:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e8eaef0769bb7f0d53da492a969937c8950b5cae', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic. Note that\nthe actual proposed specs for Juno are adding in a later commit.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 12, 'created': '2014-09-30 00:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/01fc871fd30daa49e3891f6702d658955f71555f', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic. Note that\nthe actual proposed specs for Juno are adding in a later commit.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}, {'number': 13, 'created': '2014-10-06 20:51:48.000000000', 'files': ['specs/juno/implemented/scheduler-lib.rst', 'specs/juno/approved/tag-instances.rst', 'specs/juno/implemented/on-demand-compute-update.rst', 'specs/juno/approved/string-field-max-length.rst', 'specs/juno/approved/vmware-spbm-support.rst', 'tests/test_titles.py', 'README.rst', 'specs/juno/implemented/allow-image-to-be-specified-during-rescue.rst', 'specs/juno/redirects', 'specs/juno/approved/io-ops-weight.rst', 'specs/juno/implemented/return-status-for-hypervisor-node.rst', 'specs/juno/implemented/server-group-quotas.rst', 'specs/juno/implemented/instance-network-info-hook.rst', 'specs/juno/implemented/v3-api-schema.rst', 'specs/juno/approved/allocation-ratio-to-resource-tracker.rst', 'specs/juno/approved/libvirt-sheepdog-backed-instances.rst', 'specs/juno/implemented/backportable-db-migrations-juno.rst', 'specs/juno/approved/use-libvirt-storage-pools.rst', 'specs/juno/implemented/config-drive-image-property.rst', 'specs/juno/implemented/pci-passthrough-sriov.rst', 'specs/juno/implemented/compute-manager-objects-juno.rst', 'specs/juno/implemented/virt-objects-juno.rst', 'specs/juno/implemented/libvirt-domain-listing-speedup.rst', 'doc/source/redirect.py', 'specs/juno/implemented/add-ironic-driver.rst', 'specs/juno/approved/libvirt-driver-class-refactor.rst', 'specs/juno/approved/virt-driver-large-pages.rst', 'specs/juno/approved/db2-database.rst', 'specs/juno/approved/libvirt-start-lxc-from-block-devices.rst', 'specs/juno/implemented/libvirt-disk-discard-option.rst', 'specs/juno/implemented/use-oslo-vmware.rst', 'specs/juno/implemented/virt-driver-vcpu-topology.rst', 'specs/juno/implemented/rescue-attach-all-disks.rst', 'specs/juno/approved/restrict-image-isolation-with-defined-keys.rst', 'specs/juno/approved/virt-driver-cpu-pinning.rst', 'specs/juno/implemented/cross-service-request-id.rst', 'specs/juno/implemented/per-aggregate-filters.rst', 'specs/juno/approved/cold-migration-with-target.rst', 'specs/juno/implemented/better-support-for-multiple-networks.rst', 'specs/juno/implemented/libvirt-volume-snap-network-disk.rst', 'specs/juno/implemented/nfv-multiple-if-1-net.rst', 'specs/juno/implemented/serial-ports.rst', 'specs/juno/approved/migrate-libvirt-volumes.rst', 'specs/juno/implemented/v3-diagnostics.rst', 'specs/juno/approved/encryption-with-barbican.rst', 'specs/juno/approved/persistent-resource-claim.rst', 'specs/juno/approved/websocket-proxy-to-host-security.rst', 'specs/juno/implemented/object-subclassing.rst', 'specs/juno/approved/vmware-ephemeral-disk-support.rst', 'specs/juno/implemented/convert_ec2_api_to_use_nova_objects.rst', 'specs/juno/implemented/juno-slaveification.rst', 'specs/juno/approved/log-request-id-mappings.rst', 'specs/juno/implemented/libvirt-lxc-user-namespaces.rst', 'specs/juno/implemented/enabled-qemu-memballoon-stats.rst', 'specs/juno/approved/return-all-servers-during-multiple-create.rst', 'specs/juno/implemented/extensible-resource-tracking.rst', 'specs/juno/implemented/vmware-spawn-refactor.rst', 'specs/juno/implemented/move-prep-resize-to-conductor.rst', 'specs/juno/approved/add-virtio-scsi-bus-for-bdm.rst', 'specs/juno/implemented/find-host-and-evacuate-instance.rst', 'specs/juno/approved/vmware-vsan-support.rst', 'specs/juno/implemented/servers-list-support-multi-status.rst', 'specs/juno/approved/standardize-nova-image.rst', 'specs/juno/approved/server-count-api.rst', 'specs/juno/approved/ec2-volume-and-snapshot-tags.rst', 'specs/juno/implemented/hyper-v-soft-reboot.rst', 'specs/juno/implemented/v2-on-v3-api.rst', 'specs/juno/approved/xenapi-set-ipxe-url-as-img-metadata.rst', 'specs/juno/implemented/i18n-enablement.rst', 'specs/juno/approved/selecting-subnet-when-creating-vm.rst', 'specs/juno/approved/make-resource-tracker-use-objects.rst', 'specs/juno/implemented/libvirt-driver-domain-metadata.rst', 'specs/juno/approved/nova-pagination.rst', 'specs/juno/implemented/vmware-hot-plug.rst', 'specs/juno/implemented/remove-cast-to-schedule-run-instance.rst', 'specs/juno/implemented/add-differencing-vhdx-resize-support.rst', 'specs/juno/approved/vif-vhostuser.rst', 'specs/juno/implemented/support-cinderclient-v2.rst', 'doc/source/conf.py', 'specs/juno/approved/vmware-driver-ova-support.rst', 'specs/juno/implemented/hyper-v-console-log.rst', 'specs/juno/approved/enforce-unique-instance-uuid-in-db.rst', 'specs/juno/approved/quiesced-image-snapshots-with-qemu-guest-agent.rst', 'specs/juno/approved/support-console-log-migration.rst', 'specs/juno/implemented/virt-driver-numa-placement.rst', 'doc/source/index.rst', 'specs/juno/implemented/rbd-clone-image-handler.rst', 'specs/juno/implemented/user-defined-shutdown.rst', 'specs/juno/approved/input-output-based-numa-scheduling.rst', 'specs/juno/implemented/refactor-network-api.rst', 'specs/juno/approved/clean-logs.rst', 'specs/juno/approved/add-all-in-list-operator-to-extra-spec-ops.rst', 'specs/juno/approved/lvm-ephemeral-storage-encryption.rst', 'specs/juno/approved/xenapi-vcpu-topology.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f0b820407297ebb7e073fd43a90363d86bb0176f', 'message': ""Re-organize juno specs\n\nAs discussed at our nova meetings, reorganize the juno specs into\nthree directories:\n\n - proposed: things proposed which weren't approved\n - approved: things we approved but didn't implement\n - implemented: things approved and implemented\n\nThe first I suspect is the most controversial. I've done this\nbecause I worry about the case where a future developer wants to\npick up something dropped by a previous developer, but has trouble\nfinding previous proposed specifications on the topic. Note that\nthe actual proposed specs for Juno are adding in a later commit.\n\nChange-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8\n""}]",9,122109,f0b820407297ebb7e073fd43a90363d86bb0176f,41,7,13,2271,,,0,"Re-organize juno specs

As discussed at our nova meetings, reorganize the juno specs into
three directories:

 - proposed: things proposed which weren't approved
 - approved: things we approved but didn't implement
 - implemented: things approved and implemented

The first I suspect is the most controversial. I've done this
because I worry about the case where a future developer wants to
pick up something dropped by a previous developer, but has trouble
finding previous proposed specifications on the topic. Note that
the actual proposed specs for Juno are adding in a later commit.

Change-Id: Idcf55ca37a83d7098dcb7c2971240c4e8fd23dc8
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/09/122109/12 && git format-patch -1 --stdout FETCH_HEAD,"['specs/juno/proposed/horizontally-scalable-scheduling.rst', 'specs/juno/proposed/emc-sdc-libvirt-driver.rst', 'specs/juno/proposed/multi-attach-volume.rst', 'specs/juno/proposed/nova-api-policy.rst', 'specs/juno/proposed/metadata-service-callbacks.rst', 'specs/juno/proposed/nova-ephemeral-cinder.rst', 'specs/juno/proposed/gpfs-instance-store.rst', 'specs/juno/proposed/libvirt-smbfs-volume-support.rst', 'specs/juno/proposed/nova-api-extension-to-list-available-resources.rst', 'specs/juno/approved/io-ops-weight.rst', 'specs/juno/implemented/return-status-for-hypervisor-node.rst', 'specs/juno/proposed/nova-vmware-vcdriver-nfs-image-copy.rst', 'specs/juno/proposed/rootwrap-daemon-mode.rst', 'specs/juno/implemented/instance-network-info-hook.rst', 'specs/juno/implemented/v3-api-schema.rst', 'specs/juno/approved/libvirt-sheepdog-backed-instances.rst', 'specs/juno/implemented/virt-objects-juno.rst', 'specs/juno/proposed/add-useful-metrics.rst', 'specs/juno/proposed/host-servers-live-migrate.rst', 'specs/juno/approved/virt-driver-large-pages.rst', 'specs/juno/proposed/separated-policy-rule-v3-api.rst', 'specs/juno/proposed/standardize-client-params.rst', 'specs/juno/implemented/use-oslo-vmware.rst', 'specs/juno/implemented/virt-driver-vcpu-topology.rst', 'specs/juno/proposed/add-support-for-cinder-scheduler-hints.rst', 'specs/juno/proposed/default-quotas.rst', 'specs/juno/proposed/domain-quota-driver-v3-api.rst', 'specs/juno/proposed/synchronous-read-support.rst', 'specs/juno/proposed/incremental-instance-snapshot.rst', 'specs/juno/implemented/nfv-multiple-if-1-net.rst', 'specs/juno/implemented/serial-ports.rst', 'specs/juno/proposed/v2-api-detailed-quotas.rst', 'specs/juno/approved/migrate-libvirt-volumes.rst', 'specs/juno/approved/encryption-with-barbican.rst', 'specs/juno/approved/persistent-resource-claim.rst', 'specs/juno/proposed/template.rst', 'specs/juno/proposed/vnc-configurable-share-policy.rst', 'specs/juno/proposed/refactor-virt-capabilities.rst', 'specs/juno/proposed/virtio-scsi-settings.rst', 'specs/juno/approved/log-request-id-mappings.rst', 'specs/juno/proposed/slow-queries.rst', 'specs/juno/implemented/libvirt-lxc-user-namespaces.rst', 'specs/juno/implemented/enabled-qemu-memballoon-stats.rst', 'specs/juno/proposed/configure-tcp-keepalive.rst', 'specs/juno/proposed/flavor-cpu-overcommit.rst', 'specs/juno/approved/return-all-servers-during-multiple-create.rst', 'specs/juno/proposed/common-nova-metadata-cache.rst', 'specs/juno/proposed/scheduler-host-az-caching.rst', 'specs/juno/implemented/servers-list-support-multi-status.rst', 'specs/juno/proposed/usb-redirection.rst', 'specs/juno/proposed/spot-instances.rst', 'specs/juno/approved/ec2-volume-and-snapshot-tags.rst', 'specs/juno/proposed/image-upload-module-plugin.rst', 'specs/juno/proposed/vm-cpu-pinning-support.rst', 'specs/juno/proposed/ec2-volume-filtering.rst', 'specs/juno/proposed/vmware-vm-ref-refactor.rst', 'specs/juno/proposed/dynamic-adjust-disk-qos.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-3.rst', 'specs/juno/implemented/support-cinderclient-v2.rst', 'specs/juno/proposed/tenant-aggregate-exclusive-filter.rst', 'specs/juno/proposed/image-precacher.rst', 'specs/juno/proposed/usb-passthrough-proposal-2.rst', 'specs/juno/approved/quiesced-image-snapshots-with-qemu-guest-agent.rst', 'specs/juno/implemented/virt-driver-numa-placement.rst', 'specs/juno/implemented/user-defined-shutdown.rst', 'specs/juno/proposed/api-microversions.rst', 'specs/juno/proposed/support-keystone-v3-api.rst', 'specs/juno/implemented/scheduler-lib.rst', 'specs/juno/approved/tag-instances.rst', 'specs/juno/proposed/add-delete-on-termination-option.rst', 'specs/juno/approved/string-field-max-length.rst', 'specs/juno/approved/vmware-spbm-support.rst', 'specs/juno/proposed/audit-compute-node-on-controller-recovery.rst', 'specs/juno/proposed/domain-quota-driver-api.rst', 'specs/juno/proposed/add-extra-specs-to-flavor-calls.rst', 'specs/juno/proposed/nic-state-aware-scheduling.rst', 'README.rst', 'specs/juno/proposed/server-snapshot-support.rst', 'specs/juno/implemented/server-group-quotas.rst', 'specs/juno/proposed/use-glance-v2-api.rst', 'specs/juno/proposed/neutron-migration.rst', 'specs/juno/proposed/new-libvirt-volume-driver-for-Huawei-SDSHypervisor.rst', 'specs/juno/implemented/config-drive-image-property.rst', 'specs/juno/proposed/migrate-non-active-instances.rst', 'specs/juno/implemented/compute-manager-objects-juno.rst', 'specs/juno/implemented/libvirt-domain-listing-speedup.rst', 'specs/juno/proposed/log-guidelines.rst', 'specs/juno/proposed/freebsd-compute-node.rst', 'specs/juno/proposed/enchancement-virtio-scsi-support-for-volume.rst', 'specs/juno/proposed/set-vm-swapfile-location.rst', 'specs/juno/proposed/metadata-service-network-info.rst', 'specs/juno/approved/db2-database.rst', 'specs/juno/approved/libvirt-start-lxc-from-block-devices.rst', 'specs/juno/implemented/libvirt-disk-discard-option.rst', 'specs/juno/proposed/no-downward-resize.rst', 'specs/juno/proposed/pci-hotplug-juno.rst', 'specs/juno/proposed/hyper-v-host-power-actions.rst', 'specs/juno/proposed/libvirt-support-tpm-passthrough.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-1.rst', 'specs/juno/proposed/usb-passthrough-with-usb-controller.rst', 'specs/juno/implemented/per-aggregate-filters.rst', 'specs/juno/proposed/add-transport-support-to-iscsi.rst', 'specs/juno/proposed/data-transfer-plugin.rst', 'specs/juno/implemented/libvirt-volume-snap-network-disk.rst', 'specs/juno/proposed/default-quota-flavor.rst', 'specs/juno/proposed/validate-tenant-user-with-keystone.rst', 'specs/juno/approved/websocket-proxy-to-host-security.rst', 'specs/juno/implemented/object-subclassing.rst', 'specs/juno/proposed/schedule-available-node-return.rst', 'specs/juno/proposed/deprecate-baremetal-driver.rst', 'specs/juno/proposed/libvirt-multiple-image-backends.rst', 'specs/juno/proposed/api-microversions-alt.rst', 'specs/juno/proposed/use-configdrive-with-ironic.rst', 'specs/juno/implemented/move-prep-resize-to-conductor.rst', 'specs/juno/proposed/virt-properties-object.rst', 'specs/juno/approved/vmware-vsan-support.rst', 'specs/juno/approved/standardize-nova-image.rst', 'specs/juno/proposed/ram-as-percentage.rst', 'specs/juno/approved/server-count-api.rst', 'specs/juno/proposed/extension-level-policy-as-default-v3-api.rst', 'specs/juno/approved/xenapi-set-ipxe-url-as-img-metadata.rst', 'specs/juno/proposed/instance-level-snapshots.rst', 'specs/juno/proposed/storage-optimization-for-multi-datastore-clusters.rst', 'specs/juno/proposed/username-in-nova-list-for-admin-purpose.rst', 'specs/juno/implemented/i18n-enablement.rst', 'specs/juno/proposed/default-schedule-zones.rst', 'specs/juno/proposed/vmware-clone-image-handler.rst', 'specs/juno/proposed/compute-image-precache.rst', 'specs/juno/proposed/add-app-lock.rst', 'specs/juno/proposed/add-tags-for-os-resources.rst', 'specs/juno/proposed/user-project-metadata.rst', 'specs/juno/approved/vif-vhostuser.rst', 'specs/juno/proposed/console-tls-mode.rst', 'specs/juno/proposed/generate-vmstates-graph.rst', 'specs/juno/proposed/quota-state-management.rst', 'specs/juno/approved/vmware-driver-ova-support.rst', 'specs/juno/implemented/hyper-v-console-log.rst', 'specs/juno/proposed/no-migration-resize.rst', 'specs/juno/approved/support-console-log-migration.rst', 'specs/juno/proposed/internal-dns-resolution.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-1.rst', 'specs/juno/proposed/pxe-boot-instance.rst', 'specs/juno/implemented/rbd-clone-image-handler.rst', 'specs/juno/proposed/cinder-events.rst', 'specs/juno/proposed/thunderboost-proposal-1.rst', 'specs/juno/approved/add-all-in-list-operator-to-extra-spec-ops.rst', 'specs/juno/proposed/dnsmasq-options-config.rst', 'specs/juno/proposed/hyper-v-rescue.rst', 'specs/juno/proposed/restrict-instance-migration.rst', 'specs/juno/proposed/add-support-for-cpu-hotadd.rst', 'specs/juno/proposed/thunderboost-proposal-2.rst', 'specs/juno/proposed/extends-nova-hypervisor.rst', 'specs/juno/proposed/transfer-instance-ownership.rst', 'specs/juno/proposed/validate-targethost-live-migration.rst', 'specs/juno/implemented/allow-image-to-be-specified-during-rescue.rst', 'specs/juno/proposed/instance-tasks-api.rst', 'specs/juno/proposed/no-db-scheduler.rst', 'specs/juno/proposed/soft-affinity-for-server-group.rst', 'specs/juno/approved/allocation-ratio-to-resource-tracker.rst', 'specs/juno/proposed/hyper-v-remotefx.rst', 'specs/juno/proposed/pcs-support.rst', 'specs/juno/implemented/add-ironic-driver.rst', 'specs/juno/proposed/libvirt-separate-virt-types-to-classes.rst', 'specs/juno/implemented/rescue-attach-all-disks.rst', 'specs/juno/proposed/add-delete-node-to-nova-manage.rst', 'specs/juno/approved/virt-driver-cpu-pinning.rst', 'specs/juno/approved/cold-migration-with-target.rst', 'specs/juno/proposed/encrypted-live-migration-nova.rst', 'specs/juno/implemented/better-support-for-multiple-networks.rst', 'specs/juno/proposed/policy-based-scheduing-engine.rst', 'specs/juno/proposed/nova-compute-multi-backend-support.rst', 'specs/juno/approved/vmware-ephemeral-disk-support.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-2.rst', 'specs/juno/proposed/remove-fakelibvirt.rst', 'specs/juno/proposed/libvirt-storpool-volume-attach.rst', 'specs/juno/proposed/ec2-volume-type.rst', 'specs/juno/proposed/flavor-quota-memory.rst', 'specs/juno/implemented/extensible-resource-tracking.rst', 'specs/juno/implemented/vmware-spawn-refactor.rst', 'specs/juno/implemented/find-host-and-evacuate-instance.rst', 'specs/juno/proposed/vcpus-in-api.rst', 'specs/juno/proposed/isolate-scheduler-db.rst', 'specs/juno/proposed/solver-scheduler.rst', 'specs/juno/proposed/periodic-heartbeat.rst', 'specs/juno/proposed/associate-lru-fixed-ip-address.rst', 'specs/juno/proposed/idempotentcy-client-token.rst', 'specs/juno/proposed/lock-free-quota-management.rst', 'specs/juno/approved/selecting-subnet-when-creating-vm.rst', 'specs/juno/approved/make-resource-tracker-use-objects.rst', 'specs/juno/proposed/domain-quota-manage-commands.rst', 'specs/juno/approved/nova-pagination.rst', 'specs/juno/proposed/vmware-encrypt-vcenter-passwords-proposal-2.rst', 'specs/juno/implemented/remove-cast-to-schedule-run-instance.rst', 'specs/juno/proposed/get-lock-status-of-instance.rst', 'specs/juno/proposed/cache-qos-monitoring.rst', 'specs/juno/proposed/auto-disable-and-enable-hypervisor.rst', 'specs/juno/proposed/isnot-operator.rst', 'specs/juno/proposed/lvm-driver-for-shared-storage.rst', 'specs/juno/implemented/refactor-network-api.rst', 'specs/juno/approved/lvm-ephemeral-storage-encryption.rst', 'specs/juno/proposed/add-force-detach-to-nova.rst', 'specs/juno/proposed/get-floatingip-by-all-tenants.rst', 'specs/juno/proposed/action-type-aware-scheduling.rst', 'specs/juno/implemented/on-demand-compute-update.rst', 'specs/juno/proposed/log-translation-hints.rst', 'specs/juno/proposed/server_http_proxy.rst', 'tests/test_titles.py', 'specs/juno/proposed/keypair-x509-certificates.rst', 'specs/juno/proposed/virt-image-transfer-layer.rst', 'specs/juno/proposed/message-in-update-notifications.rst', 'specs/juno/proposed/change-instances-ownership-proposal-2.rst', 'specs/juno/proposed/cpu-allocation-per-flavor.rst', 'specs/juno/proposed/instance-boot.rst', 'specs/juno/proposed/add-an-index-column-to-nova-list.rst', 'specs/juno/proposed/libvirt-hugepage.rst', 'specs/juno/proposed/pci-device-capability-aware-scheduling.rst', 'specs/juno/implemented/backportable-db-migrations-juno.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-1.rst', 'specs/juno/approved/use-libvirt-storage-pools.rst', 'specs/juno/implemented/pci-passthrough-sriov.rst', 'specs/juno/proposed/thunderboost-proposal-3.rst', 'specs/juno/proposed/add-ironic-boot-mode-filters.rst', 'specs/juno/proposed/datastore-image-cache-update-improvements.rst', 'specs/juno/approved/libvirt-driver-class-refactor.rst', 'specs/juno/proposed/vmware-resource-pool-enablement.rst', 'specs/juno/proposed/nodename-in-pci-device.rst', 'specs/juno/proposed/simultaneous-server-group.rst', 'specs/juno/approved/restrict-image-isolation-with-defined-keys.rst', 'specs/juno/proposed/libvirt-ovs-use-usvhost.rst', 'specs/juno/proposed/restrict-image-types.rst', 'specs/juno/proposed/host-metric-hook.rst', 'specs/juno/implemented/cross-service-request-id.rst', 'specs/juno/proposed/shelf-snapshot-selection.rst', 'specs/juno/proposed/v3-api-neutron-network-support.rst', 'specs/juno/proposed/db-sync-models-with-migrations.rst', 'specs/juno/proposed/add-usb-controller.rst', 'specs/juno/proposed/pci-extra-info.rst', 'specs/juno/proposed/compute-node-metrics-api.rst', 'specs/juno/implemented/v3-diagnostics.rst', 'specs/juno/proposed/hot-resize.rst', 'specs/juno/implemented/convert_ec2_api_to_use_nova_objects.rst', 'specs/juno/implemented/juno-slaveification.rst', 'specs/juno/proposed/per-flavor-quotas.rst', 'specs/juno/proposed/projects-to-aggregate.rst', 'specs/juno/proposed/cold-migrations-to-conductor-final.rst', 'specs/juno/approved/add-virtio-scsi-bus-for-bdm.rst', 'specs/juno/proposed/separate-stats-from-periodic-task.rst', 'specs/juno/proposed/docker-hypervisor-plugin.rst', 'specs/juno/proposed/hyper-v-generation-2-vms.rst', 'specs/juno/proposed/online-schema-changes.rst', 'specs/juno/proposed/nested-quota-driver-api-proposal-3.rst', 'specs/juno/implemented/hyper-v-soft-reboot.rst', 'specs/juno/implemented/v2-on-v3-api.rst', 'specs/juno/proposed/dynamic-logging.rst', 'specs/juno/proposed/online-volume-extend-extension.rst', 'specs/juno/proposed/add-utilization-based-weighers.rst', 'specs/juno/proposed/only-allow-admins-to-do-local-delete.rst', 'specs/juno/implemented/libvirt-driver-domain-metadata.rst', 'specs/juno/proposed/libvirt-linux-net-refactor-for-freebsd.rst', 'specs/juno/implemented/vmware-hot-plug.rst', 'specs/juno/implemented/add-differencing-vhdx-resize-support.rst', 'specs/juno/proposed/normalize-scheduler-weights-2.rst', 'specs/juno/approved/enforce-unique-instance-uuid-in-db.rst', 'specs/juno/proposed/exclude-cbs-in-snapshot.rst', 'specs/juno/proposed/hyper-v-smbfs-volume-support.rst', 'specs/juno/proposed/usb-hot-plug.rst', 'specs/juno/proposed/use-physical-cdrom.rst', 'specs/juno/proposed/usb-passthrough-proposal-1.rst', 'specs/juno/proposed/monitoring-ip-availability-proposal-2.rst', 'specs/juno/approved/input-output-based-numa-scheduling.rst', 'specs/juno/approved/clean-logs.rst', 'specs/juno/proposed/specify-number-of-cores-per-socket.rst', 'specs/juno/proposed/change-instances-ownership-proposal-1.rst', 'specs/juno/proposed/persist-scheduler-hints.rst', 'specs/juno/approved/xenapi-vcpu-topology.rst', 'specs/juno/proposed/creating-hyperv-ha-instances.rst']",276,4fd12ce061f0a16441437e3a0f088ccb7413d064,archive-juno-proposals,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================================================== HyperV nova driver enhancement to create highly available instances =================================================================== https://blueprints.launchpad.net/nova/+spec/creating-hyperv-ha-instances This blueprint creating-hyperv-ha-instances allows creating of highly available instances in a HyperV hosts that are in a failover cluster. Highly available virtual machines are defined by the the document http://technet.microsoft.com/en-us/library/cc967323.aspx as 'Highly available virtual machines, also known as HAVMs, can easily be migrated to a different virtual machine host in a failover cluster to provide continuing service when their current host needs maintenance. If their current host fails, the HAVMs automatically migrate to a different host in the cluster through a process known as failover.' The following whitepaper provides more details. Failover Clustering in Windows Server 2008 R2 - Whitepaper Problem description =================== Existing HyperV nova driver does not provide the benefits available on HyperV hosts configured in a failover cluster and therefore when a host in the cluster fails the instance is not available to the user. Proposed change =============== Add support to configure high availability for an instance in the HyperV nova driver. This is done by modifying the instance creation steps in the following way * 1. Create instances on shared storage * 2. Configure the instance as highly available Also, the image cache should also be created on the shared storage A new boolean config option failover_clustering will be added. When the option is set to true, the proposed changes take effect. The user can override the config on a per instance basis by specifying the property hyperv_ha as false Alternatives for implementation of the proposed change * 1. Using the config option approach the existing driver behaviour can be modified without adding a new driver deriving from the existing driver. However with this approach, the implementation will have conditional switch since WMI calls to get cluster data are done using a different namespace and classes. * 2. Create a new driver that derives from the existing driver. Only override the methods that require changes. It is proposed to using alternative 1 described above since the changes are limited to spawn method. Configuration requirements that have to be met by the HyperV host for HA to work correctly (Ref: http://technet.microsoft.com/en-us/library/cc742396.aspx) Networking - All nodes in the same cluster must use the same name for the virtual network that provides external networking for the virtual machines. Processor - If the nodes in the cluster use different processor versions, make sure that the virtual machine is configured for processor compatibility. Security - All nodes in the cluster must use the same authorization policy. Storage - Must use shared storage that is supported by both the Failover Clustering feature and Hyper-V. Alternatives ------------ * 1. A single driver manages all the hosts in the cluster. The problem with this is the server hosting the nova-compute should always be available. To make this work the nova-compute service must be made a clustered service. * 2. The nova-compute runs in a VM that is hosted in a host in the cluster. This VM is configured as a highly available VM. The drawback of this approach is that the remote WMI are slow and therefore will impact the performance of the driver. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Instance deployments will have additional WMI calls done to detect the shared storage. However since the image cache is on the shared storage, the number of downloads from glance is reduced. Earlier each host has its own cache and therefore needed to download its own copy. Other deployer impact --------------------- None Developer impact ---------------- * This change only impacts the HyperV nova driver. Other drivers will not be impacted due to this change. Implementation ============== The connections are done to the root/MSCluster namespace First, the HA resource group of the VMs disk is obtained using the query ASSOCIATORS OF {MSCluster_Resource.Name=insert_disk_name_here} where ResultRole = GroupComponent ResultClass = MSCluster_ResourceGroup If its not part of a group a new group can be created using CreateGroup The resource is created using the CreateResource method The resource is brough online using BringOnline method Assignee(s) ----------- Primary assignee: kiran-kumar-vaddi Other contributors: Work Items ---------- * Modify the code the selects the location to spawn an instance to select only shared storage (Cluster Shared Volumes) * Enable HA on the instance before starting the instance * The image cache must be on shared storage Dependencies ============ None Testing ======= The unit tests will be modified to test the branches introduced by the above work items Documentation Impact ==================== A new boolean config option failover_clustering will be added. When the option is set to true, the instances are configured as highly available instances. The user can override the config on a per instance basis by specifying the property hyperv_ha as false. References ========== Failover Clusters in Windows Server 2008 R2 http://technet.microsoft.com/en-us/library/ff182338(v=ws.10).aspx Failover Clustering Overview (Win 2012 and Win 2012 R2) http://technet.microsoft.com/en-us/library/hh831579.aspx",,36053,20
openstack%2Ftraining-guides~master~I642fac63a384846f085389e1e535ea2b5d02ef43,openstack/training-guides,master,I642fac63a384846f085389e1e535ea2b5d02ef43,Upstream Training proposal for modifications,MERGED,2014-10-06 19:12:03.000000000,2014-10-06 22:52:45.000000000,2014-10-06 22:52:45.000000000,"[{'_account_id': 3}, {'_account_id': 287}, {'_account_id': 2064}, {'_account_id': 4556}, {'_account_id': 6923}]","[{'number': 1, 'created': '2014-10-06 19:12:03.000000000', 'files': ['doc/upstream-training/01-release-cycle.rst', 'doc/upstream-training/14-gerrit.rst', 'doc/upstream-training/_assets/14-14-git-repush.png', 'doc/upstream-training/04-program-ecosystem.rst', 'doc/upstream-training/17-commit-message.rst', 'doc/upstream-training/_assets/05-04-sessions.png', 'doc/upstream-training/_assets/14-10-git-review.png', 'doc/upstream-training/05-design-summit.rst', 'doc/upstream-training/13-launchpad.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/112efc2cd29d237f9910a93417c41efa90726a23', 'message': 'Upstream Training proposal for modifications\n\nDesign Summits are now held differently by using Etherpad for selecting\nsessions. Also, drafts are no longer accepted by Gerrit because of various\nbugs they were creating.\n\nChange-Id: I642fac63a384846f085389e1e535ea2b5d02ef43\n'}]",0,126398,112efc2cd29d237f9910a93417c41efa90726a23,8,5,1,7166,,,0,"Upstream Training proposal for modifications

Design Summits are now held differently by using Etherpad for selecting
sessions. Also, drafts are no longer accepted by Gerrit because of various
bugs they were creating.

Change-Id: I642fac63a384846f085389e1e535ea2b5d02ef43
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/98/126398/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/upstream-training/01-release-cycle.rst', 'doc/upstream-training/14-gerrit.rst', 'doc/upstream-training/_assets/14-14-git-repush.png', 'doc/upstream-training/04-program-ecosystem.rst', 'doc/upstream-training/17-commit-message.rst', 'doc/upstream-training/_assets/05-04-sessions.png', 'doc/upstream-training/05-design-summit.rst', 'doc/upstream-training/_assets/14-10-git-review.png', 'doc/upstream-training/13-launchpad.rst']",9,112efc2cd29d237f9910a93417c41efa90726a23,,- Most of the projects now manage blueprints on a git repo called specs,- Nova and Neutron manage blueprints on a git repo,11,26
openstack%2Fopenstacksdk~master~I7b1706cfac8ed93274042606794ca1438762f03a,openstack/openstacksdk,master,I7b1706cfac8ed93274042606794ca1438762f03a,Use meter_name as id for statistics,MERGED,2014-10-04 13:04:24.000000000,2014-10-06 22:44:44.000000000,2014-10-06 22:44:43.000000000,"[{'_account_id': 3}, {'_account_id': 7680}, {'_account_id': 8257}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-10-04 13:04:24.000000000', 'files': ['openstack/telemetry/v2/statistics.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/11d9df126a6208714f7a97db839b4bea213b3601', 'message': 'Use meter_name as id for statistics\n\nChange-Id: I7b1706cfac8ed93274042606794ca1438762f03a\n'}]",0,126142,11d9df126a6208714f7a97db839b4bea213b3601,7,4,1,8736,,,0,"Use meter_name as id for statistics

Change-Id: I7b1706cfac8ed93274042606794ca1438762f03a
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/42/126142/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/telemetry/v2/statistics.py'],1,11d9df126a6208714f7a97db839b4bea213b3601,meter_name, id_attribute = 'meter_name', @property def id(self): return None ,1,4
openstack%2Fglance~stable%2Ficehouse~I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945,openstack/glance,stable/icehouse,I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945,Do not log password in swift URLs in g-registry,MERGED,2014-08-07 00:45:57.000000000,2014-10-06 22:27:41.000000000,2014-10-06 22:27:41.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2537}, {'_account_id': 9656}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-08-07 00:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/12502be2ef6ebb4a21c289f99bf553b9c4ea6ea3', 'message': 'Do not log password in swift URLs in g-registry\n\nThere was a debug level log with the locations added to it.\nThis change fixes the log to not contain that sensitive info.\n\nBeing backported, original change at I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945\n\nFixes bug 1348838\n\nChange-Id: I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945\n'}, {'number': 2, 'created': '2014-09-25 11:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9fd932f163bbec750cb79308ab2378c722553cea', 'message': 'Do not log password in swift URLs in g-registry\n\nThere was a debug level log with the locations added to it.\nThis change fixes the log to not contain that sensitive info.\n\nFixes bug 1348838\n\nConflicts:\n\tglance/registry/api/v1/images.py\n\nChange-Id: I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945\n(cherry picked from commit 28fdfdbaca81adcc94d5e6d57c55f7c985d6c512)\n'}, {'number': 3, 'created': '2014-09-25 11:12:39.000000000', 'files': ['glance/registry/api/v1/images.py', 'glance/tests/unit/v1/test_registry_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/81ea399c7ac3ebfa70d607a3f374fac4e9819a8d', 'message': 'Do not log password in swift URLs in g-registry\n\nThere was a debug level log with the locations added to it.\nThis change fixes the log to not contain that sensitive info.\n\nFixes bug 1348838\n\nConflicts:\n\tglance/registry/api/v1/images.py\n\nNeeded changes for Icehouse:\n- use fixture.iteritems() instead of six.iteritems(fixture) in unit\n  tests.\n\nChange-Id: I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945\n(cherry picked from commit 28fdfdbaca81adcc94d5e6d57c55f7c985d6c512)\n'}]",0,112442,81ea399c7ac3ebfa70d607a3f374fac4e9819a8d,17,5,3,2537,,,0,"Do not log password in swift URLs in g-registry

There was a debug level log with the locations added to it.
This change fixes the log to not contain that sensitive info.

Fixes bug 1348838

Conflicts:
	glance/registry/api/v1/images.py

Needed changes for Icehouse:
- use fixture.iteritems() instead of six.iteritems(fixture) in unit
  tests.

Change-Id: I3c5b29616c8d76bed17dbd31a8f4fc7ccd2dd945
(cherry picked from commit 28fdfdbaca81adcc94d5e6d57c55f7c985d6c512)
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/112442/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/api/v1/images.py', 'glance/tests/unit/v1/test_registry_api.py']",2,12502be2ef6ebb4a21c289f99bf553b9c4ea6ea3,bug/1348838,"import mock @mock.patch.object(rserver.images.LOG, 'debug') def test_update_image_not_log_sensitive_info(self, log_debug): """""" Tests that there is no any sensitive info of image location was logged in glance during the image update operation. """""" def fake_log_debug(fmt_str, image_meta): self.assertNotIn(""'locations'"", fmt_str % image_meta) fixture = {'name': 'fake public image #2', 'min_disk': 5, 'min_ram': 256, 'disk_format': 'raw', 'location': 'fake://image'} body = jsonutils.dumps(dict(image=fixture)) log_debug.side_effect = fake_log_debug res = self.get_api_response_ext(200, url='/images/%s' % UUID2, body=body, method='PUT', content_type='json') res_dict = jsonutils.loads(res.body) self.assertNotEqual(res_dict['image']['created_at'], res_dict['image']['updated_at']) for k, v in fixture.iteritems(): self.assertEqual(v, res_dict['image'][k]) ",,36,3
openstack%2Foslo.db~master~I6f3a457e9d959cb6d208775c873547e78fafe210,openstack/oslo.db,master,I6f3a457e9d959cb6d208775c873547e78fafe210,Skip certain tests that use migrate when it's not available,ABANDONED,2014-10-04 04:11:40.000000000,2014-10-06 22:16:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-10-04 04:11:40.000000000', 'files': ['tests/sqlalchemy/test_migrate_cli.py', 'tests/sqlalchemy/test_migration_common.py', 'tests/utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e3d44a0b5616e3a2fb1329273e43e3ca198e683d', 'message': ""Skip certain tests that use migrate when it's not available\n\nTo move further toward py3.x support we need to skip certain\ntests that currently will not work for py3.x due to the usage\nof the migrate package (which still appears to not be/if ever\nready for py3.x)\n\nChange-Id: I6f3a457e9d959cb6d208775c873547e78fafe210\n""}]",1,126112,e3d44a0b5616e3a2fb1329273e43e3ca198e683d,4,2,1,1297,,,0,"Skip certain tests that use migrate when it's not available

To move further toward py3.x support we need to skip certain
tests that currently will not work for py3.x due to the usage
of the migrate package (which still appears to not be/if ever
ready for py3.x)

Change-Id: I6f3a457e9d959cb6d208775c873547e78fafe210
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/12/126112/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_migrate_cli.py', 'tests/sqlalchemy/test_migration_common.py', 'tests/utils.py']",3,e3d44a0b5616e3a2fb1329273e43e3ca198e683d,,try: import migrate # noqa MIGRATE_AVAILABLE = True except ImportError: MIGRATE_AVAILABLE = False ,,17,1
openstack%2Ftempest~master~Ic9f13cb51166c0907002b20ac3229ddb25740702,openstack/tempest,master,Ic9f13cb51166c0907002b20ac3229ddb25740702,Allows to specify disabled extension,ABANDONED,2014-08-21 22:41:25.000000000,2014-10-06 22:06:57.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-21 22:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/56f4f4653cd6429232abe2785f26e2d34a9c4980', 'message': 'Allows to specify disabled extension\n\nThis patch adds configuration options for disabling extensions\nfor the following services: compute, network, volume, and\nobject storage.\n\nThese new options will be used for skipping tests not only\naccording to enabled extensions, but also according to disabled\nones. This will simplify handling of situations where all\nextensions except a few ones should be enabled.\n\nPartially-implements: Blueprint branchless-tempest-extension\n\nChange-Id: Ic9f13cb51166c0907002b20ac3229ddb25740702\n'}, {'number': 2, 'created': '2014-08-26 13:38:40.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4328ce4ec83b909ec33c1a2a89bb9cc0cfdcf0d1', 'message': 'Allows to specify disabled extension\n\nThis patch adds configuration options for disabling extensions\nfor the following services: compute, network, volume, and\nobject storage.\n\nThese new options will be used for skipping tests not only\naccording to enabled extensions, but also according to disabled\nones. This will simplify handling of situations where all\nextensions except a few ones should be enabled.\n\nPartially-implements: Blueprint branchless-tempest-extension\n\nChange-Id: Ic9f13cb51166c0907002b20ac3229ddb25740702\n'}]",8,116121,4328ce4ec83b909ec33c1a2a89bb9cc0cfdcf0d1,20,5,2,261,,,0,"Allows to specify disabled extension

This patch adds configuration options for disabling extensions
for the following services: compute, network, volume, and
object storage.

These new options will be used for skipping tests not only
according to enabled extensions, but also according to disabled
ones. This will simplify handling of situations where all
extensions except a few ones should be enabled.

Partially-implements: Blueprint branchless-tempest-extension

Change-Id: Ic9f13cb51166c0907002b20ac3229ddb25740702
",git fetch https://review.opendev.org/openstack/tempest refs/changes/21/116121/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/test.py']",4,56f4f4653cd6429232abe2785f26e2d34a9c4980,bp/branchless-tempest-extensions," enabled_config_dict = { disabled_config_dict = { 'compute': CONF.compute_feature_disabled.api_extensions, 'compute_v3': CONF.compute_feature_disabled.api_v3_extensions, 'volume': CONF.volume_feature_disabled.api_extensions, 'network': CONF.network_feature_disabled.api_extensions, 'object': CONF.object_storage_feature_disabled.discoverable_apis, } if len(enabled_config_dict[service]) == 0: if extension_name in disabled_config_dict[service]: return False if enabled_config_dict[service][0] == 'all': if extension_name in enabled_config_dict[service]:", config_dict = { if len(config_dict[service]) == 0: if config_dict[service][0] == 'all': if extension_name in config_dict[service]:,147,23
openstack%2Fironic-specs~master~Ifa7bb3a207f2160c2e95b74dab7e2692aeea6ed1,openstack/ironic-specs,master,Ifa7bb3a207f2160c2e95b74dab7e2692aeea6ed1,Automate testing of template titles,MERGED,2014-10-03 17:18:31.000000000,2014-10-06 21:48:38.000000000,2014-10-06 21:48:38.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-10-03 17:18:31.000000000', 'files': ['tests/test_titles.py'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/75180f2772a8001871cda7c507278f2e7bd47170', 'message': 'Automate testing of template titles\n\nInstead of hard-coding the list of section titles in the unit test,\njust auto-generate it by reading the template.\n\nChange-Id: Ifa7bb3a207f2160c2e95b74dab7e2692aeea6ed1\n'}]",0,126019,75180f2772a8001871cda7c507278f2e7bd47170,7,3,1,2889,,,0,"Automate testing of template titles

Instead of hard-coding the list of section titles in the unit test,
just auto-generate it by reading the template.

Change-Id: Ifa7bb3a207f2160c2e95b74dab7e2692aeea6ed1
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/19/126019/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_titles.py'],1,75180f2772a8001871cda7c507278f2e7bd47170,update-template,"RELEASE = 'kilo' def _check_titles(self, filename, expect, actual): missing_sections = [x for x in expect.keys() if x not in actual.keys()] extra_sections = [x for x in actual.keys() if x not in expect.keys()] msgs = [] if len(missing_sections) > 0: msgs.append(""Missing sections: %s"" % missing_sections) if len(extra_sections) > 0: msgs.append(""Extra sections: %s"" % extra_sections) for section in expect.keys(): missing_subsections = [x for x in expect[section] if x not in actual[section]] # extra subsections are allowed if len(missing_subsections) > 0: msgs.append(""Section '%s' is missing subsections: %s"" % (section, missing_subsections)) if len(msgs) > 0: self.fail(""While checking '%s':\n %s"" % (filename, ""\n "".join(msgs))) def _check_trailing_spaces(self, tpl, raw): for i, line in enumerate(raw.split(""\n"")): trailing_spaces = re.findall("" +$"", line) self.assertEqual(len(trailing_spaces),0, ""Found trailing spaces on line %s of %s"" % (i+1, tpl)) def test_template(self): with open(""specs/template.rst"") as f: template = f.read() spec = docutils.core.publish_doctree(template) template_titles = self._get_titles(spec) files = glob.glob('specs/%s/*' % RELEASE) self._check_titles(filename, template_titles, titles) self._check_trailing_spaces(filename, data)"," def _check_titles(self, titles): self.assertEqual(8, len(titles)) problem = 'Problem description' self.assertIn(problem, titles) proposed = 'Proposed change' self.assertIn(proposed, titles) self.assertIn('Alternatives', titles[proposed]) self.assertIn('Data model impact', titles[proposed]) self.assertIn('REST API impact', titles[proposed]) self.assertIn('RPC API impact', titles[proposed]) self.assertIn('Driver API impact', titles[proposed]) self.assertIn('Nova driver impact', titles[proposed]) self.assertIn('Security impact', titles[proposed]) self.assertIn('Other end user impact', titles[proposed]) self.assertIn('Scalability impact', titles[proposed]) self.assertIn('Performance Impact', titles[proposed]) self.assertIn('Other deployer impact', titles[proposed]) self.assertIn('Developer impact', titles[proposed]) impl = 'Implementation' self.assertIn(impl, titles) self.assertIn('Assignee(s)', titles[impl]) self.assertIn('Work Items', titles[impl]) deps = 'Dependencies' self.assertIn(deps, titles) testing = 'Testing' self.assertIn(testing, titles) compat = 'Upgrades and Backwards Compatibility' self.assertIn(compat, titles) docs = 'Documentation Impact' self.assertIn(docs, titles) refs = 'References' self.assertIn(refs, titles) def test_template(self): files = ['specs/template.rst'] + glob.glob('specs/kilo/*') self._check_titles(titles)",36,38
openstack%2Fcongress~master~I6db3119330bcf9f695651bb59f1b5f56f6d9ea93,openstack/congress,master,I6db3119330bcf9f695651bb59f1b5f56f6d9ea93,Test commit,ABANDONED,2014-10-06 17:24:44.000000000,2014-10-06 21:39:00.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-06 17:24:44.000000000', 'files': ['a'], 'web_link': 'https://opendev.org/openstack/congress/commit/f17016576759b25c60b19a0122fce46540904e2d', 'message': 'Test commit\n\nChange-Id: I6db3119330bcf9f695651bb59f1b5f56f6d9ea93\n'}]",0,126367,f17016576759b25c60b19a0122fce46540904e2d,7,3,1,4395,,,0,"Test commit

Change-Id: I6db3119330bcf9f695651bb59f1b5f56f6d9ea93
",git fetch https://review.opendev.org/openstack/congress refs/changes/67/126367/1 && git format-patch -1 --stdout FETCH_HEAD,['a'],1,f17016576759b25c60b19a0122fce46540904e2d,,,,0,0
openstack%2Fcongress~master~I50b5a807935c41bdd12064ef8f085fd57cb12928,openstack/congress,master,I50b5a807935c41bdd12064ef8f085fd57cb12928,Trival whitespace cleanup,MERGED,2014-10-06 18:12:56.000000000,2014-10-06 21:32:08.000000000,2014-10-06 21:25:25.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 9253}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-06 18:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/846cff8879fd71e1ea8bfc85728b1bcbaa5a048b', 'message': 'Trival whitespace cleanup\n\nChange-Id: I50b5a807935c41bdd12064ef8f085fd57cb12928\n'}, {'number': 2, 'created': '2014-10-06 21:00:53.000000000', 'files': ['etc/datasources.conf.sample'], 'web_link': 'https://opendev.org/openstack/congress/commit/aae285bafb4ddec0b8fb154190ad4a34cdd7822a', 'message': 'Trival whitespace cleanup\n\nChange-Id: I50b5a807935c41bdd12064ef8f085fd57cb12928\n'}]",0,126378,aae285bafb4ddec0b8fb154190ad4a34cdd7822a,12,4,2,4395,,,0,"Trival whitespace cleanup

Change-Id: I50b5a807935c41bdd12064ef8f085fd57cb12928
",git fetch https://review.opendev.org/openstack/congress refs/changes/78/126378/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/datasources.conf.sample'],1,846cff8879fd71e1ea8bfc85728b1bcbaa5a048b,,,,0,2
openstack%2Fpython-openstackclient~master~I2b4c0e27c85b52e1eeb4ad959e3976d23c8fe896,openstack/python-openstackclient,master,I2b4c0e27c85b52e1eeb4ad959e3976d23c8fe896,Add functional swift tests for OSC,ABANDONED,2014-10-06 18:08:59.000000000,2014-10-06 21:27:56.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-06 18:08:59.000000000', 'files': ['functional/tests/test_object.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8a6b3596c16ce2df4af736f7128f2068f8d3aa41', 'message': 'Add functional swift tests for OSC\n\nChange-Id: I2b4c0e27c85b52e1eeb4ad959e3976d23c8fe896\n'}]",0,126376,8a6b3596c16ce2df4af736f7128f2068f8d3aa41,3,1,1,6482,,,0,"Add functional swift tests for OSC

Change-Id: I2b4c0e27c85b52e1eeb4ad959e3976d23c8fe896
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/76/126376/1 && git format-patch -1 --stdout FETCH_HEAD,['functional/tests/test_object.py'],1,8a6b3596c16ce2df4af736f7128f2068f8d3aa41,add_swift_func_tests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from functional.common import test class ObjectV1Tests(test.TestCase): """"""Functional tests for Object V1 commands. """""" def test_0container_list(self): raw_output = self.openstack('container list') self.assertEqual(0, len(raw_output)) def test_container_create(self): self.openstack('container create' + uuid.uuid4().hex) ",,26,0
openstack%2Fcongress~master~I00c51c40b9108987e2337c7e866b552e0209f730,openstack/congress,master,I00c51c40b9108987e2337c7e866b552e0209f730,Ceilometer should also connect as admin,MERGED,2014-10-06 20:58:06.000000000,2014-10-06 21:27:21.000000000,2014-10-06 21:22:56.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 9253}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-06 20:58:06.000000000', 'files': ['etc/datasources.conf.sample'], 'web_link': 'https://opendev.org/openstack/congress/commit/ce15d88890ee0719b4c91791135a6407b46d6eb3', 'message': 'Ceilometer should also connect as admin\n\nChange-Id: I00c51c40b9108987e2337c7e866b552e0209f730\n'}]",0,126415,ce15d88890ee0719b4c91791135a6407b46d6eb3,8,4,1,4395,,,0,"Ceilometer should also connect as admin

Change-Id: I00c51c40b9108987e2337c7e866b552e0209f730
",git fetch https://review.opendev.org/openstack/congress refs/changes/15/126415/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/datasources.conf.sample'],1,ce15d88890ee0719b4c91791135a6407b46d6eb3,,username: admintenant_name: admin,username: demotenant_name: demo,2,2
openstack%2Fkolla~master~Icf70b33080ef19643f133f2b6f60087c524bd4fb,openstack/kolla,master,Icf70b33080ef19643f133f2b6f60087c524bd4fb,fix issues with build-docker-image,MERGED,2014-10-05 04:04:02.000000000,2014-10-06 21:15:36.000000000,2014-10-06 21:15:36.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6348}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-05 04:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4b010e4cd7cf9d449a2a71ce84606aa0b43a4545', 'message': ""fix typo in --namespace option\n\nbuild-docker-image had a missing '$' in the code that handled the\n--namespace option.\n\nChange-Id: Icf70b33080ef19643f133f2b6f60087c524bd4fb\n""}, {'number': 2, 'created': '2014-10-06 01:30:01.000000000', 'files': ['tools/build-docker-image'], 'web_link': 'https://opendev.org/openstack/kolla/commit/cf9440005a3ff067666e898a9b6b0d44a98a0516', 'message': ""fix issues with build-docker-image\n\n- fix typo in --namespace option\n\n    build-docker-image had a missing '$' in the code that handled the\n    --namespace option.\n\n- force builds to kollaglue namespace with 'latest' tag to use\n  the --release flag\n\n- build IMAGE after config and options processing to permit overriding\n  PREFIX in .buildconf\n\nChange-Id: Icf70b33080ef19643f133f2b6f60087c524bd4fb\n""}]",0,126174,cf9440005a3ff067666e898a9b6b0d44a98a0516,10,4,2,8745,,,0,"fix issues with build-docker-image

- fix typo in --namespace option

    build-docker-image had a missing '$' in the code that handled the
    --namespace option.

- force builds to kollaglue namespace with 'latest' tag to use
  the --release flag

- build IMAGE after config and options processing to permit overriding
  PREFIX in .buildconf

Change-Id: Icf70b33080ef19643f133f2b6f60087c524bd4fb
",git fetch https://review.opendev.org/openstack/kolla refs/changes/74/126174/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-docker-image'],1,4b010e4cd7cf9d449a2a71ce84606aa0b43a4545,larsks/fixbuild," NAMESPACE=""$1"""," NAMESPACE=""1""",1,1
openstack%2Fkolla~master~I02cc56c6205a411a3f042b65ccfb9624795c13d2,openstack/kolla,master,I02cc56c6205a411a3f042b65ccfb9624795c13d2,Remove whitespace errors in mariadb JSON,MERGED,2014-10-03 16:57:39.000000000,2014-10-06 21:03:46.000000000,2014-10-06 21:03:46.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 5792}, {'_account_id': 6348}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-03 16:57:39.000000000', 'files': ['docker/mariadb/mariadb.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6a8eb99608dc99a3b560dc5bee653fd53872608d', 'message': 'Remove whitespace errors in mariadb JSON\n\nJSON should not introduce whitespace errors\n\nChange-Id: I02cc56c6205a411a3f042b65ccfb9624795c13d2\n'}]",0,126018,6a8eb99608dc99a3b560dc5bee653fd53872608d,9,5,1,2834,,,0,"Remove whitespace errors in mariadb JSON

JSON should not introduce whitespace errors

Change-Id: I02cc56c6205a411a3f042b65ccfb9624795c13d2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/18/126018/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/mariadb/mariadb.json'],1,6a8eb99608dc99a3b560dc5bee653fd53872608d,,,,0,1
openstack%2Fproject-config~master~Iac45738ba7b8148e4d98153da6fba355adced66d,openstack/project-config,master,Iac45738ba7b8148e4d98153da6fba355adced66d,Add bashate job to sahara-image-elements,MERGED,2014-10-03 22:00:52.000000000,2014-10-06 20:58:55.000000000,2014-10-06 20:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 7710}]","[{'number': 1, 'created': '2014-10-03 22:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/25780004e020e43dc6eb095b3106e1d77303781d', 'message': 'Add bashate job to sahara-image-elements\n\nChange-Id: Iac45738ba7b8148e4d98153da6fba355adced66d\n'}, {'number': 2, 'created': '2014-10-04 19:38:20.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e9b8776dd7704ee45ba0a33a45dfbc0e6886ed95', 'message': 'Add bashate job to sahara-image-elements\n\nChange-Id: Iac45738ba7b8148e4d98153da6fba355adced66d\n'}]",0,126085,e9b8776dd7704ee45ba0a33a45dfbc0e6886ed95,16,6,2,6786,,,0,"Add bashate job to sahara-image-elements

Change-Id: Iac45738ba7b8148e4d98153da6fba355adced66d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/126085/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,25780004e020e43dc6eb095b3106e1d77303781d,126085, - name: gate-sahara-image-elements-bashate voting: false - gate-sahara-image-elements-bashate,,4,0
openstack%2Fproject-config~master~Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a,openstack/project-config,master,Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a,Add buildimages job for Sahara,MERGED,2014-10-02 18:16:26.000000000,2014-10-06 20:57:24.000000000,2014-10-06 20:57:23.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-10-02 18:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a954913556d349e6283e47e454abdceeb488a0d3', 'message': ""Add buildimages job for Sahara\n\nIt's only in check pipeline, non-voting and for master branch.\n\nChange-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a\n""}, {'number': 2, 'created': '2014-10-02 18:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2339bd22e6e2df3c8befb1be8a8eac7609043a66', 'message': ""Add buildimages job for Sahara\n\nIt's only in check pipeline, non-voting and for master branch.\n\nChange-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a\n""}, {'number': 3, 'created': '2014-10-02 20:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4cd6856017593928d18957515753d0f6096429b2', 'message': ""Add buildimages job for Sahara\n\nIt's only in check pipeline, non-voting and for master branch.\n\nChange-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a\n""}, {'number': 4, 'created': '2014-10-03 21:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9386c082325bb7887078bca29b560aca4ddc5ef9', 'message': ""Add buildimages job for Sahara\n\nIt's only in check pipeline, non-voting and for master branch.\n\nChange-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a\n""}, {'number': 5, 'created': '2014-10-04 19:38:20.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/sahara.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f3caab5b5e61bddf8e646fd4217bc3cdddd9583e', 'message': ""Add buildimages job for Sahara\n\nIt's only in check pipeline, non-voting and for master branch.\n\nChange-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a\n""}]",2,125729,f3caab5b5e61bddf8e646fd4217bc3cdddd9583e,20,6,5,6786,,,0,"Add buildimages job for Sahara

It's only in check pipeline, non-voting and for master branch.

Change-Id: Ib2bb2ce5f60de733cecde0396dbc1b00e692dc5a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/29/125729/5 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/sahara.yaml']",3,a954913556d349e6283e47e454abdceeb488a0d3,126085,- job-template: name: 'check-sahara-buildimages-{plugin}' node: bare-trusty builders: - link-logs - net-info - gerrit-git-prep - sahara-buildimage - shell: | #!/bin/bash -xe sudo mkdir -p /opt/sahara-image-build sudo chown $(whoami) /opt/sahara-image-build export DEST=/opt/sahara-image-build ./tools/gate/build-images {plugin} publishers: - console-log ,,22,0
openstack%2Fsahara~stable%2Ficehouse~Ifcafbfedb8c29b1f76a4e1387d08817661cb4259,openstack/sahara,stable/icehouse,Ifcafbfedb8c29b1f76a4e1387d08817661cb4259,[DO NOT MERGE] Test commit,ABANDONED,2014-09-29 20:09:19.000000000,2014-10-06 20:54:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-09-29 20:09:19.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4bae3cc7e048f851209bc12ccca48d8fcf5390d2', 'message': '[DO NOT MERGE] Test commit\n\nChange-Id: Ifcafbfedb8c29b1f76a4e1387d08817661cb4259\n'}]",0,124855,4bae3cc7e048f851209bc12ccca48d8fcf5390d2,17,5,1,6786,,,0,"[DO NOT MERGE] Test commit

Change-Id: Ifcafbfedb8c29b1f76a4e1387d08817661cb4259
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/124855/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4bae3cc7e048f851209bc12ccca48d8fcf5390d2,,DO NOT MERGE ,,2,0
openstack%2Fsahara~proposed%2Fjuno~Ifcafbfedb8c29b1f76a4e1387d08817661cb4259,openstack/sahara,proposed/juno,Ifcafbfedb8c29b1f76a4e1387d08817661cb4259,[DO NOT MERGE] Test commit,ABANDONED,2014-10-05 21:08:29.000000000,2014-10-06 20:54:35.000000000,,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-05 21:08:29.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/dda06317a680eb655a9858660768d0a7b90cf928', 'message': '[DO NOT MERGE] Test commit\n\nChange-Id: Ifcafbfedb8c29b1f76a4e1387d08817661cb4259\n'}]",0,126202,dda06317a680eb655a9858660768d0a7b90cf928,7,4,1,6786,,,0,"[DO NOT MERGE] Test commit

Change-Id: Ifcafbfedb8c29b1f76a4e1387d08817661cb4259
",git fetch https://review.opendev.org/openstack/sahara refs/changes/02/126202/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,dda06317a680eb655a9858660768d0a7b90cf928,,DO NOT MERGE ,,2,0
openstack%2Fopenstacksdk~master~I6c2789c08012d1e2df4f254cb3ca26d37c302964,openstack/openstacksdk,master,I6c2789c08012d1e2df4f254cb3ca26d37c302964,Add find command to the examples,MERGED,2014-09-20 12:11:44.000000000,2014-10-06 20:24:02.000000000,2014-10-06 20:24:00.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-09-20 12:11:44.000000000', 'files': ['examples/find.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8ce791f26e29e5e36e1715abb469b28dec3463c3', 'message': 'Add find command to the examples\n\nChange-Id: I6c2789c08012d1e2df4f254cb3ca26d37c302964\n'}]",0,122944,8ce791f26e29e5e36e1715abb469b28dec3463c3,7,3,1,8736,,,0,"Add find command to the examples

Change-Id: I6c2789c08012d1e2df4f254cb3ca26d37c302964
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/44/122944/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/find.py'],1,8ce791f26e29e5e36e1715abb469b28dec3463c3,find,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Example Find Command For example: python -m examples.find openstack/network/v2_0/network.py \ --data '{""id"": ""a1369557-748f-429c-bd3e-fc385aacaec7""}' """""" import sys from examples import common from examples import session def run_find(opts): sess = session.make_session(opts) cls = common.find_resource_cls(opts) obj = cls.find(sess, opts.data) print(str(obj)) return if __name__ == ""__main__"": opts = common.setup() sys.exit(common.main(opts, run_find)) ",,37,0
openstack%2Ftripleo-image-elements~master~Ic89379eca8699b27a4b89de9da3fc4f56011963e,openstack/tripleo-image-elements,master,Ic89379eca8699b27a4b89de9da3fc4f56011963e,Allow custom root labels,MERGED,2014-09-16 18:29:06.000000000,2014-10-06 20:11:10.000000000,2014-10-06 20:11:10.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7471}, {'_account_id': 7585}, {'_account_id': 8399}]","[{'number': 1, 'created': '2014-09-16 18:29:06.000000000', 'files': ['elements/localboot/cleanup.d/99-adjust-grub-conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/407a99f063994a50b7891e1a782b845c0c866e90', 'message': 'Allow custom root labels\n\nMakes the localboot element aware of the custom root fs labels\nadded in I596104d1a63b5dc6549e8460a1ae3da00165ef04 for\ndiskimage-builder.  That change must merge before this one.\n\nChange-Id: Ic89379eca8699b27a4b89de9da3fc4f56011963e\n'}]",0,121945,407a99f063994a50b7891e1a782b845c0c866e90,17,7,1,6928,,,0,"Allow custom root labels

Makes the localboot element aware of the custom root fs labels
added in I596104d1a63b5dc6549e8460a1ae3da00165ef04 for
diskimage-builder.  That change must merge before this one.

Change-Id: Ic89379eca8699b27a4b89de9da3fc4f56011963e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/45/121945/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/localboot/cleanup.d/99-adjust-grub-conf'],1,407a99f063994a50b7891e1a782b845c0c866e90,root-label," sed -i ""s,${parm#root=},LABEL=${DIB_ROOT_LABEL},g"" $BOOTDIR/grub/grub.conf"," sed -i ""s,${parm#root=},LABEL=cloudimg-rootfs,g"" $BOOTDIR/grub/grub.conf",1,1
openstack%2Fcongress~master~Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13,openstack/congress,master,Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13,Data source driver for ceilometer,MERGED,2014-09-16 17:30:41.000000000,2014-10-06 19:53:04.000000000,2014-10-06 19:53:04.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9008}, {'_account_id': 12293}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-09-16 17:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/67fc7409b1a2111b5a6d3bdd4b7d32c6caf4ca7a', 'message': 'Initial commit for Ceilometer driver\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 2, 'created': '2014-09-17 05:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5e1718bd449ec1734ccef2fede3afaa72ef34e83', 'message': 'Initial commit for Ceilometer driver\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 3, 'created': '2014-09-30 06:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/13e1fb063003a8b2d77726c25fdd81d8f94555d5', 'message': 'Initial commit for Ceilometer driver\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 4, 'created': '2014-09-30 07:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/79a1adee0bb48a13e8e8b04c203b0599a08a587f', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 5, 'created': '2014-09-30 07:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/87b85af8550db0e45cd6e8108de5322537c417b8', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 6, 'created': '2014-09-30 10:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1eebccc18e78f941fe9a4d22a28a3ba80d80c823', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 7, 'created': '2014-09-30 13:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3a8328542d8e3557d3579b89d5e971c95da0cd39', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 8, 'created': '2014-09-30 19:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/128f22f6f557ce3c9b5fb0c40155f5fe7a19175d', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 9, 'created': '2014-10-01 05:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3f9a7e211e685edc33a474c128cfa4b0a219077d', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}, {'number': 10, 'created': '2014-10-04 09:59:31.000000000', 'files': ['congress/datasources/tests/unit/test_ceilometer_driver.py', 'requirements.txt', 'congress/datasources/tests/unit/util.py', 'etc/datasources.conf.sample', 'congress/datasources/ceilometer_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/ab03f13d4e9126560e63c19f15ef824838ab1a6d', 'message': 'Data source driver for ceilometer\n\nThe driver provides 3 lists :\n1. Meters\n2. Alarms\n3. Events\nThe patch also includes test for the above lists.\n\nChange-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13\n'}]",17,121933,ab03f13d4e9126560e63c19f15ef824838ab1a6d,47,6,10,12293,,,0,"Data source driver for ceilometer

The driver provides 3 lists :
1. Meters
2. Alarms
3. Events
The patch also includes test for the above lists.

Change-Id: Iab4f96fdf3f21ec6fab06f08aeaf3eb96bcf4d13
",git fetch https://review.opendev.org/openstack/congress refs/changes/33/121933/8 && git format-patch -1 --stdout FETCH_HEAD,"['etc/datasources.conf.sample', 'congress/datasources/ceilometer_driver.py', 'congress/datasources/settings.py']",3,67fc7409b1a2111b5a6d3bdd4b7d32c6caf4ca7a,datasource_driver/ceilometer,"OS_CEILOMETER_URL = ""http://127.0.0.1:8777/""",,162,0
openstack%2Fnova~master~I07fa1a5d53708f33b68a49186dbc5db15a1dbf17,openstack/nova,master,I07fa1a5d53708f33b68a49186dbc5db15a1dbf17,Break out quota refresh check code from quota_reserve(),MERGED,2014-09-15 21:23:52.000000000,2014-10-06 19:39:03.000000000,2014-10-06 19:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 21:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b5dea5081b9324bebafde2184bea725fed6f4b1', 'message': 'Break out quota refresh check code from quota_reserve()\n\nThis moves the logic that is checking if a quota refresh is needed into\na private method.\n\nThis is part of a larger series to refactor the quota_reserve method.\n\nPartial-Bug: #1369605\n\nChange-Id: I07fa1a5d53708f33b68a49186dbc5db15a1dbf17\n'}, {'number': 2, 'created': '2014-10-03 21:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6a9528d28e553e622e8ead0c3dd2716ef799e34', 'message': 'Break out quota refresh check code from quota_reserve()\n\nThis moves the logic that is checking if a quota refresh is needed into\na private method.\n\nThis is part of a larger series to refactor the quota_reserve method.\n\nPartial-Bug: #1369605\n\nChange-Id: I07fa1a5d53708f33b68a49186dbc5db15a1dbf17\n'}, {'number': 3, 'created': '2014-10-04 21:38:05.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9de8c0eb009d8c260b4102b1325421bcbad0a47e', 'message': 'Break out quota refresh check code from quota_reserve()\n\nThis moves the logic that is checking if a quota refresh is needed into\na private method.\n\nThis is part of a larger series to refactor the quota_reserve method.\n\nPartial-Bug: #1369605\n\nChange-Id: I07fa1a5d53708f33b68a49186dbc5db15a1dbf17\n'}]",5,121671,9de8c0eb009d8c260b4102b1325421bcbad0a47e,23,9,3,6873,,,0,"Break out quota refresh check code from quota_reserve()

This moves the logic that is checking if a quota refresh is needed into
a private method.

This is part of a larger series to refactor the quota_reserve method.

Partial-Bug: #1369605

Change-Id: I07fa1a5d53708f33b68a49186dbc5db15a1dbf17
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/121671/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,8b5dea5081b9324bebafde2184bea725fed6f4b1,bug/1369605,"def _is_quota_refresh_needed(user_usages, resource, until_refresh, max_age, project_id, user_id, session): """"""Determines if a quota usage refresh is needed. :param user_usages: dict of resource keys to QuotaUsage records. This may be updated if resource is not in user_usages yet or until_refresh is not None. :param resource: The resource being checked for quota usage. :param until_refresh: Count of reservations until usage is refreshed, int or None :param max_age: Number of seconds between subsequent usage refreshes. :param project_id: The project being checked for quota usage. :param user_id: The user being checked for quota usage. :param session: DB session holding a transaction lock. :return: True if a refresh is needed, False otherwise. """""" refresh = False if resource not in user_usages: user_id_to_use = user_id if resource in PER_PROJECT_QUOTAS: user_id_to_use = None user_usages[resource] = _quota_usage_create( project_id, user_id_to_use, resource, 0, 0, until_refresh or None, session=session) refresh = True elif user_usages[resource].in_use < 0: # Negative in_use count indicates a desync, so try to # heal from that... refresh = True elif user_usages[resource].until_refresh is not None: user_usages[resource].until_refresh -= 1 if user_usages[resource].until_refresh <= 0: refresh = True elif max_age and (timeutils.utcnow() - user_usages[resource].updated_at).seconds >= max_age: refresh = True return refresh refresh = _is_quota_refresh_needed( user_usages, resource, until_refresh, max_age, project_id, user_id, session)"," refresh = False if ((resource not in PER_PROJECT_QUOTAS) and (resource not in user_usages)): user_usages[resource] = _quota_usage_create( project_id, user_id, resource, 0, 0, until_refresh or None, session=session) refresh = True elif ((resource in PER_PROJECT_QUOTAS) and (resource not in user_usages)): user_usages[resource] = _quota_usage_create( project_id, None, resource, 0, 0, until_refresh or None, session=session) refresh = True elif user_usages[resource].in_use < 0: # Negative in_use count indicates a desync, so try to # heal from that... refresh = True elif user_usages[resource].until_refresh is not None: user_usages[resource].until_refresh -= 1 if user_usages[resource].until_refresh <= 0: refresh = True elif max_age and (timeutils.utcnow() - user_usages[resource].updated_at).seconds >= max_age: refresh = True",47,32
openstack%2Fdevstack~master~Id1b52529001319eaf41321118ab560711c752003,openstack/devstack,master,Id1b52529001319eaf41321118ab560711c752003,fix olso != oslo typos,MERGED,2014-10-03 12:04:31.000000000,2014-10-06 19:23:00.000000000,2014-10-03 16:38:09.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 12:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5fdeec005b69bf43e63971f733884d8ad57a0c31', 'message': ""fix olso != oslo typos\n\nApparently oslo is the hardest word in the world for me to understand\nthat I didn't spell correctly.\n\nChange-Id: Id1b52529001319eaf41321118ab560711c752003\n""}, {'number': 2, 'created': '2014-10-03 12:05:44.000000000', 'files': ['lib/oslo', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7cda389376ed6996f84122fb7b021cf8c6b5007', 'message': ""fix olso != oslo typos\n\nApparently oslo is the hardest word in the world for me to understand\nthat I didn't spell correctly.\n\nChange-Id: Id1b52529001319eaf41321118ab560711c752003\n""}]",0,125946,b7cda389376ed6996f84122fb7b021cf8c6b5007,11,5,2,2750,,,0,"fix olso != oslo typos

Apparently oslo is the hardest word in the world for me to understand
that I didn't spell correctly.

Change-Id: Id1b52529001319eaf41321118ab560711c752003
",git fetch https://review.opendev.org/openstack/devstack refs/changes/46/125946/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/oslo', 'stackrc']",2,5fdeec005b69bf43e63971f733884d8ad57a0c31,released_libs,"GITBRANCH[""oslo.concurrency""]=${OSLOCON_BRANCH:-master}GITREPO[""oslo.db""]=${OSLODB_REPO:-${GIT_BASE}/openstack/oslo.db.git} GITBRANCH[""oslo.db""]=${OSLODB_BRANCH:-master}GITREPO[""oslo.i18n""]=${OSLOI18N_REPO:-${GIT_BASE}/openstack/oslo.i18n.git} GITBRANCH[""oslo.i18n""]=${OSLOI18N_BRANCH:-master}GITREPO[""oslo.log""]=${OSLOLOG_REPO:-${GIT_BASE}/openstack/oslo.log.git} GITBRANCH[""oslo.log""]=${OSLOLOG_BRANCH:-master}GITREPO[""oslo.messaging""]=${OSLOMSG_REPO:-${GIT_BASE}/openstack/oslo.messaging.git} GITBRANCH[""oslo.messaging""]=${OSLOMSG_BRANCH:-master}GITREPO[""oslo.rootwrap""]=${OSLORWRAP_REPO:-${GIT_BASE}/openstack/oslo.rootwrap.git} GITBRANCH[""oslo.rootwrap""]=${OSLORWRAP_BRANCH:-master}GITREPO[""oslo.serialization""]=${OSLOSERIALIZATION_REPO:-${GIT_BASE}/openstack/oslo.serialization.git} GITBRANCH[""oslo.serialization""]=${OSLOSERIALIZATION_BRANCH:-master}GITREPO[""oslo.utils""]=${OSLOUTILS_REPO:-${GIT_BASE}/openstack/oslo.utils.git} GITBRANCH[""oslo.utils""]=${OSLOUTILS_BRANCH:-master}GITREPO[""oslo.vmware""]=${OSLOVMWARE_REPO:-${GIT_BASE}/openstack/oslo.vmware.git} GITBRANCH[""oslo.vmware""]=${OSLOVMWARE_BRANCH:-master}","GITBRANCH[""olso.concurrency""]=${OSLOCON_BRANCH:-master}GITREPO[""olso.db""]=${OSLODB_REPO:-${GIT_BASE}/openstack/oslo.db.git} GITBRANCH[""olso.db""]=${OSLODB_BRANCH:-master}GITREPO[""olso.i18n""]=${OSLOI18N_REPO:-${GIT_BASE}/openstack/oslo.i18n.git} GITBRANCH[""olso.i18n""]=${OSLOI18N_BRANCH:-master}GITREPO[""olso.log""]=${OSLOLOG_REPO:-${GIT_BASE}/openstack/oslo.log.git} GITBRANCH[""olso.log""]=${OSLOLOG_BRANCH:-master}GITREPO[""olso.messaging""]=${OSLOMSG_REPO:-${GIT_BASE}/openstack/oslo.messaging.git} GITBRANCH[""olso.messaging""]=${OSLOMSG_BRANCH:-master}GITREPO[""olso.rootwrap""]=${OSLORWRAP_REPO:-${GIT_BASE}/openstack/oslo.rootwrap.git} GITBRANCH[""olso.rootwrap""]=${OSLORWRAP_BRANCH:-master}GITREPO[""olso.serialization""]=${OSLOSERIALIZATION_REPO:-${GIT_BASE}/openstack/oslo.serialization.git} GITBRANCH[""olso.serialization""]=${OSLOSERIALIZATION_BRANCH:-master}GITREPO[""olso.utils""]=${OSLOUTILS_REPO:-${GIT_BASE}/openstack/oslo.utils.git} GITBRANCH[""olso.utils""]=${OSLOUTILS_BRANCH:-master}GITREPO[""olso.vmware""]=${OSLOVMWARE_REPO:-${GIT_BASE}/openstack/oslo.vmware.git} GITBRANCH[""olso.vmware""]=${OSLOVMWARE_BRANCH:-master}",18,18
openstack%2Fmagnetodb~master~Ib58d1433dd546f1472129b669f14a1b689647e1d,openstack/magnetodb,master,Ib58d1433dd546f1472129b669f14a1b689647e1d,Handle non-existent item when calling update_item,MERGED,2014-09-25 03:54:16.000000000,2014-10-06 19:22:30.000000000,2014-10-06 19:22:30.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8188}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-09-25 03:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/98fb63efbd95289c5c62586e562e94878ff6a6ea', 'message': 'Closes-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 2, 'created': '2014-09-25 21:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/678702bec1e877c021f779b14eace79d8f567753', 'message': 'Handle non existent item when calling update_item\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 3, 'created': '2014-09-26 01:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/12b186b5441bf3ca375ce1209b80f22c562fe619', 'message': 'Handle non existent item when calling update_item\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 4, 'created': '2014-09-26 20:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/4257ac9ad1b497fbfd7ac892a9e2df46728670ac', 'message': 'Handle non-existent item when calling update_item\n\nIf update_item action is ADD or PUT, a new item will\nbe created. If action is DELETE, no operation will be\nperformed and a success response will be returned.\n\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 5, 'created': '2014-09-26 21:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/d0efd8f27fad0462dfb83296cd4703f1a644cc2d', 'message': 'Handle non-existent item when calling update_item\n\nIf update_item action is ADD or PUT, a new item will\nbe created if expected conditions are satisfied. Otherwise\nConditionalCheckFailedException will be thrown. If\naction is DELETE, no operation will be performed and\na success response will be returned.\n\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 6, 'created': '2014-09-30 14:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/fa67f471a1935abaab389e678a3fcbcd3a741ab5', 'message': 'Handle non-existent item when calling update_item\n\nIf update_item action(s) is(are) ADD and/or PUT, a new item\nwill be created if expected conditions are satisfied. Otherwise\nConditionalCheckFailedException will be thrown. If\naction(s) is(are) DELETE only, no operation will be performed\nand a success response will be returned.\n\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}, {'number': 7, 'created': '2014-09-30 22:12:18.000000000', 'files': ['magnetodb/storage/driver/cassandra/cassandra_impl.py', 'tempest/api/keyvalue/stable/rest/test_update_item.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/0e0fb8091e50b06f86166b73a8541efd1fb8ec2d', 'message': 'Handle non-existent item when calling update_item\n\nIf update_item action(s) is(are) ADD and/or PUT, a new item\nwill be created if expected conditions are satisfied. Otherwise\nConditionalCheckFailedException will be thrown. If\naction(s) is(are) DELETE only, no operation will be performed\nand a success response will be returned.\n\nCloses-Bug: #1373627\n\nChange-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d\n'}]",10,123927,0e0fb8091e50b06f86166b73a8541efd1fb8ec2d,35,6,7,11006,,,0,"Handle non-existent item when calling update_item

If update_item action(s) is(are) ADD and/or PUT, a new item
will be created if expected conditions are satisfied. Otherwise
ConditionalCheckFailedException will be thrown. If
action(s) is(are) DELETE only, no operation will be performed
and a success response will be returned.

Closes-Bug: #1373627

Change-Id: Ib58d1433dd546f1472129b669f14a1b689647e1d
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/27/123927/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnetodb/storage/driver/cassandra/cassandra_impl.py', 'tempest/api/keyvalue/stable/rest/test_update_item.py']",2,98fb63efbd95289c5c62586e562e94878ff6a6ea,bug/1373627,"# Copyright 2014 Symantec Corporation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the 'License'); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an 'AS IS' BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import random import string from tempest.api.keyvalue.rest_base.base import MagnetoDBTestCase from tempest.common.utils.data_utils import rand_name class MagnetoDBUpdateItemTest(MagnetoDBTestCase): @classmethod def setUpClass(cls): super(MagnetoDBUpdateItemTest, cls).setUpClass() def random_name(self, length): return ''.join(random.choice(string.lowercase + string.digits) for i in range(length)) def test_update_item_non_existent_item(self): self.table_name = rand_name().replace('-', '') self._create_test_table( [{'attribute_name': 'ForumName', 'attribute_type': 'S'}, {'attribute_name': 'Subject', 'attribute_type': 'S'}], self.table_name, [{'attribute_name': 'ForumName', 'key_type': 'HASH'}], wait_for_active=True) key = { ""ForumName"": { ""S"": ""forum name"" } } attribute_updates = { ""Tags"": { ""action"": ""ADD"", ""value"": { ""SS"": [""tag set value""] } } } update_resp = self.client.update_item(self, self.table_name, key, attribute_updates, expected=None, time_to_live=None, return_values=None) self.assertEqual(update_resp[1], {}) get_resp = self.client.get_item(self.table_name, {""ForumName"": {""S"": 'forum name'}}, consistent_read=True) self.assertEqual(get_resp[1]['item']['ForumName'], {'S': 'forum name'}) self.assertEqual(get_resp[1]['item']['Tags'], {'SS': ['tag set value']}) ",,72,5
openstack%2Fnova~master~I5608b9eec625452edda9a0c9eb366ece2a95800f,openstack/nova,master,I5608b9eec625452edda9a0c9eb366ece2a95800f,Ironic: Do not try to unplug VIF if not associated,MERGED,2014-09-26 12:57:19.000000000,2014-10-06 19:18:34.000000000,2014-10-06 19:18:31.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-09-26 12:57:19.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3acac0f5bffca59441d9a4a12c89db1d45ec4cf', 'message': 'Ironic: Do not try to unplug VIF if not associated\n\nDuring instance spawn, Ironic attempts to unplug any plugged VIFs from\nports associated with an instance. If there are no associated VIFs\nto unplug, this would raise an exeception that would be logged into\nn-cpu. This patch fix that behavior by making the driver check if the\nport has an VIF associated with it before trying to remove it.\n\nChange-Id: I5608b9eec625452edda9a0c9eb366ece2a95800f\nCloses-Bug: #1292733\n'}]",3,124394,d3acac0f5bffca59441d9a4a12c89db1d45ec4cf,9,5,1,6773,,,0,"Ironic: Do not try to unplug VIF if not associated

During instance spawn, Ironic attempts to unplug any plugged VIFs from
ports associated with an instance. If there are no associated VIFs
to unplug, this would raise an exeception that would be logged into
n-cpu. This patch fix that behavior by making the driver check if the
port has an VIF associated with it before trying to remove it.

Change-Id: I5608b9eec625452edda9a0c9eb366ece2a95800f
Closes-Bug: #1292733
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/124394/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/virt/ironic/test_driver.py']",2,d3acac0f5bffca59441d9a4a12c89db1d45ec4cf,bug/1292733-no-VIF-associated," port = ironic_utils.get_test_port(extra={'vif_port_id': 'fake-vif'}) mock_node.list_ports.assert_called_once_with(node_uuid, detail=True) @mock.patch.object(FAKE_CLIENT, 'node') def test_unplug_vifs_port_not_associated(self, mock_node, mock_update): node_uuid = 'aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee' node = ironic_utils.get_test_node(uuid=node_uuid) port = ironic_utils.get_test_port(extra={}) mock_node.get.return_value = node mock_node.list_ports.return_value = [port] instance = fake_instance.fake_instance_obj(self.ctx, node=node_uuid) self.driver.unplug_vifs(instance, utils.get_test_network_info()) mock_node.get.assert_called_once_with(node_uuid) mock_node.list_ports.assert_called_once_with(node_uuid, detail=True) # assert port.update() was not called self.assertFalse(mock_update.called) @mock.patch.object(FAKE_CLIENT.port, 'update')", port = ironic_utils.get_test_port() mock_node.list_ports.assert_called_once_with(node_uuid),27,9
openstack%2Ftaskflow~master~I3fc1819df8fb42d0c3d394bbc7d047b09152af68,openstack/taskflow,master,I3fc1819df8fb42d0c3d394bbc7d047b09152af68,Avoid usage of six.moves in local functions,MERGED,2014-10-04 21:24:19.000000000,2014-10-06 19:17:45.000000000,2014-10-06 19:17:44.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-10-04 21:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/40312694f16d90fb9720b57b3593686e70e01f81', 'message': ""Avoid usage of six.moves in local functions\n\nCurrently it appears that using six.moves in threaded code isn't\nworking as expected (something there in six does not appear to\nbe thread safe) so until this is fixed avoid using those moves\nfunctions in the examples and in the utility code (and instead\nimport the moved function at the top of the module in utility\ncode to avoid any thread usage problems).\n\nUpstream bug filed at:\n\nhttps://bitbucket.org/gutworth/six/issue/98/\n\nFixes bug 1377514\n\nChange-Id: I3fc1819df8fb42d0c3d394bbc7d047b09152af68\n""}, {'number': 2, 'created': '2014-10-05 03:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e4964fca7d8e6b31ebe3c64177567010afe8cb5b', 'message': ""Avoid usage of six.moves in local functions\n\nCurrently it appears that using six.moves in threaded code isn't\nworking as expected (something there in six does not appear to\nbe thread safe) so until this is fixed avoid using those moves\nfunctions in the examples and in the utility code (and instead\nimport the moved function at the top of the module in utility\ncode to avoid any thread usage problems).\n\nUpstream bug filed at:\n\nhttps://bitbucket.org/gutworth/six/issue/98/\n\nFixes bug 1377514\n\nChange-Id: I3fc1819df8fb42d0c3d394bbc7d047b09152af68\n""}, {'number': 3, 'created': '2014-10-05 04:41:46.000000000', 'files': ['taskflow/utils/kazoo_utils.py', 'taskflow/examples/wbe_mandelbrot.py', 'taskflow/utils/misc.py', 'tox.ini', 'taskflow/examples/jobboard_produce_consume_colors.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/27badfc314d31c6932993b117e3c12d9eb7f064f', 'message': ""Avoid usage of six.moves in local functions\n\nCurrently it appears that using six.moves in threaded code isn't\nworking as expected (something there in six does not appear to\nbe thread safe) so until this is fixed avoid using those moves\nin functions in the examples and in the utility code (and instead\nimport the moved function at the top of the module in code to\navoid any threaded usage problems).\n\nUpstream bug filed at:\n\nhttps://bitbucket.org/gutworth/six/issue/98/\n\nFixes bug 1377514\n\nChange-Id: I3fc1819df8fb42d0c3d394bbc7d047b09152af68\n""}]",0,126168,27badfc314d31c6932993b117e3c12d9eb7f064f,11,3,3,1297,,,0,"Avoid usage of six.moves in local functions

Currently it appears that using six.moves in threaded code isn't
working as expected (something there in six does not appear to
be thread safe) so until this is fixed avoid using those moves
in functions in the examples and in the utility code (and instead
import the moved function at the top of the module in code to
avoid any threaded usage problems).

Upstream bug filed at:

https://bitbucket.org/gutworth/six/issue/98/

Fixes bug 1377514

Change-Id: I3fc1819df8fb42d0c3d394bbc7d047b09152af68
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/68/126168/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/examples/wbe_mandelbrot.py', 'taskflow/utils/misc.py', 'tox.ini', 'taskflow/examples/jobboard_produce_consume_colors.py']",4,40312694f16d90fb9720b57b3593686e70e01f81,bug/1377514," for i in range(0, PRODUCER_UNITS):","import six for i in six.moves.xrange(0, PRODUCER_UNITS):",10,11
openstack%2Fnova~master~I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5,openstack/nova,master,I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5,Fix the os_networks display to show cidr properly,MERGED,2014-10-02 23:08:44.000000000,2014-10-06 19:00:58.000000000,2014-10-06 19:00:56.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 23:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c53b759660c39f647dd218ba0a4175bdfb74e58b', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n'}, {'number': 2, 'created': '2014-10-02 23:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8402c59e2734549fbf184a8f227ff2feded3ada4', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n'}, {'number': 3, 'created': '2014-10-02 23:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12266dc4d81822292f5b1daece77c017fc05ef14', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n(cherry picked from commit 8402c59e2734549fbf184a8f227ff2feded3ada4)\n'}, {'number': 4, 'created': '2014-10-03 02:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee852d4a774ed67979805b8a5b90d9a86ae90d6d', 'message': 'Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPNetwork objects\ndumped as lists by the jsonutils extension. We therefore must\nexplicitly convert these objects to string. Do this by forcing\nthe object back to a primitive before returning it. Also, update\nthe tests to use objects so that we pick up bugs like this in\nthe future.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\n'}, {'number': 5, 'created': '2014-10-03 15:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93f52095d3ff0e2f050414a7cbd7238c9d2eb5d8', 'message': ""Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPAddress\nfields in Network objects are dumped as lists by the jsonutils\nextension. We therefore must explicitly convert these object\nfield values to string.\n\nThe tests are updated to use objects so that we pick up bugs\nlike this in the future. Incorrect assertEqual parameter order\nis fixed in the tests too since these are comparing dicts and\nit's not fun debugging a MismatchError when the reference/actual\nvalues are backwards.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\nCo-authored-by: Matt Riedemann <mriedem@us.ibm.com>\n""}, {'number': 6, 'created': '2014-10-03 15:07:34.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/api/openstack/compute/contrib/os_networks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/da25467aafce9b62dd3fdff9d6cd84121fbee17e', 'message': ""Fix the os_networks display to show cidr properly\n\nConverting network_get and network_get_all to use objects broke\nthe display of the os_networks extension, because IPAddress\nfields in Network objects are dumped as lists by the jsonutils\nextension. We therefore must explicitly convert these object\nfield values to string.\n\nThe tests are updated to use objects so that we pick up bugs\nlike this in the future. Incorrect assertEqual parameter order\nis fixed in the tests too since these are comparing dicts and\nit's not fun debugging a MismatchError when the reference/actual\nvalues are backwards.\n\nChange-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5\nCloses-Bug: #1376945\nCo-authored-by: Matt Riedemann <mriedem@us.ibm.com>\n""}]",11,125814,da25467aafce9b62dd3fdff9d6cd84121fbee17e,32,10,6,67,,,0,"Fix the os_networks display to show cidr properly

Converting network_get and network_get_all to use objects broke
the display of the os_networks extension, because IPAddress
fields in Network objects are dumped as lists by the jsonutils
extension. We therefore must explicitly convert these object
field values to string.

The tests are updated to use objects so that we pick up bugs
like this in the future. Incorrect assertEqual parameter order
is fixed in the tests too since these are comparing dicts and
it's not fun debugging a MismatchError when the reference/actual
values are backwards.

Change-Id: I0f05a9b4d7bbe5fe0a3b110c191455ca7edefcb5
Closes-Bug: #1376945
Co-authored-by: Matt Riedemann <mriedem@us.ibm.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/125814/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/api/openstack/compute/contrib/os_networks.py']",2,c53b759660c39f647dd218ba0a4175bdfb74e58b,bug/1376945," result = [network_dict(context, net_ref.obj_to_primitive()['nova_object.data'], self.extended) return {'network': network_dict( context, network.obj_to_primitive()['nova_object.data'], self.extended)}"," result = [network_dict(context, net_ref, self.extended) return {'network': network_dict(context, network, self.extended)}",24,8
openstack%2Ftempest~master~I411eb8c29d0c00d6d64358ede26992ee2fe380c9,openstack/tempest,master,I411eb8c29d0c00d6d64358ede26992ee2fe380c9,Fix schema definition admin_flavor_create,MERGED,2014-09-30 09:19:45.000000000,2014-10-06 19:00:46.000000000,2014-10-06 19:00:45.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-30 09:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c202088365519e6dc9cba6b2e2286603542beba2', 'message': 'Fix schema definition admin_flavor_create\n\nThe api of flavor_create has a missing property level. Property ""id""\nis noneable and need to be excluded from negative testing.\n\nChange-Id: I411eb8c29d0c00d6d64358ede26992ee2fe380c9\nCloses-bug: #1375142\n'}, {'number': 2, 'created': '2014-09-30 09:21:03.000000000', 'files': ['tempest/api_schema/request/compute/flavors.py', 'tempest/common/generator/base_generator.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e16bef0a0b6370d4e7da37141b7c52c8bf71400a', 'message': 'Fix schema definition admin_flavor_create\n\nThe api of flavor_create has a missing property level. Property ""id""\nis noneable and need to be excluded from negative testing.\n\nChange-Id: I411eb8c29d0c00d6d64358ede26992ee2fe380c9\nCloses-bug: #1375142\n'}]",0,124988,e16bef0a0b6370d4e7da37141b7c52c8bf71400a,23,7,2,7872,,,0,"Fix schema definition admin_flavor_create

The api of flavor_create has a missing property level. Property ""id""
is noneable and need to be excluded from negative testing.

Change-Id: I411eb8c29d0c00d6d64358ede26992ee2fe380c9
Closes-bug: #1375142
",git fetch https://review.opendev.org/openstack/tempest refs/changes/88/124988/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api_schema/request/compute/flavors.py', 'tempest/common/generator/base_generator.py']",2,c202088365519e6dc9cba6b2e2286603542beba2,bug/1375142," if (""exclude_tests"" in schema and name in schema[""exclude_tests""]): continue",,16,8
openstack%2Ftempest~master~I8deed33d37c5bf07c26118d6d66ada105d259c89,openstack/tempest,master,I8deed33d37c5bf07c26118d6d66ada105d259c89,Reduce complexity during import phase,MERGED,2014-08-19 12:39:15.000000000,2014-10-06 19:00:36.000000000,2014-10-06 19:00:35.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 10624}]","[{'number': 1, 'created': '2014-08-19 12:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/84d27fee0a651eda8deceed3cd8c41cf0362c4cc', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 2, 'created': '2014-08-30 12:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b9654582f697beb5c11d86daf9f41cc8f9ff3abf', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 3, 'created': '2014-09-01 07:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a5474fd9d9509ae25b6d3cab998cff642e211255', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 4, 'created': '2014-09-09 08:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4de342f2b0e2297ed333e8b93fc083eb5706c298', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 5, 'created': '2014-09-26 10:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be918e11b07e760e3dfd5e8e54c9142306400362', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 6, 'created': '2014-09-30 09:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a28febc2426c130e1693783d744c809baaba6d2', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}, {'number': 7, 'created': '2014-09-30 09:21:03.000000000', 'files': ['tempest/common/generator/negative_generator.py', 'tempest/tests/negative/test_negative_generators.py', 'tempest/common/generator/base_generator.py', 'tempest/common/generator/valid_generator.py', 'tempest/tests/negative/test_negative_auto_test.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f07f5d1f193afb57a14639e932209c4a1975ca32', 'message': 'Reduce complexity during import phase\n\nIn the current state of the negative testing framework the import phase\nconsists in many complex operation during import phase. This fix reduces\nthe complexity during that phase to improve the performance,\ndebugability and robustness.\n\nIn this fix we only determine the test scenarios in the import phase. The\npayloads are created while test execution. This also improves the\nflexibility since the test executor has full access to the test variables.\n\nChange-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89\nPartially-implements: bp autogen-negative-tests\n'}]",1,115273,f07f5d1f193afb57a14639e932209c4a1975ca32,35,8,7,7872,,,0,"Reduce complexity during import phase

In the current state of the negative testing framework the import phase
consists in many complex operation during import phase. This fix reduces
the complexity during that phase to improve the performance,
debugability and robustness.

In this fix we only determine the test scenarios in the import phase. The
payloads are created while test execution. This also improves the
flexibility since the test executor has full access to the test variables.

Change-Id: I8deed33d37c5bf07c26118d6d66ada105d259c89
Partially-implements: bp autogen-negative-tests
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/115273/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/negative/test_negative_generators.py', 'tempest/common/generator/base_generator.py', 'tempest/common/generator/valid_generator.py', 'tempest/tests/negative/test_negative_auto_test.py', 'tempest/test.py']",5,84d27fee0a651eda8deceed3cd8c41cf0362c4cc,bug/1375142," for scenario in generator.generate_scenarios(schema): scenario_list.append((scenario['_negtest_name'], scenario)) generator = importutils.import_class( CONF.negative.test_generator)() schema = description.get(""json-schema"", None) expected_result = None if ""default_result_code"" in description: expected_result = description[""default_result_code""] elif hasattr(self, ""_negtest_name""): schema_under_test = \ valid.ValidTestGenerator().generate_valid(schema) local_expected_result = \ generator.generate_payload(self, schema_under_test) if local_expected_result is not None: expected_result = local_expected_result new_url, body = \ self._http_arguments(schema_under_test, url, method) self._check_negative_response(expected_result, resp.status, resp_body) def _check_negative_response(self, expected_result, result, body):"," for name, schema, expected_result in generator.generate(schema): if (expected_result is None and ""default_result_code"" in description): expected_result = description[""default_result_code""] scenario_list.append((name, {""schema"": schema, ""expected_result"": expected_result})) schema = description.get(""json-schema"", None) elif hasattr(self, ""schema""): new_url, body = self._http_arguments(self.schema, url, method) self._check_negative_response(resp.status, resp_body) def _check_negative_response(self, result, body): expected_result = getattr(self, ""expected_result"", None)",119,75
openstack%2Fswift~master~I5c648010f09b6e4b1fb0380bc97b266e680602f8,openstack/swift,master,I5c648010f09b6e4b1fb0380bc97b266e680602f8,Fix minor typo,MERGED,2014-10-06 10:05:36.000000000,2014-10-06 18:58:06.000000000,2014-10-06 18:24:16.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-06 10:05:36.000000000', 'files': ['swift/container/reconciler.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7528f2b22169e90fe8ddd19b7ef7d46ecff5d231', 'message': 'Fix minor typo\n\nFixes minor typo in one method and adds missing parameter in other\nmethod. Only checked swift/container/reconciler.py for now.\n\nChange-Id: I5c648010f09b6e4b1fb0380bc97b266e680602f8\n'}]",0,126249,7528f2b22169e90fe8ddd19b7ef7d46ecff5d231,8,5,1,6968,,,0,"Fix minor typo

Fixes minor typo in one method and adds missing parameter in other
method. Only checked swift/container/reconciler.py for now.

Change-Id: I5c648010f09b6e4b1fb0380bc97b266e680602f8
",git fetch https://review.opendev.org/openstack/swift refs/changes/49/126249/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/container/reconciler.py'],1,7528f2b22169e90fe8ddd19b7ef7d46ecff5d231,fix-typo, :param obj: the name of the misplaced object :param obj: the object name, :param account: the object name,2,1
openstack%2Fnova~master~I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54,openstack/nova,master,I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54,Ironic: use list comprehension,ABANDONED,2014-09-08 08:14:37.000000000,2014-10-06 18:33:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 6167}, {'_account_id': 6773}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9545}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-08 08:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7989d2d24801ad3c9b2e1e468ecfbd95783fb68d', 'message': 'Ironic: use list comprehension\n\nMake use of a list comprehension for getting the host stats\n\nChange-Id: I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54\n'}, {'number': 2, 'created': '2014-09-08 08:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee07b14a2cb82f7e40d2c60c433d67e3e4fb6124', 'message': 'Ironic: use list comprehension\n\nMake use of a list comprehension for getting the host stats\n\nChange-Id: I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54\n'}, {'number': 3, 'created': '2014-10-05 06:38:12.000000000', 'files': ['nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a959fe262c755ffba2ed4b8d323e49e5640e1e40', 'message': 'Ironic: use list comprehension\n\nMake use of a list comprehension for getting the host stats\n\nChange-Id: I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54\n'}]",3,119711,a959fe262c755ffba2ed4b8d323e49e5640e1e40,43,16,3,1653,,,0,"Ironic: use list comprehension

Make use of a list comprehension for getting the host stats

Change-Id: I2fa34f7be6eb6f20e2af56deb69bbf4e24b6bb54
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/119711/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/driver.py'],1,7989d2d24801ad3c9b2e1e468ecfbd95783fb68d,ironic-comprehension, caps = [self._node_resource(node) for node in node_list], caps = [] for node in node_list: data = self._node_resource(node) caps.append(data),1,4
openstack%2Fpython-glanceclient~master~I329dcfba7a5a4cef428c468f0c842561092a945a,openstack/python-glanceclient,master,I329dcfba7a5a4cef428c468f0c842561092a945a,Make glanceclient respect --public paremeter,ABANDONED,2014-09-09 01:34:01.000000000,2014-10-06 18:32:35.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 5202}, {'_account_id': 8871}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-09-09 01:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3852f9558d4976ff2dc6b0d1640d82de1b2e97e7', 'message': 'Make glanceclient respect --public paremeter\n\nIn I66e82872988e3835e4f290f48dfc80538271426c we stopped respecting the\n--public parameter but it is still available.\n\nFixes bug: #1366808\n\nChange-Id: I329dcfba7a5a4cef428c468f0c842561092a945a\n'}, {'number': 2, 'created': '2014-09-09 01:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/24ce467a7ded6f534bb4d011743590199645e0fb', 'message': 'Make glanceclient respect --public paremeter\n\nIn I66e82872988e3835e4f290f48dfc80538271426c we stopped respecting the\n--public parameter but it is still available.\n\nFixes bug: #1366808\n\nChange-Id: I329dcfba7a5a4cef428c468f0c842561092a945a\n'}, {'number': 3, 'created': '2014-09-09 01:43:39.000000000', 'files': ['glanceclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3704c18a8a9702891420adefd706fdfaf2a53846', 'message': 'Make glanceclient respect --public paremeter\n\nIn I66e82872988e3835e4f290f48dfc80538271426c we stopped respecting the\n--public parameter but it is still available.\n\nFixes-bug: #1366808\n\nChange-Id: I329dcfba7a5a4cef428c468f0c842561092a945a\n'}]",0,119973,3704c18a8a9702891420adefd706fdfaf2a53846,13,5,3,10035,,,0,"Make glanceclient respect --public paremeter

In I66e82872988e3835e4f290f48dfc80538271426c we stopped respecting the
--public parameter but it is still available.

Fixes-bug: #1366808

Change-Id: I329dcfba7a5a4cef428c468f0c842561092a945a
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/73/119973/3 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/v1/shell.py'],1,3852f9558d4976ff2dc6b0d1640d82de1b2e97e7,fix/respect-public-param, fields['protected'] = fields.pop('is_protected') or fields.pop('public'), fields['protected'] = fields.pop('is_protected'),1,1
openstack%2Fopenstacksdk~master~I766440d5f8bd60b685f30254acb3987cabd161f0,openstack/openstacksdk,master,I766440d5f8bd60b685f30254acb3987cabd161f0,Make user_id a higher priority for v2 auth,MERGED,2014-10-02 21:42:00.000000000,2014-10-06 18:26:05.000000000,2014-10-06 18:26:05.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-10-02 21:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cc87f8228a41388049841cc5daa800d0236287a6', 'message': 'Make user_id a higher priority for v2 auth\n\nChange-Id: I766440d5f8bd60b685f30254acb3987cabd161f0\n'}, {'number': 2, 'created': '2014-10-04 11:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7ad08251514cf6071af250d7b976a53a1c332cd0', 'message': 'Make user_id a higher priority for v2 auth\n\nChange-Id: I766440d5f8bd60b685f30254acb3987cabd161f0\n'}, {'number': 3, 'created': '2014-10-06 18:11:48.000000000', 'files': ['openstack/auth/identity/v2.py', 'openstack/tests/auth/identity/test_v2.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/44c164875824b6f9f646bbd1e8648a1ba9d4f4f1', 'message': 'Make user_id a higher priority for v2 auth\n\nChange-Id: I766440d5f8bd60b685f30254acb3987cabd161f0\n'}]",0,125799,44c164875824b6f9f646bbd1e8648a1ba9d4f4f1,12,3,3,8736,,,0,"Make user_id a higher priority for v2 auth

Change-Id: I766440d5f8bd60b685f30254acb3987cabd161f0
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/99/125799/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/auth/identity/v2.py', 'openstack/tests/auth/identity/test_v2.py']",2,cc87f8228a41388049841cc5daa800d0236287a6,user_id," def test_user_id(self): kargs = { 'password': common.TEST_PASS, 'project_id': common.TEST_TENANT_ID, 'project_name': common.TEST_TENANT_NAME, 'trust_id': common.TEST_TRUST_ID, 'user_name': common.TEST_USER, 'user_id': common.TEST_USER_ID, } sot = v2.Auth(TEST_URL, **kargs) self.assertEqual(common.TEST_USER, sot.user_name) self.assertEqual(common.TEST_USER_ID, sot.user_id) self.assertEqual(common.TEST_PASS, sot.password) self.assertEqual(common.TEST_TRUST_ID, sot.trust_id) self.assertEqual(common.TEST_TENANT_ID, sot.tenant_id) self.assertEqual(common.TEST_TENANT_NAME, sot.tenant_name) expected = {'passwordCredentials': {'password': common.TEST_PASS, 'userId': common.TEST_USER_ID}} headers = {} self.assertEqual(expected, sot.get_auth_data(headers)) self.assertEqual({}, headers) ",,27,3
openstack%2Fpython-novaclient~master~Id10ebc7f720aa4183a6ed313388a7a006d17bc37,openstack/python-novaclient,master,Id10ebc7f720aa4183a6ed313388a7a006d17bc37,Friendly error message while creating security group,ABANDONED,2014-09-11 19:24:16.000000000,2014-10-06 18:09:40.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 12566}]","[{'number': 1, 'created': '2014-09-11 19:24:16.000000000', 'files': ['novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/effc862183107a075da3c205ec2509661c8d3ec7', 'message': 'Friendly error message while creating security group\n\nValidate parameter name before going to the parser, while\ncreating security group. Before that, there was an\nerror about no such parameter.\nNow there is validation in case of:\n* nova secgroup-create -name\n\nCloses-Bug: #977192\nChange-Id: Id10ebc7f720aa4183a6ed313388a7a006d17bc37\n'}]",0,120889,effc862183107a075da3c205ec2509661c8d3ec7,9,4,1,12566,,,0,"Friendly error message while creating security group

Validate parameter name before going to the parser, while
creating security group. Before that, there was an
error about no such parameter.
Now there is validation in case of:
* nova secgroup-create -name

Closes-Bug: #977192
Change-Id: Id10ebc7f720aa4183a6ed313388a7a006d17bc37
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/89/120889/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/shell.py'],1,effc862183107a075da3c205ec2509661c8d3ec7,bug/977192," # Check name of the secgroup in case of a dash at the beggining # Print friendly error user message if 'secgroup-create -name', # check argv contains secgropu-create follow. if 'secgroup-create' in argv: secgroup_index = argv.index('secgroup-create') secgroup_name = argv[secgroup_index + 1] if secgroup_name.startswith('-'): raise exc.CommandError(_(""Name of the security group "" ""can't start with '-'."")) ",,10,0
openstack%2Fswift-specs~master~Ib4f84efab8b3af3ddd47d38d63a91362612bd655,openstack/swift-specs,master,Ib4f84efab8b3af3ddd47d38d63a91362612bd655,Add RSS feed,MERGED,2014-09-10 19:15:33.000000000,2014-10-06 17:50:08.000000000,2014-10-06 17:50:07.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-09-10 19:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/9c6531dc0af6b8b9bba688f3431289d3ef301ae6', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}, {'number': 2, 'created': '2014-09-10 20:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/bd9f7663b168bef68dcc9d8d2d82bed86cad628b', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}, {'number': 3, 'created': '2014-09-26 20:32:02.000000000', 'files': ['requirements.txt', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/e777cf8bce25117bced48b8b9be190ddb5987cec', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}]",0,120544,e777cf8bce25117bced48b8b9be190ddb5987cec,13,3,3,2472,,,0,"Add RSS feed

Publish an RSS feed of the changes to the specs repository to make the
specs more discoverable.

Change-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/44/120544/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'doc/source/conf.py']",2,9c6531dc0af6b8b9bba688f3431289d3ef301ae6,rss-feed," 'oslosphinx', 'yasfb',# Feed configuration for yasfb feed_base_url = 'http://specs.openstack.org/openstack/swift-specs/' feed_author = 'OpenStack Swift Team' ", 'oslosphinx',7,1
openstack%2Fkeystone~master~I02566b3168b5f1792149b67e582d8e97ff02f8a6,openstack/keystone,master,I02566b3168b5f1792149b67e582d8e97ff02f8a6,Remove identity and assignment kvs backends,MERGED,2014-10-02 12:15:26.000000000,2014-10-06 17:42:06.000000000,2014-10-06 17:42:05.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-10-02 12:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3c7fb15b909ad0547032b8cc78132c522f80141e', 'message': 'Remove identity and assignment kvs backends\n\nAs part of deprecating the kvs backends, this patch removes those\nfor identity and assignment.\n\nPartially implements: bp deprecate-kvs\n\nChange-Id: I02566b3168b5f1792149b67e582d8e97ff02f8a6\n'}, {'number': 2, 'created': '2014-10-02 14:52:55.000000000', 'files': ['keystone/identity/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/assignment/backends/kvs.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0b4ec0bd09101553d32e359e2d71b562bb17451e', 'message': 'Remove identity and assignment kvs backends\n\nAs part of deprecating the kvs backends, this patch removes those\nfor identity and assignment.\n\nPartially implements: bp removed-as-of-kilo\n\nChange-Id: I02566b3168b5f1792149b67e582d8e97ff02f8a6\n'}]",0,125610,0b4ec0bd09101553d32e359e2d71b562bb17451e,14,7,2,5707,,,0,"Remove identity and assignment kvs backends

As part of deprecating the kvs backends, this patch removes those
for identity and assignment.

Partially implements: bp removed-as-of-kilo

Change-Id: I02566b3168b5f1792149b67e582d8e97ff02f8a6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/10/125610/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/assignment/backends/kvs.py']",3,3c7fb15b909ad0547032b8cc78132c522f80141e,bp/deprecate-kvs,,"# Copyright 2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystone import assignment from keystone import clean from keystone.common import kvs from keystone import config from keystone import exception from keystone.i18n import _ from keystone.openstack.common import versionutils CONF = config.CONF class Assignment(kvs.Base, assignment.Driver): """"""KVS Assignment backend. This backend uses the following mappings to store data: * Domains: * domain_list -> [domain_id, ...] * domain-{id} -> domain_ref * domain_name-{name} -> domain_ref * Projects: * tenant-{id} -> project_ref * tenant_name-{name} -> project_ref * Roles: * role_list -> [role_id, ...] * role-{id} -> role_ref * Role assignments: * metadata_user-{target}-{user_id} -> {'roles': [{'id': role-id, ...}, ...]} * metadata_group-{target}-{group_id} -> {'roles': [{'id': role-id, ...}, ...]} """""" @versionutils.deprecated(versionutils.deprecated.JUNO, in_favor_of='keystone.assignment.backends.sql', remove_in=+1, what='keystone.assignment.backends.kvs') def __init__(self): super(Assignment, self).__init__() # Public interface def get_project(self, tenant_id): try: return self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) def _build_project_refs(self): project_keys = (k for k in self.db.keys() if k.startswith('tenant-')) return [self.db.get(key) for key in project_keys] def list_projects(self, hints): return self._build_project_refs() def list_projects_in_domain(self, domain_id): project_refs = self._build_project_refs() self.get_domain(domain_id) return [ref for ref in project_refs if domain_id == ref['domain_id']] def get_project_by_name(self, tenant_name, domain_id): try: return self.db.get('tenant_name-%s' % tenant_name) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_name) def list_user_ids_for_project(self, tenant_id): self.get_project(tenant_id) user_ids = set() metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_user_id = key.split('-') if meta_project_or_domain_id != tenant_id: # target is not the project, so on to next metadata. continue user_ids.add(meta_user_id) return list(user_ids) def _get_metadata(self, user_id=None, tenant_id=None, domain_id=None, group_id=None): try: if user_id: if tenant_id: return self.db.get('metadata_user-%s-%s' % (tenant_id, user_id)) else: return self.db.get('metadata_user-%s-%s' % (domain_id, user_id)) else: if tenant_id: return self.db.get('metadata_group-%s-%s' % (tenant_id, group_id)) else: return self.db.get('metadata_group-%s-%s' % (domain_id, group_id)) except exception.NotFound: raise exception.MetadataNotFound() def get_role(self, role_id): try: return self.db.get('role-%s' % role_id) except exception.NotFound: raise exception.RoleNotFound(role_id=role_id) def get_group_project_roles(self, groups, project_id, project_domain_id): role_list = [] for group_id in groups: try: metadata_ref = self._get_metadata( group_id=group_id, tenant_id=project_id) role_list += self._roles_from_role_dicts( metadata_ref.get('roles', {}), False) except exception.MetadataNotFound: # no group assignment, skip pass if CONF.os_inherit.enabled: # Now get any inherited group roles for the owning domain try: metadata_ref = self._get_metadata( group_id=group_id, domain_id=project_domain_id) role_list += self._roles_from_role_dicts( metadata_ref.get('roles', {}), True) except exception.MetadataNotFound: pass return role_list def list_roles(self, hints): return self._list_roles() def _list_roles(self): role_ids = self.db.get('role_list', []) return [self.get_role(x) for x in role_ids] def list_projects_for_user(self, user_id, group_ids, hints): project_ids = set() all_projects = self.list_projects(hints=None) metadata_keys = (k for k in self.db.keys() if (k.startswith('metadata_user-') or k.startswith('metadata_group-'))) for key in metadata_keys: i, meta_project_or_domain_id, meta_entity_id = key.split('-') if meta_entity_id != user_id and meta_entity_id not in group_ids: # Not the user not one of the groups, so on to next metadata. continue try: self.get_project(meta_project_or_domain_id) except exception.NotFound: # target is not a project, could it be a domain if not CONF.os_inherit.enabled: # Inheritance is disabled, skip domain handling continue try: self.get_domain(meta_project_or_domain_id) except exception.NotFound: # Not a domain, move on continue data = self.db.get(key) for role in data.get('roles', []): if role['inherited_to'] == 'projects': # Role is inherited for project in all_projects: # add all projects for the domain to the list # of ids if (project['domain_id'] == meta_project_or_domain_id): project_ids.add(project['id']) break continue project_id = meta_project_or_domain_id project_ids.add(project_id) project_refs = [] for project_id in project_ids: project_refs.append(self.get_project(project_id)) return project_refs def list_domains_for_user(self, user_id, group_ids, hints): raise exception.NotImplemented() def get_roles_for_groups(self, group_ids, project_id=None, domain_id=None): raise exception.NotImplemented() def list_projects_for_groups(self, group_ids): raise exception.NotImplemented() def list_domains_for_groups(self, group_ids): raise exception.NotImplemented() def add_role_to_user_and_project(self, user_id, tenant_id, role_id): self.get_project(tenant_id) self.get_role(role_id) try: metadata_ref = self._get_metadata(user_id, tenant_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._add_role_to_role_dicts( role_id, False, metadata_ref.get('roles', []), allow_existing=False) except KeyError: msg = ('User %s already has role %s in tenant %s' % (user_id, role_id, tenant_id)) raise exception.Conflict(type='role grant', details=msg) self._update_metadata(user_id, tenant_id, metadata_ref) def remove_role_from_user_and_project(self, user_id, tenant_id, role_id): try: metadata_ref = self._get_metadata(user_id, tenant_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._remove_role_from_role_dicts( role_id, False, metadata_ref.get('roles', [])) except KeyError: raise exception.RoleNotFound(message=_( 'Cannot remove role that has not been granted, %s') % role_id) if metadata_ref['roles']: self._update_metadata(user_id, tenant_id, metadata_ref) else: self.db.delete('metadata_user-%s-%s' % (tenant_id, user_id)) def list_role_assignments(self): """"""List the role assignments. We enumerate the metadata entries and extract the targets, actors, and roles. """""" assignment_list = [] metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: template = {} i, meta_project_or_domain_id, template['user_id'] = key.split('-') try: self.get_project(meta_project_or_domain_id) template['project_id'] = meta_project_or_domain_id except exception.NotFound: template['domain_id'] = meta_project_or_domain_id entry = self.db.get(key) inherited = False for r in self._roles_from_role_dicts(entry.get('roles', {}), inherited): role_assignment = template.copy() role_assignment['role_id'] = r assignment_list.append(role_assignment) metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_group-')) for key in metadata_keys: template = {} i, meta_project_or_domain_id, template['group_id'] = key.split('-') try: self.get_project(meta_project_or_domain_id) template['project_id'] = meta_project_or_domain_id except exception.NotFound: template['domain_id'] = meta_project_or_domain_id entry = self.db.get(key) inherited = False for r in self._roles_from_role_dicts(entry.get('roles', {}), inherited): role_assignment = template.copy() role_assignment['role_id'] = r assignment_list.append(role_assignment) return assignment_list # CRUD def create_project(self, tenant_id, tenant): tenant['name'] = clean.project_name(tenant['name']) try: self.get_project(tenant_id) except exception.ProjectNotFound: pass else: msg = 'Duplicate ID, %s.' % tenant_id raise exception.Conflict(type='tenant', details=msg) try: self.get_project_by_name(tenant['name'], tenant['domain_id']) except exception.ProjectNotFound: pass else: msg = 'Duplicate name, %s.' % tenant['name'] raise exception.Conflict(type='tenant', details=msg) self.db.set('tenant-%s' % tenant_id, tenant) self.db.set('tenant_name-%s' % tenant['name'], tenant) return tenant def update_project(self, tenant_id, tenant): if 'name' in tenant: tenant['name'] = clean.project_name(tenant['name']) try: existing = self.db.get('tenant_name-%s' % tenant['name']) if existing and tenant_id != existing['id']: msg = 'Duplicate name, %s.' % tenant['name'] raise exception.Conflict(type='tenant', details=msg) except exception.NotFound: pass # get the old name and delete it too try: old_project = self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) new_project = old_project.copy() new_project.update(tenant) new_project['id'] = tenant_id self.db.delete('tenant_name-%s' % old_project['name']) self.db.set('tenant-%s' % tenant_id, new_project) self.db.set('tenant_name-%s' % new_project['name'], new_project) return new_project def delete_project(self, tenant_id): try: old_project = self.db.get('tenant-%s' % tenant_id) except exception.NotFound: raise exception.ProjectNotFound(project_id=tenant_id) self.db.delete('tenant_name-%s' % old_project['name']) self.db.delete('tenant-%s' % tenant_id) def _create_metadata(self, user_id, tenant_id, metadata, domain_id=None, group_id=None): return self._update_metadata(user_id, tenant_id, metadata, domain_id, group_id) def _update_metadata(self, user_id, tenant_id, metadata, domain_id=None, group_id=None): if user_id: if tenant_id: self.db.set('metadata_user-%s-%s' % (tenant_id, user_id), metadata) else: self.db.set('metadata_user-%s-%s' % (domain_id, user_id), metadata) else: if tenant_id: self.db.set('metadata_group-%s-%s' % (tenant_id, group_id), metadata) else: self.db.set('metadata_group-%s-%s' % (domain_id, group_id), metadata) return metadata def create_role(self, role_id, role): try: self.get_role(role_id) except exception.RoleNotFound: pass else: msg = 'Duplicate ID, %s.' % role_id raise exception.Conflict(type='role', details=msg) for role_ref in self._list_roles(): if role['name'] == role_ref['name']: msg = 'Duplicate name, %s.' % role['name'] raise exception.Conflict(type='role', details=msg) self.db.set('role-%s' % role_id, role) role_list = set(self.db.get('role_list', [])) role_list.add(role_id) self.db.set('role_list', list(role_list)) return role def update_role(self, role_id, role): old_role_ref = None for role_ref in self._list_roles(): if role['name'] == role_ref['name'] and role_id != role_ref['id']: msg = 'Duplicate name, %s.' % role['name'] raise exception.Conflict(type='role', details=msg) if role_id == role_ref['id']: old_role_ref = role_ref if old_role_ref is None: raise exception.RoleNotFound(role_id=role_id) new_role = old_role_ref.copy() new_role.update(role) new_role['id'] = role_id self.db.set('role-%s' % role_id, new_role) return role def delete_role(self, role_id): self.get_role(role_id) metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_user-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_user_id = key.split('-') try: self.delete_grant(role_id, project_id=meta_project_or_domain_id, user_id=meta_user_id) except exception.NotFound: pass try: self.delete_grant(role_id, domain_id=meta_project_or_domain_id, user_id=meta_user_id) except exception.NotFound: pass metadata_keys = (k for k in self.db.keys() if k.startswith('metadata_group-')) for key in metadata_keys: i, meta_project_or_domain_id, meta_group_id = key.split('-') try: self.delete_grant(role_id, project_id=meta_project_or_domain_id, group_id=meta_group_id) except exception.NotFound: pass try: self.delete_grant(role_id, domain_id=meta_project_or_domain_id, group_id=meta_group_id) except exception.NotFound: pass self.db.delete('role-%s' % role_id) role_list = set(self.db.get('role_list', [])) role_list.remove(role_id) self.db.set('role_list', list(role_list)) def create_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} metadata_ref['roles'] = self._add_role_to_role_dicts( role_id, inherited_to_projects, metadata_ref.get('roles', [])) self._update_metadata(user_id, project_id, metadata_ref, domain_id, group_id) def list_grants(self, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} return [self.get_role(x) for x in self._roles_from_role_dicts(metadata_ref.get('roles', []), inherited_to_projects)] def get_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if group_id: self.get_group(group_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} role_ids = set(self._roles_from_role_dicts( metadata_ref.get('roles', []), inherited_to_projects)) if role_id not in role_ids: raise exception.RoleNotFound(role_id=role_id) return self.get_role(role_id) def delete_grant(self, role_id, user_id=None, group_id=None, domain_id=None, project_id=None, inherited_to_projects=False): self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} try: metadata_ref['roles'] = self._remove_role_from_role_dicts( role_id, inherited_to_projects, metadata_ref.get('roles', [])) except KeyError: raise exception.RoleNotFound(role_id=role_id) self._update_metadata(user_id, project_id, metadata_ref, domain_id, group_id) # domain crud def create_domain(self, domain_id, domain): try: self.get_domain(domain_id) except exception.DomainNotFound: pass else: msg = 'Duplicate ID, %s.' % domain_id raise exception.Conflict(type='domain', details=msg) try: self.get_domain_by_name(domain['name']) except exception.DomainNotFound: pass else: msg = 'Duplicate name, %s.' % domain['name'] raise exception.Conflict(type='domain', details=msg) self.db.set('domain-%s' % domain_id, domain) self.db.set('domain_name-%s' % domain['name'], domain) domain_list = set(self.db.get('domain_list', [])) domain_list.add(domain_id) self.db.set('domain_list', list(domain_list)) return domain def list_domains(self, hints): domain_ids = self.db.get('domain_list', []) return [self.get_domain(x) for x in domain_ids] def get_domain(self, domain_id): try: return self.db.get('domain-%s' % domain_id) except exception.NotFound: raise exception.DomainNotFound(domain_id=domain_id) def get_domain_by_name(self, domain_name): try: return self.db.get('domain_name-%s' % domain_name) except exception.NotFound: raise exception.DomainNotFound(domain_id=domain_name) def update_domain(self, domain_id, domain): orig_domain = self.get_domain(domain_id) domain['id'] = domain_id self.db.set('domain-%s' % domain_id, domain) self.db.set('domain_name-%s' % domain['name'], domain) if domain['name'] != orig_domain['name']: self.db.delete('domain_name-%s' % orig_domain['name']) return domain def delete_domain(self, domain_id): domain = self.get_domain(domain_id) self.db.delete('domain-%s' % domain_id) self.db.delete('domain_name-%s' % domain['name']) domain_list = set(self.db.get('domain_list', [])) domain_list.remove(domain_id) self.db.set('domain_list', list(domain_list)) def delete_user(self, user_id): """"""Deletes all assignments for a user. :raises: keystone.exception.RoleNotFound """""" # KVS doesn't bother cleaning up role assignments for the user. I # guess it's too difficult to implement or something. def delete_group(self, group_id): """"""Deletes all assignments for a group. :raises: keystone.exception.RoleNotFound """""" # KVS doesn't bother cleaning up role assignments for the group. I # guess it's too difficult to implement or something. ",2,1056
openstack%2Fbarbican~master~I45b7a3d6ae3685d9ebaf3ebae0398a1a1c545aad,openstack/barbican,master,I45b7a3d6ae3685d9ebaf3ebae0398a1a1c545aad,Open Kilo development,MERGED,2014-10-02 15:36:10.000000000,2014-10-06 17:37:19.000000000,2014-10-06 17:37:18.000000000,"[{'_account_id': 3}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-10-02 15:36:10.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican/commit/8467aef4cec4705bcc10a2aec4c55b91ecf7f5ff', 'message': 'Open Kilo development\n\nBump pre-version to 2015.1 to formally open master branch to Kilo\ndevelopment.\n\nChange-Id: I45b7a3d6ae3685d9ebaf3ebae0398a1a1c545aad\n'}]",0,125678,8467aef4cec4705bcc10a2aec4c55b91ecf7f5ff,9,4,1,308,,,0,"Open Kilo development

Bump pre-version to 2015.1 to formally open master branch to Kilo
development.

Change-Id: I45b7a3d6ae3685d9ebaf3ebae0398a1a1c545aad
",git fetch https://review.opendev.org/openstack/barbican refs/changes/78/125678/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8467aef4cec4705bcc10a2aec4c55b91ecf7f5ff,open-kilo,version = 2015.1,version = 2014.2,1,1
openstack%2Fopenstacksdk~master~I4828be6537bbe865b43ec43de41f6060ea8f2c98,openstack/openstacksdk,master,I4828be6537bbe865b43ec43de41f6060ea8f2c98,Use stevedore to load authorization plugins,MERGED,2014-09-07 16:36:17.000000000,2014-10-06 17:25:12.000000000,2014-10-06 17:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-09-07 16:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3aae4947f26c704deb738f8f201570d71f9b7be5', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}, {'number': 2, 'created': '2014-09-09 16:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d92a96f01d2a2ac28578c52035fcd21bf7ba568d', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}, {'number': 3, 'created': '2014-09-12 21:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/60f0fcaa4e038a876605e8ed4e3c7f5bbbb39692', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}, {'number': 4, 'created': '2014-09-12 21:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/18370a80185d874a691800983ed92f20d96a5707', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}, {'number': 5, 'created': '2014-10-06 14:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1139989138862d6616ac269e64f18f0d4b0688cf', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}, {'number': 6, 'created': '2014-10-06 16:06:15.000000000', 'files': ['openstack/auth/identity/authenticator.py', 'openstack/tests/auth/identity/test_authenticator.py', 'examples/authenticate.py', 'requirements.txt', 'openstack/tests/test_session.py', 'openstack/session.py', 'examples/common.py', 'examples/session.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/836b9e852d424e08f17bfac63ef06ba7ad2ac2ba', 'message': 'Use stevedore to load authorization plugins\n\nAdd basic infrastructure to load authorization plugins with\nstevedore.\n\nChange-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98\n'}]",8,119628,836b9e852d424e08f17bfac63ef06ba7ad2ac2ba,26,5,6,8736,,,0,"Use stevedore to load authorization plugins

Add basic infrastructure to load authorization plugins with
stevedore.

Change-Id: I4828be6537bbe865b43ec43de41f6060ea8f2c98
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/28/119628/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/auth/identity/authenticator.py', 'examples/authenticate.py', 'openstack/tests/auth/identity/test_authenticator.py', 'requirements.txt', 'openstack/tests/test_session.py', 'openstack/session.py', 'examples/common.py', 'examples/session.py', 'setup.cfg']",9,3aae4947f26c704deb738f8f201570d71f9b7be5,stevedore, [entry_points] openstack.auth.plugin = identity_v2 = openstack.auth.identity.v2:Auth identity_v3 = openstack.auth.identity.v3:Auth,,55,105
openstack%2Fbandit~master~Ic006c9913561283a9ef8d09098cbecc4c5871e22,openstack/bandit,master,Ic006c9913561283a9ef8d09098cbecc4c5871e22,Adding a check to bandit for use of 'exec',MERGED,2014-09-25 12:46:32.000000000,2014-10-06 16:57:50.000000000,2014-10-06 16:57:50.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 11861}]","[{'number': 1, 'created': '2014-09-25 12:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/881de9bc9d597ba0ccfff64d4e84bb6026d637ca', 'message': ""Adding a check to bandit for use of 'exec'\n\nPython exec allows execution of strings as dynamic code. Possible\nvector for code injection attack, but can also hide stuff from\nother bandit checks when presented as a string.\n\nChange-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22\n""}, {'number': 2, 'created': '2014-09-25 12:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/020ee2b9d0938bd79e7ce7e9ccaef3ce9e820533', 'message': ""Adding a check to bandit for use of 'exec'\n\nPython exec allows execution of strings as dynamic code. Possible\nvector for code injection attack, but can also hide stuff from\nother bandit checks when presented as a string.\n\nChange-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22\n""}, {'number': 3, 'created': '2014-10-02 12:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/35fbabcd3c47f7f792eb7cade974508d3649f61f', 'message': ""Adding a check to bandit for use of 'exec'\n\nPython exec allows execution of strings as dynamic code. Possible\nvector for code injection attack, but can also hide stuff from\nother bandit checks when presented as a string.\n\nChange-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22\n""}, {'number': 4, 'created': '2014-10-02 12:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/bdd0f815c5afb81aaadc49af68b7e6e9f5fb1b56', 'message': ""Adding a check to bandit for use of 'exec'\n\nPython exec allows execution of strings as dynamic code. Possible\nvector for code injection attack, but can also hide stuff from\nother bandit checks when presented as a string.\n\nChange-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22\n""}, {'number': 5, 'created': '2014-10-06 16:50:50.000000000', 'files': ['plugins/exec.py', 'examples/exec.py', 'bandit/test_selector.py', 'bandit/node_visitor.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/39e1ffcbff3ca1db8f442fc2ef24ba122594bbc6', 'message': ""Adding a check to bandit for use of 'exec'\n\nPython exec allows execution of strings as dynamic code. Possible\nvector for code injection attack, but can also hide stuff from\nother bandit checks when presented as a string.\n\nChange-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22\n""}]",2,124039,39e1ffcbff3ca1db8f442fc2ef24ba122594bbc6,21,6,5,11716,,,0,"Adding a check to bandit for use of 'exec'

Python exec allows execution of strings as dynamic code. Possible
vector for code injection attack, but can also hide stuff from
other bandit checks when presented as a string.

Change-Id: Ic006c9913561283a9ef8d09098cbecc4c5871e22
",git fetch https://review.opendev.org/openstack/bandit refs/changes/39/124039/5 && git format-patch -1 --stdout FETCH_HEAD,"['examples/exec.py', 'bandit/node_visitor.py']",2,881de9bc9d597ba0ccfff64d4e84bb6026d637ca,test-for-exec,"from bandit.constants import * # tkelsey: why not? they seem to generate Call nodes ?? # tests seem to suport this, I can blacklist 'zip' for example. def visit_Exec(self, node): # NOTE(tkelsey): do we need more user control over this? result = (ERROR, ""Use of exec detected."") self.context['lineno'] = node.lineno self.context['str'] = 'exec' self.tester.results.add(self.context, 'exec', result) super(BanditNodeVisitor, self).generic_visit(node) ",,14,0
openstack%2Fcongress~master~Ifbf17378c1ca660c47421b11a30204f9be1af056,openstack/congress,master,Ifbf17378c1ca660c47421b11a30204f9be1af056,Fix bug in value_to_congress,MERGED,2014-10-02 00:31:47.000000000,2014-10-06 16:51:59.000000000,2014-10-06 16:51:58.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-10-02 00:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9b2fe5fe3f823dad5f7882e1a59cb3593f13e146', 'message': ""Fix bug in value_to_congress\n\nThe previous version checks if a value is equal to either True or False, if\nso, it converts the value to a string.  The problem is that 0 and 1 are equal\nto False and True respectively in python which would cause integer values 0\nand 1 to be converted to '0' and '1'.\n\nThis change uses isinstance(obj, bool) and does so before isinstance(obj, int)\nbecause a bool value is also an instance of int.  Also, add a test to verify\nthis bug.\n\nChange-Id: Ifbf17378c1ca660c47421b11a30204f9be1af056\n""}, {'number': 2, 'created': '2014-10-02 01:07:10.000000000', 'files': ['congress/datasources/tests/unit/test_neutron_driver.py', 'congress/datasources/datasource_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/696e0fe9e34f3aad8ef814627bc35655a2e09d0e', 'message': ""Fix bug in value_to_congress\n\nThe previous version checks if a value is equal to either True or False, if\nso, it converts the value to a string.  The problem is that 0 and 1 are equal\nto False and True respectively in python which would cause integer values 0\nand 1 to be converted to '0' and '1'.\n\nThis change uses isinstance(obj, bool) and does so before isinstance(obj, int)\nbecause a bool value is also an instance of int.  Also, add a test to verify\nthis bug.\n\nChange-Id: Ifbf17378c1ca660c47421b11a30204f9be1af056\n""}]",0,125525,696e0fe9e34f3aad8ef814627bc35655a2e09d0e,10,4,2,12875,,,0,"Fix bug in value_to_congress

The previous version checks if a value is equal to either True or False, if
so, it converts the value to a string.  The problem is that 0 and 1 are equal
to False and True respectively in python which would cause integer values 0
and 1 to be converted to '0' and '1'.

This change uses isinstance(obj, bool) and does so before isinstance(obj, int)
because a bool value is also an instance of int.  Also, add a test to verify
this bug.

Change-Id: Ifbf17378c1ca660c47421b11a30204f9be1af056
",git fetch https://review.opendev.org/openstack/congress refs/changes/25/125525/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/datasources/tests/unit/test_neutron_driver.py', 'congress/datasources/datasource_driver.py']",2,9b2fe5fe3f823dad5f7882e1a59cb3593f13e146,," # Check for bool first because True and False are also ints if isinstance(value, bool):"," if value in (True, False):",14,1
openstack%2Fcongress~master~Id1add83b2fa8b7432ac5cc5d3156a13af92ba858,openstack/congress,master,Id1add83b2fa8b7432ac5cc5d3156a13af92ba858,Removed d6cage reload module warning messages,MERGED,2014-10-06 16:28:42.000000000,2014-10-06 16:50:31.000000000,2014-10-06 16:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-10-06 16:28:42.000000000', 'files': ['congress/dse/d6cage.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/c082e6d396fd6aaebafecac576f6cc97728b1c73', 'message': 'Removed d6cage reload module warning messages\n\nPreviously, d6cage would log errors when the same module\nwas loaded more than once.\n\nIt is unclear whether this behavior is useful, and it\nproduced many errors during testing.  This change\nlogs a warning instead of an error when a module\nis reloaded.\n\nCloses-bug: 1360443\nChange-Id: Id1add83b2fa8b7432ac5cc5d3156a13af92ba858\n'}]",0,126346,c082e6d396fd6aaebafecac576f6cc97728b1c73,6,2,1,8215,,,0,"Removed d6cage reload module warning messages

Previously, d6cage would log errors when the same module
was loaded more than once.

It is unclear whether this behavior is useful, and it
produced many errors during testing.  This change
logs a warning instead of an error when a module
is reloaded.

Closes-bug: 1360443
Change-Id: Id1add83b2fa8b7432ac5cc5d3156a13af92ba858
",git fetch https://review.opendev.org/openstack/congress refs/changes/46/126346/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/dse/d6cage.py'],1,c082e6d396fd6aaebafecac576f6cc97728b1c73,," # self.log_error( # ""error loading module '%s': module already exists"" % name)"," self.log_error( ""error loading module '%s': module already exists"" % name)",2,2
openstack%2Fcongress~master~I55967ded77f140b7d809c69e4b56f1ea4fd7168d,openstack/congress,master,I55967ded77f140b7d809c69e4b56f1ea4fd7168d,Removed extraneous print statements from policy engine builtins,MERGED,2014-10-06 16:28:42.000000000,2014-10-06 16:49:29.000000000,2014-10-06 16:49:29.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-10-06 16:28:42.000000000', 'files': ['congress/policy/builtin/congressbuiltin.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/eb514b112af1a0dd871d586413264896bed30af8', 'message': 'Removed extraneous print statements from policy engine builtins\n\nChange-Id: I55967ded77f140b7d809c69e4b56f1ea4fd7168d\n'}]",0,126345,eb514b112af1a0dd871d586413264896bed30af8,6,2,1,8215,,,0,"Removed extraneous print statements from policy engine builtins

Change-Id: I55967ded77f140b7d809c69e4b56f1ea4fd7168d
",git fetch https://review.opendev.org/openstack/congress refs/changes/45/126345/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/policy/builtin/congressbuiltin.py'],1,eb514b112af1a0dd871d586413264896bed30af8,," # print ncode, ninputs, nfunc, nfunc_pred, nfunc_arglist # print key # print 'category exists'"," print predtriple print predtriple print ncode, ninputs, nfunc, nfunc_pred, nfunc_arglist print key print 'category exists' else: print ""builtin exists""",3,7
openstack%2Fhorizon~master~I6774b9b7215d191259586e4721e357487bb777cd,openstack/horizon,master,I6774b9b7215d191259586e4721e357487bb777cd,Document token hash algorithm option,MERGED,2014-08-24 15:07:45.000000000,2014-10-06 16:47:45.000000000,2014-10-06 16:47:44.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6486}, {'_account_id': 6802}, {'_account_id': 6983}, {'_account_id': 9622}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-08-24 15:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f9b3684a6ef82290e57d20e5e141031abfd5b768', 'message': ""Document token hash algorithm option\n\nWith https://review.openstack.org/#/c/116509/ ,\ndjango-openstack-auth will support a new option for the token hash\nalgorithm. This adds the documentation to Horizon's local settings\nexample file.\n\nThis is for security hardening. The token hash algorithm defaults\nto MD5, which is considered too weak due to the potential for hash\ncollisions. Some security standards require a SHA2 hash algorithm to\nbe used.\n\nDocImpact\nSecurityImpact\n\nChange-Id: I6774b9b7215d191259586e4721e357487bb777cd\nCloses-Bug: #1174499\n""}, {'number': 2, 'created': '2014-08-26 23:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c3d1bf37c27eb292827625391ec72da54308743b', 'message': ""Document token hash algorithm option\n\nWith https://review.openstack.org/#/c/116509/ ,\ndjango-openstack-auth will support a new option for the token hash\nalgorithm. This adds the documentation to Horizon's local settings\nexample file.\n\nThis is for security hardening. The token hash algorithm defaults\nto MD5, which is considered too weak due to the potential for hash\ncollisions. Some security standards require a SHA2 hash algorithm to\nbe used.\n\nDocImpact\nSecurityImpact\n\nChange-Id: I6774b9b7215d191259586e4721e357487bb777cd\nCloses-Bug: #1174499\n""}, {'number': 3, 'created': '2014-09-22 00:55:28.000000000', 'files': ['doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example'], 'web_link': 'https://opendev.org/openstack/horizon/commit/372d033d89c0f5d305959a6ad5fd3e1159cc91ed', 'message': ""Document token hash algorithm option\n\nWith https://review.openstack.org/#/c/116509/ ,\ndjango-openstack-auth will support a new option for the token hash\nalgorithm. This adds the documentation to Horizon's local settings\nexample file.\n\nThis is for security hardening. The token hash algorithm defaults\nto MD5, which is considered too weak due to the potential for hash\ncollisions. Some security standards require a SHA2 hash algorithm to\nbe used.\n\nDocImpact\nSecurityImpact\n\nChange-Id: I6774b9b7215d191259586e4721e357487bb777cd\nCloses-Bug: #1174499\n""}]",2,116510,372d033d89c0f5d305959a6ad5fd3e1159cc91ed,19,9,3,6486,,,0,"Document token hash algorithm option

With https://review.openstack.org/#/c/116509/ ,
django-openstack-auth will support a new option for the token hash
algorithm. This adds the documentation to Horizon's local settings
example file.

This is for security hardening. The token hash algorithm defaults
to MD5, which is considered too weak due to the potential for hash
collisions. Some security standards require a SHA2 hash algorithm to
be used.

DocImpact
SecurityImpact

Change-Id: I6774b9b7215d191259586e4721e357487bb777cd
Closes-Bug: #1174499
",git fetch https://review.opendev.org/openstack/horizon refs/changes/10/116510/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/local/local_settings.py.example'],1,f9b3684a6ef82290e57d20e5e141031abfd5b768,bug/1174499, # The hash algorithm to use for authentication tokens. This must # match the hash algorithm that the identity server and the # auth_token middleware are using. Allowed values are the # algorithms supported by Python's hashlib library. # OPENSTACK_TOKEN_HASH_ALGORITHM = md5 ,,7,0
openstack%2Fbarbican~master~I0b151573ca3e345b0e09eed358550fff9571e204,openstack/barbican,master,I0b151573ca3e345b0e09eed358550fff9571e204,Update to the latest global requirements versions,MERGED,2014-10-03 20:14:21.000000000,2014-10-06 16:46:27.000000000,2014-10-06 16:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7764}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}]","[{'number': 1, 'created': '2014-10-03 20:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/57d60894f660fe46d4ff7283d27f55a8bbead3c3', 'message': 'Update to the latest global requirements versions\n\nExecuted the update.py script against Barbican per this repository:\nhttps://github.com/openstack/requirements\nThe resultant modified files are added per this CR.\n\nChange-Id: I0b151573ca3e345b0e09eed358550fff9571e204\n'}, {'number': 2, 'created': '2014-10-06 15:54:00.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/d4db1e22102281c08e3ea42f52e75894ac04d263', 'message': 'Update to the latest global requirements versions\n\nExecuted the update.py script against Barbican per this repository:\nhttps://github.com/openstack/requirements\nThe resultant modified files are added per this CR.\n\nChange-Id: I0b151573ca3e345b0e09eed358550fff9571e204\n'}]",2,126055,d4db1e22102281c08e3ea42f52e75894ac04d263,17,6,2,7789,,,0,"Update to the latest global requirements versions

Executed the update.py script against Barbican per this repository:
https://github.com/openstack/requirements
The resultant modified files are added per this CR.

Change-Id: I0b151573ca3e345b0e09eed358550fff9571e204
",git fetch https://review.opendev.org/openstack/barbican refs/changes/55/126055/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,57d60894f660fe46d4ff7283d27f55a8bbead3c3,sync-global-reqs-juno-rc1,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,29,15
openstack%2Fpython-ironicclient~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/python-ironicclient,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,MERGED,2014-10-04 18:47:40.000000000,2014-10-06 16:40:22.000000000,2014-10-06 16:40:22.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6618}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-10-04 18:47:40.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/aeabe6bb89a359e644c5adcb4c6456fd3428f6de', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,126156,aeabe6bb89a359e644c5adcb4c6456fd3428f6de,10,5,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/56/126156/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,aeabe6bb89a359e644c5adcb4c6456fd3428f6de,bug/1368910,," 'sphinx.ext.intersphinx', # Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None}",0,4
openstack%2Fbandit~master~Ia63b71962d8d472f241c02806df0f44fd25fc85c,openstack/bandit,master,Ia63b71962d8d472f241c02806df0f44fd25fc85c,"Better checks against blacklisted modules, catch __import__",MERGED,2014-09-25 14:00:17.000000000,2014-10-06 16:37:54.000000000,2014-10-06 16:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 11861}]","[{'number': 1, 'created': '2014-09-25 14:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/727b3eaafabc1ab2d3c20ba9f94ec43037e02f6d', 'message': 'Better checks against blacklisted modules, catch __import__\n\nChange-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c\n'}, {'number': 2, 'created': '2014-09-25 14:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/9fe3f258b9b4d11fd20300fe301729bc2c35bdc7', 'message': 'Better checks against blacklisted modules, catch __import__\n\nChange-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c\n'}, {'number': 3, 'created': '2014-10-02 13:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/b50f1bc8f491d8f7195eb25259ca108beb5b1be2', 'message': 'Better checks against blacklisted modules, catch __import__\n\nChange-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c\n'}, {'number': 4, 'created': '2014-10-02 13:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/21b255c9445867419502262d8000d8b7a4cd7c28', 'message': 'Better checks against blacklisted modules, catch __import__\n\nChange-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c\n'}, {'number': 5, 'created': '2014-10-02 13:41:20.000000000', 'files': ['bandit/tester.py', 'bandit/context.py', 'bandit/test_selector.py', 'examples/imports-function.py', 'plugins/blacklist_imports.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/d003bf71cd385d5eeabddaf42223708c870a1b50', 'message': 'Better checks against blacklisted modules, catch __import__\n\nChange-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c\n'}]",2,124058,d003bf71cd385d5eeabddaf42223708c870a1b50,20,6,5,11716,,,0,"Better checks against blacklisted modules, catch __import__

Change-Id: Ia63b71962d8d472f241c02806df0f44fd25fc85c
",git fetch https://review.opendev.org/openstack/bandit refs/changes/58/124058/2 && git format-patch -1 --stdout FETCH_HEAD,"['bandit/context.py', 'examples/imports-function.py', 'plugins/blacklist_imports.py']",3,727b3eaafabc1ab2d3c20ba9f94ec43037e02f6d,better_import_checks,"@checks_functions def blacklist_imports(context, config): if context.call_function_name_qual == '__import__': return blacklist_imports_func(context,config) else: checks = _get_checks(config) # for each check, go through and see if it matches all # qualifications for check in checks: # item 0=import, 1=message, 2=level if check[0]: for im in check[0]: if context.is_module_being_imported(im): return _get_result(check, im) # NOTE(tkelsey): I would like this to be a separate test that checks # functions but uses the config options of 'blacklist_imports' this # seems imposible with the current way Bandit works though, so I call # if from above. # def blacklist_imports_func(context, config): checks = _get_checks(config) if context.call_function_name_qual == '__import__': for check in checks: # item 0=import, 1=message, 2=level if check[0]: for im in check[0]: if im == context.call_args[0]: return _get_result(check, im) def _get_result(check, name): # substitute '{module}' for the imported module name message = check[1].replace('{module}', name) level = None if check[2] == 'ERROR': level = bandit.ERROR elif check[2] == 'WARN': level = bandit.WARN elif check[2] == 'INFO': level = bandit.INFO return level, ""%s"" % message def _get_checks(config): return checks","def blacklist_imports(context, config): # for each check, go through and see if it matches all qualifications for check in checks: does_match = True # item 0=import, 1=message, 2=level if check[0]: for im in check[0]: if context.is_module_being_imported(im): # substitute '{module}' for the imported module name message = check[1].replace('{module}', im) level = None if check[2] == 'ERROR': level = bandit.ERROR elif check[2] == 'WARN': level = bandit.WARN elif check[2] == 'INFO': level = bandit.INFO return level, ""%s"" % message ",63,22
openstack%2Fdesignate~master~I57f861fb164822f5fa37fddd0e1fb938ba95a04a,openstack/designate,master,I57f861fb164822f5fa37fddd0e1fb938ba95a04a,Imported Translations from Transifex,MERGED,2014-10-04 06:07:02.000000000,2014-10-06 16:35:52.000000000,2014-10-06 16:35:52.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2014-10-04 06:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8ccda731047787ea32ef66286b27e08215e16410', 'message': 'Imported Translations from Transifex\n\nChange-Id: I57f861fb164822f5fa37fddd0e1fb938ba95a04a\n'}, {'number': 2, 'created': '2014-10-05 06:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/eb4e7950229440309fcf652bc5e03fee5cc12259', 'message': 'Imported Translations from Transifex\n\nChange-Id: I57f861fb164822f5fa37fddd0e1fb938ba95a04a\n'}, {'number': 3, 'created': '2014-10-06 06:06:53.000000000', 'files': ['designate/locale/pt_BR/LC_MESSAGES/designate-log-critical.po', 'designate/locale/pt_BR/LC_MESSAGES/designate-log-error.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/ac8bbd26533636fae6c686226cc056a7d95d2dda', 'message': 'Imported Translations from Transifex\n\nChange-Id: I57f861fb164822f5fa37fddd0e1fb938ba95a04a\n'}]",0,126120,ac8bbd26533636fae6c686226cc056a7d95d2dda,11,3,3,11131,,,0,"Imported Translations from Transifex

Change-Id: I57f861fb164822f5fa37fddd0e1fb938ba95a04a
",git fetch https://review.opendev.org/openstack/designate refs/changes/20/126120/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/locale/pt_BR/LC_MESSAGES/designate-log-critical.po', 'designate/locale/pt_BR/LC_MESSAGES/designate-log-error.po']",2,8ccda731047787ea32ef66286b27e08215e16410,transifex/translations,"# Translations template for designate. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the designate project. # # Translators: # Rodrigo Felix de Almeida <rodrigofelixdealmeida@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Designate\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-10-04 06:06+0000\n"" ""PO-Revision-Date: 2014-10-04 04:36+0000\n"" ""Last-Translator: Rodrigo Felix de Almeida <rodrigofelixdealmeida@gmail.com>\n"" ""Language-Team: Portuguese (Brazil) (http://www.transifex.com/projects/p/"" ""designate/language/pt_BR/)\n"" ""Language: pt_BR\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" #: designate/api/middleware.py:267 msgid ""Missing context in request, please check."" msgstr ""Faltando contexto na requisio, por favor verifique."" #: designate/backend/impl_ipa/__init__.py:398 msgid """" ""Error: could not authenticate to IPA - please check for correct keytab file"" msgstr """" ""Erro: no foi possvel autenticar no IPA - por favor, verifique para "" ""corrigir o arquivo do keytab"" #: designate/backend/impl_ipa/auth.py:55 designate/backend/impl_ipa/auth.py:60 #, python-format msgid ""caught kerberos exception %r"" msgstr ""Capturada exceo do kerberos %r"" #: designate/manage/tlds.py:138 #, python-format msgid ""Number of errors: %d"" msgstr ""Nmero de erros: %d"" #: designate/manage/tlds.py:141 #, python-format msgid """" ""Error Lines:\n"" ""%s"" msgstr """" ""Linhas de erros:\n"" ""%s"" #: designate/mdns/handler.py:118 #, python-format msgid ""got exception while handling axfr request. Question is %(qr)s"" msgstr ""obtida exceo enquanto processando requisio axfr. Questo  %(qr)s"" #: designate/mdns/service.py:92 #, python-format msgid ""Failed to deserialize packet from %(host)s:%(port)d"" msgstr ""Falha ao deserializar pacote do %(host)s:%(port)d"" #: designate/mdns/service.py:178 #, python-format msgid ""Unhandled exception while processing request from %(host)s:%(port)d"" msgstr """" ""Exception no-tratada enquanto processando requisio do %(host)s:%(port)d"" #: designate/network_api/neutron.py:126 #, python-format msgid ""Failed calling Neutron %(region)s - %(endpoint)s"" msgstr ""Falha ao chamar Neutron %(region)s - %(endpoint)s"" #: designate/openstack/common/excutils.py:76 #, python-format msgid ""Original exception being dropped: %s"" msgstr ""Exceo original sendo descartada: %s"" #: designate/openstack/common/excutils.py:105 #, python-format msgid ""Unexpected exception occurred %d time(s)... retrying."" msgstr ""Exceo inesperada ocorrida %d vez(es)... tentando novamente."" #: designate/openstack/common/lockutils.py:117 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr ""No foi possvel liberar a trava adquirida `%s`"" #: designate/openstack/common/loopingcall.py:95 msgid ""in fixed duration looping call"" msgstr ""em chamada de durao fixa de loop"" #: designate/openstack/common/loopingcall.py:138 msgid ""in dynamic looping call"" msgstr ""em chamada de loop dinmico"" #: designate/openstack/common/policy.py:508 #, python-format msgid ""Failed to understand rule %s"" msgstr ""Falha ao entender regra %s"" #: designate/openstack/common/policy.py:518 #, python-format msgid ""No handler for matches of kind %s"" msgstr ""Nenhum manipulador para correspondncias do tipo %s"" #: designate/openstack/common/policy.py:788 #, python-format msgid ""Failed to understand rule %r"" msgstr ""Falha ao entender regra %r"" #: designate/openstack/common/service.py:188 msgid ""Exception during rpc cleanup."" msgstr ""Exceo durante limpeza rpc."" #: designate/openstack/common/service.py:277 msgid ""Unhandled exception"" msgstr ""Exceo no-tratada"" ",,170,0
openstack%2Fcookbook-openstack-block-storage~master~If4e75092f969bb6b5df29d715e1cff696e41a9a3,openstack/cookbook-openstack-block-storage,master,If4e75092f969bb6b5df29d715e1cff696e41a9a3,Allow cinder authtoken settings to be configurable,MERGED,2014-09-19 03:00:06.000000000,2014-10-06 16:30:38.000000000,2014-10-06 16:30:37.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 6983}, {'_account_id': 7128}, {'_account_id': 7138}, {'_account_id': 7148}, {'_account_id': 8651}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-09-19 03:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/3a7cbdf0ba639a19bd7de36c647411735829a7c8', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, memcached_servers,\nmemcache_security_strategy, memcache_secret_key and\nhash_algorithms to be configurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 2, 'created': '2014-09-19 03:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/f14eb161c9ec660b8e6e667aa1edcd5f88488b45', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, memcached_servers,\nmemcache_security_strategy, memcache_secret_key and\nhash_algorithms to be configurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 3, 'created': '2014-09-19 14:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/72154e6380b86e40aab8734fbe4e2010ac6a9aac', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 4, 'created': '2014-09-22 07:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/435d5b5f5021b449b3aeea3f013b9d3b1202e4ea', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 5, 'created': '2014-09-22 09:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/95ab30d8e8475ceee6e38832d0e0c0056c3e54a0', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 6, 'created': '2014-09-22 09:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/90be611721897ca9a72de467423a705b7eeee432', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 7, 'created': '2014-09-22 13:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/dccbd3b3fd7a1df14e74e1141a30d8fd01348d74', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 8, 'created': '2014-09-23 02:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/e9058ec3fc446ad966d454a01dac564fa75077ed', 'message': 'Allow block storage keystone authtoken to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 9, 'created': '2014-09-25 10:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/4d5fb2f4f8432b6d2b92d7b352e7904c98b893aa', 'message': 'Allow cinder authtoken settings to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}, {'number': 10, 'created': '2014-09-29 01:58:03.000000000', 'files': ['attributes/default.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/5641af2512bbf285ef80732d6baf28d66fc811ad', 'message': 'Allow cinder authtoken settings to be configurable\n\nThis patch is for allowing cafile, insecure,\nmemcached_servers, memcache_security_strategy,\nmemcache_secret_key and hash_algorithms to be\nconfigurable.\n\nChange-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3\nCloses-Bug: #1370906\n'}]",4,122593,5641af2512bbf285ef80732d6baf28d66fc811ad,41,8,10,8651,,,0,"Allow cinder authtoken settings to be configurable

This patch is for allowing cafile, insecure,
memcached_servers, memcache_security_strategy,
memcache_secret_key and hash_algorithms to be
configurable.

Change-Id: If4e75092f969bb6b5df29d715e1cff696e41a9a3
Closes-Bug: #1370906
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/93/122593/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md']",5,3a7cbdf0ba639a19bd7de36c647411735829a7c8,add_authtoken_configuration,"* `openstack[""block-storage""][""snapshot_name_template""]` - Template string to be used to generate snapshot names* `openstack['block-storage']['api']['auth']['memcached_servers']` - A list of memcached server(s) to use for caching. * `openstack['block-storage']['api']['auth']['memcache_security_strategy']` - Whether token data should be authenticated or authenticated and encrypted. Acceptable values are MAC or ENCRYPT. * `openstack['block-storage']['api']['auth']['memcache_secret_key']` - This string is used for key derivation. * `openstack['block-storage']['api']['auth']['hash_algorithms']` - Hash algorithms to use for hashing PKI tokens. * `openstack['block-storage']['api']['auth']['cafile']` - A PEM encoded Certificate Authority to use when verifying HTTPs connections.","* `openstack[""block-storage""][""snapshot_name_template""]` - Template string to be used to generate snapshot names",74,2
openstack%2Fpuppet-neutron~master~I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1,openstack/puppet-neutron,master,I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1,Install package libreswan in RHEL 7 systems for vpnaas,MERGED,2014-10-04 16:10:07.000000000,2014-10-06 16:24:33.000000000,2014-10-06 16:24:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-10-04 16:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/42ac78453d68097753abb80f3d47bece923ac5fb', 'message': 'Install package libreswan in RHEL 7 systems for vpnaas\n\nRHEL 7 systems have replaced the openswan package with libreswan.\n\nChange-Id: I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1\n'}, {'number': 2, 'created': '2014-10-04 16:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/9fb43126150f7fef339742b21567c9ab3c7816dc', 'message': 'Install package libreswan in RHEL 7 systems for vpnaas\n\nRHEL 7 systems have replaced the openswan package with libreswan.\n\nChange-Id: I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1\n'}, {'number': 3, 'created': '2014-10-05 02:23:08.000000000', 'files': ['spec/classes/neutron_agents_vpnaas_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/cd831f7a69d634ae735bc9642839024f8cf03c11', 'message': 'Install package libreswan in RHEL 7 systems for vpnaas\n\nRHEL 7 systems have replaced the openswan package with libreswan.\n\nChange-Id: I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1\n'}]",0,126150,cd831f7a69d634ae735bc9642839024f8cf03c11,12,5,3,7822,,,0,"Install package libreswan in RHEL 7 systems for vpnaas

RHEL 7 systems have replaced the openswan package with libreswan.

Change-Id: I4c8e891b83b8301cb111af1be6e84ec4cf9c69a1
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/50/126150/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_vpnaas_spec.rb', 'manifests/params.pp']",2,42ac78453d68097753abb80f3d47bece923ac5fb,libreswan_rhel7, if $::operatingsystemmajrelease >= 7 { $openswan_package = 'libreswan' } else { $openswan_package = 'openswan' }, $openswan_package = 'openswan',24,4
openstack%2Fpuppet-horizon~master~I194d7caecbce5e527a14b9d69b7d76281b5bc680,openstack/puppet-horizon,master,I194d7caecbce5e527a14b9d69b7d76281b5bc680,Add possibility to manage httpd service,ABANDONED,2014-08-20 15:45:33.000000000,2014-10-06 16:23:53.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-08-20 15:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/763d9748e897c6d3daba0a4ec5f46191cdc2e4b5', 'message': 'Add manage_service feature\n\npuppet-horizon lacks of disabling service managing. This patch adds\n$manage_service and $enabled parameters to relevant class.\n\nChange-Id: I194d7caecbce5e527a14b9d69b7d76281b5bc680\n'}, {'number': 2, 'created': '2014-08-25 13:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/9920026754dbd73458dc1adef653cec428f62e89', 'message': 'Add manage_service feature\n\npuppet-horizon lacks of disabling service managing. This patch adds\n$manage_service and $enabled parameters to relevant class.\n\nCloses-bug: #1359823\nChange-Id: I194d7caecbce5e527a14b9d69b7d76281b5bc680\n'}, {'number': 3, 'created': '2014-09-29 14:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/5bb4c0b073cef80645b892f24898da2e612bb7d8', 'message': 'Add possibility to manage httpd service\n\npuppet-horizon lacks of httpd service management. Unfortunately it is impossible\nimplement manage_service parameter as in other OpenStack related modules, so parameters\nservice_ensure and service_enable have been added.\n\nCloses-bug: #1359823\nChange-Id: I194d7caecbce5e527a14b9d69b7d76281b5bc680\n'}, {'number': 4, 'created': '2014-09-29 14:46:41.000000000', 'files': ['manifests/wsgi/apache.pp', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb', 'spec/classes/horizon_wsgi_apache_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/6a6c05437d588bf4692a5e95cb1731e07c921943', 'message': 'Add possibility to manage httpd service\n\npuppet-horizon lacks of httpd service management. Unfortunately it is impossible\nimplement manage_service parameter as in other OpenStack related modules, so parameters\nservice_ensure and service_enable have been added.\n\nCloses-bug: #1359823\nChange-Id: I194d7caecbce5e527a14b9d69b7d76281b5bc680\n'}]",0,115690,6a6c05437d588bf4692a5e95cb1731e07c921943,11,2,4,5241,,,0,"Add possibility to manage httpd service

puppet-horizon lacks of httpd service management. Unfortunately it is impossible
implement manage_service parameter as in other OpenStack related modules, so parameters
service_ensure and service_enable have been added.

Closes-bug: #1359823
Change-Id: I194d7caecbce5e527a14b9d69b7d76281b5bc680
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/90/115690/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/wsgi/apache.pp', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb', 'spec/classes/horizon_wsgi_apache_spec.rb']",4,763d9748e897c6d3daba0a4ec5f46191cdc2e4b5,manage_service,," ""include apache\n"" +",34,15
openstack%2Fopenstack-manuals~master~Icdc04c742349cfa9d6013dcb51b1f904e6fab391,openstack/openstack-manuals,master,Icdc04c742349cfa9d6013dcb51b1f904e6fab391,Add a note regarding image properties for volumes,MERGED,2014-10-05 07:01:48.000000000,2014-10-06 16:21:36.000000000,2014-10-06 16:21:35.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-05 07:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab971bb59291698d697b3f15da147c96ef109fd7', 'message': 'Add a note regarding image properties for volumes\n\nAs introduced in Havana, the glance_core_properties option\nin cinder is an important consideration if the core properties\nof images are changed. This patch adds a note in the image metadata\nsection.\n\nChange-Id: Icdc04c742349cfa9d6013dcb51b1f904e6fab391\nCloses-Bug: 1329419\n'}, {'number': 2, 'created': '2014-10-06 14:15:14.000000000', 'files': ['doc/image-guide/section_glance-image-metadata.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e79fa31ff17813775f3fcfe35cc27a7f064e39e', 'message': 'Add a note regarding image properties for volumes\n\nAs introduced in Havana, the glance_core_properties option\nin cinder is an important consideration if the core properties\nof images are changed. This patch adds a note in the image metadata\nsection.\n\nChange-Id: Icdc04c742349cfa9d6013dcb51b1f904e6fab391\nCloses-Bug: 1329419\n'}]",3,126178,9e79fa31ff17813775f3fcfe35cc27a7f064e39e,10,4,2,612,,,0,"Add a note regarding image properties for volumes

As introduced in Havana, the glance_core_properties option
in cinder is an important consideration if the core properties
of images are changed. This patch adds a note in the image metadata
section.

Change-Id: Icdc04c742349cfa9d6013dcb51b1f904e6fab391
Closes-Bug: 1329419
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/78/126178/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_glance-image-metadata.xml'],1,ab971bb59291698d697b3f15da147c96ef109fd7,bug/1329419," <note> <title>Volume-from-Image properties</title> <para>When creating Block Storage volumes from images, image properties should be considered. If you have altered the 'core' image properties, the Block Storage should be updated. Amend <option>glance_core_properties</option> in <filename>/etc/cinder/cinder.conf</filename> on all controller nodes to match the 'core' properties you have set in the Image service.</para> </note>",,9,0
openstack%2Fkeystone-specs~master~I31b872c48af91a5c438afd479160e19491827f00,openstack/keystone-specs,master,I31b872c48af91a5c438afd479160e19491827f00,Remove deprecated items from the Kilo release,MERGED,2014-09-22 13:23:32.000000000,2014-10-06 16:21:26.000000000,2014-10-06 16:21:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-09-22 13:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/3bcc426de9a8c0fa5f6dbe5abb174d8f30adba8f', 'message': 'Remove depreacted kvs backends\n\nPartially implements: bp deprecate-kvs\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}, {'number': 2, 'created': '2014-10-02 14:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/97685f28b912151f23d3444c78d5f70fb479f20e', 'message': 'Remove depreacted kvs backends\n\nPartially implements: bp deprecate-kvs\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}, {'number': 3, 'created': '2014-10-02 14:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/b6c415be3c068ac9d20b9096b78b1a432c0cab43', 'message': 'Remove depreacted kvs backends\n\nPartially implements: bp removed-as-of-kilo\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}, {'number': 4, 'created': '2014-10-02 15:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4303cb411ae7886456ec324274dcf2002ec214a6', 'message': 'Remove deprecated kvs backends\n\nPartially implements: bp removed-as-of-kilo\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}, {'number': 5, 'created': '2014-10-04 01:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/70e7d8d88856a30741e9ecf0d7f1870d796d0ab5', 'message': 'Remove deprecated items from the Kilo release\n\nImplements: bp removed-as-of-kilo\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}, {'number': 6, 'created': '2014-10-04 01:17:58.000000000', 'files': ['specs/kilo/removed-as-of-kilo.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/a6030f84f71e05ec0372da938b611bcc0c43c749', 'message': 'Remove deprecated items from the Kilo release\n\nImplements: bp removed-as-of-kilo\n\nChange-Id: I31b872c48af91a5c438afd479160e19491827f00\n'}]",6,123122,a6030f84f71e05ec0372da938b611bcc0c43c749,33,7,6,5707,,,0,"Remove deprecated items from the Kilo release

Implements: bp removed-as-of-kilo

Change-Id: I31b872c48af91a5c438afd479160e19491827f00
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/22/123122/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/deprecate-kvs.rst'],1,3bcc426de9a8c0fa5f6dbe5abb174d8f30adba8f,bp/removed-as-of-kilo,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Deprecate most of the kvs backends ================================== `bp deprecate-kvs <https://blueprints.launchpad.net/keystone/+spec/deprecate-kvs>`_ Now that we use sqlite for much of our lightweight backend testing, the usefulness of the kvs backends has diminished. Most of these are now marked as deprecate and for removal in Kilo. Problem Description =================== Maintaining the kvs backends provides added complications in terms of legacy internal APIs (e.g. the role metadata constructs in assignment), additional code to write for new APIs as well as the maintenance of the existing code and tests. The negatives now outweigh the positives of maintaining kvs for most of our backends. Proposed Change =============== The kvs backends (and their associated tests) will be removed for - Identity - Assignment - Trusts - Revoke extension Kvs is not recommended for production use in any of the above backends, and all had previously beem marked for removal in Kilo. The kvs backends will remain for - Catalog (since the templated version uses kvs) - Tokens (since this is an often selected backend for performance reasons) - Stats extension (since kvs is the only backend supported) Alternatives ------------ Keep maintaining the current code. Data Model Impact ----------------- None, other than the removal of the kvs storage of such models. REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- None, other than kvs will no longer be an option that can be specified for the backends in question. All these have previous been marked as deprecated, with log file entries to that effect. Performance Impact ------------------ None - kvs is not a recommended production option for the backends in question, and the sqlite alternative can be used in its place if required. Other Deployer Impact --------------------- None Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: henry-nash Work Items ---------- - Remove tests - Remove backend code Dependencies ============ None Testing ======= None Documentation Impact ==================== Changes to configuring.rst. References ========== None ",,129,0
openstack%2Fhorizon~master~I8320c789737ca6ca9fe04030a2c74c6fd6c303c8,openstack/horizon,master,I8320c789737ca6ca9fe04030a2c74c6fd6c303c8,Fix exponentially growing AJAX updates for table rows,ABANDONED,2014-10-06 16:20:14.000000000,2014-10-06 16:20:54.000000000,,[],"[{'number': 1, 'created': '2014-10-06 16:20:14.000000000', 'files': ['horizon/templates/horizon/qunit.html', 'horizon/static/horizon/tests/tables.js', 'horizon/static/horizon/lib/sinon-1.10.3.js', 'horizon/static/horizon/js/horizon.tables.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/53a2fa1c0126dbdcaad78554a1dbbb74aa4bdc26', 'message': 'Fix exponentially growing AJAX updates for table rows\n\nSchedule next table rows update only when the last row was updated.\nProvide unit test for that regression with XHR and timeouts being\nstubbed out via Sinon.js.\n\nChange-Id: Id603a4fde5713d8f2b85b1dcf72c82c93a87c755\nCloses-Bug: #1263665\n\nChange-Id: I8320c789737ca6ca9fe04030a2c74c6fd6c303c8\n'}]",0,126342,53a2fa1c0126dbdcaad78554a1dbbb74aa4bdc26,2,0,1,8040,,,0,"Fix exponentially growing AJAX updates for table rows

Schedule next table rows update only when the last row was updated.
Provide unit test for that regression with XHR and timeouts being
stubbed out via Sinon.js.

Change-Id: Id603a4fde5713d8f2b85b1dcf72c82c93a87c755
Closes-Bug: #1263665

Change-Id: I8320c789737ca6ca9fe04030a2c74c6fd6c303c8
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/126342/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/qunit.html', 'horizon/static/horizon/tests/tables.js', 'horizon/static/horizon/lib/sinon-1.10.3.js', 'horizon/static/horizon/js/horizon.tables.js']",4,53a2fa1c0126dbdcaad78554a1dbbb74aa4bdc26,bug/1263665," var $rows_to_update = $('tr.status_unknown.ajax-update'), rows_to_update = $rows_to_update.length; if (rows_to_update) { rows_to_update--; // Schedule next poll when all the rows were updated if (!rows_to_update) { // Set interval decay to this table, and increase if it already exist if(decay_constant === undefined) { decay_constant = 1; } else { decay_constant++; } $table.attr('decay_constant', decay_constant); // Poll until there are no rows in an ""unknown"" state on the page. var next_poll = interval * decay_constant; // Limit the interval to 30 secs if(next_poll > 30 * 1000) { next_poll = 30 * 1000; } setTimeout(horizon.datatables.update, next_poll); }"," var $rows_to_update = $('tr.status_unknown.ajax-update'); if ($rows_to_update.length) { // Set interval decay to this table, and increase if it already exist if(decay_constant === undefined) { decay_constant = 1; } else { decay_constant++; } $table.attr('decay_constant', decay_constant); // Poll until there are no rows in an ""unknown"" state on the page. next_poll = interval * decay_constant; // Limit the interval to 30 secs if(next_poll > 30 * 1000) { next_poll = 30 * 1000; } setTimeout(horizon.datatables.update, next_poll);",5158,14
openstack%2Fcongress-specs~master~I81c302883b0865975b211331899b3219739dfde9,openstack/congress-specs,master,I81c302883b0865975b211331899b3219739dfde9,Add a spec for refactoring datasource drivers,MERGED,2014-09-23 00:07:38.000000000,2014-10-06 16:18:43.000000000,2014-10-06 16:18:42.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-09-23 00:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/468d0a3202d2e1dcffd9190caa41ecc79b3c71f5', 'message': 'Add a spec for refactoring datasource drivers\n\nThis spec describes how we can refactor datasource drivers to make it easier\nto write new datasource drivers, and reduce duplicate code.\n\nblueprint: refactor-drivers\n\nChange-Id: I81c302883b0865975b211331899b3219739dfde9\n'}, {'number': 2, 'created': '2014-10-02 21:52:45.000000000', 'files': ['specs/juno/refactor-drivers.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/98b554d1277ca2b52ac0b6287712e8786745b72e', 'message': 'Add a spec for refactoring datasource drivers\n\nThis spec describes how we can refactor datasource drivers to make it easier\nto write new datasource drivers, and reduce duplicate code.\n\nblueprint: refactor-drivers\n\nChange-Id: I81c302883b0865975b211331899b3219739dfde9\n'}]",2,123288,98b554d1277ca2b52ac0b6287712e8786745b72e,11,4,2,12875,,,0,"Add a spec for refactoring datasource drivers

This spec describes how we can refactor datasource drivers to make it easier
to write new datasource drivers, and reduce duplicate code.

blueprint: refactor-drivers

Change-Id: I81c302883b0865975b211331899b3219739dfde9
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/88/123288/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/refactor-drivers.rst'],1,468d0a3202d2e1dcffd9190caa41ecc79b3c71f5,bp/refactor-drivers,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================================================== Pull common functionality into driver superclass, including data transformation =============================================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/congress/+spec/refactor-drivers Currently, each datasource driver contains code to convert data from the API call response to the Congress data tables. This change will make it easier for a developer to add each incremental data source driver. Problem description =================== Today, it takes more code than necessary to write a data source driver. The code is also more difficult to write than necessary. Some of these API responses (like in neutron list networks) contain nested data, for example in the list of networks, each network can contain a sub-list of subnets. The driver populates a separate table for subnets and the creates a key to link between the network table and the subnet table. Proposed change =============== To generalize the driver, this change will allow a driver class to specify how to extract data from the API response, and into which table/field to put the response data. To handle the sublist conversion, the driver class will specify if a field is a sublist, and then also specify a key, so that the main table can link to the subtable. This sublist relationship will be recursive, so that a sublist can also contain another sublist. Alternatives ------------ None Policy ------ None Policy Actions -------------- None Data Sources ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other Deployer Impacts ---------------------- This change will have an effect as soon as it is merged, but Congress should behave exactly as it did without the change. Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other hypervisors would implement the feature is required. Implementation ============== Assignee(s) ----------- ayip Work Items ---------- 1) Write new superclass. 2) Rewrite Nova driver. 3) Rewrite Neutron driver. 4) Rewrite Keystone driver. Dependencies ============ None Testing ======= Unit tests for superclass, and modify existing test cases for individual drivers. Documentation Impact ==================== This change will include new documentation for how to use the new datasource driver superclass. References ========== None ",,162,0
openstack%2Fcongress-specs~master~Ia2b86cf9937fb15da4bf4ecc8b36d9efad03d150,openstack/congress-specs,master,Ia2b86cf9937fb15da4bf4ecc8b36d9efad03d150,Added datalog-column-names spec,MERGED,2014-09-29 22:28:18.000000000,2014-10-06 16:13:47.000000000,2014-10-06 16:13:47.000000000,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 8155}, {'_account_id': 8215}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-09-29 22:28:18.000000000', 'files': ['specs/kilo/datalog-column-names.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/be14c6995438f35fd0d82fe0a525fc44f6de9bf3', 'message': 'Added datalog-column-names spec\n\nChange-Id: Ia2b86cf9937fb15da4bf4ecc8b36d9efad03d150\n'}]",1,124912,be14c6995438f35fd0d82fe0a525fc44f6de9bf3,8,5,1,8215,,,0,"Added datalog-column-names spec

Change-Id: Ia2b86cf9937fb15da4bf4ecc8b36d9efad03d150
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/12/124912/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/datalog-column-names.rst'],1,be14c6995438f35fd0d82fe0a525fc44f6de9bf3,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/congress/+spec/datalog-column-names Writing policy can be challenging when tables have many columns. This spec aims to give end users the ability to write policy by referencing column names directly in Datalog rules. Problem description =================== The main problem is that wide tables (those with many columns) are hard to use. (a) it is hard to remember what all the columns are, (b) it is easy to mistakenly use the same variable in two different tables in the body of the rule, i.e. to create an accidental join, (c) changes to the datasource drivers can require tedious/error-prone modifications to policy. Proposed change =============== Today people write policy statements as follows: error(net) :- neutron:networks(x0,x1,net,x3,x4,x5,x6,x7,x8,x9,x10), ... This change enables an alternative syntax where columns are referenced by name instead of position. error(net) :- neutron:networks(id=net), ... To implement this change, we will expand the grammar to accept column-name references and modify the AST constructor to translate the rules from column-name references back into position references. Alternatives ------------ There were 2 alternatives described in a ML discussion. 2) Be disciplined about writing narrow tables and write tutorials/recommendations demonstrating how. Instead of a table like... neutron:ports(port_id, addr_pairs, security_groups, extra_dhcp_opts, binding_cap, status, name, admin_state_up, network_id, tenant_id, binding_vif, device_owner, mac_address, fixed_ips, router_id, binding_host) we would have many tables... neutron:ports(port_id) neutron:ports.addr_pairs(port_id, addr_pairs) neutron:ports.security_groups(port_id, security_groups) neutron:ports.extra_dhcp_opts(port_id, extra_dhcp_opts) neutron:ports.name(port_id, name) ... People writing policy would write rules such as ... p(x) :- neutron:ports.name(port, name), ... [Here, the period e.g. in ports.name is not an operator--just a convenient way to spell the tablename.] To do this, Congress would need to know which columns in a table are sufficient to uniquely identify a row, which in most cases is just the ID. Pros: (i) this requires only changes in the datasource drivers; everything else remains the same (ii) still leveraging database technology under the hood (iii) policy is robust to changes in fields of original data Cons: (i) datasource driver can force policy writer to use wide tables (ii) this data model is much different than the original data models (iii) we need primary-key information about tables 3) Enhance the Congress policy language to handle objects natively. Instead of writing a rule like the following ... p(port_id, name, group) :- neutron:ports(port_id, addr_pairs, security_groups, extra_dhcp_opts, binding_cap, status, name, admin_state_up, network_id, tenant_id, binding_vif, device_owner, mac_address, fixed_ips, router_id, binding_host), neutron:ports.security_groups(security_group, group) we would write a rule such as p(port_id, name) :- neutron:ports(port), port.name(name), port.id(port_id), port.security_groups(group) The big difference here is that the period (.) is an operator in the language, just as in C++/Java. Pros: (i) The data model we use in Congress is almost exactly the same as the data model we use in Neutron/Nova. (ii) Policy is robust to changes in the Neutron/Nova data model as long as those changes only ADD fields. (iii) Programmers may be slightly more comfortable with this language. Cons: (i) The obvious implementation (changing the engine to implement the (.) operator directly is quite a change from traditional database technology. At this point, that seems risky. (ii) It is unclear how to implement this via a preprocessor (thereby leveraging database technology). The key problem I see is that we would need to translate port.name(...) into something like option (2) above. The difficulty is that TABLE could sometimes be a port, sometimes be a network, sometimes be a subnet, etc. (iii) Requires some extra syntactic restrictions to ensure we don't lose decidability. (iv) Because the Congress and Nova/Neutron models are the same, changes to the Nova/Neutron model can require rewriting policy. Policy ------ error(net) :- neutron:networks(id=net) Policy Actions -------------- None Data Sources ------------ None Data model impact ----------------- None REST API impact --------------- String-arguments to API calls representing policy can use either position or column syntax. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Other UIs can expose this enhanced syntax, but since currently all UIs just pass policy statements as strings, they will require no actual changes to leverage the enhancement. Performance Impact ------------------ Should have no performance impact, with the possible exception that eventually we will want to reverse the preprocessing step for tracing so that we present users with a more intuitive trace. Other Deployer Impacts ---------------------- None Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: thinrich Work Items ---------- * Modify grammar * Make datasource schemas available to runtime * Add preprocessor to rule AST constructor to convert column references into positional references. Dependencies ============ The following change makes datasource schema available to policy engine Change-Id: I7cfbd82c721509634c0acfd51e66031af2ed7f2d Testing ======= No tempest tests are necessary. Unit tests only. Documentation Impact ==================== Should include modifications to docs to simplify the examples that use tables with many columns. Will also require modifying the section where we introduce Datalog. References ========== Mailing list discussion: * http://lists.openstack.org/pipermail/openstack-dev/2014-August/041862.html ",,253,0
openstack%2Fmonasca-persister~master~Ic5512018256e5307bbebcbd9d57d3c8d2a0db937,openstack/monasca-persister,master,Ic5512018256e5307bbebcbd9d57d3c8d2a0db937,Fix flush logic to remove unnecessary variable assignment,MERGED,2014-10-06 14:55:34.000000000,2014-10-06 16:12:24.000000000,2014-10-06 16:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-10-06 14:55:34.000000000', 'files': ['monasca_persister/persister.py'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/4ed35ac9acc86edd4bd63b6794925089d7aa7c18', 'message': 'Fix flush logic to remove unnecessary variable assignment\n\nChange-Id: Ic5512018256e5307bbebcbd9d57d3c8d2a0db937\n'}]",0,126315,4ed35ac9acc86edd4bd63b6794925089d7aa7c18,8,5,1,12512,,,0,"Fix flush logic to remove unnecessary variable assignment

Change-Id: Ic5512018256e5307bbebcbd9d57d3c8d2a0db937
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/15/126315/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_persister/persister.py'],1,4ed35ac9acc86edd4bd63b6794925089d7aa7c18,, self.__json_body = [], self.__json_body = [],1,1
openstack%2Fkolla~master~I893adfa3b7d17249b6814fc161e6f3f1696d8cd6,openstack/kolla,master,I893adfa3b7d17249b6814fc161e6f3f1696d8cd6,add openssl to base image,MERGED,2014-10-06 01:32:21.000000000,2014-10-06 16:04:23.000000000,2014-10-06 16:04:23.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-06 01:32:21.000000000', 'files': ['docker/fedora-rdo-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/cab0499c6683935cc492214984d762f215275ede', 'message': 'add openssl to base image\n\nwe use openssl in many of our start scripts for password generation, so\nopenssl should probably be part of the base image.\n\nChange-Id: I893adfa3b7d17249b6814fc161e6f3f1696d8cd6\n'}]",0,126210,cab0499c6683935cc492214984d762f215275ede,8,4,1,8745,,,0,"add openssl to base image

we use openssl in many of our start scripts for password generation, so
openssl should probably be part of the base image.

Change-Id: I893adfa3b7d17249b6814fc161e6f3f1696d8cd6
",git fetch https://review.opendev.org/openstack/kolla refs/changes/10/126210/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/fedora-rdo-base/Dockerfile'],1,cab0499c6683935cc492214984d762f215275ede,larsks/fixbase, openssl \,,1,0
openstack%2Ffuel-web~master~I9e40b93fb046397d6e1eebcdd4ee446b4ae604c2,openstack/fuel-web,master,I9e40b93fb046397d6e1eebcdd4ee446b4ae604c2,Removal of redundant Health Check templates,MERGED,2014-10-06 15:23:33.000000000,2014-10-06 16:01:37.000000000,2014-10-06 16:01:36.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-10-06 15:23:33.000000000', 'files': ['nailgun/static/templates/cluster/healthcheck_testset.html', 'nailgun/static/templates/cluster/healthcheck_tests.html', 'nailgun/static/templates/cluster/healthcheck_credentials.html', 'nailgun/static/templates/cluster/healthcheck_tab.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/97897ec6d18f2c7d329579254850a4556e62f844', 'message': 'Removal of redundant Health Check templates\n\nChange-Id: I9e40b93fb046397d6e1eebcdd4ee446b4ae604c2\n'}]",0,126322,97897ec6d18f2c7d329579254850a4556e62f844,10,6,1,8766,,,0,"Removal of redundant Health Check templates

Change-Id: I9e40b93fb046397d6e1eebcdd4ee446b4ae604c2
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/22/126322/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/templates/cluster/healthcheck_testset.html', 'nailgun/static/templates/cluster/healthcheck_tests.html', 'nailgun/static/templates/cluster/healthcheck_credentials.html', 'nailgun/static/templates/cluster/healthcheck_tab.html']",4,97897ec6d18f2c7d329579254850a4556e62f844,,,"<div class=""wrapper""> <div class=""row-fluid page-sub-title""> <h3 class=""span6"" data-i18n=""cluster_page.healthcheck_tab.title""></h3> <div class=""span2 ostf-controls""> <div class=""toggle-credentials pull-right <%= isLocked ? 'hide' : '' %>""> <i></i> <div data-i18n=""cluster_page.healthcheck_tab.provide_credentials""></div> </div> </div> <div class=""span2 ostf-controls""> <label class=""checkbox pull-right select-all""> <input type=""checkbox"" class=""select-all-tumbler""><span data-i18n=""common.select_all""></span> </label> </div> <div class=""span2 ostf-controls""> <button class=""btn btn-success pull-right action-btn run-tests-btn"" data-i18n=""cluster_page.healthcheck_tab.run_tests_button""></button> <button class=""btn btn-danger pull-right action-btn stop-tests-btn hide"" data-i18n=""cluster_page.healthcheck_tab.stop_tests_button""></button> </div> </div> <% if (cluster.get('status') == 'new') { %> <div class=""row-fluid""> <div class=""span12""> <div class=""alert"" data-i18n=""cluster_page.healthcheck_tab.deploy_alert""></div> </div> </div> <% } %> <div class=""credentials collapse""></div> <div class=""testsets""> <div class=""progress-bar""> <div class=""progress progress-striped progress-success active""><div class=""bar""></div></div> </div> </div> <div class=""alert hide error-message alert-error"" data-i18n=""cluster_page.healthcheck_tab.not_available_alert""></div> </div>",0,151
openstack%2Fopenstacksdk~master~I7778438930bad2a32f79189b46d4fe7dbfbb67f6,openstack/openstacksdk,master,I7778438930bad2a32f79189b46d4fe7dbfbb67f6,Prepare for auth plugins,MERGED,2014-09-03 16:14:51.000000000,2014-10-06 15:59:39.000000000,2014-10-06 15:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7191}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-09-03 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2e895492ab71837112749c536b6c94422b856796', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 2, 'created': '2014-09-06 23:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8eb7bd45adbe570d02808f56bbf7b66d3deba0b3', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 3, 'created': '2014-09-07 12:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b50994598b642e0340e8d71b6723e4287f9a5ffc', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 4, 'created': '2014-09-07 15:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2a3feb5199c90d8e868e9271eb9b6b6852e25188', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 5, 'created': '2014-09-09 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1768da4c8261a27efc0764c553df1486305f9693', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 6, 'created': '2014-09-09 15:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/beda42caabe2c26fdebaf6e5891bb2a33d367e59', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 7, 'created': '2014-09-12 20:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5d7a01f02ddc11529a6e029c867b59f881946170', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 8, 'created': '2014-10-04 11:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2a7d8e7a074b9729e43a8b00765de31eb269d746', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}, {'number': 9, 'created': '2014-10-06 14:38:13.000000000', 'files': ['openstack/auth/identity/v2.py', 'openstack/auth/identity/authenticator.py', 'openstack/tests/auth/identity/test_authenticator.py', 'openstack/auth/base.py', 'openstack/auth/identity/base.py', 'openstack/tests/test_session.py', 'openstack/tests/auth/identity/test_v2.py', 'openstack/tests/auth/identity/test_v3.py', 'openstack/auth/identity/v3.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/549301b24ba56e3effacebb4a5eea68f2077d76e', 'message': 'Prepare for auth plugins\n\nIn order to get ready for auth plugins I kind of needed to\nturn auth plugins on their head.  The goals:\n\n* The plugin should know what to construct based on what the\n  user provides.  If a token is provided, use it.\n* If a token is provided and it expires, allow the user to reauth\n  with user name and password without the user having to do\n  anything special.\n* Support auth plugin names like identity_v2 and identity_v3 where\n  the user does not need to know exactly what method they are\n  using.\n* Keep is simple.\n\nIn the simple department, I think this makes it simplier for the\nuser.\n\nChange-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6\n'}]",8,118679,549301b24ba56e3effacebb4a5eea68f2077d76e,29,6,9,8736,,,0,"Prepare for auth plugins

In order to get ready for auth plugins I kind of needed to
turn auth plugins on their head.  The goals:

* The plugin should know what to construct based on what the
  user provides.  If a token is provided, use it.
* If a token is provided and it expires, allow the user to reauth
  with user name and password without the user having to do
  anything special.
* Support auth plugin names like identity_v2 and identity_v3 where
  the user does not need to know exactly what method they are
  using.
* Keep is simple.

In the simple department, I think this makes it simplier for the
user.

Change-Id: I7778438930bad2a32f79189b46d4fe7dbfbb67f6
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/79/118679/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/auth/identity/v2.py', 'openstack/auth/identity/authenticator.py', 'openstack/tests/auth/identity/test_authenticator.py', 'openstack/auth/base.py', 'openstack/auth/identity/base.py', 'openstack/tests/test_session.py', 'openstack/tests/auth/identity/test_v2.py', 'openstack/tests/auth/identity/test_v3.py', 'openstack/auth/identity/v3.py']",9,2e895492ab71837112749c536b6c94422b856796,stevedore," def __init__(self, auth_url, password='', project_id=None, project_name=None, reauthenticate=True, token=None, trust_id=None, user_domain_id=None, user_domain_name=None, user_id=None, user_name=None): This authorization plugin should be constructed with a password and user_id or user_name. It may also be constructed with a token. :param string password: User password for authentication. :param string project_id: Project ID for project scoping. :param string project_name: Project name for project scoping. :param bool reauthenticate: Get new token if token expires. :param string token: Token to use for authentication. :param string trust_id: Trust ID for trust scoping. :param string user_domain_id: User's domain ID for authentication. :param string user_domain_name: User's domain name for authentication. :param string user_name: User name for authentication. :param string user_id: User ID for authentication. :raises TypeError: if a user_id, user_name or token is not provided. if not (user_id or user_name or token): msg = 'You need to specify either a user_name, user_id or token' raise TypeError(msg) self.project_id = project_id self.project_name = project_name self.reauthenticate = reauthenticate self.trust_id = trust_id self.password_method = PasswordMethod( password=password, user_domain_id=user_domain_id, user_domain_name=user_domain_name, user_name=user_name, user_id=user_id, ) if token: self.token_method = TokenMethod(token=token) self.auth_methods = [self.token_method] else: self.auth_methods = [self.password_method] @classmethod def get_options(cls): options = super(Auth, cls).get_options() options.extend([ 'domain_id', 'domain_name', 'password', 'project_domain_id', 'project_domain_name', 'project_id', 'project_name', 'reauthenticate', 'token', 'trust_id', 'user_domain_id', 'user_domain_name', 'user_id', 'user_name', ]) return options def invalidate(self): if super(Auth, self).invalidate(): self.auth_methods = [self.password_method] return True return False def __init__(self, **kwargs): for param in kwargs: setattr(self, param, kwargs.get(param, None))class PasswordMethod(AuthMethod): elif self.user_name: user['name'] = self.user_nameclass TokenMethod(AuthMethod):"," def __init__(self, auth_url, auth_methods, trust_id=None, project_id=None, project_name=None, reauthenticate=True): :param list auth_methods: A collection of methods to authenticate with. :param string trust_id: Trust ID for trust scoping. :param string project_id: Project ID for project scoping. :param string project_name: Project name for project scoping. :param bool reauthenticate: Allow fetching a new token if the current one is going to expire. (optional) default True self.auth_methods = auth_methods self.trust_id = trust_id self.project_id = project_id self.project_name = project_name Note: When implementing an AuthMethod use the method_parameters and do not use positional arguments. Otherwise they can't be picked up by the factory method and don't work as well with AuthConstructors. _method_parameters = [] def __init__(self, **kwargs): for param in self._method_parameters: setattr(self, param, kwargs.pop(param, None)) if kwargs: msg = ""Unexpected Attributes: %s"" % "", "".join(kwargs.keys()) raise AttributeError(msg) @classmethod def _extract_kwargs(cls, kwargs): """"""Remove parameters related to this method from other kwargs."""""" return dict([(p, kwargs.pop(p, None)) for p in cls._method_parameters])@six.add_metaclass(abc.ABCMeta) class _AuthConstructor(Auth): """"""AuthConstructor creates an authentication plugin with one method. AuthConstructor is a means of creating an authentication plugin that contains only one authentication method. This is generally the required usage. An AuthConstructor creates an AuthMethod based on the method's arguments and the auth_method_class defined by the plugin. It then creates the auth plugin with only that authentication method. """""" _auth_method_class = None def __init__(self, auth_url, *args, **kwargs): method_kwargs = self._auth_method_class._extract_kwargs(kwargs) method = self._auth_method_class(*args, **method_kwargs) super(_AuthConstructor, self).__init__(auth_url, [method], **kwargs) class PasswordMethod(AuthMethod): _method_parameters = ['user_id', 'username', 'user_domain_id', 'user_domain_name', 'password'] def __init__(self, **kwargs): """"""Construct a User/Password based authentication method. :param string password: Password for authentication. :param string username: Username for authentication. :param string user_id: User ID for authentication. :param string user_domain_id: User's domain ID for authentication. :param string user_domain_name: User's domain name for authentication. """""" super(PasswordMethod, self).__init__(**kwargs) elif self.username: user['name'] = self.usernameclass Password(_AuthConstructor): _auth_method_class = PasswordMethod class TokenMethod(AuthMethod): _method_parameters = ['token'] def __init__(self, **kwargs): """"""Construct an Auth plugin to fetch a token from a token. :param string token: Token for authentication. """""" super(TokenMethod, self).__init__(**kwargs) class Token(_AuthConstructor): _auth_method_class = TokenMethod def __init__(self, auth_url, token, **kwargs): super(Token, self).__init__(auth_url, token=token, **kwargs)",366,304
openstack%2Fqa-specs~master~I1a72514085f37075dc707a3519a97cf8f3482f0e,openstack/qa-specs,master,I1a72514085f37075dc707a3519a97cf8f3482f0e,Move implemented specs into implemented dir,MERGED,2014-10-03 03:11:36.000000000,2014-10-06 15:49:40.000000000,2014-10-06 15:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 8859}]","[{'number': 1, 'created': '2014-10-03 03:11:36.000000000', 'files': ['specs/implemented/add-service-tags.rst', 'specs/implemented/tempest-client-scenarios.rst', 'specs/implemented/more-selectable-swift-tests.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/5dd111817dfc4746a12ea94a64ea14e4394ff01c', 'message': ""Move implemented specs into implemented dir\n\nIn the past few weeks a few more open BPs have been closed. Let's\nmigrate these specs into the implemented dir to mark them as such.\n\nChange-Id: I1a72514085f37075dc707a3519a97cf8f3482f0e\n""}]",0,125867,5dd111817dfc4746a12ea94a64ea14e4394ff01c,8,4,1,5196,,,0,"Move implemented specs into implemented dir

In the past few weeks a few more open BPs have been closed. Let's
migrate these specs into the implemented dir to mark them as such.

Change-Id: I1a72514085f37075dc707a3519a97cf8f3482f0e
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/67/125867/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/implemented/add-service-tags.rst', 'specs/implemented/tempest-client-scenarios.rst', 'specs/implemented/more-selectable-swift-tests.rst']",3,5dd111817dfc4746a12ea94a64ea14e4394ff01c,bp/s,,,0,0
openstack%2Foslo.messaging~master~I7cf746178f2a9fbcf6ee71a5cf083752f426664e,openstack/oslo.messaging,master,I7cf746178f2a9fbcf6ee71a5cf083752f426664e,RabbitMQ heartbeat implementation,ABANDONED,2014-10-06 15:43:59.000000000,2014-10-06 15:46:21.000000000,,[],"[{'number': 1, 'created': '2014-10-06 15:43:59.000000000', 'files': ['oslo/messaging/_drivers/pool.py', 'oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'test-requirements.txt', 'tests/drivers/test_impl_rabbit.py', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c094da277b5b20c75d26cd0382b0f9631cea684a', 'message': 'RabbitMQ heartbeat implementation\n\nAMQP offers a heartbeat feature to ensure that the application layer\npromptly finds out about disrupted connections (and also completely\nunresponsive peers). If the client requests heartbeats on connection, rabbit\nserver will regularly send messages to each connections with the expectation of\na response.\n\nChange-Id: I3dae1c1bee4ecf521903f3b1bee44dcda18bc3df\nCo-Authored-By: Oleksii Zamiatin <ozamiatin@mirantis.com>\nRelated-Bug: #856764\n\nChange-Id: I7cf746178f2a9fbcf6ee71a5cf083752f426664e\n'}]",0,126329,c094da277b5b20c75d26cd0382b0f9631cea684a,2,0,1,7536,,,0,"RabbitMQ heartbeat implementation

AMQP offers a heartbeat feature to ensure that the application layer
promptly finds out about disrupted connections (and also completely
unresponsive peers). If the client requests heartbeats on connection, rabbit
server will regularly send messages to each connections with the expectation of
a response.

Change-Id: I3dae1c1bee4ecf521903f3b1bee44dcda18bc3df
Co-Authored-By: Oleksii Zamiatin <ozamiatin@mirantis.com>
Related-Bug: #856764

Change-Id: I7cf746178f2a9fbcf6ee71a5cf083752f426664e
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/29/126329/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/pool.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'test-requirements.txt', 'test-requirements-py3.txt', 'tests/drivers/test_impl_rabbit.py']",6,c094da277b5b20c75d26cd0382b0f9631cea684a,heartbeat," expected=[dict(heartbeat=60, hostname='localhost', expected=[dict(heartbeat=60, hostname='host', expected=[dict(heartbeat=60, hostname='host', expected=[dict(heartbeat=60, hostname='host', expected=[dict(heartbeat=60, hostname='host', dict(heartbeat=60, hostname='host2',"," expected=[dict(hostname='localhost', expected=[dict(hostname='host', expected=[dict(hostname='host', expected=[dict(hostname='host', expected=[dict(hostname='host', dict(hostname='host2',",158,16
openstack%2Fdevstack~master~I12693350b2e381eea83d00785f324db37966bb54,openstack/devstack,master,I12693350b2e381eea83d00785f324db37966bb54,Reset no_proxy when the node is installed behind a proxy,ABANDONED,2014-10-06 15:34:33.000000000,2014-10-06 15:42:11.000000000,,[{'_account_id': 10385}],"[{'number': 1, 'created': '2014-10-06 15:34:33.000000000', 'files': ['functions-common', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5153f34f9b3e8b877065c51e964bcaae20548ade', 'message': 'Reset no_proxy when the node is installed behind a proxy\n\nCloses-Bug: 1291111\nCloses-Bug: 1322200\nProblem:\n=======\nWhen devstack is installed behind a proxy with proxy variables\nhttp_proxy and https_proxy being exported and without exporting\nno_proxy, the installation will fail. The reason is that any REST\nrequest sent to Keystone will be redirected to the proxy server.\nSolution:\n========\nFix involves appending no_proxy variable with localhost,HOST_IP,\nSERVICE_HOST if they are not included already and then exporting\nthe variable.\nSave it into localrc.\n\nChange-Id: I12693350b2e381eea83d00785f324db37966bb54\n'}]",0,126325,5153f34f9b3e8b877065c51e964bcaae20548ade,3,1,1,11226,,,0,"Reset no_proxy when the node is installed behind a proxy

Closes-Bug: 1291111
Closes-Bug: 1322200
Problem:
=======
When devstack is installed behind a proxy with proxy variables
http_proxy and https_proxy being exported and without exporting
no_proxy, the installation will fail. The reason is that any REST
request sent to Keystone will be redirected to the proxy server.
Solution:
========
Fix involves appending no_proxy variable with localhost,HOST_IP,
SERVICE_HOST if they are not included already and then exporting
the variable.
Save it into localrc.

Change-Id: I12693350b2e381eea83d00785f324db37966bb54
",git fetch https://review.opendev.org/openstack/devstack refs/changes/25/126325/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'stack.sh']",2,5153f34f9b3e8b877065c51e964bcaae20548ade,bug/1291111,# Make sure the proxy config is visible to sub-processes (new),# Make sure the proxy config is visible to sub-processes,2,2
openstack%2Foslo.vmware~master~I5309cad5b0eeb380387eb3051d80c59b783561e8,openstack/oslo.vmware,master,I5309cad5b0eeb380387eb3051d80c59b783561e8,Supress error logs when exception is thrown,MERGED,2014-10-06 13:05:50.000000000,2014-10-06 15:37:28.000000000,2014-10-06 15:37:27.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 8759}, {'_account_id': 9008}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-10-06 13:05:50.000000000', 'files': ['oslo/vmware/api.py', 'oslo/vmware/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/42eab0c82f0ef17cd1e7dd54da2964b8eb19c660', 'message': 'Supress error logs when exception is thrown\n\nThere are many cases when exceptions from the backend are expected and\nthese exceptions must not be logged as errors. For example it is a\ncommon pattern to catch DuplicateName/AlreadyExists exceptions and\nignore them in the cases when multiple threads are trying to perform the\nsame operation. Currently there is no way for clients to prevent logging\nthese exceptions as errors and the proper way to fix this is to just\nraise the exception in oslo and let the client decide if it must be\nlogged as an error or not.\n\nCloses-Bug: #1377927\nChange-Id: I5309cad5b0eeb380387eb3051d80c59b783561e8\n'}]",0,126287,42eab0c82f0ef17cd1e7dd54da2964b8eb19c660,8,6,1,9172,,,0,"Supress error logs when exception is thrown

There are many cases when exceptions from the backend are expected and
these exceptions must not be logged as errors. For example it is a
common pattern to catch DuplicateName/AlreadyExists exceptions and
ignore them in the cases when multiple threads are trying to perform the
same operation. Currently there is no way for clients to prevent logging
these exceptions as errors and the proper way to fix this is to just
raise the exception in oslo and let the client decide if it must be
logged as an error or not.

Closes-Bug: #1377927
Change-Id: I5309cad5b0eeb380387eb3051d80c59b783561e8
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/87/126287/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/api.py', 'oslo/vmware/common/loopingcall.py']",2,42eab0c82f0ef17cd1e7dd54da2964b8eb19c660,bug/1377927,, LOG.exception(_LE('in dynamic looping call')),0,7
openstack%2Fdesignate~proposed%2Fjuno~I05a54600bf7493ff467b8f5a81af7d682fe5ca7a,openstack/designate,proposed/juno,I05a54600bf7493ff467b8f5a81af7d682fe5ca7a,Multi backend attepts to read a deleted domain,MERGED,2014-09-29 18:07:38.000000000,2014-10-06 15:37:10.000000000,2014-10-06 15:37:10.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}, {'_account_id': 8174}]","[{'number': 1, 'created': '2014-09-29 18:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/31aa56987bfdba9ad5839e8eafbe6fb65e68f3ab', 'message': 'Multi backend attepts to read a deleted domain\n\nThis effectively results in all delete-domain requests failing when\nthe multi backend is used.\n\nCloses-Bug: 1375397\nChange-Id: I05a54600bf7493ff467b8f5a81af7d682fe5ca7a\n'}, {'number': 2, 'created': '2014-09-30 22:12:27.000000000', 'files': ['designate/backend/impl_multi.py', 'designate/tests/test_backend/test_multi.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/4de363a5eeb07dae13cfab653ef92798966c8e1d', 'message': 'Multi backend attepts to read a deleted domain\n\nThis effectively results in all delete-domain requests failing when\nthe multi backend is used.\n\nCloses-Bug: 1375397\nChange-Id: I05a54600bf7493ff467b8f5a81af7d682fe5ca7a\n'}]",0,124822,4de363a5eeb07dae13cfab653ef92798966c8e1d,12,7,2,741,,,0,"Multi backend attepts to read a deleted domain

This effectively results in all delete-domain requests failing when
the multi backend is used.

Closes-Bug: 1375397
Change-Id: I05a54600bf7493ff467b8f5a81af7d682fe5ca7a
",git fetch https://review.opendev.org/openstack/designate refs/changes/22/124822/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/backend/impl_multi.py', 'designate/tests/test_backend/test_multi.py']",2,31aa56987bfdba9ad5839e8eafbe6fb65e68f3ab,bug/1375397, domain['id'] = 'a8aeb2ee-40da-476b-a9d8-26bf0c0065f6',,6,2
openstack%2Frally~master~Ic8935d3069225d95ef800e98c1d9c842f17b4639,openstack/rally,master,Ic8935d3069225d95ef800e98c1d9c842f17b4639,"Change default endpoint_type to ""public""",MERGED,2014-10-06 12:20:54.000000000,2014-10-06 15:30:12.000000000,2014-10-06 15:30:11.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-10-06 12:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/14bb6fe7efb605c3223f27b452cb17f8cc15b466', 'message': 'Change default endpoint_type to ""public""\n\nChange-Id: Ic8935d3069225d95ef800e98c1d9c842f17b4639\n'}, {'number': 2, 'created': '2014-10-06 14:21:35.000000000', 'files': ['rally/deploy/engines/existing.py', 'tests/objects/test_endpoint.py', 'doc/source/deploy_engines.rst', 'doc/samples/deployments/existing-keystone-v3.json', 'tests/test_osclients.py', 'doc/samples/deployments/existing.json', 'rally/objects/endpoint.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d3ba7792f4a98f9fa1c9462bbeace9875a631ee4', 'message': 'Change default endpoint_type to ""public""\n\nChange-Id: Ic8935d3069225d95ef800e98c1d9c842f17b4639\n'}]",5,126274,d3ba7792f4a98f9fa1c9462bbeace9875a631ee4,17,4,2,6124,,,0,"Change default endpoint_type to ""public""

Change-Id: Ic8935d3069225d95ef800e98c1d9c842f17b4639
",git fetch https://review.opendev.org/openstack/rally refs/changes/74/126274/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/deploy/engines/existing.py', 'tests/objects/test_endpoint.py', 'doc/source/deploy_engines.rst', 'doc/samples/deployments/existing-keystone-v3.json', 'tests/test_osclients.py', 'doc/samples/deployments/existing.json', 'rally/objects/endpoint.py']",7,14bb6fe7efb605c3223f27b452cb17f8cc15b466,bug/fix," region_name=None, endpoint_type=consts.EndpointType.PUBLIC,"," region_name=None, endpoint_type=consts.EndpointType.INTERNAL,",23,15
openstack%2Fneutron~stable%2Ficehouse~I772a86bf896a1d3d9c69c545ce6918b0fe3a2e48,openstack/neutron,stable/icehouse,I772a86bf896a1d3d9c69c545ce6918b0fe3a2e48,update vsm credential correctly,MERGED,2014-10-03 23:01:56.000000000,2014-10-06 15:25:43.000000000,2014-10-06 15:25:42.000000000,"[{'_account_id': 3}, {'_account_id': 6502}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9680}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-03 23:01:56.000000000', 'files': ['neutron/tests/unit/cisco/test_network_db.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3ccaa72eef077dea00128456c48c7a706c0a0d3', 'message': 'update vsm credential correctly\n\nToday if we modify the n1kv VSM credential in the cisco_plugins.ini, the\nolder VSM ip address remains in the db, and all requests are sent to\nthe older VSM. This patch deletes all n1kv VSM credentials on neutron\nstart up before adding the newer VSM credentials. Hence making sure\nthat there is only one n1kv VSM IP address and credential in the db.\n\nChange-Id: I772a86bf896a1d3d9c69c545ce6918b0fe3a2e48\nCloses-Bug: #1341014\n(cherry picked from commit 487b98a73f6be41697dd4f59a245f1a7f338a72f)\n'}]",0,126095,d3ccaa72eef077dea00128456c48c7a706c0a0d3,19,15,1,11757,,,0,"update vsm credential correctly

Today if we modify the n1kv VSM credential in the cisco_plugins.ini, the
older VSM ip address remains in the db, and all requests are sent to
the older VSM. This patch deletes all n1kv VSM credentials on neutron
start up before adding the newer VSM credentials. Hence making sure
that there is only one n1kv VSM IP address and credential in the db.

Change-Id: I772a86bf896a1d3d9c69c545ce6918b0fe3a2e48
Closes-Bug: #1341014
(cherry picked from commit 487b98a73f6be41697dd4f59a245f1a7f338a72f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/126095/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/cisco/test_network_db.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py']",3,d3ccaa72eef077dea00128456c48c7a706c0a0d3,update_vsm_credential, 2. clear N1kv credential 3. Initialize Nexus1000v and Credential DB 4. Establish communication with Cisco Nexus1000V network_db_v2.delete_all_n1kv_credentials(), 2. Initialize Nexus1000v and Credential DB 3. Establish communication with Cisco Nexus1000V,36,2
openstack%2Fmurano-dashboard~master~I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4,openstack/murano-dashboard,master,I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4,Remove font-awesome resources from muranodashboard/static,MERGED,2014-10-03 15:31:24.000000000,2014-10-06 15:23:48.000000000,2014-10-06 15:23:48.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 11098}]","[{'number': 1, 'created': '2014-10-03 15:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ebf450b242464ea51994a79d07d97555dac44825', 'message': 'Remove font-awesome resources from muranodashboard/static\n\n... because horizon packages them as xstatic package, muranodashboard\ncan get them as horizon static resources, no need to keep a separate\ncopy of them.\n\nChange-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4\n'}, {'number': 2, 'created': '2014-10-03 15:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c413f461c6ccc80b4aa6b59fe461066102e8e7a0', 'message': 'Remove font-awesome resources from muranodashboard/static\n\n... because horizon packages them as xstatic package, muranodashboard\ncan get them from horizon static resources, no need to keep a separate\ncopy of them.\n\nChange-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4\n'}, {'number': 3, 'created': '2014-10-06 14:49:40.000000000', 'files': ['muranodashboard/static/muranodashboard/fonts/FontAwesome.otf', 'muranodashboard/static/muranodashboard/css/font-awesome.min.css', 'muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.eot', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.woff', 'muranodashboard/templates/catalog/app_details.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.svg', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.ttf'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e4408ffdb7cb39c7676b5c919e087cd6f2b1934c', 'message': 'Remove font-awesome resources from muranodashboard/static\n\n... because horizon packages them as xstatic package, muranodashboard\ncan get them as horizon static resources, no need to keep a separate\ncopy of them.\n\nChange-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4\n'}]",0,125995,e4408ffdb7cb39c7676b5c919e087cd6f2b1934c,25,9,3,8040,,,0,"Remove font-awesome resources from muranodashboard/static

... because horizon packages them as xstatic package, muranodashboard
can get them as horizon static resources, no need to keep a separate
copy of them.

Change-Id: I53c2b0cf1ad19b7a805bb3a3b683f43d452083d4
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/95/125995/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/static/muranodashboard/fonts/FontAwesome.otf', 'muranodashboard/static/muranodashboard/css/font-awesome.min.css', 'muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.eot', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.woff', 'muranodashboard/templates/catalog/app_details.html', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.svg', 'muranodashboard/static/muranodashboard/fonts/fontawesome-webfont.ttf']",8,ebf450b242464ea51994a79d07d97555dac44825,,,,2,420
openstack%2Fcookbook-openstack-compute~master~I7ddb7854e0ce2ea1890d82958d4575407be06c01,openstack/cookbook-openstack-compute,master,I7ddb7854e0ce2ea1890d82958d4575407be06c01,"Add attributes for ssl_only, cert and key",MERGED,2014-09-17 16:25:35.000000000,2014-10-06 15:23:19.000000000,2014-10-06 15:23:18.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2589}, {'_account_id': 7128}, {'_account_id': 8112}, {'_account_id': 8410}, {'_account_id': 9488}]","[{'number': 1, 'created': '2014-09-17 16:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/fe0edac039f79d492d36bcded92d30a1e7086b46', 'message': 'Add attributes for ssl_only, cert and key\n\nAdd some basic attributes for vnc support.\n\nChange-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01\nCloses-bug: #1370592\n'}, {'number': 2, 'created': '2014-09-19 15:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/b7d282d570e67374776095f09e1050e7b0815e62', 'message': 'Add attributes for ssl_only, cert and key\n\nAdd some basic attributes for vnc support.\n\nChange-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01\nCloses-bug: #1370592\n'}, {'number': 3, 'created': '2014-09-22 19:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/8173481165bc7af9ff6029e64a93da8e161b1802', 'message': 'Add attributes for ssl_only, cert and key\n\nAdd some basic attributes for vnc support.\n\nChange-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01\nCloses-bug: #1370592\n'}, {'number': 4, 'created': '2014-09-25 22:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/65729c5d471c2b66a5ce6ac86018cf665f49a970', 'message': 'Add attributes for ssl_only, cert and key\n\nAdd some basic attributes for vnc support.\n\nChange-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01\nCloses-bug: #1370592\n'}, {'number': 5, 'created': '2014-09-29 15:30:30.000000000', 'files': ['attributes/default.rb', 'spec/nova-common_spec.rb', 'CHANGELOG.md', 'templates/default/nova.conf.erb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/c8c7a6e561ed7480c0547ad060b45f0a638a48b1', 'message': 'Add attributes for ssl_only, cert and key\n\nAdd some basic attributes for vnc support.\n\nChange-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01\nCloses-bug: #1370592\n'}]",1,122198,c8c7a6e561ed7480c0547ad060b45f0a638a48b1,38,7,5,7128,,,0,"Add attributes for ssl_only, cert and key

Add some basic attributes for vnc support.

Change-Id: I7ddb7854e0ce2ea1890d82958d4575407be06c01
Closes-bug: #1370592
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/98/122198/5 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/nova-common_spec.rb', 'CHANGELOG.md', 'templates/default/nova.conf.erb', 'README.md']",5,fe0edac039f79d492d36bcded92d30a1e7086b46,bug/1370592,* `openstack['compute']['ssl_only'] = Disallow non-encrypted connections * `openstack['compute']['cert'] = SSL certificate file * `openstack['compute']['key'] = SSL key file (if separate from cert),,25,0
openstack%2Fneutron~stable%2Ficehouse~Id1f94a5844111a916f984d6dd7bda2cb4e11e1ee,openstack/neutron,stable/icehouse,Id1f94a5844111a916f984d6dd7bda2cb4e11e1ee,Networks are not scheduled to DHCP agents for Cisco N1KV plugin,MERGED,2014-10-03 18:24:22.000000000,2014-10-06 15:19:54.000000000,2014-10-06 15:19:53.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 8940}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-03 18:24:22.000000000', 'files': ['neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2152f5b03fbccd001ef0fba7a55de42eb74aeb86', 'message': ""Networks are not scheduled to DHCP agents for Cisco N1KV plugin\n\nWith the config option 'network_auto_schedule = False' in\nneutron.conf, networks do not get scheduled to available DHCP\nagents. The fix is to explicitly schedule the network as part\nof the subnet creation flow.\n\nConflicts:\n\tneutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py\n\nChange-Id: Id1f94a5844111a916f984d6dd7bda2cb4e11e1ee\nCloses-Bug: #1356609\n(cherry picked from commit 0fcedae747f257e2424b669ec65f32b76f12155a)\n""}]",0,126028,2152f5b03fbccd001ef0fba7a55de42eb74aeb86,19,15,1,11757,,,0,"Networks are not scheduled to DHCP agents for Cisco N1KV plugin

With the config option 'network_auto_schedule = False' in
neutron.conf, networks do not get scheduled to available DHCP
agents. The fix is to explicitly schedule the network as part
of the subnet creation flow.

Conflicts:
	neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py

Change-Id: Id1f94a5844111a916f984d6dd7bda2cb4e11e1ee
Closes-Bug: #1356609
(cherry picked from commit 0fcedae747f257e2424b669ec65f32b76f12155a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/126028/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py']",2,2152f5b03fbccd001ef0fba7a55de42eb74aeb86,," if not q_conf.CONF.network_auto_schedule: # Schedule network to a DHCP agent net = self.get_network(context, sub['network_id']) self.schedule_network(context, net)",,16,0
openstack%2Fsolum~master~I53f407c1f685bbf12bbe021af9fe3708e0527cc8,openstack/solum,master,I53f407c1f685bbf12bbe021af9fe3708e0527cc8,Add static type and attribute definition metadata files.,MERGED,2014-09-30 19:42:25.000000000,2014-10-06 15:15:42.000000000,2014-10-06 15:15:41.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 11813}]","[{'number': 1, 'created': '2014-09-30 19:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/05d84c8c0a83a8e08598bdb3618cd84d7bc0a8fa', 'message': 'Add static type and attribute definition metadata files. These files\nwill be used to construct the type_definition and attribute_definition\nresources that describe Solum CAMP API resource model.\n\nImplements: blueprint solum-camp-api\n\nChange-Id: I53f407c1f685bbf12bbe021af9fe3708e0527cc8'}, {'number': 2, 'created': '2014-09-30 20:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f91e165fcd6c8b4decb467f6f4cedb322e685eff', 'message': 'Add static type and attribute definition metadata files.\n\nImplements: blueprint solum-camp-api\n\nChange-Id: I53f407c1f685bbf12bbe021af9fe3708e0527cc8'}, {'number': 3, 'created': '2014-09-30 22:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2b9f6afd3c0a563cd22e72b7b07a4b85548d56c8', 'message': 'Add static type and attribute definition metadata files.\n\nImplements: blueprint solum-camp-api\n\nChange-Id: I53f407c1f685bbf12bbe021af9fe3708e0527cc8'}, {'number': 4, 'created': '2014-10-01 21:55:16.000000000', 'files': ['etc/solum/camp/attributeDefs/backward_compatible_specification_versions.json', 'etc/solum/camp/attributeDefs/extension_links.json', 'etc/solum/camp/attributeDefs/required.json', 'etc/solum/camp/typeDefs/platform_endpoints.json', 'etc/solum/camp/attributeDefs/representation_skew.json', 'etc/solum/camp/attributeDefs/backward_compatible_implementation_versions.json', 'etc/solum/camp/attributeDefs/mime_type.json', 'etc/solum/camp/attributeDefs/value.json', 'etc/solum/camp/attributeDefs/operations_uri.json', 'etc/solum/camp/attributeDefs/plans_uri.json', 'etc/solum/camp/attributeDefs/default_value.json', 'etc/solum/camp/typeDefs/assemblies.json', 'etc/solum/camp/attributeDefs/uri.json', 'etc/solum/camp/typeDefs/service.json', 'etc/solum/camp/attributeDefs/target_resource.json', 'etc/solum/camp/typeDefs/platform_endpoint.json', 'etc/solum/camp/attributeDefs/plan_uri.json', 'etc/solum/camp/attributeDefs/parameter_definitions_uri.json', 'etc/solum/camp/attributeDefs/service.json', 'etc/solum/camp/typeDefs/platform.json', 'etc/solum/camp/typeDefs/sensors.json', 'etc/solum/camp/attributeDefs/implementation_version.json', 'etc/solum/camp/attributeDefs/sensors_uri.json', 'etc/solum/camp/typeDefs/parameter_definitions.json', 'etc/solum/camp/attributeDefs/services_uri.json', 'etc/solum/camp/attributeDefs/auth_scheme.json', 'etc/solum/camp/attributeDefs/format_links.json', 'etc/solum/camp/attributeDefs/parameter_type.json', 'etc/solum/camp/attributeDefs/tags.json', 'etc/solum/camp/attributeDefs/service_links.json', 'etc/solum/camp/attributeDefs/version.json', 'etc/solum/camp/attributeDefs/characteristics.json', 'etc/solum/camp/attributeDefs/parameter_extension_uri.json', 'etc/solum/camp/attributeDefs/related_components.json', 'etc/solum/camp/attributeDefs/artifact.json', 'etc/solum/camp/attributeDefs/camp_version.json', 'etc/solum/camp/typeDefs/services.json', 'etc/solum/camp/attributeDefs/attribute_definition_links.json', 'etc/solum/camp/attributeDefs/type_definition_links.json', 'etc/solum/camp/attributeDefs/type_definitions_uri.json', 'etc/solum/camp/typeDefs/extensions.json', 'etc/solum/camp/typeDefs/operation.json', 'etc/solum/camp/typeDefs/type_definitions.json', 'etc/solum/camp/attributeDefs/description.json', 'etc/solum/camp/attributeDefs/type.json', 'etc/solum/camp/attributeDefs/supported_formats_uri.json', 'etc/solum/camp/attributeDefs/documentation.json', 'etc/solum/camp/attributeDefs/components.json', 'etc/solum/camp/attributeDefs/assemblies.json', 'etc/solum/camp/attributeDefs/platform_uri.json', 'etc/solum/camp/typeDefs/plans.json', 'etc/solum/camp/typeDefs/camp_resource.json', 'etc/solum/camp/attributeDefs/platform_endpoints_uri.json', 'etc/solum/camp/typeDefs/component.json', 'etc/solum/camp/typeDefs/type_definition.json', 'etc/solum/camp/attributeDefs/external_management_resource.json', 'etc/solum/camp/attributeDefs/specification_version.json', 'etc/solum/camp/typeDefs/sensor.json', 'etc/solum/camp/typeDefs/attribute_definition.json', 'etc/solum/camp/typeDefs/format.json', 'etc/solum/camp/attributeDefs/assemblies_uri.json', 'etc/solum/camp/attributeDefs/name.json', 'etc/solum/camp/typeDefs/extension.json', 'etc/solum/camp/attributeDefs/attribute_type.json', 'etc/solum/camp/attributeDefs/extensions_uri.json', 'etc/solum/camp/attributeDefs/origin.json', 'etc/solum/camp/typeDefs/assembly.json', 'etc/solum/camp/typeDefs/formats.json', 'etc/solum/camp/attributeDefs/status.json', 'etc/solum/camp/attributeDefs/platform_endpoint_links.json', 'etc/solum/camp/typeDefs/parameter_definition.json', 'etc/solum/camp/attributeDefs/artifacts.json', 'etc/solum/camp/attributeDefs/plan_links.json', 'etc/solum/camp/attributeDefs/operation_links.json', 'etc/solum/camp/attributeDefs/timestamp.json', 'etc/solum/camp/attributeDefs/sensor_links.json', 'etc/solum/camp/attributeDefs/sensor_type.json', 'etc/solum/camp/typeDefs/plan.json', 'etc/solum/camp/attributeDefs/parameter_definition_links.json', 'etc/solum/camp/attributeDefs/services.json', 'etc/solum/camp/typeDefs/operations.json', 'etc/solum/camp/attributeDefs/assembly_links.json'], 'web_link': 'https://opendev.org/openstack/solum/commit/d576d1f7203165cf4d2bdf128781484ba8c8cb9b', 'message': 'Add static type and attribute definition metadata files.\n\nImplements: blueprint solum-camp-api\n\nChange-Id: I53f407c1f685bbf12bbe021af9fe3708e0527cc8\n'}]",9,125170,d576d1f7203165cf4d2bdf128781484ba8c8cb9b,21,4,4,11813,,,0,"Add static type and attribute definition metadata files.

Implements: blueprint solum-camp-api

Change-Id: I53f407c1f685bbf12bbe021af9fe3708e0527cc8
",git fetch https://review.opendev.org/openstack/solum refs/changes/70/125170/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/solum/camp/attributeDefs/backward_compatible_specification_versions.json', 'etc/solum/camp/attributeDefs/extension_links.json', 'etc/solum/camp/attributeDefs/required.json', 'etc/solum/camp/typeDefs/platform_endpoints.json', 'etc/solum/camp/attributeDefs/representation_skew.json', 'etc/solum/camp/attributeDefs/backward_compatible_implementation_versions.json', 'etc/solum/camp/attributeDefs/mime_type.json', 'etc/solum/camp/attributeDefs/value.json', 'etc/solum/camp/attributeDefs/operations_uri.json', 'etc/solum/camp/attributeDefs/plans_uri.json', 'etc/solum/camp/attributeDefs/default_value.json', 'etc/solum/camp/typeDefs/assemblies.json', 'etc/solum/camp/attributeDefs/uri.json', 'etc/solum/camp/typeDefs/service.json', 'etc/solum/camp/attributeDefs/target_resource.json', 'etc/solum/camp/typeDefs/platform_endpoint.json', 'etc/solum/camp/attributeDefs/plan_uri.json', 'etc/solum/camp/attributeDefs/parameter_definitions_uri.json', 'etc/solum/camp/attributeDefs/service.json', 'etc/solum/camp/typeDefs/platform.json', 'etc/solum/camp/typeDefs/sensors.json', 'etc/solum/camp/attributeDefs/implementation_version.json', 'etc/solum/camp/attributeDefs/sensors_uri.json', 'etc/solum/camp/typeDefs/parameter_definitions.json', 'etc/solum/camp/attributeDefs/services_uri.json', 'etc/solum/camp/attributeDefs/auth_scheme.json', 'etc/solum/camp/attributeDefs/format_links.json', 'etc/solum/camp/attributeDefs/parameter_type.json', 'etc/solum/camp/attributeDefs/tags.json', 'etc/solum/camp/attributeDefs/service_links.json', 'etc/solum/camp/attributeDefs/version.json', 'etc/solum/camp/attributeDefs/characteristics.json', 'etc/solum/camp/attributeDefs/parameter_extension_uri.json', 'etc/solum/camp/attributeDefs/related_components.json', 'etc/solum/camp/attributeDefs/artifact.json', 'etc/solum/camp/attributeDefs/camp_version.json', 'etc/solum/camp/typeDefs/services.json', 'etc/solum/camp/attributeDefs/attribute_definition_links.json', 'etc/solum/camp/attributeDefs/type_definition_links.json', 'etc/solum/camp/attributeDefs/type_definitions_uri.json', 'etc/solum/camp/typeDefs/extensions.json', 'etc/solum/camp/typeDefs/operation.json', 'etc/solum/camp/typeDefs/type_definitions.json', 'etc/solum/camp/attributeDefs/description.json', 'etc/solum/camp/attributeDefs/type.json', 'etc/solum/camp/attributeDefs/supported_formats_uri.json', 'etc/solum/camp/attributeDefs/documentation.json', 'etc/solum/camp/attributeDefs/components.json', 'etc/solum/camp/attributeDefs/assemblies.json', 'etc/solum/camp/attributeDefs/platform_uri.json', 'etc/solum/camp/typeDefs/plans.json', 'etc/solum/camp/typeDefs/camp_resource.json', 'etc/solum/camp/attributeDefs/platform_endpoints_uri.json', 'etc/solum/camp/typeDefs/component.json', 'etc/solum/camp/typeDefs/type_definition.json', 'etc/solum/camp/attributeDefs/external_management_resource.json', 'etc/solum/camp/attributeDefs/specification_version.json', 'etc/solum/camp/typeDefs/sensor.json', 'etc/solum/camp/typeDefs/attribute_definition.json', 'etc/solum/camp/typeDefs/format.json', 'etc/solum/camp/attributeDefs/assemblies_uri.json', 'etc/solum/camp/attributeDefs/name.json', 'etc/solum/camp/typeDefs/extension.json', 'etc/solum/camp/attributeDefs/attribute_type.json', 'etc/solum/camp/attributeDefs/extensions_uri.json', 'etc/solum/camp/attributeDefs/origin.json', 'etc/solum/camp/typeDefs/assembly.json', 'etc/solum/camp/typeDefs/formats.json', 'etc/solum/camp/attributeDefs/status.json', 'etc/solum/camp/attributeDefs/platform_endpoint_links.json', 'etc/solum/camp/typeDefs/parameter_definition.json', 'etc/solum/camp/attributeDefs/artifacts.json', 'etc/solum/camp/attributeDefs/plan_links.json', 'etc/solum/camp/attributeDefs/operation_links.json', 'etc/solum/camp/attributeDefs/timestamp.json', 'etc/solum/camp/attributeDefs/sensor_links.json', 'etc/solum/camp/attributeDefs/sensor_type.json', 'etc/solum/camp/typeDefs/plan.json', 'etc/solum/camp/attributeDefs/parameter_definition_links.json', 'etc/solum/camp/attributeDefs/services.json', 'etc/solum/camp/typeDefs/operations.json', 'etc/solum/camp/attributeDefs/assembly_links.json']",82,05d84c8c0a83a8e08598bdb3618cd84d7bc0a8fa,bp/solum-camp-api,"{ ""uri"": ""assembly_links"", ""name"": ""assembly_links"", ""type"": ""attribute_definition"", ""description"": ""CAMP 1.1 standard assembly_links attribute definition"", ""documentation"": ""http://docs.oasis-open.org/camp/camp-spec/v1.1/camp-spec-v1.1.pdf"", ""attribute_type"": ""Link[]"" } ",,1271,0
openstack%2Fcookbook-openstack-dashboard~master~Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d,openstack/cookbook-openstack-dashboard,master,Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d,Config OPENSTACK_TOKEN_HASH_ALGORITHM,MERGED,2014-09-22 07:45:19.000000000,2014-10-06 15:13:41.000000000,2014-10-06 15:13:41.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 6983}, {'_account_id': 7128}, {'_account_id': 7138}, {'_account_id': 8112}, {'_account_id': 11915}]","[{'number': 1, 'created': '2014-09-22 07:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/b5a4d1647ebcfed0ded4aae8c12b2faf57b3b02f', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAdd this according to the following code changes.\nhttps://review.openstack.org/#/c/116509/\nhttps://review.openstack.org/#/c/116510/\n\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 2, 'created': '2014-09-22 08:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/492564a678159d62c1db6a4992f636086855758f', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAdd this according to the following code changes.\nhttps://review.openstack.org/#/c/116509/\nhttps://review.openstack.org/#/c/116510/\n\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 3, 'created': '2014-09-22 13:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/af318c568c37cfaefef01a23ae4b00a975e34ccd', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAdd this according to the following code changes.\nhttps://review.openstack.org/#/c/116509/\nhttps://review.openstack.org/#/c/116510/\n\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 4, 'created': '2014-09-23 02:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/baae4765191b4343e98960d298870b41b0a6a87c', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 5, 'created': '2014-09-23 03:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/729ebf9d634a1e6c0ec23621cf47a9ee67ad7245', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 6, 'created': '2014-09-23 07:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/4079f2c4b5d1943a87b10f04359a132e1e13ae1c', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 7, 'created': '2014-09-24 01:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/03d0c9f085e3ac306b472a8d67e33ada2ad8385a', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 8, 'created': '2014-09-24 05:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/5f6414d983087241975ea246868a827b5b0cd231', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 9, 'created': '2014-09-24 13:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/066d294fc61fb7bdab9546bda27af73ef1d31359', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 10, 'created': '2014-09-25 05:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/96435252b8074d5b53ba557cce57e141edafb6ef', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 11, 'created': '2014-09-25 08:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/e76565f93b9841cf994d8708e2e345a63c1a2dfb', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}, {'number': 12, 'created': '2014-09-27 03:23:36.000000000', 'files': ['templates/default/local_settings.py.erb', 'attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/514081ef0ba9008ffd5cd99cb8543f6ef2c8c027', 'message': 'Config OPENSTACK_TOKEN_HASH_ALGORITHM\n\nAllow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable\n\nCloses-Bug: #1372717\nChange-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d\n'}]",12,123063,514081ef0ba9008ffd5cd99cb8543f6ef2c8c027,48,7,12,6983,,,0,"Config OPENSTACK_TOKEN_HASH_ALGORITHM

Allow OPENSTACK_TOKEN_HASH_ALGORITHM to be configurable

Closes-Bug: #1372717
Change-Id: Ifd26bfeff7dab70c30ad4cbb1007ec697e79017d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/63/123063/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/local_settings.py.erb', 'spec/server_spec.rb', 'CHANGELOG.md']",3,b5a4d1647ebcfed0ded4aae8c12b2faf57b3b02f,hash_algorithm,* Add hash algorithms option to local_settings,,15,0
openstack%2Fbarbican~master~Ib455d164209a7e9a3c9fb6fd4561ec196009a02e,openstack/barbican,master,Ib455d164209a7e9a3c9fb6fd4561ec196009a02e,Adding tox job for local functional test dev,MERGED,2014-10-03 00:18:25.000000000,2014-10-06 15:07:37.000000000,2014-10-06 15:07:37.000000000,"[{'_account_id': 3}, {'_account_id': 7764}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-10-03 00:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/59f334bf68468727dd7dcb1fa70f01048ebce3fd', 'message': 'Adding tox job for local functional test dev\n\n* Also adding a couple basic log messages to highlight when\ntests start and end.\n\nChange-Id: Ib455d164209a7e9a3c9fb6fd4561ec196009a02e\n'}, {'number': 2, 'created': '2014-10-03 00:19:21.000000000', 'files': ['functionaltests/common/client.py', 'functionaltests/api/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/7fd68bed3771f398e2951a0a224028098d83a5a7', 'message': 'Adding tox job for local functional test dev\n\n* Also adding a couple basic log messages to highlight when\ntests start and end.\n\nChange-Id: Ib455d164209a7e9a3c9fb6fd4561ec196009a02e\n'}]",1,125824,7fd68bed3771f398e2951a0a224028098d83a5a7,12,7,2,7262,,,0,"Adding tox job for local functional test dev

* Also adding a couple basic log messages to highlight when
tests start and end.

Change-Id: Ib455d164209a7e9a3c9fb6fd4561ec196009a02e
",git fetch https://review.opendev.org/openstack/barbican refs/changes/24/125824/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/common/client.py', 'functionaltests/api/base.py', 'tox.ini']",3,59f334bf68468727dd7dcb1fa70f01048ebce3fd,adding_tox_env,[testenv:functional] # This tox env is purely to make local test developments easier # Note: This requires local running instances of Barbican and Keystone deps = {[testenv]deps} nose git+https://github.com/openstack/tempest.git commands = nosetests {toxinidir}/functionaltests ,,30,3
openstack%2Fsolum~master~I1a0836c12fee97a5192aa40f5c2948809d009ae9,openstack/solum,master,I1a0836c12fee97a5192aa40f5c2948809d009ae9,Stop using intersphinx,MERGED,2014-09-25 08:51:20.000000000,2014-10-06 15:04:51.000000000,2014-10-06 15:04:51.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6547}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-09-25 08:51:20.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/3d8e76896c845099be9793c9340206ad25fdbe6f', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I1a0836c12fee97a5192aa40f5c2948809d009ae9\nRelated-Bug: #1368910\n""}]",0,123980,3d8e76896c845099be9793c9340206ad25fdbe6f,11,6,1,167,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I1a0836c12fee97a5192aa40f5c2948809d009ae9
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/solum refs/changes/80/123980/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,3d8e76896c845099be9793c9340206ad25fdbe6f,bug/1368910,," 'sphinx.ext.intersphinx', # Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None}",0,4
openstack%2Ftempest~master~I111d1af8a17e9fc30c5f52a26041a6912f1e4625,openstack/tempest,master,I111d1af8a17e9fc30c5f52a26041a6912f1e4625,Refactor stack actions and add stack check,ABANDONED,2014-07-11 18:08:30.000000000,2014-10-06 15:04:44.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 9189}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-11 18:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3f6b92a4536e690e28f637ae4c0970384629007', 'message': 'Refactor stack actions and add stack check\n\nAll stack actions are very similar and can reuse the same code.  This\nalso adds an entry for stack-check as well.\n\nChange-Id: I111d1af8a17e9fc30c5f52a26041a6912f1e4625\nImplements: blueprint stack-check\n'}, {'number': 2, 'created': '2014-08-20 14:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39d930a58dd45deaf43b826d5e56ca0f3b161a49', 'message': 'Refactor stack actions and add stack check\n\nAll stack actions are very similar and can reuse the same code.  This\nalso adds an entry for stack-check as well.\n\nChange-Id: I111d1af8a17e9fc30c5f52a26041a6912f1e4625\nImplements: blueprint stack-check\n'}, {'number': 3, 'created': '2014-09-11 19:46:31.000000000', 'files': ['tempest/services/orchestration/json/orchestration_client.py', 'tempest/api/orchestration/stacks/test_non_empty_stack.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab8d961bfbef1b9bf9dcdd5336f37261fdce5542', 'message': 'Refactor stack actions and add stack check\n\nAll stack actions are very similar and can reuse the same code.  This\nalso adds an entry for stack-check as well.\n\nChange-Id: I111d1af8a17e9fc30c5f52a26041a6912f1e4625\nImplements: blueprint stack-check\n'}]",0,106456,ab8d961bfbef1b9bf9dcdd5336f37261fdce5542,17,4,3,9189,,,0,"Refactor stack actions and add stack check

All stack actions are very similar and can reuse the same code.  This
also adds an entry for stack-check as well.

Change-Id: I111d1af8a17e9fc30c5f52a26041a6912f1e4625
Implements: blueprint stack-check
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/106456/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/orchestration/json/orchestration_client.py', 'tempest/api/orchestration/stacks/test_non_empty_stack.py']",2,e3f6b92a4536e690e28f637ae4c0970384629007,bp/stack-check," def _test_stack_action(self, action): args = { 'stack_identifier': self.stack_identifier, 'action': action, } resp, stack = self.client.stack_action(**args) self.assertEqual('200', resp['status']) status = '%s_COMPLETE' % action.upper() self.client.wait_for_stack_status(self.stack_identifier, status) self._test_stack_action('suspend') self._test_stack_action('resume') @test.attr(type='gate') def test_check_stack(self): """"""Perform a stack check."""""" self._test_stack_action('check')"," resp, suspend_stack = self.client.suspend_stack(self.stack_identifier) self.assertEqual('200', resp['status']) self.client.wait_for_stack_status(self.stack_identifier, 'SUSPEND_COMPLETE') resp, resume_stack = self.client.resume_stack(self.stack_identifier) self.assertEqual('200', resp['status']) self.client.wait_for_stack_status(self.stack_identifier, 'RESUME_COMPLETE')",20,18
openstack%2Ftraining-guides~master~I7e18fefb1804fb81a82dd9d5fda958ccc3430a55,openstack/training-guides,master,I7e18fefb1804fb81a82dd9d5fda958ccc3430a55,Testing do not merge,ABANDONED,2014-10-06 14:51:44.000000000,2014-10-06 15:03:31.000000000,,[{'_account_id': 7007}],"[{'number': 1, 'created': '2014-10-06 14:51:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/42525582c4525773f1cd322316ab7cba722449db', 'message': 'Testing do not merge\n\nChange-Id: I7e18fefb1804fb81a82dd9d5fda958ccc3430a55\n'}]",0,126313,42525582c4525773f1cd322316ab7cba722449db,4,1,1,7007,,,0,"Testing do not merge

Change-Id: I7e18fefb1804fb81a82dd9d5fda958ccc3430a55
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/13/126313/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,42525582c4525773f1cd322316ab7cba722449db,tg_tools, {toxinidir}/tools/test_upstream-training {toxinidir},,1,0
openstack%2Fnova~master~Idf4d29a0df2280c78fe879fa09632c666ff04436,openstack/nova,master,Idf4d29a0df2280c78fe879fa09632c666ff04436,libvirt: convert volume snapshot test case to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-06 15:01:41.000000000,2014-10-06 15:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f5f06b6e42b9e0aa9df24bac1b7230e1b0d1ed3', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}, {'number': 2, 'created': '2014-09-17 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/557205db9247b0c40746dfe18d4f6f8fb20ed17a', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adb8d27db7444751f2130616ff342eae578252a7', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d8b34c07d70a394a25bb5305ee5c2110c4b4212', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/820145d46abd001ea43ddeea59cdadbcc9a18bd1', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}, {'number': 6, 'created': '2014-10-01 17:24:09.000000000', 'files': ['nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bfbeae7c7b1956e6f75a525eff57651464261059', 'message': 'libvirt: convert volume snapshot test case to avoid DB usage\n\nConvert the LibvirtVolumeSnapshotTestCase so that it avoids\ncreating instance objects in the database. This allows it to\nbe converted to use NoDBTestCase improving perf from 4.2s\nto 2.3s\n\nPartial-bug: #1369516\nChange-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436\n'}]",0,121874,bfbeae7c7b1956e6f75a525eff57651464261059,50,15,6,1779,,,0,"libvirt: convert volume snapshot test case to avoid DB usage

Convert the LibvirtVolumeSnapshotTestCase so that it avoids
creating instance objects in the database. This allows it to
be converted to use NoDBTestCase improving perf from 4.2s
to 2.3s

Partial-bug: #1369516
Change-Id: Idf4d29a0df2280c78fe879fa09632c666ff04436
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/121874/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,4f5f06b6e42b9e0aa9df24bac1b7230e1b0d1ed3,libvirt-nodb-tests,class LibvirtVolumeSnapshotTestCase(test.NoDBTestCase): instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst) instance = objects.Instance(**self.inst),"class LibvirtVolumeSnapshotTestCase(test.TestCase): instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst) instance = db.instance_create(self.c, self.inst)",12,12
openstack%2Fnova~master~If2ab915388c2a1ba0565d4aa8bb66b98db535094,openstack/nova,master,If2ab915388c2a1ba0565d4aa8bb66b98db535094,libvirt: convert volume usage test case to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-06 15:01:22.000000000,2014-10-06 15:01:20.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d18afac1abd6e7ef7e4bff0a90772195a742f1d', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}, {'number': 2, 'created': '2014-09-17 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6eccc67bf743d664694b8138dba174ff20b01a80', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/978c71f36caf12dc65da396ba9037b8a1d1c10fc', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a4547321faba92894049b08b48144760da93ed9', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9189215295626c18960a6f7cc4a958bb663735b', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}, {'number': 6, 'created': '2014-10-01 17:24:09.000000000', 'files': ['nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/baba74450e5f1f794601ca7bee99fa149321b66e', 'message': 'libvirt: convert volume usage test case to avoid DB usage\n\nConvert LibvirtVolumeUsageTestCase so that it avoids creating an\ninstance in the database. This allows it to be switched over to\nuse NoDBTestCase, improving perf from 1.7s to 0.13s.\n\nPartial-bug: #1369516\nChange-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094\n'}]",0,121873,baba74450e5f1f794601ca7bee99fa149321b66e,44,13,6,1779,,,0,"libvirt: convert volume usage test case to avoid DB usage

Convert LibvirtVolumeUsageTestCase so that it avoids creating an
instance in the database. This allows it to be switched over to
use NoDBTestCase, improving perf from 1.7s to 0.13s.

Partial-bug: #1369516
Change-Id: If2ab915388c2a1ba0565d4aa8bb66b98db535094
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/121873/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,6d18afac1abd6e7ef7e4bff0a90772195a742f1d,libvirt-nodb-tests,"class LibvirtVolumeUsageTestCase(test.NoDBTestCase): self.ins_ref = objects.Instance( id=1729, uuid='875a8070-d0b9-4949-8b31-104d125c9a64' )","class LibvirtVolumeUsageTestCase(test.TestCase): # creating instance inst = {} inst['uuid'] = '875a8070-d0b9-4949-8b31-104d125c9a64' self.ins_ref = db.instance_create(self.c, inst)",5,5
openstack%2Fnova~master~I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f,openstack/nova,master,I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f,libvirt: convert LibvirtNonblockingTestCase to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-06 15:01:04.000000000,2014-10-06 15:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5432a915e6e2ee64cdc982139e3a77b8b9a2731d', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}, {'number': 2, 'created': '2014-09-17 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a81f4365c9c06bccb7ea3db6f6f1e7d618d92a5', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8b529147b18ed27dba717c35702545002d80bbf', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3a8e9273bd0cc800b102833b65c502cb5c05b8c', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3226de85fabb7fe77ab96e5a124a44ad3aedc6f', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}, {'number': 6, 'created': '2014-10-01 17:24:09.000000000', 'files': ['nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2b9e2f9398da09983268983586868102d8264820', 'message': 'libvirt: convert LibvirtNonblockingTestCase to avoid DB usage\n\nThe LibvirtNonblockingTestCase test case does not do anything DB\nrelated. Convert it to NoDBTestCase to avoid DB setup penalty.\nThis improves perf from 1.8s to 0.4s\n\nPartial-bug: #1369516\nChange-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f\n'}]",0,121872,2b9e2f9398da09983268983586868102d8264820,49,15,6,1779,,,0,"libvirt: convert LibvirtNonblockingTestCase to avoid DB usage

The LibvirtNonblockingTestCase test case does not do anything DB
related. Convert it to NoDBTestCase to avoid DB setup penalty.
This improves perf from 1.8s to 0.4s

Partial-bug: #1369516
Change-Id: I6ff4f46a2e8c2e436d40dd47134f5ec496ce153f
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/121872/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,5432a915e6e2ee64cdc982139e3a77b8b9a2731d,libvirt-nodb-tests,class LibvirtNonblockingTestCase(test.NoDBTestCase):,class LibvirtNonblockingTestCase(test.TestCase):,1,1
openstack%2Fopenstack-chef-repo~master~I398c40f274cbb12caa228297b0bcc2c49ece0fcc,openstack/openstack-chef-repo,master,I398c40f274cbb12caa228297b0bcc2c49ece0fcc,Add Chef Zero(local mode) deploy guide,MERGED,2014-08-15 01:31:39.000000000,2014-10-06 14:59:12.000000000,2014-10-06 14:59:12.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 7128}, {'_account_id': 9884}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-08-15 01:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/d21de82d642fc144da8e34b847b68cfb2b74de76', 'message': 'Add Chef Zero(local mode) deploy guide.\n\nChange-Id: I398c40f274cbb12caa228297b0bcc2c49ece0fcc\n'}, {'number': 2, 'created': '2014-09-16 05:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/5ccfd01de440cd6d1345e96d5a2953e71b37e857', 'message': 'Add Chef Zero(local mode) deploy guide.\n\nChange-Id: I398c40f274cbb12caa228297b0bcc2c49ece0fcc\n'}, {'number': 3, 'created': '2014-09-26 08:16:13.000000000', 'files': ['environments/zero-demo.json', 'README.md'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/63e35f9d4f6b21f3a8abc8c18bdab41c4fd9cf8a', 'message': 'Add Chef Zero(local mode) deploy guide\n\nChange-Id: I398c40f274cbb12caa228297b0bcc2c49ece0fcc\n'}]",5,114413,63e35f9d4f6b21f3a8abc8c18bdab41c4fd9cf8a,21,5,3,9488,,,0,"Add Chef Zero(local mode) deploy guide

Change-Id: I398c40f274cbb12caa228297b0bcc2c49ece0fcc
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/13/114413/2 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,d21de82d642fc144da8e34b847b68cfb2b74de76,chef-zero-mode,"# Usage with Chef server # # Usage with Chef Zero # Chef Zero is Chef local mode, without Chef server. ## Install Chef ``` curl -L https://www.opscode.com/chef/install.sh | bash ``` ## Checkout cookbooks ``` git clone https://github.com/stackforge/openstack-chef-repo /opt/chef/embedded/bin/gem install berkshelf /opt/chef/embedded/bin/berks install --path=./cookbooks ``` ## Prepare Chef environment Here is a minimal environment [environments/zero-demo.json](environments/zero-demo.json) ``` { ""name"": ""demo"", ""override_attributes"": { ""mysql"": { ""server_root_password"": ""ilikerandompasswords"" }, ""openstack"": { ""developer_mode"": true } } } } ``` ## Start to deploy ``` chef-client -z knife node -z add run_list your_node_name 'role[allinone-compute]' chef-client -z -E demo ``` ",# Usage #,47,1
openstack%2Fpython-cloudkittyclient~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/python-cloudkittyclient,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,MERGED,2014-10-04 18:51:57.000000000,2014-10-06 14:54:53.000000000,2014-10-06 14:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-10-04 18:51:57.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/3d5814ed2ccbf8d838c13b0125339f81f5e346cc', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,126161,3d5814ed2ccbf8d838c13b0125339f81f5e346cc,6,2,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/61/126161/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,3d5814ed2ccbf8d838c13b0125339f81f5e346cc,bug/1368910,," 'sphinx.ext.intersphinx',",0,1
openstack%2Fnova~master~I7172edace9e568d961fc1dc9f449cd858551bb0d,openstack/nova,master,I7172edace9e568d961fc1dc9f449cd858551bb0d,libvirt: convert firewall tests to avoid DB usage,MERGED,2014-09-16 14:24:23.000000000,2014-10-06 14:54:08.000000000,2014-10-06 14:54:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 7746}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 14:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/976e03a233d38740eb2a864848e46ec11976168d', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}, {'number': 2, 'created': '2014-09-17 09:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a26f6433bcea484c95b2b476535be9b630a36eac', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}, {'number': 3, 'created': '2014-09-22 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b8498de06343b10753517c0d8894103da18c493', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}, {'number': 4, 'created': '2014-09-24 17:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8008f45fde53e2e58f526e2a14a7383e4b06bca1', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}, {'number': 5, 'created': '2014-09-30 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e621443b14866c30dbeab71971110328ee13af8', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}, {'number': 6, 'created': '2014-10-01 17:24:09.000000000', 'files': ['nova/tests/virt/libvirt/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13c696f330a4567fc51606493d1451c7a2201fa1', 'message': ""libvirt: convert firewall tests to avoid DB usage\n\nThe test_firewall.py test suite had alot of code which created\nand accessed database objects. This can all be avoided by making\nmore use of mock to patch out a handful of object access functions.\nThe test_cidr_rule_nwfilter_xml was deleted entirely since it was\nnever actually validating any aspect of the nwfilter execution,\nso didn't add any benefits over the other test functions that\nrun.\n\nPartial-bug: #1369516\nChange-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d\n""}]",0,121871,13c696f330a4567fc51606493d1451c7a2201fa1,52,13,6,1779,,,0,"libvirt: convert firewall tests to avoid DB usage

The test_firewall.py test suite had alot of code which created
and accessed database objects. This can all be avoided by making
more use of mock to patch out a handful of object access functions.
The test_cidr_rule_nwfilter_xml was deleted entirely since it was
never actually validating any aspect of the nwfilter execution,
so didn't add any benefits over the other test functions that
run.

Partial-bug: #1369516
Change-Id: I7172edace9e568d961fc1dc9f449cd858551bb0d
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/121871/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_firewall.py'],1,976e03a233d38740eb2a864848e46ec11976168d,libvirt-nodb-tests,"from nova import objectsfrom nova.virt import virtapiclass FakeVirtAPI(virtapi.VirtAPI): def provider_fw_rule_get_all(self, context): return [] class IptablesFirewallTestCase(test.NoDBTestCase): FakeVirtAPI(), get_connection=lambda: self.fake_libvirt_connection) def _create_instance_ref(self, uuid=""74526555-9166-4893-a203-126bdcab0d67""): inst = objects.Instance( id=7, uuid=uuid, user_id=""fake"", project_id=""fake"", image_ref='155d900f-4e14-4e4c-a73d-069cbf4541e6', instance_type_id=1) inst.info_cache = objects.InstanceInfoCache() inst.info_cache.deleted = False return inst @mock.patch.object(objects.InstanceList, ""get_by_security_group_id"") @mock.patch.object(objects.SecurityGroupRuleList, ""get_by_security_group_id"") @mock.patch.object(objects.SecurityGroupList, ""get_by_instance"") def test_static_filters(self, mock_lock, mock_secgroup, mock_secrule, mock_instlist): UUID = ""2674993b-6adb-4733-abd9-a7c10cc1f146"" SRC_UUID = ""0e0a76b2-7c52-4bc0-9a60-d83017e42c1a"" instance_ref = self._create_instance_ref(UUID) src_instance_ref = self._create_instance_ref(SRC_UUID) secgroup = objects.SecurityGroup(id=1, user_id='fake', project_id='fake', name='testgroup', description='test group') src_secgroup = objects.SecurityGroup(id=2, user_id='fake', project_id='fake', name='testsourcegroup', description='src group') r1 = objects.SecurityGroupRule(parent_group_id=secgroup['id'], protocol='icmp', from_port=-1, to_port=-1, cidr='192.168.11.0/24', grantee_group=None) r2 = objects.SecurityGroupRule(parent_group_id=secgroup['id'], protocol='icmp', from_port=8, to_port=-1, cidr='192.168.11.0/24', grantee_group=None) r3 = objects.SecurityGroupRule(parent_group_id=secgroup['id'], protocol='tcp', from_port=80, to_port=81, cidr='192.168.10.0/24', grantee_group=None) r4 = objects.SecurityGroupRule(parent_group_id=secgroup['id'], protocol='tcp', from_port=80, to_port=81, cidr=None, grantee_group=src_secgroup, group_id=src_secgroup['id']) r5 = objects.SecurityGroupRule(parent_group_id=secgroup['id'], protocol=None, cidr=None, grantee_group=src_secgroup, group_id=src_secgroup['id']) secgroup_list = objects.SecurityGroupList() secgroup_list.objects.append(secgroup) src_secgroup_list = objects.SecurityGroupList() src_secgroup_list.objects.append(src_secgroup) instance_ref.security_groups = secgroup_list src_instance_ref.security_groups = src_secgroup_list def _fake_secgroup(ctxt, instance): if instance.uuid == UUID: return instance_ref.security_groups else: return src_instance_ref.security_groups mock_secgroup.side_effect = _fake_secgroup def _fake_secrule(ctxt, id): if id == secgroup.id: rules = objects.SecurityGroupRuleList() rules.objects.extend([r1, r2, r3, r4, r5]) return rules else: return [] mock_secrule.side_effect = _fake_secrule def _fake_instlist(ctxt, id): if id == src_secgroup['id']: insts = objects.InstanceList() insts.objects.append(src_instance_ref) return insts else: insts = objects.InstanceList() insts.objects.append(instance_ref) return insts mock_instlist.side_effect = _fake_instlist @mock.patch.object(objects.SecurityGroupList, ""get_by_instance"") def test_multinic_iptables(self, mock_lock, mock_secgroup): mock_secgroup.return_value = objects.SecurityGroupList() @mock.patch.object(objects.InstanceList, ""get_by_security_group_id"") @mock.patch.object(objects.SecurityGroupRuleList, ""get_by_security_group_id"") @mock.patch.object(objects.SecurityGroupList, ""get_by_instance"") def test_unfilter_instance_undefines_nwfilter(self, mock_lock, mock_secgroup, mock_secrule, mock_instlist): mock_secgroup.return_value = objects.SecurityGroupList() @mock.patch.object(FakeVirtAPI, ""provider_fw_rule_get_all"") @mock.patch.object(objects.SecurityGroupList, ""get_by_instance"") def test_provider_firewall_rules(self, mock_lock, mock_secgroup, mock_fwrules): mock_secgroup.return_value = objects.SecurityGroupList() # add a rule angd send the update message, check for 1 rule mock_fwrules.return_value = [{'protocol': 'tcp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}] mock_fwrules.return_value = [{'protocol': 'tcp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}, {'protocol': 'udp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}] mock_fwrules.return_value = [{'protocol': 'udp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}]class NWFilterTestCase(test.NoDBTestCase): self.fw = firewall.NWFilterFirewall( FakeVirtAPI(), lambda: self.fake_libvirt_connection) def _create_security_group(self, instance_ref): secgroup = objects.SecurityGroup(id=1, user_id='fake', project_id='fake', name='testgroup', description='test group description') secgroup_list = objects.SecurityGroupList() secgroup_list.objects.append(secgroup) instance_ref.security_groups = secgroup_list return secgroup inst = objects.Instance( id=7, uuid=""74526555-9166-4893-a203-126bdcab0d67"", user_id=""fake"", project_id=""fake"", image_ref='155d900f-4e14-4e4c-a73d-069cbf4541e6', instance_type_id=1) inst.info_cache = objects.InstanceInfoCache() inst.info_cache.deleted = False return inst self._create_security_group(instance_ref) self.fw.setup_basic_filtering(instance_ref, network_info) self.fw.setup_basic_filtering(instance_ref, network_info) self._create_security_group(instance_ref) self.fw.setup_basic_filtering(instance_ref, network_info) self.fw.unfilter_instance(instance_ref, network_info) def test_nwfilter_parameters(self): self._create_security_group(instance_ref) self.fw.setup_basic_filtering(instance_ref, network_info) instance_filter_name = self.fw._instance_filter_name(instance_ref, nic_id) self._create_security_group(instance_ref) self.fw.setup_basic_filtering(instance_ref, network_info) assert_filterref(instance_ref, network_info[0], expected=['nova-base']) assert_filterref(instance_ref, network_info[1], expected=['nova-nodhcp'])","from nova.api.ec2 import cloudfrom nova import context from nova import dbfrom nova.virt import fakeclass IptablesFirewallTestCase(test.TestCase): self.user_id = 'fake' self.project_id = 'fake' self.context = context.RequestContext(self.user_id, self.project_id) fake.FakeVirtAPI(), get_connection=lambda: self.fake_libvirt_connection) def _create_instance_ref(self): return db.instance_create(self.context, {'user_id': 'fake', 'project_id': 'fake', 'instance_type_id': 1}) def test_static_filters(self, mock_lock): instance_ref = self._create_instance_ref() src_instance_ref = self._create_instance_ref() admin_ctxt = context.get_admin_context() secgroup = db.security_group_create(admin_ctxt, {'user_id': 'fake', 'project_id': 'fake', 'name': 'testgroup', 'description': 'test group'}) src_secgroup = db.security_group_create(admin_ctxt, {'user_id': 'fake', 'project_id': 'fake', 'name': 'testsourcegroup', 'description': 'src group'}) db.security_group_rule_create(admin_ctxt, {'parent_group_id': secgroup['id'], 'protocol': 'icmp', 'from_port': -1, 'to_port': -1, 'cidr': '192.168.11.0/24'}) db.security_group_rule_create(admin_ctxt, {'parent_group_id': secgroup['id'], 'protocol': 'icmp', 'from_port': 8, 'to_port': -1, 'cidr': '192.168.11.0/24'}) db.security_group_rule_create(admin_ctxt, {'parent_group_id': secgroup['id'], 'protocol': 'tcp', 'from_port': 80, 'to_port': 81, 'cidr': '192.168.10.0/24'}) db.security_group_rule_create(admin_ctxt, {'parent_group_id': secgroup['id'], 'protocol': 'tcp', 'from_port': 80, 'to_port': 81, 'group_id': src_secgroup['id']}) db.security_group_rule_create(admin_ctxt, {'parent_group_id': secgroup['id'], 'group_id': src_secgroup['id']}) db.instance_add_security_group(admin_ctxt, instance_ref['uuid'], secgroup['id']) db.instance_add_security_group(admin_ctxt, src_instance_ref['uuid'], src_secgroup['id']) instance_ref = db.instance_get(admin_ctxt, instance_ref['id']) src_instance_ref = db.instance_get(admin_ctxt, src_instance_ref['id']) db.instance_destroy(admin_ctxt, instance_ref['uuid']) def test_multinic_iptables(self, mock_lock): def test_unfilter_instance_undefines_nwfilter(self, mock_lock): admin_ctxt = context.get_admin_context() db.instance_destroy(admin_ctxt, instance_ref['uuid']) def test_provider_firewall_rules(self, mock_lock): admin_ctxt = context.get_admin_context() # add a rule and send the update message, check for 1 rule db.provider_fw_rule_create(admin_ctxt, {'protocol': 'tcp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}) provider_fw1 = db.provider_fw_rule_create(admin_ctxt, {'protocol': 'udp', 'cidr': '10.99.99.99/32', 'from_port': 1, 'to_port': 65535}) db.provider_fw_rule_destroy(admin_ctxt, provider_fw1['id'])class NWFilterTestCase(test.TestCase): self.user_id = 'fake' self.project_id = 'fake' self.context = context.RequestContext(self.user_id, self.project_id) self.fw = firewall.NWFilterFirewall(fake.FakeVirtAPI(), lambda: self.fake_libvirt_connection) def test_cidr_rule_nwfilter_xml(self): cloud_controller = cloud.CloudController() cloud_controller.create_security_group(self.context, 'testgroup', 'test group description') cloud_controller.authorize_security_group_ingress(self.context, 'testgroup', from_port='80', to_port='81', ip_protocol='tcp', cidr_ip='0.0.0.0/0') db.security_group_get_by_name(self.context, 'fake', 'testgroup') self.teardown_security_group() def teardown_security_group(self): cloud_controller = cloud.CloudController() cloud_controller.delete_security_group(self.context, 'testgroup') def setup_and_return_security_group(self): cloud_controller = cloud.CloudController() cloud_controller.create_security_group(self.context, 'testgroup', 'test group description') cloud_controller.authorize_security_group_ingress(self.context, 'testgroup', from_port='80', to_port='81', ip_protocol='tcp', cidr_ip='0.0.0.0/0') return db.security_group_get_by_name(self.context, 'fake', 'testgroup') return db.instance_create(self.context, {'user_id': 'fake', 'project_id': 'fake', 'instance_type_id': 1}) inst_id = instance_ref['id'] inst_uuid = instance_ref['uuid'] self.security_group = self.setup_and_return_security_group() db.instance_add_security_group(self.context, inst_uuid, self.security_group['id']) instance = db.instance_get(self.context, inst_id) self.fw.setup_basic_filtering(instance, network_info) self.fw.setup_basic_filtering(instance, network_info) db.instance_remove_security_group(self.context, inst_uuid, self.security_group['id']) self.teardown_security_group() db.instance_destroy(context.get_admin_context(), instance_ref['uuid']) admin_ctxt = context.get_admin_context() inst_id = instance_ref['id'] inst_uuid = instance_ref['uuid'] self.security_group = self.setup_and_return_security_group() db.instance_add_security_group(self.context, inst_uuid, self.security_group['id']) instance = db.instance_get(self.context, inst_id) self.fw.setup_basic_filtering(instance, network_info) self.fw.unfilter_instance(instance, network_info) db.instance_destroy(admin_ctxt, instance_ref['uuid']) def test_nwfilter_parameters(self): admin_ctxt = context.get_admin_context() inst_id = instance_ref['id'] inst_uuid = instance_ref['uuid'] self.security_group = self.setup_and_return_security_group() db.instance_add_security_group(self.context, inst_uuid, self.security_group['id']) instance = db.instance_get(self.context, inst_id) self.fw.setup_basic_filtering(instance, network_info) instance_filter_name = self.fw._instance_filter_name(instance, nic_id) db.instance_destroy(admin_ctxt, instance_ref['uuid']) inst_id = instance_ref['id'] inst_uuid = instance_ref['uuid'] self.security_group = self.setup_and_return_security_group() db.instance_add_security_group(self.context, inst_uuid, self.security_group['id']) instance = db.instance_get(self.context, inst_id) self.fw.setup_basic_filtering(instance, network_info) assert_filterref(instance, network_info[0], expected=['nova-base']) assert_filterref(instance, network_info[1], expected=['nova-nodhcp']) db.instance_remove_security_group(self.context, inst_uuid, self.security_group['id']) self.teardown_security_group() db.instance_destroy(context.get_admin_context(), instance_ref['uuid'])",186,185
openstack%2Fpuppet-cinder~master~Icfc545e41049ee6b3d05fb6770a12d5d2b683f93,openstack/puppet-cinder,master,Icfc545e41049ee6b3d05fb6770a12d5d2b683f93,Add tuning data base configs,MERGED,2014-09-24 13:51:09.000000000,2014-10-06 14:36:29.000000000,2014-10-06 14:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6994}, {'_account_id': 9500}, {'_account_id': 10536}]","[{'number': 1, 'created': '2014-09-24 13:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/d50754ba0b2df457d86046638d0a56da46427cd8', 'message': 'Add tunning data base configs\n\nAdd data base configs: min_pool_size, max_pool_size, max_retries,\nretry_interval, max_overflow\n\nUse the same default values as cinder project\n\nChange-Id: Icfc545e41049ee6b3d05fb6770a12d5d2b683f93\n'}, {'number': 2, 'created': '2014-09-24 17:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/a17679695904f5ea89c7e19d682b3f9d259e7c78', 'message': 'Add tunning data base configs\n\nAdd data base configs: min_pool_size, max_pool_size, max_retries,\nretry_interval, max_overflow\n\nUse the same default values as cinder project\n\nChange-Id: Icfc545e41049ee6b3d05fb6770a12d5d2b683f93\n'}, {'number': 3, 'created': '2014-09-25 09:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/1bfb3db5dab905c095e85ab1a8edd9268aa765a1', 'message': 'Add tuning data base configs\n\nAdd data base configs: min_pool_size, max_pool_size, max_retries,\nretry_interval, max_overflow\n\nUse the same default values as cinder project\n\nChange-Id: Icfc545e41049ee6b3d05fb6770a12d5d2b683f93\n'}, {'number': 4, 'created': '2014-10-01 08:45:01.000000000', 'files': ['manifests/init.pp', 'spec/classes/cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/992aa924fe279c14d98739339bef51c6026c63c6', 'message': 'Add tuning data base configs\n\nAdd data base configs: min_pool_size, max_pool_size, max_retries,\nretry_interval, max_overflow\n\nUse the same default values as cinder project\n\nChange-Id: Icfc545e41049ee6b3d05fb6770a12d5d2b683f93\n'}]",4,123734,992aa924fe279c14d98739339bef51c6026c63c6,21,6,4,10536,,,0,"Add tuning data base configs

Add data base configs: min_pool_size, max_pool_size, max_retries,
retry_interval, max_overflow

Use the same default values as cinder project

Change-Id: Icfc545e41049ee6b3d05fb6770a12d5d2b683f93
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/34/123734/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/cinder_spec.rb']",2,d50754ba0b2df457d86046638d0a56da46427cd8,tune_db_config, should contain_cinder_config('database/min_pool_size').with( :value => '1' ) should contain_cinder_config('database/max_pool_size').with( :value => '5' ) should contain_cinder_config('database/max_retries').with( :value => '10' ) should contain_cinder_config('database/retry_interval').with( :value => '10' ) should_not contain_cinder_config('database/max_overflow'),,44,0
openstack%2Foslo.serialization~master~I3d25f7a9b7255dfe8fc7bfa9af2094c55bb8f1f2,openstack/oslo.serialization,master,I3d25f7a9b7255dfe8fc7bfa9af2094c55bb8f1f2,Bring the version of hacking in line with openstack/requirements,ABANDONED,2014-10-06 13:01:00.000000000,2014-10-06 14:10:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-10-06 13:01:00.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/bf965721f81d589c512fa548d50df8add133167f', 'message': ""Bring the version of hacking in line with openstack/requirements\n\nGenerating a pypi mirror from openstack/requirements gives us\na newer version of hacking than the test-requirements ask for,\nso our tests were failing because they couldn't set up\nthe test environment. This brings the test-requirements in line\nwith openstack/requirements, and all tests still seem to pass.\n\nChange-Id: I3d25f7a9b7255dfe8fc7bfa9af2094c55bb8f1f2\n""}]",0,126285,bf965721f81d589c512fa548d50df8add133167f,3,2,1,12100,,,0,"Bring the version of hacking in line with openstack/requirements

Generating a pypi mirror from openstack/requirements gives us
a newer version of hacking than the test-requirements ask for,
so our tests were failing because they couldn't set up
the test environment. This brings the test-requirements in line
with openstack/requirements, and all tests still seem to pass.

Change-Id: I3d25f7a9b7255dfe8fc7bfa9af2094c55bb8f1f2
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/85/126285/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,bf965721f81d589c512fa548d50df8add133167f,,"hacking>=0.9.2,<0.10","hacking>=0.5.6,<0.8",1,1
openstack%2Fopenstack-manuals~master~I691fd21b38da42c7c1c4fafe9fbd5c4cf7787aeb,openstack/openstack-manuals,master,I691fd21b38da42c7c1c4fafe9fbd5c4cf7787aeb,Rework the HOT environment section,MERGED,2014-10-04 18:04:09.000000000,2014-10-06 14:09:55.000000000,2014-10-06 14:09:54.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 18:04:09.000000000', 'files': ['doc/hot-guide/source/environment.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dcc67866c9e60efce55719728b2ead4f987d6dd0', 'message': 'Rework the HOT environment section\n\n* Rephrase the descriptions\n* Use yaml syntax highlighting\n* Reorder the examples\n* Comment out the setup of environment server side (this should be moved\n  to the admin cloud guide)\n\nChange-Id: I691fd21b38da42c7c1c4fafe9fbd5c4cf7787aeb\n'}]",0,126154,dcc67866c9e60efce55719728b2ead4f987d6dd0,7,3,1,7923,,,0,"Rework the HOT environment section

* Rephrase the descriptions
* Use yaml syntax highlighting
* Reorder the examples
* Comment out the setup of environment server side (this should be moved
  to the admin cloud guide)

Change-Id: I691fd21b38da42c7c1c4fafe9fbd5c4cf7787aeb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/54/126154/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/environment.rst'],1,dcc67866c9e60efce55719728b2ead4f987d6dd0,hot-env,"The environment affects the runtime behaviour of a template. It provides a way to override the resource implementations and a mechanism to place parametersTo fully understand the runtime behavior you have to consider what plug-ins are installed on the cloud you're using. Environment file format ----------------------- The environment is a yaml text file that contains two main sections: ``parameters`` A map of key/pair values. ``resource_registry`` Definition of custom resources. Use the :option:`-e` option of the :command:`heat stack-create` command to create a stack using with the environment defined in such a file. You can also provide environment parameters as a list of key/value pairs using the :option:`-P` option of the :command:`heat stack-create` command. In the following example the environment is read from the :file:`my_env.yaml` file and an extra parameter is provided using the :option:`-P` option: .. code-block:: console $ heat stack-create my_stack -e my_env.yaml -P ""param1=val1;param2=val2"" -f my_tmpl.yaml The environment used for a stack is the combination of the environment you use with the template for the stack, and a global environment that is determined by your cloud operator. An entry in the user environment takes precedence over the global environment. OpenStack includes a default global environment, but you cloud operator can add additional environment entries. .. TODO: move this to a heat section in the admin-guide-cloud The cloud operator can add to the global environment by putting environment files in a configurable directory wherever the Orchestration engine runs. The configuration variable is named ""environment_dir"" is found in the ""[DEFAULT]"" section of ""/etc/heat/heat.conf"". The default for that directory is ""/etc/heat/environment.d"". Its contents are combined in whatever order the shell delivers them when the service starts up, which is the time when these files are read. If the ""my_env.yaml"" file from the example above had been put in the ""environment_dir"" then the user's command line could be this: :: heat stack-create my_stack -P ""some_parm=bla"" -f my_tmpl.yaml Define values for a template arguments -------------------------------------- You can define values for the template arguments in the ``parameters`` section of an environment file: .. code-block:: yaml KeyName: my_keypair InstanceType: m1.tinyCreate and override resources ----------------------------- You can create or override resources in the ``resource_registry`` section of an environment file. The resource you provide in this manner must have an identifier, and references either other resources IDs or the URL of an existing template file. The following example maps the new ``OS::Networking::FloatingIP`` resource to the existing ``OS::Nova::FloatingIP`` resource: .. code-block:: yamlYou can use wilcards to map multiple resources: .. code-block:: yaml resource_registry: ""OS::Network*"": ""OS::Neutron*"" To create or override a resource with a custom resource, create a template file to define this resource, and provide the URL to the template file in the environment file: .. code-block:: yaml resource_registry: ""AWS::EC2::Instance"": file:///path/to/my_instance.yaml The supported URL scheme are ``file``, ``http`` and ``https``. .. note:: The template file extension must be ``.yaml`` or ``.template``, or it will not be treated as a custom template resource. You can limit the usage of a custom resource to a specific resource of the template: .. code-block:: yaml","The environment is used to affect the runtime behaviour of the template. It provides a way to override the resource implementations and provide a mechanism to place parametersTo fully understand the runtime behavior you also have to consider what plug-ins the cloud operator has installed. ------ Format ------ It is a yaml text file with two main sections ""resource_registry"" and ""parameters"". ------------------ Command line usage ------------------ :: heat stack-create my_stack -e my_env.yaml -P ""some_parm=bla"" -f my_tmpl.yaml ---------------------------------The environment used for a stack is the combination of (1) the environment given by the user with the template for the stack and (2) a global environment that is determined by the cloud operator. Combination is asymmetric: an entry in the user environment takes precedence over the global environment. The OpenStack software includes a default global environment, which supplies some resource types that are included in the standard documentation. The cloud operator can add additional environment entries. The cloud operator can add to the global environment by putting environment files in a configurable directory wherever the heat engine runs. The configuration variable is named ""environment_dir"" is found in the ""[DEFAULT]"" section of ""/etc/heat/heat.conf"". The default for that directory is ""/etc/heat/environment.d"". Its contents are combined in whatever order the shell delivers them when the service starts up, which is the time when these files are read. If the ""my_env.yaml"" file from the example above had been put in the ""environment_dir"" then the user's command line could be this: :: heat stack-create my_stack -P ""some_parm=bla"" -f my_tmpl.yaml -------------- Usage examples -------------- 1) Pass parameters into Heat ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: KeyName: heat_key InstanceType: m1.micro 2) Deal with the mapping of Quantum to Neutron ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: resource_registry: ""OS::Quantum*"": ""OS::Neutron*"" So all existing resources which can be matched with ""OS::Neutron*"" will be mapped to ""OS::Quantum*"" accordingly. 3) Override a resource type with a provider resource ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: resource_registry: ""AWS::EC2::Instance"": file:///home/mine/my_instance.yaml Please note that the template resource URL here must end with "".yaml"" or "".template"", or it will not be treated as a custom template resource. The supported URL types are ""http, https and file"". 4) Always map resource type X to Y ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: 5) Use default resources except one for a particular resource in the template ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ::",88,69
openstack%2Ftripleo-image-elements~master~I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986,openstack/tripleo-image-elements,master,I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986,haproxy global maxconn is less than default maxconn,MERGED,2014-10-02 15:29:23.000000000,2014-10-06 14:05:41.000000000,2014-10-06 14:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 1605}, {'_account_id': 4220}, {'_account_id': 7582}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-10-02 15:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f29d383c9748bab9b71b2980ab0d233564221cdb', 'message': 'haproxy global maxconn is less than default maxconn\n\nThe current global maxconn is hard-coded to 4000 and the default\nmaxconn is 8000. As a result we have a potential denial of service\nattack with a single service using up the global limit.\n\nThis patch makes the global maxconn and the per-service maxconn\nconfigurable. The default global maxconn is left at 4000 and the\ndefault value for the default per-service maxconn is set to a much\nlower value. With this change, both per-service default and\nindividual service maxconn settings are configurable.\n\nNote the default per-service level setting of 150 was chosen on the\nbasis of haproxy handling 20 services, leading to 200 connections\nper service. A value lower than 200 was chosen to allow wriggle room\nfor specific service maxconn levels to be set higher than others.\n\nChange-Id: I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986\n'}, {'number': 2, 'created': '2014-10-02 15:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a256d51f1c6a71e0c40950da888a85de6834aab3', 'message': 'haproxy global maxconn is less than default maxconn\n\nThe current global maxconn is hard-coded to 4000 and the default\nmaxconn is 8000. As a result we have a potential denial of service\nattack with a single service using up the global limit.\n\nThis patch makes the global maxconn and the per-service maxconn\nconfigurable. The default global maxconn is left at 4000 and the\ndefault value for the default per-service maxconn is set to a much\nlower value. With this change, both per-service default and\nindividual service maxconn settings are configurable.\n\nNote the default per-service level setting of 150 was chosen on the\nbasis of haproxy handling 20 services, leading to 200 connections\nper service. A value lower than 200 was chosen to allow wriggle room\nfor specific service maxconn levels to be set higher than others.\n\nChange-Id: I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986\n'}, {'number': 3, 'created': '2014-10-02 15:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/77327e0611d5f7237d369c1eaf769fdd0a0c74e0', 'message': 'haproxy global maxconn is less than default maxconn\n\nThe current global maxconn is hard-coded to 4000 and the default\nmaxconn is 8000. As a result we have a potential denial of service\nattack with a single service using up the global limit.\n\nThis patch makes the global maxconn and the per-service maxconn\nconfigurable. The default global maxconn is left at 4000 and the\ndefault value for the default per-service maxconn is set to a much\nlower value. With this change, both per-service default and\nindividual service maxconn settings are configurable.\n\nNote the default per-service level setting of 150 was chosen on the\nbasis of haproxy handling 20 services, leading to 200 connections\nper service. A value lower than 200 was chosen to allow wriggle room\nfor specific service maxconn levels to be set higher than others.\n\nChange-Id: I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986\n'}, {'number': 4, 'created': '2014-10-03 09:26:54.000000000', 'files': ['elements/haproxy/os-apply-config/etc/haproxy/haproxy.cfg', 'elements/haproxy/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a5382bd1ad7e5318904a2b65034a52e6a217e048', 'message': 'haproxy global maxconn is less than default maxconn\n\nThe current global maxconn is hard-coded to 4000 and the default\nper-service maxconn is 8000. As a result we have a potential\ndenial of service attack with a single service using up the\nglobal limit.\n\nThis patch makes the global maxconn and the per-service maxconn\nconfigurable. The default global maxconn is left at 4000 and the\ndefault value for the default per-service maxconn is set to a much\nlower value. With this change, both per-service default and\nindividual service maxconn settings are configurable.\n\nNote the default per-service level setting of 150 was chosen on the\nbasis of haproxy handling 20 services, leading to 200 connections\nper service. A value lower than 200 was chosen to allow wriggle room\nfor specific service maxconn levels to be set higher than others.\n\nChange-Id: I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986\n'}]",2,125675,a5382bd1ad7e5318904a2b65034a52e6a217e048,21,5,4,1605,,,0,"haproxy global maxconn is less than default maxconn

The current global maxconn is hard-coded to 4000 and the default
per-service maxconn is 8000. As a result we have a potential
denial of service attack with a single service using up the
global limit.

This patch makes the global maxconn and the per-service maxconn
configurable. The default global maxconn is left at 4000 and the
default value for the default per-service maxconn is set to a much
lower value. With this change, both per-service default and
individual service maxconn settings are configurable.

Note the default per-service level setting of 150 was chosen on the
basis of haproxy handling 20 services, leading to 200 connections
per service. A value lower than 200 was chosen to allow wriggle room
for specific service maxconn levels to be set higher than others.

Change-Id: I0f1c6bd47f25fb8839c6ebc7fd5f1afb3fabd986
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/75/125675/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/os-apply-config/etc/haproxy/haproxy.cfg'],1,f29d383c9748bab9b71b2980ab0d233564221cdb,haproxy-maxconn, maxconn {{#haproxy.global_maxconn}}{{.}}{{/haproxy.global_maxconn}}{{^haproxy.global_maxconn}}4000{{/haproxy.global_maxconn}} maxconn {{#haproxy.service_maxconn}}{{.}}{{/haproxy.service_maxconn}}{{^haproxy.service_maxconn}}150{{/haproxy.service_maxconn}} server {{name}} {{ip}}:{{port}} check inter 2000 rise 2 fall 5 {{#service_maxconn}}maxconn {{.}}{{/service_maxconn}} {{#extra_server_params}} {{.}}{{/extra_server_params}}, maxconn 4000 maxconn 8000 server {{name}} {{ip}}:{{port}} check inter 2000 rise 2 fall 5{{#extra_server_params}} {{.}}{{/extra_server_params}},3,3
openstack%2Fnova~master~I56256696b384fd2e0c26cceba640c339ad2e4fc7,openstack/nova,master,I56256696b384fd2e0c26cceba640c339ad2e4fc7,Fix the nova compute crash when using libvirt < 1.0.4,ABANDONED,2014-10-01 18:54:25.000000000,2014-10-06 14:03:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6509}, {'_account_id': 6854}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9932}, {'_account_id': 10237}, {'_account_id': 10385}, {'_account_id': 12805}]","[{'number': 1, 'created': '2014-10-01 18:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/361175f4e7f854fb5728a76f74d6ad194d6cee69', 'message': 'Fix the nova compute crash for libvirt 0.9.8\n\nlibvirt 0.9.8 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\ncell.memory / units.Ki is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\n(Test cases in progress)\n\nThe other solution is to initialise LibvirtConfigCapsNUMACell.memory\nto 0.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 2, 'created': '2014-10-02 08:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d060012699d84b6eafbcd71684f763cce8242965', 'message': 'Fix the nova compute crash for libvirt 0.9.8\n\nlibvirt 0.9.8 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\ncell.memory / units.Ki is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\n(Test cases in progress)\n\nThe other solution is to initialise LibvirtConfigCapsNUMACell.memory\nto 0.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 3, 'created': '2014-10-03 06:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38426ed3eb133ab30143a179b16b2702b03d9ebf', 'message': 'Fix the nova compute crash for libvirt 0.9.8\n\nlibvirt 0.9.8 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\ncell.memory / units.Ki is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\n(Test cases in progress)\n\nThe other solution is to initialise LibvirtConfigCapsNUMACell.memory\nto 0.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 4, 'created': '2014-10-03 06:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c51b87a862ff23cdabf6ab8fe5e77e1e7df221d', 'message': 'Fix the nova compute crash when using libvirt < 1.0.4\n\nlibvirt < 1.0.4 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\n(cell.memory / units.Ki) is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 5, 'created': '2014-10-03 07:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/044a18cfbee491c567b558eb082acb16d253d0a8', 'message': 'Fix the nova compute crash when using libvirt < 1.0.4\n\nlibvirt < 1.0.4 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\n(cell.memory / units.Ki) is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 6, 'created': '2014-10-03 09:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dee3288c788632e27f7256b65ebab968c539deb9', 'message': 'Fix the nova compute crash when using libvirt < 1.0.4\n\nlibvirt < 1.0.4 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\n(cell.memory / units.Ki) is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}, {'number': 7, 'created': '2014-10-03 12:12:47.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4272daf0b2b54c171ee14365fb27bca2a873ddde', 'message': 'Fix the nova compute crash when using libvirt < 1.0.4\n\nlibvirt < 1.0.4 is not returning memory information\nin the topology in the function driver._get_host_capabilities().\nLibvirtConfigCapsNUMACell.memory is None because of this and\n(cell.memory / units.Ki) is failing of TypeError.\n\nThis issue is not seen in later libvirt versions.\n\nChange-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7\nCloses-bug: #1376307\n'}]",8,125459,4272daf0b2b54c171ee14365fb27bca2a873ddde,66,18,7,10237,,,0,"Fix the nova compute crash when using libvirt < 1.0.4

libvirt < 1.0.4 is not returning memory information
in the topology in the function driver._get_host_capabilities().
LibvirtConfigCapsNUMACell.memory is None because of this and
(cell.memory / units.Ki) is failing of TypeError.

This issue is not seen in later libvirt versions.

Change-Id: I56256696b384fd2e0c26cceba640c339ad2e4fc7
Closes-bug: #1376307
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/125459/7 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,361175f4e7f854fb5728a76f74d6ad194d6cee69,bug/1376307, cell.memory / units.Ki if cell.memory else None), cell.memory / units.Ki),1,1
openstack%2Ftripleo-image-elements~master~I9f3932f88c5796755fefaeedea9811b82b291635,openstack/tripleo-image-elements,master,I9f3932f88c5796755fefaeedea9811b82b291635,RHEL SELinux custom policy for neutron-ns-meta,MERGED,2014-09-30 17:22:05.000000000,2014-10-06 14:03:13.000000000,2014-10-06 14:03:13.000000000,"[{'_account_id': 3}, {'_account_id': 7582}, {'_account_id': 7585}]","[{'number': 1, 'created': '2014-09-30 17:22:05.000000000', 'files': ['elements/selinux/custom-policies/tripleo-selinux-neutron.te'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/44429d8fefd152c42d91cafe3621cb7618c069e8', 'message': 'RHEL SELinux custom policy for neutron-ns-meta\n\nneutron-ns-meta is denied connectto on unix_stream_socket on RHEL.\n\nFedora selinux-policy has the correct fix. That fix needs to be\napplied to RHEL. We need this custom policy until it is applied.\n\nPartial-Bug: 1375534\n\nChange-Id: I9f3932f88c5796755fefaeedea9811b82b291635\n'}]",1,125123,44429d8fefd152c42d91cafe3621cb7618c069e8,8,3,1,7471,,,0,"RHEL SELinux custom policy for neutron-ns-meta

neutron-ns-meta is denied connectto on unix_stream_socket on RHEL.

Fedora selinux-policy has the correct fix. That fix needs to be
applied to RHEL. We need this custom policy until it is applied.

Partial-Bug: 1375534

Change-Id: I9f3932f88c5796755fefaeedea9811b82b291635
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/23/125123/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/custom-policies/tripleo-selinux-neutron.te'],1,44429d8fefd152c42d91cafe3621cb7618c069e8,bug/1375534, module tripleo-selinux-neutron 1.0; require { type neutron_t; type init_t; class unix_stream_socket connectto; } #============= neutron_t ============== # https://bugs.launchpad.net/tripleo/+bug/1375534 # https://bugzilla.redhat.com/show_bug.cgi?id=1147104 allow neutron_t init_t:unix_stream_socket connectto; ,,13,0
openstack%2Ftripleo-image-elements~master~I93c85ed883fc5f6f05ff37bb8f05eee0e53f1b78,openstack/tripleo-image-elements,master,I93c85ed883fc5f6f05ff37bb8f05eee0e53f1b78,SELinux: allow openssl access to /run/keystone,MERGED,2014-09-30 22:50:10.000000000,2014-10-06 14:02:36.000000000,2014-10-06 14:02:36.000000000,"[{'_account_id': 3}, {'_account_id': 7582}, {'_account_id': 7585}]","[{'number': 1, 'created': '2014-09-30 22:50:10.000000000', 'files': ['elements/selinux/custom-policies/tripleo-selinux-keystone.te'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9d4d5c21de0fc666e36154f1e5e4b3c8ce780c11', 'message': 'SELinux: allow openssl access to /run/keystone\n\nOn RHEL, openssl is being denied access to /run/keystone. This issue\nwas fixed on Fedora and that fix needs to be merged into the RHEL\nselinux-policy package. In the meantime, this custom policy is needed.\n\nChange-Id: I93c85ed883fc5f6f05ff37bb8f05eee0e53f1b78\nRelated-Bug: 1376038\n'}]",1,125219,9d4d5c21de0fc666e36154f1e5e4b3c8ce780c11,8,3,1,7471,,,0,"SELinux: allow openssl access to /run/keystone

On RHEL, openssl is being denied access to /run/keystone. This issue
was fixed on Fedora and that fix needs to be merged into the RHEL
selinux-policy package. In the meantime, this custom policy is needed.

Change-Id: I93c85ed883fc5f6f05ff37bb8f05eee0e53f1b78
Related-Bug: 1376038
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/19/125219/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/custom-policies/tripleo-selinux-keystone.te'],1,9d4d5c21de0fc666e36154f1e5e4b3c8ce780c11,bug/1376038, module tripleo-selinux-keystone 1.0; require { type var_run_t; type keystone_t; class dir { write add_name }; class file { write getattr setattr read create open }; } #============= keystone_t ============== # https://bugzilla.redhat.com/show_bug.cgi?id=1144158 # https://bugs.launchpad.net/tripleo/+bug/1376038 allow keystone_t var_run_t:dir { write add_name }; allow keystone_t var_run_t:file { write getattr setattr read create open }; ,,15,0
openstack%2Ftripleo-image-elements~master~Ief542a442b8206ad59c1aa055307df213597b532,openstack/tripleo-image-elements,master,Ief542a442b8206ad59c1aa055307df213597b532,Custom SELinux policy for rhsmcertd,MERGED,2014-09-30 17:33:32.000000000,2014-10-06 14:02:04.000000000,2014-10-06 14:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 7582}, {'_account_id': 7585}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-09-30 17:33:32.000000000', 'files': ['elements/selinux/custom-policies/tripleo-selinux-rhsmcertd.te'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f9dc34aadbc9147bf1a52e54d8db274b48c2a004', 'message': 'Custom SELinux policy for rhsmcertd\n\nPolicy update to fix rhsmcertd denials on RHEL. This is needed\nuntil the RHEL selinux-policy package is updated.\n\nChange-Id: Ief542a442b8206ad59c1aa055307df213597b532\nPartial-Bug: 1375532\n'}]",1,125125,f9dc34aadbc9147bf1a52e54d8db274b48c2a004,10,5,1,7471,,,0,"Custom SELinux policy for rhsmcertd

Policy update to fix rhsmcertd denials on RHEL. This is needed
until the RHEL selinux-policy package is updated.

Change-Id: Ief542a442b8206ad59c1aa055307df213597b532
Partial-Bug: 1375532
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/25/125125/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/custom-policies/tripleo-selinux-rhsmcertd.te'],1,f9dc34aadbc9147bf1a52e54d8db274b48c2a004,bug/1375532, module tripleo-selinux-rhsmcertd 1.0; require { type rhsmcertd_t; type user_home_t; type rpm_var_lib_t; class capability dac_override; class file create; class dir { write getattr add_name }; } #============= rhsmcertd_t ============== # https://bugzilla.redhat.com/show_bug.cgi?id=1144165 # https://bugs.launchpad.net/tripleo/+bug/1375532 allow rhsmcertd_t rpm_var_lib_t:dir { write add_name }; allow rhsmcertd_t rpm_var_lib_t:file create; allow rhsmcertd_t self:capability dac_override; allow rhsmcertd_t user_home_t:dir getattr; ,,19,0
openstack%2Fopenstacksdk~master~I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c,openstack/openstacksdk,master,I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c,Add support for telemetry sample Statistics,MERGED,2014-08-23 00:45:51.000000000,2014-10-06 13:49:00.000000000,2014-10-06 13:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-08-23 00:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/275d0953418cf0ba5768887909646e26e94c009e', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 2, 'created': '2014-08-27 18:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3d6d18966e07543919cfcb6796d949b4f5792ebc', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 3, 'created': '2014-09-02 22:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4a8c60780686c0d2646c2a58e605ac276cd4af4b', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\nAdds convenience method to Meter resource to query statistics.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 4, 'created': '2014-09-12 22:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/84126e59b7feecc11c29a34762585e977fad8658', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\nAdds convenience method to Meter resource to query statistics.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 5, 'created': '2014-09-15 19:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2ad8c1c8098886b2b59332f139541211e5dc5c83', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\nAdds convenience method to Meter resource to query statistics.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 6, 'created': '2014-09-15 23:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2e48fc29b0aa827f285e925f4b8a1baf66bf4001', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\nAdds convenience method to Meter resource to query statistics.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}, {'number': 7, 'created': '2014-09-22 17:55:24.000000000', 'files': ['openstack/telemetry/v2/statistics.py', 'openstack/tests/telemetry/v2/test_statistics.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c0c04ec4dfd3a5510821b4898b076b99ba79090a', 'message': 'Add support for telemetry sample Statistics\n\nList operation only with optional query string filters.\nStatistics endpoint requires a meter name in forming the URL.\n\nChange-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c\n'}]",6,116420,c0c04ec4dfd3a5510821b4898b076b99ba79090a,34,4,7,12807,,,0,"Add support for telemetry sample Statistics

List operation only with optional query string filters.
Statistics endpoint requires a meter name in forming the URL.

Change-Id: I3bf0e051783b9fa601b2aaaa940dbac0bc93d69c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/116420/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/statistics.py', 'openstack/tests/telemetry/v2/test_statistics.py']",2,275d0953418cf0ba5768887909646e26e94c009e,add-telemetry-statistics,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import testtools from openstack.telemetry.v2 import statistics EXAMPLE = { 'aggregate': '1', 'avg': '2', 'count': '3', 'duration': '4', 'duration_end': '5', 'duration_start': '6', 'groupby': '7', 'max': '8', 'min': '9', 'period': '10', 'period_end': '11', 'period_start': '12', 'sum': '13', 'unit': '14', } class TestStatistics(testtools.TestCase): def test_basic(self): sot = statistics.Statistics() self.assertEqual('statistics', sot.resource_key) self.assertIsNone(sot.resources_key) self.assertEqual('/v2/meters/%(meter)s/statistics', sot.base_path) self.assertEqual('metering', sot.service.service_type) self.assertFalse(sot.allow_create) self.assertFalse(sot.allow_retrieve) self.assertFalse(sot.allow_update) self.assertFalse(sot.allow_delete) self.assertTrue(sot.allow_list) def test_make_it(self): sot = statistics.Statistics(EXAMPLE) self.assertIsNone(sot.id) self.assertEqual(EXAMPLE['aggregate'], sot.aggregate) self.assertEqual(EXAMPLE['avg'], sot.avg) self.assertEqual(EXAMPLE['count'], sot.count) self.assertEqual(EXAMPLE['duration'], sot.duration) self.assertEqual(EXAMPLE['duration_end'], sot.duration_end) self.assertEqual(EXAMPLE['duration_start'], sot.duration_start) self.assertEqual(EXAMPLE['groupby'], sot.group_by) self.assertEqual(EXAMPLE['max'], sot.max) self.assertEqual(EXAMPLE['min'], sot.min) self.assertEqual(EXAMPLE['period'], sot.period) self.assertEqual(EXAMPLE['period_end'], sot.period_end) self.assertEqual(EXAMPLE['period_start'], sot.period_start) self.assertEqual(EXAMPLE['sum'], sot.sum) self.assertEqual(EXAMPLE['unit'], sot.unit) def test_list(self): sess = mock.Mock() resp = mock.Mock() resp.body = [EXAMPLE] sess.get = mock.Mock(return_value=resp) reply = statistics.Statistics.list(sess, path_args={'meter': 'name'}) self.assertEqual(1, len(reply)) self.assertEqual(EXAMPLE['aggregate'], reply[0].aggregate) self.assertEqual(EXAMPLE['avg'], reply[0].avg) self.assertEqual(EXAMPLE['count'], reply[0].count) self.assertEqual(EXAMPLE['duration'], reply[0].duration) self.assertEqual(EXAMPLE['duration_end'], reply[0].duration_end) self.assertEqual(EXAMPLE['duration_start'], reply[0].duration_start) self.assertEqual(EXAMPLE['groupby'], reply[0].group_by) self.assertEqual(EXAMPLE['max'], reply[0].max) self.assertEqual(EXAMPLE['min'], reply[0].min) self.assertEqual(EXAMPLE['period'], reply[0].period) self.assertEqual(EXAMPLE['period_end'], reply[0].period_end) self.assertEqual(EXAMPLE['period_start'], reply[0].period_start) self.assertEqual(EXAMPLE['sum'], reply[0].sum) self.assertEqual(EXAMPLE['unit'], reply[0].unit)",,142,0
openstack%2Fcloudkitty~master~I0d07f7333e08a2c41fbe644179a5a296cd130703,openstack/cloudkitty,master,I0d07f7333e08a2c41fbe644179a5a296cd130703,Removed i18n from flake checks,MERGED,2014-10-06 13:31:35.000000000,2014-10-06 13:47:44.000000000,2014-10-06 13:47:44.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-10-06 13:31:35.000000000', 'files': ['cloudkitty/api/controllers/types.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b4e44f9060813c5a03df098df9e5e322835d754c', 'message': 'Removed i18n from flake checks\n\nChange-Id: I0d07f7333e08a2c41fbe644179a5a296cd130703\n'}]",0,126295,b4e44f9060813c5a03df098df9e5e322835d754c,6,2,1,7042,,,0,"Removed i18n from flake checks

Change-Id: I0d07f7333e08a2c41fbe644179a5a296cd130703
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/95/126295/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/api/controllers/types.py', 'tox.ini']",2,b4e44f9060813c5a03df098df9e5e322835d754c,, [hacking] import_exceptions = cloudkitty.i18n,,4,1
openstack%2Fnova~master~I00f6325cb554bc5e34d9f0fe651af39630f35b5d,openstack/nova,master,I00f6325cb554bc5e34d9f0fe651af39630f35b5d,Disable libvirt NUMA topology support if libvirt < 1.0.4,MERGED,2014-10-05 12:58:10.000000000,2014-10-06 13:41:49.000000000,2014-10-06 13:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 1935}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6854}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10237}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-05 12:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c4e02b205a6e33581f4c5aefa07c4001294aa7e', 'message': ""WIP: Disable libvirt NUMA topology support if libvirt < 1.0.4\n\nIf you're not at a new enough version of libvirt, the compute service\nfails on startup because VirtNUMATopologyCellUsage is not fully\npopulated.\n\nThis add a min version check before trying to get host NUMA topology\ninformation.\n\nCloses-Bug: #1376307\n\nChange-Id: I00f6325cb554bc5e34d9f0fe651af39630f35b5d\n""}, {'number': 2, 'created': '2014-10-05 14:21:48.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ba0d9188d492028fcf4e65f908aa2d3db571952', 'message': ""Disable libvirt NUMA topology support if libvirt < 1.0.4\n\nIf you're not at a new enough version of libvirt, the compute service\nfails on startup because VirtNUMATopologyCellUsage is not fully\npopulated.\n\nThis add a min version check before trying to get host NUMA topology\ninformation.\n\nCloses-Bug: #1376307\n\nChange-Id: I00f6325cb554bc5e34d9f0fe651af39630f35b5d\n""}]",3,126181,8ba0d9188d492028fcf4e65f908aa2d3db571952,28,15,2,6873,,,0,"Disable libvirt NUMA topology support if libvirt < 1.0.4

If you're not at a new enough version of libvirt, the compute service
fails on startup because VirtNUMATopologyCellUsage is not fully
populated.

This add a min version check before trying to get host NUMA topology
information.

Closes-Bug: #1376307

Change-Id: I00f6325cb554bc5e34d9f0fe651af39630f35b5d
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/126181/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,1c4e02b205a6e33581f4c5aefa07c4001294aa7e,bug/1376307,"# libvirt numa topology support MIN_LIBVIRT_NUMA_TOPOLOGY_VERSION = (1, 0, 4) if not self._has_min_version(MIN_LIBVIRT_NUMA_TOPOLOGY_VERSION): return ",,5,0
openstack%2Fdiskimage-builder~master~Ic3a646b923738464b5217d799758b6980b2deaf2,openstack/diskimage-builder,master,Ic3a646b923738464b5217d799758b6980b2deaf2,Fix openSUSE cloud image download and extraction,MERGED,2014-08-29 06:54:55.000000000,2014-10-06 13:25:06.000000000,2014-10-06 13:25:05.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 10035}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-08-29 06:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/78dae54bba92d4cb7536105c8be62df95b809a4f', 'message': 'Fix openSUSE cloud image download\n\nUse the latest available version and update image processing.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 2, 'created': '2014-09-01 11:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ce6f15f31b4ac46ad2dbfaceefbf02bf55ccb228', 'message': 'Fix openSUSE cloud image download\n\nUse the latest available version and update image processing.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 3, 'created': '2014-09-01 11:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/8e455c8846844a0be041bced772aeeba2cea3684', 'message': 'Fix openSUSE cloud image download\n\nUse the latest available version and update image processing.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 4, 'created': '2014-09-02 07:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4a70fb5e7598645277cb9685c318327ef2138cca', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 5, 'created': '2014-09-02 07:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fabdaebd9a62334b74c66ea380f03723e0fdbcc3', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 6, 'created': '2014-09-02 11:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/998e4d2b24c4af510a4ea2da3354171395be5f85', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 7, 'created': '2014-09-02 12:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1b4fba36edbaaea4431556e9360ff952b54dc307', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 8, 'created': '2014-09-03 07:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ab6a9302894c27645f5ec3b20560b55b3134863c', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}, {'number': 9, 'created': '2014-09-03 07:55:26.000000000', 'files': ['elements/opensuse/root.d/10-opensuse-cloud-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1757ef20ea8a2a82658bdc0a62159a107a64fb88', 'message': 'Fix openSUSE cloud image download and extraction\n\nUse the latest available version of the rootfs (instead of a qcow2\nimage) to simplify rootfs extraction.\n\nChange-Id: Ic3a646b923738464b5217d799758b6980b2deaf2\n'}]",7,117704,1757ef20ea8a2a82658bdc0a62159a107a64fb88,42,8,9,7102,,,0,"Fix openSUSE cloud image download and extraction

Use the latest available version of the rootfs (instead of a qcow2
image) to simplify rootfs extraction.

Change-Id: Ic3a646b923738464b5217d799758b6980b2deaf2
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/04/117704/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/opensuse/root.d/10-opensuse-cloud-image'],1,78dae54bba92d4cb7536105c8be62df95b809a4f,fix-opensuse-image-download,"BASE_IMAGE_FILE=${BASE_IMAGE_FILE:-openSUSE-$DIB_RELEASE-OS-guest.$ARCH-raw.tar.bz2} # get the current name (versioned) of the base image from the header location # FIXME: this is just a workaround for non available unversioned .sha256 files on the server BASE_IMAGE_FILE_CURRENT=$(basename $(curl -sI $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE \ |grep Location|cut -d "" "" -f2|tr -d '\r')) BASE_IMAGE_NAME_CURRENT=$(echo $BASE_IMAGE_FILE_CURRENT|sed -e 's/-raw\.tar\.bz2$//') SHA256SUMS_FILE=""$BASE_IMAGE_FILE_CURRENT.sha256"" BASE_IMAGE_FILE_CURRENT=${BASE_IMAGE_FILE_CURRENT:-$BASE_IMAGE_FILE} SHA256SUMS_FILE=${SHA256SUMS_FILE:-$BASE_IMAGE_FILE.sha256} BASE_IMAGE_NAME_CURRENT=$(echo $BASE_IMAGE_FILE_CURRENT|sed -e 's/-raw\.tar\.bz2$//')CACHED_FILE=$DIB_IMAGE_CACHE/$BASE_IMAGE_FILE_CURRENT CACHED_SHA256SUMS_FILE=$DIB_IMAGE_CACHE/SHA256SUMS.$BASE_IMAGE_NAME_CURRENT $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$SHA256SUMS_FILE $CACHED_SHA256SUMS_FILE grep ""$BASE_IMAGE_FILE_CURRENT"" SHA256SUMS.$BASE_IMAGE_NAME_CURRENT | sha256sum --check -sudo tar -C $UNTAR_TO_LOCATION -xjf $CACHED_FILEmount_device_bn=`basename $nbd_device` mount_device=/dev/$mount_device_bn sudo qemu-nbd -c $mount_device $UNTAR_TO_LOCATION/$BASE_IMAGE_NAME_CURRENT.qcow2 # create device maps for partition table sudo kpartx -s -a $mount_device sudo mount /dev/mapper/${mount_device_bn}p1 $UNTAR_TO_LOCATION/mnt sudo kpartx -d $mount_device","# FIXME: Hard coded build numbers, versions, etc. # NOTE: Actual file name seems unstable, and has changed several times. BASE_IMAGE_NAME=${BASE_IMAGE_NAME:-openSUSE-$DIB_RELEASE-OS-guest.$ARCH-0.0.2-Build3.1} # XXX: Try to extract the filename of the current built from the index # page. As there is one built available in the repo at a given time, this # should work. This is a tempoary workaround until the fix for # https://bugzilla.novell.com/show_bug.cgi?id=853882 is deployed echo ""Looking up current built of Base Image ($BASE_IMAGE_NAME):"" BASE_IMAGE_FILE=${BASE_IMAGE_FILE:-$(curl $DIB_CLOUD_IMAGES | \ sed -n ""s/^.*\<a\ href\=\""\($BASE_IMAGE_NAME.*\.tar\.bz2\)\"".*$/\1/p"")} if [ -n ""$BASE_IMAGE_FILE"" ]; then echo ""Using base image: $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE"" else echo -e ""Failed to extract image file name from $DIB_CLOUD_IMAGES"" \ ""\nPlease set BASE_IMAGE_FILE manually and retry."" exit 1 fi BASE_IMAGE_FILE=${BASE_IMAGE_FILE:-$BASE_IMAGE_NAME-raw.tar.bz2}SHA256SUMS=${SHA256SUMS:-$DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE.sha256} CACHED_FILE=$DIB_IMAGE_CACHE/$BASE_IMAGE_FILE $TMP_HOOKS_PATH/bin/cache-url $SHA256SUMS $DIB_IMAGE_CACHE/SHA256SUMS.openSUSE.$DIB_RELEASE.$ARCH grep ""$BASE_IMAGE_FILE"" SHA256SUMS.openSUSE.$DIB_RELEASE.$ARCH | sha256sum --check -sudo tar -C $UNTAR_TO_LOCATION -xjf $DIB_IMAGE_CACHE/$BASE_IMAGE_FILEmount_device=/dev/`basename $nbd_device` sudo qemu-nbd -c $mount_device $UNTAR_TO_LOCATION/$BASE_IMAGE_NAME.qcow2 sudo mount ${mount_device}p1 $UNTAR_TO_LOCATION/mnt",23,27
openstack%2Ffuel-web~master~Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3,openstack/fuel-web,master,Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3,Fix for input auto-suggestions in wizard  - disable autosuggestion for Name and Release step,MERGED,2014-10-02 13:09:56.000000000,2014-10-06 13:19:31.000000000,2014-10-06 13:19:31.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-10-02 13:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f7abd7a4942643dfcbab960fd42a2fb30e2a2b88', 'message': 'Fix for input auto-suggestions in wizard\n - added keyup handler to keep track of previously pressed key\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 2, 'created': '2014-10-03 09:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6a52236c46b0c078a5e6e5d6c7c8789d674b5d19', 'message': 'Fix for input auto-suggestions in wizard\n - added keyup handler to keep track of previously pressed key\n - added fix for e.key which is not supported in Chrome\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 3, 'created': '2014-10-03 10:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2154510b0c8f831697dfe26210fdaa05c879ae81', 'message': 'Fix for input auto-suggestions in wizard\n - added keyup handler to keep track of previously pressed key\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 4, 'created': '2014-10-03 12:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/488aab4704ec999817ba8c2d3e76b7320dcdbea9', 'message': 'Fix for input auto-suggestions in wizard\n - added keyup handler to keep track of previously pressed key\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 5, 'created': '2014-10-03 14:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/35797d0d037e494246a590a5bc6faa0d36d89d00', 'message': 'Fix for input auto-suggestions in wizard\n - added keyup handler to keep track of previously pressed key\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 6, 'created': '2014-10-03 14:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/78189559af567f16cb531695b552ff88fcc7858d', 'message': 'Fix for input auto-suggestions in wizard\n \n- added keyup handler to keep track of previously pressed key\n\nCloses-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}, {'number': 7, 'created': '2014-10-06 12:39:16.000000000', 'files': ['nailgun/static/js/views/wizard.js', 'nailgun/static/templates/dialogs/create_cluster_wizard/name_and_release.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/818bac71c5b075423d6a99f862c8d4489f69d42b', 'message': 'Fix for input auto-suggestions in wizard\n - disable autosuggestion for Name and Release step\n\n Closes-bug: 1373440\n\nChange-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3\n'}]",2,125621,818bac71c5b075423d6a99f862c8d4489f69d42b,43,7,7,9091,,,0,"Fix for input auto-suggestions in wizard
 - disable autosuggestion for Name and Release step

 Closes-bug: 1373440

Change-Id: Ie07a12bd4ed21ca2f33b832ecabcee3103000ea3
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/21/125621/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/wizard.js'],1,f7abd7a4942643dfcbab960fd42a2fb30e2a2b88,bug/1373440," keydown: 'onKeydown', keyup: 'onKeyup',// fix to work with input suggestions (morale) onKeyup: function(e) { this.previousKeyPressed = e.key; }, onKeydown: function(e) { if (e.key == 'Enter' && (this.previousKeyPressed != 'Down')) {"," keydown: 'onInputKeydown', onInputKeydown: function(e) { if (e.which == 13) {",8,3
openstack%2Foslo.concurrency~master~Idbe9cdd90e9ce5e38b03ec1c20066928daa9ef00,openstack/oslo.concurrency,master,Idbe9cdd90e9ce5e38b03ec1c20066928daa9ef00,Test with both vanilla and eventlet stdlib,MERGED,2014-10-03 23:30:35.000000000,2014-10-06 13:04:17.000000000,2014-10-06 13:04:16.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-10-03 23:30:35.000000000', 'files': ['tests/unit/test_lockutils_eventlet.py', 'tox.ini', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/8483811889baa2c9f839c1ccbf74d2c14174bd67', 'message': ""Test with both vanilla and eventlet stdlib\n\nWe intend this project's code to function both with and without\neventlet monkey patching, so we should test that way too.  This adds\na separate test run that explicitly enables eventlet and removes\nthe racy monkey patching that existed before.\n\nI left the eventlet-specific unit test because it's making direct\ncalls into eventlet, so it is a somewhat different case from\nimplicitly using monkey patched classes and I'd rather leave a\nredundant test than remove it and find out it covered something\nthe others don't.\n\nChange-Id: Idbe9cdd90e9ce5e38b03ec1c20066928daa9ef00\nCloses-Bug: 1367966\n""}]",0,126097,8483811889baa2c9f839c1ccbf74d2c14174bd67,8,4,1,6928,,,0,"Test with both vanilla and eventlet stdlib

We intend this project's code to function both with and without
eventlet monkey patching, so we should test that way too.  This adds
a separate test run that explicitly enables eventlet and removes
the racy monkey patching that existed before.

I left the eventlet-specific unit test because it's making direct
calls into eventlet, so it is a somewhat different case from
implicitly using monkey patched classes and I'd rather leave a
redundant test than remove it and find out it covered something
the others don't.

Change-Id: Idbe9cdd90e9ce5e38b03ec1c20066928daa9ef00
Closes-Bug: 1367966
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/97/126097/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_lockutils_eventlet.py', 'tox.ini', 'tests/__init__.py']",3,8483811889baa2c9f839c1ccbf74d2c14174bd67,concurrency-cleanup,"# Copyright 2014 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os if os.environ.get('TEST_EVENTLET'): import eventlet eventlet.monkey_patch()",,21,1
openstack%2Frally~master~Ifbbf973b3666a795663675169da5957709dce8de,openstack/rally,master,Ifbbf973b3666a795663675169da5957709dce8de,Sahara plugins support,MERGED,2014-09-29 12:49:47.000000000,2014-10-06 12:52:32.000000000,2014-10-06 12:52:31.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-09-29 12:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cfa7056e63686330aaf1c3dd3e19a7c4c5aab2d6', 'message': 'Sahara plugins support\n\nAdded cluster creation support for the following plugins:\n* Vanilla 2.4.1\n* HDP 1.3.4 and 2.0.6\n\nChange-Id: Ifbbf973b3666a795663675169da5957709dce8de\n'}, {'number': 2, 'created': '2014-10-01 10:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fa15088004f4a4b7768cfda3e07e4c888856f394', 'message': 'Sahara plugins support\n\nAdded cluster creation support for the following plugins:\n* Vanilla 2.4.1\n* HDP 1.3.4 and 2.0.6\n\nChange-Id: Ifbbf973b3666a795663675169da5957709dce8de\n'}, {'number': 3, 'created': '2014-10-06 09:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5a35ee6833746c87cdc3db9fdb5cfa8576dc17bf', 'message': 'Sahara plugins support\n\nAdded cluster creation support for the following plugins:\n* Vanilla 2.4.1\n* HDP 1.3.4 and 2.0.6\n\nChange-Id: Ifbbf973b3666a795663675169da5957709dce8de\n'}, {'number': 4, 'created': '2014-10-06 11:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/48244d5ec059a7fa08b4f28da94354ef2ee19cf9', 'message': 'Sahara plugins support\n\nAdded cluster creation support for the following plugins:\n* Vanilla 2.4.1\n* HDP 1.3.2 and 2.0.6\n\nChange-Id: Ifbbf973b3666a795663675169da5957709dce8de'}, {'number': 5, 'created': '2014-10-06 11:11:43.000000000', 'files': ['rally/benchmark/scenarios/sahara/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/fabf5d964a332f8f53132a56ceda157394bb9d10', 'message': 'Sahara plugins support\n\nAdded cluster creation support for the following plugins:\n* Vanilla 2.4.1\n* HDP 1.3.2 and 2.0.6\n\nChange-Id: Ifbbf973b3666a795663675169da5957709dce8de'}]",2,124735,fabf5d964a332f8f53132a56ceda157394bb9d10,19,5,5,7132,,,0,"Sahara plugins support

Added cluster creation support for the following plugins:
* Vanilla 2.4.1
* HDP 1.3.2 and 2.0.6

Change-Id: Ifbbf973b3666a795663675169da5957709dce8de",git fetch https://review.opendev.org/openstack/rally refs/changes/35/124735/3 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/scenarios/sahara/utils.py'],1,cfa7056e63686330aaf1c3dd3e19a7c4c5aab2d6,," }, ""2.4.1"": { ""master"": [""namenode"", ""resourcemanager"", ""historyserver"", ""oozie""], ""worker"": [""datanode"", ""nodemanager""] } }, ""hdp"": { ""1.3.4"": { ""master"": ['JOBTRACKER', 'NAMENODE', 'SECONDARY_NAMENODE', 'GANGLIA_SERVER', 'NAGIOS_SERVER', 'AMBARI_SERVER', 'OOZIE_SERVER'], ""worker"": ['TASKTRACKER', 'DATANODE', 'HDFS_CLIENT', 'MAPREDUCE_CLIENT', 'OOZIE_CLIENT', 'PIG'] }, ""2.0.6"": { ""master"": ['NAMENODE', 'SECONDARY_NAMENODE', 'ZOOKEEPER_SERVER', 'AMBARI_SERVER', 'HISTORYSERVER', 'RESOURCEMANAGER', 'GANGLIA_SERVER', 'NAGIOS_SERVER', 'OOZIE_SERVER'], ""worker"": ['HDFS_CLIENT', 'DATANODE', 'ZOOKEEPER_CLIENT', 'MAPREDUCE2_CLIENT', 'YARN_CLIENT', 'NODEMANAGER', 'PIG', 'OOZIE_CLIENT'] }, ""2.4.1"": { ""target"": ""HDFS"", ""config_name"": ""dfs.replication"" } }, ""hdp"": { ""1.3.4"": { ""target"": ""HDFS"", ""config_name"": ""dfs.replication"" }, ""2.0.6"": { ""target"": ""HDFS"", ""config_name"": ""dfs.replication""",,37,0
openstack%2Fhorizon~master~I0231eaa693e7f36699fda6e011db8c976b639411,openstack/horizon,master,I0231eaa693e7f36699fda6e011db8c976b639411,Make Image Description an input field instead of a textarea,MERGED,2014-09-17 21:51:16.000000000,2014-10-06 12:51:02.000000000,2014-10-06 12:51:01.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5280}, {'_account_id': 6610}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-09-17 21:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3d32a145c339c3e9a0b8da949be1ec39aa7d0191', 'message': 'Make Image Description an input field instead of a textarea\n\nThe glanceclient passes the value of the ""Description"" field as\nHTTP headers to the API, completely unmodified.  If there are\nnewlines in the content, it corrupts the headers and creates havoc.\n\nEncoding/decoding the results is not viable, since arbitrary (and\nnot necessarily controlled by anyone) clients can retrieve the data.  So as\na dodge, use a normal <input> field for Description instead of\n<textarea> field, as newlines are not permitted in the former.\n\nChange-Id: I0231eaa693e7f36699fda6e011db8c976b639411\nCloses-Bug: 1370732\n'}, {'number': 2, 'created': '2014-09-18 05:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/86444be06517f9d57c7afbebddf652344eb42233', 'message': 'Make Image Description an input field instead of a textarea\n\nThe glanceclient passes the value of the ""Description"" field as\nHTTP headers to the API, completely unmodified.  If there are\nnewlines in the content, it corrupts the headers and creates havoc.\n\nEncoding/decoding the results is not viable, since arbitrary (and\nnot necessarily controlled by anyone) clients can retrieve the data.  So as\na dodge, use a normal <input> field for Description instead of\n<textarea> field, as newlines are not permitted in the former.\n\nCloses-Bug: 1370732\nChange-Id: I0231eaa693e7f36699fda6e011db8c976b639411\n'}, {'number': 3, 'created': '2014-09-30 21:32:49.000000000', 'files': ['openstack_dashboard/dashboards/project/images/images/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/363ccf7b39bb14624e60ee1aa1f08f4e3f5f0642', 'message': 'Make Image Description an input field instead of a textarea\n\nThe glanceclient passes the value of the ""Description"" field as\nHTTP headers to the API, completely unmodified.  If there are\nnewlines in the content, it corrupts the headers and creates havoc.\n\nEncoding/decoding the results is not viable, since arbitrary (and\nnot necessarily controlled by anyone) clients can retrieve the data.  So as\na dodge, use a normal <input> field for Description instead of\n<textarea> field, as newlines are not permitted in the former.\n\nCloses-Bug: 1370732\nChange-Id: I0231eaa693e7f36699fda6e011db8c976b639411\n'}]",0,122257,363ccf7b39bb14624e60ee1aa1f08f4e3f5f0642,20,8,3,5280,,,0,"Make Image Description an input field instead of a textarea

The glanceclient passes the value of the ""Description"" field as
HTTP headers to the API, completely unmodified.  If there are
newlines in the content, it corrupts the headers and creates havoc.

Encoding/decoding the results is not viable, since arbitrary (and
not necessarily controlled by anyone) clients can retrieve the data.  So as
a dodge, use a normal <input> field for Description instead of
<textarea> field, as newlines are not permitted in the former.

Closes-Bug: 1370732
Change-Id: I0231eaa693e7f36699fda6e011db8c976b639411
",git fetch https://review.opendev.org/openstack/horizon refs/changes/57/122257/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/images/images/forms.py'],1,3d32a145c339c3e9a0b8da949be1ec39aa7d0191,bug/1370732," description = forms.CharField(max_length=255, label=_(""Description""), required=False) description = forms.CharField(max_length=255, label=_(""Description""), required=False,"," description = forms.CharField(widget=forms.widgets.Textarea( attrs={'class': 'modal-body-fixed-width', 'rows': 4}), label=_(""Description""), required=False) description = forms.CharField( widget=forms.widgets.Textarea(), label=_(""Description""), required=False,",4,8
openstack%2Fnova~master~Ibdd920e61408eab389e4520ced3b7a239cc8e7b1,openstack/nova,master,Ibdd920e61408eab389e4520ced3b7a239cc8e7b1,Removed unused method get_bdm_ephemeral_disk_size(),ABANDONED,2014-10-03 16:55:08.000000000,2014-10-06 12:42:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 16:55:08.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f70f87b641dbb939529c213ca84978bcac8bf402', 'message': 'Removed unused method get_bdm_ephemeral_disk_size()\n\nChange-Id: Ibdd920e61408eab389e4520ced3b7a239cc8e7b1\n'}]",0,126016,f70f87b641dbb939529c213ca84978bcac8bf402,13,9,1,1063,,,0,"Removed unused method get_bdm_ephemeral_disk_size()

Change-Id: Ibdd920e61408eab389e4520ced3b7a239cc8e7b1
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/126016/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,f70f87b641dbb939529c213ca84978bcac8bf402,remove_bdm_local,," def get_bdm_ephemeral_disk_size(block_device_mappings): return sum(bdm.get('volume_size', 0) for bdm in block_device_mappings if new_format_is_ephemeral(bdm))",0,10
openstack%2Fnova~master~I7c95f2d3cb320ed7a186e33ad36657a6b790463c,openstack/nova,master,I7c95f2d3cb320ed7a186e33ad36657a6b790463c,Removed unused method get_bdm_swap_list(),ABANDONED,2014-10-03 16:44:24.000000000,2014-10-06 12:41:57.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 16:44:24.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/52be3120dbfad814c3f4916d242ea109593b462c', 'message': 'Removed unused method get_bdm_swap_list()\n\nChange-Id: I7c95f2d3cb320ed7a186e33ad36657a6b790463c\n'}]",0,126013,52be3120dbfad814c3f4916d242ea109593b462c,8,6,1,1063,,,0,"Removed unused method get_bdm_swap_list()

Change-Id: I7c95f2d3cb320ed7a186e33ad36657a6b790463c
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/126013/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,52be3120dbfad814c3f4916d242ea109593b462c,remove_bdm_local,, def get_bdm_swap_list(block_device_mappings): return [bdm for bdm in block_device_mappings if new_format_is_swap(bdm)],0,10
openstack%2Fnova~master~Id339e15bddb0e9aad0e1272295970c618a6771bc,openstack/nova,master,Id339e15bddb0e9aad0e1272295970c618a6771bc,Removed unused method get_bdm_local_disk_num(),ABANDONED,2014-10-03 16:23:50.000000000,2014-10-06 12:41:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 16:23:50.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b8434413c35b34ac3cf2262db4f12d9599d6233b', 'message': 'Removed unused method get_bdm_local_disk_num()\n\nChange-Id: Id339e15bddb0e9aad0e1272295970c618a6771bc\n'}]",0,126007,b8434413c35b34ac3cf2262db4f12d9599d6233b,10,10,1,1063,,,0,"Removed unused method get_bdm_local_disk_num()

Change-Id: Id339e15bddb0e9aad0e1272295970c618a6771bc
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/126007/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,b8434413c35b34ac3cf2262db4f12d9599d6233b,remove_bdm_local,, def get_bdm_local_disk_num(block_device_mappings): return len([bdm for bdm in block_device_mappings if bdm.get('destination_type') == 'local']),0,9
openstack%2Fhorizon~master~I5cf9efa468d3f0a57d20e5ae54f74425d01ac606,openstack/horizon,master,I5cf9efa468d3f0a57d20e5ae54f74425d01ac606,remove read-only network ID field from Edit Network form,MERGED,2014-09-23 06:50:07.000000000,2014-10-06 12:32:23.000000000,2014-10-06 12:32:21.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-09-23 06:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8cb626629bcec8a3dfef2873d700f54f68a4fe42', 'message': 'mark form field network_id as hidden\n\nBefore that network_id was marked as read only widget.\nnetwork_id can still be visible in network detail panel.\n\nCloses-Bug: 1372348\nChange-Id: I5cf9efa468d3f0a57d20e5ae54f74425d01ac606\n'}, {'number': 2, 'created': '2014-09-23 08:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/20b1b3d07290f062a1f6d67a6d615c01fec22878', 'message': ""get network_id from self.initial['network_id']\n\nRemove hidden field 'network_id' from form, as in can be\nretrieved from neutron api, and is no longer needed in\nclent 'create network operation' as can not be changed.\n\nCloses-Bug: 1372348\nChange-Id: I5cf9efa468d3f0a57d20e5ae54f74425d01ac606\n""}, {'number': 3, 'created': '2014-09-30 14:59:38.000000000', 'files': ['openstack_dashboard/dashboards/admin/networks/forms.py', 'openstack_dashboard/dashboards/project/networks/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/696bd32fa02757127d13e5f9cd73bc79d633d3ec', 'message': 'remove read-only network ID field from Edit Network form\n\nRemove unnecessary field network_id from UpdateNetwork form.\nCurrently field is required to pass it to the\napi.neutron.network_update method, but there is also\nself.initial dict where the value can be get.\n\nCloses-Bug: 1372348\nChange-Id: I5cf9efa468d3f0a57d20e5ae54f74425d01ac606\n'}]",3,123350,696bd32fa02757127d13e5f9cd73bc79d633d3ec,24,6,3,12566,,,0,"remove read-only network ID field from Edit Network form

Remove unnecessary field network_id from UpdateNetwork form.
Currently field is required to pass it to the
api.neutron.network_update method, but there is also
self.initial dict where the value can be get.

Closes-Bug: 1372348
Change-Id: I5cf9efa468d3f0a57d20e5ae54f74425d01ac606
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/123350/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/networks/forms.py'],1,8cb626629bcec8a3dfef2873d700f54f68a4fe42,bug/1372348, network_id = forms.CharField(widget=forms.HiddenInput)," network_id = forms.CharField(label=_(""ID""), widget=forms.TextInput( attrs={'readonly': 'readonly'}))",1,3
openstack%2Fheat-specs~master~Ibc9055b5e37398dd29a807cace1d4235b85d4b30,openstack/heat-specs,master,Ibc9055b5e37398dd29a807cace1d4235b85d4b30,Support Cinder scheduler hints,MERGED,2014-09-17 13:46:35.000000000,2014-10-06 12:25:37.000000000,2014-10-06 12:25:36.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 8435}, {'_account_id': 9542}, {'_account_id': 12561}]","[{'number': 1, 'created': '2014-09-17 13:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/b39b9c28dcaae859947b0ab4009137daf0e35dd8', 'message': ""Support Cinder scheduler hints\n\nWhen creating volumes with Cinder, passing scheduler hints can be\nnecessary to select an appropriate back-end.  This spec propose to add\na 'scheduler_hints' option for OS::Cinder::Volume objects, as is it\nalready done for OS::Nova::Server.\n\nChange-Id: Ibc9055b5e37398dd29a807cace1d4235b85d4b30\n""}, {'number': 2, 'created': '2014-09-18 08:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/8b6f0811517afc580a54f20f07900c69333401e3', 'message': ""Support Cinder scheduler hints\n\nWhen creating volumes with Cinder, passing scheduler hints can be\nnecessary to select an appropriate back-end.  This spec proposes to\nadd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nChange-Id: Ibc9055b5e37398dd29a807cace1d4235b85d4b30\n""}, {'number': 3, 'created': '2014-09-29 13:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/1ea5ee02e7556c3bc18aa2e92d0b05947928a219', 'message': ""Support Cinder scheduler hints\n\nWhen creating volumes with Cinder, passing scheduler hints can be\nnecessary to select an appropriate back-end.  This spec proposes to\nadd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nChange-Id: Ibc9055b5e37398dd29a807cace1d4235b85d4b30\n""}, {'number': 4, 'created': '2014-09-29 20:17:30.000000000', 'files': ['specs/kilo/cinder-scheduler-hints.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/435cd28bd4182aa6e585ed85762582fba13c925a', 'message': ""Support Cinder scheduler hints\n\nWhen creating volumes with Cinder, passing scheduler hints can be\nnecessary to select an appropriate back-end.  This spec proposes to\nadd a 'scheduler_hints' option for OS::Cinder::Volume objects, as is\nit already done for OS::Nova::Server.\n\nChange-Id: Ibc9055b5e37398dd29a807cace1d4235b85d4b30\n""}]",5,122157,435cd28bd4182aa6e585ed85762582fba13c925a,26,7,4,12561,,,0,"Support Cinder scheduler hints

When creating volumes with Cinder, passing scheduler hints can be
necessary to select an appropriate back-end.  This spec proposes to
add a 'scheduler_hints' option for OS::Cinder::Volume objects, as is
it already done for OS::Nova::Server.

Change-Id: Ibc9055b5e37398dd29a807cace1d4235b85d4b30
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/57/122157/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/cinder-scheduler-hints.rst'],1,b39b9c28dcaae859947b0ab4009137daf0e35dd8,bp/cinder-scheduler-hints,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== Support Cinder scheduler hints ============================== https://blueprints.launchpad.net/heat/+spec/cinder-scheduler-hints When creating volumes with Cinder, passing scheduler hints can be necessary to select an appropriate back-end. This spec propose to add a 'scheduler_hints' option for OS::Cinder::Volume objects, as is it already done for OS::Nova::Server. Problem description =================== Currently, it is not possible to pass hints to Cinder scheduler when using Heat to create volumes. Proposed change =============== Add a new property for OS::Cinder::Volume resources: 'scheduler_hints'. When specifying it, a user can pass hints to the Cinder scheduler. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: adrien-verge Milestones ---------- Target Milestone for completion: Juno-rc1 Work Items ---------- * Extend OS::Cinder::Volume to support a new 'scheduler_hints' option * When set, pass this option to the Cinder client Dependencies ============ * Support Cinder API version 2 https://blueprints.launchpad.net/heat/+spec/support-cinder-api-v2 ",,65,0
openstack%2Fheat-specs~master~I91d283b58c1e66b02426f87e22435f149b6b8afb,openstack/heat-specs,master,I91d283b58c1e66b02426f87e22435f149b6b8afb,Support Cinder API version 2,MERGED,2014-09-17 13:40:52.000000000,2014-10-06 12:25:05.000000000,2014-10-06 12:25:05.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6899}, {'_account_id': 9542}, {'_account_id': 12561}]","[{'number': 1, 'created': '2014-09-17 13:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/42789e7a1a2137e367793394b66559ba66bc077b', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.  Deployers will be able to choose which API version to use.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 2, 'created': '2014-09-18 09:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/f2ae0756aa1ff874f9ea6ebc9e45967c48b7c7a0', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.  Deployers will be able to choose which API version to use.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 3, 'created': '2014-09-19 10:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/dff855a3fccc177af325fd5aa0c3a0b8388d6532', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.  Deployers will be able to choose which API version to use.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 4, 'created': '2014-09-23 09:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/d38d2d5983cde93620d8fbb2dd7abc043a49112a', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 5, 'created': '2014-09-29 13:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/a980068f038b8c640aceaf06b9d91f0d6bf7af25', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 6, 'created': '2014-09-29 13:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/8136346507048c5c7ead1a3358e9e769fc7caf71', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}, {'number': 7, 'created': '2014-09-29 20:15:04.000000000', 'files': ['doc/source/index.rst', 'specs/kilo/support-cinder-api-v2.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/86c2c543408fcf32c9437bc9f6357d860a59fdfd', 'message': 'Support Cinder API version 2\n\nThis specification proposes to add support for the second version of the\nCinder API, which brings useful improvements and will soon replace\nversion one.\n\nChange-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb\n'}]",8,122153,86c2c543408fcf32c9437bc9f6357d860a59fdfd,33,7,7,12561,,,0,"Support Cinder API version 2

This specification proposes to add support for the second version of the
Cinder API, which brings useful improvements and will soon replace
version one.

Change-Id: I91d283b58c1e66b02426f87e22435f149b6b8afb
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/53/122153/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/support-cinder-api-v2.rst'],1,42789e7a1a2137e367793394b66559ba66bc077b,bp/support-cinder-api-v2,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Support Cinder API version 2 ============================ https://blueprints.launchpad.net/heat/+spec/support-cinder-api-v2 This specification proposes to add support for the second version of the Cinder API, which brings useful improvements and will soon replace version one. Deployers will be able to choose which API version to use. Problem description =================== Currently Heat uses only version 1 of Cinder API to create volumes. Version two, however, brings useful features such as scheduler hints, more consistent responses, caching, filtering, etc. Also, Cinder is deprecating version 1 in favor of 2, so supporting both would make switching easier for users. Use cases: * As a developer I want to be able to pass scheduler hints to Cinder when creating volumes, in order to choose back-ends more precisely. * As a deployer I want to be able to choose between legacy Cinder API v1 and newer v2 API. Proposed change =============== The implementation will add a configuration option, cinder_api_version, that will be defaulted to: ``cinder_api_version=1`` but can be changed to ``cinder_api_version=2`` by modifying heat.conf. The cinderclient variable in heat/engine/clients.py will be created depending on the configuration. Alternatives ------------ Wait for Cinder API v1 to be deprecated and switch abruptly to v2. Implementation ============== Assignee(s) ----------- Primary assignee: adrien-verge Milestones ---------- Target Milestone for completion: Juno-rc1 Work Items ---------- * Add a configuration option: cinder_api_version. * Put some magic in heat/engine/clients.py to pick the correct Cinder client depending on the configuration. Dependencies ============ None ",,87,0
openstack%2Fdesignate~master~I48e5c8c2c04a50c69d39b49a743a155c40350b21,openstack/designate,master,I48e5c8c2c04a50c69d39b49a743a155c40350b21,Fixes minor errors and warning in Sphinx build,MERGED,2014-10-05 14:09:29.000000000,2014-10-06 12:22:58.000000000,2014-10-06 12:22:58.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-10-05 14:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/cf429fb397b6af55e5e657e399135cec85f7cc53', 'message': 'This patch is for minor errors and a warning seen in while doing a Sphinx build\n\n* Fixes error : doc/source/backends/powerdns.rst:29: ERROR: Malformed table.\n* Fixes error : doc/source/configuration.rst:43: ERROR: Malformed table.\n* Fixes error : doc/source/getting-started.rst:285: ERROR: Duplicate target name, cannot be used as a unique reference: ""installing designate""\n* Fixes warning : WARNING: html_static_path entry u\'/opt/stack/designate/doc/source/_static\' does not exist\n\nChange-Id: I48e5c8c2c04a50c69d39b49a743a155c40350b21\nCloses-Bug: #1377619\n'}, {'number': 2, 'created': '2014-10-06 05:37:44.000000000', 'files': ['doc/source/configuration.rst', 'doc/source/getting-started.rst', 'doc/source/backends/powerdns.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/b254e98c78f2cdd0f0f038b22fbed985bd7a4bc0', 'message': 'Fixes minor errors and warning in Sphinx build\n\n * Fixes error : doc/source/backends/powerdns.rst:29: ERROR: Malformed table.\n * Fixes error : doc/source/configuration.rst:43: ERROR: Malformed table.\n * Fixes error : doc/source/getting-started.rst:285: ERROR: Duplicate target name, cannot be used as a unique reference: ""installing designate""\n * Fixes warning : WARNING: html_static_path entry u\'/opt/stack/designate/doc/source/_static\' does not exist\n\nChange-Id: I48e5c8c2c04a50c69d39b49a743a155c40350b21\nCloses-Bug: #1377619\n'}]",0,126183,b254e98c78f2cdd0f0f038b22fbed985bd7a4bc0,9,3,2,13291,,,0,"Fixes minor errors and warning in Sphinx build

 * Fixes error : doc/source/backends/powerdns.rst:29: ERROR: Malformed table.
 * Fixes error : doc/source/configuration.rst:43: ERROR: Malformed table.
 * Fixes error : doc/source/getting-started.rst:285: ERROR: Duplicate target name, cannot be used as a unique reference: ""installing designate""
 * Fixes warning : WARNING: html_static_path entry u'/opt/stack/designate/doc/source/_static' does not exist

Change-Id: I48e5c8c2c04a50c69d39b49a743a155c40350b21
Closes-Bug: #1377619
",git fetch https://review.opendev.org/openstack/designate refs/changes/83/126183/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration.rst', 'doc/source/getting-started.rst', 'doc/source/backends/powerdns.rst']",3,cf429fb397b6af55e5e657e399135cec85f7cc53,fix-bug-1377619,connection sqlite:///$pystatepath/powerdns.sqlite Database connection string,connection sqlite:///$pystatepath/powerdns.sqlite Database connection string,5,5
openstack%2Ftempest~master~I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1,openstack/tempest,master,I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1,Fix use of code name in services decorator,MERGED,2014-09-18 21:41:46.000000000,2014-10-06 12:20:35.000000000,2014-10-06 12:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-18 21:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/55a6a27fb00baa88492607ae99adfee86ecab030', 'message': 'Fix use of code name in services decorator\n\nThis commit fixes an incorrect usage of ceilometer in the services\ndecorator, telemetry is the correct service tag name. This also adds\na unit test to catch the incorrect usage of a service tag.\n\nChange-Id: I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1\n'}, {'number': 2, 'created': '2014-09-23 21:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7286f2b140fab384c2484979026bfd16733a7c5e', 'message': 'Fix use of code name in services decorator\n\nThis commit fixes an incorrect usage of ceilometer in the services\ndecorator, telemetry is the correct service tag name. This also adds\na unit test to catch the incorrect usage of a service tag.\n\nChange-Id: I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1\n'}, {'number': 3, 'created': '2014-09-25 14:17:12.000000000', 'files': ['tempest/tests/test_decorators.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/60359050caa5acf75ee41a7be19ea4aa7102789a', 'message': 'Fix use of code name in services decorator\n\nThis commit fixes an incorrect usage of ceilometer in the services\ndecorator, telemetry is the correct service tag name. This also adds\na unit test to catch the incorrect usage of a service tag.\n\nChange-Id: I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1\n'}]",0,122538,60359050caa5acf75ee41a7be19ea4aa7102789a,28,8,3,5196,,,0,"Fix use of code name in services decorator

This commit fixes an incorrect usage of ceilometer in the services
decorator, telemetry is the correct service tag name. This also adds
a unit test to catch the incorrect usage of a service tag.

Change-Id: I5c231ec3ba064013f8d5fc2f49dbdf28e5c637c1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/38/122538/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/test_decorators.py', 'tempest/test.py']",2,55a6a27fb00baa88492607ae99adfee86ecab030,service-tags-fixes," 'telemetry', 'data_processing']"," 'ceilometer', 'data_processing']",16,1
openstack%2Fhorizon~master~Ic1b42fea349e011da07e2a39c735dfa32a637284,openstack/horizon,master,Ic1b42fea349e011da07e2a39c735dfa32a637284,Imported Translations from Transifex,MERGED,2014-10-04 06:03:46.000000000,2014-10-06 11:59:41.000000000,2014-10-06 11:59:40.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-10-04 06:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/529e4e8372c6a3c79b29b14ae861b2d5ce80019e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic1b42fea349e011da07e2a39c735dfa32a637284\n'}, {'number': 2, 'created': '2014-10-05 06:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/58727bea488f5fb0e1b7302e5d08d4a9d968842b', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic1b42fea349e011da07e2a39c735dfa32a637284\n'}, {'number': 3, 'created': '2014-10-06 06:03:37.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/52c375e6ed773365c368586bfd6f3a046ece1d7c', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic1b42fea349e011da07e2a39c735dfa32a637284\n'}]",0,126118,52c375e6ed773365c368586bfd6f3a046ece1d7c,12,4,3,11131,,,0,"Imported Translations from Transifex

Change-Id: Ic1b42fea349e011da07e2a39c735dfa32a637284
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/126118/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",12,529e4e8372c6a3c79b29b14ae861b2d5ce80019e,transifex/translations,"""POT-Creation-Date: 2014-10-03 23:47-0500\n"" ""PO-Revision-Date: 2014-10-04 04:46+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: dashboards/identity/domains/tables.py:198#: dashboards/identity/groups/tables.py:115 #: dashboards/identity/projects/tables.py:193#: dashboards/project/database_backups/tables.py:145#: dashboards/project/databases/tables.py:315#: dashboards/identity/domains/tables.py:200#: dashboards/identity/groups/tables.py:117#: dashboards/identity/projects/tables.py:197#: dashboards/project/databases/tables.py:270#: dashboards/project/databases/tables.py:249#: dashboards/project/databases/tables.py:254#: dashboards/admin/instances/tables.py:138#: dashboards/project/database_backups/tables.py:161#: dashboards/project/databases/tables.py:264 #: dashboards/project/databases/tables.py:328#: dashboards/identity/domains/tables.py:202#: dashboards/identity/groups/tables.py:195 #: dashboards/identity/projects/tables.py:203 #: dashboards/identity/projects/tables.py:205#: dashboards/project/databases/tables.py:256#: dashboards/identity/projects/tables.py:202#: dashboards/project/database_backups/tables.py:150#: dashboards/project/databases/tables.py:316#: dashboards/identity/domains/tables.py:80 #: dashboards/identity/roles/tables.py:37#: dashboards/admin/volumes/volumes/forms.py:98#: dashboards/admin/volumes/volumes/forms.py:103#: dashboards/identity/domains/tables.py:206#: dashboards/identity/domains/tables.py:38 #: dashboards/identity/groups/tables.py:91 #: dashboards/identity/projects/tables.py:30#: dashboards/identity/domains/tables.py:54 #: dashboards/identity/projects/tables.py:46#: dashboards/identity/domains/tables.py:68#: dashboards/identity/domains/tables.py:94 msgid ""Delete Domain"" msgid_plural ""Delete Domains"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/domains/tables.py:102 msgid ""Deleted Domain"" msgid_plural ""Deleted Domains"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/domains/tables.py:116#: dashboards/identity/domains/tables.py:146#: dashboards/identity/domains/tables.py:171#: dashboards/identity/domains/tables.py:175#: dashboards/identity/domains/tables.py:180#: dashboards/identity/domains/tables.py:194#: dashboards/identity/domains/tables.py:201#: dashboards/identity/groups/tables.py:122#: dashboards/identity/groups/tables.py:39#: dashboards/identity/groups/tables.py:51#: dashboards/identity/groups/tables.py:65 msgid ""Delete Group"" msgid_plural ""Delete Groups"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:73 msgid ""Deleted Group"" msgid_plural ""Deleted Groups"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:118#: dashboards/identity/groups/tables.py:141 msgid ""Remove User"" msgid_plural ""Remove Users"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:149 msgid ""Removed User"" msgid_plural ""Removed Users"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:175#: dashboards/identity/groups/tables.py:190#: dashboards/project/databases/tables.py:281#: dashboards/identity/groups/tables.py:191#: dashboards/identity/groups/tables.py:194#: dashboards/identity/groups/tables.py:204#: dashboards/identity/groups/tables.py:212 msgid ""Add User"" msgid_plural ""Add Users"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:220 msgid ""Added User"" msgid_plural ""Added Users"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/groups/tables.py:254#: dashboards/identity/projects/tables.py:211#: dashboards/identity/projects/tables.py:64#: dashboards/identity/projects/tables.py:75#: dashboards/identity/projects/tables.py:87#: dashboards/identity/projects/tables.py:99#: dashboards/identity/projects/tables.py:116 msgid ""Delete Project"" msgid_plural ""Delete Projects"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/projects/tables.py:124 msgid ""Deleted Project"" msgid_plural ""Deleted Projects"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/projects/tables.py:184#: dashboards/identity/roles/tables.py:81#: dashboards/identity/roles/tables.py:86#: dashboards/identity/roles/tables.py:25#: dashboards/identity/roles/tables.py:51 msgid ""Delete Role"" msgid_plural ""Delete Roles"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/roles/tables.py:59 msgid ""Deleted Role"" msgid_plural ""Deleted Roles"" msgstr[0] """" msgstr[1] """" #: dashboards/identity/roles/tables.py:82#: dashboards/identity/users/forms.py:96 msgid ""Role"" msgstr ""Role"" #: dashboards/identity/users/panel.py:27 #: dashboards/identity/users/tables.py:185 #: dashboards/identity/users/templates/users/index.html:3 #: dashboards/identity/users/templates/users/index.html:6 #: dashboards/project/databases/tables.py:287 #: dashboards/project/databases/tabs.py:47 msgid ""Users"" msgstr ""Users"" #: dashboards/project/databases/tables.py:90#: dashboards/project/databases/tables.py:98#: dashboards/project/database_backups/tables.py:153#: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:27 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:59 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:69 #: dashboards/project/firewalls/workflows.py:106 #: dashboards/project/firewalls/workflows.py:213 #: dashboards/project/firewalls/workflows.py:291 #: dashboards/project/loadbalancers/workflows.py:136 #: dashboards/project/loadbalancers/workflows.py:259 #: dashboards/project/loadbalancers/workflows.py:425 #: dashboards/project/loadbalancers/workflows.py:603 #: dashboards/project/vpn/workflows.py:94 #: dashboards/project/vpn/workflows.py:193 #: dashboards/project/vpn/workflows.py:290 #: dashboards/project/vpn/workflows.py:475 msgid ""Add"" msgstr ""Add"" #: dashboards/project/databases/tables.py:318#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:16 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:34 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:47 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html:3 msgid ""Remove"" msgstr ""Remove"" #: dashboards/project/database_backups/tables.py:167#: dashboards/project/databases/tables.py:334#: dashboards/project/database_backups/tables.py:38 #: dashboards/project/databases/tables.py:148#: dashboards/project/database_backups/tables.py:46#: dashboards/project/database_backups/tables.py:61#: dashboards/project/database_backups/tables.py:81 msgid ""Delete Backup"" msgid_plural ""Delete Backups"" msgstr[0] """" msgstr[1] """" #: dashboards/project/database_backups/tables.py:89 msgid ""Deleted Backup"" msgid_plural ""Deleted Backups"" msgstr[0] """" msgstr[1] """" #: dashboards/project/database_backups/tables.py:129 #: dashboards/project/database_backups/tables.py:135 #: dashboards/project/databases/tables.py:194 #: dashboards/project/databases/tables.py:200 #: dashboards/project/databases/tables.py:217 #: dashboards/project/databases/tables.py:223#: dashboards/project/database_backups/tables.py:147#: dashboards/project/databases/tables.py:251#: dashboards/project/database_backups/tables.py:149#: dashboards/project/databases/tables.py:253#: dashboards/project/database_backups/tables.py:155 #: dashboards/project/databases/tables.py:322#: dashboards/project/database_backups/workflows/create_backup.py:83 #: dashboards/project/databases/workflows/create_instance.py:228 msgid ""Backup"" msgstr ""Backup"" #: dashboards/project/databases/tables.py:37 #: dashboards/project/instances/tables.py:90 msgid ""Terminate Instance"" msgid_plural ""Terminate Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/project/databases/tables.py:45 #: dashboards/project/instances/tables.py:98 msgid ""Scheduled termination of Instance"" msgid_plural ""Scheduled termination of Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/project/databases/tables.py:62 msgid ""Restart Instance"" msgid_plural ""Restart Instances"" msgstr[0] """" msgstr[1] """"msgid ""Restarted Instance"" msgid_plural ""Restarted Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/project/databases/tables.py:108#: dashboards/project/databases/tables.py:116 msgid ""Delete Database"" msgid_plural ""Delete Databases"" msgstr[0] """" msgstr[1] """" #: dashboards/project/databases/tables.py:124 msgid ""Deleted Database"" msgid_plural ""Deleted Databases"" msgstr[0] """" msgstr[1] """" #: dashboards/project/databases/tables.py:134#: dashboards/project/databases/tables.py:140#: dashboards/project/databases/tables.py:164#: dashboards/project/databases/tables.py:208#: dashboards/project/databases/tables.py:213#: dashboards/project/databases/tables.py:231#: dashboards/project/databases/tables.py:259#: dashboards/project/databases/tables.py:282#: dashboards/project/databases/tables.py:283 #: dashboards/project/databases/tables.py:300 #: dashboards/project/databases/tabs.py:77 msgid ""Databases"" msgstr ""Databases"" #: dashboards/project/databases/tables.py:296#: dashboards/project/databases/tables.py:320#: dashboards/project/instances/workflows/create_instance.py:51 msgid ""User"" msgstr ""User"" ","""POT-Creation-Date: 2014-10-02 13:57-0500\n"" ""PO-Revision-Date: 2014-10-02 21:37+0000\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n""#: dashboards/identity/domains/tables.py:183#: dashboards/identity/groups/tables.py:100 #: dashboards/identity/projects/tables.py:178#: dashboards/project/database_backups/tables.py:131#: dashboards/project/databases/tables.py:264#: dashboards/identity/domains/tables.py:185#: dashboards/identity/groups/tables.py:102#: dashboards/identity/projects/tables.py:182#: dashboards/project/databases/tables.py:37 #: dashboards/project/databases/tables.py:50 #: dashboards/project/databases/tables.py:219#: dashboards/project/databases/tables.py:198#: dashboards/project/databases/tables.py:203#: dashboards/admin/instances/tables.py:137#: dashboards/project/database_backups/tables.py:147#: dashboards/project/databases/tables.py:213 #: dashboards/project/databases/tables.py:277#: dashboards/identity/domains/tables.py:187#: dashboards/identity/groups/tables.py:168 #: dashboards/identity/projects/tables.py:188 #: dashboards/identity/projects/tables.py:190#: dashboards/project/databases/tables.py:36 #: dashboards/project/databases/tables.py:49#: dashboards/identity/projects/tables.py:112#: dashboards/project/databases/tables.py:205#: dashboards/identity/projects/tables.py:187#: dashboards/project/database_backups/tables.py:136#: dashboards/project/databases/tables.py:265#: dashboards/identity/domains/tables.py:79 #: dashboards/identity/roles/tables.py:36#: dashboards/admin/volumes/volumes/forms.py:97#: dashboards/admin/volumes/volumes/forms.py:102#: dashboards/identity/domains/tables.py:92 #: dashboards/identity/domains/tables.py:191#: dashboards/identity/domains/tables.py:37 #: dashboards/identity/groups/tables.py:76 #: dashboards/identity/projects/tables.py:29#: dashboards/identity/domains/tables.py:53 #: dashboards/identity/projects/tables.py:45#: dashboards/identity/domains/tables.py:67#: dashboards/identity/domains/tables.py:91 msgid ""Domain"" msgstr ""Domain"" #: dashboards/identity/domains/tables.py:101#: dashboards/identity/domains/tables.py:131#: dashboards/identity/domains/tables.py:156#: dashboards/identity/domains/tables.py:160#: dashboards/identity/domains/tables.py:165#: dashboards/identity/domains/tables.py:179#: dashboards/identity/domains/tables.py:186#: dashboards/identity/groups/tables.py:63 #: dashboards/identity/groups/tables.py:107#: dashboards/identity/groups/tables.py:38#: dashboards/identity/groups/tables.py:50#: dashboards/identity/groups/tables.py:62 msgid ""Group"" msgstr ""Group"" #: dashboards/identity/groups/tables.py:103#: dashboards/identity/groups/tables.py:124 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:16 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:34 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:47 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html:3 msgid ""Remove"" msgstr ""Remove"" #: dashboards/identity/groups/tables.py:125 msgid ""Removed"" msgstr ""Removed"" #: dashboards/identity/groups/tables.py:126 #: dashboards/identity/groups/tables.py:185 #: dashboards/project/databases/tables.py:62 #: dashboards/project/instances/workflows/create_instance.py:51 msgid ""User"" msgstr ""User"" #: dashboards/identity/groups/tables.py:127 #: dashboards/identity/groups/tables.py:186 #: dashboards/identity/users/panel.py:27 #: dashboards/identity/users/tables.py:185 #: dashboards/identity/users/templates/users/index.html:3 #: dashboards/identity/users/templates/users/index.html:6 #: dashboards/project/databases/tables.py:63 #: dashboards/project/databases/tables.py:236 #: dashboards/project/databases/tabs.py:47 msgid ""Users"" msgstr ""Users"" #: dashboards/identity/groups/tables.py:148#: dashboards/identity/groups/tables.py:163#: dashboards/project/databases/tables.py:230#: dashboards/identity/groups/tables.py:164#: dashboards/identity/groups/tables.py:167#: dashboards/identity/groups/tables.py:177#: dashboards/identity/groups/tables.py:183 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:27 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:59 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:69 #: dashboards/project/firewalls/workflows.py:106 #: dashboards/project/firewalls/workflows.py:213 #: dashboards/project/firewalls/workflows.py:291 #: dashboards/project/loadbalancers/workflows.py:136 #: dashboards/project/loadbalancers/workflows.py:259 #: dashboards/project/loadbalancers/workflows.py:425 #: dashboards/project/loadbalancers/workflows.py:603 #: dashboards/project/vpn/workflows.py:94 #: dashboards/project/vpn/workflows.py:193 #: dashboards/project/vpn/workflows.py:290 #: dashboards/project/vpn/workflows.py:475 msgid ""Add"" msgstr ""Add"" #: dashboards/identity/groups/tables.py:184 msgid ""Added"" msgstr ""Added"" #: dashboards/identity/groups/tables.py:215#: dashboards/identity/projects/tables.py:113 #: dashboards/identity/projects/tables.py:196#: dashboards/identity/projects/tables.py:63#: dashboards/identity/projects/tables.py:74#: dashboards/identity/projects/tables.py:86#: dashboards/identity/projects/tables.py:98#: dashboards/identity/projects/tables.py:169#: dashboards/identity/roles/tables.py:67#: dashboards/identity/roles/tables.py:48 #: dashboards/identity/roles/tables.py:72#: dashboards/identity/roles/tables.py:24#: dashboards/identity/roles/tables.py:47 #: dashboards/identity/users/forms.py:96 msgid ""Role"" msgstr ""Role"" #: dashboards/identity/roles/tables.py:68#: dashboards/project/database_backups/tables.py:139 #: dashboards/project/databases/tables.py:75#: dashboards/project/databases/tables.py:267#: dashboards/project/database_backups/tables.py:78 #: dashboards/project/database_backups/tables.py:153#: dashboards/project/databases/tables.py:283#: dashboards/project/database_backups/tables.py:37 #: dashboards/project/databases/tables.py:97#: dashboards/project/database_backups/tables.py:45#: dashboards/project/database_backups/tables.py:60#: dashboards/project/database_backups/tables.py:77 #: dashboards/project/database_backups/workflows/create_backup.py:83 #: dashboards/project/databases/workflows/create_instance.py:228 msgid ""Backup"" msgstr ""Backup"" #: dashboards/project/database_backups/tables.py:115 #: dashboards/project/database_backups/tables.py:121 #: dashboards/project/databases/tables.py:143 #: dashboards/project/databases/tables.py:149 #: dashboards/project/databases/tables.py:166 #: dashboards/project/databases/tables.py:172#: dashboards/project/database_backups/tables.py:133#: dashboards/project/databases/tables.py:200#: dashboards/project/database_backups/tables.py:135#: dashboards/project/databases/tables.py:202#: dashboards/project/database_backups/tables.py:141 #: dashboards/project/databases/tables.py:271#: dashboards/project/databases/tables.py:34 msgid ""Terminate"" msgstr ""Terminate"" #: dashboards/project/databases/tables.py:35 #, python-format msgid ""Scheduled termination of %(data_type)s"" msgstr ""Scheduled termination of %(data_type)s"" #: dashboards/project/databases/tables.py:47 msgid ""Restart"" msgstr ""Restart"" #: dashboards/project/databases/tables.py:48 msgid ""Restarted"" msgstr ""Restarted""#: dashboards/project/databases/tables.py:76 #: dashboards/project/databases/tables.py:232 #: dashboards/project/databases/tables.py:249 #: dashboards/project/databases/tabs.py:77 msgid ""Databases"" msgstr ""Databases"" #: dashboards/project/databases/tables.py:83#: dashboards/project/databases/tables.py:89#: dashboards/project/databases/tables.py:113#: dashboards/project/databases/tables.py:157#: dashboards/project/databases/tables.py:162#: dashboards/project/databases/tables.py:180#: dashboards/project/databases/tables.py:208#: dashboards/project/databases/tables.py:231#: dashboards/project/databases/tables.py:245#: dashboards/project/databases/tables.py:269#: dashboards/project/instances/tables.py:90 msgid ""Terminate Instance"" msgid_plural ""Terminate Instances"" msgstr[0] """" msgstr[1] """" #: dashboards/project/instances/tables.py:98 msgid ""Scheduled termination of Instance"" msgid_plural ""Scheduled termination of Instances"" msgstr[0] """" msgstr[1] """" ",3047,2417
openstack%2Fhorizon~master~I9f1cc8ff862471f33a5cb40f9e210c5222b7fb94,openstack/horizon,master,I9f1cc8ff862471f33a5cb40f9e210c5222b7fb94,Use action_present/past methods in BatchAction,MERGED,2014-10-04 17:20:04.000000000,2014-10-06 11:56:55.000000000,2014-10-06 11:56:54.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-10-04 17:20:04.000000000', 'files': ['openstack_dashboard/dashboards/project/vpn/tables.py', 'openstack_dashboard/dashboards/project/loadbalancers/tables.py', 'openstack_dashboard/dashboards/admin/instances/tables.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/969ff4828b40a9be2283a9f20ba95d0668cb7e4b', 'message': 'Use action_present/past methods in BatchAction\n\naction_present/past methods were introduced in BatchAction to allow\ntranslators to control word orders and plural forms. This patch\nreplaces the remaining old attribute version of action_present/past\nwith the method version.\n\nChange-Id: I9f1cc8ff862471f33a5cb40f9e210c5222b7fb94\nPartial-Bug: #1307476\n'}]",0,126153,969ff4828b40a9be2283a9f20ba95d0668cb7e4b,8,4,1,841,,,0,"Use action_present/past methods in BatchAction

action_present/past methods were introduced in BatchAction to allow
translators to control word orders and plural forms. This patch
replaces the remaining old attribute version of action_present/past
with the method version.

Change-Id: I9f1cc8ff862471f33a5cb40f9e210c5222b7fb94
Partial-Bug: #1307476
",git fetch https://review.opendev.org/openstack/horizon refs/changes/53/126153/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/vpn/tables.py', 'openstack_dashboard/dashboards/project/loadbalancers/tables.py', 'openstack_dashboard/dashboards/admin/instances/tables.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py']",4,969ff4828b40a9be2283a9f20ba95d0668cb7e4b,bug/1307476," @staticmethod def action_present(count): return ungettext_lazy( u""Detach Volume"", u""Detach Volumes"", count ) # This action is asynchronous. @staticmethod def action_past(count): return ungettext_lazy( u""Detaching Volume"", u""Detaching Volumes"", count ) "," action_present = _(""Detach"") action_past = _(""Detaching"") # This action is asynchronous. data_type_singular = _(""Volume"") data_type_plural = _(""Volumes"")",164,40
openstack%2Ffuel-main~master~I84c955a55acb1104b749d6c1fd163bcc2ebe4a94,openstack/fuel-main,master,I84c955a55acb1104b749d6c1fd163bcc2ebe4a94,Installing fuel-agent into bootstrap,ABANDONED,2014-09-25 16:41:36.000000000,2014-10-06 11:52:13.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-09-25 16:41:36.000000000', 'files': ['bootstrap/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bd8233aa6c31bb7ab4d8827351a6a9c7655bdb27', 'message': 'Installing fuel-agent into bootstrap\n\nImplements: blueprint image-based-provisioning\nChange-Id: I84c955a55acb1104b749d6c1fd163bcc2ebe4a94\n'}]",0,124110,bd8233aa6c31bb7ab4d8827351a6a9c7655bdb27,5,2,1,3009,,,0,"Installing fuel-agent into bootstrap

Implements: blueprint image-based-provisioning
Change-Id: I84c955a55acb1104b749d6c1fd163bcc2ebe4a94
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/10/124110/1 && git format-patch -1 --stdout FETCH_HEAD,['bootstrap/module.mk'],1,bd8233aa6c31bb7ab4d8827351a6a9c7655bdb27,bp/image-based-provisioning, nailgun-net-check \ fuel-agent, nailgun-net-check,2,1
openstack%2Fneutron~master~Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17,openstack/neutron,master,Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17,Implement ModelsMigrationsSync test from oslo.db,MERGED,2014-04-28 20:01:23.000000000,2014-10-06 11:41:30.000000000,2014-10-06 11:41:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6849}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 8911}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9885}, {'_account_id': 9897}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 14, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/22316fb8096954e85be35cb357538592f5b13bb5', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 15, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33394fd0ddb04ba5ec4cc7abfc819c2df5227c1c', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 12, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cdceeb50d2f45b90431987b2efefd889ef63b2fd', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 13, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a1e6deae8065aa0718a8debe44aa2ad79d7c4b4', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 10, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83e703e062c19128599ee3779de9496834374383', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 11, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d50f6b90dd3cce9997ac50b40b95690bdb59a05', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 8, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71d0ac99e819f55dc20c1b7b0f2ff4e2e0a81a2b', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 9, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a0c9df2842d574bd4773215962100f4030193c8', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/086ab4103cb70d592483b6b65fc059c6f7bab91e', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 7, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83d616d1b8c0f578bb2be2277a1d33c00d7a0520', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4ae39852d0adb1466e924a65509394fc886bd0b', 'message': 'Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/91ee78b39d2da6857e6f38be6b1f817f0a37bcb5', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f275b13cf062ad42b29742e6d4f7140c739d037', 'message': 'Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a206ce8f275d04e809c692261890a0168b1f007', 'message': 'Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d142efcbfa2a8f966660fba63ad182966cc4720b', 'message': 'Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 16, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/294a3e683e0f54b42453fc97c55bf717c1e45034', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 17, 'created': '2014-05-12 09:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/074bea1de3b24d3fc39616f072495eed14da2a01', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 18, 'created': '2014-07-07 12:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4975e0e71bd3a1dec57326765355f365784a895', 'message': 'WIP Implement test\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 19, 'created': '2014-07-10 09:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/534f73647a66200a9c399633490abbb9c008de48', 'message': 'WIP: Implement ModelsMigrationsSync test from oslo.db\n\nAdd testing for checking syncronization of models with\ndb content. It is needed for healing script as unit testing.\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 20, 'created': '2014-07-14 12:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b036cd504b47dfe09d0d94167d53e47c842aa426', 'message': 'WIP: Implement ModelsMigrationsSync test from oslo.db\n\nAdd testing for checking synchronization of models with\ndb content. It is needed for healing script as unit testing.\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 21, 'created': '2014-07-14 14:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/084aa3c697c05b3073c77e418e701cd3af4cae95', 'message': 'WIP: Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nbp: db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 22, 'created': '2014-07-15 10:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3de77cb2d12c5115c0c3635acb955095213101ec', 'message': 'WIP: Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nbp: db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 23, 'created': '2014-07-16 08:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c385374abf38cfe4ed105ed7d483acc971599fa', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nbp: db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 24, 'created': '2014-07-16 10:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a353f5199a6024ebe0403ac4fd82cf8ced686998', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 25, 'created': '2014-07-16 10:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/244c3f281c1cc150913fcc138daf2bc73ee7cb28', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 26, 'created': '2014-07-17 08:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8ad7dbbdb706953e98e3b1c41e99a117e365b71', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 27, 'created': '2014-07-17 11:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e38ceacd817a90b7e006e0f11ac88c1a6f75eb8', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 28, 'created': '2014-07-17 15:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/401eaad843932992f51923c2e898ff30b9200083', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 29, 'created': '2014-07-17 15:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d991f0866c05e05dc2806c676a1d2c4fc5e7a1d', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 30, 'created': '2014-07-17 15:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da3b61c4fb925c813daff2f95190cbf4b0a34da5', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 31, 'created': '2014-07-18 08:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/090caa4f7d6588de00b039e2f0f42fe6fefe249e', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 32, 'created': '2014-07-18 09:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efb7b2ae5be1c207990e7daacf4c60c017380469', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 33, 'created': '2014-07-18 09:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ee15e69c317a05330f7e5d87cb6dbbab4b8434e', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 34, 'created': '2014-07-18 10:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ed5840b9bc60517f7cad7629d2dccaeb86d5b7e', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 35, 'created': '2014-07-18 10:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd5f4bc0957e8a8453a4c86d844dfa450a2e2f4a', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 36, 'created': '2014-07-18 11:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/454b78808e220823f0177c7016a354000edf1c96', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 37, 'created': '2014-07-18 11:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fab16baacfbeef9c92d44cab154ee74daa0a17b', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 38, 'created': '2014-07-18 12:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e487e27f52a819077841ed1c8875be84ac4806e', 'message': 'Some tests\n\nImplement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 39, 'created': '2014-07-21 08:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/584d30c2eb1f32ef0d57d153d38c884b59b025a9', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 40, 'created': '2014-07-21 18:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff2aa1a936a60d3a43d0d9001de3dac6277a60dc', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 41, 'created': '2014-07-23 08:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bbcea61c91a2ec1e0802ac97f889c240c443acf6', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nImplements: blueprint db-migration-refactor\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 42, 'created': '2014-07-23 08:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44df8a37b9dfcf7d896f947330aa7cc0c5cab041', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 43, 'created': '2014-07-23 11:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99117eae5804bbdc4d570077e1ae3c23f28bd4e0', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 44, 'created': '2014-07-23 13:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0246a3b1d042170d787c8cf25caee1af1ad6b61f', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 45, 'created': '2014-07-23 13:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5b9cef02a0d05d544884c53f5c85f48f5d8d37f', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 46, 'created': '2014-07-24 08:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d780cbb04dbf6f07643a7d8971bbb05b43a0d8d0', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 47, 'created': '2014-07-24 12:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b047c20526f098a4f2bcea91fbad8a61e6fa69b8', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 48, 'created': '2014-07-28 14:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/029fa70404a0635b7983a711958658e5629da582', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 49, 'created': '2014-07-30 12:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ab6e7df13dc1db74d99b671e2c233a9edfa6ac5', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 50, 'created': '2014-07-31 13:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f0c6a1e285e9548f56e72279a7b032dd307458d', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 51, 'created': '2014-07-31 14:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d2371a64f5641102c83ed906747703151b6755a', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 52, 'created': '2014-08-18 09:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/419cc6a39a95f97504c599ffb31e1af512092d26', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 53, 'created': '2014-08-18 15:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/042740979fbc286f65621dea2041a269196c9810', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 54, 'created': '2014-08-19 08:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98db2fe3191fe280558338cbe72963377c19a811', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 55, 'created': '2014-08-19 09:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a753321864c1a7aa9eecd83cff793bb4f5d3dd6c', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 56, 'created': '2014-08-20 09:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f95c26862d9ff1f30d621d70d04debdaf1f13e6b', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 57, 'created': '2014-08-20 13:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cffb0343e29d9787113be7f8a33aa0eaed6ff536', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 58, 'created': '2014-08-22 11:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ff23c4698d20c4166fb0459be6548c0d078fea2', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 59, 'created': '2014-08-25 12:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f93f3c06739f93f10be8a9ef6fb1d2a389841542', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 60, 'created': '2014-08-26 14:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e844f8a60259e5a53d6c929d3653970c54809a7c', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 62, 'created': '2014-09-02 07:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f4bd174fec4fd4c4e6743ba3b23f37be8a366244', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 63, 'created': '2014-09-04 12:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2cf1d694c24ab845e6e36e9e39ea246ba01cbf6', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 64, 'created': '2014-09-08 10:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77fbc5edf24a67276123f7b2e3eb907570119d91', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 65, 'created': '2014-09-08 14:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94c34bd590dd8cf18ebf39fe4ae7ce672a36e313', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 66, 'created': '2014-09-09 08:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0fc24346cde589aa83dced69dacb1a5649982261', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nAdded Testcase for Ml2 plugins.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 67, 'created': '2014-09-09 08:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/babf97e6a8668d12fb4f6433edd2937d60b11078', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nAdded Testcase for Ml2 plugins.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 68, 'created': '2014-09-11 12:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b58799e0eabbffc5a27679a5d12675abe11da1a2', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nAdded Testcase for Ml2 plugins.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 69, 'created': '2014-09-12 12:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26107fe342566a9c98c88e88c4e010df12f731f4', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nAdded Testcase for Ml2 plugins.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 70, 'created': '2014-09-12 15:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e12d8d1604655bdb42829ce7608b500ea83d6bdf', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 71, 'created': '2014-09-15 11:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a585b83775b51c878d0fcc65056663a38e6301a', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 72, 'created': '2014-09-15 13:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13deaa5d32b3180f0fdfdb80287288145f38969d', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 73, 'created': '2014-09-17 14:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce00dafcd0b78009a47cdd2e644e9828321548a0', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd test for checking of equality models state and migrations and\nusage InnoDB engine for MySQL.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 74, 'created': '2014-09-18 14:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d0ef19ba1c0e39872710d599776fa2c739b9a06', 'message': 'Functional tests to verify models and migrations sync\n\nAdd functional tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocal from Python unittest\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 75, 'created': '2014-09-19 05:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/36ceb4ec3161cbd1788e3b18d2d380748cd6c726', 'message': 'Functional tests to verify models and migrations sync\n\nAdd functional tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 76, 'created': '2014-09-19 07:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/527e329b9cef1d8e67363397c3ed711970a546f2', 'message': 'Functional tests to verify models and migrations sync\n\nAdd functional tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 77, 'created': '2014-09-22 07:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca9c8dec9acc2b29899a66014a21f6c2801cfe64', 'message': 'Functional tests to verify models and migrations sync\n\nAdd functional tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 78, 'created': '2014-09-22 13:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10adc66a50a5394d6d7a6c454b242aef312c0e6d', 'message': 'Functional tests to verify models and migrations sync\n\nAdd functional tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 79, 'created': '2014-09-23 12:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2dccb686fd39e0dfa16c6a0f59e8bb3efaf211bc', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 80, 'created': '2014-09-25 08:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/990a47804a26a497e57843e2af1df2de22b7226e', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 81, 'created': '2014-09-26 07:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1024545615cf8ce536e7ad7adbdcb7cd44121b62', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}, {'number': 82, 'created': '2014-09-30 07:58:23.000000000', 'files': ['neutron/db/migration/cli.py', 'doc/source/devref/db_layer.rst', 'test-requirements.txt', 'neutron/db/migration/alembic_migrations/env.py', 'neutron/tests/unit/db/test_migration.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5247f5cdf15bad4c62bbf854e30716fcf00a1d2a', 'message': 'Implement ModelsMigrationsSync test from oslo.db\n\nAdd tests to verify that database migrations produce\nthe same schema as the database models.\n\nAlso for MySQL, check that all tables are configured to use InnoDB\nas the storage engine.\nThese tests make use of the ModelsMigrationsSync test class from\noslo.db and the load_tests protocol from Python unittest.\n\nCloses-bug: #1346444\n\nChange-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17\n'}]",110,76520,5247f5cdf15bad4c62bbf854e30716fcf00a1d2a,1500,41,81,7249,,,0,"Implement ModelsMigrationsSync test from oslo.db

Add tests to verify that database migrations produce
the same schema as the database models.

Also for MySQL, check that all tables are configured to use InnoDB
as the storage engine.
These tests make use of the ModelsMigrationsSync test class from
oslo.db and the load_tests protocol from Python unittest.

Closes-bug: #1346444

Change-Id: Ic0e7eb37c30cc5e94cbdbddf07a6dc1ebf377c17
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/76520/78 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/cli.py', 'neutron/plugins/vmware/dbexts/networkgw_db.py', 'neutron/db/firewall/firewall_db.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/plugins/vmware/dbexts/lsn_db.py', 'neutron/plugins/vmware/dbexts/models.py', 'neutron/db/migration/alembic_migrations/versions/1c33fa3cd1a1_extra_route_config.py', 'neutron/plugins/cisco/db/network_models_v2.py', 'neutron/plugins/ml2/models.py', 'neutron/db/metering/metering_db.py', 'neutron/plugins/nec/db/packetfilter.py', 'neutron/tests/unit/db/test_sync_migration.py', 'neutron/db/migration/alembic.ini', 'neutron/plugins/cisco/db/nexus_models_v2.py']",14,22316fb8096954e85be35cb357538592f5b13bb5,add_test," switch_ip = sa.Column(sa.String(255), nullable=False) instance_id = sa.Column(sa.String(255), nullable=False)", switch_ip = sa.Column(sa.String(255)) instance_id = sa.Column(sa.String(255)),548,26
openstack%2Foslo.messaging~master~I65b8673cc97c491cfc5c1ab79915549fb8afb8b1,openstack/oslo.messaging,master,I65b8673cc97c491cfc5c1ab79915549fb8afb8b1,Switch to oslo.i18n,ABANDONED,2014-09-30 16:10:45.000000000,2014-10-06 11:24:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-09-30 16:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5697a69d9c06fcacfd905b672ce34c5f5ad67138', 'message': 'Switch to oslo.i18n\n\nChange-Id: I65b8673cc97c491cfc5c1ab79915549fb8afb8b1\n'}, {'number': 2, 'created': '2014-10-01 11:25:38.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_i18n.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/openstack/common/gettextutils.py', 'requirements.txt', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/notify/middleware.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/rpc/dispatcher.py', 'openstack-common.conf', 'requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/33bd157a87d794d2d1637d40de8e421adef958c2', 'message': 'Switch to oslo.i18n\n\nChange-Id: I65b8673cc97c491cfc5c1ab79915549fb8afb8b1\n'}]",0,125107,33bd157a87d794d2d1637d40de8e421adef958c2,6,1,2,1669,,,0,"Switch to oslo.i18n

Change-Id: I65b8673cc97c491cfc5c1ab79915549fb8afb8b1
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/07/125107/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_i18n.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/openstack/common/gettextutils.py', 'requirements.txt', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/notify/middleware.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/rpc/dispatcher.py', 'openstack-common.conf', 'requirements-py3.txt', 'tox.ini']",15,5697a69d9c06fcacfd905b672ce34c5f5ad67138,jd/oslo.i18n, oslo.messaging._i18n, oslo.messaging.openstack.common.gettextutils,32,515
openstack%2Ftempest~master~I3dd272f15a282b2ac58beee10f36c8af66377727,openstack/tempest,master,I3dd272f15a282b2ac58beee10f36c8af66377727,Improve IPV6 parity in Security Group testcases,MERGED,2014-05-19 05:04:48.000000000,2014-10-06 11:18:45.000000000,2014-10-06 11:18:44.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 4656}, {'_account_id': 5371}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6537}, {'_account_id': 7139}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10118}, {'_account_id': 10257}, {'_account_id': 10385}, {'_account_id': 10624}, {'_account_id': 10966}, {'_account_id': 10969}]","[{'number': 1, 'created': '2014-05-19 05:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/89a8fada4a718dc4efb79ce084895bdaec650cc1', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements IPV6 testcases for Security Groups\nand adds few additional test cases to validate icmp protocol,\nremote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 2, 'created': '2014-05-20 12:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1fc0a9b1deb44fb453e80334b5f4607879a44665', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 3, 'created': '2014-05-21 04:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/372ca6026224ff28fd766342a1b5e963e4ce33be', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 4, 'created': '2014-05-22 09:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a76ffcae91b5b9c156c2cb6b50cda603e3f865e7', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 5, 'created': '2014-05-26 08:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8dd8ba8ff2af673f312aed654b1f5d8034a38d6', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 6, 'created': '2014-05-26 09:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5aaeba0f192781fe4f95a5950abd0e50a07bb252', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix.\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 7, 'created': '2014-06-09 15:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c910a4684c4f7d254766dca1939e6e69e82edb3', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 8, 'created': '2014-06-25 10:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f6cfa7be47e74ddbe83bc44d8e0f6559301b33c9', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 9, 'created': '2014-08-11 06:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/40336f8732e589dcd940a93e19c3b3996b1865c9', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-testing-parity\n'}, {'number': 10, 'created': '2014-08-12 09:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c04a5b24de8d4e8b637b5cd9240da620e44825d', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-api-testing-parity\n'}, {'number': 11, 'created': '2014-09-04 10:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e6b9f2c4519f8849d177de65be248855b8a6ae0', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-api-testing-parity\n'}, {'number': 12, 'created': '2014-09-08 18:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/21cbb99719bce2acf7e3a87dd6155c0ba3c54cc8', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-api-testing-parity\n'}, {'number': 13, 'created': '2014-10-03 09:20:12.000000000', 'files': ['tempest/api/network/test_security_groups_negative.py', 'tempest/api/network/test_security_groups.py', 'tempest/api/network/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/510f896cf670ec1e765250b159b6712b9acaef9e', 'message': 'Improve IPV6 parity in Security Group testcases\n\nThis patch implements positive and negative IPV6 testcases\nfor Security Groups and adds few additional test cases to\nvalidate icmp protocol, remote_group_id and remote_ip_prefix\n\nChange-Id: I3dd272f15a282b2ac58beee10f36c8af66377727\nPartially implements: bp ipv6-api-testing-parity\n'}]",69,94130,510f896cf670ec1e765250b159b6712b9acaef9e,144,22,13,10257,,,0,"Improve IPV6 parity in Security Group testcases

This patch implements positive and negative IPV6 testcases
for Security Groups and adds few additional test cases to
validate icmp protocol, remote_group_id and remote_ip_prefix

Change-Id: I3dd272f15a282b2ac58beee10f36c8af66377727
Partially implements: bp ipv6-api-testing-parity
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/94130/12 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_security_groups.py', 'tempest/api/network/base.py']",2,89a8fada4a718dc4efb79ce084895bdaec650cc1,bp/ipv6-api-testing-parity," cls.ethertype = ""IPv"" + str(cls._ip_version)",,122,1
openstack%2Ffuel-web~master~I9d64aaa53bef80a51fec2f09992d49c96b0b5e0d,openstack/fuel-web,master,I9d64aaa53bef80a51fec2f09992d49c96b0b5e0d,Show both real and ht CPU cores on UI,MERGED,2014-10-01 12:46:49.000000000,2014-10-06 11:16:38.000000000,2014-10-06 11:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-10-01 12:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/80b59af6e7690b1f35ebae297d6d17fbeb67491a', 'message': ""Show both real and ht CPU cores on UI\n\nWe should show real CPU cores in order to don't confuse users. HT cores\ninfo is useful, but not primary, so we can show it in parentheses.\n\nChange-Id: I9d64aaa53bef80a51fec2f09992d49c96b0b5e0d\nCloses-Bug: #1373608\n""}, {'number': 2, 'created': '2014-10-03 12:21:12.000000000', 'files': ['nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/node.html', 'nailgun/static/js/views/clusters_page.jsx', 'nailgun/static/js/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8fbee916c8e7df88c007320c3f283d1f9dd99377', 'message': ""Show both real and ht CPU cores on UI\n\nWe should show real CPU cores in order to don't confuse users. HT cores\ninfo is useful, but not primary, so we can show it in parentheses.\n\nChange-Id: I9d64aaa53bef80a51fec2f09992d49c96b0b5e0d\nCloses-Bug: #1373608\n""}]",0,125342,8fbee916c8e7df88c007320c3f283d1f9dd99377,19,6,2,10391,,,0,"Show both real and ht CPU cores on UI

We should show real CPU cores in order to don't confuse users. HT cores
info is useful, but not primary, so we can show it in parentheses.

Change-Id: I9d64aaa53bef80a51fec2f09992d49c96b0b5e0d
Closes-Bug: #1373608
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/42/125342/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/templates/cluster/node.html', 'nailgun/static/js/views/clusters_page.jsx', 'nailgun/static/js/models.js']",3,80b59af6e7690b1f35ebae297d6d17fbeb67491a,bug/1373608, resource = this.get('meta').cpu.real; } else if (resourceName == 'ht_cores') {,,5,3
openstack%2Ftripleo-image-elements~master~I1129e9f8d0a5dd337eb546bb13e9fe6100d76339,openstack/tripleo-image-elements,master,I1129e9f8d0a5dd337eb546bb13e9fe6100d76339,Use --resource-registry parameter,MERGED,2014-10-03 19:03:46.000000000,2014-10-06 11:01:23.000000000,2014-10-06 11:01:23.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 7585}, {'_account_id': 8532}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-10-03 19:03:46.000000000', 'files': ['elements/tuskar/os-refresh-config/configure.d/90-tuskar-db-sync'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/60bccfa297946056a8eafb94693e503fbd156e62', 'message': 'Use --resource-registry parameter\n\nAs of I6d2f44332404fd9cab846df1256a2804dce42d70 you must now pass the\n--resource-registry parameter when using tuskar-load-roles.\n\nChange-Id: I1129e9f8d0a5dd337eb546bb13e9fe6100d76339\n'}]",0,126041,60bccfa297946056a8eafb94693e503fbd156e62,10,5,1,7144,,,0,"Use --resource-registry parameter

As of I6d2f44332404fd9cab846df1256a2804dce42d70 you must now pass the
--resource-registry parameter when using tuskar-load-roles.

Change-Id: I1129e9f8d0a5dd337eb546bb13e9fe6100d76339
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/41/126041/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/tuskar/os-refresh-config/configure.d/90-tuskar-db-sync'],1,60bccfa297946056a8eafb94693e503fbd156e62,tuskar-orc, --resource-registry $TUSKAR_ROLE_DIRECTORY/overcloud-resource-registry.yaml \,,1,0
openstack%2Fglance~master~Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6,openstack/glance,master,Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6,Refactor test_migrations module,MERGED,2014-08-29 16:49:33.000000000,2014-10-06 11:00:54.000000000,2014-10-06 11:00:53.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 706}, {'_account_id': 1736}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 9656}, {'_account_id': 11356}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-08-29 16:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8ab7c22272cee6a66aa663deb9dddf79cc347983', 'message': 'Refactor TestMigrations class\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 2, 'created': '2014-09-01 12:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e67ce4e5630a6223cded5305911d07403d3d2472', 'message': ""Refactor test_migrations module\n\n_walk_versions method exist in oslo.db test_migrations.\nRemove duplicated code from test class. Remove conf file\nas we don't need it anymore.\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n""}, {'number': 3, 'created': '2014-09-02 11:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2318ddb3a7a9b7e15291c3960d0bde6f922b682e', 'message': ""Refactor test_migrations module\n\n_walk_versions method exist in oslo.db test_migrations.\nRemove duplicated code from test class. Remove conf file\nas we don't need it anymore.\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n""}, {'number': 4, 'created': '2014-09-02 11:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6559081e62ef274ecd96ab44297cd1cf7308296d', 'message': ""Refactor test_migrations module\n\n_walk_versions method exist in oslo.db test_migrations.\nRemove duplicated code from test class. Remove conf file\nas we don't need it anymore.\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n""}, {'number': 5, 'created': '2014-09-02 13:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/618fa688f24b17d5e76e5ebf3ce012cc509d54e1', 'message': ""Refactor test_migrations module\n\n_walk_versions method exist in oslo.db test_migrations.\nRemove duplicated code from test class. Remove conf file\nas we don't need it anymore.\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n""}, {'number': 6, 'created': '2014-09-02 16:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/05bacc206f901e555d2f6f1050bf132e60673fee', 'message': ""Refactor test_migrations module\n\n_walk_versions method exist in oslo.db test_migrations.\nRemove duplicated code from test class. Remove conf file\nas we don't need it anymore.\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n""}, {'number': 7, 'created': '2014-09-11 15:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b217528e64b0f05649b11c4360e874471b4514a9', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 8, 'created': '2014-09-11 15:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b1825ce44e90683d10cffbaa6f3511b41e99a042', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 9, 'created': '2014-09-11 16:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c4e5ccdd3f6242b5d5d5b24a4634b645a68610e2', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 10, 'created': '2014-09-14 13:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2df45b1136f870ece63d9f8d339e2b67f1735cd1', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 11, 'created': '2014-09-19 10:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c3cb53566a2623833b393f59bb54b4a2f6eb554e', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 12, 'created': '2014-09-19 11:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d21d659c54cad749bd81f11ca2e881f0930c689f', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 13, 'created': '2014-09-19 16:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e72ea3392cbea5a9c9de48f7f2441ea57d472d5a', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 14, 'created': '2014-09-19 16:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cf1dd85b6916f91fce57a7ab7a4f66d667204fbb', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 15, 'created': '2014-09-23 13:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cfabceb2d7ca260bbdd1c0a10020b4b37c4c2751', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}, {'number': 16, 'created': '2014-09-30 11:32:43.000000000', 'files': ['glance/tests/unit/test_migrations.py', 'test-requirements.txt', 'glance/db/migration.py', 'glance/tests/unit/test_migrations.conf', 'glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e518ab629b9a21fe038bc4f98f559ee4479beb39', 'message': 'Refactor test_migrations module\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nPartial-Bug: #1368274\n\nChange-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6\n'}]",86,117837,e518ab629b9a21fe038bc4f98f559ee4479beb39,78,16,16,12363,,,0,"Refactor test_migrations module

Refactored migration tests to use OpportunisticTestCase, removed
unused code and ``test_migrations.conf`` file.

The main feature of this approach is to create a new database with
random name for each migration test.  This will avoid migration tests of
race conditions and reduce tests intersection. After this change, database
``openstack_citest`` will be used only for initial connection to the database.

``test_migrations.conf`` file not required anymore, because we create test
database for migration test, so we no longer need to keep database credentials.

Partial-Bug: #1368274

Change-Id: Ib1d6dfae62cc60f814c01d07adc53f68e7c234f6
",git fetch https://review.opendev.org/openstack/glance refs/changes/37/117837/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_migrations.py'],1,8ab7c22272cee6a66aa663deb9dddf79cc347983,bug/1368274,"from migrate.versioning.repository import Repository from oslo.db.sqlalchemy import test_base from oslo.db.sqlalchemy import test_migrationsclass MigrationsMixin(test_migrations.WalkVersionsMixin): @property def INIT_VERSION(self): migration.INIT_VERSION @property def REPOSITORY(self): migrate_file = glance.db.sqlalchemy.migrate_repo.__file__ return Repository(os.path.abspath(os.path.dirname(migrate_file))) @property def migration_api(self): return migration_api def migrate_engine(self): return self.engine super(MigrationsMixin, self).setUp() text_type(MigrationsMixin.CONFIG_FILE_PATH)) if os.path.exists(MigrationsMixin.CONFIG_FILE_PATH): cp.read(MigrationsMixin.CONFIG_FILE_PATH) def tearDown(self): super(MigrationsMixin, self).tearDown() self._walk_versions(self.snake_walk) self._create_unversioned_001_db(self.migrate_engine) #we must start from version 1 migration.INIT_VERSION = 1 self._walk_versions(self.snake_walk) self.addCleanup(self.set_init_version_to_0) def set_init_version_to_0(self): migration.INIT_VERSION = 0 CONF.set_override('metadata_encryption_key', metadata_encryption_key) self.addCleanup(CONF.reset) CONF.set_override('metadata_encryption_key', metadata_encryption_key) self.addCleanup(CONF.reset) class TestMysqlMigrations(test_base.MySQLOpportunisticTestCase, MigrationsMixin): def test_mysql_connect_fail(self): """""" Test that we can trigger a mysql connection failure and we fail gracefully to ensure we don't break people without mysql """""" if _is_backend_avail('mysql', user=""openstack_cifail""): self.fail(""Shouldn't have connected"") def test_mysql_opportunistically(self): self._walk_versions(False, False) connection = self.migrate_engine.connect() # sanity check total = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest'"") self.assertTrue(total.scalar() > 0, ""No tables found. Wrong schema?"") noninnodb = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest' "" ""and ENGINE!='InnoDB' "" ""and TABLE_NAME!='migrate_version'"") count = noninnodb.scalar() self.assertEqual(count, 0, ""%d non InnoDB tables created"" % count) connection.close() class TestPostgresqlMigrations(test_base.PostgreSQLOpportunisticTestCase, MigrationsMixin): def test_postgresql_connect_fail(self): """""" Test that we can trigger a postgres connection failure and we fail gracefully to ensure we don't break people without postgres """""" if _is_backend_avail('postgresql', user=""openstack_cifail""): self.fail(""Shouldn't have connected"") def test_postgresql_opportunistically(self): self._walk_versions(False, False) class TestSqliteMigrations(test_base.DbTestCase, MigrationsMixin): pass","import subprocessfrom migrate.versioning.repository import Repositoryimport six.moves.urllib.parse as urlparse from six.moves import xrangefrom glance.tests import utils as test_utils def _have_mysql(): present = os.environ.get('GLANCE_TEST_MYSQL_PRESENT') if present is None: return _is_backend_avail('mysql') return present.lower() in ('', 'true') class TestMigrations(test_utils.BaseTestCase): """"""Test sqlalchemy-migrate migrations."""""" MIGRATE_FILE = glance.db.sqlalchemy.migrate_repo.__file__ REPOSITORY = Repository(os.path.abspath(os.path.dirname(MIGRATE_FILE))) super(TestMigrations, self).setUp() self.snake_walk = False self.test_databases = {} # Load test databases from the config file. Only do this # once. No need to re-run this on each test... text_type(TestMigrations.CONFIG_FILE_PATH)) if os.path.exists(TestMigrations.CONFIG_FILE_PATH): cp.read(TestMigrations.CONFIG_FILE_PATH) defaults = cp.defaults() for key, value in defaults.items(): self.test_databases[key] = value self.engines = {} for key, value in self.test_databases.items(): self.engines[key] = sqlalchemy.create_engine(value) # We start each test case with a completely blank slate. self._reset_databases() def tearDown(self): # We destroy the test data store between each test case, # and recreate it, which ensures that we have no side-effects # from the tests self._reset_databases() super(TestMigrations, self).tearDown() def _reset_databases(self): def execute_cmd(cmd=None): proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True) output = proc.communicate()[0] LOG.debug(output) self.assertEqual(0, proc.returncode) for key, engine in self.engines.items(): conn_string = self.test_databases[key] conn_pieces = urlparse.urlparse(conn_string) engine.dispose() if conn_string.startswith('sqlite'): # We can just delete the SQLite database, which is # the easiest and cleanest solution db_path = conn_pieces.path[1:] if os.path.exists(db_path): os.unlink(db_path) # No need to recreate the SQLite DB. SQLite will # create it for us if it's not there... elif conn_string.startswith('mysql'): # We can execute the MySQL client to destroy and re-create # the MYSQL database, which is easier and less error-prone # than using SQLAlchemy to do this via MetaData...trust me. database = conn_pieces.path.strip('/') loc_pieces = conn_pieces.netloc.split('@') host = loc_pieces[1] auth_pieces = loc_pieces[0].split(':') user = auth_pieces[0] password = """" if len(auth_pieces) > 1: if auth_pieces[1].strip(): password = ""-p\""%s\"""" % auth_pieces[1] sql = (""drop database if exists %(database)s; create "" ""database %(database)s;"") % {'database': database} cmd = (""mysql -u \""%(user)s\"" %(password)s -h %(host)s "" ""-e \""%(sql)s\"""") % {'user': user, 'password': password, 'host': host, 'sql': sql} execute_cmd(cmd) elif conn_string.startswith('postgresql'): database = conn_pieces.path.strip('/') loc_pieces = conn_pieces.netloc.split('@') host = loc_pieces[1] auth_pieces = loc_pieces[0].split(':') user = auth_pieces[0] password = """" if len(auth_pieces) > 1: password = auth_pieces[1].strip() # note(boris-42): This file is used for authentication # without password prompt. createpgpass = (""echo '*:*:*:%(user)s:%(password)s' > "" ""~/.pgpass && chmod 0600 ~/.pgpass"" % {'user': user, 'password': password}) execute_cmd(createpgpass) # note(boris-42): We must create and drop database, we can't # drop database which we have connected to, so for such # operations there is a special database template1. sqlcmd = (""psql -w -U %(user)s -h %(host)s -c"" "" '%(sql)s' -d template1"") sql = (""drop database if exists %(database)s;"") sql = sql % {'database': database} droptable = sqlcmd % {'user': user, 'host': host, 'sql': sql} execute_cmd(droptable) sql = (""create database %(database)s;"") sql = sql % {'database': database} createtable = sqlcmd % {'user': user, 'host': host, 'sql': sql} execute_cmd(createtable) """""" Walks all version scripts for each tested database, ensuring that there are no errors in the version scripts for each engine """""" for key, engine in self.engines.items(): self._walk_versions(engine, self.snake_walk) def test_mysql_connect_fail(self): """""" Test that we can trigger a mysql connection failure and we fail gracefully to ensure we don't break people without mysql """""" if _is_backend_avail('mysql', user=""openstack_cifail""): self.fail(""Shouldn't have connected"") def test_mysql_opportunistically(self): # Test that table creation on mysql only builds InnoDB tables if not _is_backend_avail('mysql'): self.skipTest(""mysql not available"") # add this to the global lists to make reset work with it, it's removed # automatically in tearDown so no need to clean it up here. connect_string = _get_connect_string(""mysql"") engine = sqlalchemy.create_engine(connect_string) self.engines[""mysqlcitest""] = engine self.test_databases[""mysqlcitest""] = connect_string # build a fully populated mysql database with all the tables self._reset_databases() self._walk_versions(engine, False, False) connection = engine.connect() # sanity check total = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest'"") self.assertTrue(total.scalar() > 0, ""No tables found. Wrong schema?"") noninnodb = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest' "" ""and ENGINE!='InnoDB' "" ""and TABLE_NAME!='migrate_version'"") count = noninnodb.scalar() self.assertEqual(count, 0, ""%d non InnoDB tables created"" % count) connection.close() def test_postgresql_connect_fail(self): """""" Test that we can trigger a postgres connection failure and we fail gracefully to ensure we don't break people without postgres """""" if _is_backend_avail('postgresql', user=""openstack_cifail""): self.fail(""Shouldn't have connected"") def test_postgresql_opportunistically(self): # Test postgresql database migration walk if not _is_backend_avail('postgres'): self.skipTest(""postgresql not available"") # add this to the global lists to make reset work with it, it's removed # automatically in tearDown so no need to clean it up here. connect_string = _get_connect_string(""postgres"") engine = sqlalchemy.create_engine(connect_string) self.engines[""postgresqlcitest""] = engine self.test_databases[""postgresqlcitest""] = connect_string # build a fully populated postgresql database with all the tables self._reset_databases() self._walk_versions(engine, False, False) def _walk_versions(self, engine=None, snake_walk=False, downgrade=True, initial_version=None): # Determine latest version script from the repo, then # upgrade from 1 through to the latest, with no data # in the databases. This just checks that the schema itself # upgrades successfully. def db_version(): return migration_api.db_version(engine, TestMigrations.REPOSITORY) # Place the database under version control init_version = migration.INIT_VERSION if initial_version is not None: init_version = initial_version migration_api.version_control(engine, TestMigrations.REPOSITORY, init_version) self.assertEqual(init_version, db_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, init_version + 1) self.assertEqual(init_version + 1, db_version()) LOG.debug('latest version is %s', TestMigrations.REPOSITORY.latest) for version in xrange(init_version + 2, TestMigrations.REPOSITORY.latest + 1): # upgrade -> downgrade -> upgrade self._migrate_up(engine, version, with_data=True) if snake_walk: self._migrate_down(engine, version - 1, with_data=True) self._migrate_up(engine, version) if downgrade: # Now walk it back down to 0 from the latest, testing # the downgrade paths. for version in reversed( xrange(init_version + 2, TestMigrations.REPOSITORY.latest + 1)): # downgrade -> upgrade -> downgrade self._migrate_down(engine, version - 1) if snake_walk: self._migrate_up(engine, version) self._migrate_down(engine, version - 1) # Ensure we made it all the way back to the first migration self.assertEqual(init_version + 1, db_version()) def _migrate_down(self, engine, version, with_data=False): migration_api.downgrade(engine, TestMigrations.REPOSITORY, version) self.assertEqual(version, migration_api.db_version(engine, TestMigrations.REPOSITORY)) # NOTE(sirp): `version` is what we're downgrading to (i.e. the 'target' # version). So if we have any downgrade checks, they need to be run for # the previous (higher numbered) migration. if with_data: post_downgrade = getattr(self, ""_post_downgrade_%03d"" % (version + 1), None) if post_downgrade: post_downgrade(engine) def _migrate_up(self, engine, version, with_data=False): """"""migrate up to a new version of the db. We allow for data insertion and post checks at every migration version with special _pre_upgrade_### and _check_### functions in the main test. """""" if with_data: data = None pre_upgrade = getattr(self, ""_pre_upgrade_%3.3d"" % version, None) if pre_upgrade: data = pre_upgrade(engine) migration_api.upgrade(engine, TestMigrations.REPOSITORY, version) self.assertEqual(version, migration_api.db_version(engine, TestMigrations.REPOSITORY)) if with_data: check = getattr(self, ""_check_%3.3d"" % version, None) if check: check(engine, data) for key, engine in self.engines.items(): self._create_unversioned_001_db(engine) self._walk_versions(engine, self.snake_walk, initial_version=1) self.config(metadata_encryption_key=metadata_encryption_key) self.config(metadata_encryption_key=metadata_encryption_key)",90,276
openstack%2Ffuel-library~master~I247bdd628c9756ad26bc4471f10dd9f872744d8b,openstack/fuel-library,master,I247bdd628c9756ad26bc4471f10dd9f872744d8b,Adapt synced puppet-ceilometer for Fuel usage,MERGED,2014-06-27 11:16:49.000000000,2014-10-06 10:36:35.000000000,2014-10-06 10:36:34.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-27 11:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e7895ae9db8288943297c3b1a1c9e6fbe47e616d', 'message': 'Adapt synced puppet-ceilometer for Fuel usage (WIP)\n\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 2, 'created': '2014-06-27 11:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8d16d460126d96f4defb62d033fb866287e5a34b', 'message': 'Adapt synced puppet-ceilometer for Fuel usage (WIP)\n\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 3, 'created': '2014-09-04 16:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bcf712fcc8ab0bdaf441636cf870b875cfcf4716', 'message': 'Adapt synced puppet-ceilometer for Fuel usage (WIP)\n\nWORK IN PROGRESS. DO NOT MERGE YET.\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 4, 'created': '2014-09-25 00:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a4b650d7e49ff4b8485e67a7ae0eb89b70c20580', 'message': 'Adapt synced puppet-ceilometer for Fuel usage (WIP)\n\nWORK IN PROGRESS. DO NOT MERGE YET.\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 5, 'created': '2014-09-26 07:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ab6bf48d9e5060f8426bb892436ffa5300eeb6ab', 'message': 'Adapt synced puppet-ceilometer for Fuel usage (WIP)\n\nWORK IN PROGRESS. DO NOT MERGE YET.\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 6, 'created': '2014-10-01 09:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7c8ce51d246447b78308dd40830b7525c063092b', 'message': 'Adapt synced puppet-ceilometer for Fuel usage\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 7, 'created': '2014-10-01 12:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/55480aa3cefcb9888eea64b6c7daa4858df2e659', 'message': 'Adapt synced puppet-ceilometer for Fuel usage\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nAlso includes bugfix for ceilometer::agent::notification which\nis already in master in the upstream.\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 8, 'created': '2014-10-02 11:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/20e71f13fba3a23fb1adf394a2248d9994f406c2', 'message': 'Adapt synced puppet-ceilometer for Fuel usage\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nAlso includes bugfixes for:\n- ceilometer::agent::notification\n- ceilometer::params\n\nWhich are already included in upstream master.\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 9, 'created': '2014-10-03 12:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a208d73a8951fa66354ad19d6a134fe0b38cfb23', 'message': 'Adapt synced puppet-ceilometer for Fuel usage\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nAlso includes bugfixes for:\n- ceilometer::agent::notification\n- ceilometer::params\n\nWhich are already included in upstream master.\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}, {'number': 10, 'created': '2014-10-03 13:53:54.000000000', 'files': ['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/compute.pp', 'deployment/puppet/ceilometer/files/ocf/ceilometer-alarm-evaluator', 'deployment/puppet/ceilometer/manifests/params.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/ceilometer/files/ocf/ceilometer-agent-central', 'deployment/puppet/ceilometer/manifests/agent/notification.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9dfa1d45b6b992845d9dbd9c22e64ba8a251a180', 'message': 'Adapt synced puppet-ceilometer for Fuel usage\n\nRequires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n\nAlso includes bugfixes for:\n- ceilometer::agent::notification\n- ceilometer::params\n\nWhich are already included in upstream master.\n\nImplements: blueprint merge-openstack-puppet-modules\nChange-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b\n'}]",3,103092,9dfa1d45b6b992845d9dbd9c22e64ba8a251a180,75,7,10,11090,,,0,"Adapt synced puppet-ceilometer for Fuel usage

Requires Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e

Also includes bugfixes for:
- ceilometer::agent::notification
- ceilometer::params

Which are already included in upstream master.

Implements: blueprint merge-openstack-puppet-modules
Change-Id: I247bdd628c9756ad26bc4471f10dd9f872744d8b
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/92/103092/10 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/all.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/compute.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp']",5,e7895ae9db8288943297c3b1a1c9e6fbe47e616d,bp/merge-openstack-puppet-modules," $host = '0.0.0.0', $port = '8777', rabbit_host => $amqp_hosts, rabbit_userid => $amqp_user, rabbit_password => $amqp_password, log_facility => $syslog_log_facility, host => $host, port => $port, class { '::ceilometer::agent::central': } evaluation_interval => 600, #class { '::ceilometer::agent_notification': # use_neutron => $use_neutron, # swift => $swift, #} if $ha_mode { $res_name = ""p_${::ceilometer::params::agent_central_service_name}"" Package['pacemaker'] -> File['ceilometer-agent-central-ocf'] Package['ceilometer-common'] -> File['ceilometer-agent-central-ocf'] Package['ceilometer-agent-central'] -> File['ceilometer-agent-central-ocf'] file {'ceilometer-agent-central-ocf': path =>'/usr/lib/ocf/resource.d/mirantis/ceilometer-agent-central', mode => '0755', owner => root, group => root, source => 'puppet:///modules/ceilometer/ocf/ceilometer-agent-central', } if $primary_controller { cs_resource { $res_name: ensure => present, primitive_class => 'ocf', provided_by => 'mirantis', primitive_type => 'ceilometer-agent-central', metadata => { 'target-role' => 'stopped', 'resource-stickiness' => '1' }, parameters => { 'user' => 'ceilometer' }, operations => { 'monitor' => { 'interval' => '20', 'timeout' => '30' }, 'start' => { 'timeout' => '360' }, 'stop' => { 'timeout' => '360' } }, } File['ceilometer-agent-central-ocf'] -> Cs_resource[$res_name] -> Service['ceilometer-agent-central'] } else { File['ceilometer-agent-central-ocf'] -> Service['ceilometer-agent-central'] } } else { Package['ceilometer-common'] -> Service['ceilometer-agent-central'] Package['ceilometer-agent-central'] -> Service['ceilometer-agent-central'] } } if $ha_mode { $res_name = ""p_${::ceilometer::params::alarm_evaluator_service}"" Package['ceilometer-common'] -> File['ceilometer-alarm-evaluator-ocf'] Package[$::ceilometer::params::alarm_package] -> File['ceilometer-alarm-evaluator-ocf'] Package['pacemaker'] -> File['ceilometer-alarm-evaluator-ocf'] file {'ceilometer-alarm-evaluator-ocf': path =>'/usr/lib/ocf/resource.d/mirantis/ceilometer-alarm-evaluator', mode => '0755', owner => root, group => root, source => 'puppet:///modules/ceilometer/ocf/ceilometer-alarm-evaluator', } if $primary_controller { cs_resource { $res_name: ensure => present, primitive_class => 'ocf', provided_by => 'mirantis', primitive_type => 'ceilometer-alarm-evaluator', metadata => { 'target-role' => 'stopped' }, parameters => { 'user' => 'ceilometer' }, operations => { 'monitor' => { 'interval' => '20', 'timeout' => '30' } , 'start' => { 'timeout' => '360' } , 'stop' => { 'timeout' => '360' } }, } File['ceilometer-alarm-evaluator-ocf'] -> Cs_resource[$res_name] -> Service['ceilometer-alarm-evaluator'] } Cs_resource[$res_name] -> Service['ceilometer-alarm-evaluator'] } else { } Package<| title == $::ceilometer::params::alarm_package or title == 'ceilometer-common'|> ~> Service<| title == 'ceilometer-alarm-evaluator'|> if !defined(Service['ceilometer-alarm-evaluator']) { notify{ ""Module ${module_name} cannot notify service ceilometer-alarm-evaluator\ on packages update"": } }"," $queue_provider = 'rabbitmq', $bind_host = '0.0.0.0', $bind_port = '8777', queue_provider => $queue_provider, amqp_hosts => $amqp_hosts, amqp_user => $amqp_user, amqp_password => $amqp_password, rabbit_ha_queues => $rabbit_ha_queues, syslog_log_facility => $syslog_log_facility, bind_host => $bind_host, bind_port => $bind_port, class { '::ceilometer::agent::central': auth_host => $keystone_host, auth_password => $keystone_password, ha_mode => $ha_mode, primary_controller => $primary_controller } eval_interval => 600, ha_mode => $ha_mode, primary_controller => $primary_controller class { '::ceilometer::agent_notification': use_neutron => $use_neutron, swift => $swift, } } ",140,138
openstack%2Ffuel-library~master~Ifa403d8066ede566dddbf49d67308c080b97ea77,openstack/fuel-library,master,Ifa403d8066ede566dddbf49d67308c080b97ea77,Sync puppet-ceilometer,MERGED,2014-06-27 10:23:19.000000000,2014-10-06 10:36:28.000000000,2014-10-06 10:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-27 10:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0a9f3b29d364ce9ccfa62044ccaeacc0a317bbb6', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 2, 'created': '2014-07-14 10:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c060b33edb16496f5258e1e2c09b316973618c1c', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2014-09-04 16:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ab7bb1a6d88e3cafcf3b20404a403f571dffd084', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 4, 'created': '2014-09-25 00:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8be150c1fdd06413301a9bbf85c4e6f1d14db645', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 5, 'created': '2014-09-26 07:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7d2846bdfa3e67614e413a2c8691835e2506dfca', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 6, 'created': '2014-10-01 09:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/54e2aa284253976984a32d1dca9387db960ca6d0', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 7, 'created': '2014-10-01 12:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6bcb1a424f37cbd7be0d8a52d265a88dea7e4912', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 8, 'created': '2014-10-02 11:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1aa331ee37a415906d8cb442ff4246e3845e329c', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 9, 'created': '2014-10-03 12:48:57.000000000', 'files': ['deployment/puppet/ceilometer/spec/classes/ceilometer_agent_central_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_client_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_expirer_spec.rb', 'deployment/puppet/ceilometer/manifests/db/mysql/host_access.pp', 'deployment/puppet/ceilometer/Modulefile', 'deployment/puppet/ceilometer/manifests/api.pp', 'deployment/puppet/ceilometer/.gitignore', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_notification_spec.rb', 'deployment/puppet/ceilometer/README', 'deployment/puppet/ceilometer/manifests/agent/auth.pp', 'deployment/puppet/ceilometer/Rakefile', 'deployment/puppet/ceilometer/manifests/alarm/notifier.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_alarm_notifier_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_collector_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_db_mysql_spec.rb', 'deployment/puppet/ceilometer/manifests/expirer.pp', 'deployment/puppet/ceilometer/lib/puppet/provider/ceilometer_config/ini_setting.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_auth_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_alarm_evaluator_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_config_spec.rb', 'deployment/puppet/ceilometer/manifests/collector.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_db_spec.rb', 'deployment/puppet/ceilometer/.fixtures.yml', 'deployment/puppet/ceilometer/manifests/params.pp', 'deployment/puppet/ceilometer/manifests/agent/central.pp', 'deployment/puppet/ceilometer/manifests/agent/notification.pp', 'deployment/puppet/ceilometer/manifests/agent/compute.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_compute_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_api_spec.rb', 'deployment/puppet/ceilometer/examples/site.pp', 'deployment/puppet/ceilometer/manifests/keystone/auth.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_init_spec.rb', 'deployment/puppet/ceilometer/files/ocf/ceilometer-alarm-evaluator', 'deployment/puppet/ceilometer/lib/puppet/provider/file_line_after/ruby.rb', 'deployment/puppet/ceilometer/manifests/alarm/evaluator.pp', 'deployment/puppet/ceilometer/manifests/config.pp', 'deployment/puppet/ceilometer/Gemfile', 'deployment/puppet/ceilometer/manifests/agent_notification.pp', 'deployment/puppet/ceilometer/README.md', 'deployment/puppet/ceilometer/manifests/init.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_keystone_auth_spec.rb', 'deployment/puppet/ceilometer/lib/puppet/type/file_line_after.rb', 'deployment/puppet/ceilometer/files/ocf/ceilometer-agent-central', 'deployment/puppet/ceilometer/manifests/db/mysql.pp', 'deployment/puppet/ceilometer/manifests/db.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5e9c27865270d751e78af5f2e72864b59f7642d9', 'message': 'Sync puppet-ceilometer\n\n4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327\n\nChange-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77\nImplements: blueprint merge-openstack-puppet-modules\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,103078,5e9c27865270d751e78af5f2e72864b59f7642d9,64,6,9,11090,,,0,"Sync puppet-ceilometer

4.0.0 b231c9681d476a05f437f828b95870ab4cbc4327

Change-Id: Ifa403d8066ede566dddbf49d67308c080b97ea77
Implements: blueprint merge-openstack-puppet-modules
Signed-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/78/103078/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/ceilometer/spec/classes/ceilometer_agent_central_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_client_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_expirer_spec.rb', 'deployment/puppet/ceilometer/manifests/db/mysql/host_access.pp', 'deployment/puppet/ceilometer/Modulefile', 'deployment/puppet/ceilometer/manifests/api.pp', 'deployment/puppet/ceilometer/.gitignore', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_notification_spec.rb', 'deployment/puppet/ceilometer/README', 'deployment/puppet/ceilometer/manifests/agent/auth.pp', 'deployment/puppet/ceilometer/Rakefile', 'deployment/puppet/ceilometer/manifests/alarm/notifier.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_alarm_notifier_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_collector_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_db_mysql_spec.rb', 'deployment/puppet/ceilometer/manifests/expirer.pp', 'deployment/puppet/ceilometer/lib/puppet/provider/ceilometer_config/ini_setting.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_auth_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_alarm_evaluator_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_config_spec.rb', 'deployment/puppet/ceilometer/manifests/collector.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_db_spec.rb', 'deployment/puppet/ceilometer/.fixtures.yml', 'deployment/puppet/ceilometer/manifests/params.pp', 'deployment/puppet/ceilometer/manifests/agent/central.pp', 'deployment/puppet/ceilometer/manifests/agent/notification.pp', 'deployment/puppet/ceilometer/manifests/agent/compute.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_agent_compute_spec.rb', 'deployment/puppet/ceilometer/spec/classes/ceilometer_api_spec.rb', 'deployment/puppet/ceilometer/examples/site.pp', 'deployment/puppet/ceilometer/manifests/keystone/auth.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_init_spec.rb', 'deployment/puppet/ceilometer/files/ocf/ceilometer-alarm-evaluator', 'deployment/puppet/ceilometer/lib/puppet/provider/file_line_after/ruby.rb', 'deployment/puppet/ceilometer/manifests/alarm/evaluator.pp', 'deployment/puppet/ceilometer/manifests/config.pp', 'deployment/puppet/ceilometer/Gemfile', 'deployment/puppet/ceilometer/manifests/agent_notification.pp', 'deployment/puppet/ceilometer/README.md', 'deployment/puppet/ceilometer/manifests/init.pp', 'deployment/puppet/ceilometer/spec/classes/ceilometer_keystone_auth_spec.rb', 'deployment/puppet/ceilometer/lib/puppet/type/file_line_after.rb', 'deployment/puppet/ceilometer/files/ocf/ceilometer-agent-central', 'deployment/puppet/ceilometer/manifests/db/mysql.pp', 'deployment/puppet/ceilometer/manifests/db.pp']",45,0a9f3b29d364ce9ccfa62044ccaeacc0a317bbb6,bp/merge-openstack-puppet-modules,"# [*sync_db*] # enable dbsync. # # [*mysql_module*] # (optional) Mysql puppet module version to use. Tested versions # are 0.9 and 2.2 # Defaults to '0.9 # $database_connection = 'mysql://ceilometer:ceilometer@localhost/ceilometer', $sync_db = true, $mysql_module = '0.9', '(sqlite|mysql|postgresql|mongodb):\/\/(\S+:\S+@\S+\/\S+)?') if ($mysql_module >= 2.2) { include mysql::bindings::python } else { include mysql::python } $backend_package = $::ceilometer::params::psycopg_package_name $backend_package = $::ceilometer::params::pymongo_package_name $backend_package = $::ceilometer::params::sqlite_package_name if $sync_db { $command = $::ceilometer::params::dbsync_command } else { $command = '/bin/true' } command => $command, user => $::ceilometer::params::user,"," $database_connection = 'mysql://ceilometer:ceilometer@localhost/ceilometer' '(sqlite|mysql|posgres|mongodb):\/\/(\S+:\S+@\S+\/\S+)?') include mysql::python $backend_package = 'python-psycopg2' $backend_package = 'python-pymongo' $backend_package = 'python-pysqlite2' 'database/max_retries': value => ""-1""; command => $::ceilometer::params::dbsync_command, user => $::ceilometer::params::username,",2161,1375
openstack%2Ffuel-library~master~Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e,openstack/fuel-library,master,Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e,Sync inifile with upstream,MERGED,2014-09-04 14:25:38.000000000,2014-10-06 10:35:49.000000000,2014-10-06 10:35:49.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-04 14:25:38.000000000', 'files': ['deployment/puppet/inifile/lib/puppet/util/ini_file/section.rb', 'deployment/puppet/inifile/spec/acceptance/ini_subsetting_spec.rb', 'deployment/puppet/inifile/spec/spec_helper_acceptance.rb', 'deployment/puppet/inifile/README.markdown', 'deployment/puppet/inifile/spec/acceptance/nodesets/default.yml', 'deployment/puppet/inifile/Gemfile', 'deployment/puppet/inifile/spec/unit/puppet/util/ini_file_spec.rb', 'deployment/puppet/inifile/CHANGELOG.md', 'deployment/puppet/inifile/Rakefile', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-10044-x64.yml', 'deployment/puppet/inifile/.project', 'deployment/puppet/inifile/spec/acceptance/nodesets/fedora-18-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/inifile/.travis.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2012r2-x86_64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-510-x64.yml', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_setting/inheritance_spec.rb', 'deployment/puppet/inifile/spec/spec.opts', 'deployment/puppet/inifile/spec/acceptance/nodesets/debian-607-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-64-x64-pe.yml', 'deployment/puppet/inifile/spec/unit/puppet/util/setting_value_spec.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-12042-x64.yml', 'deployment/puppet/inifile/lib/puppet/util/setting_value.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/inifile/spec/classes/inherit_test1_spec.rb', 'deployment/puppet/inifile/CHANGELOG', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2003-i386.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/sles-11sp1-x64.yml', 'deployment/puppet/inifile/spec/spec_helper.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2008r2-x86_64.yml', 'deployment/puppet/inifile/.sync.yml', 'deployment/puppet/inifile/spec/acceptance/ini_setting_spec.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2008-x86_64.yml', 'deployment/puppet/inifile/CONTRIBUTING.md', 'deployment/puppet/inifile/.gitignore', 'deployment/puppet/inifile/lib/puppet/provider/ini_setting/ruby.rb', 'deployment/puppet/inifile/tests/ini_setting.pp', 'deployment/puppet/inifile/tests/ini_subsetting.pp', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_subsetting/ruby_spec.rb', 'deployment/puppet/inifile/lib/puppet/provider/ini_subsetting/ruby.rb', 'deployment/puppet/inifile/lib/puppet/util/ini_file.rb', 'deployment/puppet/inifile/.fixtures.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_setting/ruby_spec.rb', 'deployment/puppet/inifile/lib/puppet/type/ini_subsetting.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/debian-73-x64.yml', 'deployment/puppet/inifile/Modulefile', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2012-x86_64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2003r2-x86_64.yml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/81e85f07663759ccce7babc91f8af15b3dcb2f50', 'message': 'Sync inifile with upstream\n\nv1.1.3 41e2ddbc1cd861247e57d16b778cbe891602f509\nPartial blueprint merge-openstack-puppet-modules\n\nChange-Id: Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e\n'}]",0,119076,81e85f07663759ccce7babc91f8af15b3dcb2f50,11,4,1,9387,,,0,"Sync inifile with upstream

v1.1.3 41e2ddbc1cd861247e57d16b778cbe891602f509
Partial blueprint merge-openstack-puppet-modules

Change-Id: Idd6b512a4adafc31cd0c80ccf0ca59a18b43d98e
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/76/119076/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/inifile/lib/puppet/util/ini_file/section.rb', 'deployment/puppet/inifile/spec/acceptance/ini_subsetting_spec.rb', 'deployment/puppet/inifile/spec/spec_helper_acceptance.rb', 'deployment/puppet/inifile/README.markdown', 'deployment/puppet/inifile/spec/acceptance/nodesets/default.yml', 'deployment/puppet/inifile/Gemfile', 'deployment/puppet/inifile/spec/unit/puppet/util/ini_file_spec.rb', 'deployment/puppet/inifile/CHANGELOG.md', 'deployment/puppet/inifile/Rakefile', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-10044-x64.yml', 'deployment/puppet/inifile/.project', 'deployment/puppet/inifile/spec/acceptance/nodesets/fedora-18-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/inifile/.travis.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2012r2-x86_64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-510-x64.yml', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_setting/inheritance_spec.rb', 'deployment/puppet/inifile/spec/spec.opts', 'deployment/puppet/inifile/spec/acceptance/nodesets/debian-607-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-64-x64-pe.yml', 'deployment/puppet/inifile/spec/unit/puppet/util/setting_value_spec.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/ubuntu-server-12042-x64.yml', 'deployment/puppet/inifile/lib/puppet/util/setting_value.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/inifile/spec/classes/inherit_test1_spec.rb', 'deployment/puppet/inifile/CHANGELOG', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2003-i386.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/sles-11sp1-x64.yml', 'deployment/puppet/inifile/spec/spec_helper.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2008r2-x86_64.yml', 'deployment/puppet/inifile/.sync.yml', 'deployment/puppet/inifile/spec/acceptance/ini_setting_spec.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2008-x86_64.yml', 'deployment/puppet/inifile/CONTRIBUTING.md', 'deployment/puppet/inifile/.gitignore', 'deployment/puppet/inifile/lib/puppet/provider/ini_setting/ruby.rb', 'deployment/puppet/inifile/tests/ini_setting.pp', 'deployment/puppet/inifile/tests/ini_subsetting.pp', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_subsetting/ruby_spec.rb', 'deployment/puppet/inifile/lib/puppet/provider/ini_subsetting/ruby.rb', 'deployment/puppet/inifile/lib/puppet/util/ini_file.rb', 'deployment/puppet/inifile/.fixtures.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/inifile/spec/unit/puppet/provider/ini_setting/ruby_spec.rb', 'deployment/puppet/inifile/lib/puppet/type/ini_subsetting.rb', 'deployment/puppet/inifile/spec/acceptance/nodesets/debian-73-x64.yml', 'deployment/puppet/inifile/Modulefile', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2012-x86_64.yml', 'deployment/puppet/inifile/spec/acceptance/nodesets/windows-2003r2-x86_64.yml']",50,81e85f07663759ccce7babc91f8af15b3dcb2f50,bp/merge-openstack-puppet-modules,HOSTS: ubuntu1204: roles: - master - database - dashboard platform: ubuntu-12.04-amd64 template: ubuntu-1204-x86_64 hypervisor: vcloud win2003r2_x86_64: roles: - agent - default platform: windows-2003r2-x86_64 template: win-2003r2-x86_64 hypervisor: vcloud CONFIG: nfs_server: none consoleport: 443 datastore: instance0 folder: Delivery/Quality Assurance/Enterprise/Dynamic resourcepool: delivery/Quality Assurance/Enterprise/Dynamic pooling_api: http://vcloud.delivery.puppetlabs.net/ pe_dir: http://neptune.puppetlabs.lan/3.3/ci-ready/ ,,2444,157
openstack%2Fdiskimage-builder~master~I00fff354d6c931ad67cf3052d055f0e4604dfdc8,openstack/diskimage-builder,master,I00fff354d6c931ad67cf3052d055f0e4604dfdc8,Use DIB_IMAGE_CACHE everywhere,MERGED,2014-10-05 20:59:06.000000000,2014-10-06 10:23:02.000000000,2014-10-06 10:23:01.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}]","[{'number': 1, 'created': '2014-10-05 20:59:06.000000000', 'files': ['elements/zypper/root.d/50-zypper-cache', 'elements/pypi/extra-data.d/00-mount-pypi-mirror', 'elements/pip-cache/root.d/01-pip-cache', 'elements/yum/root.d/50-yum-cache', 'elements/base/root.d/01-ccache', 'elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3acc866f6da1a6c2a708d6e1ab76b2ac30b7ca83', 'message': 'Use DIB_IMAGE_CACHE everywhere\n\ndisk-image-create processes a DIB_IMAGE_CACHE variable and exports it,\nbut there are several elements that ignore the value and wrote out\nthe base location themselves. Use the variable everywhere so that it\nwill get overridden everywhere.\n\nChange-Id: I00fff354d6c931ad67cf3052d055f0e4604dfdc8\n'}]",0,126201,3acc866f6da1a6c2a708d6e1ab76b2ac30b7ca83,8,3,1,2,,,0,"Use DIB_IMAGE_CACHE everywhere

disk-image-create processes a DIB_IMAGE_CACHE variable and exports it,
but there are several elements that ignore the value and wrote out
the base location themselves. Use the variable everywhere so that it
will get overridden everywhere.

Change-Id: I00fff354d6c931ad67cf3052d055f0e4604dfdc8
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/01/126201/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/zypper/root.d/50-zypper-cache', 'elements/pypi/extra-data.d/00-mount-pypi-mirror', 'elements/pip-cache/root.d/01-pip-cache', 'elements/yum/root.d/50-yum-cache', 'elements/base/root.d/01-ccache', 'elements/source-repositories/extra-data.d/98-source-repositories']",6,3acc866f6da1a6c2a708d6e1ab76b2ac30b7ca83,,CACHE_BASE=$DIB_IMAGE_CACHE/source-repositories OLD_CACHE_BASE=$DIB_IMAGE_CACHE/repository-sources,CACHE_BASE=~/.cache/image-create/source-repositories OLD_CACHE_BASE=~/.cache/image-create/repository-sources,7,7
openstack%2Fneutron~stable%2Fhavana~I889a2c2fdecc5d6f57c5b2cecb9bf017d0d36a5c,openstack/neutron,stable/havana,I889a2c2fdecc5d6f57c5b2cecb9bf017d0d36a5c,NSX plugin security group rules summarization,ABANDONED,2014-10-03 02:05:27.000000000,2014-10-06 10:20:44.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10461}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-03 02:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/714053e87c801f1915e1f3b352f3edad7195f231', 'message': 'NSX plugin security group rules summarization\n\nSummarize the security group rules before creating the rules in NSX\ncontroller. This fix removes duplicate and redundant rules to yield\nsame or smaller set of rules that enforces the same security\npolicies on the hypervisors and reduce the NSX control cluster\nmemory consumption.\n\nChange-Id: I889a2c2fdecc5d6f57c5b2cecb9bf017d0d36a5c\nCloses-Bug: 1376981\n'}, {'number': 2, 'created': '2014-10-03 02:41:53.000000000', 'files': ['neutron/plugins/nicira/nvplib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24f108ca96201e88d3f7c3bbc3f2368f8c3e0eeb', 'message': 'NSX plugin security group rules summarization\n\nSummarize the security group rules before creating the rules in NSX\ncontroller. This fix removes duplicate and redundant rules to yield\nsame or smaller set of rules that enforces the same security\npolicies on the hypervisors and reduce the NSX control cluster\nmemory consumption.\n\nChange-Id: I889a2c2fdecc5d6f57c5b2cecb9bf017d0d36a5c\nCloses-Bug: 1376981\n'}]",8,125851,24f108ca96201e88d3f7c3bbc3f2368f8c3e0eeb,26,11,2,10461,,,0,"NSX plugin security group rules summarization

Summarize the security group rules before creating the rules in NSX
controller. This fix removes duplicate and redundant rules to yield
same or smaller set of rules that enforces the same security
policies on the hypervisors and reduce the NSX control cluster
memory consumption.

Change-Id: I889a2c2fdecc5d6f57c5b2cecb9bf017d0d36a5c
Closes-Bug: 1376981
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/125851/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/nicira/nvplib.py'],1,714053e87c801f1915e1f3b352f3edad7195f231,bug/1376981," logical_port_ingress_rules=summarize_security_group_rules(rules[ 'logical_port_ingress_rules']), logical_port_egress_rules=summarize_security_group_rules(rules[ 'logical_port_egress_rules']))def summarize_security_group_rules(logical_port_rules): """""" Summarizes security group rules and remove duplicates """""" # Pass 1: Remove port_range_min & port_range_max if port_range_min=1 & # port_range_max=65535, ip_prefix if it is 0.0.0.0/0 for rule in logical_port_rules: if 'port_range_min' in rule and 'port_range_max' in rule and \ rule['port_range_min'] == 1 and \ rule['port_range_max'] == 65535: del rule['port_range_min'] del rule['port_range_max'] if 'ip_prefix' in rule and rule['ip_prefix'] == '0.0.0.0/0': del rule['ip_prefix'] # Pass 2: If there are TCP, UDP, ICMP rules, then replace the 3 rules # with a single rule for ethertype in ['IPv4', 'IPv6']: allow_all_rules = [ {'ethertype': ethertype, 'protocol': constants.PROTO_NUM_TCP}, {'ethertype': ethertype, 'protocol': constants.PROTO_NUM_UDP}, {'ethertype': ethertype, 'protocol': constants.PROTO_NUM_ICMP} ] if not len([rule for rule in allow_all_rules if rule not in logical_port_rules]): for rule in allow_all_rules: logical_port_rules.remove(rule) logical_port_rules.append({'ethertype': ethertype}) # Final Pass: Remove duplicates after all the rule substitutions. Loop # through each rule and determine if it is part of another rule, if so, # drop the rule logical_port_rules_summarized = [] for i in range(len(logical_port_rules)): include_rule_i = True for j in range(len(logical_port_rules)): if i == j: continue if is_sg_rule_subset(logical_port_rules[i], logical_port_rules[j]): include_rule_i = False break if include_rule_i: logical_port_rules_summarized.append(logical_port_rules[i]) return logical_port_rules_summarized def is_sg_rule_subset(sgr1, sgr2): """""" determine if security group rule sgr1 is a subset of sgr2 """""" all_protocols = set([constants.PROTO_NUM_TCP, constants.PROTO_NUM_UDP, constants.PROTO_NUM_ICMP]) sgr1_protocols = {sgr1['protocol']} if 'protocol' in sgr1 else all_protocols sgr2_protocols = {sgr2['protocol']} if 'protocol' in sgr2 else all_protocols sgr1_profile_uuid = sgr1.get('profile_uuid', None) sgr2_profile_uuid = sgr2.get('profile_uuid', None) return \ sgr1['ethertype'] == sgr2['ethertype'] and \ sgr1_protocols.issubset(sgr2_protocols) and \ sgr1.get('port_range_min', 1L) >= sgr2.get('port_range_min', 1L) and \ sgr1.get('port_range_max', 65535L) <= sgr2.get('port_range_max', 65535L) and \ sgr1.get('remote_ip_prefix', None) == sgr2.get('remote_ip_prefix', None) and \ (sgr2_profile_uuid is None or sgr1_profile_uuid == sgr2_profile_uuid) "," logical_port_ingress_rules=rules['logical_port_ingress_rules'], logical_port_egress_rules=rules['logical_port_egress_rules'])",76,2
openstack%2Fneutron~master~Iac6ddbba56657205a7eafef3f6b5bad5927c1323,openstack/neutron,master,Iac6ddbba56657205a7eafef3f6b5bad5927c1323,Radware LBaaS v2 driver,ABANDONED,2014-08-12 13:46:55.000000000,2014-10-06 10:16:57.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6447}, {'_account_id': 8446}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-08-12 13:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c14fb4ef0d46cdeccf7ea75ff6ba6170a5d26e8', 'message': 'Radware LBaaS v2 driver\n\nThis is a WIP\n\nChange-Id: Iac6ddbba56657205a7eafef3f6b5bad5927c1323\nImplements: blueprint radware-lbaas-driver\n'}, {'number': 2, 'created': '2014-09-02 14:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f79ff44d68d71bdb1129cac4b3e3a32b0c88dda5', 'message': 'Radware LBaaS v2 driver\n\nThis is a WIP\n\nChange-Id: Iac6ddbba56657205a7eafef3f6b5bad5927c1323\nImplements: blueprint radware-lbaas-driver\nCo-authored-by: Avishay Balderman <avishayb@radware.com>\nCo-authored-by: Evgeny Fedoruk <evgenyf@radware.com>\n'}, {'number': 3, 'created': '2014-09-22 08:13:32.000000000', 'files': ['neutron/services/loadbalancer/drivers/radware/v2/driver.py', 'neutron/services/loadbalancer/drivers/radware/v2/radware_lbass.py', 'neutron/services/loadbalancer/drivers/radware/v2/__init__.py', 'etc/services.conf', 'neutron/services/loadbalancer/drivers/radware/v2/rest_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/908855c539b39976de4aa3ce3cb613bf4a5ca7ab', 'message': 'Radware LBaaS v2 driver\n\nThis is a WIP\n\nChange-Id: Iac6ddbba56657205a7eafef3f6b5bad5927c1323\nImplements: blueprint radware-lbaas-driver\nCo-authored-by: Avishay Balderman <avishayb@radware.com>\nCo-authored-by: Evgeny Fedoruk <evgenyf@radware.com>\n'}]",0,113525,908855c539b39976de4aa3ce3cb613bf4a5ca7ab,55,22,3,6447,,,0,"Radware LBaaS v2 driver

This is a WIP

Change-Id: Iac6ddbba56657205a7eafef3f6b5bad5927c1323
Implements: blueprint radware-lbaas-driver
Co-authored-by: Avishay Balderman <avishayb@radware.com>
Co-authored-by: Evgeny Fedoruk <evgenyf@radware.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/113525/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/radware/v2/driver.py', 'neutron/services/loadbalancer/drivers/radware/v2/radware_lbass.py', 'neutron/services/loadbalancer/drivers/radware/v2/__init__.py', 'neutron/services/loadbalancer/drivers/radware/v2/rest_client.py']",4,2c14fb4ef0d46cdeccf7ea75ff6ba6170a5d26e8,bp/radware-lbaas-driver,"import base64 import httplib from neutron.common import log as call_log from neutron.openstack.common import log as logging from neutron.openstack.common import jsonutils as json LOG = logging.getLogger(__name__) RESP_STATUS = 0 RESP_REASON = 1 RESP_STR = 2 RESP_DATA = 3 class vDirectRESTClient: """"""REST server proxy to Radware vDirect."""""" @call_log.log def __init__(self, server='localhost', secondary_server=None, user=None, password=None, port=2189, ssl=True, timeout=5000, base_uri=''): self.server = server self.secondary_server = secondary_server self.port = port self.ssl = ssl self.base_uri = base_uri self.timeout = timeout if user and password: self.auth = base64.encodestring('%s:%s' % (user, password)) self.auth = self.auth.replace('\n', '') else: raise r_exc.AuthenticationMissing() debug_params = {'server': self.server, 'sec_server': self.secondary_server, 'port': self.port, 'ssl': self.ssl} LOG.debug(_('vDirectRESTClient:init server=%(server)s, ' 'secondary server=%(sec_server)s, ' 'port=%(port)d, ' 'ssl=%(ssl)r'), debug_params) def _flip_servers(self): LOG.warning(_('Fliping servers. Current is: %(server)s, ' 'switching to %(secondary)s'), {'server': self.server, 'secondary': self.secondary_server}) self.server, self.secondary_server = self.secondary_server, self.server def _recover(self, action, resource, data, headers, binary=False): if self.server and self.secondary_server: self._flip_servers() resp = self._call(action, resource, data, headers, binary) return resp else: LOG.exception(_('REST client is not able to recover ' 'since only one vDirect server is ' 'configured.')) return -1, None, None, None def call(self, action, resource, data, headers, binary=False): resp = self._call(action, resource, data, headers, binary) if resp[RESP_STATUS] == -1: LOG.warning(_('vDirect server is not responding (%s).'), self.server) return self._recover(action, resource, data, headers, binary) elif resp[RESP_STATUS] in (301, 307): LOG.warning(_('vDirect server is not active (%s).'), self.server) return self._recover(action, resource, data, headers, binary) else: return resp @call_log.log def _call(self, action, resource, data, headers, binary=False): if resource.startswith('http'): uri = resource else: uri = self.base_uri + resource if binary: body = data else: body = json.dumps(data) debug_data = 'binary' if binary else body debug_data = debug_data if debug_data else 'EMPTY' if not headers: headers = {'Authorization': 'Basic %s' % self.auth} else: headers['Authorization'] = 'Basic %s' % self.auth conn = None if self.ssl: conn = httplib.HTTPSConnection( self.server, self.port, timeout=self.timeout) if conn is None: LOG.error(_('vdirectRESTClient: Could not establish HTTPS ' 'connection')) return 0, None, None, None else: conn = httplib.HTTPConnection( self.server, self.port, timeout=self.timeout) if conn is None: LOG.error(_('vdirectRESTClient: Could not establish HTTP ' 'connection')) return 0, None, None, None try: conn.request(action, uri, body, headers) response = conn.getresponse() respstr = response.read() respdata = respstr try: respdata = json.loads(respstr) except ValueError: # response was not JSON, ignore the exception pass ret = (response.status, response.reason, respstr, respdata) except Exception as e: log_dict = {'action': action, 'e': e} LOG.error(_('vdirectRESTClient: %(action)s failure, %(e)r'), log_dict) ret = -1, None, None, None conn.close() return ret ",,816,0
openstack%2Fcloudkitty~master~Id110aa817a680cc02c882ea24f275eb127a738a8,openstack/cloudkitty,master,Id110aa817a680cc02c882ea24f275eb127a738a8,Add tests for the DB state manager,MERGED,2014-09-26 13:34:54.000000000,2014-10-06 10:11:17.000000000,2014-10-06 10:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-09-26 13:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/04887715f6591f957ff5e0b68d530cedeeb793b7', 'message': 'Add tests for the DB state manager\n\nThis patch also defines a testcase base class which handles the database\nconnection setup.\n\nChange-Id: Id110aa817a680cc02c882ea24f275eb127a738a8\n'}, {'number': 2, 'created': '2014-09-26 15:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/3d68929dc7bd040b32e992e108f15290ab7c1551', 'message': 'Add tests for the DB state manager\n\nThis patch also defines a testcase base class which handles the database\nconnection setup.\n\nFix the format() calls for python 2.6.\n\nAdd eventlet requirement.\n\nChange-Id: Id110aa817a680cc02c882ea24f275eb127a738a8\n'}, {'number': 3, 'created': '2014-09-26 16:46:53.000000000', 'files': ['cloudkitty/state.py', 'requirements.txt', 'cloudkitty/tests/test_state.py', 'test-requirements.txt', 'cloudkitty/tests/__init__.py', 'cloudkitty/tests/test_fake.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/4a67f8106807a13f0f7c075ef8e00afd034ce703', 'message': 'Add tests for the DB state manager\n\nThis patch also defines a testcase base class which handles the database\nconnection setup.\n\nFix the format() calls for python 2.6.\n\nAdd eventlet requirement.\n\nChange-Id: Id110aa817a680cc02c882ea24f275eb127a738a8\n'}]",0,124397,4a67f8106807a13f0f7c075ef8e00afd034ce703,10,2,3,7923,,,0,"Add tests for the DB state manager

This patch also defines a testcase base class which handles the database
connection setup.

Fix the format() calls for python 2.6.

Add eventlet requirement.

Change-Id: Id110aa817a680cc02c882ea24f275eb127a738a8
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/97/124397/2 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/tests/__init__.py', 'cloudkitty/tests/test_state.py', 'test-requirements.txt', 'cloudkitty/tests/test_fake.py']",4,04887715f6591f957ff5e0b68d530cedeeb793b7,state-tests,,import testtools class FakeTest(testtools.TestCase): def test_foo(self): pass ,82,6
openstack%2Fpython-neutronclient~master~I8b03fa5839fb9d8dc6e2a1512b184b26e8619233,openstack/python-neutronclient,master,I8b03fa5839fb9d8dc6e2a1512b184b26e8619233,Migration to hacking 0.9.2 (first patch),ABANDONED,2014-10-03 16:07:53.000000000,2014-10-06 10:07:29.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 7505}]","[{'number': 1, 'created': '2014-10-03 16:07:53.000000000', 'files': ['neutronclient/client.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e10c60478e60122e39a3387189a02a39a8fb1278', 'message': ""Migration to hacking 0.9.2 (first patch)\n\nWhereas Neutron uses hacking 0.9.2, python-neutronclient still uses\n0.8.1 and a lot of code convention violations raise if you use a system\nwide 'hacking' installed because the number of checks is much bigger\nwith the last release of the library.\n\nInstead of modify the test-requirements.txt and let them raise (that\nwould block other's patches because Zuul gates would fail hereinafter),\na slow and steady bunch of patches will be proposed to modify these\nchuncks of code and have a smooth transition from 0.8.1 to 0.9.2.\n\nIn this one, docstrings have been converted in common comments due the\nimpossibility to convert them into proper docstring conventions. Some of\nthem have changes to maintain code coherency into the class.\n\nChange-Id: I8b03fa5839fb9d8dc6e2a1512b184b26e8619233\n""}]",0,126002,e10c60478e60122e39a3387189a02a39a8fb1278,6,3,1,7505,,,0,"Migration to hacking 0.9.2 (first patch)

Whereas Neutron uses hacking 0.9.2, python-neutronclient still uses
0.8.1 and a lot of code convention violations raise if you use a system
wide 'hacking' installed because the number of checks is much bigger
with the last release of the library.

Instead of modify the test-requirements.txt and let them raise (that
would block other's patches because Zuul gates would fail hereinafter),
a slow and steady bunch of patches will be proposed to modify these
chuncks of code and have a smooth transition from 0.8.1 to 0.9.2.

In this one, docstrings have been converted in common comments due the
impossibility to convert them into proper docstring conventions. Some of
them have changes to maintain code coherency into the class.

Change-Id: I8b03fa5839fb9d8dc6e2a1512b184b26e8619233
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/02/126002/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py']",13,e10c60478e60122e39a3387189a02a39a8fb1278,hacking092_first_patch, # $ lb-vip-create # with all mandatory params # $ lb-vip-create # with all params # $ lb-vip-create # with mandatory and session-persistence params # $ lb-vip-list # $ lb-vip-list # $ lb-vip-list --sort-key name --sort-key id --sort-key # --sort-key desc # $ lb-vip-list -P # $ lb-vip-show test_id # $ lb-vip-show # $ lb-vip-update myid --name myname --tags a b # $ lb-vip-delete my-id ," """"""lb-vip-create with all mandatory params."""""" """"""lb-vip-create with all params."""""" """"""lb-vip-create with mandatory and session-persistence params."""""" """"""lb-vip-list."""""" """"""lb-vip-list."""""" """"""lb-vip-list --sort-key name --sort-key id --sort-key asc --sort-key desc """""" """"""lb-vip-list -P."""""" """"""lb-vip-show test_id."""""" """"""lb-vip-show."""""" """"""lb-vip-update myid --name myname --tags a b."""""" """"""lb-vip-delete my-id.""""""",263,148
openstack%2Fcloudkitty~master~I0216fdb6829fdb2274edf693971c6730727f2cde,openstack/cloudkitty,master,I0216fdb6829fdb2274edf693971c6730727f2cde,Added support for Multiple Collectors,MERGED,2014-09-25 21:24:11.000000000,2014-10-06 09:53:16.000000000,2014-10-06 09:53:15.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 7042}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-09-25 21:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ead8dde9f258ad60dedc402673262acde39e0201', 'message': 'Added support for Multiple Collectors\n\nChange-Id: I0216fdb6829fdb2274edf693971c6730727f2cde\n'}, {'number': 2, 'created': '2014-09-26 12:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/84b5432d0c3d788a964b9d4cdfb70362fb3f9960', 'message': 'Added support for Multiple Collectors\n\nChange-Id: I0216fdb6829fdb2274edf693971c6730727f2cde\n'}, {'number': 3, 'created': '2014-09-26 16:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/d38141a90473522d1de8ab5b32fd84730e14e26b', 'message': 'Added support for Multiple Collectors\n\nChange-Id: I0216fdb6829fdb2274edf693971c6730727f2cde\n'}, {'number': 4, 'created': '2014-10-06 09:45:11.000000000', 'files': ['cloudkitty/db/sqlalchemy/alembic/versions/2ac2217dcbd9_added_support_for_meta_collector.py', 'doc/source/webapi/v1.rst', 'cloudkitty/collector/meta.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/db/sqlalchemy/models.py', 'setup.cfg', 'cloudkitty/db/api.py', 'cloudkitty/api/controllers/v1.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/cc10eb6e08bf36f6afb729091bfdef613cc4303b', 'message': 'Added support for Multiple Collectors\n\nAdded a new collector backend: MetaCollector.\nAdded new API endpoints for the MetaCollector configuration.\nModified documentation to add new API endpoints.\n\nChange-Id: I0216fdb6829fdb2274edf693971c6730727f2cde\n'}]",1,124186,cc10eb6e08bf36f6afb729091bfdef613cc4303b,14,4,4,7042,,,0,"Added support for Multiple Collectors

Added a new collector backend: MetaCollector.
Added new API endpoints for the MetaCollector configuration.
Modified documentation to add new API endpoints.

Change-Id: I0216fdb6829fdb2274edf693971c6730727f2cde
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/86/124186/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cloudkitty/cloudkitty.conf.sample', 'cloudkitty/db/sqlalchemy/alembic/versions/2ac2217dcbd9_added_support_for_meta_collector.py', 'doc/source/webapi/v1.rst', 'cloudkitty/collector/meta.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/db/sqlalchemy/models.py', 'setup.cfg', 'cloudkitty/db/api.py', 'cloudkitty/api/controllers/v1.py']",9,ead8dde9f258ad60dedc402673262acde39e0201,refactoring/new_arch,"from cloudkitty.db import api as db_apiclass MetricToCollectorMapping(wtypes.Base): """"""Type describing a metric to collector mapping. """""" metric = wtypes.text """"""Name of the metric."""""" collector = wtypes.text """"""Name of the collector."""""" def to_json(self): res_dict = {} res_dict[self.metric] = self.collector return res_dict @classmethod def sample(cls): sample = cls(metric='compute', collector='ceilometer') return sample class MappingController(rest.RestController): """"""REST Controller managing metric to collector mapping. """""" def __init__(self): self._db = db_api.get_instance().get_metric_to_collector_mapping() @wsme_pecan.wsexpose([wtypes.text]) def get_all(self): """"""Return the list of every metrics mapped. :return: List of every metrics mapped. """""" return [mapping.metric for mapping in self._db.list_mappings()] @wsme_pecan.wsexpose(MetricToCollectorMapping, wtypes.text) def get_one(self, metric): """"""Return a metric to collector mapping. :param metric: Name of the metric to filter on. """""" try: return self._db.get_mapping(metric) except db_api.NoSuchMapping as e: pecan.abort(400, str(e)) pecan.response.status = 200 @wsme_pecan.wsexpose(MetricToCollectorMapping, wtypes.text, body=wtypes.text) def post(self, metric, collector): """"""Create or modify a mapping. :param metric: Name of the metric to map a collector to. :param collector: Name of the collector. """""" return self._db.set_mapping(metric, collector) @wsme_pecan.wsexpose(None, body=wtypes.text) def delete(self, metric): """"""Delete a mapping. :param metric: Name of the metric to suppress the mapping from. """""" try: self._db.delete_mapping(metric) except db_api.NoSuchMapping as e: pecan.abort(400, str(e)) pecan.response.status = 204 class CollectorController(rest.RestController): """"""REST Controller managing collector modules. """""" mapping = MappingController() _custom_actions = { 'state': ['GET', 'POST'] } def __init__(self): self._db = db_api.get_instance().get_module_enable_state() @wsme_pecan.wsexpose(bool, wtypes.text) def state(self, collector): """"""Query the enable state of a collector. :param collector: Name of the collector. :return: State of the collector. """""" return self._db.get_state('collector_{}'.format(collector)) @wsme_pecan.wsexpose(bool, wtypes.text, body=bool) def post_state(self, collector, state): """"""Set the enable state of a collector. :param collector: Name of the collector. :param state: New state for the collector. :return: State of the collector. """""" return self._db.set_state('collector_{}'.format(collector), state) collector = CollectorController()",,389,13
openstack%2Fneutron~master~I05d70417e0f78ae51a9ce377fc93a3f12046b313,openstack/neutron,master,I05d70417e0f78ae51a9ce377fc93a3f12046b313,Iterate over same port_id if more than one exists,MERGED,2014-09-18 08:39:14.000000000,2014-10-06 09:41:46.000000000,2014-10-06 09:41:44.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-18 08:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff5a60c5e29498dca98779e830ccb25bf627c420', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nCloses-bug: #1370914\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 2, 'created': '2014-09-21 11:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a755b557735c445d63e5d3b9d817983bb8f283f7', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 3, 'created': '2014-09-23 13:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10eb4d647803c4ef07ab7b38f283a8c1fe112bd5', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 4, 'created': '2014-09-28 13:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd8bc2e42331afaf0ba545233ce7f365ef73031e', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nRelated-bug: #1374947\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 5, 'created': '2014-09-29 14:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c702caaa940777900f9fa81ea9c35f41941166d5', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nRelated-bug: #1374947\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 6, 'created': '2014-09-30 08:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fbcbe1474847259a1924e04f90a54772226a1bc', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nRelated-bug: #1374947\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}, {'number': 7, 'created': '2014-10-02 08:54:39.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ovs_lib.py', 'neutron/agent/linux/ovs_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e90d6d6c833db51964037afd1c4aa1f521ee380a', 'message': ""Iterate over same port_id if more than one exists\n\nIn certain cases where multiple ports can have the same\nexternal_ids:iface_id property, the ovs agent will arbitrarily choose\none and ignore the rest. In case the chosen port isn't on the\nintegration bridge the ovs agent is managing, an error is returned to\nthe calling function. This is faulty since one of the other ports may\nbelong to the correct bridge and it should be chosen instead.\n\nThis is interesting for future L3 HA integration tests, where 2\ndifferent instances of l3 agents are needed to run on the same machine.\nIn this case, both agents will register ports which have the same\niface_id property, but obviously only one of the ports is relevant for\neach agent.\n\nCloses-bug: #1370914\nRelated-bug: #1374947\nChange-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313\n""}]",12,122357,e90d6d6c833db51964037afd1c4aa1f521ee380a,180,31,7,12444,,,0,"Iterate over same port_id if more than one exists

In certain cases where multiple ports can have the same
external_ids:iface_id property, the ovs agent will arbitrarily choose
one and ignore the rest. In case the chosen port isn't on the
integration bridge the ovs agent is managing, an error is returned to
the calling function. This is faulty since one of the other ports may
belong to the correct bridge and it should be chosen instead.

This is interesting for future L3 HA integration tests, where 2
different instances of l3 agents are needed to run on the same machine.
In this case, both agents will register ports which have the same
iface_id property, but obviously only one of the ports is relevant for
each agent.

Closes-bug: #1370914
Related-bug: #1374947
Change-Id: I05d70417e0f78ae51a9ce377fc93a3f12046b313
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/122357/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ovs_lib.py'],1,ff5a60c5e29498dca98779e830ccb25bf627c420,bug/1370914," for data in json_result['data']: port_name = data[name_idx] switch = get_bridge_for_iface(self.root_helper, port_name) if switch != self.br_name: continue ofport = data[ofport_idx] # ofport must be integer otherwise return None if not isinstance(ofport, int) or ofport == -1: LOG.warn(_(""ofport: %(ofport)s for VIF: %(vif)s is not a "" ""positive integer""), {'ofport': ofport, 'vif': port_id}) return # Find VIF's mac address in external ids ext_id_dict = dict((item[0], item[1]) for item in data[ext_ids_idx][1]) vif_mac = ext_id_dict['attached-mac'] return VifPort(port_name, ofport, port_id, vif_mac, self) LOG.info(_(""port %(port_id)s has no ports in bridge %(br_name)s!""), {'port_id': port_id, 'br_name': self.br_name}) return"," data = json_result['data'][0] port_name = data[name_idx] switch = get_bridge_for_iface(self.root_helper, port_name) if switch != self.br_name: LOG.info(_(""Port: %(port_name)s is on %(switch)s,"" "" not on %(br_name)s""), {'port_name': port_name, 'switch': switch, 'br_name': self.br_name}) return ofport = data[ofport_idx] # ofport must be integer otherwise return None if not isinstance(ofport, int) or ofport == -1: LOG.warn(_(""ofport: %(ofport)s for VIF: %(vif)s is not a "" ""positive integer""), {'ofport': ofport, 'vif': port_id}) return # Find VIF's mac address in external ids ext_id_dict = dict((item[0], item[1]) for item in data[ext_ids_idx][1]) vif_mac = ext_id_dict['attached-mac'] return VifPort(port_name, ofport, port_id, vif_mac, self)",20,21
openstack%2Ftooz~master~I01de25fc4a1ef5681e2878d1215251cea1dd9f33,openstack/tooz,master,I01de25fc4a1ef5681e2878d1215251cea1dd9f33,ipc: Fix acquire lock loop logic,MERGED,2014-10-06 08:45:48.000000000,2014-10-06 09:40:52.000000000,2014-10-06 09:40:51.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-10-06 08:45:48.000000000', 'files': ['tooz/drivers/ipc.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/8932510009d4ee80db7b36bc1db6f08e3547543e', 'message': 'ipc: Fix acquire lock loop logic\n\nReally restart the loop, when ExistentialError occurs.\n\nChange-Id: I01de25fc4a1ef5681e2878d1215251cea1dd9f33\n'}]",3,126238,8932510009d4ee80db7b36bc1db6f08e3547543e,8,3,1,2813,,,0,"ipc: Fix acquire lock loop logic

Really restart the loop, when ExistentialError occurs.

Change-Id: I01de25fc4a1ef5681e2878d1215251cea1dd9f33
",git fetch https://review.opendev.org/openstack/tooz refs/changes/38/126238/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/ipc.py'],1,8932510009d4ee80db7b36bc1db6f08e3547543e,, continue continue, pass pass,2,2
openstack%2Ftooz~master~I7274cb597eb1e84d13d37f99508f1bdabe108d8c,openstack/tooz,master,I7274cb597eb1e84d13d37f99508f1bdabe108d8c,Split up the requirements for py2.x and py3.x,MERGED,2014-09-25 04:01:39.000000000,2014-10-06 09:32:56.000000000,2014-10-06 09:32:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-09-25 04:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/bccd3852a781b66e22e20458f0c58e501ef36b43', 'message': 'Split up the requirements for py2.x and py3.x\n\nCertain requirements are not needed in py3.x since they\nexist in the base python tree so it is good to split off\nthe requirements files and add the backported requirements\nto the py2.x requirements and not the py3.x requirements.\n\nChange-Id: I7274cb597eb1e84d13d37f99508f1bdabe108d8c\n'}, {'number': 2, 'created': '2014-09-25 04:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/c6f7a331ab7c32ecee549e7979d8753cd8c8cfb1', 'message': 'Split up the requirements for py2.x and py3.x\n\nCertain requirements are not needed in py3.x since they\nexist in the base python tree so it is good to split off\nthe requirements files and add the backported requirements\nto the py2.x requirements and not the py3.x requirements.\n\nThe main current difference is the concurrent.futures\npackage which is built-in to python 3.x as part of the\nstandard library.\n\nChange-Id: I7274cb597eb1e84d13d37f99508f1bdabe108d8c\n'}, {'number': 3, 'created': '2014-10-06 09:12:04.000000000', 'files': ['requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tooz/commit/74237d1e21c81a582b23074f60980b406100a10d', 'message': 'Split up the requirements for py2.x and py3.x\n\nCertain requirements are not needed in py3.x since they\nexist in the base python tree so it is good to split off\nthe requirements files and add the backported requirements\nto the py2.x requirements and not the py3.x requirements.\n\nThe main current difference is the concurrent.futures\npackage which is built-in to python 3.x as part of the\nstandard library.\n\nChange-Id: I7274cb597eb1e84d13d37f99508f1bdabe108d8c\n'}]",0,123928,74237d1e21c81a582b23074f60980b406100a10d,14,3,3,1297,,,0,"Split up the requirements for py2.x and py3.x

Certain requirements are not needed in py3.x since they
exist in the base python tree so it is good to split off
the requirements files and add the backported requirements
to the py2.x requirements and not the py3.x requirements.

The main current difference is the concurrent.futures
package which is built-in to python 3.x as part of the
standard library.

Change-Id: I7274cb597eb1e84d13d37f99508f1bdabe108d8c
",git fetch https://review.opendev.org/openstack/tooz refs/changes/28/123928/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-py3.txt', 'tox.ini']",2,bccd3852a781b66e22e20458f0c58e501ef36b43,123928,[testenv:py33] deps = -r{toxinidir}/requirements-py3.txt -r{toxinidir}/test-requirements.txt [testenv:py34] deps = -r{toxinidir}/requirements-py3.txt -r{toxinidir}/test-requirements.txt ,,19,0
openstack%2Ffuel-library~stable%2F5.0~Idfe4b54caa0d96a93e93bfff12d8b6216f83e2f1,openstack/fuel-library,stable/5.0,Idfe4b54caa0d96a93e93bfff12d8b6216f83e2f1,Change keystone memcache backend,ABANDONED,2014-09-17 19:40:36.000000000,2014-10-06 09:29:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-17 19:40:36.000000000', 'files': ['deployment/puppet/keystone/manifests/init.pp', 'deployment/puppet/stdlib/lib/puppet/provider/file_line/ruby.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0b66fa672a7ec69e4fbb3749c63be9ed891a9a39', 'message': 'Change keystone memcache backend\n\nUse keystone memcache pool backend\nin order to fix scalability and\nfailover problems\n\nAlso fixing file_line ""match"" + ""after"" insertion logic.\n\nChange-Id: Idfe4b54caa0d96a93e93bfff12d8b6216f83e2f1\nCloses-bug: #1364401\nCloses-bug: #1340657\n'}]",0,122230,0b66fa672a7ec69e4fbb3749c63be9ed891a9a39,10,10,1,11090,,,0,"Change keystone memcache backend

Use keystone memcache pool backend
in order to fix scalability and
failover problems

Also fixing file_line ""match"" + ""after"" insertion logic.

Change-Id: Idfe4b54caa0d96a93e93bfff12d8b6216f83e2f1
Closes-bug: #1364401
Closes-bug: #1340657
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/30/122230/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/keystone/manifests/init.pp', 'deployment/puppet/stdlib/lib/puppet/provider/file_line/ruby.rb']",2,0b66fa672a7ec69e4fbb3749c63be9ed891a9a39,bug/1340657," if (match_count == 0) and resource[:after] handle_create_with_after elsif File.open(resource[:path], 'w') do |fh| lines.each do |l| fh.puts(regex.match(l) ? resource[:line] : l) end if (match_count == 0) fh.puts(resource[:line]) end"," File.open(resource[:path], 'w') do |fh| lines.each do |l| fh.puts(regex.match(l) ? resource[:line] : l) end if (match_count == 0) fh.puts(resource[:line])",30,11
openstack%2Fglance~master~I7310e2dbedba8770ff3c11310c645a360e7ff9da,openstack/glance,master,I7310e2dbedba8770ff3c11310c645a360e7ff9da,Sync service module from oslo-incubator,ABANDONED,2014-08-27 08:30:27.000000000,2014-10-06 09:28:35.000000000,,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 2835}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 9303}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-08-27 08:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/28ed989f8cd5d9e07cc9d0c42140ceac3c154371', 'message': 'Sync service module from oslo-incubator\n\nThis pathc will sync oslo-incubator service framework in glance\nwith dependent modules.\n\nChange-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da\nblueprint:use-common-service-framework\n'}, {'number': 2, 'created': '2014-08-30 19:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/349deb60829466e613afad2663b8a9ee838c8abb', 'message': 'Sync service module from oslo-incubator\n\nThis pathc will sync oslo-incubator service framework in glance\nwith dependent modules.\n\nChange-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da\nblueprint:use-common-service-framework\n'}, {'number': 3, 'created': '2014-09-02 19:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/926a28caca52af00a1381a47c730815022f020c1', 'message': 'Sync service module from oslo-incubator\n\nThis pathc will sync oslo-incubator service framework in glance\nwith dependent modules.\n\nChange-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da\nblueprint:use-common-service-framework\n'}, {'number': 4, 'created': '2014-09-03 19:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e79e34b11c34d5d314c148df881b935da04b94c3', 'message': 'Sync service module from oslo-incubator\n\nThis patch will sync oslo-incubator service framework in glance\nwith dependent modules from commit 5f12bba4267b3a34b8d9db99928c998ae197fc52.\n\nChange-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da\nblueprint:use-common-service-framework\n'}, {'number': 5, 'created': '2014-09-15 08:07:48.000000000', 'files': ['glance/openstack/common/systemd.py', 'glance/openstack/common/threadgroup.py', 'glance/openstack/common/service.py', 'glance/openstack/common/jsonutils.py', 'openstack-common.conf', 'glance/openstack/common/strutils.py', 'glance/openstack/common/gettextutils.py', 'glance/openstack/common/loopingcall.py', 'glance/openstack/common/eventlet_backdoor.py', 'glance/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f88d57e4bd3eb0f481bd237fe16b9fb354dd1830', 'message': 'Sync service module from oslo-incubator\n\nThis pathc will sync oslo-incubator service framework in glance\nwith dependent modules.\n\nChange-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da\nblueprint:use-common-service-framework\n'}]",0,117135,f88d57e4bd3eb0f481bd237fe16b9fb354dd1830,16,10,5,10795,,,0,"Sync service module from oslo-incubator

This pathc will sync oslo-incubator service framework in glance
with dependent modules.

Change-Id: I7310e2dbedba8770ff3c11310c645a360e7ff9da
blueprint:use-common-service-framework
",git fetch https://review.opendev.org/openstack/glance refs/changes/35/117135/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/openstack/common/systemd.py', 'glance/openstack/common/threadgroup.py', 'glance/openstack/common/service.py', 'glance/openstack/common/jsonutils.py', 'openstack-common.conf', 'glance/openstack/common/strutils.py', 'glance/openstack/common/gettextutils.py', 'glance/openstack/common/loopingcall.py', 'glance/openstack/common/eventlet_backdoor.py', 'glance/openstack/common/log.py']",10,28ed989f8cd5d9e07cc9d0c42140ceac3c154371,bp/use-common-service-framework,"import socket_PY26 = sys.version_info[0:2] == (2, 6) # NOTE(flaper87): Pls, remove when graduating this module # from the incubator. from glance.openstack.common.strutils import mask_password # noqaDEFAULT_LOG_LEVELS = ['amqp=WARN', 'amqplib=WARN', 'boto=WARN', 'qpid=WARN', 'sqlalchemy=WARN', 'suds=INFO', 'oslo.messaging=INFO', 'iso8601=WARN', 'requests.packages.urllib3.connectionpool=WARN', 'urllib3.connectionpool=WARN', 'websocket=WARN', ""keystonemiddleware=WARN"", ""routes.middleware=WARN"", ""stevedore=WARN""] default=DEFAULT_LOG_LEVELS, 'message.'), 'log message.'), def isEnabledFor(self, level): if _PY26: # This method was added in python 2.7 (and it does the exact # same logic, so we need to do the exact same logic so that # python 2.6 has this capability as well). return self.logger.isEnabledFor(level) else: return super(BaseLoggerAdapter, self).isEnabledFor(level) if six.PY3: # In Python 3, the code fails because the 'manager' attribute # cannot be found when using a LoggerAdapter as the # underlying logger. Work around this issue. self._logger.manager = self._logger.logger.manager # NOTE(jecarey): If msg is not unicode, coerce it into unicode # before it can get to the python logging and # possibly cause string encoding trouble if not isinstance(msg, six.text_type): except (moves.configparser.Error, KeyError) as exc:def set_defaults(logging_context_format_string=None, default_log_levels=None): # Just in case the caller is not setting the # default_log_level. This is insurance because # we introduced the default_log_level parameter # later in a backwards in-compatible change if default_log_levels is not None: cfg.set_defaults( log_opts, default_log_levels=default_log_levels) if logging_context_format_string is not None: cfg.set_defaults( log_opts, logging_context_format_string=logging_context_format_string) if CONF.use_syslog: try: facility = _find_facility_from_conf() # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(facility=facility) else: syslog = logging.handlers.SysLogHandler(facility=facility) log_root.addHandler(syslog) except socket.error: log_root.error('Unable to add syslog handler. Verify that syslog' 'is running.') # NOTE(jecarey): If msg is not unicode, coerce it into unicode # before it can get to the python logging and # possibly cause string encoding trouble if not isinstance(record.msg, six.text_type): record.msg = six.text_type(record.msg) ","import re_SANITIZE_KEYS = ['adminPass', 'admin_pass', 'password', 'admin_password'] # NOTE(ldbragst): Let's build a list of regex objects using the list of # _SANITIZE_KEYS we already have. This way, we only have to add the new key # to the list of _SANITIZE_KEYS and we can generate regular expressions # for XML and JSON automatically. _SANITIZE_PATTERNS = [] _FORMAT_PATTERNS = [r'(%(key)s\s*[=]\s*[\""\']).*?([\""\'])', r'(<%(key)s>).*?(</%(key)s>)', r'([\""\']%(key)s[\""\']\s*:\s*[\""\']).*?([\""\'])', r'([\'""].*?%(key)s[\'""]\s*:\s*u?[\'""]).*?([\'""])', r'([\'""].*?%(key)s[\'""]\s*,\s*\'--?[A-z]+\'\s*,\s*u?[\'""])' '.*?([\'""])', r'(%(key)s\s*--?[A-z]+\s*).*?([\s])'] for key in _SANITIZE_KEYS: for pattern in _FORMAT_PATTERNS: reg_ex = re.compile(pattern % {'key': key}, re.DOTALL) _SANITIZE_PATTERNS.append(reg_ex) default=[ 'amqp=WARN', 'amqplib=WARN', 'boto=WARN', 'qpid=WARN', 'sqlalchemy=WARN', 'suds=INFO', 'oslo.messaging=INFO', 'iso8601=WARN', 'requests.packages.urllib3.connectionpool=WARN' ], 'message. '), 'log message. '),def mask_password(message, secret=""***""): """"""Replace password with 'secret' in message. :param message: The string which includes security information. :param secret: value with which to replace passwords. :returns: The unicode value of message with the password fields masked. For example: >>> mask_password(""'adminPass' : 'aaaaa'"") ""'adminPass' : '***'"" >>> mask_password(""'admin_pass' : 'aaaaa'"") ""'admin_pass' : '***'"" >>> mask_password('""password"" : ""aaaaa""') '""password"" : ""***""' >>> mask_password(""'original_password' : 'aaaaa'"") ""'original_password' : '***'"" >>> mask_password(""u'original_password' : u'aaaaa'"") ""u'original_password' : u'***'"" """""" message = six.text_type(message) # NOTE(ldbragst): Check to see if anything in message contains any key # specified in _SANITIZE_KEYS, if not then just return the message since # we don't have to mask any passwords. if not any(key in message for key in _SANITIZE_KEYS): return message secret = r'\g<1>' + secret + r'\g<2>' for pattern in _SANITIZE_PATTERNS: message = re.sub(pattern, secret, message) return message # NOTE(mrodden): catch any Message/other object and # coerce to unicode before they can get # to the python logging and possibly # cause string encoding trouble if not isinstance(msg, six.string_types): except moves.configparser.Error as exc:def set_defaults(logging_context_format_string): cfg.set_defaults( log_opts, logging_context_format_string=logging_context_format_string) if CONF.use_syslog: facility = _find_facility_from_conf() # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) log_root.addHandler(syslog) ",1232,130
openstack%2Fceilometer~master~I71a8204282ff88b07a9dfdde3f3812e7073acc33,openstack/ceilometer,master,I71a8204282ff88b07a9dfdde3f3812e7073acc33,Correct JSON-based query examples in documentation,MERGED,2014-09-25 10:21:11.000000000,2014-10-06 09:00:53.000000000,2014-10-06 09:00:52.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-09-25 10:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ab8d594904fa7ba9cddfe34fff8743d6360a8704', 'message': 'Correct JSON-based query examples in documentation\n\nChange-Id: I71a8204282ff88b07a9dfdde3f3812e7073acc33\nCloses-bug: 1362591\n'}, {'number': 2, 'created': '2014-09-29 09:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6db2f6a3d2d7e6cbe04ec4dbe5191546d28686da', 'message': 'Correct JSON-based query examples in documentation\n\nNeed to formulate GET query parameters in JSON, but ""-d"" in curl implies a POST request.\n\nChange-Id: I71a8204282ff88b07a9dfdde3f3812e7073acc33\nCloses-bug: 1362591\n'}, {'number': 3, 'created': '2014-09-29 11:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bb5db775f057fd588be1f4979fb4feac06c8bcc7', 'message': 'Correct JSON-based query examples in documentation\n\nNeed to formulate GET query parameters in JSON, but ""-d"" in curl implies\na POST request.\n\nChange-Id: I71a8204282ff88b07a9dfdde3f3812e7073acc33\nCloses-bug: 1362591\n'}, {'number': 4, 'created': '2014-09-30 12:14:37.000000000', 'files': ['doc/source/webapi/v2.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/afc977b97644c459f97c642ff5e05ba3735a2324', 'message': 'Correct JSON-based query examples in documentation\n\nNeed to formulate GET query parameters in JSON, but ""-d"" in curl implies\na POST request.\n\nChange-Id: I71a8204282ff88b07a9dfdde3f3812e7073acc33\nCloses-bug: 1362591\n'}]",7,124000,afc977b97644c459f97c642ff5e05ba3735a2324,28,9,4,13273,,,0,"Correct JSON-based query examples in documentation

Need to formulate GET query parameters in JSON, but ""-d"" in curl implies
a POST request.

Change-Id: I71a8204282ff88b07a9dfdde3f3812e7073acc33
Closes-bug: 1362591
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/00/124000/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/webapi/v2.rst'],1,ab8d594904fa7ba9cddfe34fff8743d6360a8704,bug/1362591," curl -H ""X-Auth-Token: <inserttokenhere>"" -H ""Content-Type: application/json"" {""field"": ""timestamp"",""op"": ""ge"",""value"":""2013-04-01T13:34:17""} http://localhost:8777/v2/meters/instance curl -H ""X-Auth-Token: <inserttokenhere>"" -H ""Content-Type: application/json"" [{""field"": ""timestamp"",""op"": ""ge"",""value"":""2013-04-01T13:34:17""},'\ ""'{""field"": ""project_id"",""op"": ""eq"",""value"":""8d6057bc-5b90-4296-afe0-84acaa2ef909""}] http://localhost:8777/v2/meters/instance"," curl -H 'X-Auth-Token: <inserttokenhere>' -H 'Content-Type: application/json' \ -d '{""q"":[{""field"": ""timestamp"",""op"": ""ge"",""value"":""2013-04-01T13:34:17""}]}' \ http://localhost:8777/v2/meters curl -H 'X-Auth-Token: <inserttokenhere>' -H 'Content-Type: application/json' \ -d '{""q"":[{""field"": ""timestamp"",""op"": ""ge"",""value"":""2013-04-01T13:34:17""},'\ ""'{""field"": ""project_id"",""op"": ""eq"",""value"":""8d6057bc-5b90-4296-afe0-84acaa2ef909""}]}' \ http://localhost:8777/v2/meters/instance",7,7
openstack%2Fzaqar~master~I4ef05ddad3275b797d959a2933b0f56bbc6bff24,openstack/zaqar,master,I4ef05ddad3275b797d959a2933b0f56bbc6bff24,Implementation of claims controller for Redis,ABANDONED,2014-07-02 02:49:07.000000000,2014-10-06 08:54:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6944}, {'_account_id': 10812}]","[{'number': 1, 'created': '2014-07-02 02:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/59c47f83f527e53b3e9590933d2664908afa0994', 'message': 'Implementation of claims controller for Redis\n\nRedis Claims controller manages lifecycle of message claims\nusing redis as the storage backend\n\nChange-Id: I4ef05ddad3275b797d959a2933b0f56bbc6bff24\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 2, 'created': '2014-07-10 09:17:24.000000000', 'files': ['marconi/queues/storage/redis/claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7406e99330747dc71e40eb32b986bfa8d4ff54bb', 'message': 'Implementation of claims controller for Redis\n\nRedis Claims controller manages lifecycle of message claims\nusing redis as the storage backend\n\nChange-Id: I4ef05ddad3275b797d959a2933b0f56bbc6bff24\nPartially-Implements: bp/redis-storage-driver\n'}]",3,104055,7406e99330747dc71e40eb32b986bfa8d4ff54bb,13,3,2,10812,,,0,"Implementation of claims controller for Redis

Redis Claims controller manages lifecycle of message claims
using redis as the storage backend

Change-Id: I4ef05ddad3275b797d959a2933b0f56bbc6bff24
Partially-Implements: bp/redis-storage-driver
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/55/104055/2 && git format-patch -1 --stdout FETCH_HEAD,['marconi/queues/storage/redis/claims.py'],1,59c47f83f527e53b3e9590933d2664908afa0994,bp/redis-storage-driver-p3-queues,"from marconi.openstack.common import log as logging from marconi.openstack.common import timeutilsfrom marconi.queues.storage import errors from marconi.queues.storage.redis import utils def _exists(self, queue, claim_id, project, delete=True): # Note : Handle expired claims here. client = self._client qclaims_set_id = utils.scope_claims_set(queue, project, QUEUE_CLAIMS_SUFFIX) # Return False if no such claim exists if not client.sismember(qclaims_set_id, claim_id): return False # If the claim exists delete if it is expired # and return False claim = client.hgetall(claim_id) c_expires = int(claim['e.g']) now = timeutils.utcnow_ts() if now > c_expires and delete: self.delete(queue, claim_id, project) return False return True def _get_claimed_messages(self, claim_id): return self._client.smembers(claim_id) def _init_pipeline(self): self._pipeline = self._client.pipeline() def init_connection(self): """"""Will be used during reconnection attempts. self._client = self.driver.connection def __init__(self, *args, **kwargs): super(ClaimController, self).__init__(*args, **kwargs) self.init_connection() self._init_pipeline() self.message_ctrl = self.driver.message_controller @utils.raises_conn_error @utils.retries_on_autoreconnect def get(self, queue, claim_id, project=None): client = self._client now = timeutils.utcnow_ts() if not self._exists(queue, claim_id, project): raise errors.ClaimDoesNotExist(claim_id, queue, project) claim_messages = utils.scope_claim_messages(claim_id, CLAIM_MESSAGES_SUFFIX) ids = self._get_claimed_messages(claim_messages) msgs = [utils.basic_message(client.hgetall(id), now) for id in ids] claim_meta = client.hgetall(claim_id) now = timeutils.utcnow_ts() update_time = int(claim_meta['e']) - int(claim_meta['t']) age = now - update_time claim_meta = { 'age': int(age), 'ttl': claim_meta['t'], 'id': str(claim_meta['id']), } return (claim_meta, msgs) @utils.raises_conn_error @utils.retries_on_autoreconnect @utils.reset_pipeline qclaims_set_id = utils.scope_claims_set(queue, project, QUEUE_CLAIMS_SUFFIX) claim_id = utils.generate_uuid() now = timeutils.utcnow_ts() ttl = metadata['ttl'] grace = metadata['grace'] claim_messages = utils.scope_claim_messages(claim_id, CLAIM_MESSAGES_SUFFIX) claim_info = { 'id': claim_id, 't': ttl, 'g': grace, 'e': now + ttl, 'e.g': now + ttl + grace } # Create the claim and load the metadata information. pipe = self._pipeline pipe.sadd(qclaims_set_id, claim_id) pipe.hmset(claim_id, claim_info) pipe.execute() # Manual resetting required here. pipe.reset() messages = self.message_ctrl._active(queue, project=project, limit=limit) messages_list = list(next(messages)) ids = [message['id'] for message in messages_list] if len(ids) == 0: return (None, iter([])) message_info = { 'c': claim_id, 'c.e': now + ttl } # Update the claim id and claim expiration info # for all the messages. self.driver.queue_controller._inc_claimed(queue, project, len(ids)) for message_id in ids: pipe.sadd(claim_messages, message_id) pipe.hmset(message_id, message_info) pipe.execute() return claim_id, messages_list @utils.raises_conn_error @utils.retries_on_autoreconnect @utils.reset_pipeline def update(self, queue, claim_id, metadata, project=None): pipe = self._pipeline if not self._exists(queue, claim_id, project): raise errors.ClaimDoesNotExist(claim_id, queue, project) now = timeutils.utcnow_ts() ttl = int(metadata.get('ttl', 60)) grace = int(metadata.get('grace', 60)) expires = now + ttl claim_messages = utils.scope_claim_messages(claim_id, CLAIM_MESSAGES_SUFFIX) ids = self._get_claimed_messages(claim_messages) claim_info = { 't': ttl, 'g': grace, 'e': expires, 'e.g': expires + grace } message_info = { 'c.e': expires } # Update the claim id and claim expiration info # for all the messages. pipe.hmset(claim_id, claim_info) for message_id in ids: pipe.hmset(message_id, message_info) pipe.execute() @utils.raises_conn_error @utils.retries_on_autoreconnect @utils.reset_pipeline def delete(self, queue, claim_id, project=None): qclaims_set_id = utils.scope_claims_set(queue, project, QUEUE_CLAIMS_SUFFIX) pipe = self._pipeline # delete:False avoids an infinite recursive case. if not self._exists(queue, claim_id, project, delete=False): raise errors.ClaimDoesNotExist(claim_id, queue, project) now = timeutils.utcnow_ts() claim_messages = utils.scope_claim_messages(claim_id, CLAIM_MESSAGES_SUFFIX) ids = self._get_claimed_messages(claim_messages) # Reset values of the claimed messages. message_info = { 'c': None, 'c.e': now } # Update the claim id and claim expiration info # for all the messages. pipe.srem(qclaims_set_id, claim_id) pipe.delete(claim_id) pipe.delete(claim_messages) for message_id in ids: pipe.hmset(message_id, message_info) pipe.execute()","import marconi.openstack.common.log as logging def get(self, queue, claim_id, project=None): """"""Base method for getting a claim. :param queue: Name of the queue this claim belongs to. :param claim_id: The claim id :param project: Project id :returns: (Claim's metadata, claimed messages) :raises: DoesNotExist raise NotImplementedError """"""Base method for creating a claim. :param queue: Name of the queue this claim belongs to. :param metadata: Claim's parameters to be stored. :param project: Project id :param limit: (Default 10) Max number of messages to claim. :returns: (Claim ID, claimed messages) """""" raise NotImplementedError def update(self, queue, claim_id, metadata, project=None): """"""Base method for updating a claim. :param queue: Name of the queue this claim belongs to. :param claim_id: Claim to be updated :param metadata: Claim's parameters to be updated. :param project: Project id """""" raise NotImplementedError def delete(self, queue, claim_id, project=None): """"""Base method for deleting a claim. :param queue: Name of the queue this claim belongs to. :param claim_id: Claim to be deleted :param project: Project id """""" raise NotImplementedError",185,37
openstack%2Fceilometer~master~I60af82d5d8b5750884ba0d1ca726645f8b31448b,openstack/ceilometer,master,I60af82d5d8b5750884ba0d1ca726645f8b31448b,Run unit tests against PostgreSQL,MERGED,2014-10-03 09:05:34.000000000,2014-10-06 08:53:38.000000000,2014-10-06 08:53:37.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 13097}]","[{'number': 1, 'created': '2014-10-03 09:05:34.000000000', 'files': ['test-requirements.txt', 'setup-test-env-postgresql.sh', 'tox.ini', 'ceilometer/tests/db.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/52598e12729f69a0c42fbab3f67e68e6b9a19bc9', 'message': 'Run unit tests against PostgreSQL\n\n* Creates a new tox env py-pgsql\n* Adds a new script setupt-test-env-postgresql.sh to set up postgresql\n* Renames the MySQLDbManager into SQLManage, used by both mysql and\n  postgresql tests\n* Creates a new scenario for posgresql in the\n  MixinTestsWithBackendScenarios\n\nRelated to blueprint sql-unit-tests-on-real-backend\nCo-Authored-By: Ala Rezmerita <ala.rezmerita@cloudwatt.com>\n\nChange-Id: I60af82d5d8b5750884ba0d1ca726645f8b31448b\n'}]",0,125910,52598e12729f69a0c42fbab3f67e68e6b9a19bc9,12,7,1,7020,,,0,"Run unit tests against PostgreSQL

* Creates a new tox env py-pgsql
* Adds a new script setupt-test-env-postgresql.sh to set up postgresql
* Renames the MySQLDbManager into SQLManage, used by both mysql and
  postgresql tests
* Creates a new scenario for posgresql in the
  MixinTestsWithBackendScenarios

Related to blueprint sql-unit-tests-on-real-backend
Co-Authored-By: Ala Rezmerita <ala.rezmerita@cloudwatt.com>

Change-Id: I60af82d5d8b5750884ba0d1ca726645f8b31448b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/10/125910/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'setup-test-env-postgresql.sh', 'tox.ini', 'ceilometer/tests/db.py']",4,52598e12729f69a0c42fbab3f67e68e6b9a19bc9,bp/sql-unit-tests-on-real-backend,"class SQLManager(fixtures.Fixture): super(SQLManager, self).setUp() 'mysql': SQLManager, 'postgresql': SQLManager, for db in ('MONGODB', 'MYSQL', 'PGSQL', 'HBASE', 'DB2'):","class MySQLDbManager(fixtures.Fixture): super(MySQLDbManager, self).setUp() 'mysql': MySQLDbManager, for db in ('MONGODB', 'MYSQL', 'HBASE', 'DB2'):",39,6
openstack%2Fopenstack-manuals~master~I67728e4643610c809fd442df8230ecfea8b1bee1,openstack/openstack-manuals,master,I67728e4643610c809fd442df8230ecfea8b1bee1,Fixed the french word 'secrete' to secret in docs,ABANDONED,2014-09-22 22:37:12.000000000,2014-10-06 08:37:37.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 10068}, {'_account_id': 13300}, {'_account_id': 13358}]","[{'number': 1, 'created': '2014-09-22 22:37:12.000000000', 'files': ['doc/install-guide/samples/openrc.txt', 'doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/install-guide/samples/glance-api.conf', 'doc/install-guide/samples/glance-registry.conf'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7d498fbaf41a303cb2cf50766d02a94e70bbe06f', 'message': ""Fixed the french word 'secrete' to secret in docs\n\nMost examples use 'secrete' which is a french and has entirely\ndifferent meaning in english, since docs are in english, changed\nit to secret.\nCloses-Bug: #1372639\nChange-Id: I67728e4643610c809fd442df8230ecfea8b1bee1\n""}]",0,123267,7d498fbaf41a303cb2cf50766d02a94e70bbe06f,7,5,1,12609,,,0,"Fixed the french word 'secrete' to secret in docs

Most examples use 'secrete' which is a french and has entirely
different meaning in english, since docs are in english, changed
it to secret.
Closes-Bug: #1372639
Change-Id: I67728e4643610c809fd442df8230ecfea8b1bee1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/123267/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/samples/openrc.txt', 'doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/install-guide/samples/glance-api.conf', 'doc/install-guide/samples/glance-registry.conf']",5,7d498fbaf41a303cb2cf50766d02a94e70bbe06f,bug/1372639,admin_password = secret,admin_password = secrete,12,12
openstack%2Fceilometer~master~I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce,openstack/ceilometer,master,I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce,Add cfg.CONF.import_group for service_credentials,MERGED,2014-09-26 07:48:20.000000000,2014-10-06 08:37:07.000000000,2014-10-06 08:37:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12193}]","[{'number': 1, 'created': '2014-09-26 07:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e23a90da2a8eec8b9826a048de8c85abc808139c', 'message': 'Add cfg.CONF.import_group for service_credentials\n\nThe cfg.CONF.service_credentials attribute is used without calling\ncfg.CONF.import_group. Add calling the method in this patch.\n\nChange-Id: I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce\nCloses-Bug: 1373753\n'}, {'number': 2, 'created': '2014-09-26 11:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b88cce7fb166b3cc309e2f252e17fb8f4955ee75', 'message': 'Add cfg.CONF.import_group for service_credentials\n\nThe cfg.CONF.service_credentials attribute is used without calling\ncfg.CONF.import_group. Add calling the method in this patch.\n\nChange-Id: I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce\nCloses-Bug: 1373753\n'}, {'number': 3, 'created': '2014-09-29 11:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3b9e38c3b04f31f8c4cc6236bbb07fd88ebba9a1', 'message': 'Add cfg.CONF.import_group for service_credentials\n\nThe cfg.CONF.service_credentials attribute is used without calling\ncfg.CONF.import_group. Add calling the method in this patch.\n\nChange-Id: I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce\nCloses-Bug: 1373753\n'}, {'number': 4, 'created': '2014-09-30 06:41:02.000000000', 'files': ['ceilometer/objectstore/swift.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/157044dfcced0f971216ff371f1a3b4b12adae47', 'message': 'Add cfg.CONF.import_group for service_credentials\n\nThe cfg.CONF.service_credentials attribute is used without calling\ncfg.CONF.import_group. Add calling the method in this patch.\n\nChange-Id: I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce\nCloses-Bug: 1373753\n'}]",10,124318,157044dfcced0f971216ff371f1a3b4b12adae47,24,7,4,12193,,,0,"Add cfg.CONF.import_group for service_credentials

The cfg.CONF.service_credentials attribute is used without calling
cfg.CONF.import_group. Add calling the method in this patch.

Change-Id: I700c5ea7ae5ff3f61c28a767e5aa60db0dfb46ce
Closes-Bug: 1373753
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/124318/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/objectstore/test_swift.py', 'ceilometer/objectstore/swift.py']",2,e23a90da2a8eec8b9826a048de8c85abc808139c,bug/1373753,"cfg.CONF.import_group('service_credentials', 'ceilometer.service')",,10,0
openstack%2Fneutron~master~Ia8a74f1326ecd98c47cbe447f04d475bf61e19d3,openstack/neutron,master,Ia8a74f1326ecd98c47cbe447f04d475bf61e19d3,Removed kombu from requirements,MERGED,2014-08-07 20:28:49.000000000,2014-10-06 08:29:52.000000000,2014-10-04 22:30:22.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 6348}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7805}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-07 20:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a457b62f92ad800e50dc8e5a48559ce7ec041f3', 'message': ""Removed kombu from requirements\n\nSince we've replaced oslo-incubator RPC layer with oslo.messaging, we\ndon't ship any code that uses kombu.\n\nChange-Id: Ia8a74f1326ecd98c47cbe447f04d475bf61e19d3\n""}, {'number': 2, 'created': '2014-09-08 09:47:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/424c7faa75d96950d80f49f20f5414d1a297af72', 'message': ""Removed kombu from requirements\n\nSince we've replaced oslo-incubator RPC layer with oslo.messaging, we\ndon't ship any code that uses kombu.\n\nChange-Id: Ia8a74f1326ecd98c47cbe447f04d475bf61e19d3\n""}]",0,112683,424c7faa75d96950d80f49f20f5414d1a297af72,71,33,2,9656,,,0,"Removed kombu from requirements

Since we've replaced oslo-incubator RPC layer with oslo.messaging, we
don't ship any code that uses kombu.

Change-Id: Ia8a74f1326ecd98c47cbe447f04d475bf61e19d3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/112683/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4a457b62f92ad800e50dc8e5a48559ce7ec041f3,remove-kombu,,kombu>=2.4.8,0,1
openstack%2Fheat~master~I0409a04789f0ca362cb9ab0b612d47226d785334,openstack/heat,master,I0409a04789f0ca362cb9ab0b612d47226d785334,Import the stack module directly,MERGED,2014-07-16 09:59:19.000000000,2014-10-06 08:16:23.000000000,2014-10-06 08:16:22.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7239}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 9580}]","[{'number': 1, 'created': '2014-07-16 09:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bee8232b5afc355b3168a5f6e77513df81a353d6', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 2, 'created': '2014-07-16 11:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e96ef378e1e8385486d93d250c9146b4bbe34047', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 3, 'created': '2014-07-17 00:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e8979418358e404ded0823a59bdce3ec5acd604', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 4, 'created': '2014-07-18 01:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/621cde8e436d175b9252d60ccf55c10f4e41a6ca', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 5, 'created': '2014-07-18 02:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ec636b6fd39b16ecafa0a46b623dbd48dbd9ceda', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 6, 'created': '2014-07-21 21:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/30252fe8b355b8a8206fe46af8de92a5c3d34952', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 7, 'created': '2014-07-23 12:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d1537ced1d5611c470ad8a843be986c095eaf3ab', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 8, 'created': '2014-07-23 21:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/120f2106a81e36d07a6df3b97787c581c467fd16', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 9, 'created': '2014-07-24 06:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3de86b6efcffb1298e26624d0934a94e017fe98c', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 10, 'created': '2014-07-25 01:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/093e4971530c23ab1e61a4209c2989043581c707', 'message': 'Import the stack module directly\n\nTo reduce the number of changes this patch imports stack as parser.\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 11, 'created': '2014-08-18 03:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e0bf461a2319f110208ce1cc809d7b07f40bb4c3', 'message': 'Import the stack module directly\n\nNote: the patch imports ""stack as parser"" in some places to maintain\nAPI (service.py and event.py).\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 12, 'created': '2014-08-21 03:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d93561aa947d5270b103c8bb6d0e48b6e81525f0', 'message': 'Import the stack module directly\n\nNote: the patch imports ""stack as parser"" in some places to maintain\nAPI (service.py and event.py).\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 13, 'created': '2014-08-31 23:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d6ec108b9a12f4171c75ba31c8dc86b92419c159', 'message': 'Import the stack module directly\n\nNote: the patch imports ""stack as parser"" in some places to maintain\nAPI (service.py and event.py).\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 14, 'created': '2014-09-08 02:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fc4af4fbab39443ff8d7d0b94f3531a798c1ac87', 'message': 'Import the stack module directly\n\nNote: the patch imports ""stack as parser"" in some places to maintain\nAPI (service.py and event.py).\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}, {'number': 15, 'created': '2014-09-09 01:00:16.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/utils.py', 'heat/engine/stack_resource.py', 'heat/engine/event.py', 'heat/engine/watchrule.py', 'heat/tests/test_stack_resource.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5131d6c9b29b829b2283354f3824cca32eec9906', 'message': 'Import the stack module directly\n\nNote: the patch imports ""stack as parser"" in some places to maintain\nAPI (service.py and event.py).\n\nChange-Id: I0409a04789f0ca362cb9ab0b612d47226d785334\n'}]",18,107292,5131d6c9b29b829b2283354f3824cca32eec9906,86,15,15,4715,,,0,"Import the stack module directly

Note: the patch imports ""stack as parser"" in some places to maintain
API (service.py and event.py).

Change-Id: I0409a04789f0ca362cb9ab0b612d47226d785334
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/107292/10 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_cloud_config.py', 'heat/tests/test_structured_config.py', 'heat/tests/test_os_database.py', 'heat/tests/test_nested_stack.py', 'heat/tests/test_eip.py', 'heat/tests/test_parser.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_multi_part.py', 'heat/tests/test_security_group.py', 'heat/engine/watchrule.py', 'heat/engine/service.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/utils.py', 'heat/tests/test_event.py', 'heat/tests/test_notifications.py', 'heat/tests/test_instance_group_update_policy.py', 'heat/tests/test_dbinstance.py', 'heat/tests/test_vpc.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/tests/test_signal.py', 'heat/tests/test_instance.py', 'heat/tests/test_glance_image.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_provider_template.py', 'heat/tests/test_software_deployment.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_stack_resource.py', 'heat/tests/test_hot.py', 'heat/tests/test_instance_group.py', 'heat/tests/test_resource.py', 'heat/tests/test_metadata_refresh.py', 'heat/tests/test_autoscaling.py', 'heat/engine/stack_resource.py', 'heat/engine/event.py', 'heat/tests/test_software_config.py', 'heat/tests/test_random_string.py', 'heat/tests/test_server.py', 'heat/tests/test_watch.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_ceilometer_alarm.py', 'heat/tests/test_engine_api_utils.py']",44,bee8232b5afc355b3168a5f6e77513df81a353d6,stack,from heat.engine import stack as parser,from heat.engine import parser,45,45
openstack%2Fcloudkitty~master~I921ec986297771a908700b3ed3f7fc449f897087,openstack/cloudkitty,master,I921ec986297771a908700b3ed3f7fc449f897087,Rename get_migrate method for consistency,MERGED,2014-09-26 15:44:59.000000000,2014-10-06 08:14:15.000000000,2014-10-06 08:14:14.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-09-26 15:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/6b37eb458f9501de3237fcf98fcd0ef9345a0d02', 'message': 'Rename get_migrate methoods for consistency\n\nUse get_migration everywhere.\n\nChange-Id: I921ec986297771a908700b3ed3f7fc449f897087\n'}, {'number': 2, 'created': '2014-09-26 15:46:02.000000000', 'files': ['cloudkitty/cli/dbsync.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/db/api.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/312fc7b48bc1ed62219b9a91a9842dae582d9eea', 'message': 'Rename get_migrate method for consistency\n\nUse get_migration instead.\n\nChange-Id: I921ec986297771a908700b3ed3f7fc449f897087\n'}]",0,124445,312fc7b48bc1ed62219b9a91a9842dae582d9eea,8,3,2,7923,,,0,"Rename get_migrate method for consistency

Use get_migration instead.

Change-Id: I921ec986297771a908700b3ed3f7fc449f897087
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/45/124445/2 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/cli/dbsync.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/db/api.py']",3,6b37eb458f9501de3237fcf98fcd0ef9345a0d02,migration, def get_migration(self):, def get_migrate(self):,4,4
openstack%2Ftripleo-incubator~master~I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9,openstack/tripleo-incubator,master,I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9,Make a sentence less ambiguous in README,MERGED,2014-09-20 07:26:47.000000000,2014-10-06 08:12:50.000000000,2014-10-06 08:12:49.000000000,"[{'_account_id': 3}, {'_account_id': 5538}, {'_account_id': 6348}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 11224}]","[{'number': 1, 'created': '2014-09-20 07:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/19d086c2ec3963ae0e1e86479db4ead56b78e3c2', 'message': 'Make a sentence less ambiguous in README\n\nChange-Id: I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9\n'}, {'number': 2, 'created': '2014-09-20 07:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/14964857b7a129f94b164630eca726a0cad6c220', 'message': 'Make a sentence less ambiguous in README\n\nChange-Id: I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9\n'}, {'number': 3, 'created': '2014-09-23 14:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/237126537b7487ad518967f1886de4f2e5397687', 'message': 'Make a sentence less ambiguous in README\n\nChange-Id: I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9\n'}, {'number': 4, 'created': '2014-10-02 12:49:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1b4a736b8188e2aa2732b1fafb60a49ebf45c7fb', 'message': 'Make a sentence less ambiguous in README\n\nChange-Id: I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9\n'}]",12,122930,1b4a736b8188e2aa2732b1fafb60a49ebf45c7fb,25,7,4,5538,,,0,"Make a sentence less ambiguous in README

Change-Id: I7bc366f3aa4b4fe10f4730fe62fdb871272d02b9
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/30/122930/4 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,19d086c2ec3963ae0e1e86479db4ead56b78e3c2,122930,"Eventually, we will have the Heat instance hosted in only the undercloud, which we'll use to deploy both the undercloud and overcloud. That depends on a full-HA setup so that","Eventually, we will have the Heat instance we use to deploy both the undercloud and overcloud hosted in the undercloud. That depends on a full-HA setup so that",3,2
openstack%2Ftripleo-image-elements~master~I382631746e458f2f8603a7dcf5221a21f4b53255,openstack/tripleo-image-elements,master,I382631746e458f2f8603a7dcf5221a21f4b53255,Add initial svc-map support,MERGED,2014-07-02 13:42:19.000000000,2014-10-06 07:46:44.000000000,2014-10-06 07:46:43.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 7585}, {'_account_id': 8449}, {'_account_id': 8532}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-07-02 13:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/adec81fa9f22d8a80566d6b904eea1a17b6a3e78', 'message': ""Add initial svc-map support\n\nThis patch provides a very small proof of concept to\nincorporate the svc-map patch[1] into other elements\nby integrating svc-map into os-svc-enable.  The\nsvc-map patch helps to decouple tripleo-image-elements\nfrom diskimage-builder.  This first effort is to get\nsomething into CI that is testing svc-map and provide\na path to iterate on to complete the migration.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 2, 'created': '2014-07-24 20:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/41de0930fb85179748e31702121fcc2286000951', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 3, 'created': '2014-08-13 10:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9537a880d38afbb77f1dbb37b953db5bbe35ddca', 'message': ""Add initial svc-map support\n\nThis patch provides a very small proof of concept to\nincorporate the svc-map patch[1] into other elements\nby integrating svc-map into os-svc-enable.  The\nsvc-map patch helps to decouple tripleo-image-elements\nfrom diskimage-builder.  This first effort is to get\nsomething into CI that is testing svc-map and provide\na path to iterate on to complete the migration.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 4, 'created': '2014-08-13 11:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a8804a312fe19e96efb86b763b46dbd5288ca4ea', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior and it preserves the calls to\nmap-services.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 5, 'created': '2014-08-13 11:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/42ecac7951ee626ea791c425948c28db4d56f8ae', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior and it preserves the calls to\nmap-services.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 6, 'created': '2014-09-03 13:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8168bd9357034b5be109b60308b9350d79699cb7', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required. The\nos-svc-restart script has also promoted the optional\nSERVICENAME to a positional argument.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior and it preserves the calls to\nmap-services.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 7, 'created': '2014-09-03 16:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/73630f065cfe2c25b7957403887a1e8e17c20a82', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required. The\nos-svc-restart script has also promoted the optional\nSERVICENAME to a positional argument.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior and it preserves the calls to\nmap-services.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 8, 'created': '2014-09-09 14:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ddf2cf2e59a123b6d914342e8cd836aed5b1039c', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This first effort is to get something into CI\nthat is testing svc-map and provide a path to iterate on\nto complete the migration of the rest of\ntripleo-image-elements.\n\nThe original os-svc-enable script used the SERVICENAME\nas an option but had a check to make it required.  All\nof the elements that currently call os-svc-enable do so\nusing the -n option.  This patch takes that into account\nand layers the newer syntax without breaking the code\nthat's out there now.  The SERVICENAME is now a\npositional argument, but is still required. The\nos-svc-restart script has also promoted the optional\nSERVICENAME to a positional argument.\n\nThe os-svc-daemon and os-svc-restart scripts have been\nmodified to accept an element to map to.  If the mapping\nelement has been passed, it calls out to svc-map to find\nthe mapped service name.  If the mapping element isn't\npresent in the arguments, there is no change to the\ncurrent script behavior and it preserves the calls to\nmap-services.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 9, 'created': '2014-09-15 20:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fd670c326b603911285fc27c1b81c81a9046317a', 'message': ""Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This patch is an illustration of easy the\nswitch from map-services to svc-map would be, however\nthis patch can't necessarily land as is without the\nentire tripleo-image-elements first being converted\nto the svc-map format.\n\nI want to raise the question about transition: Do we\nmodify these three files in this patch to add a switch\nfor using svc-map instead of map-services to provide a\nphased transition or do we do a mass conversion of\ntripleo-image-elements to svc-map at once?\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n""}, {'number': 10, 'created': '2014-10-02 14:41:01.000000000', 'files': ['elements/os-svc-install/bin/os-svc-daemon', 'elements/os-svc-install/element-deps', 'elements/os-svc-install/bin/os-svc-enable', 'elements/os-svc-install/bin/os-svc-restart'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/49dbaae6df0ca9104a5feba38de956668b8088bc', 'message': 'Add initial svc-map support\n\nThis patch incorporates the svc-map patch[1] into other\nelements by integrating svc-map into the os-svc-install\nelement.  This patch adds the -a option to select svc-map\ninstead of the default of map-services.  The -a option\nenables a phased transition from map-services to svc-map\nusage throughout the rest of the elements.\n\n[1] Id11433ea342aace71a358936a7ca3151ec11d506\n\nChange-Id: I382631746e458f2f8603a7dcf5221a21f4b53255\n'}]",29,104196,49dbaae6df0ca9104a5feba38de956668b8088bc,76,9,10,8532,,,0,"Add initial svc-map support

This patch incorporates the svc-map patch[1] into other
elements by integrating svc-map into the os-svc-install
element.  This patch adds the -a option to select svc-map
instead of the default of map-services.  The -a option
enables a phased transition from map-services to svc-map
usage throughout the rest of the elements.

[1] Id11433ea342aace71a358936a7ca3151ec11d506

Change-Id: I382631746e458f2f8603a7dcf5221a21f4b53255
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/96/104196/9 && git format-patch -1 --stdout FETCH_HEAD,['elements/os-svc-install/bin/os-svc-enable'],1,adec81fa9f22d8a80566d6b904eea1a17b6a3e78,add-svc-map-support-update," echo ""Usage: os-svc-enable SERVICENAME"" echo "" -h Show help and exit"" echo "" -m MAP_ELEMENT Use custom element service map (Example: -m nova)""MAP_ELEMENT=${MAP_ELEMENT:-""""} while getopts "":hnm:"" opt; do m) MAP_ELEMENT=$OPTARG;;SERVICENAME=${SERVICENAME:-$1}if [ -n ""$MAP_ELEMENT"" ] ; then SERVICENAME=$(svc-map --element $MAP_ELEMENT $SERVICENAME) fi fi"," echo ""Usage: os-svc-enable -n SERVICENAME"" echo "" -h Show help and exit"" echo "" -n SERVICENAME Name of job/service file.""SERVICENAME=${SERVICENAME:-""""} nshift=0 while getopts ""hn:"" opt; do n) SERVICENAME=$OPTARG;;fi ",12,8
openstack%2Fnova~master~Iea5defb2f21373bd9c5264bbdab678b6a0ab23b2,openstack/nova,master,Iea5defb2f21373bd9c5264bbdab678b6a0ab23b2,WIP - ERT having request_spec for claiming resources correctly,ABANDONED,2014-08-13 15:36:04.000000000,2014-10-06 07:40:16.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7641}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-13 15:36:04.000000000', 'files': ['nova/compute/resources/__init__.py', 'nova/compute/resources/flavors.py', 'nova/compute/resources/base.py', 'nova/compute/manager.py', 'setup.cfg', 'nova/compute/claims.py', 'nova/tests/compute/test_resources.py', 'nova/tests/compute/test_claims.py', 'nova/compute/resource_tracker.py', 'nova/compute/resources/vcpu.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cf152a9db40f5624af53e73bdab081a5e3b1ef35', 'message': ""WIP - ERT having request_spec for claiming resources correctly\n\nAs discussed upstream [1], ERT plugins allow to test resources when\ncompute manager is claiming. That said, it was missing request_spec so\nwe were unable to know what was passed from the user.\n\nHere is a proposal for fixing this, that would allow computes to check on\nthe same metrics as for the scheduler (once isolate-scheduler-db will be\nlanded, because it will write these resources to the scheduler)\n\nJoint is a Flavors resource for updating in-memory extra_specs and\nmaking sure we don't race keys adding\n\nImplements blueprint extensible-resource-tracker\n\nChange-Id: Iea5defb2f21373bd9c5264bbdab678b6a0ab23b2\n""}]",3,113936,cf152a9db40f5624af53e73bdab081a5e3b1ef35,11,7,1,7166,,,0,"WIP - ERT having request_spec for claiming resources correctly

As discussed upstream [1], ERT plugins allow to test resources when
compute manager is claiming. That said, it was missing request_spec so
we were unable to know what was passed from the user.

Here is a proposal for fixing this, that would allow computes to check on
the same metrics as for the scheduler (once isolate-scheduler-db will be
landed, because it will write these resources to the scheduler)

Joint is a Flavors resource for updating in-memory extra_specs and
making sure we don't race keys adding

Implements blueprint extensible-resource-tracker

Change-Id: Iea5defb2f21373bd9c5264bbdab678b6a0ab23b2
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/113936/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/resources/__init__.py', 'nova/compute/resources/flavors.py', 'nova/compute/resources/base.py', 'nova/compute/manager.py', 'setup.cfg', 'nova/compute/claims.py', 'nova/tests/compute/test_resources.py', 'nova/compute/resource_tracker.py', 'nova/tests/compute/test_claims.py', 'nova/compute/resources/vcpu.py']",10,cf152a9db40f5624af53e73bdab081a5e3b1ef35,bp/extensible-resource-tracker," def test(self, usage, limits, request_spec):"," def test(self, usage, limits):",112,20
openstack%2Fnova~master~I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d,openstack/nova,master,I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d,Add missing fields to ComputeNode object,ABANDONED,2014-06-04 15:51:46.000000000,2014-10-06 07:39:24.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2835}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 8514}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9407}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10937}]","[{'number': 1, 'created': '2014-06-04 15:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/593c3a71e4b552ccd6fde7faaddb07b78094a5c2', 'message': 'Add pci_stats and host_ip to ComputeNode object fields\n\nLatest changes to DB model for ComputeNode were not impacting\nComputeNode object. Fixed it as it is necessary for the Scheduler\nclient fork.\n\nChange-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d\nImplements: blueprint scheduler-lib\n'}, {'number': 2, 'created': '2014-06-04 15:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37adc96165dfb3f32426a856c3fca7945c42266a', 'message': 'Add pci_stats and host_ip to ComputeNode object fields\n\nLatest changes to DB model for ComputeNode were not impacting\nComputeNode object. Fixed it as it is necessary for the Scheduler\nclient fork.\n\nChange-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d\nImplements: blueprint scheduler-lib\n'}, {'number': 3, 'created': '2014-06-04 17:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/063d78b9cc07f0c35e0b9b4892fbb9f7a6b063cc', 'message': 'Add pci_stats and host_ip to ComputeNode object fields\n\nLatest changes to DB model for ComputeNode were not impacting\nComputeNode object. Fixed it as it is necessary for the Scheduler\nclient fork.\n\nChange-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d\nImplements: blueprint scheduler-lib\n'}, {'number': 4, 'created': '2014-06-05 08:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1194d8aa63c9c99a110a711592ad53571ada559a', 'message': 'Add pci_stats and host_ip to ComputeNode object fields\n\nLatest changes to DB model for ComputeNode were not impacting\nComputeNode object. Fixed it as it is necessary for the Scheduler\nclient fork.\nAlso modified some unittests to map with use of Objects\n\nChange-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d\nImplements: blueprint scheduler-lib\n'}, {'number': 5, 'created': '2014-06-06 11:26:33.000000000', 'files': ['nova/virt/fake.py', 'nova/tests/objects/test_compute_node.py', 'nova/objects/compute_node.py', 'nova/tests/objects/test_objects.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/compute/test_compute.py', 'nova/tests/compute/test_multiple_nodes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/049d110d2f62498cc66593ce19d0325d90b59e65', 'message': 'Add missing fields to ComputeNode object\n\nLatest changes to DB model for ComputeNode were not impacting\nComputeNode object. Fixed it as it is necessary for the Scheduler\nclient fork.\nAlso modified some unittests to map with use of Objects\n\nChange-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d\nImplements: blueprint scheduler-lib\n'}]",19,97837,049d110d2f62498cc66593ce19d0325d90b59e65,63,15,5,7166,,,0,"Add missing fields to ComputeNode object

Latest changes to DB model for ComputeNode were not impacting
ComputeNode object. Fixed it as it is necessary for the Scheduler
client fork.
Also modified some unittests to map with use of Objects

Change-Id: I4a4a2704a78631a7f3a9b6dafea9e6db4a650d2d
Implements: blueprint scheduler-lib
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/97837/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/compute_node.py', 'nova/tests/objects/test_compute_node.py', 'nova/tests/objects/test_objects.py']",3,593c3a71e4b552ccd6fde7faaddb07b78094a5c2,bp/scheduler-lib," 'ComputeNode': '1.4-ae6ddf011de6e10906de361807ec2e79', 'ComputeNodeList': '1.3-be44294fa7d0deef6146863836adb1e5',"," 'ComputeNode': '1.3-da09be1ff8b43f9889f2bb4e43b5686e', 'ComputeNodeList': '1.2-be44294fa7d0deef6146863836adb1e5',",16,5
openstack%2Fdevstack~master~Ie6a272f60059a1f363630f307416b32c450a1ebb,openstack/devstack,master,Ie6a272f60059a1f363630f307416b32c450a1ebb,Added libvirt-dev[el] as a required system package,MERGED,2014-08-29 06:54:12.000000000,2014-10-06 07:23:00.000000000,2014-10-05 13:59:35.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 7175}, {'_account_id': 7715}, {'_account_id': 8328}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-29 06:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b3d70f0a482f0efb08f43ad66aa1bf27db25fc93', 'message': 'Added libvirt-dev as a testonly apt\n\nAdded libvir-dev as a system package to install with apt\nwhen INSTALL_TESTONLY_PACKAGES is true.\n\nChange-Id: Ie6a272f60059a1f363630f307416b32c450a1ebb\nCloses-Bug: 1362948\n'}, {'number': 2, 'created': '2014-09-18 16:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc715787dc0f9954007803c82d758ec479d60f86', 'message': 'Added libvirt-dev[el] as a testonly system package\n\nAdded libvirt-dev as a system package to install with apt-get and\nlibvirt-devel as a system package to install with rpm when\nINSTALL_TESTONLY_PACKAGES is true.  This is needed because installing\nlibvirt-python version 1.2.5 on Ubuntu 14.04 was observed to fail in\nthe building step if libvirt-dev is missing.\n\nChange-Id: Ie6a272f60059a1f363630f307416b32c450a1ebb\nCloses-Bug: 1362948\n'}, {'number': 3, 'created': '2014-10-03 03:25:48.000000000', 'files': ['files/apts/nova', 'files/rpms/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3edd4540b936d1f03e990660312f2377354140a8', 'message': 'Added libvirt-dev[el] as a required system package\n\nAdded libvirt-dev as a system package to install with apt-get and\nlibvirt-devel as a system package to install with rpm.\n\nEarly drafts qualified with ""testonly"" (meaning to install only if\nINSTALL_TESTONLY_PACKAGES is true).  This is needed because installing\nlibvirt-python version 1.2.5 on Ubuntu 14.04 was observed to fail in\nthe building step if libvirt-dev is missing.  Later drafts removed\nthat qualification, because Sean Dague said he thinks libvirt-dev[el]\nis always required.\n\nChange-Id: Ie6a272f60059a1f363630f307416b32c450a1ebb\nCloses-Bug: 1362948\n'}]",6,117703,3edd4540b936d1f03e990660312f2377354140a8,31,11,3,8328,,,0,"Added libvirt-dev[el] as a required system package

Added libvirt-dev as a system package to install with apt-get and
libvirt-devel as a system package to install with rpm.

Early drafts qualified with ""testonly"" (meaning to install only if
INSTALL_TESTONLY_PACKAGES is true).  This is needed because installing
libvirt-python version 1.2.5 on Ubuntu 14.04 was observed to fail in
the building step if libvirt-dev is missing.  Later drafts removed
that qualification, because Sean Dague said he thinks libvirt-dev[el]
is always required.

Change-Id: Ie6a272f60059a1f363630f307416b32c450a1ebb
Closes-Bug: 1362948
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/117703/3 && git format-patch -1 --stdout FETCH_HEAD,['files/apts/nova'],1,b3d70f0a482f0efb08f43ad66aa1bf27db25fc93,bug/1362948,libvirt-dev # testonly,,1,0
openstack%2Ftempest~master~Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8,openstack/tempest,master,Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8,Check for created_objects in resource_cleanup,ABANDONED,2014-09-29 20:31:47.000000000,2014-10-06 07:17:18.000000000,,"[{'_account_id': 3}, {'_account_id': 5174}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-29 20:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8799fb2a3410029ae8705516238c46f7eec51b06', 'message': ""Init created_objects for baremetal API tests before skipException\n\nThe created_objects attribute isn't getting initialized in\nresource_setup before the skipException so when baremetal tests are\nskipped we get an AttributeError in resource_cleanup when trying to use\ncreated_objects.\n\nCloses-Bug: #1375454\n\nChange-Id: Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8\n""}, {'number': 2, 'created': '2014-09-29 20:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5539b6f7a6de8f5b3e9364a565322b9c019998cc', 'message': ""Chekc for created_objects in resource_cleanup\n\nThe created_objects attribute isn't getting initialized in\nresource_setup before the skipException so when baremetal tests are\nskipped we get an AttributeError in resource_cleanup when trying to use\ncreated_objects. This simply checks to see if the attribute is set\nbefore trying to use it in resource_cleanup.\n\nCloses-Bug: #1375454\n\nChange-Id: Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8\n""}, {'number': 3, 'created': '2014-09-29 20:40:46.000000000', 'files': ['tempest/api/baremetal/admin/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ccd9fd2bcd81a91edcbbafc3c37da88a31ad756', 'message': ""Check for created_objects in resource_cleanup\n\nThe created_objects attribute isn't getting initialized in\nresource_setup before the skipException so when baremetal tests are\nskipped we get an AttributeError in resource_cleanup when trying to use\ncreated_objects. This simply checks to see if the attribute is set\nbefore trying to use it in resource_cleanup.\n\nCloses-Bug: #1375454\n\nChange-Id: Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8\n""}]",0,124863,4ccd9fd2bcd81a91edcbbafc3c37da88a31ad756,11,5,3,6873,,,0,"Check for created_objects in resource_cleanup

The created_objects attribute isn't getting initialized in
resource_setup before the skipException so when baremetal tests are
skipped we get an AttributeError in resource_cleanup when trying to use
created_objects. This simply checks to see if the attribute is set
before trying to use it in resource_cleanup.

Closes-Bug: #1375454

Change-Id: Ia8120e08f0358294a9ef6b4d6ecb24b1a4d34ab8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/63/124863/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/baremetal/admin/base.py'],1,8799fb2a3410029ae8705516238c46f7eec51b06,bug/1375454, cls.created_objects = {}, cls.created_objects = {},1,1
openstack%2Ftempest~master~I28f9e4862ddd42322757f5b206ddfb6ddabcfe0f,openstack/tempest,master,I28f9e4862ddd42322757f5b206ddfb6ddabcfe0f,Fix arguments for method expected_success,MERGED,2014-08-08 11:12:34.000000000,2014-10-06 07:08:05.000000000,2014-10-06 07:08:04.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6537}, {'_account_id': 7227}, {'_account_id': 8556}, {'_account_id': 8824}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-08 11:12:34.000000000', 'files': ['tempest/services/orchestration/json/orchestration_client.py', 'tempest/services/compute/xml/images_client.py', 'tempest/services/compute/json/images_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8f79850de98ea2c89c15f1f82811935dafa57c31', 'message': ""Fix arguments for method expected_success\n\nIn expected_success method we expect to get status code of\nAPI response, but we use incorrect argument 'resp' instead\nof 'resp.status' in several files.\n\nChange-Id: I28f9e4862ddd42322757f5b206ddfb6ddabcfe0f\nCloses-Bug: #1354389\n""}]",0,112828,8f79850de98ea2c89c15f1f82811935dafa57c31,33,13,1,7227,,,0,"Fix arguments for method expected_success

In expected_success method we expect to get status code of
API response, but we use incorrect argument 'resp' instead
of 'resp.status' in several files.

Change-Id: I28f9e4862ddd42322757f5b206ddfb6ddabcfe0f
Closes-Bug: #1354389
",git fetch https://review.opendev.org/openstack/tempest refs/changes/28/112828/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/orchestration/json/orchestration_client.py', 'tempest/services/compute/xml/images_client.py', 'tempest/services/compute/json/images_client.py']",3,8f79850de98ea2c89c15f1f82811935dafa57c31,," self.expected_success(200, resp.status)"," self.expected_success(200, resp)",11,11
openstack%2Fxstatic-d3~master~I71ad0b703683f79d96abf5fd2e82d5ee10b34ffc,openstack/xstatic-d3,master,I71ad0b703683f79d96abf5fd2e82d5ee10b34ffc,Add .gitreview,MERGED,2014-08-12 10:44:04.000000000,2014-10-06 06:51:45.000000000,2014-10-06 06:51:45.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4978}]","[{'number': 1, 'created': '2014-08-12 10:44:04.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/xstatic-d3/commit/a66ea9768832b4d53f35a33265a3a4e94eec3cf9', 'message': 'Add .gitreview\n\nChange-Id: I71ad0b703683f79d96abf5fd2e82d5ee10b34ffc\n'}]",0,113487,a66ea9768832b4d53f35a33265a3a4e94eec3cf9,8,3,1,8648,,,0,"Add .gitreview

Change-Id: I71ad0b703683f79d96abf5fd2e82d5ee10b34ffc
",git fetch https://review.opendev.org/openstack/xstatic-d3 refs/changes/87/113487/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,a66ea9768832b4d53f35a33265a3a4e94eec3cf9,,[gerrit] host=review.openstack.org port=29418 project=stackforge/xstatic-d3.git ,,4,0
openstack%2Fxstatic-bootstrap-datepicker~master~I6936503281719198fab6a97a5093906aef9198bc,openstack/xstatic-bootstrap-datepicker,master,I6936503281719198fab6a97a5093906aef9198bc,Add .gitreview,MERGED,2014-08-13 13:53:48.000000000,2014-10-06 06:39:42.000000000,2014-10-06 06:39:41.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4978}]","[{'number': 1, 'created': '2014-08-13 13:53:48.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/xstatic-bootstrap-datepicker/commit/63c33bc22103ee8583ce943f02a44e5d63fc4b1c', 'message': 'Add .gitreview\n\nChange-Id: I6936503281719198fab6a97a5093906aef9198bc\n'}]",0,113895,63c33bc22103ee8583ce943f02a44e5d63fc4b1c,8,3,1,8648,,,0,"Add .gitreview

Change-Id: I6936503281719198fab6a97a5093906aef9198bc
",git fetch https://review.opendev.org/openstack/xstatic-bootstrap-datepicker refs/changes/95/113895/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,63c33bc22103ee8583ce943f02a44e5d63fc4b1c,(detached,[gerrit] host=review.openstack.org port=29418 project=stackforge/xstatic-bootstrap-datepicker.git ,,4,0
openstack%2Fxstatic-angular~master~I8fead4a56481e3c86f2619802dd40a8f4d8bad9d,openstack/xstatic-angular,master,I8fead4a56481e3c86f2619802dd40a8f4d8bad9d,Add a .gitreview file,MERGED,2014-08-11 13:37:38.000000000,2014-10-06 06:38:26.000000000,2014-10-06 06:38:26.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4978}]","[{'number': 1, 'created': '2014-08-11 13:37:38.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/ba017c3aed3a9ba5f1959050684891a56593df08', 'message': 'Add a .gitreview file\n\nSo that we can easily push patches for review to gerrit.\n\nChange-Id: I8fead4a56481e3c86f2619802dd40a8f4d8bad9d\n'}]",0,113256,ba017c3aed3a9ba5f1959050684891a56593df08,8,3,1,8648,,,0,"Add a .gitreview file

So that we can easily push patches for review to gerrit.

Change-Id: I8fead4a56481e3c86f2619802dd40a8f4d8bad9d
",git fetch https://review.opendev.org/openstack/xstatic-angular refs/changes/56/113256/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,ba017c3aed3a9ba5f1959050684891a56593df08,,[gerrit] host=review.openstack.org port=29418 project=stackforge/xstatic-angular.git ,,4,0
openstack%2Fneutron~master~I8a300d6da3f0d651ccf676169c2857f758fff056,openstack/neutron,master,I8a300d6da3f0d651ccf676169c2857f758fff056,L7 capability extension implementation for lbaas v2,ABANDONED,2014-08-04 12:39:02.000000000,2014-10-06 06:38:00.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6447}, {'_account_id': 6951}, {'_account_id': 7398}, {'_account_id': 8446}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9897}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11685}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-08-04 12:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14edc175d0505d013c864507b97baeadb2560d0c', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis is WIP\nMissing Unit testing for extension and db model\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 2, 'created': '2014-08-04 13:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a779b4cf02bb8a014da77c18b2ed0c3edf4596b', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis is WIP\nMissing Unit testing for extension and db model\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 3, 'created': '2014-08-05 15:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e3b3a06e4fb17bab67dab4f75ef20df3a3269a2', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis is WIP\nSome unit tests were added\nMissing more unit testing\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 4, 'created': '2014-08-07 13:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/991bef8c98816190921130c7aafaa32d52aea639', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis is WIP\nSome unit tests were added\nMissing more unit testing\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 5, 'created': '2014-08-13 14:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c752ed3e777ee118c4d11dd8e524f776eae058db', 'message': 'L7 capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\nIncluding unit testing\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 6, 'created': '2014-08-14 06:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/acf4c524747d645876f55a8d4fbf70548face3a1', 'message': 'L7 capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\nIncluding unit testing\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}, {'number': 7, 'created': '2014-08-16 19:21:05.000000000', 'files': ['neutron/db/loadbalancer/models.py', 'neutron/services/loadbalancer/data_models.py', 'neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/db/migration/alembic_migrations/versions/f70aef653b1_lbaas_l7.py', 'neutron/services/loadbalancer/constants.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a20b29ac870c858bd80473cff97c06c58df5ba35', 'message': 'L7 capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding alembic migration\nIncluding new driver managers for l7 rules and policies\nIncluding unit testing\n\nChange-Id: I8a300d6da3f0d651ccf676169c2857f758fff056\nImplements: blueprint lbaas-l7-rules\n'}]",14,111706,a20b29ac870c858bd80473cff97c06c58df5ba35,147,30,7,8446,,,0,"L7 capability extension implementation for lbaas v2

Including extension and db model modifications
Including alembic migration
Including new driver managers for l7 rules and policies
Including unit testing

Change-Id: I8a300d6da3f0d651ccf676169c2857f758fff056
Implements: blueprint lbaas-l7-rules
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/111706/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/db/migration/alembic_migrations/versions/f70aef653b1_lbaas_l7.py', 'neutron/services/loadbalancer/constants.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/services/loadbalancer/plugin.py']",6,14edc175d0505d013c864507b97baeadb2560d0c,bp/lbaas-l7-rules," def create_l7policy(self, context, l7policy): l7policy = l7policy.get('l7policy') l7policy_db = super(LoadBalancerPluginv2, self).create_l7policy( context, l7policy) if l7policy_db.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, l7policy_db.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7policy.create, l7policy_db) self._activate_loadbalancer_tree( context, l7policy_db.listener.loadbalancer) else: self.update_status(context, ldbv2.L7Policy, l7policy_db.id, constants.DEFERRED) return l7policy_db.to_dict() def update_l7policy(self, context, id, l7policy): l7policy = l7policy.get('l7policy') old_ctx = self._duplicate_context(context) old_l7policy = super(LoadBalancerPluginv2, self).get_l7policy( old_ctx, id) self.test_and_set_status(context, ldbv2.L7Policy, id, constants.PENDING_UPDATE) try: updated_l7policy = \ super(LoadBalancerPluginv2, self).update_l7policy( context, id, l7policy) except Exception as exc: self.update_status(context, ldbv2.L7Policy, id, old_l7policy.status) raise exc if (updated_l7policy.attached_to_loadbalancer() or old_l7policy.attached_to_loadbalancer()): if updated_l7policy.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, updated_l7policy.listener.loadbalancer_id) else: driver = self._get_driver_for_loadbalancer( context, old_l7policy.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7policy.update, updated_l7policy, old_db_entity=old_l7policy) else: self.update_status(context, ldbv2.L7Policy, id, constants.DEFERRED) return updated_l7policy.to_dict() def _delete_db_l7policy(self, context, id): super(LoadBalancerPluginv2, self).delete_l7policy(context, id) def delete_l7policy(self, context, id): self.test_and_set_status(context, ldbv2.L7Policy, id, constants.PENDING_DELETE) l7policy_db = super(LoadBalancerPluginv2, self).get_l7policy( context, id) if l7policy_db.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, l7policy_db.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7policy.delete, l7policy_db) else: super(LoadBalancerPluginv2, self).delete_l7policy(context, id) def get_l7policies(self, context, filters=None, fields=None): l7policies = super(LoadBalancerPluginv2, self).get_l7policies( context, filters=filters) return [self._fields(l7policy.to_dict(), fields) for l7policy in l7policies] def get_l7policy(self, context, id, fields=None): l7policy_db = super(LoadBalancerPluginv2, self).get_l7policy( context, id) return self._fields(l7policy_db.to_dict(l7_rules=True), fields) def create_l7rule(self, context, l7rule): l7rule = l7rule.get('l7rule') l7rule_db = super(LoadBalancerPluginv2, self).create_l7rule( context, l7rule) if l7rule_db.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, l7rule_db.l7policy.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7rule.create, l7rule_db) self._activate_loadbalancer_tree( context, l7rule_db.listener.loadbalancer) else: self.update_status(context, ldbv2.L7Rule, l7rule_db.id, constants.DEFERRED) return l7rule_db.to_dict() def update_l7rule(self, context, id, l7rule): l7rule = l7rule.get('l7rule') old_ctx = self._duplicate_context(context) old_l7rule = super(LoadBalancerPluginv2, self).get_l7rule( old_ctx, id) self.test_and_set_status(context, ldbv2.L7Rule, id, constants.PENDING_UPDATE) try: updated_l7rule = super(LoadBalancerPluginv2, self).update_l7rule( context, id, l7rule) except Exception as exc: self.update_status(context, ldbv2.L7Rule, id, old_l7rule.status) raise exc if (updated_l7rule.attached_to_loadbalancer() or old_l7rule.attached_to_loadbalancer()): if updated_l7rule.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, updated_l7rule.l7policy.listener.loadbalancer_id) else: driver = self._get_driver_for_loadbalancer( context, old_l7rule.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7rule.update, updated_l7rule, old_db_entity=old_l7rule) else: self.update_status(context, ldbv2.L7Rule, id, constants.DEFERRED) return updated_l7rule.to_dict() def _delete_db_l7rule(self, context, id): super(LoadBalancerPluginv2, self).delete_l7rule(context, id) def delete_l7rule(self, context, id): self.test_and_set_status(context, ldbv2.L7Rule, id, constants.PENDING_DELETE) l7rule_db = super(LoadBalancerPluginv2, self).get_l7rule( context, id) if l7rule_db.attached_to_loadbalancer(): driver = self._get_driver_for_loadbalancer( context, l7rule_db.l7policy.listener.loadbalancer_id) self._call_driver_operation(context, driver.l7rule.delete, l7rule_db) else: super(LoadBalancerPluginv2, self).delete_l7rule(context, id) def get_l7rules(self, context, filters=None, fields=None): l7rules = super(LoadBalancerPluginv2, self).get_l7rules( context, filters=filters) return [self._fields(l7rule.to_dict(), fields) for l7rule in l7rules] def get_l7rule(self, context, id, fields=None): l7rule_db = super(LoadBalancerPluginv2, self).get_l7rule( context, id) return self._fields(l7rule_db.to_dict(), fields) ",,546,3
openstack%2Fneutron~master~I7615cdd5eb8cc9733f5db62c687c04682563fecd,openstack/neutron,master,I7615cdd5eb8cc9733f5db62c687c04682563fecd,TLS capability extension implementation for lbaas v2,ABANDONED,2014-07-23 16:49:10.000000000,2014-10-06 06:36:22.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6447}, {'_account_id': 6951}, {'_account_id': 7249}, {'_account_id': 7398}, {'_account_id': 8446}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9461}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9897}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10750}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 12040}, {'_account_id': 12614}]","[{'number': 1, 'created': '2014-07-23 16:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70495f7c1dea5f7611c844a4bb5285d9e7b2a261', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis is WIP\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 2, 'created': '2014-07-24 10:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd1a624d03593845a0c4cd98dc336d4861bdfb8a', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis is WIP\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 3, 'created': '2014-07-24 11:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4fc719d711a66777b94a9af52a3805025c3b232a', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis is WIP\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 4, 'created': '2014-07-28 08:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83dc6e6d72c97c70ad7ce96d6e03d3edab882eb0', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis is WIP\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 5, 'created': '2014-07-29 08:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc8fae8a48ca054d9525b3fafd51d944eb97d9d1', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis is WIP\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 6, 'created': '2014-07-29 11:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/397a62a2e686664e8041fcc07675f6e8fb9aa93f', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 7, 'created': '2014-07-30 10:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5310dc95811b389ed5bda91650f1fcc539462c75', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 8, 'created': '2014-07-31 10:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2604ce8d9d0b427be996d4bbeb7fd0c4e6ba6907', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 9, 'created': '2014-07-31 10:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d7d74f651dd75a4f9f4a3458e0696937fc7ecba', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 10, 'created': '2014-07-31 11:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9cacff921d4d64b318a3de2bead936b618dd077', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 11, 'created': '2014-07-31 13:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13a0b3618c1c9cb7ee4a7d961ea6e70f82dfcb98', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 12, 'created': '2014-07-31 15:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1444efe6bf663d6e8a0a0c70c43c4209386fb259', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 13, 'created': '2014-08-02 14:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e97621ab21394f20bec1a5b1777e388ea8fc63df', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 14, 'created': '2014-08-06 13:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52a18faffa98b1f16534fc92e24e234b5976b146', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 15, 'created': '2014-08-13 08:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4aa8458c6c7ff727589ab22d1728d2495585a5a', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 16, 'created': '2014-08-13 09:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1416b7b0da6aa7f6934575a5de7f207cacd1e17b', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 17, 'created': '2014-08-13 10:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7d1f6ce923a860a26723769968ecec83ea6a7d9', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}, {'number': 18, 'created': '2014-08-16 19:20:07.000000000', 'files': ['neutron/db/loadbalancer/models.py', 'neutron/services/loadbalancer/data_models.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/constants.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9886019c87f909575b2c151cdaa50ae81b72a71', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\n'}]",46,109035,e9886019c87f909575b2c151cdaa50ae81b72a71,325,38,18,8446,,,0,"TLS capability extension implementation for lbaas v2

Including extension and db model modifications
Including db model unit testing
Including alembic migration
Including usage of new common module for Barbican TLS containers API interaction

Change-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd
Implements: blueprint lbaas-ssl-termination
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/109035/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/constants.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py']",5,70495f7c1dea5f7611c844a4bb5285d9e7b2a261,bp/lbaas-ssl-termination,"from neutron.openstack.common import uuidutils 'connection_limit', 'admin_state_up', 'default_tls_container_id', 'sni_container_ids') def test_create_listener_with_tls_no_default_container(self, **extras): listener_data = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': None, 'protocol_port': 443, 'admin_state_up': True, 'tenant_id': self._tenant_id, 'status': constants.DEFERRED } listener_data.update(extras) ctx = context.get_admin_context() self.assertRaises( loadbalancerv2.TLSDefaultContainerNotSpecified, self.plugin.create_listener, ctx, {'listener': listener_data}) def test_create_listener_with_tls(self, **extras): default_tls_container_id = uuidutils.generate_uuid() sni_tls_container_id_1 = uuidutils.generate_uuid() sni_tls_container_id_2 = uuidutils.generate_uuid() expected = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': default_tls_container_id, 'sni_container_ids': [sni_tls_container_id_1, sni_tls_container_id_2] } extras['default_tls_container_id'] = default_tls_container_id extras['sni_container_ids'] = [sni_tls_container_id_1, sni_tls_container_id_2] with self.listener(protocol=lb_const.PROTOCOL_TERMINATED_HTTPS, **extras) as listener: self.assertEqual( dict((k, v) for k, v in listener['listener'].items() if k in expected), expected ) def test_update_listener_with_tls(self): default_tls_container_id = uuidutils.generate_uuid() sni_tls_container_id_1 = uuidutils.generate_uuid() sni_tls_container_id_2 = uuidutils.generate_uuid() sni_tls_container_id_3 = uuidutils.generate_uuid() sni_tls_container_id_4 = uuidutils.generate_uuid() listener_data = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': default_tls_container_id, 'sni_container_ids': [sni_tls_container_id_1, sni_tls_container_id_2], 'protocol_port': 443, 'admin_state_up': True, 'tenant_id': self._tenant_id, } listener = self.plugin.create_listener(context.get_admin_context(), {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_1, sni_tls_container_id_2]) listener_data['sni_container_ids'] = [sni_tls_container_id_3, sni_tls_container_id_4] listener = self.plugin.update_listener(context.get_admin_context(), listener['id'], {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_3, sni_tls_container_id_4]) listener_data['sni_container_ids'] = [sni_tls_container_id_4, sni_tls_container_id_3] listener = self.plugin.update_listener(context.get_admin_context(), listener['id'], {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_4, sni_tls_container_id_3]) "," 'connection_limit', 'admin_state_up')",275,2
openstack%2Fopenstack-manuals~master~I41d704cb55c6945e5813e75d1aafc345f72ce478,openstack/openstack-manuals,master,I41d704cb55c6945e5813e75d1aafc345f72ce478,Imported Translations from Transifex,MERGED,2014-10-06 06:09:08.000000000,2014-10-06 06:35:58.000000000,2014-10-06 06:35:58.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-06 06:09:08.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87035600ddd3e64278ab29a180ca257dde971915', 'message': 'Imported Translations from Transifex\n\nChange-Id: I41d704cb55c6945e5813e75d1aafc345f72ce478\n'}]",0,126218,87035600ddd3e64278ab29a180ca257dde971915,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I41d704cb55c6945e5813e75d1aafc345f72ce478
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/126218/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po']",6,87035600ddd3e64278ab29a180ca257dde971915,transifex/translations,"""POT-Creation-Date: 2014-10-06 03:14+0000\n"" ""PO-Revision-Date: 2014-10-05 09:50+0000\n""msgid ""netapp_raid_type""#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml29(td)msgid ""netapp_disk_type""#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml28(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml28(para) msgid """" ""Please note that this extra spec has a colon (<literal>:</literal>) in its "" ""name because it is used by the driver to assign the QoS policy group to the "" ""OpenStack Block Storage volume after it has been provisioned."" msgstr """" #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml30(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml33(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml34(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml39(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml44(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml49(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml54(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml59(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml64(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml69(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml35(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml38(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml38(para) msgid """" ""In the Juno release, these negative-assertion extra specs are formally "" ""deprecated by the NetApp unified driver. Instead of using the deprecated "" ""negative-assertion extra specs (for example, "" ""<option>netapp_unmirrored</option>) with a value of <literal>true</literal>,"" "" use the corresponding positive-assertion extra spec (for example, "" ""<option>netapp_mirrored</option>) with a value of <literal>false</literal>."" msgstr """" #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml40(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml43(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml45(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml48(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml50(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml53(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml55(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml58(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml60(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml63(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml65(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml68(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml70(td)","""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:43+0000\n""msgid ""netapp:raid_type""#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml30(td)msgid ""netapp:disk_type""#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml29(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml31(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml36(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml36(para) msgid """" ""If both the positive and negative specs for a pair are specified (for "" ""example, <literal>netapp_dedup</literal> and "" ""<literal>netapp_nodedup</literal>) and set to the same value within a single"" "" <literal>extra_specs</literal> list, then neither spec will be utilized by "" ""the driver."" msgstr """" #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml37(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml42(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml47(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml52(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml57(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml62(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml67(td) #: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml72(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml38(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml41(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml43(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml46(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml48(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml51(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml53(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml56(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml58(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml61(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml63(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml66(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml68(td)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml71(literal)#: ./doc/common/tables/cinder-netapp_cdot_extraspecs.xml73(td)",700,634
openstack%2Fironic~master~I23582dd608c436159979a9519573397ee4035a3a,openstack/ironic,master,I23582dd608c436159979a9519573397ee4035a3a,Remove ironic.conf.sample,ABANDONED,2014-07-11 20:59:01.000000000,2014-10-06 05:30:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-07-11 20:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c51f578fcdb0d5cae0912696af0f586acf37ee6d', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\ntoo, also a README file is added to the place of the config sample to document\nthis change.\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 2, 'created': '2014-07-11 21:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06dff3dee0336c33becd8adaac36dd5ac5a29008', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\ntoo, also a README file is added to the place of the config sample to document\nthis change.\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 3, 'created': '2014-07-11 21:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/87f50c422b667b55e14814310955711088a05999', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\ntoo, also a README file is added to the place of the config sample to document\nthis change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 4, 'created': '2014-07-11 21:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e1cd13158625ca49c695d93805f04bdd1777f3f3', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\nand ceilometer projecdts too, also a README file is added to the place of the\nconfig sample to document this change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 5, 'created': '2014-07-11 21:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/87e24866a6079fab05608bcbf809692cc03b3a7f', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\nand ceilometer projects too, also a README file is added to the place of the\nconfig sample to document this change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 6, 'created': '2014-07-11 21:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/37ee80af05fc2c155f859da0cdafce49291c2291', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing always. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\nand ceilometer projects too, also a README file is added to the place of the\nconfig sample to document this change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 7, 'created': '2014-09-03 01:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b95b5f8615fc307ead01f763360eb4fb21005468', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing always. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\nand ceilometer projects too, also a README file is added to the place of the\nconfig sample to document this change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}, {'number': 8, 'created': '2014-09-06 00:34:44.000000000', 'files': ['.gitignore', 'etc/ironic/README-ironic.conf.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d76aeb8eefdd2183e9ed85359ceb5d5afcef8813', 'message': 'Remove ironic.conf.sample\n\nironic.conf.sample mismatch issue makes the gate failing always. This patch\nremoves the checkupdate.sh test from tox.ini, like it was removed from nova\nand ceilometer projects too, also a README file is added to the place of the\nconfig sample to document this change.\n\nReferences from Nova and Ceilometer projects:\nhttps://review.openstack.org/#/c/81588/\nhttps://review.openstack.org/#/c/83164/\nhttps://review.openstack.org/#/c/88560/\n\nChange-Id: I23582dd608c436159979a9519573397ee4035a3a\n'}]",2,106493,d76aeb8eefdd2183e9ed85359ceb5d5afcef8813,39,8,8,8106,,,0,"Remove ironic.conf.sample

ironic.conf.sample mismatch issue makes the gate failing always. This patch
removes the checkupdate.sh test from tox.ini, like it was removed from nova
and ceilometer projects too, also a README file is added to the place of the
config sample to document this change.

References from Nova and Ceilometer projects:
https://review.openstack.org/#/c/81588/
https://review.openstack.org/#/c/83164/
https://review.openstack.org/#/c/88560/

Change-Id: I23582dd608c436159979a9519573397ee4035a3a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/93/106493/8 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'etc/ironic/README-ironic.conf.txt', 'tox.ini']",3,c51f578fcdb0d5cae0912696af0f586acf37ee6d,remove-sample-conf,, {toxinidir}/tools/config/check_uptodate.sh,4,1000
openstack%2Fpython-novaclient~master~I97cd18a8451dc515c5fb19841f11d0e85bd0b484,openstack/python-novaclient,master,I97cd18a8451dc515c5fb19841f11d0e85bd0b484,Show 'state' and 'status' in hypervisor-list,MERGED,2014-10-02 10:32:33.000000000,2014-10-06 04:58:36.000000000,2014-10-06 04:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-10-02 10:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fbcef026ea188d9576e454cd34b26fc0a277b38d', 'message': ""Show 'state' and 'status' in hypervisor-list\n\nCurrently hypervisor-list only shows 'ID' and 'Hypervisor hostname',\nbut in fact nova server response also contains 'state' and 'status'\nattributes, it's better to show all the attributes.\n\nChange-Id: I97cd18a8451dc515c5fb19841f11d0e85bd0b484\nClose-Bugs:#1376664\n""}, {'number': 2, 'created': '2014-10-02 23:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/49652021b8a16ea78adf9ffe2633667cc8657372', 'message': ""Show 'state' and 'status' in hypervisor-list\n\nCurrently hypervisor-list only shows 'ID' and 'Hypervisor hostname',\nbut in fact nova server response also contains 'state' and 'status'\nattributes, it's better to show all the attributes.\n\nChange-Id: I97cd18a8451dc515c5fb19841f11d0e85bd0b484\nClose-Bug: #1376664\n""}, {'number': 3, 'created': '2014-10-03 00:43:54.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/9d5164aceea3a922a3df1bdac1310a48ed50f3e9', 'message': ""Show 'state' and 'status' in hypervisor-list\n\nCurrently hypervisor-list only shows 'ID' and 'Hypervisor hostname',\nbut in fact nova server response also contains 'state' and 'status'\nattributes, it's better to show all the attributes.\n\nChange-Id: I97cd18a8451dc515c5fb19841f11d0e85bd0b484\nCloses-Bug: #1376664\n""}]",2,125588,9d5164aceea3a922a3df1bdac1310a48ed50f3e9,15,5,3,6348,,,0,"Show 'state' and 'status' in hypervisor-list

Currently hypervisor-list only shows 'ID' and 'Hypervisor hostname',
but in fact nova server response also contains 'state' and 'status'
attributes, it's better to show all the attributes.

Change-Id: I97cd18a8451dc515c5fb19841f11d0e85bd0b484
Closes-Bug: #1376664
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/88/125588/2 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,fbcef026ea188d9576e454cd34b26fc0a277b38d,hypervisor-list," columns = ['ID', 'Hypervisor hostname', 'state', 'status']"," columns = ['ID', 'Hypervisor hostname']",1,1
openstack%2Ftempest~master~If3c9b82f85095eeb22bbf32841be534024213567,openstack/tempest,master,If3c9b82f85095eeb22bbf32841be534024213567,Add tempest post-run cleanup script,MERGED,2014-08-07 13:54:51.000000000,2014-10-06 04:51:51.000000000,2014-10-04 00:05:10.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9533}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10644}]","[{'number': 1, 'created': '2014-08-07 13:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/817c823580df630538487b99339e8043b1a205da', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 2, 'created': '2014-08-07 17:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1a6ae6e0ea05ba88fc18d3025926b8fe2fd25063', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 3, 'created': '2014-08-07 18:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6ce658d06fda1fe7a208957ce200655afdc65682', 'message': ""Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nAdded TenantManager Manager object in clients that uses\n **kwargs for its credentials so it can accept any username,\npassword an tenant_name combination for managing any\ntenant's objects\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n""}, {'number': 4, 'created': '2014-09-18 22:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/050966393b2b64a43f61724d86657ecb236b9e7a', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 5, 'created': '2014-09-18 22:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/755f367b6c7a3c49105dbfb049cb80d08b649ef3', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 6, 'created': '2014-09-19 13:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8c729d6f07f6bedafc70291d937d9687f34c81f', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 7, 'created': '2014-09-19 14:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/efee24cb01e92fbe952ceb75e9b8db74875cd921', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 8, 'created': '2014-09-19 20:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee1feea3cfce5d6aee4a43bfa5dc0939aa23c361', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 9, 'created': '2014-09-19 21:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/757d33ce772b98a11145cbf002f29f3755f2acc9', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 10, 'created': '2014-09-26 01:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5d705054dcfa848f756c4dd17a2b324faacc9b77', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 11, 'created': '2014-09-26 01:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/37ee71c2fa4a65d2c9446110bef8ea44becdaf7a', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}, {'number': 12, 'created': '2014-09-26 01:43:04.000000000', 'files': ['tempest/cmd/cleanup.py', 'doc/source/index.rst', 'tempest/cmd/cleanup_service.py', 'doc/source/cleanup.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce781498cf65c423c44fb75084785d3be75a7e5b', 'message': 'Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nChange-Id: If3c9b82f85095eeb22bbf32841be534024213567\nImplements: blueprint post-run-cleanup\n'}]",28,112581,ce781498cf65c423c44fb75084785d3be75a7e5b,55,12,12,10644,,,0,"Add tempest post-run cleanup script

Implemented all features defined in blueprint.

Change-Id: If3c9b82f85095eeb22bbf32841be534024213567
Implements: blueprint post-run-cleanup
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/112581/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/cleanup.py'],1,817c823580df630538487b99339e8043b1a205da,bp/post-run-cleanup,"#!/usr/bin/env python # # Copyright 2014 Dell Inc. # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Utility for cleaning up environment after running Tempest. @author: David Paterson --init-saved-state: Before you can execute cleanup you must initialize the saved state by running it with the --init-saved-state flag (creating ./saved_state.json), which protects your deployment from cleanup deleting objects you want to keep. Typically you would run cleanup with --init-saved-state prior to a tempest run. If this is not the case saved_state.json must be edited, removing objects you want cleanup to delete. --dry-run: Creates a report (dry_run.json) of the tenants that will be cleaned up (in the ""_tenants_to_clean"" array), and the global objects that will be removed (tenants, users, flavors and images). Once cleanup is executed in normal mode, running it again with --dry-run should yield an empty report. NOTE: The _tenants_to_clean array in dry-run.json lists the tenants that cleanup will loop through and delete child objects, not delete the tenant itself. This may differ from the tenants array as you can clean the tempest and alternate tempest tenants but not delete the tenants themselves. This is actually the default behavior. Normal mode: running with no arguments, will query your deployment and build a list of objects to delete after filtering out out the objects found in saved_state.json and based on the --preserve-tempest-tenants-and-users and --delete-tempest-users-and-tenants flags. By default the tempest and alternate tempest users and tenants are not deleted and the admin user specified in tempest.conf is never deleted. Please run with --help to see full list of options. Plugins ======= The cleanup script has a plugable interface which allows creation of custom cleanup tasks to be called via the --plugins argument. The convention/interface for building a cleanup plugin is as follows: Create a subdirectory under ./cleanup_plugins with the plugin name. Then create a module and class using the following convention: ./cleanup_plugins [plugin_name]/ [plugin_name]_cleanup.py [Plugin_name]CleanupPlugin <--class name convention. Example plugin with name 'db' ./cleanup_plugins db/ db_cleanup.py DbCleanupPlugin <--class name convention. The cleanup class must implement the following methods from abstract class CleanupPluginABC: def __run__(self): @staticmethod def init_options(parser): init_options() adds any arguments the plugin needs to the main argument parser. """""" import argparse import imp import inspect import json import os import sys from tempest import clients from tempest import config from tempest.openstack.common import log as logging SAVED_STATE_JSON = ""saved_state.json"" DRY_RUN_JSON = ""dry_run.json"" LOG = logging.getLogger(__name__) CONF = config.CONF PLUGIN_DIR = ""./cleanup_plugins"" MAIN_SUFFIX = ""_cleanup"" class Cleanup(object): def __init__(self): self.admin_manager = clients.AdminManager() self.users = {} self.tenants = {} self.flavors = {} self.images = {} self.init_options() self.admin_id = """" self.admin_role_id = """" self.admin_tenant_id = """" self.init_admin_ids() def init_admin_ids(self): tenant = self.admin_manager.identity_client \ .get_tenant_by_name(CONF.identity.admin_tenant_name) self.admin_tenant_id = tenant['id'] user = self.admin_manager.identity_client \ .get_user_by_username(self.admin_tenant_id, CONF.identity.admin_username) self.admin_id = user['id'] _, roles = self.admin_manager.identity_client.list_roles() for role in roles: if role['name'] == CONF.identity.admin_role: self.admin_role_id = role['id'] break def init_options(self): parser = argparse \ .ArgumentParser(description='Cleanup after tempest run') parser.add_argument('--init-saved-state', action=""store_true"", dest='init_saved_state', default=False, help=""Creates JSON file: "" + SAVED_STATE_JSON + "", representing the current state of your "" + ""deployment, specifically objects types "" + ""Tempest creates and destroys during a run. "" + ""You must run with this flag prior to "" + ""executing cleanup."") parser.add_argument('--preserve-tempest-users-and-tenants', action=""store_true"", dest='preserve_tempest_users_and_tenants', default=True, help=""Do not delete the "" + ""tempest and alternate tempest users and "" + ""tenants, so they may be used for future "" + ""tempest runs. By default this is argument "" + ""is true."") parser.add_argument('--delete-tempest-users-and-tenants', action=""store_false"", dest='preserve_tempest_users_and_tenants', default=False, help=""Delete the tempest and "" + ""alternate tempest users and tenants."") parser.add_argument('--plugins', action=""store"", nargs=""*"", dest='plugins', default=None, help=""Run specified cleanup plugins"") parser.add_argument('--dry-run', action=""store_true"", dest='dry_run', default=False, help=""Generate JSON file:"" + DRY_RUN_JSON + "", that reports the objects that would have "" + ""been deleted had a full cleanup been run."") if (os.path.exists(PLUGIN_DIR)): self.get_plugin_group_arguments(parser) self.options = parser.parse_args() def run(self): opts = self.options if opts.init_saved_state: self.init_state() return if opts.plugins is not None: self.run_plugins() else: self.load_json() self.cleanup() def cleanup(self): LOG.debug(""Begin cleanup"") is_dry_run = self.options.dry_run if is_dry_run: dry_run_data = {} dry_run_data[""_tenants_to_clean""] = {} f = open(DRY_RUN_JSON, 'w+') admin_manager = self.admin_manager _, tenants = admin_manager.identity_client.list_tenants() _, users = admin_manager.identity_client.get_users() _, flavors = admin_manager.flavors_client.list_flavors() _, images = admin_manager.images_client \ .list_images({""all_tenants"": True}) tempest_users = [CONF.identity.admin_username, CONF.identity.username, CONF.identity.alt_username] tempest_tenants = [CONF.identity.admin_tenant_name, CONF.identity.tenant_name, CONF.identity.alt_tenant_name] # recreate list removing saved users users[:] = [user for user in users if user['id'] not in self.users.keys()] LOG.debug(""Users after reconcile: %s users"" % users) # recreate list removing saved flavors flavors[:] = [flavor for flavor in flavors if flavor['id'] not in self.flavors.keys()] LOG.debug(""Flavors after reconcile: %s"" % flavors) # recreate list removing saved images images[:] = [image for image in images if image['id'] not in self.images.keys()] LOG.debug(""Images after reconcile: %s"" % images) # recreate list removing saved tenants tenants[:] = [tenant for tenant in tenants if tenant['id'] not in self.tenants.keys()] LOG.debug(""Tenants after reconcile: %s"" % tenants) # Loop through list of tenants and clean them up. for tenant in tenants: tenant_id = tenant['id'] self.add_admin(tenant_id) LOG.debug(""Cleaning tenant: %s "" % tenant['name']) kwargs = {""username"": CONF.identity.admin_username, ""password"": CONF.identity.admin_password, ""tenant_name"": tenant['name']} mgr = clients.TenantManager(**kwargs) # We have to delete snapshots first or # volume deletion may fail __, snaps = mgr.snapshots_client.list_snapshots() LOG.debug(""Remove %s snapshots"" % len(snaps)) _, servers_body = mgr.servers_client.list_servers() servers = servers_body['servers'] LOG.debug(""Remove %s servers"" % len(servers)) _, stacks = mgr.orchestration_client.list_stacks() LOG.debug(""Remove %s stacks"" % len(stacks)) _, keypairs = mgr.keypairs_client.list_keypairs() LOG.debug(""Remove %s keypairs"" % len(keypairs)) _, secgrp = mgr.security_groups_client.list_security_groups() secgrp_del = [grp for grp in secgrp if grp['name'] != 'default'] LOG.debug(""Remove %s Security Groups"" % len(secgrp_del)) _, floating_ips = mgr.floating_ips_client.list_floating_ips() LOG.debug(""Remove %s floating IPs"" % len(floating_ips)) _, vols = mgr.volumes_client.list_volumes() LOG.debug(""Remove %s volumes"" % len(vols)) if is_dry_run: dry_run_data[""_tenants_to_clean""][tenant_id] = \ {""name"": tenant['name'], ""snapshots"": snaps, ""servers"": servers, ""stacks"": stacks, ""keypairs"": keypairs, ""security_groups"": secgrp_del, ""floating_ips"": floating_ips, ""volumes"": vols} else: for snap in snaps: try: mgr.snapshots_client.delete_snapshot(snap['id']) except Exception as e: LOG.exception(""Delete snapshot exception: %s"" % e) pass for srv in servers: try: admin_manager.servers_client.delete_server(srv['id']) except Exception as e: LOG.exception(""Delete server exception: %s"" % e) pass for stack in stacks: try: LOG.info(""Delete stack: %s "" % stack) mgr.orchestration_client.delete_stack(stack['id']) except Exception as e: LOG.exception(""Delete stack exception: %s "" % e) pass for k in keypairs: try: name = k['keypair']['name'] resp, body = mgr.keypairs_client.delete_keypair(name) except Exception as e: LOG.exception(""Delete keypairs exception: %s"" % e) pass for g in secgrp_del: try: mgr.secgrp_client.delete_security_group(g['id']) except Exception as e: LOG.exception(""Delete security groups "" + ""exception: %s"" % e) pass for f in floating_ips: try: mgr.floating_ips_client.delete_floating_ip(f['id']) except Exception as e: LOG.exception(""Delete floating IPs exception: %s"" % e) pass for v in vols: try: mgr.volumes_client.delete_volume(v['id']) except Exception as e: LOG.exception(""Delete volume exception: %s"" % e) pass # By default keep the tempest and alt tempest users and tenants # Either way never delete admin user and tenant is_preserve = self.options.preserve_tempest_users_and_tenants LOG.debug(""is_preserve: %s "" % is_preserve) if is_preserve: users[:] = [user for user in users if user['name'] not in tempest_users] else: users[:] = [user for user in users if user['name'] != CONF.identity.admin_username] if is_preserve: tenants[:] = [tenant for tenant in tenants if tenant['name'] not in tempest_tenants] else: tenants[:] = [tenant for tenant in tenants if tenant['name'] != CONF.identity.admin_tenant_name] LOG.debug(""Remove %s flavors"" % len(flavors)) LOG.debug(""Remove %s images"" % len(images)) LOG.debug(""Remove %s users"" % len(users)) LOG.debug(""Remove %s tenants "" % len(tenants)) if is_dry_run: dry_run_data[""flavors""] = flavors dry_run_data[""images""] = images dry_run_data[""users""] = users dry_run_data[""tenants""] = tenants f.write(json.dumps(dry_run_data, sort_keys=True, indent=2, separators=(',', ': '))) f.close() else: for flavor in flavors: try: admin_manager.flavors_client.delete_flavor(flavor['id']) except Exception as e: LOG.exception(""Delete flavor exception: %s"" % e) pass for image in images: try: admin_manager.images_client.delete_image(image['id']) except Exception as e: LOG.exception(""Delete image exception: %s"" % e) pass for user in users: try: admin_manager.identity_client.delete_user(user['id']) except Exception as e: LOG.exception(""Delete user exception: %s"" % e) pass for tenant in tenants: try: admin_manager.identity_client.delete_tenant(tenant['id']) except Exception as e: LOG.exception(""Delete tenant exception: %s"" % e) pass def add_admin(self, tenant_id): identity_client = self.admin_manager.identity_client needs_role = True _, roles = identity_client.list_user_roles(tenant_id, self.admin_id) for role in roles: if role['id'] == self.admin_role_id: needs_role = False LOG.debug(""User already had admin privilege for this tenant"") if needs_role: identity_client.assign_user_role(tenant_id, self.admin_id, self.admin_role_id) def init_state(self): LOG.debug(""Initializing saved state."") admin_manager = self.admin_manager f = open(SAVED_STATE_JSON, 'w+') _, users = admin_manager.identity_client.get_users() for user in users: self.users[user['id']] = user['name'] _, tenants = self.admin_manager.identity_client.list_tenants() for tenant in tenants: self.tenants[tenant['id']] = tenant['name'] _, flavors = admin_manager.flavors_client.list_flavors() for flavor in flavors: self.flavors[flavor['id']] = flavor['name'] _, images = admin_manager.images_client \ .list_images({""all_tenants"": True}) for image in images: self.images[image['id']] = image['name'] LOG.debug(""users: %s"" % self.users) LOG.debug(""tenants: %s"" % self.tenants) LOG.debug(""flavors: %s"" % self.flavors) LOG.debug(""images: %s"" % self.images) f.write(json.dumps({'users': self.users, 'tenants': self.tenants, 'flavors': self.flavors, 'images': self.images}, sort_keys=True, indent=2, separators=(',', ': '))) f.close() def load_json(self): try: json_data = open(SAVED_STATE_JSON) cont = json_data.read() if cont == '': raise IOError try: data = json.load(open(SAVED_STATE_JSON)) except Exception as ex: LOG.exception(""Exception parsing saved state json : %s"" % ex) sys.exit(ex) LOG.debug(""data: %s"" % data) self.users = data[""users""] self.tenants = data[""tenants""] self.flavors = data[""flavors""] self.images = data[""images""] json_data.close() except IOError as ex: LOG.exception(""Failed loading saved state, please be sure you"" + "" have first run cleanup with --init-saved-state "" + ""flag prior to executing cleanup. Exception: %s"" % ex) sys.exit(ex) def run_plugins(self): if not os.path.exists(PLUGIN_DIR): LOG.exception(""Plugin directory does not exist: %s"" % PLUGIN_DIR) return plugins = self.get_plugins() for plugin in plugins: LOG.debug(""Plugin: %s "" % (plugin)) try: mod = imp.load_module(plugin[""name""] + MAIN_SUFFIX, *plugin[""info""]) for name, obj in inspect.getmembers(mod): if inspect.isclass(obj) and obj.__name__ \ .endswith('CleanupPlugin'): cls = obj(self.options) cls.run() except Exception as ex: LOG.exception(""Exception loading plugin class: %s "" % ex) def get_plugins(self): plugin_args = self.options.plugins plugins = [] possible_plugins = os.listdir(PLUGIN_DIR) LOG.debug(""possible_plugins: %s"" % possible_plugins) for pi in plugin_args: location = os.path.join(PLUGIN_DIR, pi) LOG.debug(""location: %s"" % location) main = pi + MAIN_SUFFIX LOG.debug(""main: %s"" % main) if not os.path.isdir(location) or not main + "".py"" \ in os.listdir(location): continue LOG.debug(""find_module(main, [location]) next, "" + ""main: %s, location: %s"" % (main, location)) info = imp.find_module(main, [location]) plugins.append({""name"": pi, ""info"": info}) LOG.debug(""found plugins: %s"" % plugins) return plugins def get_plugin_group_arguments(self, parser): possible_plugins = os.listdir(PLUGIN_DIR) for pi in possible_plugins: location = os.path.join(PLUGIN_DIR, pi) if os.path.isdir(location): main = pi + MAIN_SUFFIX info = imp.find_module(main, [location]) mod = imp.load_module(main, *info) for name, cls in inspect.getmembers(mod): if inspect.isclass(cls) and cls.__name__ \ .endswith('Plugin'): LOG.debug(""Adding plugin options for: %s"" % cls) cls.init_options(parser) def main(): cleanup = Cleanup() cleanup.run() LOG.info('Cleanup finished!') return 0 if __name__ == ""__main__"": sys.exit(main()) ",,488,0
openstack%2Fmistral-extra~master~I5e0040150242109cc7d7e895bd39735b0c738201,openstack/mistral-extra,master,I5e0040150242109cc7d7e895bd39735b0c738201,Fix markdown in README.md,MERGED,2014-10-02 10:32:36.000000000,2014-10-06 03:34:08.000000000,2014-10-06 03:34:08.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-10-02 10:32:36.000000000', 'files': ['examples/v2/vm_job/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/4d9d83c88f87476b0b7ea2238f035350e8b2dd50', 'message': 'Fix markdown in README.md\n\nChange-Id: I5e0040150242109cc7d7e895bd39735b0c738201\n'}]",0,125589,4d9d83c88f87476b0b7ea2238f035350e8b2dd50,10,6,1,7700,,,0,"Fix markdown in README.md

Change-Id: I5e0040150242109cc7d7e895bd39735b0c738201
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/89/125589/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/vm_job/README.md'],1,4d9d83c88f87476b0b7ea2238f035350e8b2dd50,," * Create an image of virtual machine * Make sure that VM has SSH server in running state * Make sure that VM has password access via SSH * Install packages (example for Debian/Ubuntu based systems) * Put *web_app.py* file into user's home directory. To check if it works, type * Save image"," # Create an image of virtual machine # Make sure that VM has SSH server in running state # Make sure that VM has password access via SSH # Install packages (example for Debian/Ubuntu based systems) # Put *web_app.py* file into user's home directory. To check if it works, type # Save image",6,6
openstack%2Fopenstack-manuals~master~Ic61554f78ad661e33e2eb6ed54d94e4a09868a21,openstack/openstack-manuals,master,Ic61554f78ad661e33e2eb6ed54d94e4a09868a21,Remove closing element that has no opening element in base HTML template,MERGED,2014-10-03 17:46:26.000000000,2014-10-06 03:14:08.000000000,2014-10-06 03:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-10-03 17:46:26.000000000', 'files': ['www/templates/base.tmpl'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9f43b7a3ae93012819f1d72f1f1cdb99e376db22', 'message': 'Remove closing element that has no opening element in base HTML template\n\nChange-Id: Ic61554f78ad661e33e2eb6ed54d94e4a09868a21\n'}]",0,126024,9f43b7a3ae93012819f1d72f1f1cdb99e376db22,7,3,1,167,,,0,"Remove closing element that has no opening element in base HTML template

Change-Id: Ic61554f78ad661e33e2eb6ed54d94e4a09868a21
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/126024/1 && git format-patch -1 --stdout FETCH_HEAD,['www/templates/base.tmpl'],1,9f43b7a3ae93012819f1d72f1f1cdb99e376db22,remove_closing_div,, </div>,0,1
openstack%2Foslo-cookiecutter~master~I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a,openstack/oslo-cookiecutter,master,I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a,Add configuration for pbr,MERGED,2014-10-01 16:41:41.000000000,2014-10-05 23:41:09.000000000,2014-10-05 23:41:08.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-10-01 16:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/3a17b203c32b75c38ec4fe4bea4ebcfa05fec43e', 'message': 'Add configuration for pbr\n\nChange-Id: I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a\n'}, {'number': 2, 'created': '2014-10-01 16:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/cb82b21f38442b3e58fb7938bf6603c549c189b9', 'message': 'Add configuration for pbr\n\nChange-Id: I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a\n'}, {'number': 3, 'created': '2014-10-05 23:38:33.000000000', 'files': ['oslo.{{cookiecutter.module_name}}/setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/fc243c877f5b9846a2b53885ec775fb46bc2c4c9', 'message': 'Add configuration for pbr\n\nChange-Id: I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a\n'}]",0,125418,fc243c877f5b9846a2b53885ec775fb46bc2c4c9,11,4,3,5638,,,0,"Add configuration for pbr

Change-Id: I9fb1a557a6bdf61d9c520e1c9218a1094a76e75a
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/18/125418/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo.{{cookiecutter.module_name}}/setup.cfg'],1,3a17b203c32b75c38ec4fe4bea4ebcfa05fec43e,,[pbr] warnerrors = true ,,3,0
openstack%2Fproject-config~master~Iddf8cdab8b0766a7b7ec6c2d4171708fd3c49685,openstack/project-config,master,Iddf8cdab8b0766a7b7ec6c2d4171708fd3c49685,Use git farm for layout job cloning,MERGED,2014-10-05 15:35:27.000000000,2014-10-05 22:56:09.000000000,2014-10-05 22:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-10-05 15:35:27.000000000', 'files': ['tools/run-layout.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4aef606a9d1bfa2f9047721091231c7d1ed951e9', 'message': ""Use git farm for layout job cloning\n\nIt has been witnessed that at least occasionally Gerrit's local\nmirror can fail to return data for a clone request. Instead clone\nthese additional projects from our awesome Git server farm.\n\nChange-Id: Iddf8cdab8b0766a7b7ec6c2d4171708fd3c49685\n""}]",0,126186,4aef606a9d1bfa2f9047721091231c7d1ed951e9,9,5,1,5263,,,0,"Use git farm for layout job cloning

It has been witnessed that at least occasionally Gerrit's local
mirror can fail to return data for a clone request. Instead clone
these additional projects from our awesome Git server farm.

Change-Id: Iddf8cdab8b0766a7b7ec6c2d4171708fd3c49685
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/126186/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/run-layout.sh'],1,4aef606a9d1bfa2f9047721091231c7d1ed951e9,git-layout,[ -d zuul ] || git clone https://git.openstack.org/openstack-infra/zuul --depth 1 [ -d jenkins-job-builder ] || git clone https://git.openstack.org/openstack-infra/jenkins-job-builder --depth 1,[ -d zuul ] || git clone https://review.openstack.org/p/openstack-infra/zuul --depth 1 [ -d jenkins-job-builder ] || git clone https://review.openstack.org/p/openstack-infra/jenkins-job-builder --depth 1,2,2
openstack%2Fsahara~master~I4eb0d00766066f0d387e632b0217e11cfed552c5,openstack/sahara,master,I4eb0d00766066f0d387e632b0217e11cfed552c5,Fix working Spark with cinder volumes,MERGED,2014-10-03 13:43:41.000000000,2014-10-05 22:21:58.000000000,2014-10-05 22:21:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-10-03 13:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/400e45346402bf4d874361d65056256c6d67bf0d', 'message': 'Fix working Spark with cinder volumes\n\nChange-Id: I4eb0d00766066f0d387e632b0217e11cfed552c5\nCloses-bug: #1376790\n'}, {'number': 2, 'created': '2014-10-03 16:09:05.000000000', 'files': ['sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/plugin.py', 'sahara/tests/unit/plugins/spark/test_config_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5aca5fe75aa94fe548fc0d481ad0a8edf7375d4f', 'message': 'Fix working Spark with cinder volumes\n\nChange-Id: I4eb0d00766066f0d387e632b0217e11cfed552c5\nCloses-bug: #1376790\n'}]",0,125970,5aca5fe75aa94fe548fc0d481ad0a8edf7375d4f,16,6,2,7710,,,0,"Fix working Spark with cinder volumes

Change-Id: I4eb0d00766066f0d387e632b0217e11cfed552c5
Closes-bug: #1376790
",git fetch https://review.opendev.org/openstack/sahara refs/changes/70/125970/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/plugin.py', 'sahara/tests/unit/plugins/spark/test_config_helper.py']",3,400e45346402bf4d874361d65056256c6d67bf0d,bug/1376790,"# Copyright (c) 2014 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from sahara.plugins.spark import config_helper as c_helper from sahara.tests.unit import base as test_base class ConfigHelperUtilsTest(test_base.SaharaTestCase): def test_make_hadoop_path(self): storage_paths = ['/mnt/one', '/mnt/two'] paths = c_helper.make_hadoop_path(storage_paths, '/spam') expected = ['/mnt/one/spam', '/mnt/two/spam'] self.assertListEqual(expected, paths) ",,34,3
openstack%2Fsecurity-doc~master~I650a9045250e818e3c870a4bdb5137566266622e,openstack/security-doc,master,I650a9045250e818e3c870a4bdb5137566266622e,Check for syntax issues in the security notes with doc8,MERGED,2014-09-01 11:31:45.000000000,2014-10-05 22:02:44.000000000,2014-10-05 22:02:43.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 2807}, {'_account_id': 6547}, {'_account_id': 9098}]","[{'number': 1, 'created': '2014-09-01 11:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bb690a13533fcf573adc6a855bbac83aa0300b47', 'message': 'Check for syntax issues in the security notes with doc8\n\nChange-Id: I650a9045250e818e3c870a4bdb5137566266622e\n'}, {'number': 2, 'created': '2014-09-29 07:11:33.000000000', 'files': ['test-requirements.txt', 'security-notes/OSSN-0007', 'security-notes/OSSN-0017', 'security-notes/OSSN-0001', 'security-notes/OSSN-0013', 'security-notes/OSSN-0010', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/76b49ba7877439223eecff6772faf04358499696', 'message': 'Check for syntax issues in the security notes with doc8\n\nChange-Id: I650a9045250e818e3c870a4bdb5137566266622e\n'}]",0,118139,76b49ba7877439223eecff6772faf04358499696,19,6,2,167,,,0,"Check for syntax issues in the security notes with doc8

Change-Id: I650a9045250e818e3c870a4bdb5137566266622e
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/39/118139/2 && git format-patch -1 --stdout FETCH_HEAD,"['security-notes/OSSN-0007', 'test-requirements.txt', 'security-notes/OSSN-0017', 'security-notes/OSSN-0001', 'tox.ini']",5,bb690a13533fcf573adc6a855bbac83aa0300b47,doc8, doc8 -e '' security-notes,,8,4
openstack%2Ffuel-library~master~I3b500a6268b391f7b63b50dc2a72952458226c69,openstack/fuel-library,master,I3b500a6268b391f7b63b50dc2a72952458226c69,Clone neutron L3 and DHCP agents in corosync,ABANDONED,2014-08-20 07:46:40.000000000,2014-10-05 21:13:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7787}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-20 07:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b2b044cd031bd919be69435efe97f0eb61124b86', 'message': 'Clone neutron L3 and DHCP agents in corosync\n\nAdjust the puppet manifests for the neutron l3 agents\nand dhcp agents to set them to cloned services in corosync.\nAll of these agents should be running all of the time\nsince they are not sharing state or offering conflicting\nservices. Without this, a single agent will be a performance\nbottleneck and a single point of failure for all tenant networks.\n\nCloses-Bug: #1359082\nChange-Id: I3b500a6268b391f7b63b50dc2a72952458226c69\n'}, {'number': 2, 'created': '2014-08-20 08:07:32.000000000', 'files': ['deployment/puppet/neutron/manifests/agents/dhcp.pp', 'deployment/puppet/neutron/manifests/agents/l3.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/addfeafd7aab25b82038a588a11409bcddf49ab1', 'message': 'Clone neutron L3 and DHCP agents in corosync\n\nAdjust the puppet manifests for the neutron l3 agents\nand dhcp agents to set them to cloned services in corosync.\nAll of these agents should be running all of the time\nsince they are not sharing state or offering conflicting\nservices. Without this, a single agent will be a performance\nbottleneck and a single point of failure for all tenant networks.\n\nCloses-Bug: #1359082\nChange-Id: I3b500a6268b391f7b63b50dc2a72952458226c69\n'}]",0,115529,addfeafd7aab25b82038a588a11409bcddf49ab1,19,5,2,7787,,,0,"Clone neutron L3 and DHCP agents in corosync

Adjust the puppet manifests for the neutron l3 agents
and dhcp agents to set them to cloned services in corosync.
All of these agents should be running all of the time
since they are not sharing state or offering conflicting
services. Without this, a single agent will be a performance
bottleneck and a single point of failure for all tenant networks.

Closes-Bug: #1359082
Change-Id: I3b500a6268b391f7b63b50dc2a72952458226c69
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/29/115529/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/neutron/manifests/agents/dhcp.pp', 'deployment/puppet/neutron/manifests/agents/l3.pp']",2,b2b044cd031bd919be69435efe97f0eb61124b86,bug/1359082," multistate_hash => { 'type' => 'clone', }, ms_metadata => { 'interleave' => 'false', },",,12,0
openstack%2Fkeystone~master~I355798d1024399aca194e826ed8048812e44612b,openstack/keystone,master,I355798d1024399aca194e826ed8048812e44612b,Switch LdapIdentitySqlAssignment to use oslo.mockpatch,MERGED,2014-10-03 12:19:42.000000000,2014-10-05 21:07:53.000000000,2014-10-05 21:07:52.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-10-03 12:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/96c0c076fb3b4b2612910a2b8db62c426c31768f', 'message': 'Typo olso -> oslo\n\nChange-Id: I355798d1024399aca194e826ed8048812e44612b\n'}, {'number': 2, 'created': '2014-10-03 13:19:35.000000000', 'files': ['keystone/tests/test_backend_ldap_pool.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2728e67850e9ad4ea64000375f303275508f30f3', 'message': 'Switch LdapIdentitySqlAssignment to use oslo.mockpatch\n\nReferenced bug has been fixed in oslotest 1.1.0\n\nChange-Id: I355798d1024399aca194e826ed8048812e44612b\n'}]",0,125951,2728e67850e9ad4ea64000375f303275508f30f3,11,6,2,5638,,,0,"Switch LdapIdentitySqlAssignment to use oslo.mockpatch

Referenced bug has been fixed in oslotest 1.1.0

Change-Id: I355798d1024399aca194e826ed8048812e44612b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/51/125951/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_backend_ldap_pool.py'],1,96c0c076fb3b4b2612910a2b8db62c426c31768f,, # after the parent setUp runs because oslotest will try to, # after the parent setUp runs because olsotest will try to,1,1
openstack%2Fdevstack~master~I60373ee5ad7445cd54c8c013085b28d82bb0d085,openstack/devstack,master,I60373ee5ad7445cd54c8c013085b28d82bb0d085,Adds qemu packages to ironic's apts,MERGED,2014-10-02 18:25:41.000000000,2014-10-05 20:12:58.000000000,2014-10-03 01:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2889}, {'_account_id': 5196}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 18:25:41.000000000', 'files': ['files/apts/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6566f21ddfb038c2eee402cdcb097f43f3480006', 'message': ""Adds qemu packages to ironic's apts\n\nNodepool images have recently migrated to being built with DIB, resulting\nin strange changes in how the package dependency chain works out.  This\nexplicitly adds required qemu packages to Ironic's apts to avoid some\nnot being pulled in by package dependencies alone.\n\nChange-Id: I60373ee5ad7445cd54c8c013085b28d82bb0d085\nCloses-bug: #1376863\n""}]",0,125732,6566f21ddfb038c2eee402cdcb097f43f3480006,15,7,1,1420,,,0,"Adds qemu packages to ironic's apts

Nodepool images have recently migrated to being built with DIB, resulting
in strange changes in how the package dependency chain works out.  This
explicitly adds required qemu packages to Ironic's apts to avoid some
not being pulled in by package dependencies alone.

Change-Id: I60373ee5ad7445cd54c8c013085b28d82bb0d085
Closes-bug: #1376863
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/125732/1 && git format-patch -1 --stdout FETCH_HEAD,['files/apts/ironic'],1,6566f21ddfb038c2eee402cdcb097f43f3480006,update_ironic_apts,qemu qemu-kvm qemu-utils,,3,0
openstack%2Fproject-config~master~I658b0b42d9a36b93946aaa9c18cb6034f93ca833,openstack/project-config,master,I658b0b42d9a36b93946aaa9c18cb6034f93ca833,Enable database Tox environments for Tuskar,ABANDONED,2014-10-03 15:42:38.000000000,2014-10-05 20:08:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-10-03 15:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/666c9f93302a299879905ecdea811cd32c6fbec1', 'message': 'Enable database Tox environments for Tuskar\n\nChange-Id: I658b0b42d9a36b93946aaa9c18cb6034f93ca833\n'}, {'number': 2, 'created': '2014-10-03 16:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/21cf9cea0f0fae8ea3d8361fe4a5506cfd0850d5', 'message': 'Enable database Tox environments for Tuskar\n\nChange-Id: I658b0b42d9a36b93946aaa9c18cb6034f93ca833\n'}, {'number': 3, 'created': '2014-10-04 11:37:41.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/bd6376cc44e7d53b8ba7691b840a83ced5cda824', 'message': 'Enable database Tox environments for Tuskar\n\nChange-Id: I658b0b42d9a36b93946aaa9c18cb6034f93ca833\n'}]",0,125997,bd6376cc44e7d53b8ba7691b840a83ced5cda824,11,3,3,9712,,,0,"Enable database Tox environments for Tuskar

Change-Id: I658b0b42d9a36b93946aaa9c18cb6034f93ca833
",git fetch https://review.opendev.org/openstack/project-config refs/changes/97/125997/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,666c9f93302a299879905ecdea811cd32c6fbec1,, check: - gate-tuskar-unittests-cover - gate-tuskar-unittests-26-sa-mysql - gate-tuskar-unittests-27-sa-mysql - gate-tuskar-unittests-26-sa-postgresql - gate-tuskar-unittests-27-sa-postgresql gate: - gate-tuskar-unittests-26-sa-mysql - gate-tuskar-unittests-27-sa-mysql - gate-tuskar-unittests-26-sa-postgresql - gate-tuskar-unittests-27-sa-postgresql,,11,0
openstack%2Fpython-neutronclient~master~I2e275bda23033034ed356e012147ce7a701d4695,openstack/python-neutronclient,master,I2e275bda23033034ed356e012147ce7a701d4695,Updated from global requirements,MERGED,2014-09-19 08:51:33.000000000,2014-10-05 18:06:40.000000000,2014-10-05 18:06:40.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 5572}, {'_account_id': 6854}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-09-19 08:51:33.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8115c02054cd52c99f670e04a58e9861a4a84f88', 'message': 'Updated from global requirements\n\nChange-Id: I2e275bda23033034ed356e012147ce7a701d4695\n'}]",0,122666,8115c02054cd52c99f670e04a58e9861a4a84f88,10,6,1,11131,,,0,"Updated from global requirements

Change-Id: I2e275bda23033034ed356e012147ce7a701d4695
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/66/122666/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,8115c02054cd52c99f670e04a58e9861a4a84f88,openstack/requirements,oslosphinx>=2.2.0 # Apache-2.0 oslotest>=1.1.0 # Apache-2.0,oslosphinx>=2.2.0.0a2 oslotest>=1.1.0.0a2,3,3
openstack%2Fopenstack-manuals~master~I0a130580764f61544f5abebdde21b677a4d0ece9,openstack/openstack-manuals,master,I0a130580764f61544f5abebdde21b677a4d0ece9,More updates for Juno,MERGED,2014-10-04 01:30:44.000000000,2014-10-05 15:01:04.000000000,2014-10-05 15:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-10-04 01:30:44.000000000', 'files': ['doc/install-guide/section_neutron-compute-node.xml', 'doc/install-guide/section_glance-install.xml', 'doc/install-guide/section_neutron-controller-node.xml', 'doc/install-guide/section_neutron-network-node.xml', 'doc/install-guide/section_nova-controller-install.xml', 'doc/install-guide/section_nova-compute-install.xml', 'doc/install-guide/section_keystone-install.xml', 'doc/install-guide/section_nova-networking-compute-node.xml', 'doc/install-guide/section_nova-networking-controller-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8ddea61d2155c64d007e5b0da1d4a1559312f83d', 'message': 'More updates for Juno\n\nI updated the installation guide for Juno as follows:\n\n1) Unifed RHEL/CentOS/Fedora steps to use systemd through\n   networking chapter. Will work on other chapters in a\n   future patch.\n2) Split openSUSE steps to use systemd.\n3) Removed database configuration from nova on compute\n   nodes (yay!).\n4) Added workaround for RDO changing the neutron default\n   ""auth_strategy=keystone"" back to ""auth_strategy=noauth"".\n5) Re-add workaround for broken RDO neutron init scripts. See\n   bug #1375746 for more information.\n6) Applied other changes for RHEL/CentOS 7.\n7) Improved nova-network content.\n8) Other minor fixes.\n\nChange-Id: I0a130580764f61544f5abebdde21b677a4d0ece9\nImplements: blueprint installation-guide-improvements\nCloses-Bug: #1287874\nCloses-Bug: #1373367\n'}]",15,126107,8ddea61d2155c64d007e5b0da1d4a1559312f83d,11,4,1,9515,,,0,"More updates for Juno

I updated the installation guide for Juno as follows:

1) Unifed RHEL/CentOS/Fedora steps to use systemd through
   networking chapter. Will work on other chapters in a
   future patch.
2) Split openSUSE steps to use systemd.
3) Removed database configuration from nova on compute
   nodes (yay!).
4) Added workaround for RDO changing the neutron default
   ""auth_strategy=keystone"" back to ""auth_strategy=noauth"".
5) Re-add workaround for broken RDO neutron init scripts. See
   bug #1375746 for more information.
6) Applied other changes for RHEL/CentOS 7.
7) Improved nova-network content.
8) Other minor fixes.

Change-Id: I0a130580764f61544f5abebdde21b677a4d0ece9
Implements: blueprint installation-guide-improvements
Closes-Bug: #1287874
Closes-Bug: #1373367
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/126107/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/section_neutron-compute-node.xml', 'doc/install-guide/section_glance-install.xml', 'doc/install-guide/section_neutron-controller-node.xml', 'doc/install-guide/section_neutron-network-node.xml', 'doc/install-guide/section_nova-controller-install.xml', 'doc/install-guide/section_nova-compute-install.xml', 'doc/install-guide/section_keystone-install.xml', 'doc/install-guide/section_nova-networking-compute-node.xml', 'doc/install-guide/section_nova-networking-controller-node.xml']",9,8ddea61d2155c64d007e5b0da1d4a1559312f83d,bug/1375746," <step> <para>Edit the <filename>/etc/nova/nova.conf</filename> file and complete the following actions:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, configure the network and security group APIs:</para> <programlisting language=""ini"">[DEFAULT] </step> </substeps> <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>systemctl restart openstack-nova-api.service</userinput> <prompt>#</prompt> <userinput>systemctl restart openstack-nova-scheduler.service</userinput> <prompt>#</prompt> <userinput>systemctl restart openstack-nova-conductor.service</userinput></screen> <para os=""sles"">On SLES:</para> <screen os=""sles""><prompt>#</prompt> <userinput>service openstack-nova-api restart</userinput> <para os=""opensuse"">On openSUSE:</para> <screen os=""opensuse""><prompt>#</prompt> <userinput>systemctl restart openstack-nova-api.service</userinput> <prompt>#</prompt> <userinput>systemctl restart openstack-nova-scheduler.service</userinput> <prompt>#</prompt> <userinput>systemctl restart openstack-nova-conductor.service</userinput></screen>"," <step os=""rhel;centos;fedora;sles;opensuse""> <para>Run the following commands:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ network_api_class nova.network.api.API</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ security_group_api nova</userinput></screen> </step> <step os=""ubuntu;debian""> <para>Edit the <filename>/etc/nova/nova.conf</filename> file and add the following keys to the <literal>[DEFAULT]</literal> section:</para> <programlisting language=""ini"">[DEFAULT] <screen os=""rhel;centos;fedora;sles;opensuse""><prompt>#</prompt> <userinput>service openstack-nova-api restart</userinput>",218,129
openstack%2Fnova~master~I93344b45d11720945ee606a1a00c605bc99f1060,openstack/nova,master,I93344b45d11720945ee606a1a00c605bc99f1060,Make websocketproxy tests work with older versions of urlparse,ABANDONED,2014-10-01 03:18:34.000000000,2014-10-05 14:38:17.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5371}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-01 03:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7c157a43c29b4e722009107520cd2157fb785a5', 'message': 'Make websocketproxy tests work with older versions of urlparse\n\nDue to a bug in python < 2.7.4, urlparse won\'t parse a query string in a\nURL where the scheme is not recognized:\n\nhttp://bugs.python.org/issue9374\n\nCommit 1dda5ef75a5c141c316639716820b0c37773a9e3 adds some tests for\nwebsocketproxy that uses urlparse to get a token but these don\'t work on\npython < 2.7.4 since the scheme in the tests is ""ws://"".\n\nTo fix this, simply use http:// for the scheme in the test URLs.\n\nCloses-Bug: #1376078\n\nChange-Id: I93344b45d11720945ee606a1a00c605bc99f1060\n'}, {'number': 2, 'created': '2014-10-01 14:56:47.000000000', 'files': ['nova/tests/console/test_websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/748c21ee70c6fe5b3152ef89807c669684f2dff1', 'message': 'Make websocketproxy tests work with older versions of urlparse\n\nDue to a bug in python < 2.7.4, urlparse won\'t parse a query string in a\nURL where the scheme is not recognized:\n\nhttp://bugs.python.org/issue9374\n\nCommit 1dda5ef75a5c141c316639716820b0c37773a9e3 adds some tests for\nwebsocketproxy that uses urlparse to get a token but these don\'t work on\npython < 2.7.4 since the scheme in the tests is ""ws://"".\n\nTo fix this, simply use http:// for the scheme in the test URLs.\n\nNote that this change does not attempt to workaround the python bug so\nurlparse supports arbitrary schemes.  There are several places in nova\nthat use urlparse and making those support unknown schemes is a separate\neffort/issue.  Furthermore, the admin guide docs use http:// in all vnc\nproxy examples for setting this up.\n\nDocImpact: The ""getting-started-with-vnc-proxy"" page in the\n""admin-guide-cloud"" docs should be updated with a note that the web\nproxy console URLs do not support the websocket protocol scheme (ws://)\non python versions less than 2.7.4.\n\nCloses-Bug: #1376078\n\nChange-Id: I93344b45d11720945ee606a1a00c605bc99f1060\n'}]",0,125260,748c21ee70c6fe5b3152ef89807c669684f2dff1,30,8,2,6873,,,0,"Make websocketproxy tests work with older versions of urlparse

Due to a bug in python < 2.7.4, urlparse won't parse a query string in a
URL where the scheme is not recognized:

http://bugs.python.org/issue9374

Commit 1dda5ef75a5c141c316639716820b0c37773a9e3 adds some tests for
websocketproxy that uses urlparse to get a token but these don't work on
python < 2.7.4 since the scheme in the tests is ""ws://"".

To fix this, simply use http:// for the scheme in the test URLs.

Note that this change does not attempt to workaround the python bug so
urlparse supports arbitrary schemes.  There are several places in nova
that use urlparse and making those support unknown schemes is a separate
effort/issue.  Furthermore, the admin guide docs use http:// in all vnc
proxy examples for setting this up.

DocImpact: The ""getting-started-with-vnc-proxy"" page in the
""admin-guide-cloud"" docs should be updated with a note that the web
proxy console URLs do not support the websocket protocol scheme (ws://)
on python versions less than 2.7.4.

Closes-Bug: #1376078

Change-Id: I93344b45d11720945ee606a1a00c605bc99f1060
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/125260/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/console/test_websocketproxy.py'],1,c7c157a43c29b4e722009107520cd2157fb785a5,bug/1376078," self.wh.path = ""http://127.0.0.1/?token=123-456-789"" self.wh.path = ""http://127.0.0.1/?token=XXX"""," self.wh.path = ""ws://127.0.0.1/?token=123-456-789"" self.wh.path = ""ws://127.0.0.1/?token=XXX""",2,2
openstack%2Fkeystone~master~Icc5646c143a234127a8b4ac8a74342ef3dca7e80,openstack/keystone,master,Icc5646c143a234127a8b4ac8a74342ef3dca7e80,Validates controller methods exist when specified,MERGED,2014-10-03 20:04:21.000000000,2014-10-05 14:33:58.000000000,2014-10-05 14:33:57.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-03 20:04:21.000000000', 'files': ['keystone/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/56fca743fd4d127175eb9ee908583e812250daf7', 'message': 'Validates controller methods exist when specified\n\nIt was possible to specify an invalid controller method in a router.\nThis will not cause an error until runtime. This change catches the\nerror much earlier in the application lifecycle. In fact with this\nchange errors should not be able to pass unit tests even if there is\nno specific test for the behavior.\n\nRelated-bug: #1377304\nChange-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80\n'}]",0,126051,56fca743fd4d127175eb9ee908583e812250daf7,13,5,1,7725,,,0,"Validates controller methods exist when specified

It was possible to specify an invalid controller method in a router.
This will not cause an error until runtime. This change catches the
error much earlier in the application lifecycle. In fact with this
change errors should not be able to pass unit tests even if there is
no specific test for the behavior.

Related-bug: #1377304
Change-Id: Icc5646c143a234127a8b4ac8a74342ef3dca7e80
",git fetch https://review.opendev.org/openstack/keystone refs/changes/51/126051/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/wsgi.py'],1,56fca743fd4d127175eb9ee908583e812250daf7,bug/1377304," getattr(controller, get_head_action) # ensure the attribute exists getattr(controller, get_action) # ensure the attribute exists getattr(controller, head_action) # ensure the attribute exists getattr(controller, put_action) # ensure the attribute exists getattr(controller, post_action) # ensure the attribute exists getattr(controller, patch_action) # ensure the attribute exists getattr(controller, delete_action) # ensure the attribute exists getattr(controller, get_post_action) # ensure the attribute exists",,8,0
openstack%2Ftraining-guides~master~I414b05785ad322e82f3bf3a38f3374d0e6c45c6c,openstack/training-guides,master,I414b05785ad322e82f3bf3a38f3374d0e6c45c6c,labs: add and use new cmd: queue,MERGED,2014-10-03 14:07:04.000000000,2014-10-05 14:09:31.000000000,2014-10-05 14:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 9178}]","[{'number': 1, 'created': '2014-10-03 14:07:04.000000000', 'files': ['labs/config/scripts.controller', 'labs/config/scripts.fedora', 'labs/lib/osbash/functions.host', 'labs/config/scripts.ubuntu', 'labs/config/scripts.compute', 'labs/config/scripts.network'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/35218beac6d27d1022c264a7caedc5af93d7b462', 'message': 'labs: add and use new cmd: queue\n\nAdd a new command, queue, to replace the old syntax in config/scripts.*.\nConvert all config files to use the new syntax.\n\nPreviously, the scripts used hardcoded directory code words: scripts\nfor $SCRIPTS_DIR, osbash for $SCRIPTS_DIR/osbash.\n\nWith the new syntax, the argument is just a relative path inside\n$SCRIPTS_DIR. This makes it easier to add (e.g. distribution-specific)\ndirectories.\n\nThe new syntax makes also explicit that the command is used to queue\nfiles for later execution.\n\nChange-Id: I414b05785ad322e82f3bf3a38f3374d0e6c45c6c\n'}]",0,125975,35218beac6d27d1022c264a7caedc5af93d7b462,7,3,1,11109,,,0,"labs: add and use new cmd: queue

Add a new command, queue, to replace the old syntax in config/scripts.*.
Convert all config files to use the new syntax.

Previously, the scripts used hardcoded directory code words: scripts
for $SCRIPTS_DIR, osbash for $SCRIPTS_DIR/osbash.

With the new syntax, the argument is just a relative path inside
$SCRIPTS_DIR. This makes it easier to add (e.g. distribution-specific)
directories.

The new syntax makes also explicit that the command is used to queue
files for later execution.

Change-Id: I414b05785ad322e82f3bf3a38f3374d0e6c45c6c
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/75/125975/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/config/scripts.controller', 'labs/config/scripts.fedora', 'labs/lib/osbash/functions.host', 'labs/config/scripts.ubuntu', 'labs/config/scripts.compute', 'labs/config/scripts.network']",6,35218beac6d27d1022c264a7caedc5af93d7b462,cmd_add_queue,cmd queue etc_hosts.sh cmd queue osbash/enable_vagrant_ssh_keys.shcmd queue setup_neutron_network.sh,scripts etc_hosts.sh osbash enable_vagrant_ssh_keys.shscripts setup_neutron_network.sh,35,27
openstack%2Fneutron-specs~master~Iee65c60a2ee42e597d34e92c6a8acba774446b19,openstack/neutron-specs,master,Iee65c60a2ee42e597d34e92c6a8acba774446b19,Spec: Add QoS to Big Switch Plugin,ABANDONED,2014-07-10 21:11:42.000000000,2014-10-05 11:36:38.000000000,,"[{'_account_id': 3}, {'_account_id': 490}]","[{'number': 1, 'created': '2014-07-10 21:11:42.000000000', 'files': ['specs/juno/bsn-qos.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2e2ee01de2b8290095d0958b177d3a1d20f42d4b', 'message': 'Spec: Add QoS to Big Switch Plugin\n\nChange-Id: Iee65c60a2ee42e597d34e92c6a8acba774446b19\n'}]",0,106168,2e2ee01de2b8290095d0958b177d3a1d20f42d4b,4,2,1,7787,,,0,"Spec: Add QoS to Big Switch Plugin

Change-Id: Iee65c60a2ee42e597d34e92c6a8acba774446b19
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/68/106168/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/bsn-qos.rst'],1,2e2ee01de2b8290095d0958b177d3a1d20f42d4b,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Big Switch Plugin support for QoS Extension =========================================== https://blueprints.launchpad.net/neutron/+spec/bsn-qos Add support for the Quality of Service extension[1] in the Big Switch plugin. Problem description =================== Tenants have no way to express Quality of Service requirements for OpenStack ports or networks when using the Big Switch Plugin. Proposed change =============== Leverage the new QoS mixin when it is available to take advantage of the Quality of Service extension. This information will be relayed to the backend controller so it can enforce these requirements on the physical network. Alternatives ------------ No alternative for user specified QoS in OpenStack. Data model impact ----------------- DB migration for QoS table for the Big Switch plugin. REST API impact --------------- The Big Switch Plugin will respond to the QoS endpoints. Security impact --------------- N/A Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ N/A Other deployer impact --------------------- N/A Developer impact ---------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: Kevin Benton IRC:kevinbenton Work Items ---------- Load the mixin in the Big Switch plugin and update the REST calls for ports and networks to include the QoS markings. Dependencies ============ This depends on the Neutron QoS API extension (qos-api-extension). [1] Testing ======= Unit tests will cover this for now. The backend support for QoS is in progress so once that is added, it will be integrated into the Big Switch CI tests. Documentation Impact ==================== Mention that the Big Switch plugin supports the QoS extension. References ========== 1. https://review.openstack.org/#/c/88599/ ",,119,0
openstack%2Fneutron~stable%2Ficehouse~If7560161de3be6066af0d9866e6b5cd7c7247c33,openstack/neutron,stable/icehouse,If7560161de3be6066af0d9866e6b5cd7c7247c33,Use root_helper when checking namespace existence,ABANDONED,2014-07-25 21:30:45.000000000,2014-10-05 11:34:56.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 8213}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-07-25 21:30:45.000000000', 'files': ['neutron/tests/unit/test_linux_ip_lib.py', 'neutron/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f56c1abe3322a5d6a135a012008c8e6209754901', 'message': 'Use root_helper when checking namespace existence\n\nUse the root helper in the ip netns list command executed by the IP library\nwhen checking for the existence of a namespace.  This prevents an unprivileged\nl3 agent from erroneously trying to create another namespace when one already\nexists.\n\nCloses-Bug: #1348812\nChange-Id: If7560161de3be6066af0d9866e6b5cd7c7247c33\n(cherry-picked from 6d2ded2e42239a2ea3590bc1a3b02623b34952a1)\n'}]",0,109737,f56c1abe3322a5d6a135a012008c8e6209754901,14,11,1,7787,,,0,"Use root_helper when checking namespace existence

Use the root helper in the ip netns list command executed by the IP library
when checking for the existence of a namespace.  This prevents an unprivileged
l3 agent from erroneously trying to create another namespace when one already
exists.

Closes-Bug: #1348812
Change-Id: If7560161de3be6066af0d9866e6b5cd7c7247c33
(cherry-picked from 6d2ded2e42239a2ea3590bc1a3b02623b34952a1)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/109737/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_linux_ip_lib.py', 'neutron/agent/linux/ip_lib.py']",2,f56c1abe3322a5d6a135a012008c8e6209754901,," output = self._parent._execute('o', 'netns', ['list'], root_helper=self._parent.root_helper)"," output = self._parent._execute('o', 'netns', ['list'])",10,1
openstack%2Fneutron-specs~master~I8f357a259867a3af94a8284da1acea0f06eecb70,openstack/neutron-specs,master,I8f357a259867a3af94a8284da1acea0f06eecb70,Add spec for Big Switch Tenant Name tracking,ABANDONED,2014-06-27 23:21:31.000000000,2014-10-05 10:41:52.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 6854}, {'_account_id': 7591}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-06-27 23:21:31.000000000', 'files': ['specs/juno/bigswitch-tenantnames.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bae0311f3e4d58a5112ab90727915a07b403b8b3', 'message': 'Add spec for Big Switch Tenant Name tracking\n\nChange-Id: I8f357a259867a3af94a8284da1acea0f06eecb70\n'}]",18,103268,bae0311f3e4d58a5112ab90727915a07b403b8b3,25,9,1,7787,,,0,"Add spec for Big Switch Tenant Name tracking

Change-Id: I8f357a259867a3af94a8284da1acea0f06eecb70
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/68/103268/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/bigswitch-tenantnames.rst'],1,bae0311f3e4d58a5112ab90727915a07b403b8b3,bigswitch-tenantname,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================= Big Switch Tenant Names ======================= https://blueprints.launchpad.net/neutron/+spec/bigswitch-tenantnames Tenant UUIDs are unfriendly and that's the only tenant identifier passed to the backend controller so that's all the controller can show. This spec is to record the tenant name passed in from the neutron context so tenant names can be passed to the backend for to augment the tenant UUID. Problem description =================== The tenant name is not currently passed to the backend controller. This makes debugging networks for a specific tenant difficult because the tenant has to be located by UUID. Proposed change =============== Record the tenant name passed in from the neutron context to a database table for future reference. Then include the last observed tenant name from this table in any port or network requests sent to the backend controller. This will affect both the Big Switch Plugin as well as the ML2 driver. Alternatives ------------ Polling keystone from the controller. This requires tight-coupling between the controller and a specific version of openstack as well as the configuration of the keystone credentials/URL on the controller. Data model impact ----------------- N/A REST API impact --------------- N/A Security impact --------------- N/A Notifications impact -------------------- N/A Other end user impact --------------------- Users will see tenant names on the backend controller if available. Performance Impact ------------------ Extra table lookup on port and network updates. Other deployer impact --------------------- N/A Developer impact ---------------- N/a Implementation ============== Assignee(s) ----------- Primary assignee: kevinbenton Work Items ---------- Update Big Switch Plugin and ML2 Driver Dependencies ============ N/A Testing ======= Unit tests will cover this change. Documentation Impact ==================== N/A References ========== N/A ,,118,0
openstack%2Fneutron-specs~master~I6358dc35f2b12f2a2ce1f56929572df03895f2e5,openstack/neutron-specs,master,I6358dc35f2b12f2a2ce1f56929572df03895f2e5,Add spec for BSN tap-as-a-service,ABANDONED,2014-07-11 02:42:48.000000000,2014-10-05 10:25:58.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 1935}]","[{'number': 1, 'created': '2014-07-11 02:42:48.000000000', 'files': ['specs/juno/bsn-taas.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2a052740f4ccdf026ecf4dd67d7e09cb0ef83212', 'message': 'Add spec for BSN tap-as-a-service\n\nChange-Id: I6358dc35f2b12f2a2ce1f56929572df03895f2e5\n'}]",0,106236,2a052740f4ccdf026ecf4dd67d7e09cb0ef83212,7,4,1,7787,,,0,"Add spec for BSN tap-as-a-service

Change-Id: I6358dc35f2b12f2a2ce1f56929572df03895f2e5
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/36/106236/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/bsn-taas.rst'],1,2a052740f4ccdf026ecf4dd67d7e09cb0ef83212,bsn-taas,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Big Switch - Tap as a Service Plugin ==================================== https://blueprints.launchpad.net/neutron/+spec/bsn-taas Add a new Big Switch tap-as-a-service plugin that can be used to capture traffic from arbitrary physical or virtual ports when using the Big Switch ML2 driver or the Big Switch core plugin. Problem description =================== There currently isn't a good way to capture traffic flows for a tenant. For this reason, the tap-as-a-service service was proposed.[1] Once implemented, it will give tenants the ability to capture traffic from ports they own and deliver the traffic to another port. However, this will only apply to the reference implementation and will not work for physical ports (e.g. external attachment points). Proposed change =============== Implement the new tap-as-a-service API outlined in [1] in a Big Switch service plugin. This will only work in conjuction with either the Big Switch plugin or the Big Switch ML2 driver because the backend controller needs to know the locations of the requested ports to be tapped. Tap requests will be relayed to the controller which will then configure the fabric to deliver the traffic from the target port to the destination port. The target port could be an external attachment point that has a physical appliance attached to it for high-performance analysis. Alternatives ------------ N/A Data model impact ----------------- N/A REST API impact --------------- BSN plugin will support new tap-as-a-service API Security impact --------------- N/A Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ N/A Other deployer impact --------------------- N/A Developer impact ---------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: kevinbenton Work Items ---------- * Implement tap-as-a-service API in the Big Switch plugin * Add unit tests Dependencies ============ This depends on the implementation of the base Tap-as-a-service spec.[1] Testing ======= Will be tested in 3rd party CI Documentation Impact ==================== BSN Plugin supports tap as a service References ========== 1. https://review.openstack.org/#/c/96149/ ",,112,0
openstack%2Fneutron-specs~master~I422e283ebdb34cf6121de8f9778d930ceef5a1ff,openstack/neutron-specs,master,I422e283ebdb34cf6121de8f9778d930ceef5a1ff,Add spec for BSN support for service insertion,ABANDONED,2014-07-11 01:56:02.000000000,2014-10-05 10:25:45.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1689}, {'_account_id': 2031}]","[{'number': 1, 'created': '2014-07-11 01:56:02.000000000', 'files': ['specs/juno/bsn-service-insertion.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ca1cbdb259a04eb8e7eb1d6c48dc05b04e4f8718', 'message': 'Add spec for BSN support for service insertion\n\nChange-Id: I422e283ebdb34cf6121de8f9778d930ceef5a1ff\n'}]",1,106228,ca1cbdb259a04eb8e7eb1d6c48dc05b04e4f8718,8,4,1,7787,,,0,"Add spec for BSN support for service insertion

Change-Id: I422e283ebdb34cf6121de8f9778d930ceef5a1ff
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/28/106228/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/bsn-service-insertion.rst'],1,ca1cbdb259a04eb8e7eb1d6c48dc05b04e4f8718,bsn-service-insertion,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Big Switch - Service Insertion in plugin ======================================== https://blueprints.launchpad.net/neutron/+spec/bsn-service-insertion Add support for the new service insertion model[1] once it is approved and implemented. Problem description =================== The backend controller needs to know about inserted services so it can steer traffic through the appropriate VM or hardware appliance. Proposed change =============== Add REST calls to relay information about the inserted services to the backend controller so traffic can be appropriately directed. Alternatives ------------ There is currently no way for service insertion to be expressed to the backend from Neutron. Data model impact ----------------- N/A REST API impact --------------- N/A Security impact --------------- N/A Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ N/A Other deployer impact --------------------- N/A Developer impact ---------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: kevinbenton Work Items ---------- * Implement service insertion calls in the Big Switch plugin * Add unit tests Dependencies ============ The service insertion framework needs to be approved and implemented.[1] Testing ======= This will be covered by the service insertion tests built for service insertion API.[1] Documentation Impact ==================== N/A References ========== 1. https://review.openstack.org/#/c/93128/ ,,106,0
openstack%2Fneutron~master~I119fa997e2d65c6d8a091ba8a80c9a35868a850d,openstack/neutron,master,I119fa997e2d65c6d8a091ba8a80c9a35868a850d,Add a policy keyword to match keystone username,ABANDONED,2014-07-22 07:26:15.000000000,2014-10-05 10:24:59.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 1923}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-07-22 07:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc197bfa155d45346364ec4981eb3a593b6115dc', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 2, 'created': '2014-07-22 18:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c884e47da74a63d05d3cad375ca44d8ad044f75b', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 3, 'created': '2014-07-22 22:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81621016e579c9e7c51d08e485b5d5c15462da25', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 4, 'created': '2014-07-25 01:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb05a5806e5bc8fbc54e529fc23d9429c422a952', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 5, 'created': '2014-07-29 21:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c06c55c54980e8468bdb26f62b7f8199d725c1a5', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 6, 'created': '2014-08-05 23:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8595b0591fe6cdd118d85122237a01f4d9d45ecb', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 7, 'created': '2014-08-07 03:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8658aa38e99c5b3759c82c69e8f8ce2a5d40d623', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nDocImpact\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 8, 'created': '2014-08-07 16:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ab32eca21695ce4a5c7fde37495288a3370ffb5', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nDocImpact\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}, {'number': 9, 'created': '2014-08-07 16:01:53.000000000', 'files': ['neutron/tests/unit/test_policy.py', 'neutron/tests/etc/neutron.conf.test', 'neutron/policy.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aed3957b2d4429538f92d33dc05a2bda84bb9449', 'message': 'Add a policy keyword to match keystone username\n\nAdds a keyword to policy.json to match the keystone username used by\nNeutron so the Neutron keystone account can perform admin-level operations\ninside of Neutron without being an admin at the keystone level.\n\nDocImpact\n\nCloses-Bug: #1346778\nChange-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d\n'}]",14,108598,aed3957b2d4429538f92d33dc05a2bda84bb9449,187,40,9,7787,,,0,"Add a policy keyword to match keystone username

Adds a keyword to policy.json to match the keystone username used by
Neutron so the Neutron keystone account can perform admin-level operations
inside of Neutron without being an admin at the keystone level.

DocImpact

Closes-Bug: #1346778
Change-Id: I119fa997e2d65c6d8a091ba8a80c9a35868a850d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/108598/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_policy.py', 'neutron/policy.py', 'etc/policy.json']",3,fc197bfa155d45346364ec4981eb3a593b6115dc,bug/1346778," ""context_is_admin"": ""role:admin or user_name:%(keystone_admin_user)s"","," ""context_is_admin"": ""role:admin"",",14,2
openstack%2Frally~master~I6993c046bcf5a8632b08d46ae380067ffa677f84,openstack/rally,master,I6993c046bcf5a8632b08d46ae380067ffa677f84,Add volume option to boot server from volume and run script,MERGED,2014-09-18 13:27:59.000000000,2014-10-05 09:52:45.000000000,2014-10-05 09:52:45.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6732}, {'_account_id': 7774}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-09-18 13:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dda73e89c9143ed3ab55b6086430b761cd940cf7', 'message': 'Add volume option to boot server from volume and run script\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}, {'number': 2, 'created': '2014-09-18 22:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/33d4509a79e2af5529ca33a2a2ffd022e85c7831', 'message': 'Add volume option to boot server from volume and run script\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}, {'number': 3, 'created': '2014-10-02 00:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b64e762dec59174b9f04cd8fcd3aa22a701defe2', 'message': 'Add volume option to boot server from volume and run script\n\nnova and cinder may set to different disk backend, e.g. nova use\nlocal disk for image, and cinder use rbd volume_driver. This patch\nwill add flexibility for user to choose where the vm is booted\nfrom.\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}, {'number': 4, 'created': '2014-10-02 21:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b2ffa5f45ecfd539e76a9c1f67d5c32445b6af1d', 'message': 'Add volume option to boot server from volume and run script\n\nnova and cinder may set to different disk backend, e.g. nova use\nlocal disk for image, and cinder use rbd volume_driver. This patch\nwill add flexibility for user to choose where the vm is booted\nfrom.\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}, {'number': 5, 'created': '2014-10-03 20:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3dd5d42631c2ecad4da4d0df9ceea2b724a67195', 'message': 'Add volume option to boot server from volume and run script\n\nnova and cinder may set to different disk backend, e.g. nova use\nlocal disk for image, and cinder use rbd volume_driver. This patch\nwill add flexibility for user to choose where the vm is booted\nfrom.\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}, {'number': 6, 'created': '2014-10-05 01:41:11.000000000', 'files': ['doc/samples/tasks/scenarios/vm/boot-runcommand-delete-with-disk.json', 'tests/benchmark/scenarios/vm/test_vmtasks.py', 'rally-scenarios/rally.yaml', 'rally/benchmark/scenarios/vm/vmtasks.py', 'doc/samples/tasks/scenarios/vm/boot-runcommand-delete-with-disk.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/e552b21b04a7cded33eeb494ee6c4a33c81f148f', 'message': 'Add volume option to boot server from volume and run script\n\nnova and cinder may set to different disk backend, e.g. nova use\nlocal disk for image, and cinder use rbd volume_driver. This patch\nwill add flexibility for user to choose where the vm is booted\nfrom.\n\nBased on boot_runcommand_delete scenario, add new option for volume:\nvolume_args, which is default to ""None"". It is a dict option and\n\'size\' parameter is supported now. If volume_args is assigned, this\nscenario will create a volume_args[\'size\'] size volume, and boot\nfrom the new volume, finally run ""script"".\n\nHere is a sample scenario:\n\n    ""VMTasks.boot_runcommand_delete"": [\n        {\n            ""args"": {\n                ""flavor"": {\n                    ""name"": ""m1.tiny""\n                },\n                ""image"": {\n                    ""name"": ""cirros""\n                },\n                ""volume_args"": {\n                    ""size"": 2\n                },\n                ""script"": ""./instance_dd_test.sh"",\n                ...\n\nChange-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84\n'}]",9,122409,e552b21b04a7cded33eeb494ee6c4a33c81f148f,25,7,6,7774,,,0,"Add volume option to boot server from volume and run script

nova and cinder may set to different disk backend, e.g. nova use
local disk for image, and cinder use rbd volume_driver. This patch
will add flexibility for user to choose where the vm is booted
from.

Based on boot_runcommand_delete scenario, add new option for volume:
volume_args, which is default to ""None"". It is a dict option and
'size' parameter is supported now. If volume_args is assigned, this
scenario will create a volume_args['size'] size volume, and boot
from the new volume, finally run ""script"".

Here is a sample scenario:

    ""VMTasks.boot_runcommand_delete"": [
        {
            ""args"": {
                ""flavor"": {
                    ""name"": ""m1.tiny""
                },
                ""image"": {
                    ""name"": ""cirros""
                },
                ""volume_args"": {
                    ""size"": 2
                },
                ""script"": ""./instance_dd_test.sh"",
                ...

Change-Id: I6993c046bcf5a8632b08d46ae380067ffa677f84
",git fetch https://review.opendev.org/openstack/rally refs/changes/09/122409/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/scenarios/vm/vmtasks.py'],1,dda73e89c9143ed3ab55b6086430b761cd940cf7,boot_volume,"from rally.benchmark.scenarios.cinder import utils as cinder_utilsclass VMTasks(nova_utils.NovaScenario, vm_utils.VMScenario, cinder_utils.CinderScenario): @validation.required_services(consts.Service.NOVA,consts.Service.CINDER) context={""cleanup"": [""nova"", ""cinder""], ""keypair"": {}, ""allow_ssh"": {}}) volume_args=None, if volume_args: volume_size = volume_args['size'] volume = self._create_volume(volume_size, imageRef=image) kwargs['block_device_mapping'] = {'vda': '%s:::1' % volume.id} ","class VMTasks(nova_utils.NovaScenario, vm_utils.VMScenario): @validation.required_services(consts.Service.NOVA) context={""cleanup"": [""nova""], ""keypair"": {}, ""allow_ssh"": {}})",11,3
openstack%2Fopenstack-manuals~master~I36ab7ed86bdad09ff25c6f2cc280212ca8d52b98,openstack/openstack-manuals,master,I36ab7ed86bdad09ff25c6f2cc280212ca8d52b98,Deprecate / obsolete NetApp volume extra specs,MERGED,2014-10-02 18:59:59.000000000,2014-10-05 09:49:06.000000000,2014-10-05 09:49:05.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 9186}]","[{'number': 1, 'created': '2014-10-02 18:59:59.000000000', 'files': ['doc/config-reference/block-storage/drivers/netapp-volume-driver.xml', 'doc/common/tables/cinder-netapp_cdot_extraspecs.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/761198f53644887df3e871b373c7885c8c360c3e', 'message': ""Deprecate / obsolete NetApp volume extra specs\n\nThe NetApp Data ONTAP (Cluster-mode) NFS & iSCSI drivers for Juno support\nthe Cinder pools feature, but the drivers are reporting two qualified\nextra specs that must be converted to unqualified extra specs in order to\nbe used by the Cinder scheduler's capability filter. Furthermore, there\nare four extra specs that must be deprecated due to having the pools\nfeature.\n\nThis patch updates the documentation to update the extra specs and\nformally denote the deprecation.\n\nChange-Id: I36ab7ed86bdad09ff25c6f2cc280212ca8d52b98\n""}]",0,125739,761198f53644887df3e871b373c7885c8c360c3e,9,4,1,9186,,,0,"Deprecate / obsolete NetApp volume extra specs

The NetApp Data ONTAP (Cluster-mode) NFS & iSCSI drivers for Juno support
the Cinder pools feature, but the drivers are reporting two qualified
extra specs that must be converted to unqualified extra specs in order to
be used by the Cinder scheduler's capability filter. Furthermore, there
are four extra specs that must be deprecated due to having the pools
feature.

This patch updates the documentation to update the extra specs and
formally denote the deprecation.

Change-Id: I36ab7ed86bdad09ff25c6f2cc280212ca8d52b98
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/125739/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/drivers/netapp-volume-driver.xml', 'doc/common/tables/cinder-netapp_cdot_extraspecs.xml']",2,761198f53644887df3e871b373c7885c8c360c3e,bug/1374630," <td><literal>netapp_raid_type</literal></td> <td><literal>netapp_disk_type</literal></td> <td>Limit the candidate volume list based on one of the following disk types: <literal>ATA, BSAS, EATA, FCAL, FSAS, LUN, MSATA, SAS, SATA, SCSI, XATA, XSAS, or SSD.</literal></td> <td><literal>netapp:qos_policy_group</literal><footnote xml:id=""netapp-directive-extra-specs""><para>Please note that this extra spec has a colon (<literal>:</literal>) in its name because it is used by the driver to assign the QoS policy group to the OpenStack Block Storage volume after it has been provisioned.</para></footnote></td> <td>Specify the name of a QoS policy group, which defines measurable Service Level Objectives, that should be applied to the OpenStack Block Storage volume at the time of volume creation. Ensure that the QoS policy group object within Data ONTAP should be defined before an OpenStack Block Storage volume is created, and that the QoS policy group is not associated with the destination FlexVol volume.</td> <td><literal>netapp_mirrored</literal></td> <td><literal>netapp_unmirrored</literal><footnote xml:id=""netapp-deprecated-extra-specs""><para>In the Juno release, these negative-assertion extra specs are formally deprecated by the NetApp unified driver. Instead of using the deprecated negative-assertion extra specs (for example, <option>netapp_unmirrored</option>) with a value of <literal>true</literal>, use the corresponding positive-assertion extra spec (for example, <option>netapp_mirrored</option>) with a value of <literal>false</literal>.</para></footnote></td> <td><literal>netapp_dedup</literal></td> <td><literal>netapp_nodedup</literal><footnoteref linkend=""netapp-deprecated-extra-specs""/></td> <td><literal>netapp_compression</literal></td> <td><literal>netapp_nocompression</literal><footnoteref linkend=""netapp-deprecated-extra-specs""/></td> <td><literal>netapp_thin_provisioned</literal></td> <td><literal>netapp_thick_provisioned</literal><footnoteref linkend=""netapp-deprecated-extra-specs""/></td>"," <td><literal>netapp:raid_type</literal></td> <td><literal>netapp:disk_type</literal></td> <td>Limit the candidate volume list based on one of the following disk types: <literal>ATA, BSAS, EATA, FCAL, FSAS, LUN, MSATA, SAS, SATA, SCSI, XATA, XSAS, or SSD.</literal></td> <td><literal>netapp:qos_policy_group</literal></td> <td>Specify the name of a QoS policy group, which defines measurable Service Level Objectives, that should be applied to the OpenStack Block Storage volume at the time of volume creation. Ensure that the QoS policy group object within Data ONTAP should be defined before an OpenStack Block Storage volume is created, and that the QoS policy group is not associated with the destination FlexVol volume.</td> <td><literal>netapp_mirrored</literal><footnote xml:id=""netapp-conflict-extra-specs""><para>If both the positive and negative specs for a pair are specified (for example, <literal>netapp_dedup</literal> and <literal>netapp_nodedup</literal>) and set to the same value within a single <literal>extra_specs</literal> list, then neither spec will be utilized by the driver.</para></footnote></td> <td><literal>netapp_unmirrored</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_dedup</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_nodedup</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_compression</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_nocompression</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_thin_provisioned</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td> <td><literal>netapp_thick_provisioned</literal><footnoteref linkend=""netapp-conflict-extra-specs""/></td>",13,27
openstack%2Fcinder~master~Ic89cffc93940b7b119cfcde3362f304c9f2875df,openstack/cinder,master,Ic89cffc93940b7b119cfcde3362f304c9f2875df,Refuse invalid qcow2 backing files,MERGED,2014-10-02 15:07:21.000000000,2014-10-05 09:14:33.000000000,2014-10-02 21:44:22.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-02 15:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d8e39f9e6da9c8a535e8c06f92f468b4e7f474b', 'message': ""Refuse invalid qcow2 backing files\n\nDon't allow qcow2 files that are pointing to backing files outside of:\n\nvolume-<id>\nvolume-<id>.<snap-id>\nvolume-<id>.tmp-snap-<snap-id>\n\n(optionally prefixed with /mnt/path)\n\nCloses-Bug: #1350504\n\nChange-Id: Ic89cffc93940b7b119cfcde3362f304c9f2875df\n""}, {'number': 2, 'created': '2014-10-02 15:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a1d3d21dfc6181ac21ac0534e974dea8ad6a6c24', 'message': ""Refuse invalid qcow2 backing files\n\nDon't allow qcow2 files that are pointing to backing files outside of:\n\nvolume-<id>\nvolume-<id>.<snap-id>\nvolume-<id>.tmp-snap-<snap-id>\n\n(optionally prefixed with /mnt/path)\n\nCloses-Bug: #1350504\n\nChange-Id: Ic89cffc93940b7b119cfcde3362f304c9f2875df\n(cherry picked from commit 6d8e39f9e6da9c8a535e8c06f92f468b4e7f474b)\n""}, {'number': 3, 'created': '2014-10-02 15:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c877d910f70ae9f0c7e2ea41554553fe12d70c8c', 'message': ""Refuse invalid qcow2 backing files\n\nDon't allow qcow2 files that are pointing to backing files outside of:\n\nvolume-<id>\nvolume-<id>.<snap-id>\nvolume-<id>.tmp-snap-<snap-id>\n\n(optionally prefixed with /mnt/path)\n\nCloses-Bug: #1350504\n\nChange-Id: Ic89cffc93940b7b119cfcde3362f304c9f2875df\n""}, {'number': 4, 'created': '2014-10-02 17:03:47.000000000', 'files': ['cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_smbfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dca3c8323cf8cf12aa8ce4ba21f647ce631e8153', 'message': ""Refuse invalid qcow2 backing files\n\nDon't allow qcow2 files that are pointing to backing files outside of:\n\nvolume-<id>\nvolume-<id>.<snap-id>\nvolume-<id>.tmp-snap-<snap-id>\n\n(optionally prefixed with /mnt/path)\n\nCloses-Bug: #1350504\n\nChange-Id: Ic89cffc93940b7b119cfcde3362f304c9f2875df\n""}]",0,125665,dca3c8323cf8cf12aa8ce4ba21f647ce631e8153,22,10,4,4523,,,0,"Refuse invalid qcow2 backing files

Don't allow qcow2 files that are pointing to backing files outside of:

volume-<id>
volume-<id>.<snap-id>
volume-<id>.tmp-snap-<snap-id>

(optionally prefixed with /mnt/path)

Closes-Bug: #1350504

Change-Id: Ic89cffc93940b7b119cfcde3362f304c9f2875df
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/125665/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_smbfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/tests/test_glusterfs.py']",5,6d8e39f9e6da9c8a535e8c06f92f468b4e7f474b,bug/1350504," VOLUME_NAME = 'volume-%s' % VOLUME_UUID vol_filename_2 = volume['name'] + '.abcd' vol_filename_3 = volume['name'] + '.efef' drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info)", vol_filename_2 = volume['name'] + '.asdfjkl' vol_filename_3 = volume['name'] + 'qwertyuiop' drv._qemu_img_info(IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg()).AndReturn(info) drv._qemu_img_info(IgnoreArg()).AndReturn(info),57,25
openstack%2Frally~master~Id0336a2f611bb488006355e972a0359027ec0822,openstack/rally,master,Id0336a2f611bb488006355e972a0359027ec0822,"Expand ~ in file paths, specified in rally commands",MERGED,2014-10-04 14:48:57.000000000,2014-10-05 09:10:54.000000000,2014-10-05 09:10:53.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-10-04 14:48:57.000000000', 'files': ['rally/cmd/commands/verify.py', 'rally/cmd/commands/deployment.py', 'rally/cmd/commands/task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/23b01a305cf14e123b164360874bc7e764b2ea9c', 'message': 'Expand ~ in file paths, specified in rally commands\n\nChange-Id: Id0336a2f611bb488006355e972a0359027ec0822\nCloses-Bug: 1373829\n'}]",0,126146,23b01a305cf14e123b164360874bc7e764b2ea9c,7,3,1,12124,,,0,"Expand ~ in file paths, specified in rally commands

Change-Id: Id0336a2f611bb488006355e972a0359027ec0822
Closes-Bug: 1373829
",git fetch https://review.opendev.org/openstack/rally refs/changes/46/126146/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/cmd/commands/verify.py', 'rally/cmd/commands/deployment.py', 'rally/cmd/commands/task.py']",3,23b01a305cf14e123b164360874bc7e764b2ea9c,bug/1373829, task = os.path.expanduser(task) task = os.path.expanduser(task) if out: out = os.path.expanduser(out),,7,0
openstack%2Fdevstack~master~I97629a303c55ee098e3bfbc534bfb05ccab94649,openstack/devstack,master,I97629a303c55ee098e3bfbc534bfb05ccab94649,Add support for redis to Zaqar's lib,MERGED,2014-09-05 14:04:32.000000000,2014-10-05 07:43:00.000000000,2014-10-04 09:25:55.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1297}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 7118}, {'_account_id': 7175}, {'_account_id': 7498}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-05 14:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c9224e2e21f472c551a61ff8b5e1116b446fa7f2', 'message': ""Add support for redis to Zaqar's lib\n\nA new redis driver has landed in Zaqar. This patch adds support for that\ndriver to Zaqar's lib.\n\nChange-Id: I97629a303c55ee098e3bfbc534bfb05ccab94649\n""}, {'number': 2, 'created': '2014-09-08 07:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2f19e69707aaf43e88d11acc50d3060d369d103d', 'message': ""Add support for redis to Zaqar's lib\n\nA new redis driver has landed in Zaqar. This patch adds support for that\ndriver to Zaqar's lib.\n\nChange-Id: I97629a303c55ee098e3bfbc534bfb05ccab94649\n""}, {'number': 3, 'created': '2014-10-02 07:25:20.000000000', 'files': ['files/rpms/zaqar-server', 'lib/zaqar', 'files/apts/zaqar-server'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e29a55ade1af386fda16217f4c07b90e6e95f47a', 'message': ""Add support for redis to Zaqar's lib\n\nA new redis driver has landed in Zaqar. This patch adds support for that\ndriver to Zaqar's lib.\n\nChange-Id: I97629a303c55ee098e3bfbc534bfb05ccab94649\n""}]",3,119379,e29a55ade1af386fda16217f4c07b90e6e95f47a,38,13,3,6159,,,0,"Add support for redis to Zaqar's lib

A new redis driver has landed in Zaqar. This patch adds support for that
driver to Zaqar's lib.

Change-Id: I97629a303c55ee098e3bfbc534bfb05ccab94649
",git fetch https://review.opendev.org/openstack/devstack refs/changes/79/119379/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/rpms/zaqar-server', 'lib/zaqar', 'files/apts/zaqar-server']",3,c9224e2e21f472c551a61ff8b5e1116b446fa7f2,zaqar-redis,redis-server python-redis,,11,4
openstack%2Fdevstack~master~I5807a83443b87b2c8d184e0cd2d5563a649c6273,openstack/devstack,master,I5807a83443b87b2c8d184e0cd2d5563a649c6273,Specialize Zaqar's cleanup function,MERGED,2014-09-08 07:49:33.000000000,2014-10-05 07:12:58.000000000,2014-10-02 18:28:44.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 7175}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-08 07:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5a71194cac4b606a85cd4f9143772d6da3f8f5dc', 'message': ""Specialize Zaqar's cleanup function\n\nInstead of having mongodb specific cleanup logic in `cleanup_zaqar`,\nspecialize it to perform clean ups based on the driver that has been\nenabled.\n\nChange-Id: I5807a83443b87b2c8d184e0cd2d5563a649c6273\n""}, {'number': 2, 'created': '2014-09-08 07:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/26f60e35e2c8b72e5823ac0b42f534c94fee1917', 'message': ""Specialize Zaqar's cleanup function\n\nInstead of having mongodb specific cleanup logic in `cleanup_zaqar`,\nspecialize it to perform clean ups based on the driver that has been\nenabled.\n\nChange-Id: I5807a83443b87b2c8d184e0cd2d5563a649c6273\n""}, {'number': 3, 'created': '2014-10-02 07:25:20.000000000', 'files': ['lib/zaqar'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dec13c336dd24150d57be35b54a8d40618a5e29e', 'message': ""Specialize Zaqar's cleanup function\n\nInstead of having mongodb specific cleanup logic in `cleanup_zaqar`,\nspecialize it to perform clean ups based on the driver that has been\nenabled.\n\nChange-Id: I5807a83443b87b2c8d184e0cd2d5563a649c6273\n""}]",0,119708,dec13c336dd24150d57be35b54a8d40618a5e29e,21,7,3,6159,,,0,"Specialize Zaqar's cleanup function

Instead of having mongodb specific cleanup logic in `cleanup_zaqar`,
specialize it to perform clean ups based on the driver that has been
enabled.

Change-Id: I5807a83443b87b2c8d184e0cd2d5563a649c6273
",git fetch https://review.opendev.org/openstack/devstack refs/changes/08/119708/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/zaqar'],1,5a71194cac4b606a85cd4f9143772d6da3f8f5dc,zaqar-redis,"# cleanup_zaqar_mongodb# cleanup_zaqar() - Cleans up general things from previous # runs and storage specific left overs. function cleanup_zaqar { if [ ""$ZAQAR_BACKEND"" = 'mongodb' ] ; then cleanup_zaqar_mongodb fi } # cleanup_zaqar_mongodb() - Remove residual data files, anything left over from previous # runs that a clean run would need to clean up function cleanup_zaqar_mongodb { cleanup_zaqar","# cleanup_zaqar() - Remove residual data files, anything left over from previous # runs that a clean run would need to clean up function cleanup_zaqar { cleanup_zaqar",13,3
openstack%2Fcinder~master~I801a6338250ec2dc631c4058543f7d0088b3e4d4,openstack/cinder,master,I801a6338250ec2dc631c4058543f7d0088b3e4d4,Windows SMBFS: Handle volume_name in _qemu_img_info,MERGED,2014-10-02 15:07:21.000000000,2014-10-05 03:36:59.000000000,2014-10-03 01:00:47.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 8543}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-02 15:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/93ff3621315df09a705dd754268d3e93893e9bed', 'message': ""Windows SMBFS: Handle volume_name in _qemu_img_info\n\nThe volume_name is now parsed to the _qemu_img_info wrapper. As\nthis method is not prone to security issues because this driver\ndoes not support raw images (at least not yet), we don't have to\nperform any checks on the backing image file path.\n\nThus, this method simply ignores this argument that will be parsed\nby the base class methods.\n\nRelated-Bug: #1350504\n\nChange-Id: I801a6338250ec2dc631c4058543f7d0088b3e4d4\n""}, {'number': 2, 'created': '2014-10-02 15:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f691cf4907bfb194f960247360cda4397db2edc', 'message': ""Windows SMBFS: Handle volume_name in _qemu_img_info\n\nThe volume_name is now parsed to the _qemu_img_info wrapper. As\nthis method is not prone to security issues because this driver\ndoes not support raw images (at least not yet), we don't have to\nperform any checks on the backing image file path.\n\nThus, this method simply ignores this argument that will be parsed\nby the base class methods.\n\nRelated-Bug: #1350504\n\nChange-Id: I801a6338250ec2dc631c4058543f7d0088b3e4d4\n(cherry picked from commit 93ff3621315df09a705dd754268d3e93893e9bed)\n""}, {'number': 3, 'created': '2014-10-02 15:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15cdb77a6adec7cb879059644025890271113f3e', 'message': ""Windows SMBFS: Handle volume_name in _qemu_img_info\n\nThe volume_name is now parsed to the _qemu_img_info wrapper. As\nthis method is not prone to security issues because this driver\ndoes not support raw images (at least not yet), we don't have to\nperform any checks on the backing image file path.\n\nThus, this method simply ignores this argument that will be parsed\nby the base class methods.\n\nRelated-Bug: #1350504\n\nChange-Id: I801a6338250ec2dc631c4058543f7d0088b3e4d4\n""}, {'number': 4, 'created': '2014-10-02 17:03:47.000000000', 'files': ['cinder/volume/drivers/windows/smbfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e0ce63d6df39dcad5a0ef35553369e49c67dfb8', 'message': ""Windows SMBFS: Handle volume_name in _qemu_img_info\n\nThe volume_name is now parsed to the _qemu_img_info wrapper. As\nthis method is not prone to security issues because this driver\ndoes not support raw images (at least not yet), we don't have to\nperform any checks on the backing image file path.\n\nThus, this method simply ignores this argument that will be parsed\nby the base class methods.\n\nRelated-Bug: #1350504\n\nChange-Id: I801a6338250ec2dc631c4058543f7d0088b3e4d4\n""}]",0,125666,5e0ce63d6df39dcad5a0ef35553369e49c67dfb8,16,9,4,4523,,,0,"Windows SMBFS: Handle volume_name in _qemu_img_info

The volume_name is now parsed to the _qemu_img_info wrapper. As
this method is not prone to security issues because this driver
does not support raw images (at least not yet), we don't have to
perform any checks on the backing image file path.

Thus, this method simply ignores this argument that will be parsed
by the base class methods.

Related-Bug: #1350504

Change-Id: I801a6338250ec2dc631c4058543f7d0088b3e4d4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/125666/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/windows/smbfs.py'],1,93ff3621315df09a705dd754268d3e93893e9bed,bug/1350504," def _qemu_img_info(self, path, volume_name=None):"," def _qemu_img_info(self, path):",1,1
openstack%2Fdevstack~master~I126fe9187ab46b858c33d2b7f7a47ad68b5d67bf,openstack/devstack,master,I126fe9187ab46b858c33d2b7f7a47ad68b5d67bf,Run pip install and rm separately,ABANDONED,2014-10-02 01:12:06.000000000,2014-10-05 02:07:56.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 01:12:06.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1b4ad66f8fc51ef5ab725ce369c71ae8fc0d83b2', 'message': 'Run pip install and rm separately\n\nDoing ""pip install && rm -rf ${pip_build_tmp}"" results in errexit not\ntriggering on a failed pip install. Split this line up so errexit\nterminates early if there is a pip install issue. If a required package\nfails to install its easier to debug the failure earlier in devstack\nversus debugging based on how that missing package causes things to\nfail.\n\nRelated bug: #1376526\n\nChange-Id: I126fe9187ab46b858c33d2b7f7a47ad68b5d67bf\n'}]",0,125529,1b4ad66f8fc51ef5ab725ce369c71ae8fc0d83b2,7,5,1,1849,,,0,"Run pip install and rm separately

Doing ""pip install && rm -rf ${pip_build_tmp}"" results in errexit not
triggering on a failed pip install. Split this line up so errexit
terminates early if there is a pip install issue. If a required package
fails to install its easier to debug the failure earlier in devstack
versus debugging based on how that missing package causes things to
fail.

Related bug: #1376526

Change-Id: I126fe9187ab46b858c33d2b7f7a47ad68b5d67bf
",git fetch https://review.opendev.org/openstack/devstack refs/changes/29/125529/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,1b4ad66f8fc51ef5ab725ce369c71ae8fc0d83b2,bug/1376526, $pip_mirror_opt $@ $sudo_pip rm -rf ${pip_build_tmp} $pip_mirror_opt -r $test_req $sudo_pip rm -rf ${pip_build_tmp}, $pip_mirror_opt $@ \ && $sudo_pip rm -rf ${pip_build_tmp} $pip_mirror_opt -r $test_req \ && $sudo_pip rm -rf ${pip_build_tmp},4,4
openstack%2Ftaskflow~master~Ie70e400478a092943a18f9f8595302380ec71cbc,openstack/taskflow,master,Ie70e400478a092943a18f9f8595302380ec71cbc,Stop using intersphinx,MERGED,2014-09-25 08:09:02.000000000,2014-10-05 01:22:10.000000000,2014-10-05 01:22:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-09-25 08:09:02.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5ff4c22a8be842b8db2c1c59d0ac6bcd8a21dded', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: Ie70e400478a092943a18f9f8595302380ec71cbc\nRelated-Bug: #1368910\n""}]",0,123964,5ff4c22a8be842b8db2c1c59d0ac6bcd8a21dded,10,4,1,167,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: Ie70e400478a092943a18f9f8595302380ec71cbc
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/64/123964/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,5ff4c22a8be842b8db2c1c59d0ac6bcd8a21dded,bug/1368910,," 'sphinx.ext.intersphinx',# Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None} ",0,4
openstack%2Fcinder~master~Ida34a84f8b3d156e3dca54de594c991b5ef73295,openstack/cinder,master,Ida34a84f8b3d156e3dca54de594c991b5ef73295,Clarify InvalidInput exception when the size is missing,MERGED,2014-10-02 16:46:16.000000000,2014-10-05 00:40:20.000000000,2014-10-02 22:40:10.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-10-02 16:46:16.000000000', 'files': ['cinder/volume/flows/api/create_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/04ec4673c61fb8300069e7991ab80f7782cc6b86', 'message': ""Clarify InvalidInput exception when the size is missing\n\nIn the case where size is None, the exception message\n'Volume size  must be an integer...' is misleading.\n\nChange-Id: Ida34a84f8b3d156e3dca54de594c991b5ef73295\n""}]",0,125705,04ec4673c61fb8300069e7991ab80f7782cc6b86,10,6,1,1849,,,0,"Clarify InvalidInput exception when the size is missing

In the case where size is None, the exception message
'Volume size  must be an integer...' is misleading.

Change-Id: Ida34a84f8b3d156e3dca54de594c991b5ef73295
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/125705/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/flows/api/create_volume.py'],1,04ec4673c61fb8300069e7991ab80f7782cc6b86,size," msg = _(""Volume size '%(size)s'GB cannot be smaller than"" msg = _(""Volume size '%(size)s'GB cannot be smaller than "" msg = _(""Volume size '%(size)s' must be an integer and"" LOG.debug(""Validating volume '%(size)s' using %(functors)s"" %"," msg = _(""Volume size %(size)sGB cannot be smaller than"" msg = _(""Volume size %(size)sGB cannot be smaller than "" msg = _(""Volume size %(size)s must be an integer and"" LOG.debug(""Validating volume %(size)s using %(functors)s"" %",4,4
openstack%2Fhorizon~master~I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd,openstack/horizon,master,I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd,"Add ""cancel"" button",MERGED,2014-09-29 14:07:08.000000000,2014-10-05 00:22:22.000000000,2014-10-05 00:22:20.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 8040}, {'_account_id': 9576}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-09-29 14:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cc5da7ba2796d9fe3a8a8f8b8f958dc9a319d1c', 'message': 'Add ""cancel"" button\n\nThe Create Network dialogue does not have\na cancel button. Add button for more usability\n\nChange-Id: I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd\nCloses-Bug: #1372304\n'}, {'number': 2, 'created': '2014-10-01 14:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ccd307b02a76bbd14faa67b63e23c76d6e39494c', 'message': 'Add ""cancel"" button\n\nThe Create Network dialogue does not have\na cancel button. Add button for more usability\n\nChange-Id: I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd\nCloses-Bug: #1372304\n'}, {'number': 3, 'created': '2014-10-01 14:10:17.000000000', 'files': ['openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/project/networks/templates/networks/create.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/996ca1f590bcae8f9c8448feac6588b6a2498d8d', 'message': 'Add ""cancel"" button\n\nThe Create Network dialogue does not have\na cancel button. Add button for more usability\n\nChange-Id: I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd\nCloses-Bug: #1372304\n'}]",0,124749,996ca1f590bcae8f9c8448feac6588b6a2498d8d,14,6,3,12355,,,0,"Add ""cancel"" button

The Create Network dialogue does not have
a cancel button. Add button for more usability

Change-Id: I4f6c1d0cf40657fad892d5f64dc0a9042c0371bd
Closes-Bug: #1372304
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/124749/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_workflow.html'],1,2cc5da7ba2796d9fe3a8a8f8b8f958dc9a319d1c,bug/1372304," <div class=""col-sm-6""> <a href=""{% url 'horizon:project:networks:index' %}"" class=""btn btn-default secondary cancel close"">{% trans ""Cancel"" %}</a> </div>",,3,0
openstack%2Fcinder~master~I9392fd5dd79eb44f252bf50217f17cc473e6f2f0,openstack/cinder,master,I9392fd5dd79eb44f252bf50217f17cc473e6f2f0,Handle eqlx SSH connection close on abort.,MERGED,2014-09-26 20:25:48.000000000,2014-10-04 22:01:32.000000000,2014-10-02 22:35:58.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10503}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-09-26 20:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b22bfbf8146ed2c1606f4b928013e51d0e986e94', 'message': 'Handle SSH connection close on abort.\n\nArray CLI operation timeout causes the SSH thread\nto be aborted. This would cause SSH sessions to\nbe orphaned and hit a max connection limit on the\narray. This fix catches these aborts and makes\nsure the connection is closed.\n\nChange-Id: I9392fd5dd79eb44f252bf50217f17cc473e6f2f0\nCloses-Bug: 1374613\n'}, {'number': 2, 'created': '2014-09-26 20:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e3c8db159ecfe9ff1653916af838257ccd27f23', 'message': 'Handle eqlx SSH connection close on abort.\n\nEqualLogic array CLI operation timeout causes the\nSSH thread to be aborted. This would cause SSH\nsessions to be orphaned and hit a max connection\nlimit on the array. This fix catches these aborts\nand makes sure the connection is closed.\n\nChange-Id: I9392fd5dd79eb44f252bf50217f17cc473e6f2f0\nCloses-Bug: 1374613\n'}, {'number': 3, 'created': '2014-10-02 15:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/da539fafe46cc7d7f2d14782cd9895d732bc63ff', 'message': 'Handle eqlx SSH connection close on abort.\n\nEqualLogic array CLI operation timeout causes the\nSSH thread to be aborted. This would cause SSH\nsessions to be orphaned and hit a max connection\nlimit on the array. This fix catches these aborts\nand makes sure the connection is closed.\n\nChange-Id: I9392fd5dd79eb44f252bf50217f17cc473e6f2f0\nCloses-Bug: 1374613\n'}, {'number': 4, 'created': '2014-10-02 15:36:53.000000000', 'files': ['cinder/volume/drivers/eqlx.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cb23b67c53437fc51a6b37acac477fba4d6a7ab', 'message': 'Handle eqlx SSH connection close on abort.\n\nEqualLogic array CLI operation timeout causes the\nSSH thread to be aborted. This would cause SSH\nsessions to be orphaned and hit a max connection\nlimit on the array. This fix catches these aborts\nand makes sure the connection is closed.\n\nChange-Id: I9392fd5dd79eb44f252bf50217f17cc473e6f2f0\nCloses-Bug: 1374613\n'}]",0,124509,5cb23b67c53437fc51a6b37acac477fba4d6a7ab,28,10,4,11904,,,0,"Handle eqlx SSH connection close on abort.

EqualLogic array CLI operation timeout causes the
SSH thread to be aborted. This would cause SSH
sessions to be orphaned and hit a max connection
limit on the array. This fix catches these aborts
and makes sure the connection is closed.

Change-Id: I9392fd5dd79eb44f252bf50217f17cc473e6f2f0
Closes-Bug: 1374613
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/124509/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/eqlx.py'],1,b22bfbf8146ed2c1606f4b928013e51d0e986e94,bug/1374613," completed = False try: chan.invoke_shell() LOG.debug(""Reading CLI MOTD"") self._get_output(chan) cmd = 'stty columns 255' LOG.debug(""Setting CLI terminal width: '%s'"", cmd) chan.send(cmd + '\r') out = self._get_output(chan) LOG.debug(""Sending CLI command: '%s'"", command) chan.send(command + '\r') out = self._get_output(chan) completed = True if any(ln.startswith(('% Error', 'Error:')) for ln in out): desc = _(""Error executing EQL command"") cmdout = '\n'.join(out) LOG.error(cmdout) raise processutils.ProcessExecutionError( stdout=cmdout, cmd=command, description=desc) return out finally: if not completed: LOG.debug(""Timed out executing command: '%s'"", command) chan.close() # Every record has 2 lines # sanity check"," chan.invoke_shell() LOG.debug(""Reading CLI MOTD"") self._get_output(chan) cmd = 'stty columns 255' LOG.debug(""Setting CLI terminal width: '%s'"", cmd) chan.send(cmd + '\r') out = self._get_output(chan) LOG.debug(""Sending CLI command: '%s'"", command) chan.send(command + '\r') out = self._get_output(chan) chan.close() if any(line.startswith(('% Error', 'Error:')) for line in out): desc = _(""Error executing EQL command"") cmdout = '\n'.join(out) LOG.error(cmdout) raise processutils.ProcessExecutionError( stdout=cmdout, cmd=command, description=desc) return out #Every record has 2 lines #sanity check",27,20
openstack%2Fdevstack~master~I650697df015fed8f400101a13b6165ac39626877,openstack/devstack,master,I650697df015fed8f400101a13b6165ac39626877,Relocate SERVICE_TIMEOUT to stackrc,MERGED,2014-09-19 16:29:43.000000000,2014-10-04 20:52:22.000000000,2014-10-04 20:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-19 16:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40aa131116c8640da3439d29716213e4ae43238d', 'message': ""Add SERVICE_TIMEOUT to cinder_driver_cert.sh\n\nUpdates to devstack added a SERVICE_TIMEOUT var\nto stack.sh that's used in lib/cinder\n\nThe cinder_driver_cert.sh script doesn't source\nstack.sh but restarts cinder services via lib/cinder\nso fails for undefined variable.\n\nThis patch just adds the SERVICE_TIMEOUT var to the cert\nscript.  At some point this may go away entirely but for\nnow we should keep it maintained and working.\n\nChange-Id: I650697df015fed8f400101a13b6165ac39626877\nCloses-Bug: 1350221\n""}, {'number': 2, 'created': '2014-09-29 15:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fe28470310c3907ca4775eaab1eb722b71b11f61', 'message': 'Relocate SERVICE_TIMEOUT to stackrc\n\ncinder_driver_cert.sh restarts volume services\nand needs the SERVICE_TIMEOUT variable set, but\nthat was being declared in stack.sh.\n\nRather than create another duplicate variable in\nthe cert script, just move the SERVICE_TIMEOUT\nvariable to stackrc so it can be shared like other\ncommon variables.\n\nChange-Id: I650697df015fed8f400101a13b6165ac39626877\nCloses-Bug: 1350221\n'}, {'number': 3, 'created': '2014-09-29 21:14:04.000000000', 'files': ['stackrc', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/44e16e01da9d3b7d647d379f8c9cab763fc7912a', 'message': 'Relocate SERVICE_TIMEOUT to stackrc\n\ncinder_driver_cert.sh restarts volume services\nand needs the SERVICE_TIMEOUT variable set, but\nthat was being declared in stack.sh.\n\nRather than create another duplicate variable in\nthe cert script, just move the SERVICE_TIMEOUT\nvariable to stackrc so it can be shared like other\ncommon variables.\n\nChange-Id: I650697df015fed8f400101a13b6165ac39626877\nCloses-Bug: 1350221\n'}]",1,122783,44e16e01da9d3b7d647d379f8c9cab763fc7912a,24,8,3,2243,,,0,"Relocate SERVICE_TIMEOUT to stackrc

cinder_driver_cert.sh restarts volume services
and needs the SERVICE_TIMEOUT variable set, but
that was being declared in stack.sh.

Rather than create another duplicate variable in
the cert script, just move the SERVICE_TIMEOUT
variable to stackrc so it can be shared like other
common variables.

Change-Id: I650697df015fed8f400101a13b6165ac39626877
Closes-Bug: 1350221
",git fetch https://review.opendev.org/openstack/devstack refs/changes/83/122783/1 && git format-patch -1 --stdout FETCH_HEAD,['driver_certs/cinder_driver_cert.sh'],1,40aa131116c8640da3439d29716213e4ae43238d,bug/1350221,SERVICE_TIMEOUT=${SERVICE_TIMEOUT:-60},,1,0
openstack%2Fdevstack~master~I8e00071612d79959531feffc7e7993fa8c536359,openstack/devstack,master,I8e00071612d79959531feffc7e7993fa8c536359,don't set nova.conf auth_strategy,MERGED,2014-09-26 17:18:36.000000000,2014-10-04 20:27:57.000000000,2014-10-02 20:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 7715}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-26 17:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fa81f0aa14cc28776fc8ecafe49ba75044b0949e', 'message': ""don't set nova.conf auth_strategy\n\nkeystone is the default value, so no need to override it.\n\nChange-Id: I8e00071612d79959531feffc7e7993fa8c536359\n""}, {'number': 2, 'created': '2014-10-01 19:11:53.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/82d6e537522083749a664b99e1bdca2d8a33c6b9', 'message': ""don't set nova.conf auth_strategy\n\nkeystone is the default value, so no need to override it.\n\nChange-Id: I8e00071612d79959531feffc7e7993fa8c536359\n""}]",0,124469,82d6e537522083749a664b99e1bdca2d8a33c6b9,23,7,2,1849,,,0,"don't set nova.conf auth_strategy

keystone is the default value, so no need to override it.

Change-Id: I8e00071612d79959531feffc7e7993fa8c536359
",git fetch https://review.opendev.org/openstack/devstack refs/changes/69/124469/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,fa81f0aa14cc28776fc8ecafe49ba75044b0949e,nova-auth,," iniset $NOVA_CONF DEFAULT auth_strategy ""keystone""",0,1
openstack%2Fnova~master~I748a47ecf6b6f0a2ff14db2bcd402163fc0b011e,openstack/nova,master,I748a47ecf6b6f0a2ff14db2bcd402163fc0b011e,Fixes potential reliablity issue with missing CONF import,MERGED,2014-09-25 06:19:27.000000000,2014-10-04 19:39:13.000000000,2014-10-04 19:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5367}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-09-25 06:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cb31e7cf6c68f2993694dbff5e583c3ab1804b6', 'message': 'Adds missing keys_path CONF imports\n\nAdds missing CONF.import lines for the keys_path\nconfig option in crypto.py\n\nChange-Id: I748a47ecf6b6f0a2ff14db2bcd402163fc0b011e\n'}, {'number': 2, 'created': '2014-09-26 04:19:27.000000000', 'files': ['nova/api/openstack/compute/contrib/cloudpipe.py', 'nova/cloudpipe/pipelib.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dfac11584cbbf20c98efcbf7b94a69cefda0514c', 'message': 'Fixes potential reliablity issue with missing CONF import\n\nAdds missing CONF.import lines for the keys_path\nconfig option in crypto.py. Although the code currently\nappears to work fine, missing import options can result\nin flakey unittests and so most likely problems in real\nNova setups as well.\n\nChange-Id: I748a47ecf6b6f0a2ff14db2bcd402163fc0b011e\n'}]",1,123942,dfac11584cbbf20c98efcbf7b94a69cefda0514c,25,9,2,5292,,,0,"Fixes potential reliablity issue with missing CONF import

Adds missing CONF.import lines for the keys_path
config option in crypto.py. Although the code currently
appears to work fine, missing import options can result
in flakey unittests and so most likely problems in real
Nova setups as well.

Change-Id: I748a47ecf6b6f0a2ff14db2bcd402163fc0b011e
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/123942/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/cloudpipe.py', 'nova/cloudpipe/pipelib.py']",2,7cb31e7cf6c68f2993694dbff5e583c3ab1804b6,cloudpipe_add_conf_import,"CONF.import_opt('keys_path', 'nova.crypto')",,3,0
openstack%2Fsolum~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/solum,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,ABANDONED,2014-10-04 18:53:31.000000000,2014-10-04 19:29:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-10-04 18:53:31.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/66292946588cd9bb23dd55921ae45dc01afa2bd4', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,126163,66292946588cd9bb23dd55921ae45dc01afa2bd4,3,1,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/solum refs/changes/63/126163/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,66292946588cd9bb23dd55921ae45dc01afa2bd4,bug/1368910,," 'sphinx.ext.intersphinx', # Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None}",0,4
openstack%2Ftaskflow~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/taskflow,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,ABANDONED,2014-10-04 18:48:28.000000000,2014-10-04 19:27:39.000000000,,[{'_account_id': 1297}],"[{'number': 1, 'created': '2014-10-04 18:48:28.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0a831a881b3fceb2b4abb6f9337fd9adb127c433', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,126157,0a831a881b3fceb2b4abb6f9337fd9adb127c433,3,1,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/57/126157/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,0a831a881b3fceb2b4abb6f9337fd9adb127c433,bug/1368910,," 'sphinx.ext.intersphinx',# Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None} ",0,4
openstack%2Fosprofiler~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/osprofiler,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,MERGED,2014-10-04 18:51:19.000000000,2014-10-04 19:08:30.000000000,2014-10-04 19:08:30.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-10-04 18:51:19.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/c8c1869a893e7aa391b272c54ede8c475650ffc4', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,126160,c8c1869a893e7aa391b272c54ede8c475650ffc4,6,2,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/60/126160/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,c8c1869a893e7aa391b272c54ede8c475650ffc4,bug/1368910,," 'sphinx.ext.intersphinx', # Example configuration for intersphinx: refer to the Python standard library. intersphinx_mapping = {'http://docs.python.org/': None}",0,5
openstack%2Fkolla~master~I30681d64a186e597cdd6691b4c807fea7b6c531c,openstack/kolla,master,I30681d64a186e597cdd6691b4c807fea7b6c531c,Updating the README to show starting services before pods,MERGED,2014-10-03 20:55:36.000000000,2014-10-04 18:42:42.000000000,2014-10-04 18:42:41.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-03 20:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ee085d8c6b6aaa3be6eae4f455762868c4213ed5', 'message': 'adding ADDR env vars while the start script depends on them\n\nChange-Id: I30681d64a186e597cdd6691b4c807fea7b6c531c\n'}, {'number': 2, 'created': '2014-10-03 20:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6205a12bb0163213fa0b892a466ef628de800994', 'message': 'adding ADDR env vars while the start script depends on them\n\nChange-Id: I30681d64a186e597cdd6691b4c807fea7b6c531c\n'}, {'number': 3, 'created': '2014-10-03 21:12:32.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/db3c5081809df4ab86c13888ca666d06ffced7b6', 'message': 'Updating the README to show starting services\nbefore pods\n\nChange-Id: I30681d64a186e597cdd6691b4c807fea7b6c531c\n'}]",2,126070,db3c5081809df4ab86c13888ca666d06ffced7b6,12,3,3,5792,,,0,"Updating the README to show starting services
before pods

Change-Id: I30681d64a186e597cdd6691b4c807fea7b6c531c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/70/126070/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/keystone/keystone.json', 'README.md']",2,ee085d8c6b6aaa3be6eae4f455762868c4213ed5,radez/keystone,curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/mariadb/mariadb-service.json > mariadb-service.json$ curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/keystone/keystone-service-35357.json > keystone-service-35357.json $ curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/keystone/keystone-service-5000.json > keystone-service-5000.json``` Make sure to edit the keystone.json file and update KEYSTONEMASTER_PORT_5000_TCP_ADDR and KEYSTONEMASTER_PORT_35357_TCP_ADDR to the IP address that will reach one of the kube nodes ```,curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/mariadb/mariadb-service.json > mariadb-service.json$ curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/keystone/keystone-service-35357.json > keystone-service-35357.json $ curl https://raw.githubusercontent.com/stackforge/kolla/master/docker/keystone/keystone-service-5000.json > keystone-service-5000.json,9,6
openstack%2Fkolla~master~I444d5c2256a85223f8750a0904cb4b07f18ab67f,openstack/kolla,master,I444d5c2256a85223f8750a0904cb4b07f18ab67f,introduce a new build mechanism,MERGED,2014-10-03 20:21:41.000000000,2014-10-04 18:24:22.000000000,2014-10-04 18:24:22.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 8745}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-10-03 20:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/775a03baacc58745bb2bbde980bb168e540cf7b5', 'message': 'introduce a new build mechanism\n\nThis patch replaces the collection of individual ""build"" scripts with a\nsingle script (tools/build-docker-image), made available as ""build""\ninside each image directory.\n\nThe build-docker-image script will, by default, build images tagged with\nthe current commit id in order to prevent developers from accidentally\nstepping on each other or on release images.\n\nDocumentation in docs/image-building.md describes the script in more\ndetail.\n\nChange-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f\n'}, {'number': 2, 'created': '2014-10-04 14:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/006b3c1f48c331f029c7a62a3fef912332a79614', 'message': 'introduce a new build mechanism\n\nThis patch replaces the collection of individual ""build"" scripts with a\nsingle script (tools/build-docker-image), made available as ""build""\ninside each image directory.\n\nThe build-docker-image script will, by default, build images tagged with\nthe current commit id in order to prevent developers from accidentally\nstepping on each other or on release images.\n\nDocumentation in docs/image-building.md describes the script in more\ndetail.\n\nChange-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f\n'}, {'number': 3, 'created': '2014-10-04 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2a956f6c4f56d053a168118f6ef0d00e042b38ae', 'message': 'introduce a new build mechanism\n\nThis patch replaces the collection of individual ""build"" scripts with a\nsingle script (tools/build-docker-image), made available as ""build""\ninside each image directory.\n\nThe build-docker-image script will, by default, build images tagged with\nthe current commit id in order to prevent developers from accidentally\nstepping on each other or on release images.\n\nDocumentation in docs/image-building.md describes the script in more\ndetail.\n\nChange-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f\n'}, {'number': 4, 'created': '2014-10-04 14:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6b9760cbd0ea20caac30b1a44d10c19be831449c', 'message': 'introduce a new build mechanism\n\nThis patch replaces the collection of individual ""build"" scripts with a\nsingle script (tools/build-docker-image), made available as ""build""\ninside each image directory.\n\nThe build-docker-image script will, by default, build images tagged with\nthe current commit id in order to prevent developers from accidentally\nstepping on each other or on release images.\n\nDocumentation in docs/image-building.md describes the script in more\ndetail.\n\nChange-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f\n'}, {'number': 5, 'created': '2014-10-04 15:05:08.000000000', 'files': ['docker/build', 'docker/glance/glance-base/build', 'docker/fedora-rdo-base/build', 'docker/mariadb/build', 'docker/swift/swift-account/push', 'docker/heat/heat-base/push', 'docker/swift/swift-object/push', 'tools/update-build-links', 'docker/glance/glance-base/push', 'docker/heat/heat-api/push', 'tools/build-docker-image', 'docker/rabbitmq/push', 'docker/nova-compute/nova-libvirt/push', 'docker/swift/swift-proxy-server/build', 'docker/mariadb/push', 'docker/keystone/push', 'docker/nova-compute/nova-compute/push', 'docker/glance/glance-registry/build', 'docker/nova-compute/nova-base/push', 'docker/glance/glance-api/build', 'docs/image-building.md', 'docker/swift/swift-container/push', 'docker/rhel-osp-base/build', 'docker/rabbitmq/build', 'docker/heat/heat-base/build', 'docker/glance/glance-api/push', 'docker/cinder/build', 'docker/glance/build', 'docker/nova-compute/nova-compute/build', 'docker/swift/swift-container/build', 'docker/swift/swift-proxy-server/push', 'docker/keystone/build', 'docker/nova-compute/push', 'docker/swift/swift-base/build', 'docker/heat/heat-engine/push', 'docker/nova-compute/build', 'docker/swift/swift-object/build', 'docker/nova-compute/nova-base/build', 'docker/glance/push', 'docker/swift/swift-account/build', 'docker/heat/heat-api/build', 'docker/nova-compute/nova-libvirt/build', 'docker/heat/heat-engine/build', 'docker/swift/swift-base/push', 'docker/fedora-rdo-base/push', 'docker/glance/glance-registry/push', 'docker/cinder/push'], 'web_link': 'https://opendev.org/openstack/kolla/commit/24b6db92bc5cf56a5e2c1da3481ee57bddba7c80', 'message': 'introduce a new build mechanism\n\nThis patch replaces the collection of individual ""build"" scripts with a\nsingle script (tools/build-docker-image), made available as ""build""\ninside each image directory.\n\nThe build-docker-image script will, by default, build images tagged with\nthe current commit id in order to prevent developers from accidentally\nstepping on each other or on release images.\n\nDocumentation in docs/image-building.md describes the script in more\ndetail.\n\nChange-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f\n'}]",17,126057,24b6db92bc5cf56a5e2c1da3481ee57bddba7c80,18,4,5,8745,,,0,"introduce a new build mechanism

This patch replaces the collection of individual ""build"" scripts with a
single script (tools/build-docker-image), made available as ""build""
inside each image directory.

The build-docker-image script will, by default, build images tagged with
the current commit id in order to prevent developers from accidentally
stepping on each other or on release images.

Documentation in docs/image-building.md describes the script in more
detail.

Change-Id: I444d5c2256a85223f8750a0904cb4b07f18ab67f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/57/126057/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/build', 'docker/glance/glance-base/build', 'docker/fedora-rdo-base/build', 'docker/mariadb/build', 'docker/swift/swift-account/push', 'docker/heat/heat-base/push', 'docker/swift/swift-object/push', 'tools/update-build-links', 'docker/glance/glance-base/push', 'docker/heat/heat-api/push', 'tools/build-docker-image', 'docker/rabbitmq/push', 'docker/nova-compute/nova-libvirt/push', 'docker/swift/swift-proxy-server/build', 'docker/mariadb/push', 'docker/keystone/push', 'docker/nova-compute/nova-compute/push', 'docker/glance/glance-registry/build', 'docker/nova-compute/nova-base/push', 'docker/glance/glance-api/build', 'docs/image-building.md', 'docker/swift/swift-container/push', 'docker/rhel-osp-base/build', 'docker/rabbitmq/build', 'docker/heat/heat-base/build', 'docker/glance/glance-api/push', 'docker/cinder/build', 'docker/glance/build', 'docker/nova-compute/nova-compute/build', 'docker/swift/swift-container/build', 'docker/swift/swift-proxy-server/push', 'docker/keystone/build', 'docker/nova-compute/push', 'docker/swift/swift-base/build', 'docker/heat/heat-engine/push', 'docker/nova-compute/build', 'docker/swift/swift-object/build', 'docker/nova-compute/nova-base/build', 'docker/glance/push', 'docker/swift/swift-account/build', 'docker/heat/heat-api/build', 'docker/nova-compute/nova-libvirt/build', 'docker/heat/heat-engine/build', 'docker/swift/swift-base/push', 'docker/fedora-rdo-base/push', 'docker/glance/glance-registry/push', 'docker/cinder/push']",47,775a03baacc58745bb2bbde980bb168e540cf7b5,larsks/crux,,#!/bin/bash docker push kollaglue/fedora-rdo-cinder . ,187,96
openstack%2Fopenstack-manuals~master~Ifff63dcf86499559e5bddf49f36309840059cd03,openstack/openstack-manuals,master,Ifff63dcf86499559e5bddf49f36309840059cd03,vmware-vmdk-driver: mark notes as notes,MERGED,2014-10-01 20:03:26.000000000,2014-10-04 17:46:43.000000000,2014-10-04 17:46:42.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-10-01 20:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e0b97af1443843099d3cd15b866e921b192c506', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}, {'number': 2, 'created': '2014-10-01 20:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/27ea4867164f3d6a74c4d34f8ae1c2948db0d9df', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}, {'number': 3, 'created': '2014-10-02 06:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e8c6230723c64160cd3486134e70eabc6874a91c', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}, {'number': 4, 'created': '2014-10-02 06:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/057eda799a8813f52feb15628df6e21be632617b', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}, {'number': 5, 'created': '2014-10-04 08:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/94d62bb5f2426f3c535994176a48266c56850c07', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}, {'number': 6, 'created': '2014-10-04 15:41:08.000000000', 'files': ['doc/config-reference/block-storage/drivers/vmware-vmdk-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d46d516c73ab3a00836dc34274a51f130aed976b', 'message': 'vmware-vmdk-driver: mark notes as notes\n\nChange-Id: Ifff63dcf86499559e5bddf49f36309840059cd03\n'}]",7,125486,d46d516c73ab3a00836dc34274a51f130aed976b,19,4,6,167,,,0,"vmware-vmdk-driver: mark notes as notes

Change-Id: Ifff63dcf86499559e5bddf49f36309840059cd03
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/86/125486/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/vmware-vmdk-driver.xml'],1,9e0b97af1443843099d3cd15b866e921b192c506,notes_vmware_vmdk_driver," <para>Create, delete, attach, and detach volumes. <note> <para>When a volume is attached to an instance, a reconfigure operation is performed on the instance to add the volume's VMDK to it. The user must manually rescan and mount the device from within the guest operating system.</para> </note> <para>Create, list, and delete volume snapshots.</para> <note> <para>Allowed only if volume is not attached to an instance.</para> </note> <para>Copy a volume to an image.</para> <note> <para>Allowed only if volume is not attached to an instance.</para> </note> <para>Clone a volume.</para> <note> <para>Supported only if source volume is not attached to an instance.</para> </note> <para>Restore backup to new or existing volume.</para> <note>Supported only if the existing volume doesn't contain snapshots.</para> </note>"," <para>Create, delete, attach, and detach volumes. (When a volume is attached to an instance, a reconfigure operation is performed on the instance to add the volume's VMDK to it. The user must manually rescan and mount the device from within the guest operating system.)</para> <para>Create, list, and delete volume snapshots. (Allowed only if volume is not attached to an instance.)</para> <para>Copy a volume to an image. (Allowed only if volume is not attached to an instance.)</para> <para>Clone a volume. (Supported only if source volume is not attached to an instance.)</para> <para>Restore backup to new or existing volume. (Supported only if the existing volume doesn't contain snapshots.)</para>",26,13
openstack%2Fopenstack-manuals~master~Id9fd4465ac5b39e63659322dbf3156d33ac0c778,openstack/openstack-manuals,master,Id9fd4465ac5b39e63659322dbf3156d33ac0c778,Stop splitting problem and solution on 2 pages,MERGED,2014-10-04 14:49:39.000000000,2014-10-04 17:42:47.000000000,2014-10-04 17:42:46.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 14:49:39.000000000', 'files': ['doc/admin-guide-cloud/blockstorage/section_ts_failed_attach_vol_after_detach.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_no_emulator_x86_64.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_multipath_warn.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_failed_connect_vol_FC_SAN.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_duplicate_3par_host.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_failed_attach_vol_no_sysfsutils.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_non_existent_vlun.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_HTTP_bad_req_in_cinder_vol_log.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_non_existent_host.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_cinder_config.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_vol_attach_miss_sg_scan.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_eql_volume_size.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/66d6a9aedb199fa438857c6c31e94a084b364cc8', 'message': 'Stop splitting problem and solution on 2 pages\n\nChange-Id: Id9fd4465ac5b39e63659322dbf3156d33ac0c778\n'}]",0,126147,66d6a9aedb199fa438857c6c31e94a084b364cc8,7,3,1,7923,,,0,"Stop splitting problem and solution on 2 pages

Change-Id: Id9fd4465ac5b39e63659322dbf3156d33ac0c778
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/126147/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/blockstorage/section_ts_failed_attach_vol_after_detach.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_no_emulator_x86_64.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_multipath_warn.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_failed_connect_vol_FC_SAN.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_duplicate_3par_host.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_failed_attach_vol_no_sysfsutils.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_non_existent_vlun.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_HTTP_bad_req_in_cinder_vol_log.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_non_existent_host.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_cinder_config.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_vol_attach_miss_sg_scan.xml', 'doc/admin-guide-cloud/blockstorage/section_ts_eql_volume_size.xml']",12,66d6a9aedb199fa438857c6c31e94a084b364cc8,ts_chunks, <?dbhtml stop-chunking?>,,12,0
openstack%2Ftripleo-image-elements~master~Ib7289929093f03ad39bb0aaa8e75f7e0842a9f5f,openstack/tripleo-image-elements,master,Ib7289929093f03ad39bb0aaa8e75f7e0842a9f5f,SELinux: Allow swift access to ephemeral ports,MERGED,2014-09-30 01:54:50.000000000,2014-10-04 16:13:45.000000000,2014-10-04 16:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 7585}]","[{'number': 1, 'created': '2014-09-30 01:54:50.000000000', 'files': ['elements/swift/os-refresh-config/configure.d/20-swift-selinux'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/531841d38d69754dafef7a15098e408c83a0d832', 'message': 'SELinux: Allow swift access to ephemeral ports\n\nEnable the swift_can_network SELinux boolean to allow\nswift access to ephemeral ports.\n\nChange-Id: Ib7289929093f03ad39bb0aaa8e75f7e0842a9f5f\nCloses-Bug: 1375526\n'}]",1,124940,531841d38d69754dafef7a15098e408c83a0d832,11,4,1,7471,,,0,"SELinux: Allow swift access to ephemeral ports

Enable the swift_can_network SELinux boolean to allow
swift access to ephemeral ports.

Change-Id: Ib7289929093f03ad39bb0aaa8e75f7e0842a9f5f
Closes-Bug: 1375526
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/40/124940/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift/os-refresh-config/configure.d/20-swift-selinux'],1,531841d38d69754dafef7a15098e408c83a0d832,bug/1375526,#!/bin/bash set -eux set -o pipefail # Allow swift access to ephemeral ports # https://bugs.launchpad.net/tripleo/+bug/1375526 if [[ -x /usr/sbin/semanage ]]; then setsebool -P swift_can_network 1 fi ,,9,0
openstack%2Fswift~master~I31b5e6b0f2922150902e1bfa52144302ee0c7a8e,openstack/swift,master,I31b5e6b0f2922150902e1bfa52144302ee0c7a8e,Imported Translations from Transifex,MERGED,2014-10-03 06:16:09.000000000,2014-10-04 14:26:48.000000000,2014-10-04 14:26:48.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 6547}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-03 06:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/12c10377118f5553806752f69a0b151fb2ef8d2e', 'message': 'Imported Translations from Transifex\n\nChange-Id: I31b5e6b0f2922150902e1bfa52144302ee0c7a8e\n'}, {'number': 2, 'created': '2014-10-04 06:07:48.000000000', 'files': ['swift/locale/en_GB/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-info.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-info.po', 'swift/locale/fr/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-warning.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-warning.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-error.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-error.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-warning.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-info.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-error.po'], 'web_link': 'https://opendev.org/openstack/swift/commit/94fd95ba30c72fbcb03367aaa8da407a408948d5', 'message': 'Imported Translations from Transifex\n\nChange-Id: I31b5e6b0f2922150902e1bfa52144302ee0c7a8e\n'}]",0,125886,94fd95ba30c72fbcb03367aaa8da407a408948d5,13,4,2,11131,,,0,"Imported Translations from Transifex

Change-Id: I31b5e6b0f2922150902e1bfa52144302ee0c7a8e
",git fetch https://review.opendev.org/openstack/swift refs/changes/86/125886/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/locale/en_GB/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-info.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-info.po', 'swift/locale/fr/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-warning.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-warning.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-critical.po', 'swift/locale/fr/LC_MESSAGES/swift-log-error.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-error.po', 'swift/locale/ko_KR/LC_MESSAGES/swift-log-warning.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-info.po', 'swift/locale/en_GB/LC_MESSAGES/swift-log-error.po']",12,12c10377118f5553806752f69a0b151fb2ef8d2e,transifex/translations,,"# Translations template for heat. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the heat project. # # Translators: # Andi Chandler <andi@gowling.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Swift\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-09-22 06:07+0000\n"" ""PO-Revision-Date: 2014-07-25 23:08+0000\n"" ""Last-Translator: Andi Chandler <andi@gowling.com>\n"" ""Language-Team: English (United Kingdom) (http://www.transifex.com/projects/p/"" ""swift/language/en_GB/)\n"" ""Language: en_GB\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" ",0,252
openstack%2Frally~master~I06088aa09218c2c60e630cd60b317ede3bc9341b,openstack/rally,master,I06088aa09218c2c60e630cd60b317ede3bc9341b,Testing bug #1370166,ABANDONED,2014-09-23 00:09:46.000000000,2014-10-04 13:30:22.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-09-23 00:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/029f0382c6887be3f197661eb564dd9544d983d6', 'message': 'Testing bug #1370166\n\nChange-Id: I06088aa09218c2c60e630cd60b317ede3bc9341b\n'}, {'number': 2, 'created': '2014-09-25 06:06:37.000000000', 'files': ['rally-scenarios/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/6104b0a470ac78849d062999c1072c9e23c09de3', 'message': 'Testing bug #1370166\n\nChange-Id: I06088aa09218c2c60e630cd60b317ede3bc9341b\n'}]",0,123290,6104b0a470ac78849d062999c1072c9e23c09de3,7,2,2,6172,,,0,"Testing bug #1370166

Change-Id: I06088aa09218c2c60e630cd60b317ede3bc9341b
",git fetch https://review.opendev.org/openstack/rally refs/changes/90/123290/2 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/rally.yaml'],1,029f0382c6887be3f197661eb564dd9544d983d6,bug/1370166,"{ ""CeilometerQueries.create_and_query_samples"": [ { ""args"": { ""filter"": {""="": {""counter_unit"": ""instance""}}, ""orderby"": null, ""limit"": 10, ""counter_name"": ""cpu_util"", ""counter_type"": ""gauge"", ""counter_unit"": ""instance"", ""counter_volume"": 1.0, ""resource_id"": ""resource_id"" }, ""runner"": { ""type"": ""constant"", ""times"": 5000, ""concurrency"": 20 }, ""context"": { ""users"": { ""tenants"": 5, ""users_per_tenant"": 5 } } } ] }","--- KeystoneBasic.create_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 KeystoneBasic.create_delete_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 KeystoneBasic.create_and_list_tenants: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 KeystoneBasic.create_and_list_users: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 KeystoneBasic.create_tenant: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 KeystoneBasic.create_tenant_with_users: - args: name_length: 10 users_per_tenant: 10 runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 3 sla: max_failure_percent: 0 KeystoneBasic.create_delete_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: max_failure_percent: 0 CeilometerAlarms.create_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerAlarms.create_and_delete_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerAlarms.create_and_list_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerAlarms.create_and_update_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerAlarms.list_alarms: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerMeters.list_meters: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerResource.list_resources: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 Dummy.dummy: - args: sleep: 0.25 runner: type: ""constant"" times: 20 concurrency: 5 sla: max_failure_percent: 0 - args: sleep: 0.001 runner: type: ""rps"" times: 2000 rps: 200 sla: max_failure_percent: 0 - args: sleep: 0.01 runner: type: ""constant"" times: 1 concurrency: 1 context: quotas: nova: instances: 200 cores: 200 ram: -1 floating_ips: 200 fixed_ips: 200 metadata_items: -1 injected_files: -1 injected_file_content_bytes: -1 injected_file_path_bytes: -1 key_pairs: 500 security_groups: 400 security_group_rules: 600 cinder: gigabytes: -1 snapshots: -1 volumes: -1 sla: max_failure_percent: 0 Dummy.dummy_exception: - args: size_of_message: 5 runner: type: ""constant"" times: 20 concurrency: 5 Dummy.dummy_exception_probability: - args: exception_probability: 0.5 runner: type: ""constant"" times: 100 concurrency: 1 - args: exception_probability: 0.05 runner: type: ""constant"" times: 2042 concurrency: 1 Dummy.dummy_with_scenario_output: - runner: type: ""constant"" times: 20 concurrency: 10 sla: max_failure_percent: 0 FakePlugin.testplugin: - runner: type: ""constant"" times: 4 concurrency: 4 sla: max_failure_percent: 0 CeilometerStats.create_meter_and_get_stats: - args: user_id: ""user-id"" resource_id: ""resource-id"" counter_volume: 1.0 counter_unit: """" counter_type: ""cumulative"" runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerQueries.create_and_query_alarms: - args: filter: {""and"": [{""!="": {""state"": ""dummy_state""}},{""="": {""type"": ""threshold""}}]} orderby: !!null limit: 10 meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerQueries.create_and_query_alarm_history: - args: orderby: !!null limit: !!null meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CeilometerQueries.create_and_query_samples: - args: filter: {""="": {""counter_unit"": ""instance""}} orderby: !!null limit: 10 counter_name: ""cpu_util"" counter_type: ""gauge"" counter_unit: ""instance"" counter_volume: ""1.0"" resource_id: ""resource_id"" runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 HeatStacks.create_and_list_stack: - runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 HeatStacks.create_and_delete_stack: - runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 2 users_per_tenant: 3 sla: max_failure_percent: 0 Authenticate.keystone: - runner: type: ""constant"" times: 40 concurrency: 20 context: users: tenants: 2 users_per_tenant: 10 sla: max_failure_percent: 0 SaharaNodeGroupTemplates.create_and_list_node_group_templates: - args: flavor: name: ""m1.small"" runner: type: ""constant"" times: 20 concurrency: 20 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 SaharaNodeGroupTemplates.create_delete_node_group_templates: - args: flavor: name: ""m1.small"" runner: type: ""constant"" times: 20 concurrency: 20 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 Authenticate.validate_cinder: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: max_failure_percent: 0 Authenticate.validate_glance: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: max_failure_percent: 0 Authenticate.validate_heat: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: max_failure_percent: 0 Authenticate.validate_nova: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: max_failure_percent: 0 Quotas.cinder_update_and_delete: - args: max_quota: 1024 runner: type: ""constant"" times: 4 concurrency: 1 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 Quotas.cinder_update: - args: max_quota: 1024 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 Quotas.nova_update_and_delete: - args: max_quota: 1024 runner: type: ""constant"" times: 4 concurrency: 1 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 Quotas.nova_update: - args: max_quota: 1024 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 CinderVolumes.create_and_delete_volume: - args: size: 1 runner: type: ""constant"" times: 3 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: max_failure_percent: 0 CinderVolumes.create_and_list_volume: - args: size: 1 detailed: True runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CinderVolumes.create_volume: - args: size: 1 runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: max_failure_percent: 0 CinderVolumes.create_and_delete_snapshot: - args: force: false runner: type: ""constant"" times: 3 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 sla: max_failure_percent: 0 CinderVolumes.create_and_attach_volume: - args: volume_size: 1 image: name: ""cirros-0.3.2-x86_64-uec"" flavor: name: ""m1.tiny"" runner: type: ""constant"" times: 3 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: max_failure_percent: 0 GlanceImages.create_and_delete_image: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 6 concurrency: 6 context: users: tenants: 2 users_per_tenant: 3 sla: max_failure_percent: 0 GlanceImages.create_and_list_image: - args: image_location: ""/home/jenkins/.rally/extra/fake-image.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 6 concurrency: 6 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 GlanceImages.create_image_and_boot_instances: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" flavor: name: ""m1.tiny"" number_instances: 2 runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 1 sla: max_failure_percent: 0 GlanceImages.list_images: - runner: type: ""constant"" times: 5 concurrency: 5 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-disk.img"" image_type: ""qcow2"" image_container: ""bare"" images_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_delete_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_list_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" detailed: True runner: type: ""constant"" times: 4 concurrency: 4 context: users: tenants: 4 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.resize_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" to_flavor: name: ""m1.small"" confirm: true runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 4 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_and_bounce_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" actions: - hard_reboot: 1 - soft_reboot: 1 - stop_start: 1 - rescue_unrescue: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 4 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume_and_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 3 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 1 runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.snapshot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" auto_assign_nics: false runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 VMTasks.boot_runcommand_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" floating_network: ""public"" use_floatingip: true script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" use_floatingip: false script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 Requests.check_response: - args: url: ""http://www.google.com"" response: 302 runner: type: ""constant"" times: 10 concurrency: 5",27,964
openstack%2Frally~master~I927c91f119765f27ee6b8b7c98d4156c02700102,openstack/rally,master,I927c91f119765f27ee6b8b7c98d4156c02700102,Improve CLI functional tests,MERGED,2014-09-26 11:46:08.000000000,2014-10-04 13:12:33.000000000,2014-10-04 13:12:32.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-09-26 11:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b06c18ccbbc93894e96ef5da3c959e0c1607ebb1', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 2, 'created': '2014-09-26 20:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/976888971958b360ca5ec730416baa49f3a325d6', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 3, 'created': '2014-09-28 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/572e2dd7763e57b9d364026ca35b1bd215062eee', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 4, 'created': '2014-09-28 21:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7bf41952ea1c828ea43cff546087cf1950353314', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 5, 'created': '2014-09-29 09:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9619477288b6f71ad0c25ed30e12ee43acc869e7', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 6, 'created': '2014-09-29 11:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/93193f4f0ec19f603927248a1df62ae4ae95f5f7', 'message': 'Testing bug 1374407\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 7, 'created': '2014-09-29 12:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/20f458905d46ad2722f6d86b7ea159003fd3c3af', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 8, 'created': '2014-09-29 12:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/354e3dc5944d953a946f0736491241449543e3a5', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 9, 'created': '2014-09-29 12:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ec81a8d415a611343d495f9fa74f206869a7f092', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\n'}, {'number': 10, 'created': '2014-09-29 12:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/72f3dfdddf7616f3953748a91c182434899e0617', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 11, 'created': '2014-09-29 12:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ca2d6495f5c8947bc840444341369331679919e', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 12, 'created': '2014-09-30 12:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d4b97481a35790efc1c0b7694ef32ec8b5265901', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 13, 'created': '2014-09-30 12:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a1e84af8a9b0b67a2d9d4778fc988c81d87fb8e4', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 14, 'created': '2014-09-30 14:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1b9fbfedb795619ed0ebedac5f849d6e50d4ef89', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 15, 'created': '2014-09-30 14:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/80763b224c97571c78fd758031c8f91f0d7c9e47', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 16, 'created': '2014-10-03 20:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3349d90f221bdd8e9cfff4caaa0c92c3242366e3', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCLI functional tests have been moved to a separate directory, and the tests_ci/\ndirectory has been supplied with a README file.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 17, 'created': '2014-10-03 21:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/62a2ff851dfc323d3a58118ef81f8d6400bae8a4', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCLI functional tests have been moved to a separate directory, and the tests_ci/\ndirectory has been supplied with a README file.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 18, 'created': '2014-10-03 21:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/91bbeb875a8210706588ae70b25e8222807218e6', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCLI functional tests have been moved to a separate directory, and the tests_ci/\ndirectory has been supplied with a README file.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}, {'number': 19, 'created': '2014-10-03 22:30:36.000000000', 'files': ['tests_functional/test_cli_task.py', 'tests_functional/test_cli_deployment.py', 'tests_functional/test_cli_info.py', 'tests_ci/rally-integrated.sh', 'tests_functional/test_cli_show.py', 'tests_ci/README.rst', 'tests_functional/test_cli_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/543a7900f5ec6ce5b858d51f97e046940cefcb2a', 'message': 'Improve CLI functional tests\n\nWe fix a bug connected to wrong task configuration used in CLI tests for tasks.\nWe also refactor the tests a bit to make them more readable.\n\nCLI functional tests have been moved to a separate directory, and the tests_ci/\ndirectory has been supplied with a README file.\n\nCo-authored-by: Sergey Skripnick<sskripnick@mirantis.com>\nChange-Id: I927c91f119765f27ee6b8b7c98d4156c02700102\nCloses-Bug: 1374407\n'}]",13,124378,543a7900f5ec6ce5b858d51f97e046940cefcb2a,57,5,19,8507,,,0,"Improve CLI functional tests

We fix a bug connected to wrong task configuration used in CLI tests for tasks.
We also refactor the tests a bit to make them more readable.

CLI functional tests have been moved to a separate directory, and the tests_ci/
directory has been supplied with a README file.

Co-authored-by: Sergey Skripnick<sskripnick@mirantis.com>
Change-Id: I927c91f119765f27ee6b8b7c98d4156c02700102
Closes-Bug: 1374407
",git fetch https://review.opendev.org/openstack/rally refs/changes/78/124378/9 && git format-patch -1 --stdout FETCH_HEAD,['tests_ci/test_cli_task.py'],1,b06c18ccbbc93894e96ef5da3c959e0c1607ebb1,bug/1374407," rally(""-vd task start --task %s"" % config.filename)"," rally(""task start --task %s"" % config.filename)",1,1
openstack%2Frally~master~I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8,openstack/rally,master,I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8,Call correct method to reset quotas,MERGED,2014-10-03 11:39:41.000000000,2014-10-04 13:05:08.000000000,2014-10-04 13:05:07.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-10-03 11:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/22be3036f9f74dcefb2d6dd8cfcb82773654b477', 'message': 'Call correct method to reset quotas\n\nChange-Id: I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8\n'}, {'number': 2, 'created': '2014-10-03 11:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/67d5c796b39fbb164ee9bda82c519bba3db1790f', 'message': 'Call correct method to reset quotas\n\nChange-Id: I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8\n'}, {'number': 3, 'created': '2014-10-03 12:44:47.000000000', 'files': ['rally/benchmark/context/quotas/designate_quotas.py', 'tests/benchmark/context/quotas/test_designate_quotas.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/95aece69f1ca9572a009376a34d25b30dac63677', 'message': 'Call correct method to reset quotas\n\nCloses-Bug: 1376770\nChange-Id: I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8\n'}]",3,125941,95aece69f1ca9572a009376a34d25b30dac63677,17,5,3,395,,,0,"Call correct method to reset quotas

Closes-Bug: 1376770
Change-Id: I1c4699f5e1387c91bece9f737b57ba6e4a59d5d8
",git fetch https://review.opendev.org/openstack/rally refs/changes/41/125941/3 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/context/quotas/designate_quotas.py'],1,22be3036f9f74dcefb2d6dd8cfcb82773654b477,bug/1376770, self.clients.designate().quotas.reset(tenant_id), self.clients.designate().quotas.delete(tenant_id),1,1
openstack%2Fdevstack~master~I86b15cfcffe549654c28f425c2bcf99403ac10bc,openstack/devstack,master,I86b15cfcffe549654c28f425c2bcf99403ac10bc,Use service role for neutron instead of admin,MERGED,2014-07-18 23:07:30.000000000,2014-10-04 12:52:19.000000000,2014-10-04 12:52:18.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-18 23:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/148af4a88f085a5e0c1702fd736c0860877dd88c', 'message': ""Use service role for neutron instead of admin\n\nWhen creating the account for neutron to use in keystone,\ngive it a service role instead of an admin role so it isn't\noverprivileged with the ability to create and delete tenants.\n\nCloses-Bug: #1344463\nChange-Id: I86b15cfcffe549654c28f425c2bcf99403ac10bc\n""}, {'number': 2, 'created': '2014-09-29 23:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/636f9fa36299bdfdb4505683e234090c3cd038c2', 'message': ""Use service role for neutron instead of admin\n\nWhen creating the account for neutron to use in keystone,\ngive it a service role instead of an admin role so it isn't\noverprivileged with the ability to create and delete tenants.\n\nCloses-Bug: #1344463\nChange-Id: I86b15cfcffe549654c28f425c2bcf99403ac10bc\n""}, {'number': 3, 'created': '2014-09-30 04:48:55.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/08a5fcc7faae8cab558617b46b684009df595fdd', 'message': ""Use service role for neutron instead of admin\n\nWhen creating the account for neutron to use in keystone,\ngive it a service role instead of an admin role so it isn't\noverprivileged with the ability to create and delete tenants.\nAlso set the Neutron policy.json file to allow the Neutron\naccount to administer Neutron.\n\nCloses-Bug: #1344463\nChange-Id: I86b15cfcffe549654c28f425c2bcf99403ac10bc\n""}]",4,108167,08a5fcc7faae8cab558617b46b684009df595fdd,30,8,3,7787,,,0,"Use service role for neutron instead of admin

When creating the account for neutron to use in keystone,
give it a service role instead of an admin role so it isn't
overprivileged with the ability to create and delete tenants.
Also set the Neutron policy.json file to allow the Neutron
account to administer Neutron.

Closes-Bug: #1344463
Change-Id: I86b15cfcffe549654c28f425c2bcf99403ac10bc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/67/108167/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,148af4a88f085a5e0c1702fd736c0860877dd88c,bug/1344463," SERVICE_ROLE=$(openstack role list | awk ""/ service / { print \$2 }"") get_or_add_user_role $SERVICE_ROLE $NEUTRON_USER $SERVICE_TENANT"," ADMIN_ROLE=$(openstack role list | awk ""/ admin / { print \$2 }"") get_or_add_user_role $ADMIN_ROLE $NEUTRON_USER $SERVICE_TENANT",2,2
openstack%2Fnova~master~I28497a650fbd012643080951f7d86ab8780fd59c,openstack/nova,master,I28497a650fbd012643080951f7d86ab8780fd59c,Remove libvirt legacy LVM code,MERGED,2014-05-26 12:59:47.000000000,2014-10-04 12:47:56.000000000,2014-10-04 12:47:53.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1004}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-26 12:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/474798b05a4a1a3dd1a8db98afeb88f3d7242426', 'message': ""Remove libvirt legacy LVM code\n\nThe Change-Id Ib36b962971fd1f66ea9a0818e91fec59e118e686 fixed an\nissue which could have caused volumes no longer being able to be\ncleaned up due to it's reliance on the instance_name_template\nconfiguration option.\n\nThere was code in place to handle both disk formats which are\nthe legacy format (volume name prefixed by instance name) and\nthe new one (volume name prefixed by instance uuid).\n\nThis commit removes the legacy format which was due to be\nremoved from the code.\n\nChange-Id: I28497a650fbd012643080951f7d86ab8780fd59c\n""}, {'number': 2, 'created': '2014-08-28 13:33:46.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9b37aa6b1c0296bece4d77669277f1d43a6f5d23', 'message': ""Remove libvirt legacy LVM code\n\nThe Change-Id Ib36b962971fd1f66ea9a0818e91fec59e118e686 fixed an\nissue which could have caused volumes no longer being able to be\ncleaned up due to it's reliance on the instance_name_template\nconfiguration option.\n\nThere was code in place to handle both disk formats which are\nthe legacy format (volume name prefixed by instance name) and\nthe new one (volume name prefixed by instance uuid).\n\nThis commit removes the legacy format which was due to be\nremoved from the code.\n\nUpgradeImpact - this removes support for really old lvm names that\ncould have been created in Havana clouds. That means there is a\npossible failure to cleanup of lvm volumes that existed uniterupted\nsince Havana.\n\nChange-Id: I28497a650fbd012643080951f7d86ab8780fd59c\n""}]",1,95520,9b37aa6b1c0296bece4d77669277f1d43a6f5d23,31,14,2,1004,,,0,"Remove libvirt legacy LVM code

The Change-Id Ib36b962971fd1f66ea9a0818e91fec59e118e686 fixed an
issue which could have caused volumes no longer being able to be
cleaned up due to it's reliance on the instance_name_template
configuration option.

There was code in place to handle both disk formats which are
the legacy format (volume name prefixed by instance name) and
the new one (volume name prefixed by instance uuid).

This commit removes the legacy format which was due to be
removed from the code.

UpgradeImpact - this removes support for really old lvm names that
could have been created in Havana clouds. That means there is a
possible failure to cleanup of lvm volumes that existed uniterupted
since Havana.

Change-Id: I28497a650fbd012643080951f7d86ab8780fd59c
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/95520/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,474798b05a4a1a3dd1a8db98afeb88f3d7242426,remove-libvirt-legacy-lvm,," # TODO(sdague): remove in Juno def belongs_to_instance_legacy(disk): # We don't want to leak old disks, but at the same time, we # don't want to do an unsafe thing. So we will only handle # the old filter if it's the system default still. pattern = '%s_' % instance['name'] if disk.startswith(pattern): if CONF.instance_name_template == 'instance-%08x': return True else: LOG.warning(_('Volume %(disk)s possibly unsafe to ' 'remove, please clean up manually'), {'disk': disk}) return False # TODO(sdague): remove in Juno disk_names.extend( filter(belongs_to_instance_legacy, logical_volumes) )",2,24
openstack%2Frally~master~I2463434223c82e6eb59479cc00ee34014a5fe178,openstack/rally,master,I2463434223c82e6eb59479cc00ee34014a5fe178,Remove run_tests.sh,MERGED,2014-10-04 10:13:56.000000000,2014-10-04 12:45:03.000000000,2014-10-04 12:45:02.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-10-04 10:13:56.000000000', 'files': ['run_tests.sh', 'tools/lint.py', 'tools/with_venv.sh', 'tools/run_tests_common.sh', 'tools/install_venv.sh', 'tools/colorizer.py', 'tools/install_venv_common.py', 'tools/install_venv.py', 'tools/patch_tox_venv.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b11235b83ea421eb0da5922391953e6ac9656810', 'message': 'Remove run_tests.sh\n\nThis is a bunch of code that actually does nothing.\n""tox"" command is much powerfull and it is actually used in gates.\n\nIn other words end users should use only ""tox"" command.\n\nChange-Id: I2463434223c82e6eb59479cc00ee34014a5fe178\n'}]",0,126136,b11235b83ea421eb0da5922391953e6ac9656810,12,4,1,6172,,,0,"Remove run_tests.sh

This is a bunch of code that actually does nothing.
""tox"" command is much powerfull and it is actually used in gates.

In other words end users should use only ""tox"" command.

Change-Id: I2463434223c82e6eb59479cc00ee34014a5fe178
",git fetch https://review.opendev.org/openstack/rally refs/changes/36/126136/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tools/lint.py', 'tools/with_venv.sh', 'tools/run_tests_common.sh', 'tools/install_venv.sh', 'tools/colorizer.py', 'tools/install_venv_common.py', 'tools/install_venv.py', 'tools/patch_tox_venv.py']",9,b11235b83ea421eb0da5922391953e6ac9656810,remove_run_tests_sh,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import sys import install_venv_common as install_venv # noqa def first_file(file_list): for candidate in file_list: if os.path.exists(candidate): return candidate def main(argv): root = os.path.dirname(os.path.dirname(os.path.realpath(__file__))) venv = os.environ['VIRTUAL_ENV'] pip_requires = first_file([ os.path.join(root, 'requirements.txt'), os.path.join(root, 'tools', 'pip-requires'), ]) test_requires = first_file([ os.path.join(root, 'test-requirements.txt'), os.path.join(root, 'tools', 'test-requires'), ]) py_version = ""python%s.%s"" % (sys.version_info[0], sys.version_info[1]) project = 'oslo' install = install_venv.InstallVenv(root, venv, pip_requires, test_requires, py_version, project) #NOTE(dprince): For Tox we only run post_process (which patches files, etc) install.post_process() if __name__ == '__main__': main(sys.argv) ",0,1021
openstack%2Fnova~master~I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3,openstack/nova,master,I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3,Add missing instance action record for start of live migration,MERGED,2014-05-26 07:16:12.000000000,2014-10-04 12:34:03.000000000,2014-10-04 12:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9466}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-05-26 07:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7a397d61119bb50a643326a4154946adfa339ca', 'message': 'Add action record for live migration\n\nThere is no action record for action live-migration, It will be better\nrecord for it. This patch also record action events for live-migration.\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 2, 'created': '2014-05-26 08:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55b0f85e2d89e88020ee946dacf12ddd96578b14', 'message': 'Add action record for live migration\n\nThere is no action record for action live-migration, It will be good\nthat record action live-migration.\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 3, 'created': '2014-06-10 23:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/337c1dbdaf64751e7753060aed2d03fde4168ddf', 'message': 'Add missing instance action record for start of live migration\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 4, 'created': '2014-07-11 11:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bda7fd6f00e91f28f62e3e5840549f34e5033e0f', 'message': 'Add missing instance action record for start of live migration\n\nCloses-Bug: #1340702\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 5, 'created': '2014-07-16 02:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0e401b63149e4223d701314f82f7f8ade4514e9', 'message': ""Add missing instance action record for start of live migration\n\nNova has capability of recording instance actions like start/stop ,migrate, etc. with command 'nova instance-action-list', we can check one instance's operation history\n\nCloses-Bug: #1340702\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n""}, {'number': 6, 'created': '2014-07-16 02:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49b690661867014bd3fb4388de822c642167c872', 'message': ""Add missing instance action record for start of live migration\n\nNova has capability of recording instance actions like start/stop,\n\nmigrate, etc. with command 'nova instance-action-list', we can check one\n\ninstance's operation history\n\nCloses-Bug: #1340702\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n""}, {'number': 7, 'created': '2014-07-28 12:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/febbcc461644a945b9cbe3f585aa7c367c0b351f', 'message': ""Add missing instance action record for start of live migration\n\nNova has capability of recording instance actions like start/stop,\n\nmigrate, etc. with command 'nova instance-action-list', we can check one\n\ninstance's operation history\n\nCloses-Bug: #1340702\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n""}, {'number': 8, 'created': '2014-08-13 02:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f0c06c274ddd77fe7372666bb2d8f6763b081de', 'message': 'Add action record for live migration\n\nThere is no action record for action live-migration, It will be good\nthat record action live-migration.\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 9, 'created': '2014-09-16 05:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/335f36b82051b45c8b403a335e377ae0c7a7e5c7', 'message': 'Add missing instance action record for start of live migration\n\nWe should add action record for live migration as we did for resize,\nstart,etc.\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}, {'number': 10, 'created': '2014-09-24 02:15:09.000000000', 'files': ['nova/tests/compute/test_compute_cells.py', 'nova/compute/instance_actions.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82f5cd5a4b280eb1e2b0bb40f9c8f73dcebdfce9', 'message': 'Add missing instance action record for start of live migration\n\nWe should add action record for live migration as we did for resize,\nstart,etc.\n\nChange-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3\n'}]",3,95440,82f5cd5a4b280eb1e2b0bb40f9c8f73dcebdfce9,118,16,10,9796,,,0,"Add missing instance action record for start of live migration

We should add action record for live migration as we did for resize,
start,etc.

Change-Id: I6838727bf51f4bcdba0010c72bd2d5132bcf2cc3
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/95440/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/compute/instance_actions.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",4,d7a397d61119bb50a643326a4154946adfa339ca,record_live_migration," self.mox.StubOutWithMock(self.compute_api, '_record_action_start') self.compute_api._record_action_start(self.context, instance, 'migrate')",,13,0
openstack%2Fnova~master~Iea14195a55d855bfa2cfc096260cf960e911b219,openstack/nova,master,Iea14195a55d855bfa2cfc096260cf960e911b219,fix usage of obj_reset_changes() call in flavor,MERGED,2014-09-26 18:51:19.000000000,2014-10-04 12:33:36.000000000,2014-10-04 12:33:34.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-09-26 18:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c388abbb4d4614a433c0af97bc98b08032810f1', 'message': ""fix usage of obj_reset_changes() call in flavor\n\nThere is a bug where obj_reset_changes() isn't being called with a\nlist, resulting in a no-op (changes to 'projects' not reset).\n\nChange-Id: Iea14195a55d855bfa2cfc096260cf960e911b219\n""}, {'number': 2, 'created': '2014-09-26 19:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f46684a35f205ffd643dbb10bbd53b9e403b27b2', 'message': ""fix usage of obj_reset_changes() call in flavor\n\nThere is a bug where obj_reset_changes() isn't being called with a\nlist, resulting in a no-op (changes to 'projects' not reset).\n\nChange-Id: Iea14195a55d855bfa2cfc096260cf960e911b219\n""}, {'number': 3, 'created': '2014-09-26 19:27:22.000000000', 'files': ['nova/tests/objects/test_flavor.py', 'nova/objects/flavor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/67b7b795ff5a9fb127f1dfef699f1963aba0aeae', 'message': ""fix usage of obj_reset_changes() call in flavor\n\nThere is a bug where obj_reset_changes() isn't being called with a\nlist, resulting in a no-op (changes to 'projects' not reset).\n\nChange-Id: Iea14195a55d855bfa2cfc096260cf960e911b219\n""}]",2,124492,67b7b795ff5a9fb127f1dfef699f1963aba0aeae,17,8,3,4690,,,0,"fix usage of obj_reset_changes() call in flavor

There is a bug where obj_reset_changes() isn't being called with a
list, resulting in a no-op (changes to 'projects' not reset).

Change-Id: Iea14195a55d855bfa2cfc096260cf960e911b219
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/124492/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/flavor.py'],1,6c388abbb4d4614a433c0af97bc98b08032810f1,flavor-obj-reset-changes, self.obj_reset_changes(['projects']), self.obj_reset_changes('projects'),1,1
openstack%2Ftraining-guides~master~I6c9b3dcda408bbd0581e3569f7953e749cce1d42,openstack/training-guides,master,I6c9b3dcda408bbd0581e3569f7953e749cce1d42,Updated from openstack-manuals,MERGED,2014-10-04 06:57:20.000000000,2014-10-04 12:12:49.000000000,2014-10-04 12:12:49.000000000,"[{'_account_id': 3}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-10-04 06:57:20.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/069e07296c88ee764384dceea31c824eff74077d', 'message': 'Updated from openstack-manuals\n\nChange-Id: I6c9b3dcda408bbd0581e3569f7953e749cce1d42\n'}]",0,126132,069e07296c88ee764384dceea31c824eff74077d,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I6c9b3dcda408bbd0581e3569f7953e749cce1d42
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/32/126132/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,069e07296c88ee764384dceea31c824eff74077d,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:45+0000\n""#: ./doc/glossary/glossary-terms.xml7331(secondary) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml8092(primary)#: ./doc/glossary/glossary-terms.xml7329(primary) #: ./doc/glossary/glossary-terms.xml7358(primary) #: ./doc/glossary/glossary-terms.xml8542(primary)#: ./doc/glossary/glossary-terms.xml7859(para)#: ./doc/glossary/glossary-terms.xml8352(para) #: ./doc/glossary/glossary-terms.xml8585(para) #: ./doc/glossary/glossary-terms.xml8815(para) #: ./doc/glossary/glossary-terms.xml8916(para) #: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8237(primary)#: ./doc/glossary/glossary-terms.xml7489(primary) #: ./doc/glossary/glossary-terms.xml7717(primary)#: ./doc/glossary/glossary-terms.xml7691(see)#: ./doc/glossary/glossary-terms.xml7364(para)#: ./doc/glossary/glossary-terms.xml8421(para) #: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8456(primary) #: ./doc/glossary/glossary-terms.xml8604(primary)#: ./doc/glossary/glossary-terms.xml7757(primary) #: ./doc/glossary/glossary-terms.xml7957(primary)#: ./doc/glossary/glossary-terms.xml8220(primary)#: ./doc/glossary/glossary-terms.xml8200(see)#: ./doc/glossary/glossary-terms.xml7901(glossterm) #: ./doc/glossary/glossary-terms.xml7924(primary) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7962(primary)#: ./doc/glossary/glossary-terms.xml8512(primary)#: ./doc/glossary/glossary-terms.xml7607(primary)#: ./doc/glossary/glossary-terms.xml7609(secondary)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) msgid ""SELinux"" msgstr """" #: ./doc/glossary/glossary-terms.xml7321(para) msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" #: ./doc/glossary/glossary-terms.xml7327(glossterm)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7345(glossterm) #: ./doc/glossary/glossary-terms.xml7347(primary)#: ./doc/glossary/glossary-terms.xml7351(para)#: ./doc/glossary/glossary-terms.xml7356(glossterm) #: ./doc/glossary/glossary-terms.xml7360(secondary)#: ./doc/glossary/glossary-terms.xml7370(glossterm)#: ./doc/glossary/glossary-terms.xml7372(primary)#: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml7385(glossterm) #: ./doc/glossary/glossary-terms.xml7387(primary)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7434(primary)#: ./doc/glossary/glossary-terms.xml7438(para)#: ./doc/glossary/glossary-terms.xml7444(glossterm) #: ./doc/glossary/glossary-terms.xml7448(secondary)#: ./doc/glossary/glossary-terms.xml7446(primary) #: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7477(secondary)#: ./doc/glossary/glossary-terms.xml7481(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7494(primary)#: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7498(para)#: ./doc/glossary/glossary-terms.xml7511(glossterm)#: ./doc/glossary/glossary-terms.xml7513(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7544(para)#: ./doc/glossary/glossary-terms.xml7550(glossterm) #: ./doc/glossary/glossary-terms.xml7553(primary)#: ./doc/glossary/glossary-terms.xml7557(para)#: ./doc/glossary/glossary-terms.xml7563(glossterm) #: ./doc/glossary/glossary-terms.xml7566(primary)#: ./doc/glossary/glossary-terms.xml7570(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7592(glossterm) #: ./doc/glossary/glossary-terms.xml7594(primary)#: ./doc/glossary/glossary-terms.xml7598(para)#: ./doc/glossary/glossary-terms.xml7605(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm) #: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7628(para)#: ./doc/glossary/glossary-terms.xml7634(glossterm)#: ./doc/glossary/glossary-terms.xml7636(primary)#: ./doc/glossary/glossary-terms.xml7641(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7652(secondary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7665(glossterm) #: ./doc/glossary/glossary-terms.xml7667(primary)#: ./doc/glossary/glossary-terms.xml7671(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7682(para)#: ./doc/glossary/glossary-terms.xml7688(glossterm) #: ./doc/glossary/glossary-terms.xml7690(primary)#: ./doc/glossary/glossary-terms.xml7695(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7715(glossterm)#: ./doc/glossary/glossary-terms.xml7719(secondary)#: ./doc/glossary/glossary-terms.xml7722(primary)#: ./doc/glossary/glossary-terms.xml7726(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7745(primary)#: ./doc/glossary/glossary-terms.xml7749(para)#: ./doc/glossary/glossary-terms.xml7755(glossterm) #: ./doc/glossary/glossary-terms.xml7762(primary)#: ./doc/glossary/glossary-terms.xml7759(secondary)#: ./doc/glossary/glossary-terms.xml7766(para)#: ./doc/glossary/glossary-terms.xml7773(glossterm) #: ./doc/glossary/glossary-terms.xml7777(secondary)#: ./doc/glossary/glossary-terms.xml7775(primary) #: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7952(primary)#: ./doc/glossary/glossary-terms.xml7781(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7827(glossterm)#: ./doc/glossary/glossary-terms.xml7829(primary)#: ./doc/glossary/glossary-terms.xml7833(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7855(primary)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm)#: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7888(glossterm) #: ./doc/glossary/glossary-terms.xml7890(primary)#: ./doc/glossary/glossary-terms.xml7894(para)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary)#: ./doc/glossary/glossary-terms.xml7916(para)#: ./doc/glossary/glossary-terms.xml7922(glossterm) #: ./doc/glossary/glossary-terms.xml7926(secondary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm)#: ./doc/glossary/glossary-terms.xml7954(secondary) #: ./doc/glossary/glossary-terms.xml7959(secondary) #: ./doc/glossary/glossary-terms.xml7964(secondary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7986(glossterm) #: ./doc/glossary/glossary-terms.xml7988(primary)#: ./doc/glossary/glossary-terms.xml7992(para)#: ./doc/glossary/glossary-terms.xml7999(glossterm) #: ./doc/glossary/glossary-terms.xml8001(primary)#: ./doc/glossary/glossary-terms.xml8005(para)#: ./doc/glossary/glossary-terms.xml8015(title)#: ./doc/glossary/glossary-terms.xml8018(glossterm) #: ./doc/glossary/glossary-terms.xml8020(primary)#: ./doc/glossary/glossary-terms.xml8024(para)#: ./doc/glossary/glossary-terms.xml8031(glossterm) #: ./doc/glossary/glossary-terms.xml8033(primary)#: ./doc/glossary/glossary-terms.xml8037(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8058(primary)#: ./doc/glossary/glossary-terms.xml8062(para)#: ./doc/glossary/glossary-terms.xml8068(glossterm) #: ./doc/glossary/glossary-terms.xml8079(primary) #: ./doc/glossary/glossary-terms.xml8097(primary) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8071(para)#: ./doc/glossary/glossary-terms.xml8077(glossterm) #: ./doc/glossary/glossary-terms.xml8081(secondary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8090(glossterm) #: ./doc/glossary/glossary-terms.xml8094(secondary) #: ./doc/glossary/glossary-terms.xml8099(secondary)#: ./doc/glossary/glossary-terms.xml8103(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm)#: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8141(para)#: ./doc/glossary/glossary-terms.xml8147(glossterm) #: ./doc/glossary/glossary-terms.xml8149(primary)#: ./doc/glossary/glossary-terms.xml8152(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm) #: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8190(para)#: ./doc/glossary/glossary-terms.xml8196(glossterm)#: ./doc/glossary/glossary-terms.xml8198(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8209(glossterm)#: ./doc/glossary/glossary-terms.xml8212(para)#: ./doc/glossary/glossary-terms.xml8218(glossterm)#: ./doc/glossary/glossary-terms.xml8222(secondary) #: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml8229(para)#: ./doc/glossary/glossary-terms.xml8235(glossterm)#: ./doc/glossary/glossary-terms.xml8239(secondary) #: ./doc/glossary/glossary-terms.xml8242(primary)#: ./doc/glossary/glossary-terms.xml8246(para)#: ./doc/glossary/glossary-terms.xml8251(glossterm) #: ./doc/glossary/glossary-terms.xml8253(primary)#: ./doc/glossary/glossary-terms.xml8257(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8280(title)#: ./doc/glossary/glossary-terms.xml8283(glossterm) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml8289(para)#: ./doc/glossary/glossary-terms.xml8294(glossterm) #: ./doc/glossary/glossary-terms.xml8296(primary)#: ./doc/glossary/glossary-terms.xml8300(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8317(glossterm)#: ./doc/glossary/glossary-terms.xml8319(primary)#: ./doc/glossary/glossary-terms.xml8323(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8346(glossterm) #: ./doc/glossary/glossary-terms.xml8348(primary)#: ./doc/glossary/glossary-terms.xml8360(title)#: ./doc/glossary/glossary-terms.xml8363(glossterm) #: ./doc/glossary/glossary-terms.xml8365(primary)#: ./doc/glossary/glossary-terms.xml8369(para)#: ./doc/glossary/glossary-terms.xml8374(glossterm) #: ./doc/glossary/glossary-terms.xml8376(primary)#: ./doc/glossary/glossary-terms.xml8380(para)#: ./doc/glossary/glossary-terms.xml8390(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8427(glossterm) #: ./doc/glossary/glossary-terms.xml8429(primary)#: ./doc/glossary/glossary-terms.xml8433(para)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8454(glossterm) #: ./doc/glossary/glossary-terms.xml8461(primary)#: ./doc/glossary/glossary-terms.xml8458(secondary) #: ./doc/glossary/glossary-terms.xml8514(secondary) #: ./doc/glossary/glossary-terms.xml8544(secondary)#: ./doc/glossary/glossary-terms.xml8465(para)#: ./doc/glossary/glossary-terms.xml8470(glossterm) #: ./doc/glossary/glossary-terms.xml8472(primary)#: ./doc/glossary/glossary-terms.xml8476(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8497(glossterm) #: ./doc/glossary/glossary-terms.xml8499(primary)#: ./doc/glossary/glossary-terms.xml8503(para)#: ./doc/glossary/glossary-terms.xml8510(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8527(glossterm) #: ./doc/glossary/glossary-terms.xml8529(primary)#: ./doc/glossary/glossary-terms.xml8533(para)#: ./doc/glossary/glossary-terms.xml8540(glossterm)#: ./doc/glossary/glossary-terms.xml8547(primary)#: ./doc/glossary/glossary-terms.xml8551(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8568(glossterm) #: ./doc/glossary/glossary-terms.xml8570(primary)#: ./doc/glossary/glossary-terms.xml8574(para)#: ./doc/glossary/glossary-terms.xml8579(glossterm) #: ./doc/glossary/glossary-terms.xml8581(primary)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml8596(para)#: ./doc/glossary/glossary-terms.xml8602(glossterm) #: ./doc/glossary/glossary-terms.xml8609(primary)#: ./doc/glossary/glossary-terms.xml8606(secondary)#: ./doc/glossary/glossary-terms.xml8613(para)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8635(glossterm) #: ./doc/glossary/glossary-terms.xml8637(primary)#: ./doc/glossary/glossary-terms.xml8641(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8658(glossterm) #: ./doc/glossary/glossary-terms.xml8660(primary)#: ./doc/glossary/glossary-terms.xml8664(para)#: ./doc/glossary/glossary-terms.xml8669(glossterm)#: ./doc/glossary/glossary-terms.xml8672(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8679(primary)#: ./doc/glossary/glossary-terms.xml8683(para)#: ./doc/glossary/glossary-terms.xml8689(glossterm) #: ./doc/glossary/glossary-terms.xml8701(primary) #: ./doc/glossary/glossary-terms.xml8714(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8741(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary)#: ./doc/glossary/glossary-terms.xml8692(para)#: ./doc/glossary/glossary-terms.xml8699(glossterm) #: ./doc/glossary/glossary-terms.xml8703(secondary)#: ./doc/glossary/glossary-terms.xml8707(para)#: ./doc/glossary/glossary-terms.xml8712(glossterm) #: ./doc/glossary/glossary-terms.xml8716(secondary)#: ./doc/glossary/glossary-terms.xml8720(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8739(glossterm) #: ./doc/glossary/glossary-terms.xml8743(secondary)#: ./doc/glossary/glossary-terms.xml8747(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm)#: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8801(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm) #: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8823(title)#: ./doc/glossary/glossary-terms.xml8826(glossterm) #: ./doc/glossary/glossary-terms.xml8828(primary)#: ./doc/glossary/glossary-terms.xml8832(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm) #: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8863(glossterm)#: ./doc/glossary/glossary-terms.xml8865(primary)#: ./doc/glossary/glossary-terms.xml8869(para)#: ./doc/glossary/glossary-terms.xml8880(title)#: ./doc/glossary/glossary-terms.xml8883(glossterm) #: ./doc/glossary/glossary-terms.xml8885(primary)#: ./doc/glossary/glossary-terms.xml8889(para)#: ./doc/glossary/glossary-terms.xml8899(glossterm) #: ./doc/glossary/glossary-terms.xml8910(primary) #: ./doc/glossary/glossary-terms.xml8923(primary) #: ./doc/glossary/glossary-terms.xml8937(primary)#: ./doc/glossary/glossary-terms.xml8902(para)#: ./doc/glossary/glossary-terms.xml8908(glossterm) #: ./doc/glossary/glossary-terms.xml8912(secondary)#: ./doc/glossary/glossary-terms.xml8921(glossterm) #: ./doc/glossary/glossary-terms.xml8925(secondary)#: ./doc/glossary/glossary-terms.xml8929(para)#: ./doc/glossary/glossary-terms.xml8935(glossterm)#: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8951(title)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)#: ./doc/glossary/glossary-terms.xml8980(glossterm) #: ./doc/glossary/glossary-terms.xml8982(primary)#: ./doc/glossary/glossary-terms.xml8986(para)","""POT-Creation-Date: 2014-09-23 05:56+0000\n"" ""PO-Revision-Date: 2014-09-22 16:45+0000\n""#: ./doc/glossary/glossary-terms.xml7319(secondary) #: ./doc/glossary/glossary-terms.xml7362(secondary)#: ./doc/glossary/glossary-terms.xml8080(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) #: ./doc/glossary/glossary-terms.xml7346(primary) #: ./doc/glossary/glossary-terms.xml8530(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml8340(para) #: ./doc/glossary/glossary-terms.xml8573(para) #: ./doc/glossary/glossary-terms.xml8803(para) #: ./doc/glossary/glossary-terms.xml8904(para) #: ./doc/glossary/glossary-terms.xml8931(para)#: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml7477(primary) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7679(see)#: ./doc/glossary/glossary-terms.xml7352(para)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8617(para)#: ./doc/glossary/glossary-terms.xml8444(primary) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml7745(primary) #: ./doc/glossary/glossary-terms.xml7945(primary)#: ./doc/glossary/glossary-terms.xml8208(primary)#: ./doc/glossary/glossary-terms.xml8188(see)#: ./doc/glossary/glossary-terms.xml7889(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary) #: ./doc/glossary/glossary-terms.xml7926(primary) #: ./doc/glossary/glossary-terms.xml7950(primary)#: ./doc/glossary/glossary-terms.xml8500(primary)#: ./doc/glossary/glossary-terms.xml7595(primary)#: ./doc/glossary/glossary-terms.xml7597(secondary)#: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7323(para)#: ./doc/glossary/glossary-terms.xml7327(para)#: ./doc/glossary/glossary-terms.xml7333(glossterm) #: ./doc/glossary/glossary-terms.xml7335(primary)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7344(glossterm) #: ./doc/glossary/glossary-terms.xml7348(secondary)#: ./doc/glossary/glossary-terms.xml7358(glossterm)#: ./doc/glossary/glossary-terms.xml7360(primary)#: ./doc/glossary/glossary-terms.xml7366(para)#: ./doc/glossary/glossary-terms.xml7373(glossterm) #: ./doc/glossary/glossary-terms.xml7375(primary)#: ./doc/glossary/glossary-terms.xml7379(para)#: ./doc/glossary/glossary-terms.xml7384(glossterm) #: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7390(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7436(secondary)#: ./doc/glossary/glossary-terms.xml7434(primary) #: ./doc/glossary/glossary-terms.xml7448(primary) #: ./doc/glossary/glossary-terms.xml7463(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7450(secondary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7461(glossterm) #: ./doc/glossary/glossary-terms.xml7465(secondary)#: ./doc/glossary/glossary-terms.xml7469(para)#: ./doc/glossary/glossary-terms.xml7475(glossterm) #: ./doc/glossary/glossary-terms.xml7482(primary)#: ./doc/glossary/glossary-terms.xml7479(secondary)#: ./doc/glossary/glossary-terms.xml7486(para)#: ./doc/glossary/glossary-terms.xml7499(glossterm)#: ./doc/glossary/glossary-terms.xml7501(primary)#: ./doc/glossary/glossary-terms.xml7505(para)#: ./doc/glossary/glossary-terms.xml7514(glossterm) #: ./doc/glossary/glossary-terms.xml7516(primary)#: ./doc/glossary/glossary-terms.xml7520(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7541(primary)#: ./doc/glossary/glossary-terms.xml7545(para)#: ./doc/glossary/glossary-terms.xml7551(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7568(glossterm) #: ./doc/glossary/glossary-terms.xml7570(primary)#: ./doc/glossary/glossary-terms.xml7574(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7593(glossterm) #: ./doc/glossary/glossary-terms.xml7600(primary)#: ./doc/glossary/glossary-terms.xml7604(para)#: ./doc/glossary/glossary-terms.xml7610(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm)#: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7629(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7643(primary)#: ./doc/glossary/glossary-terms.xml7640(secondary)#: ./doc/glossary/glossary-terms.xml7647(para)#: ./doc/glossary/glossary-terms.xml7653(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7664(glossterm) #: ./doc/glossary/glossary-terms.xml7666(primary)#: ./doc/glossary/glossary-terms.xml7670(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7683(para)#: ./doc/glossary/glossary-terms.xml7691(glossterm) #: ./doc/glossary/glossary-terms.xml7693(primary)#: ./doc/glossary/glossary-terms.xml7697(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm)#: ./doc/glossary/glossary-terms.xml7707(secondary)#: ./doc/glossary/glossary-terms.xml7710(primary)#: ./doc/glossary/glossary-terms.xml7714(para)#: ./doc/glossary/glossary-terms.xml7719(glossterm) #: ./doc/glossary/glossary-terms.xml7721(primary)#: ./doc/glossary/glossary-terms.xml7725(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7750(primary)#: ./doc/glossary/glossary-terms.xml7747(secondary)#: ./doc/glossary/glossary-terms.xml7754(para)#: ./doc/glossary/glossary-terms.xml7761(glossterm) #: ./doc/glossary/glossary-terms.xml7765(secondary)#: ./doc/glossary/glossary-terms.xml7763(primary) #: ./doc/glossary/glossary-terms.xml7777(primary) #: ./doc/glossary/glossary-terms.xml7791(primary) #: ./doc/glossary/glossary-terms.xml7940(primary)#: ./doc/glossary/glossary-terms.xml7769(para)#: ./doc/glossary/glossary-terms.xml7775(glossterm) #: ./doc/glossary/glossary-terms.xml7779(secondary)#: ./doc/glossary/glossary-terms.xml7783(para)#: ./doc/glossary/glossary-terms.xml7789(glossterm) #: ./doc/glossary/glossary-terms.xml7793(secondary)#: ./doc/glossary/glossary-terms.xml7797(para)#: ./doc/glossary/glossary-terms.xml7803(glossterm) #: ./doc/glossary/glossary-terms.xml7805(primary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm)#: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7840(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7852(glossterm)#: ./doc/glossary/glossary-terms.xml7854(primary)#: ./doc/glossary/glossary-terms.xml7858(para)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm) #: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7892(para)#: ./doc/glossary/glossary-terms.xml7898(glossterm) #: ./doc/glossary/glossary-terms.xml7900(primary)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7914(secondary)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7928(secondary)#: ./doc/glossary/glossary-terms.xml7932(para)#: ./doc/glossary/glossary-terms.xml7938(glossterm)#: ./doc/glossary/glossary-terms.xml7942(secondary) #: ./doc/glossary/glossary-terms.xml7947(secondary) #: ./doc/glossary/glossary-terms.xml7952(secondary)#: ./doc/glossary/glossary-terms.xml7956(para)#: ./doc/glossary/glossary-terms.xml7962(glossterm) #: ./doc/glossary/glossary-terms.xml7964(primary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary)#: ./doc/glossary/glossary-terms.xml7993(para)#: ./doc/glossary/glossary-terms.xml8003(title)#: ./doc/glossary/glossary-terms.xml8006(glossterm) #: ./doc/glossary/glossary-terms.xml8008(primary)#: ./doc/glossary/glossary-terms.xml8012(para)#: ./doc/glossary/glossary-terms.xml8019(glossterm) #: ./doc/glossary/glossary-terms.xml8021(primary)#: ./doc/glossary/glossary-terms.xml8025(para)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8067(primary) #: ./doc/glossary/glossary-terms.xml8085(primary) #: ./doc/glossary/glossary-terms.xml8099(primary)#: ./doc/glossary/glossary-terms.xml8059(para)#: ./doc/glossary/glossary-terms.xml8065(glossterm) #: ./doc/glossary/glossary-terms.xml8069(secondary)#: ./doc/glossary/glossary-terms.xml8073(para)#: ./doc/glossary/glossary-terms.xml8078(glossterm) #: ./doc/glossary/glossary-terms.xml8082(secondary) #: ./doc/glossary/glossary-terms.xml8087(secondary)#: ./doc/glossary/glossary-terms.xml8091(para)#: ./doc/glossary/glossary-terms.xml8097(glossterm) #: ./doc/glossary/glossary-terms.xml8101(secondary)#: ./doc/glossary/glossary-terms.xml8105(para)#: ./doc/glossary/glossary-terms.xml8111(glossterm)#: ./doc/glossary/glossary-terms.xml8113(primary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8140(para)#: ./doc/glossary/glossary-terms.xml8148(glossterm) #: ./doc/glossary/glossary-terms.xml8150(primary)#: ./doc/glossary/glossary-terms.xml8154(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm)#: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8197(glossterm)#: ./doc/glossary/glossary-terms.xml8200(para)#: ./doc/glossary/glossary-terms.xml8206(glossterm)#: ./doc/glossary/glossary-terms.xml8210(secondary) #: ./doc/glossary/glossary-terms.xml8213(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8227(secondary) #: ./doc/glossary/glossary-terms.xml8230(primary)#: ./doc/glossary/glossary-terms.xml8234(para)#: ./doc/glossary/glossary-terms.xml8239(glossterm) #: ./doc/glossary/glossary-terms.xml8241(primary)#: ./doc/glossary/glossary-terms.xml8245(para)#: ./doc/glossary/glossary-terms.xml8253(glossterm) #: ./doc/glossary/glossary-terms.xml8255(primary)#: ./doc/glossary/glossary-terms.xml8259(para)#: ./doc/glossary/glossary-terms.xml8268(title)#: ./doc/glossary/glossary-terms.xml8271(glossterm) #: ./doc/glossary/glossary-terms.xml8273(primary)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8282(glossterm) #: ./doc/glossary/glossary-terms.xml8284(primary)#: ./doc/glossary/glossary-terms.xml8288(para)#: ./doc/glossary/glossary-terms.xml8293(glossterm)#: ./doc/glossary/glossary-terms.xml8295(primary)#: ./doc/glossary/glossary-terms.xml8299(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8318(glossterm) #: ./doc/glossary/glossary-terms.xml8320(primary)#: ./doc/glossary/glossary-terms.xml8324(para)#: ./doc/glossary/glossary-terms.xml8334(glossterm) #: ./doc/glossary/glossary-terms.xml8336(primary)#: ./doc/glossary/glossary-terms.xml8348(title)#: ./doc/glossary/glossary-terms.xml8351(glossterm) #: ./doc/glossary/glossary-terms.xml8353(primary)#: ./doc/glossary/glossary-terms.xml8357(para)#: ./doc/glossary/glossary-terms.xml8362(glossterm) #: ./doc/glossary/glossary-terms.xml8364(primary)#: ./doc/glossary/glossary-terms.xml8368(para)#: ./doc/glossary/glossary-terms.xml8378(glossterm) #: ./doc/glossary/glossary-terms.xml8381(primary)#: ./doc/glossary/glossary-terms.xml8385(para)#: ./doc/glossary/glossary-terms.xml8391(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8421(para)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8435(para)#: ./doc/glossary/glossary-terms.xml8442(glossterm) #: ./doc/glossary/glossary-terms.xml8449(primary)#: ./doc/glossary/glossary-terms.xml8446(secondary) #: ./doc/glossary/glossary-terms.xml8502(secondary) #: ./doc/glossary/glossary-terms.xml8532(secondary)#: ./doc/glossary/glossary-terms.xml8453(para)#: ./doc/glossary/glossary-terms.xml8458(glossterm) #: ./doc/glossary/glossary-terms.xml8460(primary)#: ./doc/glossary/glossary-terms.xml8464(para)#: ./doc/glossary/glossary-terms.xml8473(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8498(glossterm) #: ./doc/glossary/glossary-terms.xml8505(primary)#: ./doc/glossary/glossary-terms.xml8509(para)#: ./doc/glossary/glossary-terms.xml8515(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8528(glossterm)#: ./doc/glossary/glossary-terms.xml8535(primary)#: ./doc/glossary/glossary-terms.xml8539(para)#: ./doc/glossary/glossary-terms.xml8544(glossterm) #: ./doc/glossary/glossary-terms.xml8546(primary)#: ./doc/glossary/glossary-terms.xml8550(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8567(glossterm) #: ./doc/glossary/glossary-terms.xml8569(primary)#: ./doc/glossary/glossary-terms.xml8578(glossterm) #: ./doc/glossary/glossary-terms.xml8580(primary)#: ./doc/glossary/glossary-terms.xml8584(para)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8597(primary)#: ./doc/glossary/glossary-terms.xml8594(secondary)#: ./doc/glossary/glossary-terms.xml8601(para)#: ./doc/glossary/glossary-terms.xml8611(glossterm) #: ./doc/glossary/glossary-terms.xml8613(primary)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8634(glossterm) #: ./doc/glossary/glossary-terms.xml8636(primary)#: ./doc/glossary/glossary-terms.xml8640(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8657(glossterm)#: ./doc/glossary/glossary-terms.xml8660(para)#: ./doc/glossary/glossary-terms.xml8665(glossterm) #: ./doc/glossary/glossary-terms.xml8667(primary)#: ./doc/glossary/glossary-terms.xml8671(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8689(primary) #: ./doc/glossary/glossary-terms.xml8702(primary) #: ./doc/glossary/glossary-terms.xml8716(primary) #: ./doc/glossary/glossary-terms.xml8729(primary) #: ./doc/glossary/glossary-terms.xml8743(primary) #: ./doc/glossary/glossary-terms.xml8757(primary) #: ./doc/glossary/glossary-terms.xml8771(primary)#: ./doc/glossary/glossary-terms.xml8680(para)#: ./doc/glossary/glossary-terms.xml8687(glossterm) #: ./doc/glossary/glossary-terms.xml8691(secondary)#: ./doc/glossary/glossary-terms.xml8695(para)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8704(secondary)#: ./doc/glossary/glossary-terms.xml8708(para)#: ./doc/glossary/glossary-terms.xml8714(glossterm) #: ./doc/glossary/glossary-terms.xml8718(secondary)#: ./doc/glossary/glossary-terms.xml8722(para)#: ./doc/glossary/glossary-terms.xml8727(glossterm) #: ./doc/glossary/glossary-terms.xml8731(secondary)#: ./doc/glossary/glossary-terms.xml8735(para)#: ./doc/glossary/glossary-terms.xml8741(glossterm) #: ./doc/glossary/glossary-terms.xml8745(secondary)#: ./doc/glossary/glossary-terms.xml8749(para)#: ./doc/glossary/glossary-terms.xml8755(glossterm) #: ./doc/glossary/glossary-terms.xml8759(secondary)#: ./doc/glossary/glossary-terms.xml8763(para)#: ./doc/glossary/glossary-terms.xml8769(glossterm) #: ./doc/glossary/glossary-terms.xml8773(secondary)#: ./doc/glossary/glossary-terms.xml8777(para)#: ./doc/glossary/glossary-terms.xml8783(glossterm)#: ./doc/glossary/glossary-terms.xml8785(primary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8797(glossterm) #: ./doc/glossary/glossary-terms.xml8799(primary)#: ./doc/glossary/glossary-terms.xml8811(title)#: ./doc/glossary/glossary-terms.xml8814(glossterm) #: ./doc/glossary/glossary-terms.xml8816(primary)#: ./doc/glossary/glossary-terms.xml8820(para)#: ./doc/glossary/glossary-terms.xml8827(glossterm) #: ./doc/glossary/glossary-terms.xml8829(primary)#: ./doc/glossary/glossary-terms.xml8833(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm)#: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8868(title)#: ./doc/glossary/glossary-terms.xml8871(glossterm) #: ./doc/glossary/glossary-terms.xml8873(primary)#: ./doc/glossary/glossary-terms.xml8877(para)#: ./doc/glossary/glossary-terms.xml8887(glossterm) #: ./doc/glossary/glossary-terms.xml8898(primary) #: ./doc/glossary/glossary-terms.xml8911(primary) #: ./doc/glossary/glossary-terms.xml8925(primary)#: ./doc/glossary/glossary-terms.xml8890(para)#: ./doc/glossary/glossary-terms.xml8896(glossterm) #: ./doc/glossary/glossary-terms.xml8900(secondary)#: ./doc/glossary/glossary-terms.xml8909(glossterm) #: ./doc/glossary/glossary-terms.xml8913(secondary)#: ./doc/glossary/glossary-terms.xml8917(para)#: ./doc/glossary/glossary-terms.xml8923(glossterm)#: ./doc/glossary/glossary-terms.xml8927(secondary)#: ./doc/glossary/glossary-terms.xml8939(title)#: ./doc/glossary/glossary-terms.xml8953(title)#: ./doc/glossary/glossary-terms.xml8956(glossterm) #: ./doc/glossary/glossary-terms.xml8958(primary)#: ./doc/glossary/glossary-terms.xml8962(para)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)",434,423
openstack%2Fpython-novaclient~master~If544ade154c53b1f18518773f4d49cd335a394d0,openstack/python-novaclient,master,If544ade154c53b1f18518773f4d49cd335a394d0,return 130 for keyboard interrupt,MERGED,2014-09-25 06:04:03.000000000,2014-10-04 11:41:05.000000000,2014-10-04 11:41:04.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 9420}, {'_account_id': 9545}, {'_account_id': 11424}]","[{'number': 1, 'created': '2014-09-25 06:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/9fdd71e300c038a28dd830e258443cc7a54ed2c5', 'message': 'return 130 for keyboard interrupt\n\nwhen keyboard interrupt is received by novaclient, the return code as\nof now is 1.\n\nBut since the client was terminated by an keyboard interrupt, the return\ncode should be 130. It is useful when people are writing automation test\ncases and want to validate based on the return code.\nI have also changed the message that is printed on shell to match other\nclients.\n\nChange-Id: If544ade154c53b1f18518773f4d49cd335a394d0\nCloses-Bug: #1373231\n'}, {'number': 2, 'created': '2014-09-26 12:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/55d06950210dc5193032b923e989dba7828732cf', 'message': 'return 130 for keyboard interrupt\n\nwhen keyboard interrupt is received by novaclient, the return code as\nof now is 1.\n\nBut since the client was terminated by an keyboard interrupt, the return\ncode should be 130. (http://tldp.org/LDP/abs/html/exitcodes.html)\nIt is useful when people are writing automation test cases and want to\nvalidate based on the return code.\nI have also changed the message that is printed on shell to match other\nclients.\n\nChange-Id: If544ade154c53b1f18518773f4d49cd335a394d0\nCloses-Bug: #1373231\n'}, {'number': 3, 'created': '2014-09-26 15:17:36.000000000', 'files': ['novaclient/tests/test_shell.py', 'novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/09f97e9ee43427d101c719ec26e8cd26dcd0e39d', 'message': 'return 130 for keyboard interrupt\n\nwhen keyboard interrupt is received by novaclient, the return code as\nof now is 1.\n\nBut since the client was terminated by an keyboard interrupt, the return\ncode should be 130. (http://tldp.org/LDP/abs/html/exitcodes.html)\nIt is useful when people are writing automation test cases and want to\nvalidate based on the return code.\nI have also changed the message that is printed on shell to match other\nclients.\n\nChange-Id: If544ade154c53b1f18518773f4d49cd335a394d0\nCloses-Bug: #1373231\n'}]",5,123936,09f97e9ee43427d101c719ec26e8cd26dcd0e39d,19,8,3,11424,,,0,"return 130 for keyboard interrupt

when keyboard interrupt is received by novaclient, the return code as
of now is 1.

But since the client was terminated by an keyboard interrupt, the return
code should be 130. (http://tldp.org/LDP/abs/html/exitcodes.html)
It is useful when people are writing automation test cases and want to
validate based on the return code.
I have also changed the message that is printed on shell to match other
clients.

Change-Id: If544ade154c53b1f18518773f4d49cd335a394d0
Closes-Bug: #1373231
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/36/123936/2 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/shell.py'],1,9fdd71e300c038a28dd830e258443cc7a54ed2c5,bug-fix-1373231," print(""... terminating nova client"", file=sys.stderr) sys.exit(130)"," print(""Shutting down novaclient"", file=sys.stderr) sys.exit(1)",2,2
openstack%2Fnova~master~I4bfd83ab92c719b1776da6445e6a4ea78d2ddfd6,openstack/nova,master,I4bfd83ab92c719b1776da6445e6a4ea78d2ddfd6,Making nova.compute.api to return Aggregate Objects,MERGED,2014-08-05 06:51:33.000000000,2014-10-04 11:33:26.000000000,2014-10-04 11:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}]","[{'number': 1, 'created': '2014-08-05 06:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc16df51938258150b117af623cc810197584ad3', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nChange-Id: I4bfd83ab92c719b1776da6445e6a4ea78d2ddfd6\nCloses-Bug: #1292644\n'}, {'number': 2, 'created': '2014-09-22 07:54:43.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/integrated/test_api_samples.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6fcb34b825b6fe4ae750f6d38d9cf62fa0254a30', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nChange-Id: I4bfd83ab92c719b1776da6445e6a4ea78d2ddfd6\nCloses-Bug: #1292644\n'}]",0,111931,6fcb34b825b6fe4ae750f6d38d9cf62fa0254a30,43,13,2,12299,,,0,"Making nova.compute.api to return Aggregate Objects

nova.compute.api should return Objects and they should be
converted into the REST API expected result in the API extensions

Change-Id: I4bfd83ab92c719b1776da6445e6a4ea78d2ddfd6
Closes-Bug: #1292644
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/111931/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/integrated/test_api_samples.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py']",6,fc16df51938258150b117af623cc810197584ad3,bug/1292644,"FORMATTED_AGGREGATE = {""name"": ""aggregate1"", ""id"": ""1"", ""availability_zone"": ""nova1""} self.assertEqual(FORMATTED_AGGREGATE, result[""aggregate""]) self.assertEqual(FORMATTED_AGGREGATE, result[""aggregate""]) ""availability_zone"": None, ""metadata"": {}, ""hosts"": []} formatted_aggregate = {""name"": ""aggregate1"", ""id"": ""1"", self.assertEqual(formatted_aggregate, result[""aggregate""])"," self.assertEqual(AGGREGATE, result[""aggregate""]) self.assertEqual(AGGREGATE, result[""aggregate""]) self.assertEqual(aggregate, result[""aggregate""])",69,37
openstack%2Fnova~master~Id5719e5e816e70311e2377e41b4350afc8dd5b50,openstack/nova,master,Id5719e5e816e70311e2377e41b4350afc8dd5b50,Remove keystoneclient requirement,MERGED,2014-10-03 02:09:33.000000000,2014-10-04 11:32:00.000000000,2014-10-04 11:31:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-03 02:09:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/1617999d1a53c6e7ec7e9bb959b569e474866f19', 'message': ""Remove keystoneclient requirement\n\nNova doesn't use keystoneclient for anything anymore it uses keystone\nmiddleware instead.\n\nChange-Id: Id5719e5e816e70311e2377e41b4350afc8dd5b50\n""}]",0,125852,1617999d1a53c6e7ec7e9bb959b569e474866f19,12,8,1,1849,,,0,"Remove keystoneclient requirement

Nova doesn't use keystoneclient for anything anymore it uses keystone
middleware instead.

Change-Id: Id5719e5e816e70311e2377e41b4350afc8dd5b50
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/125852/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1617999d1a53c6e7ec7e9bb959b569e474866f19,keystoneclient,,python-keystoneclient>=0.10.0,0,1
openstack%2Fdevstack~master~I0e7aad1d21f4fce4c020ce36685bb56893c66bdc,openstack/devstack,master,I0e7aad1d21f4fce4c020ce36685bb56893c66bdc,Drop workaround for pip < 1.4,MERGED,2014-10-02 01:25:28.000000000,2014-10-04 09:25:48.000000000,2014-10-04 09:25:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 01:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6b5effe93a667310f8058a524ee6ed78c8488dd4', 'message': ""Drop workaround for pip < 1.4\n\nNow that we are on pip 1.5.6 lets drop the workaround to make pip 1.4\nwork. As this is a development/testing tool requiring a newer pip\nshouldn't be an issue. Also stack.sh installs pip by default.\n\nWork around introduced in https://github.com/pypa/pip/issues/709\n\nChange-Id: I0e7aad1d21f4fce4c020ce36685bb56893c66bdc\n""}, {'number': 2, 'created': '2014-10-02 02:53:19.000000000', 'files': ['functions', 'functions-common', 'unstack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/944b28280b86bba7592b1c7a2032dbd0eaa39014', 'message': ""Drop workaround for pip < 1.4\n\nNow that we are on pip 1.5.6 lets drop the workaround to make pip 1.4\nwork. As this is a development/testing tool requiring a newer pip\nshouldn't be an issue. Also stack.sh installs pip by default.\n\nWork around introduced in https://github.com/pypa/pip/issues/709\n\nChange-Id: I0e7aad1d21f4fce4c020ce36685bb56893c66bdc\n""}]",0,125532,944b28280b86bba7592b1c7a2032dbd0eaa39014,14,7,2,1849,,,0,"Drop workaround for pip < 1.4

Now that we are on pip 1.5.6 lets drop the workaround to make pip 1.4
work. As this is a development/testing tool requiring a newer pip
shouldn't be an issue. Also stack.sh installs pip by default.

Work around introduced in https://github.com/pypa/pip/issues/709

Change-Id: I0e7aad1d21f4fce4c020ce36685bb56893c66bdc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/125532/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions', 'functions-common', 'unstack.sh']",3,6b5effe93a667310f8058a524ee6ed78c8488dd4,pip_fix,, cleanup_tmp,2,26
openstack%2Fgrenade~master~I5626253776909a099204634eca41abb9cc79ed47,openstack/grenade,master,I5626253776909a099204634eca41abb9cc79ed47,Typo olso -> oslo,MERGED,2014-10-03 12:19:55.000000000,2014-10-04 09:11:00.000000000,2014-10-04 09:11:00.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-10-03 12:19:55.000000000', 'files': ['upgrade-oslo'], 'web_link': 'https://opendev.org/openstack/grenade/commit/4061d910ed689b0c046ef03bcc055e3aab582691', 'message': 'Typo olso -> oslo\n\nChange-Id: I5626253776909a099204634eca41abb9cc79ed47\n'}]",0,125952,4061d910ed689b0c046ef03bcc055e3aab582691,8,4,1,5638,,,0,"Typo olso -> oslo

Change-Id: I5626253776909a099204634eca41abb9cc79ed47
",git fetch https://review.opendev.org/openstack/grenade refs/changes/52/125952/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade-oslo'],1,4061d910ed689b0c046ef03bcc055e3aab582691,,"# python library handling, this means if we don't uninstall old oslo, nova-manage","# python library handling, this means if we don't uninstall old olso, nova-manage",1,1
openstack%2Fproject-config~master~I221d37d74c400d0e2a412ec2f56af84c36c83892,openstack/project-config,master,I221d37d74c400d0e2a412ec2f56af84c36c83892,Remove oldmanual setting from projects.yaml,MERGED,2014-09-29 19:53:47.000000000,2014-10-04 09:05:44.000000000,2014-10-04 09:05:43.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6316}, {'_account_id': 6609}]","[{'number': 1, 'created': '2014-09-29 19:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b813239418b41e1640fb2cb3224e1da3a6a8818a', 'message': ""Remove oldmanual setting from projects.yaml\n\nChange I39f93f67b96961cd9991b6a13fecddb16e3a20fa remove the usage\nof oldmanual but not oldmanual itself.\n\nRemove it, it's not used anymore.\n\nChange-Id: I221d37d74c400d0e2a412ec2f56af84c36c83892\n""}, {'number': 2, 'created': '2014-10-03 18:56:11.000000000', 'files': ['jenkins/jobs/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d77372edcf1ca9afaf9cd3528a799efb143291e8', 'message': ""Remove oldmanual setting from projects.yaml\n\nChange I39f93f67b96961cd9991b6a13fecddb16e3a20fa remove the usage\nof oldmanual but not oldmanual itself.\n\nRemove it, it's not used anymore.\n\nChange-Id: I221d37d74c400d0e2a412ec2f56af84c36c83892\n""}]",0,124848,d77372edcf1ca9afaf9cd3528a799efb143291e8,14,4,2,6547,,,0,"Remove oldmanual setting from projects.yaml

Change I39f93f67b96961cd9991b6a13fecddb16e3a20fa remove the usage
of oldmanual but not oldmanual itself.

Remove it, it's not used anymore.

Change-Id: I221d37d74c400d0e2a412ec2f56af84c36c83892
",git fetch https://review.opendev.org/openstack/project-config refs/changes/48/124848/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/projects.yaml'],1,b813239418b41e1640fb2cb3224e1da3a6a8818a,cleanup-oldmanual,, oldmanual: - block-storage-admin - compute-admin - network-connectivity-admin - object-storage-admin ,0,6
openstack%2Fzaqar~master~Ic5099d6469b37f69431d984b2cde3e0893164bfb,openstack/zaqar,master,Ic5099d6469b37f69431d984b2cde3e0893164bfb,Imported Translations from Transifex,MERGED,2014-10-04 06:05:25.000000000,2014-10-04 08:59:22.000000000,2014-10-04 08:59:22.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-10-04 06:05:25.000000000', 'files': ['zaqar/locale/zaqar.pot', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/41afbed916d7c5820143561b0af9c797b1896673', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic5099d6469b37f69431d984b2cde3e0893164bfb\n'}]",0,126119,41afbed916d7c5820143561b0af9c797b1896673,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ic5099d6469b37f69431d984b2cde3e0893164bfb
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/19/126119/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/locale/zaqar.pot', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po']",2,41afbed916d7c5820143561b0af9c797b1896673,transifex/translations,"""POT-Creation-Date: 2014-10-04 06:05+0000\n""#: zaqar/queues/bootstrap.py:89 msgid """" ""Unreliable's default value will be changed to False in the Kilo release. "" ""Please, make sure your deployments are working in a reliable mode or that"" "" `unreliable` is explicitly set to `True` in your configuration files."" msgstr """" #: zaqar/queues/storage/mongodb/driver.py:79#: zaqar/queues/storage/mongodb/driver.py:84 msgid ""Either a replica set or a mongos is required to guarantee message delivery"" msgstr """" #: zaqar/queues/storage/mongodb/driver.py:97 msgid """" ""Using a write concern other than `majority` or > 2 make sthe service "" ""unreliable. Please use a different write concern or set `unreliable` to "" ""True in the config file."" msgstr """" #: zaqar/queues/transport/wsgi/v1_1/pools.py:181#: zaqar/queues/transport/wsgi/v1_1/pools.py:182","""POT-Creation-Date: 2014-10-03 06:13+0000\n""#: zaqar/queues/storage/mongodb/driver.py:77#: zaqar/queues/transport/wsgi/v1_1/pools.py:180#: zaqar/queues/transport/wsgi/v1_1/pools.py:181",45,9
openstack%2Fzaqar-specs~master~I935602a3a7a11455d009c37e9eebbb30c3ada037,openstack/zaqar-specs,master,I935602a3a7a11455d009c37e9eebbb30c3ada037,Use the current date for the copyright statement,MERGED,2014-09-10 19:25:58.000000000,2014-10-04 08:34:13.000000000,2014-10-04 08:34:13.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-09-10 19:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/aece5a1b150c6d276c2cfdd5420c45a24b25a5c1', 'message': 'Use the current date for the copyright statement\n\nChange-Id: I935602a3a7a11455d009c37e9eebbb30c3ada037\n'}, {'number': 2, 'created': '2014-09-10 20:07:12.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/98e0c6e26dda52fc872c5cfa5a2b90f6bccdf872', 'message': 'Use the current date for the copyright statement\n\nChange-Id: I935602a3a7a11455d009c37e9eebbb30c3ada037\n'}]",0,120554,98e0c6e26dda52fc872c5cfa5a2b90f6bccdf872,8,2,2,2472,,,0,"Use the current date for the copyright statement

Change-Id: I935602a3a7a11455d009c37e9eebbb30c3ada037
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/54/120554/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,aece5a1b150c6d276c2cfdd5420c45a24b25a5c1,rss-feed,"import datetimecopyright = u'%s, OpenStack Foundation' % datetime.date.today().year","copyright = u'2014, OpenStack Foundation'",2,1
openstack%2Fzaqar-specs~master~I1dd434ef8d03c2ee26eb4f301a80141d5fd747fe,openstack/zaqar-specs,master,I1dd434ef8d03c2ee26eb4f301a80141d5fd747fe,Remove templates from toctrees,MERGED,2014-09-10 19:25:58.000000000,2014-10-04 08:34:04.000000000,2014-10-04 08:34:03.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-09-10 19:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/d1f3e55df034a1f4b0f44561b6a31783c92d25ca', 'message': ""Remove templates from toctrees\n\nWe don't want the templates to show up in the RSS feed, so exclude them\nfrom being converted to HTML and listed in the toctree.\n\nChange-Id: I1dd434ef8d03c2ee26eb4f301a80141d5fd747fe\n""}, {'number': 2, 'created': '2014-09-10 20:07:12.000000000', 'files': ['doc/source/index.rst', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/329acba6ab8626ae2d31e0950b0c7646f12f3d9b', 'message': ""Remove templates from toctrees\n\nWe don't want the templates to show up in the RSS feed, so exclude them\nfrom being converted to HTML and listed in the toctree.\n\nChange-Id: I1dd434ef8d03c2ee26eb4f301a80141d5fd747fe\n""}]",0,120553,329acba6ab8626ae2d31e0950b0c7646f12f3d9b,8,2,2,2472,,,0,"Remove templates from toctrees

We don't want the templates to show up in the RSS feed, so exclude them
from being converted to HTML and listed in the toctree.

Change-Id: I1dd434ef8d03c2ee26eb4f301a80141d5fd747fe
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/53/120553/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/conf.py']",2,d1f3e55df034a1f4b0f44561b6a31783c92d25ca,rss-feed,"exclude_patterns = [ 'template.rst', '**/*template.rst', ] ",,5,1
openstack%2Fzaqar-specs~master~Ib4f84efab8b3af3ddd47d38d63a91362612bd655,openstack/zaqar-specs,master,Ib4f84efab8b3af3ddd47d38d63a91362612bd655,Add RSS feed,MERGED,2014-09-10 19:25:58.000000000,2014-10-04 08:33:35.000000000,2014-10-04 08:33:35.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-09-10 19:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/55d1b5ba3a47531da6348e69c7a2081aa59bdbed', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}, {'number': 2, 'created': '2014-09-10 20:07:12.000000000', 'files': ['requirements.txt', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/c64cdd16471a0ca0d43a88e180da6921e13e268d', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}]",0,120552,c64cdd16471a0ca0d43a88e180da6921e13e268d,9,2,2,2472,,,0,"Add RSS feed

Publish an RSS feed of the changes to the specs repository to make the
specs more discoverable.

Change-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/52/120552/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'doc/source/conf.py']",2,55d1b5ba3a47531da6348e69c7a2081aa59bdbed,rss-feed," 'oslosphinx', 'yasfb',# Feed configuration for yasfb feed_base_url = 'http://specs.openstack.org/openstack/zaqar-specs/' feed_author = 'OpenStack Zaqar Team' ", 'oslosphinx',7,1
openstack%2Fkeystone~master~I6dc36b506452f99488c2a202da5eea518cc51b68,openstack/keystone,master,I6dc36b506452f99488c2a202da5eea518cc51b68,Remove images directory from docs,MERGED,2014-10-02 16:36:25.000000000,2014-10-04 08:30:20.000000000,2014-10-04 08:30:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-02 16:36:25.000000000', 'files': ['doc/source/images/graphs_authCompDelegate.svg', 'doc/source/images/authComp.png', 'doc/source/images/graphs_authComp.svg', 'doc/source/images/graphs_authCompDelegate.png', 'doc/source/images/authComp.svg', 'doc/source/conf.py', 'doc/source/images/graphs_authComp.png'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e412785218bc7ea46a15ea64de490b9b4554a269', 'message': ""Remove images directory from docs\n\nI can't find a single place these images are used in our docs.\nBest I can tell is that middleware docs have a few of them:\nhttp://docs.openstack.org/developer/keystonemiddleware/middlewarearchitecture.html\n\nChange-Id: I6dc36b506452f99488c2a202da5eea518cc51b68\n""}]",0,125702,e412785218bc7ea46a15ea64de490b9b4554a269,11,5,1,6482,,,0,"Remove images directory from docs

I can't find a single place these images are used in our docs.
Best I can tell is that middleware docs have a few of them:
http://docs.openstack.org/developer/keystonemiddleware/middlewarearchitecture.html

Change-Id: I6dc36b506452f99488c2a202da5eea518cc51b68
",git fetch https://review.opendev.org/openstack/keystone refs/changes/02/125702/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/images/graphs_authCompDelegate.svg', 'doc/source/images/authComp.png', 'doc/source/images/graphs_authComp.svg', 'doc/source/images/graphs_authCompDelegate.png', 'doc/source/images/authComp.svg', 'doc/source/conf.py', 'doc/source/images/graphs_authComp.png']",7,e412785218bc7ea46a15ea64de490b9b4554a269,remove_images,,,1,276
openstack%2Fkeystonemiddleware~master~Ie1dad50cc44afc6ce841e87f2ee9de3149e72117,openstack/keystonemiddleware,master,Ie1dad50cc44afc6ce841e87f2ee9de3149e72117,Clean up the middleware docs,MERGED,2014-10-02 16:48:01.000000000,2014-10-04 08:21:31.000000000,2014-10-04 08:21:31.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-10-02 16:48:01.000000000', 'files': ['doc/source/middlewarearchitecture.rst'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/66ba3bd80231a2a0687cb7a7e7bdf05064540609', 'message': 'Clean up the middleware docs\n\nUsed code blocks when possible, and a minimal amount of\nhighlighting keywords.\n\nChange-Id: Ie1dad50cc44afc6ce841e87f2ee9de3149e72117\n'}]",0,125706,66ba3bd80231a2a0687cb7a7e7bdf05064540609,10,5,1,6482,,,0,"Clean up the middleware docs

Used code blocks when possible, and a minimal amount of
highlighting keywords.

Change-Id: Ie1dad50cc44afc6ce841e87f2ee9de3149e72117
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/06/125706/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/middlewarearchitecture.rst'],1,66ba3bd80231a2a0687cb7a7e7bdf05064540609,pretty_up_the_docs,a WSGI component. Example for the auth_token middleware: .. code-block:: inifrom ``api-paste.ini``: .. code-block:: iniand set in ``nova.conf``: .. code-block:: ini,a WSGI component. Example for the auth_token middleware::from api-paste.ini::and set in nova.conf:: ...,9,4
openstack%2Fsahara~master~Icbc950cc9e5f31871ea96dd1c7846fafdad444f4,openstack/sahara,master,Icbc950cc9e5f31871ea96dd1c7846fafdad444f4,Fix scaling with Heat and Neutron,MERGED,2014-10-03 06:56:57.000000000,2014-10-04 07:59:12.000000000,2014-10-04 07:59:11.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7604}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 9548}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-10-03 06:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/feb09536eb9e8d8116ad320c3fdba3a27d77f7e8', 'message': 'TEST COMMIT FOR HEAT FIX\n\nChange-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4\n'}, {'number': 2, 'created': '2014-10-03 07:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1e84a74addc197d2b03c4a6710479e1ad34fdcdf', 'message': 'TEST COMMIT FOR HEAT FIX\n\nChange-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4\n'}, {'number': 3, 'created': '2014-10-03 09:22:08.000000000', 'files': ['sahara/resources/neutron-port.heat', 'sahara/tests/unit/resources/test_serialize_resources_aa.heat', 'sahara/tests/unit/resources/test_serialize_resources_use_neutron.heat'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e9c29facbf6898047539a5a9405fd0a775ccfd7', 'message': 'Fix scaling with Heat and Neutron\n\nCloses-bug: #1376829\n\nChange-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4\n'}]",0,125900,4e9c29facbf6898047539a5a9405fd0a775ccfd7,23,9,3,7710,,,0,"Fix scaling with Heat and Neutron

Closes-bug: #1376829

Change-Id: Icbc950cc9e5f31871ea96dd1c7846fafdad444f4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/00/125900/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/resources/neutron-port.heat'],1,feb09536eb9e8d8116ad320c3fdba3a27d77f7e8,bug/1376829," ""network_id"" : ""%(fixed_net_id)s"", ""replacement_policy"": ""auto"""," ""network_id"" : ""%(fixed_net_id)s""",2,1
openstack%2Fsahara~master~I16c57dc0ab4d169245bac42e72657880137a287e,openstack/sahara,master,I16c57dc0ab4d169245bac42e72657880137a287e,Imported Translations from Transifex,MERGED,2014-10-04 06:10:58.000000000,2014-10-04 07:58:59.000000000,2014-10-04 07:58:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-10-04 06:10:58.000000000', 'files': ['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2637625a1e4fdb7f1391022b7ec43524301adfee', 'message': 'Imported Translations from Transifex\n\nChange-Id: I16c57dc0ab4d169245bac42e72657880137a287e\n'}]",0,126123,2637625a1e4fdb7f1391022b7ec43524301adfee,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I16c57dc0ab4d169245bac42e72657880137a287e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/23/126123/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po']",29,2637625a1e4fdb7f1391022b7ec43524301adfee,transifex/translations,,"# Translations template for sahara. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the sahara project. # # Translators: # Carsten Duch <cad@teuto.net>, 2014 msgid """" msgstr """" ""Project-Id-Version: Sahara\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-09-05 06:08+0000\n"" ""PO-Revision-Date: 2014-07-16 14:42+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: German (http://www.transifex.com/projects/p/sahara/language/"" ""de/)\n"" ""Language: de\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" #: sahara/main.py:76 #, python-format msgid ""Starting Sahara %s"" msgstr """" #: sahara/main.py:169 #, python-format msgid ""Loading '%s' infrastructure engine"" msgstr """" #: sahara/main.py:177 #, python-format msgid ""Loading '%s' remote"" msgstr """" #: sahara/main.py:183 #, python-format msgid ""Loading '%s' ops"" msgstr """" #: sahara/api/middleware/auth_valid.py:54 #, python-format msgid ""Incorrect path: %s"" msgstr """" #: sahara/openstack/common/lockutils.py:82 #, python-format msgid ""Created lock path: %s"" msgstr ""Sperrpfad erzeugt: %s"" #: sahara/openstack/common/lockutils.py:251 #, python-format msgid ""Failed to remove file %(file)s"" msgstr ""Lschen der Datei %(file)s fehlgeschlagen"" #: sahara/openstack/common/periodic_task.py:126 #, python-format msgid ""Skipping periodic task %(task)s because its interval is negative"" msgstr """" ""berspringe periodische Aufgabe %(task)s weil der Intervall negativ ist"" #: sahara/openstack/common/periodic_task.py:131 #, python-format msgid ""Skipping periodic task %(task)s because it is disabled"" msgstr ""berspringe periodische Aufgabe %(task)s weil sie deaktiviert ist"" #: sahara/plugins/base.py:106 #, python-format msgid ""Plugin '%(plugin_name)s' loaded %(entry_point)s"" msgstr """" #: sahara/plugins/cdh/deploy.py:292 msgid ""Cloudera Manager has been started"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:69 #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:330 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:309 msgid ""Install of Hadoop stack successful."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:178 msgid ""Provisioning Cluster via Ambari Server: {0} ..."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:247 msgid ""Using \""{0}\"" as admin user for scaling of cluster"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:330 #, python-format msgid ""AmbariPlugin: decommission_nodes called for HDP version = %s"" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:69 msgid ""{0}: Installing rpm's ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:81 msgid ""{0}: Unable to install rpm's from repo, checking for local install."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:91 msgid ""{0}: Installing swift integration ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:99 msgid """" ""{0}: Unable to install swift integration from source, checking for local rpm."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:126 msgid ""{0}: Installing ambari-server ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:130 msgid ""Running Ambari Server setup ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:156 msgid ""Starting Ambari ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:180 msgid ""{0}: Installing Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:192 msgid ""{0}: Starting Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:312 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:291 msgid ""Installing required Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:368 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:352 msgid ""Finalizing Ambari cluster state."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:385 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:369 msgid ""Starting Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:386 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:370 #, python-format msgid """" ""Cluster name: %(cluster_name)s, Ambari server address: %(server_address)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:407 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:391 msgid ""Successfully started Hadoop cluster '{0}'."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:434 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:418 msgid ""Successfully changed state of Hadoop components "" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:462 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:446 msgid ""Starting Hadoop components while scaling up"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:463 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:447 #, python-format msgid ""Cluster name %(cluster_name)s, Ambari server ip %(ip)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:519 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:503 msgid ""Waiting for all Ambari agents to register with server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:532 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:516 #, python-format msgid ""Registered Hosts: %(current_number)s of %(final_number)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:541 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:525 msgid ""Waiting to connect to ambari server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:623 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:713 msgid ""HTTP session is not cached"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:917 msgid ""Creating Hue ini property tree from configuration named {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1017 #, python-format msgid ""Merging configuration properties: %(source)s -> %(destination)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1061 msgid ""Installing Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1066 msgid ""Setting Hue configuration on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1072 msgid ""Uninstalling Shell, if it is installed on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1081 msgid ""Creating initial Hue user on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1086 msgid ""(Re)starting Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1177 msgid """" ""Missing HDFS client from Hue node... adding it since it is required for Hue"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1183 msgid """" ""Missing HIVE client from Hue node... adding it since it is required for "" ""Beeswax and HCatalog"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:642 msgid ""AmbariClient: decommission post request succeeded!"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:660 #, python-format msgid """" ""AmbariClient: number of hosts waiting for decommissioning to complete = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:669 #, python-format msgid ""AmbariClient: decommission status request ok, result = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:679 #, python-format msgid ""AmbariClient: node = %(node)s is now in adminState = %(admin_state)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:687 msgid ""AmbariClient: sleeping for 5 seconds"" msgstr """" #: sahara/plugins/spark/config_helper.py:221 #: sahara/plugins/vanilla/v1_2_1/config_helper.py:227 #, python-format msgid ""Applying config: %s"" msgstr """" #: sahara/plugins/spark/plugin.py:112 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:128 #, python-format msgid ""Hadoop services in cluster %s have been started"" msgstr """" #: sahara/plugins/spark/plugin.py:124 #, python-format msgid ""Spark service at '%s' has been started"" msgstr """" #: sahara/plugins/spark/plugin.py:127 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:158 #, python-format msgid ""Cluster %s has been started successfully"" msgstr """" #: sahara/plugins/spark/plugin.py:380 #, python-format msgid ""Spark master service at '%s' has been restarted"" msgstr """" #: sahara/plugins/vanilla/hadoop2/config.py:300 msgid """" ""Node group awareness is not implemented in YARN yet so "" ""enable_hypervisor_awareness set to False explicitly"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:147 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:166 #, python-format msgid ""Waiting %s datanodes to start up"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:152 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:171 #, python-format msgid ""Datanodes on cluster %s has been started"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:160 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:179 #, python-format msgid ""Stop waiting datanodes on cluster %s since it has been deleted"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:139 #, python-format msgid ""Oozie service at '%s' has been started"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:154 #, python-format msgid ""Hive Metastore server at %s has been started"" msgstr """" #: sahara/service/direct_engine.py:314 #, python-format msgid ""Cluster '%s': all instances are active"" msgstr """" #: sahara/service/direct_engine.py:351 sahara/service/heat_engine.py:146 #, python-format msgid ""Cluster '%(name)s' creation rollback (reason: %(reason)s)"" msgstr """" #: sahara/service/direct_engine.py:359 sahara/service/heat_engine.py:163 #, python-format msgid ""Cluster '%(name)s' scaling rollback (reason: %(reason)s)"" msgstr """" #: sahara/service/engine.py:77 #, python-format msgid ""Cluster '%s': all instances have IPs assigned"" msgstr """" #: sahara/service/engine.py:87 #, python-format msgid ""Cluster '%s': all instances are accessible"" msgstr """" #: sahara/service/ops.py:115 sahara/service/ops.py:134 #, python-format msgid ""Cluster with %s was deleted. Canceling current operation."" msgstr """" #: sahara/service/periodic.py:96 #, python-format msgid ""Terminating transient cluster %(cluster)s with id %(id)s"" msgstr """" #: sahara/service/periodic.py:103 #, python-format msgid """" ""Failed to terminate transient cluster %(cluster)s with id %(id)s: %(error)s."" msgstr """" #: sahara/swift/swift_helper.py:50 #, python-format msgid ""Swift would be integrated with the following params: %s"" msgstr """" #: sahara/topology/topology_helper.py:154 #, python-format msgid ""Vm awareness will add following configs in core-site params: %s"" msgstr """" #: sahara/topology/topology_helper.py:162 #, python-format msgid ""Vm awareness will add following configs in map-red params: %s"" msgstr """" #: sahara/utils/general.py:74 #, python-format msgid ""Cluster status has been changed: id=%(id)s, New status=%(status)s"" msgstr """" #: sahara/utils/rpc.py:121 msgid ""Notifications disabled"" msgstr """" #: sahara/utils/rpc.py:123 msgid ""Notifications enabled"" msgstr """" #: sahara/utils/timing.py:56 #, python-format msgid ""Exception raised by invocation of %(name)s: %(info)s"" msgstr """" ",36,12742
openstack%2Fhorizon~master~I47cc582340625aac87ab0242b147e11ef1d9b38e,openstack/horizon,master,I47cc582340625aac87ab0242b147e11ef1d9b38e,Remove #noqa from django.conf.urls.include,MERGED,2014-09-25 12:30:57.000000000,2014-10-04 07:08:52.000000000,2014-10-04 07:08:51.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 7012}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 11592}, {'_account_id': 11880}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-09-25 12:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d97c55ff6244e2760a2e6a8c19fe63d5a52266f3', 'message': 'Remove #noqa from django.conf.urls.include\n\nWe have one more import with #noqa: django.conf.urls.include that is also\ncommonly used in urls.py module and could be included to the list of\nimport exceptions. This change has also revealed one unused import.\n\nChange-Id: I47cc582340625aac87ab0242b147e11ef1d9b38e\n'}, {'number': 2, 'created': '2014-09-29 10:19:16.000000000', 'files': ['openstack_dashboard/dashboards/admin/networks/urls.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/urls.py', 'openstack_dashboard/dashboards/project/networks/urls.py', 'horizon/base.py', 'openstack_dashboard/dashboards/admin/hypervisors/urls.py', 'openstack_dashboard/dashboards/project/volumes/urls.py', 'horizon/site_urls.py', 'openstack_dashboard/dashboards/project/images/urls.py', 'horizon/test/urls.py', 'openstack_dashboard/dashboards/admin/volumes/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/urls.py', 'openstack_dashboard/urls.py', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b47f226647243464b1af4a182390f1301d7e804a', 'message': 'Remove #noqa from django.conf.urls.include\n\nWe have one more import with #noqa: django.conf.urls.include that is also\ncommonly used in urls.py module and could be included to the list of\nimport exceptions. This change has also revealed one unused import.\n\nChange-Id: I47cc582340625aac87ab0242b147e11ef1d9b38e\n'}]",2,124032,b47f226647243464b1af4a182390f1301d7e804a,27,12,2,6914,,,0,"Remove #noqa from django.conf.urls.include

We have one more import with #noqa: django.conf.urls.include that is also
commonly used in urls.py module and could be included to the list of
import exceptions. This change has also revealed one unused import.

Change-Id: I47cc582340625aac87ab0242b147e11ef1d9b38e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/124032/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/networks/urls.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/urls.py', 'openstack_dashboard/dashboards/project/networks/urls.py', 'horizon/base.py', 'openstack_dashboard/dashboards/admin/hypervisors/urls.py', 'openstack_dashboard/dashboards/project/volumes/urls.py', 'horizon/site_urls.py', 'openstack_dashboard/dashboards/project/images/urls.py', 'horizon/test/urls.py', 'openstack_dashboard/dashboards/admin/volumes/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/urls.py', 'openstack_dashboard/urls.py', 'tox.ini', 'HACKING.rst']",15,d97c55ff6244e2760a2e6a8c19fe63d5a52266f3,moarexceptions," django.conf.urls.include,",,14,13
openstack%2Foperations-guide~master~Ied41f5dbac814f3592a11273874554162b04f175,openstack/operations-guide,master,Ied41f5dbac814f3592a11273874554162b04f175,Updated from openstack-manuals,MERGED,2014-10-04 06:57:12.000000000,2014-10-04 07:06:17.000000000,2014-10-04 07:06:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 06:57:12.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6c2815e14e4fd17406b0341c0b5fb226aff8b705', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ied41f5dbac814f3592a11273874554162b04f175\n'}]",0,126130,6c2815e14e4fd17406b0341c0b5fb226aff8b705,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ied41f5dbac814f3592a11273874554162b04f175
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/30/126130/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,6c2815e14e4fd17406b0341c0b5fb226aff8b705,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:45+0000\n""#: ./doc/glossary/glossary-terms.xml7331(secondary) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml8092(primary)#: ./doc/glossary/glossary-terms.xml7329(primary) #: ./doc/glossary/glossary-terms.xml7358(primary) #: ./doc/glossary/glossary-terms.xml8542(primary)#: ./doc/glossary/glossary-terms.xml7859(para)#: ./doc/glossary/glossary-terms.xml8352(para) #: ./doc/glossary/glossary-terms.xml8585(para) #: ./doc/glossary/glossary-terms.xml8815(para) #: ./doc/glossary/glossary-terms.xml8916(para) #: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8237(primary)#: ./doc/glossary/glossary-terms.xml7489(primary) #: ./doc/glossary/glossary-terms.xml7717(primary)#: ./doc/glossary/glossary-terms.xml7691(see)#: ./doc/glossary/glossary-terms.xml7364(para)#: ./doc/glossary/glossary-terms.xml8421(para) #: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8456(primary) #: ./doc/glossary/glossary-terms.xml8604(primary)#: ./doc/glossary/glossary-terms.xml7757(primary) #: ./doc/glossary/glossary-terms.xml7957(primary)#: ./doc/glossary/glossary-terms.xml8220(primary)#: ./doc/glossary/glossary-terms.xml8200(see)#: ./doc/glossary/glossary-terms.xml7901(glossterm) #: ./doc/glossary/glossary-terms.xml7924(primary) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7962(primary)#: ./doc/glossary/glossary-terms.xml8512(primary)#: ./doc/glossary/glossary-terms.xml7607(primary)#: ./doc/glossary/glossary-terms.xml7609(secondary)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) msgid ""SELinux"" msgstr """" #: ./doc/glossary/glossary-terms.xml7321(para) msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" #: ./doc/glossary/glossary-terms.xml7327(glossterm)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7345(glossterm) #: ./doc/glossary/glossary-terms.xml7347(primary)#: ./doc/glossary/glossary-terms.xml7351(para)#: ./doc/glossary/glossary-terms.xml7356(glossterm) #: ./doc/glossary/glossary-terms.xml7360(secondary)#: ./doc/glossary/glossary-terms.xml7370(glossterm)#: ./doc/glossary/glossary-terms.xml7372(primary)#: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml7385(glossterm) #: ./doc/glossary/glossary-terms.xml7387(primary)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7434(primary)#: ./doc/glossary/glossary-terms.xml7438(para)#: ./doc/glossary/glossary-terms.xml7444(glossterm) #: ./doc/glossary/glossary-terms.xml7448(secondary)#: ./doc/glossary/glossary-terms.xml7446(primary) #: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7477(secondary)#: ./doc/glossary/glossary-terms.xml7481(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7494(primary)#: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7498(para)#: ./doc/glossary/glossary-terms.xml7511(glossterm)#: ./doc/glossary/glossary-terms.xml7513(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7544(para)#: ./doc/glossary/glossary-terms.xml7550(glossterm) #: ./doc/glossary/glossary-terms.xml7553(primary)#: ./doc/glossary/glossary-terms.xml7557(para)#: ./doc/glossary/glossary-terms.xml7563(glossterm) #: ./doc/glossary/glossary-terms.xml7566(primary)#: ./doc/glossary/glossary-terms.xml7570(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7592(glossterm) #: ./doc/glossary/glossary-terms.xml7594(primary)#: ./doc/glossary/glossary-terms.xml7598(para)#: ./doc/glossary/glossary-terms.xml7605(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm) #: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7628(para)#: ./doc/glossary/glossary-terms.xml7634(glossterm)#: ./doc/glossary/glossary-terms.xml7636(primary)#: ./doc/glossary/glossary-terms.xml7641(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7652(secondary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7665(glossterm) #: ./doc/glossary/glossary-terms.xml7667(primary)#: ./doc/glossary/glossary-terms.xml7671(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7682(para)#: ./doc/glossary/glossary-terms.xml7688(glossterm) #: ./doc/glossary/glossary-terms.xml7690(primary)#: ./doc/glossary/glossary-terms.xml7695(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7715(glossterm)#: ./doc/glossary/glossary-terms.xml7719(secondary)#: ./doc/glossary/glossary-terms.xml7722(primary)#: ./doc/glossary/glossary-terms.xml7726(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7745(primary)#: ./doc/glossary/glossary-terms.xml7749(para)#: ./doc/glossary/glossary-terms.xml7755(glossterm) #: ./doc/glossary/glossary-terms.xml7762(primary)#: ./doc/glossary/glossary-terms.xml7759(secondary)#: ./doc/glossary/glossary-terms.xml7766(para)#: ./doc/glossary/glossary-terms.xml7773(glossterm) #: ./doc/glossary/glossary-terms.xml7777(secondary)#: ./doc/glossary/glossary-terms.xml7775(primary) #: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7952(primary)#: ./doc/glossary/glossary-terms.xml7781(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7827(glossterm)#: ./doc/glossary/glossary-terms.xml7829(primary)#: ./doc/glossary/glossary-terms.xml7833(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7855(primary)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm)#: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7888(glossterm) #: ./doc/glossary/glossary-terms.xml7890(primary)#: ./doc/glossary/glossary-terms.xml7894(para)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary)#: ./doc/glossary/glossary-terms.xml7916(para)#: ./doc/glossary/glossary-terms.xml7922(glossterm) #: ./doc/glossary/glossary-terms.xml7926(secondary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm)#: ./doc/glossary/glossary-terms.xml7954(secondary) #: ./doc/glossary/glossary-terms.xml7959(secondary) #: ./doc/glossary/glossary-terms.xml7964(secondary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7986(glossterm) #: ./doc/glossary/glossary-terms.xml7988(primary)#: ./doc/glossary/glossary-terms.xml7992(para)#: ./doc/glossary/glossary-terms.xml7999(glossterm) #: ./doc/glossary/glossary-terms.xml8001(primary)#: ./doc/glossary/glossary-terms.xml8005(para)#: ./doc/glossary/glossary-terms.xml8015(title)#: ./doc/glossary/glossary-terms.xml8018(glossterm) #: ./doc/glossary/glossary-terms.xml8020(primary)#: ./doc/glossary/glossary-terms.xml8024(para)#: ./doc/glossary/glossary-terms.xml8031(glossterm) #: ./doc/glossary/glossary-terms.xml8033(primary)#: ./doc/glossary/glossary-terms.xml8037(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8058(primary)#: ./doc/glossary/glossary-terms.xml8062(para)#: ./doc/glossary/glossary-terms.xml8068(glossterm) #: ./doc/glossary/glossary-terms.xml8079(primary) #: ./doc/glossary/glossary-terms.xml8097(primary) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8071(para)#: ./doc/glossary/glossary-terms.xml8077(glossterm) #: ./doc/glossary/glossary-terms.xml8081(secondary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8090(glossterm) #: ./doc/glossary/glossary-terms.xml8094(secondary) #: ./doc/glossary/glossary-terms.xml8099(secondary)#: ./doc/glossary/glossary-terms.xml8103(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm)#: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8141(para)#: ./doc/glossary/glossary-terms.xml8147(glossterm) #: ./doc/glossary/glossary-terms.xml8149(primary)#: ./doc/glossary/glossary-terms.xml8152(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm) #: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8190(para)#: ./doc/glossary/glossary-terms.xml8196(glossterm)#: ./doc/glossary/glossary-terms.xml8198(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8209(glossterm)#: ./doc/glossary/glossary-terms.xml8212(para)#: ./doc/glossary/glossary-terms.xml8218(glossterm)#: ./doc/glossary/glossary-terms.xml8222(secondary) #: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml8229(para)#: ./doc/glossary/glossary-terms.xml8235(glossterm)#: ./doc/glossary/glossary-terms.xml8239(secondary) #: ./doc/glossary/glossary-terms.xml8242(primary)#: ./doc/glossary/glossary-terms.xml8246(para)#: ./doc/glossary/glossary-terms.xml8251(glossterm) #: ./doc/glossary/glossary-terms.xml8253(primary)#: ./doc/glossary/glossary-terms.xml8257(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8280(title)#: ./doc/glossary/glossary-terms.xml8283(glossterm) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml8289(para)#: ./doc/glossary/glossary-terms.xml8294(glossterm) #: ./doc/glossary/glossary-terms.xml8296(primary)#: ./doc/glossary/glossary-terms.xml8300(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8317(glossterm)#: ./doc/glossary/glossary-terms.xml8319(primary)#: ./doc/glossary/glossary-terms.xml8323(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8346(glossterm) #: ./doc/glossary/glossary-terms.xml8348(primary)#: ./doc/glossary/glossary-terms.xml8360(title)#: ./doc/glossary/glossary-terms.xml8363(glossterm) #: ./doc/glossary/glossary-terms.xml8365(primary)#: ./doc/glossary/glossary-terms.xml8369(para)#: ./doc/glossary/glossary-terms.xml8374(glossterm) #: ./doc/glossary/glossary-terms.xml8376(primary)#: ./doc/glossary/glossary-terms.xml8380(para)#: ./doc/glossary/glossary-terms.xml8390(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8427(glossterm) #: ./doc/glossary/glossary-terms.xml8429(primary)#: ./doc/glossary/glossary-terms.xml8433(para)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8454(glossterm) #: ./doc/glossary/glossary-terms.xml8461(primary)#: ./doc/glossary/glossary-terms.xml8458(secondary) #: ./doc/glossary/glossary-terms.xml8514(secondary) #: ./doc/glossary/glossary-terms.xml8544(secondary)#: ./doc/glossary/glossary-terms.xml8465(para)#: ./doc/glossary/glossary-terms.xml8470(glossterm) #: ./doc/glossary/glossary-terms.xml8472(primary)#: ./doc/glossary/glossary-terms.xml8476(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8497(glossterm) #: ./doc/glossary/glossary-terms.xml8499(primary)#: ./doc/glossary/glossary-terms.xml8503(para)#: ./doc/glossary/glossary-terms.xml8510(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8527(glossterm) #: ./doc/glossary/glossary-terms.xml8529(primary)#: ./doc/glossary/glossary-terms.xml8533(para)#: ./doc/glossary/glossary-terms.xml8540(glossterm)#: ./doc/glossary/glossary-terms.xml8547(primary)#: ./doc/glossary/glossary-terms.xml8551(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8568(glossterm) #: ./doc/glossary/glossary-terms.xml8570(primary)#: ./doc/glossary/glossary-terms.xml8574(para)#: ./doc/glossary/glossary-terms.xml8579(glossterm) #: ./doc/glossary/glossary-terms.xml8581(primary)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml8596(para)#: ./doc/glossary/glossary-terms.xml8602(glossterm) #: ./doc/glossary/glossary-terms.xml8609(primary)#: ./doc/glossary/glossary-terms.xml8606(secondary)#: ./doc/glossary/glossary-terms.xml8613(para)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8635(glossterm) #: ./doc/glossary/glossary-terms.xml8637(primary)#: ./doc/glossary/glossary-terms.xml8641(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8658(glossterm) #: ./doc/glossary/glossary-terms.xml8660(primary)#: ./doc/glossary/glossary-terms.xml8664(para)#: ./doc/glossary/glossary-terms.xml8669(glossterm)#: ./doc/glossary/glossary-terms.xml8672(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8679(primary)#: ./doc/glossary/glossary-terms.xml8683(para)#: ./doc/glossary/glossary-terms.xml8689(glossterm) #: ./doc/glossary/glossary-terms.xml8701(primary) #: ./doc/glossary/glossary-terms.xml8714(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8741(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary)#: ./doc/glossary/glossary-terms.xml8692(para)#: ./doc/glossary/glossary-terms.xml8699(glossterm) #: ./doc/glossary/glossary-terms.xml8703(secondary)#: ./doc/glossary/glossary-terms.xml8707(para)#: ./doc/glossary/glossary-terms.xml8712(glossterm) #: ./doc/glossary/glossary-terms.xml8716(secondary)#: ./doc/glossary/glossary-terms.xml8720(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8739(glossterm) #: ./doc/glossary/glossary-terms.xml8743(secondary)#: ./doc/glossary/glossary-terms.xml8747(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm)#: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8801(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm) #: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8823(title)#: ./doc/glossary/glossary-terms.xml8826(glossterm) #: ./doc/glossary/glossary-terms.xml8828(primary)#: ./doc/glossary/glossary-terms.xml8832(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm) #: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8863(glossterm)#: ./doc/glossary/glossary-terms.xml8865(primary)#: ./doc/glossary/glossary-terms.xml8869(para)#: ./doc/glossary/glossary-terms.xml8880(title)#: ./doc/glossary/glossary-terms.xml8883(glossterm) #: ./doc/glossary/glossary-terms.xml8885(primary)#: ./doc/glossary/glossary-terms.xml8889(para)#: ./doc/glossary/glossary-terms.xml8899(glossterm) #: ./doc/glossary/glossary-terms.xml8910(primary) #: ./doc/glossary/glossary-terms.xml8923(primary) #: ./doc/glossary/glossary-terms.xml8937(primary)#: ./doc/glossary/glossary-terms.xml8902(para)#: ./doc/glossary/glossary-terms.xml8908(glossterm) #: ./doc/glossary/glossary-terms.xml8912(secondary)#: ./doc/glossary/glossary-terms.xml8921(glossterm) #: ./doc/glossary/glossary-terms.xml8925(secondary)#: ./doc/glossary/glossary-terms.xml8929(para)#: ./doc/glossary/glossary-terms.xml8935(glossterm)#: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8951(title)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)#: ./doc/glossary/glossary-terms.xml8980(glossterm) #: ./doc/glossary/glossary-terms.xml8982(primary)#: ./doc/glossary/glossary-terms.xml8986(para)","""POT-Creation-Date: 2014-09-23 05:56+0000\n"" ""PO-Revision-Date: 2014-09-22 16:45+0000\n""#: ./doc/glossary/glossary-terms.xml7319(secondary) #: ./doc/glossary/glossary-terms.xml7362(secondary)#: ./doc/glossary/glossary-terms.xml8080(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) #: ./doc/glossary/glossary-terms.xml7346(primary) #: ./doc/glossary/glossary-terms.xml8530(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml8340(para) #: ./doc/glossary/glossary-terms.xml8573(para) #: ./doc/glossary/glossary-terms.xml8803(para) #: ./doc/glossary/glossary-terms.xml8904(para) #: ./doc/glossary/glossary-terms.xml8931(para)#: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml7477(primary) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7679(see)#: ./doc/glossary/glossary-terms.xml7352(para)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8617(para)#: ./doc/glossary/glossary-terms.xml8444(primary) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml7745(primary) #: ./doc/glossary/glossary-terms.xml7945(primary)#: ./doc/glossary/glossary-terms.xml8208(primary)#: ./doc/glossary/glossary-terms.xml8188(see)#: ./doc/glossary/glossary-terms.xml7889(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary) #: ./doc/glossary/glossary-terms.xml7926(primary) #: ./doc/glossary/glossary-terms.xml7950(primary)#: ./doc/glossary/glossary-terms.xml8500(primary)#: ./doc/glossary/glossary-terms.xml7595(primary)#: ./doc/glossary/glossary-terms.xml7597(secondary)#: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7323(para)#: ./doc/glossary/glossary-terms.xml7327(para)#: ./doc/glossary/glossary-terms.xml7333(glossterm) #: ./doc/glossary/glossary-terms.xml7335(primary)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7344(glossterm) #: ./doc/glossary/glossary-terms.xml7348(secondary)#: ./doc/glossary/glossary-terms.xml7358(glossterm)#: ./doc/glossary/glossary-terms.xml7360(primary)#: ./doc/glossary/glossary-terms.xml7366(para)#: ./doc/glossary/glossary-terms.xml7373(glossterm) #: ./doc/glossary/glossary-terms.xml7375(primary)#: ./doc/glossary/glossary-terms.xml7379(para)#: ./doc/glossary/glossary-terms.xml7384(glossterm) #: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7390(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7436(secondary)#: ./doc/glossary/glossary-terms.xml7434(primary) #: ./doc/glossary/glossary-terms.xml7448(primary) #: ./doc/glossary/glossary-terms.xml7463(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7450(secondary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7461(glossterm) #: ./doc/glossary/glossary-terms.xml7465(secondary)#: ./doc/glossary/glossary-terms.xml7469(para)#: ./doc/glossary/glossary-terms.xml7475(glossterm) #: ./doc/glossary/glossary-terms.xml7482(primary)#: ./doc/glossary/glossary-terms.xml7479(secondary)#: ./doc/glossary/glossary-terms.xml7486(para)#: ./doc/glossary/glossary-terms.xml7499(glossterm)#: ./doc/glossary/glossary-terms.xml7501(primary)#: ./doc/glossary/glossary-terms.xml7505(para)#: ./doc/glossary/glossary-terms.xml7514(glossterm) #: ./doc/glossary/glossary-terms.xml7516(primary)#: ./doc/glossary/glossary-terms.xml7520(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7541(primary)#: ./doc/glossary/glossary-terms.xml7545(para)#: ./doc/glossary/glossary-terms.xml7551(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7568(glossterm) #: ./doc/glossary/glossary-terms.xml7570(primary)#: ./doc/glossary/glossary-terms.xml7574(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7593(glossterm) #: ./doc/glossary/glossary-terms.xml7600(primary)#: ./doc/glossary/glossary-terms.xml7604(para)#: ./doc/glossary/glossary-terms.xml7610(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm)#: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7629(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7643(primary)#: ./doc/glossary/glossary-terms.xml7640(secondary)#: ./doc/glossary/glossary-terms.xml7647(para)#: ./doc/glossary/glossary-terms.xml7653(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7664(glossterm) #: ./doc/glossary/glossary-terms.xml7666(primary)#: ./doc/glossary/glossary-terms.xml7670(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7683(para)#: ./doc/glossary/glossary-terms.xml7691(glossterm) #: ./doc/glossary/glossary-terms.xml7693(primary)#: ./doc/glossary/glossary-terms.xml7697(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm)#: ./doc/glossary/glossary-terms.xml7707(secondary)#: ./doc/glossary/glossary-terms.xml7710(primary)#: ./doc/glossary/glossary-terms.xml7714(para)#: ./doc/glossary/glossary-terms.xml7719(glossterm) #: ./doc/glossary/glossary-terms.xml7721(primary)#: ./doc/glossary/glossary-terms.xml7725(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7750(primary)#: ./doc/glossary/glossary-terms.xml7747(secondary)#: ./doc/glossary/glossary-terms.xml7754(para)#: ./doc/glossary/glossary-terms.xml7761(glossterm) #: ./doc/glossary/glossary-terms.xml7765(secondary)#: ./doc/glossary/glossary-terms.xml7763(primary) #: ./doc/glossary/glossary-terms.xml7777(primary) #: ./doc/glossary/glossary-terms.xml7791(primary) #: ./doc/glossary/glossary-terms.xml7940(primary)#: ./doc/glossary/glossary-terms.xml7769(para)#: ./doc/glossary/glossary-terms.xml7775(glossterm) #: ./doc/glossary/glossary-terms.xml7779(secondary)#: ./doc/glossary/glossary-terms.xml7783(para)#: ./doc/glossary/glossary-terms.xml7789(glossterm) #: ./doc/glossary/glossary-terms.xml7793(secondary)#: ./doc/glossary/glossary-terms.xml7797(para)#: ./doc/glossary/glossary-terms.xml7803(glossterm) #: ./doc/glossary/glossary-terms.xml7805(primary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm)#: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7840(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7852(glossterm)#: ./doc/glossary/glossary-terms.xml7854(primary)#: ./doc/glossary/glossary-terms.xml7858(para)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm) #: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7892(para)#: ./doc/glossary/glossary-terms.xml7898(glossterm) #: ./doc/glossary/glossary-terms.xml7900(primary)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7914(secondary)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7928(secondary)#: ./doc/glossary/glossary-terms.xml7932(para)#: ./doc/glossary/glossary-terms.xml7938(glossterm)#: ./doc/glossary/glossary-terms.xml7942(secondary) #: ./doc/glossary/glossary-terms.xml7947(secondary) #: ./doc/glossary/glossary-terms.xml7952(secondary)#: ./doc/glossary/glossary-terms.xml7956(para)#: ./doc/glossary/glossary-terms.xml7962(glossterm) #: ./doc/glossary/glossary-terms.xml7964(primary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary)#: ./doc/glossary/glossary-terms.xml7993(para)#: ./doc/glossary/glossary-terms.xml8003(title)#: ./doc/glossary/glossary-terms.xml8006(glossterm) #: ./doc/glossary/glossary-terms.xml8008(primary)#: ./doc/glossary/glossary-terms.xml8012(para)#: ./doc/glossary/glossary-terms.xml8019(glossterm) #: ./doc/glossary/glossary-terms.xml8021(primary)#: ./doc/glossary/glossary-terms.xml8025(para)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8067(primary) #: ./doc/glossary/glossary-terms.xml8085(primary) #: ./doc/glossary/glossary-terms.xml8099(primary)#: ./doc/glossary/glossary-terms.xml8059(para)#: ./doc/glossary/glossary-terms.xml8065(glossterm) #: ./doc/glossary/glossary-terms.xml8069(secondary)#: ./doc/glossary/glossary-terms.xml8073(para)#: ./doc/glossary/glossary-terms.xml8078(glossterm) #: ./doc/glossary/glossary-terms.xml8082(secondary) #: ./doc/glossary/glossary-terms.xml8087(secondary)#: ./doc/glossary/glossary-terms.xml8091(para)#: ./doc/glossary/glossary-terms.xml8097(glossterm) #: ./doc/glossary/glossary-terms.xml8101(secondary)#: ./doc/glossary/glossary-terms.xml8105(para)#: ./doc/glossary/glossary-terms.xml8111(glossterm)#: ./doc/glossary/glossary-terms.xml8113(primary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8140(para)#: ./doc/glossary/glossary-terms.xml8148(glossterm) #: ./doc/glossary/glossary-terms.xml8150(primary)#: ./doc/glossary/glossary-terms.xml8154(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm)#: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8197(glossterm)#: ./doc/glossary/glossary-terms.xml8200(para)#: ./doc/glossary/glossary-terms.xml8206(glossterm)#: ./doc/glossary/glossary-terms.xml8210(secondary) #: ./doc/glossary/glossary-terms.xml8213(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8227(secondary) #: ./doc/glossary/glossary-terms.xml8230(primary)#: ./doc/glossary/glossary-terms.xml8234(para)#: ./doc/glossary/glossary-terms.xml8239(glossterm) #: ./doc/glossary/glossary-terms.xml8241(primary)#: ./doc/glossary/glossary-terms.xml8245(para)#: ./doc/glossary/glossary-terms.xml8253(glossterm) #: ./doc/glossary/glossary-terms.xml8255(primary)#: ./doc/glossary/glossary-terms.xml8259(para)#: ./doc/glossary/glossary-terms.xml8268(title)#: ./doc/glossary/glossary-terms.xml8271(glossterm) #: ./doc/glossary/glossary-terms.xml8273(primary)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8282(glossterm) #: ./doc/glossary/glossary-terms.xml8284(primary)#: ./doc/glossary/glossary-terms.xml8288(para)#: ./doc/glossary/glossary-terms.xml8293(glossterm)#: ./doc/glossary/glossary-terms.xml8295(primary)#: ./doc/glossary/glossary-terms.xml8299(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8318(glossterm) #: ./doc/glossary/glossary-terms.xml8320(primary)#: ./doc/glossary/glossary-terms.xml8324(para)#: ./doc/glossary/glossary-terms.xml8334(glossterm) #: ./doc/glossary/glossary-terms.xml8336(primary)#: ./doc/glossary/glossary-terms.xml8348(title)#: ./doc/glossary/glossary-terms.xml8351(glossterm) #: ./doc/glossary/glossary-terms.xml8353(primary)#: ./doc/glossary/glossary-terms.xml8357(para)#: ./doc/glossary/glossary-terms.xml8362(glossterm) #: ./doc/glossary/glossary-terms.xml8364(primary)#: ./doc/glossary/glossary-terms.xml8368(para)#: ./doc/glossary/glossary-terms.xml8378(glossterm) #: ./doc/glossary/glossary-terms.xml8381(primary)#: ./doc/glossary/glossary-terms.xml8385(para)#: ./doc/glossary/glossary-terms.xml8391(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8421(para)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8435(para)#: ./doc/glossary/glossary-terms.xml8442(glossterm) #: ./doc/glossary/glossary-terms.xml8449(primary)#: ./doc/glossary/glossary-terms.xml8446(secondary) #: ./doc/glossary/glossary-terms.xml8502(secondary) #: ./doc/glossary/glossary-terms.xml8532(secondary)#: ./doc/glossary/glossary-terms.xml8453(para)#: ./doc/glossary/glossary-terms.xml8458(glossterm) #: ./doc/glossary/glossary-terms.xml8460(primary)#: ./doc/glossary/glossary-terms.xml8464(para)#: ./doc/glossary/glossary-terms.xml8473(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8498(glossterm) #: ./doc/glossary/glossary-terms.xml8505(primary)#: ./doc/glossary/glossary-terms.xml8509(para)#: ./doc/glossary/glossary-terms.xml8515(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8528(glossterm)#: ./doc/glossary/glossary-terms.xml8535(primary)#: ./doc/glossary/glossary-terms.xml8539(para)#: ./doc/glossary/glossary-terms.xml8544(glossterm) #: ./doc/glossary/glossary-terms.xml8546(primary)#: ./doc/glossary/glossary-terms.xml8550(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8567(glossterm) #: ./doc/glossary/glossary-terms.xml8569(primary)#: ./doc/glossary/glossary-terms.xml8578(glossterm) #: ./doc/glossary/glossary-terms.xml8580(primary)#: ./doc/glossary/glossary-terms.xml8584(para)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8597(primary)#: ./doc/glossary/glossary-terms.xml8594(secondary)#: ./doc/glossary/glossary-terms.xml8601(para)#: ./doc/glossary/glossary-terms.xml8611(glossterm) #: ./doc/glossary/glossary-terms.xml8613(primary)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8634(glossterm) #: ./doc/glossary/glossary-terms.xml8636(primary)#: ./doc/glossary/glossary-terms.xml8640(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8657(glossterm)#: ./doc/glossary/glossary-terms.xml8660(para)#: ./doc/glossary/glossary-terms.xml8665(glossterm) #: ./doc/glossary/glossary-terms.xml8667(primary)#: ./doc/glossary/glossary-terms.xml8671(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8689(primary) #: ./doc/glossary/glossary-terms.xml8702(primary) #: ./doc/glossary/glossary-terms.xml8716(primary) #: ./doc/glossary/glossary-terms.xml8729(primary) #: ./doc/glossary/glossary-terms.xml8743(primary) #: ./doc/glossary/glossary-terms.xml8757(primary) #: ./doc/glossary/glossary-terms.xml8771(primary)#: ./doc/glossary/glossary-terms.xml8680(para)#: ./doc/glossary/glossary-terms.xml8687(glossterm) #: ./doc/glossary/glossary-terms.xml8691(secondary)#: ./doc/glossary/glossary-terms.xml8695(para)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8704(secondary)#: ./doc/glossary/glossary-terms.xml8708(para)#: ./doc/glossary/glossary-terms.xml8714(glossterm) #: ./doc/glossary/glossary-terms.xml8718(secondary)#: ./doc/glossary/glossary-terms.xml8722(para)#: ./doc/glossary/glossary-terms.xml8727(glossterm) #: ./doc/glossary/glossary-terms.xml8731(secondary)#: ./doc/glossary/glossary-terms.xml8735(para)#: ./doc/glossary/glossary-terms.xml8741(glossterm) #: ./doc/glossary/glossary-terms.xml8745(secondary)#: ./doc/glossary/glossary-terms.xml8749(para)#: ./doc/glossary/glossary-terms.xml8755(glossterm) #: ./doc/glossary/glossary-terms.xml8759(secondary)#: ./doc/glossary/glossary-terms.xml8763(para)#: ./doc/glossary/glossary-terms.xml8769(glossterm) #: ./doc/glossary/glossary-terms.xml8773(secondary)#: ./doc/glossary/glossary-terms.xml8777(para)#: ./doc/glossary/glossary-terms.xml8783(glossterm)#: ./doc/glossary/glossary-terms.xml8785(primary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8797(glossterm) #: ./doc/glossary/glossary-terms.xml8799(primary)#: ./doc/glossary/glossary-terms.xml8811(title)#: ./doc/glossary/glossary-terms.xml8814(glossterm) #: ./doc/glossary/glossary-terms.xml8816(primary)#: ./doc/glossary/glossary-terms.xml8820(para)#: ./doc/glossary/glossary-terms.xml8827(glossterm) #: ./doc/glossary/glossary-terms.xml8829(primary)#: ./doc/glossary/glossary-terms.xml8833(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm)#: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8868(title)#: ./doc/glossary/glossary-terms.xml8871(glossterm) #: ./doc/glossary/glossary-terms.xml8873(primary)#: ./doc/glossary/glossary-terms.xml8877(para)#: ./doc/glossary/glossary-terms.xml8887(glossterm) #: ./doc/glossary/glossary-terms.xml8898(primary) #: ./doc/glossary/glossary-terms.xml8911(primary) #: ./doc/glossary/glossary-terms.xml8925(primary)#: ./doc/glossary/glossary-terms.xml8890(para)#: ./doc/glossary/glossary-terms.xml8896(glossterm) #: ./doc/glossary/glossary-terms.xml8900(secondary)#: ./doc/glossary/glossary-terms.xml8909(glossterm) #: ./doc/glossary/glossary-terms.xml8913(secondary)#: ./doc/glossary/glossary-terms.xml8917(para)#: ./doc/glossary/glossary-terms.xml8923(glossterm)#: ./doc/glossary/glossary-terms.xml8927(secondary)#: ./doc/glossary/glossary-terms.xml8939(title)#: ./doc/glossary/glossary-terms.xml8953(title)#: ./doc/glossary/glossary-terms.xml8956(glossterm) #: ./doc/glossary/glossary-terms.xml8958(primary)#: ./doc/glossary/glossary-terms.xml8962(para)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)",434,423
openstack%2Fsecurity-doc~master~I14c3bc833831067f3b57ad5a68ee36665921962f,openstack/security-doc,master,I14c3bc833831067f3b57ad5a68ee36665921962f,Updated from openstack-manuals,MERGED,2014-10-04 06:57:15.000000000,2014-10-04 07:03:41.000000000,2014-10-04 07:03:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 06:57:15.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/fcc5e92afafcd40a21ac9c0b99432919814ea8fe', 'message': 'Updated from openstack-manuals\n\nChange-Id: I14c3bc833831067f3b57ad5a68ee36665921962f\n'}]",0,126131,fcc5e92afafcd40a21ac9c0b99432919814ea8fe,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I14c3bc833831067f3b57ad5a68ee36665921962f
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/31/126131/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,fcc5e92afafcd40a21ac9c0b99432919814ea8fe,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:45+0000\n""#: ./doc/glossary/glossary-terms.xml7331(secondary) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml8092(primary)#: ./doc/glossary/glossary-terms.xml7329(primary) #: ./doc/glossary/glossary-terms.xml7358(primary) #: ./doc/glossary/glossary-terms.xml8542(primary)#: ./doc/glossary/glossary-terms.xml7859(para)#: ./doc/glossary/glossary-terms.xml8352(para) #: ./doc/glossary/glossary-terms.xml8585(para) #: ./doc/glossary/glossary-terms.xml8815(para) #: ./doc/glossary/glossary-terms.xml8916(para) #: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8237(primary)#: ./doc/glossary/glossary-terms.xml7489(primary) #: ./doc/glossary/glossary-terms.xml7717(primary)#: ./doc/glossary/glossary-terms.xml7691(see)#: ./doc/glossary/glossary-terms.xml7364(para)#: ./doc/glossary/glossary-terms.xml8421(para) #: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8456(primary) #: ./doc/glossary/glossary-terms.xml8604(primary)#: ./doc/glossary/glossary-terms.xml7757(primary) #: ./doc/glossary/glossary-terms.xml7957(primary)#: ./doc/glossary/glossary-terms.xml8220(primary)#: ./doc/glossary/glossary-terms.xml8200(see)#: ./doc/glossary/glossary-terms.xml7901(glossterm) #: ./doc/glossary/glossary-terms.xml7924(primary) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7962(primary)#: ./doc/glossary/glossary-terms.xml8512(primary)#: ./doc/glossary/glossary-terms.xml7607(primary)#: ./doc/glossary/glossary-terms.xml7609(secondary)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) msgid ""SELinux"" msgstr """" #: ./doc/glossary/glossary-terms.xml7321(para) msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" #: ./doc/glossary/glossary-terms.xml7327(glossterm)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7345(glossterm) #: ./doc/glossary/glossary-terms.xml7347(primary)#: ./doc/glossary/glossary-terms.xml7351(para)#: ./doc/glossary/glossary-terms.xml7356(glossterm) #: ./doc/glossary/glossary-terms.xml7360(secondary)#: ./doc/glossary/glossary-terms.xml7370(glossterm)#: ./doc/glossary/glossary-terms.xml7372(primary)#: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml7385(glossterm) #: ./doc/glossary/glossary-terms.xml7387(primary)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7434(primary)#: ./doc/glossary/glossary-terms.xml7438(para)#: ./doc/glossary/glossary-terms.xml7444(glossterm) #: ./doc/glossary/glossary-terms.xml7448(secondary)#: ./doc/glossary/glossary-terms.xml7446(primary) #: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7477(secondary)#: ./doc/glossary/glossary-terms.xml7481(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7494(primary)#: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7498(para)#: ./doc/glossary/glossary-terms.xml7511(glossterm)#: ./doc/glossary/glossary-terms.xml7513(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7544(para)#: ./doc/glossary/glossary-terms.xml7550(glossterm) #: ./doc/glossary/glossary-terms.xml7553(primary)#: ./doc/glossary/glossary-terms.xml7557(para)#: ./doc/glossary/glossary-terms.xml7563(glossterm) #: ./doc/glossary/glossary-terms.xml7566(primary)#: ./doc/glossary/glossary-terms.xml7570(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7592(glossterm) #: ./doc/glossary/glossary-terms.xml7594(primary)#: ./doc/glossary/glossary-terms.xml7598(para)#: ./doc/glossary/glossary-terms.xml7605(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm) #: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7628(para)#: ./doc/glossary/glossary-terms.xml7634(glossterm)#: ./doc/glossary/glossary-terms.xml7636(primary)#: ./doc/glossary/glossary-terms.xml7641(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7652(secondary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7665(glossterm) #: ./doc/glossary/glossary-terms.xml7667(primary)#: ./doc/glossary/glossary-terms.xml7671(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7682(para)#: ./doc/glossary/glossary-terms.xml7688(glossterm) #: ./doc/glossary/glossary-terms.xml7690(primary)#: ./doc/glossary/glossary-terms.xml7695(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7715(glossterm)#: ./doc/glossary/glossary-terms.xml7719(secondary)#: ./doc/glossary/glossary-terms.xml7722(primary)#: ./doc/glossary/glossary-terms.xml7726(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7745(primary)#: ./doc/glossary/glossary-terms.xml7749(para)#: ./doc/glossary/glossary-terms.xml7755(glossterm) #: ./doc/glossary/glossary-terms.xml7762(primary)#: ./doc/glossary/glossary-terms.xml7759(secondary)#: ./doc/glossary/glossary-terms.xml7766(para)#: ./doc/glossary/glossary-terms.xml7773(glossterm) #: ./doc/glossary/glossary-terms.xml7777(secondary)#: ./doc/glossary/glossary-terms.xml7775(primary) #: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7952(primary)#: ./doc/glossary/glossary-terms.xml7781(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7827(glossterm)#: ./doc/glossary/glossary-terms.xml7829(primary)#: ./doc/glossary/glossary-terms.xml7833(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7855(primary)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm)#: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7888(glossterm) #: ./doc/glossary/glossary-terms.xml7890(primary)#: ./doc/glossary/glossary-terms.xml7894(para)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary)#: ./doc/glossary/glossary-terms.xml7916(para)#: ./doc/glossary/glossary-terms.xml7922(glossterm) #: ./doc/glossary/glossary-terms.xml7926(secondary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm)#: ./doc/glossary/glossary-terms.xml7954(secondary) #: ./doc/glossary/glossary-terms.xml7959(secondary) #: ./doc/glossary/glossary-terms.xml7964(secondary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7986(glossterm) #: ./doc/glossary/glossary-terms.xml7988(primary)#: ./doc/glossary/glossary-terms.xml7992(para)#: ./doc/glossary/glossary-terms.xml7999(glossterm) #: ./doc/glossary/glossary-terms.xml8001(primary)#: ./doc/glossary/glossary-terms.xml8005(para)#: ./doc/glossary/glossary-terms.xml8015(title)#: ./doc/glossary/glossary-terms.xml8018(glossterm) #: ./doc/glossary/glossary-terms.xml8020(primary)#: ./doc/glossary/glossary-terms.xml8024(para)#: ./doc/glossary/glossary-terms.xml8031(glossterm) #: ./doc/glossary/glossary-terms.xml8033(primary)#: ./doc/glossary/glossary-terms.xml8037(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8058(primary)#: ./doc/glossary/glossary-terms.xml8062(para)#: ./doc/glossary/glossary-terms.xml8068(glossterm) #: ./doc/glossary/glossary-terms.xml8079(primary) #: ./doc/glossary/glossary-terms.xml8097(primary) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8071(para)#: ./doc/glossary/glossary-terms.xml8077(glossterm) #: ./doc/glossary/glossary-terms.xml8081(secondary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8090(glossterm) #: ./doc/glossary/glossary-terms.xml8094(secondary) #: ./doc/glossary/glossary-terms.xml8099(secondary)#: ./doc/glossary/glossary-terms.xml8103(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm)#: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8141(para)#: ./doc/glossary/glossary-terms.xml8147(glossterm) #: ./doc/glossary/glossary-terms.xml8149(primary)#: ./doc/glossary/glossary-terms.xml8152(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm) #: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8190(para)#: ./doc/glossary/glossary-terms.xml8196(glossterm)#: ./doc/glossary/glossary-terms.xml8198(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8209(glossterm)#: ./doc/glossary/glossary-terms.xml8212(para)#: ./doc/glossary/glossary-terms.xml8218(glossterm)#: ./doc/glossary/glossary-terms.xml8222(secondary) #: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml8229(para)#: ./doc/glossary/glossary-terms.xml8235(glossterm)#: ./doc/glossary/glossary-terms.xml8239(secondary) #: ./doc/glossary/glossary-terms.xml8242(primary)#: ./doc/glossary/glossary-terms.xml8246(para)#: ./doc/glossary/glossary-terms.xml8251(glossterm) #: ./doc/glossary/glossary-terms.xml8253(primary)#: ./doc/glossary/glossary-terms.xml8257(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8280(title)#: ./doc/glossary/glossary-terms.xml8283(glossterm) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml8289(para)#: ./doc/glossary/glossary-terms.xml8294(glossterm) #: ./doc/glossary/glossary-terms.xml8296(primary)#: ./doc/glossary/glossary-terms.xml8300(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8317(glossterm)#: ./doc/glossary/glossary-terms.xml8319(primary)#: ./doc/glossary/glossary-terms.xml8323(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8346(glossterm) #: ./doc/glossary/glossary-terms.xml8348(primary)#: ./doc/glossary/glossary-terms.xml8360(title)#: ./doc/glossary/glossary-terms.xml8363(glossterm) #: ./doc/glossary/glossary-terms.xml8365(primary)#: ./doc/glossary/glossary-terms.xml8369(para)#: ./doc/glossary/glossary-terms.xml8374(glossterm) #: ./doc/glossary/glossary-terms.xml8376(primary)#: ./doc/glossary/glossary-terms.xml8380(para)#: ./doc/glossary/glossary-terms.xml8390(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8427(glossterm) #: ./doc/glossary/glossary-terms.xml8429(primary)#: ./doc/glossary/glossary-terms.xml8433(para)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8454(glossterm) #: ./doc/glossary/glossary-terms.xml8461(primary)#: ./doc/glossary/glossary-terms.xml8458(secondary) #: ./doc/glossary/glossary-terms.xml8514(secondary) #: ./doc/glossary/glossary-terms.xml8544(secondary)#: ./doc/glossary/glossary-terms.xml8465(para)#: ./doc/glossary/glossary-terms.xml8470(glossterm) #: ./doc/glossary/glossary-terms.xml8472(primary)#: ./doc/glossary/glossary-terms.xml8476(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8497(glossterm) #: ./doc/glossary/glossary-terms.xml8499(primary)#: ./doc/glossary/glossary-terms.xml8503(para)#: ./doc/glossary/glossary-terms.xml8510(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8527(glossterm) #: ./doc/glossary/glossary-terms.xml8529(primary)#: ./doc/glossary/glossary-terms.xml8533(para)#: ./doc/glossary/glossary-terms.xml8540(glossterm)#: ./doc/glossary/glossary-terms.xml8547(primary)#: ./doc/glossary/glossary-terms.xml8551(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8568(glossterm) #: ./doc/glossary/glossary-terms.xml8570(primary)#: ./doc/glossary/glossary-terms.xml8574(para)#: ./doc/glossary/glossary-terms.xml8579(glossterm) #: ./doc/glossary/glossary-terms.xml8581(primary)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml8596(para)#: ./doc/glossary/glossary-terms.xml8602(glossterm) #: ./doc/glossary/glossary-terms.xml8609(primary)#: ./doc/glossary/glossary-terms.xml8606(secondary)#: ./doc/glossary/glossary-terms.xml8613(para)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8635(glossterm) #: ./doc/glossary/glossary-terms.xml8637(primary)#: ./doc/glossary/glossary-terms.xml8641(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8658(glossterm) #: ./doc/glossary/glossary-terms.xml8660(primary)#: ./doc/glossary/glossary-terms.xml8664(para)#: ./doc/glossary/glossary-terms.xml8669(glossterm)#: ./doc/glossary/glossary-terms.xml8672(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8679(primary)#: ./doc/glossary/glossary-terms.xml8683(para)#: ./doc/glossary/glossary-terms.xml8689(glossterm) #: ./doc/glossary/glossary-terms.xml8701(primary) #: ./doc/glossary/glossary-terms.xml8714(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8741(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary)#: ./doc/glossary/glossary-terms.xml8692(para)#: ./doc/glossary/glossary-terms.xml8699(glossterm) #: ./doc/glossary/glossary-terms.xml8703(secondary)#: ./doc/glossary/glossary-terms.xml8707(para)#: ./doc/glossary/glossary-terms.xml8712(glossterm) #: ./doc/glossary/glossary-terms.xml8716(secondary)#: ./doc/glossary/glossary-terms.xml8720(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8739(glossterm) #: ./doc/glossary/glossary-terms.xml8743(secondary)#: ./doc/glossary/glossary-terms.xml8747(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm)#: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8801(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm) #: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8823(title)#: ./doc/glossary/glossary-terms.xml8826(glossterm) #: ./doc/glossary/glossary-terms.xml8828(primary)#: ./doc/glossary/glossary-terms.xml8832(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm) #: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8863(glossterm)#: ./doc/glossary/glossary-terms.xml8865(primary)#: ./doc/glossary/glossary-terms.xml8869(para)#: ./doc/glossary/glossary-terms.xml8880(title)#: ./doc/glossary/glossary-terms.xml8883(glossterm) #: ./doc/glossary/glossary-terms.xml8885(primary)#: ./doc/glossary/glossary-terms.xml8889(para)#: ./doc/glossary/glossary-terms.xml8899(glossterm) #: ./doc/glossary/glossary-terms.xml8910(primary) #: ./doc/glossary/glossary-terms.xml8923(primary) #: ./doc/glossary/glossary-terms.xml8937(primary)#: ./doc/glossary/glossary-terms.xml8902(para)#: ./doc/glossary/glossary-terms.xml8908(glossterm) #: ./doc/glossary/glossary-terms.xml8912(secondary)#: ./doc/glossary/glossary-terms.xml8921(glossterm) #: ./doc/glossary/glossary-terms.xml8925(secondary)#: ./doc/glossary/glossary-terms.xml8929(para)#: ./doc/glossary/glossary-terms.xml8935(glossterm)#: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8951(title)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)#: ./doc/glossary/glossary-terms.xml8980(glossterm) #: ./doc/glossary/glossary-terms.xml8982(primary)#: ./doc/glossary/glossary-terms.xml8986(para)","""POT-Creation-Date: 2014-09-23 05:56+0000\n"" ""PO-Revision-Date: 2014-09-22 16:45+0000\n""#: ./doc/glossary/glossary-terms.xml7319(secondary) #: ./doc/glossary/glossary-terms.xml7362(secondary)#: ./doc/glossary/glossary-terms.xml8080(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) #: ./doc/glossary/glossary-terms.xml7346(primary) #: ./doc/glossary/glossary-terms.xml8530(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml8340(para) #: ./doc/glossary/glossary-terms.xml8573(para) #: ./doc/glossary/glossary-terms.xml8803(para) #: ./doc/glossary/glossary-terms.xml8904(para) #: ./doc/glossary/glossary-terms.xml8931(para)#: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml7477(primary) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7679(see)#: ./doc/glossary/glossary-terms.xml7352(para)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8617(para)#: ./doc/glossary/glossary-terms.xml8444(primary) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml7745(primary) #: ./doc/glossary/glossary-terms.xml7945(primary)#: ./doc/glossary/glossary-terms.xml8208(primary)#: ./doc/glossary/glossary-terms.xml8188(see)#: ./doc/glossary/glossary-terms.xml7889(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary) #: ./doc/glossary/glossary-terms.xml7926(primary) #: ./doc/glossary/glossary-terms.xml7950(primary)#: ./doc/glossary/glossary-terms.xml8500(primary)#: ./doc/glossary/glossary-terms.xml7595(primary)#: ./doc/glossary/glossary-terms.xml7597(secondary)#: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7323(para)#: ./doc/glossary/glossary-terms.xml7327(para)#: ./doc/glossary/glossary-terms.xml7333(glossterm) #: ./doc/glossary/glossary-terms.xml7335(primary)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7344(glossterm) #: ./doc/glossary/glossary-terms.xml7348(secondary)#: ./doc/glossary/glossary-terms.xml7358(glossterm)#: ./doc/glossary/glossary-terms.xml7360(primary)#: ./doc/glossary/glossary-terms.xml7366(para)#: ./doc/glossary/glossary-terms.xml7373(glossterm) #: ./doc/glossary/glossary-terms.xml7375(primary)#: ./doc/glossary/glossary-terms.xml7379(para)#: ./doc/glossary/glossary-terms.xml7384(glossterm) #: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7390(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7436(secondary)#: ./doc/glossary/glossary-terms.xml7434(primary) #: ./doc/glossary/glossary-terms.xml7448(primary) #: ./doc/glossary/glossary-terms.xml7463(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7450(secondary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7461(glossterm) #: ./doc/glossary/glossary-terms.xml7465(secondary)#: ./doc/glossary/glossary-terms.xml7469(para)#: ./doc/glossary/glossary-terms.xml7475(glossterm) #: ./doc/glossary/glossary-terms.xml7482(primary)#: ./doc/glossary/glossary-terms.xml7479(secondary)#: ./doc/glossary/glossary-terms.xml7486(para)#: ./doc/glossary/glossary-terms.xml7499(glossterm)#: ./doc/glossary/glossary-terms.xml7501(primary)#: ./doc/glossary/glossary-terms.xml7505(para)#: ./doc/glossary/glossary-terms.xml7514(glossterm) #: ./doc/glossary/glossary-terms.xml7516(primary)#: ./doc/glossary/glossary-terms.xml7520(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7541(primary)#: ./doc/glossary/glossary-terms.xml7545(para)#: ./doc/glossary/glossary-terms.xml7551(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7568(glossterm) #: ./doc/glossary/glossary-terms.xml7570(primary)#: ./doc/glossary/glossary-terms.xml7574(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7593(glossterm) #: ./doc/glossary/glossary-terms.xml7600(primary)#: ./doc/glossary/glossary-terms.xml7604(para)#: ./doc/glossary/glossary-terms.xml7610(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm)#: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7629(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7643(primary)#: ./doc/glossary/glossary-terms.xml7640(secondary)#: ./doc/glossary/glossary-terms.xml7647(para)#: ./doc/glossary/glossary-terms.xml7653(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7664(glossterm) #: ./doc/glossary/glossary-terms.xml7666(primary)#: ./doc/glossary/glossary-terms.xml7670(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7683(para)#: ./doc/glossary/glossary-terms.xml7691(glossterm) #: ./doc/glossary/glossary-terms.xml7693(primary)#: ./doc/glossary/glossary-terms.xml7697(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm)#: ./doc/glossary/glossary-terms.xml7707(secondary)#: ./doc/glossary/glossary-terms.xml7710(primary)#: ./doc/glossary/glossary-terms.xml7714(para)#: ./doc/glossary/glossary-terms.xml7719(glossterm) #: ./doc/glossary/glossary-terms.xml7721(primary)#: ./doc/glossary/glossary-terms.xml7725(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7750(primary)#: ./doc/glossary/glossary-terms.xml7747(secondary)#: ./doc/glossary/glossary-terms.xml7754(para)#: ./doc/glossary/glossary-terms.xml7761(glossterm) #: ./doc/glossary/glossary-terms.xml7765(secondary)#: ./doc/glossary/glossary-terms.xml7763(primary) #: ./doc/glossary/glossary-terms.xml7777(primary) #: ./doc/glossary/glossary-terms.xml7791(primary) #: ./doc/glossary/glossary-terms.xml7940(primary)#: ./doc/glossary/glossary-terms.xml7769(para)#: ./doc/glossary/glossary-terms.xml7775(glossterm) #: ./doc/glossary/glossary-terms.xml7779(secondary)#: ./doc/glossary/glossary-terms.xml7783(para)#: ./doc/glossary/glossary-terms.xml7789(glossterm) #: ./doc/glossary/glossary-terms.xml7793(secondary)#: ./doc/glossary/glossary-terms.xml7797(para)#: ./doc/glossary/glossary-terms.xml7803(glossterm) #: ./doc/glossary/glossary-terms.xml7805(primary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm)#: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7840(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7852(glossterm)#: ./doc/glossary/glossary-terms.xml7854(primary)#: ./doc/glossary/glossary-terms.xml7858(para)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm) #: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7892(para)#: ./doc/glossary/glossary-terms.xml7898(glossterm) #: ./doc/glossary/glossary-terms.xml7900(primary)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7914(secondary)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7928(secondary)#: ./doc/glossary/glossary-terms.xml7932(para)#: ./doc/glossary/glossary-terms.xml7938(glossterm)#: ./doc/glossary/glossary-terms.xml7942(secondary) #: ./doc/glossary/glossary-terms.xml7947(secondary) #: ./doc/glossary/glossary-terms.xml7952(secondary)#: ./doc/glossary/glossary-terms.xml7956(para)#: ./doc/glossary/glossary-terms.xml7962(glossterm) #: ./doc/glossary/glossary-terms.xml7964(primary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary)#: ./doc/glossary/glossary-terms.xml7993(para)#: ./doc/glossary/glossary-terms.xml8003(title)#: ./doc/glossary/glossary-terms.xml8006(glossterm) #: ./doc/glossary/glossary-terms.xml8008(primary)#: ./doc/glossary/glossary-terms.xml8012(para)#: ./doc/glossary/glossary-terms.xml8019(glossterm) #: ./doc/glossary/glossary-terms.xml8021(primary)#: ./doc/glossary/glossary-terms.xml8025(para)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8067(primary) #: ./doc/glossary/glossary-terms.xml8085(primary) #: ./doc/glossary/glossary-terms.xml8099(primary)#: ./doc/glossary/glossary-terms.xml8059(para)#: ./doc/glossary/glossary-terms.xml8065(glossterm) #: ./doc/glossary/glossary-terms.xml8069(secondary)#: ./doc/glossary/glossary-terms.xml8073(para)#: ./doc/glossary/glossary-terms.xml8078(glossterm) #: ./doc/glossary/glossary-terms.xml8082(secondary) #: ./doc/glossary/glossary-terms.xml8087(secondary)#: ./doc/glossary/glossary-terms.xml8091(para)#: ./doc/glossary/glossary-terms.xml8097(glossterm) #: ./doc/glossary/glossary-terms.xml8101(secondary)#: ./doc/glossary/glossary-terms.xml8105(para)#: ./doc/glossary/glossary-terms.xml8111(glossterm)#: ./doc/glossary/glossary-terms.xml8113(primary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8140(para)#: ./doc/glossary/glossary-terms.xml8148(glossterm) #: ./doc/glossary/glossary-terms.xml8150(primary)#: ./doc/glossary/glossary-terms.xml8154(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm)#: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8197(glossterm)#: ./doc/glossary/glossary-terms.xml8200(para)#: ./doc/glossary/glossary-terms.xml8206(glossterm)#: ./doc/glossary/glossary-terms.xml8210(secondary) #: ./doc/glossary/glossary-terms.xml8213(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8227(secondary) #: ./doc/glossary/glossary-terms.xml8230(primary)#: ./doc/glossary/glossary-terms.xml8234(para)#: ./doc/glossary/glossary-terms.xml8239(glossterm) #: ./doc/glossary/glossary-terms.xml8241(primary)#: ./doc/glossary/glossary-terms.xml8245(para)#: ./doc/glossary/glossary-terms.xml8253(glossterm) #: ./doc/glossary/glossary-terms.xml8255(primary)#: ./doc/glossary/glossary-terms.xml8259(para)#: ./doc/glossary/glossary-terms.xml8268(title)#: ./doc/glossary/glossary-terms.xml8271(glossterm) #: ./doc/glossary/glossary-terms.xml8273(primary)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8282(glossterm) #: ./doc/glossary/glossary-terms.xml8284(primary)#: ./doc/glossary/glossary-terms.xml8288(para)#: ./doc/glossary/glossary-terms.xml8293(glossterm)#: ./doc/glossary/glossary-terms.xml8295(primary)#: ./doc/glossary/glossary-terms.xml8299(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8318(glossterm) #: ./doc/glossary/glossary-terms.xml8320(primary)#: ./doc/glossary/glossary-terms.xml8324(para)#: ./doc/glossary/glossary-terms.xml8334(glossterm) #: ./doc/glossary/glossary-terms.xml8336(primary)#: ./doc/glossary/glossary-terms.xml8348(title)#: ./doc/glossary/glossary-terms.xml8351(glossterm) #: ./doc/glossary/glossary-terms.xml8353(primary)#: ./doc/glossary/glossary-terms.xml8357(para)#: ./doc/glossary/glossary-terms.xml8362(glossterm) #: ./doc/glossary/glossary-terms.xml8364(primary)#: ./doc/glossary/glossary-terms.xml8368(para)#: ./doc/glossary/glossary-terms.xml8378(glossterm) #: ./doc/glossary/glossary-terms.xml8381(primary)#: ./doc/glossary/glossary-terms.xml8385(para)#: ./doc/glossary/glossary-terms.xml8391(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8421(para)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8435(para)#: ./doc/glossary/glossary-terms.xml8442(glossterm) #: ./doc/glossary/glossary-terms.xml8449(primary)#: ./doc/glossary/glossary-terms.xml8446(secondary) #: ./doc/glossary/glossary-terms.xml8502(secondary) #: ./doc/glossary/glossary-terms.xml8532(secondary)#: ./doc/glossary/glossary-terms.xml8453(para)#: ./doc/glossary/glossary-terms.xml8458(glossterm) #: ./doc/glossary/glossary-terms.xml8460(primary)#: ./doc/glossary/glossary-terms.xml8464(para)#: ./doc/glossary/glossary-terms.xml8473(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8498(glossterm) #: ./doc/glossary/glossary-terms.xml8505(primary)#: ./doc/glossary/glossary-terms.xml8509(para)#: ./doc/glossary/glossary-terms.xml8515(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8528(glossterm)#: ./doc/glossary/glossary-terms.xml8535(primary)#: ./doc/glossary/glossary-terms.xml8539(para)#: ./doc/glossary/glossary-terms.xml8544(glossterm) #: ./doc/glossary/glossary-terms.xml8546(primary)#: ./doc/glossary/glossary-terms.xml8550(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8567(glossterm) #: ./doc/glossary/glossary-terms.xml8569(primary)#: ./doc/glossary/glossary-terms.xml8578(glossterm) #: ./doc/glossary/glossary-terms.xml8580(primary)#: ./doc/glossary/glossary-terms.xml8584(para)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8597(primary)#: ./doc/glossary/glossary-terms.xml8594(secondary)#: ./doc/glossary/glossary-terms.xml8601(para)#: ./doc/glossary/glossary-terms.xml8611(glossterm) #: ./doc/glossary/glossary-terms.xml8613(primary)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8634(glossterm) #: ./doc/glossary/glossary-terms.xml8636(primary)#: ./doc/glossary/glossary-terms.xml8640(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8657(glossterm)#: ./doc/glossary/glossary-terms.xml8660(para)#: ./doc/glossary/glossary-terms.xml8665(glossterm) #: ./doc/glossary/glossary-terms.xml8667(primary)#: ./doc/glossary/glossary-terms.xml8671(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8689(primary) #: ./doc/glossary/glossary-terms.xml8702(primary) #: ./doc/glossary/glossary-terms.xml8716(primary) #: ./doc/glossary/glossary-terms.xml8729(primary) #: ./doc/glossary/glossary-terms.xml8743(primary) #: ./doc/glossary/glossary-terms.xml8757(primary) #: ./doc/glossary/glossary-terms.xml8771(primary)#: ./doc/glossary/glossary-terms.xml8680(para)#: ./doc/glossary/glossary-terms.xml8687(glossterm) #: ./doc/glossary/glossary-terms.xml8691(secondary)#: ./doc/glossary/glossary-terms.xml8695(para)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8704(secondary)#: ./doc/glossary/glossary-terms.xml8708(para)#: ./doc/glossary/glossary-terms.xml8714(glossterm) #: ./doc/glossary/glossary-terms.xml8718(secondary)#: ./doc/glossary/glossary-terms.xml8722(para)#: ./doc/glossary/glossary-terms.xml8727(glossterm) #: ./doc/glossary/glossary-terms.xml8731(secondary)#: ./doc/glossary/glossary-terms.xml8735(para)#: ./doc/glossary/glossary-terms.xml8741(glossterm) #: ./doc/glossary/glossary-terms.xml8745(secondary)#: ./doc/glossary/glossary-terms.xml8749(para)#: ./doc/glossary/glossary-terms.xml8755(glossterm) #: ./doc/glossary/glossary-terms.xml8759(secondary)#: ./doc/glossary/glossary-terms.xml8763(para)#: ./doc/glossary/glossary-terms.xml8769(glossterm) #: ./doc/glossary/glossary-terms.xml8773(secondary)#: ./doc/glossary/glossary-terms.xml8777(para)#: ./doc/glossary/glossary-terms.xml8783(glossterm)#: ./doc/glossary/glossary-terms.xml8785(primary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8797(glossterm) #: ./doc/glossary/glossary-terms.xml8799(primary)#: ./doc/glossary/glossary-terms.xml8811(title)#: ./doc/glossary/glossary-terms.xml8814(glossterm) #: ./doc/glossary/glossary-terms.xml8816(primary)#: ./doc/glossary/glossary-terms.xml8820(para)#: ./doc/glossary/glossary-terms.xml8827(glossterm) #: ./doc/glossary/glossary-terms.xml8829(primary)#: ./doc/glossary/glossary-terms.xml8833(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm)#: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8868(title)#: ./doc/glossary/glossary-terms.xml8871(glossterm) #: ./doc/glossary/glossary-terms.xml8873(primary)#: ./doc/glossary/glossary-terms.xml8877(para)#: ./doc/glossary/glossary-terms.xml8887(glossterm) #: ./doc/glossary/glossary-terms.xml8898(primary) #: ./doc/glossary/glossary-terms.xml8911(primary) #: ./doc/glossary/glossary-terms.xml8925(primary)#: ./doc/glossary/glossary-terms.xml8890(para)#: ./doc/glossary/glossary-terms.xml8896(glossterm) #: ./doc/glossary/glossary-terms.xml8900(secondary)#: ./doc/glossary/glossary-terms.xml8909(glossterm) #: ./doc/glossary/glossary-terms.xml8913(secondary)#: ./doc/glossary/glossary-terms.xml8917(para)#: ./doc/glossary/glossary-terms.xml8923(glossterm)#: ./doc/glossary/glossary-terms.xml8927(secondary)#: ./doc/glossary/glossary-terms.xml8939(title)#: ./doc/glossary/glossary-terms.xml8953(title)#: ./doc/glossary/glossary-terms.xml8956(glossterm) #: ./doc/glossary/glossary-terms.xml8958(primary)#: ./doc/glossary/glossary-terms.xml8962(para)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)",434,423
openstack%2Fha-guide~master~I6ed83613b2f26b3ac4e428fdbf708c7456275738,openstack/ha-guide,master,I6ed83613b2f26b3ac4e428fdbf708c7456275738,Updated from openstack-manuals,MERGED,2014-10-04 06:57:07.000000000,2014-10-04 07:02:54.000000000,2014-10-04 07:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 06:57:07.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/79706db12d0109fae7f28aca6afca5eef8aa45e0', 'message': 'Updated from openstack-manuals\n\nChange-Id: I6ed83613b2f26b3ac4e428fdbf708c7456275738\n'}]",0,126129,79706db12d0109fae7f28aca6afca5eef8aa45e0,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I6ed83613b2f26b3ac4e428fdbf708c7456275738
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/29/126129/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,79706db12d0109fae7f28aca6afca5eef8aa45e0,openstack/openstack-manuals,"""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:45+0000\n""#: ./doc/glossary/glossary-terms.xml7331(secondary) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml8092(primary)#: ./doc/glossary/glossary-terms.xml7329(primary) #: ./doc/glossary/glossary-terms.xml7358(primary) #: ./doc/glossary/glossary-terms.xml8542(primary)#: ./doc/glossary/glossary-terms.xml7859(para)#: ./doc/glossary/glossary-terms.xml8352(para) #: ./doc/glossary/glossary-terms.xml8585(para) #: ./doc/glossary/glossary-terms.xml8815(para) #: ./doc/glossary/glossary-terms.xml8916(para) #: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8237(primary)#: ./doc/glossary/glossary-terms.xml7489(primary) #: ./doc/glossary/glossary-terms.xml7717(primary)#: ./doc/glossary/glossary-terms.xml7691(see)#: ./doc/glossary/glossary-terms.xml7364(para)#: ./doc/glossary/glossary-terms.xml8421(para) #: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8456(primary) #: ./doc/glossary/glossary-terms.xml8604(primary)#: ./doc/glossary/glossary-terms.xml7757(primary) #: ./doc/glossary/glossary-terms.xml7957(primary)#: ./doc/glossary/glossary-terms.xml8220(primary)#: ./doc/glossary/glossary-terms.xml8200(see)#: ./doc/glossary/glossary-terms.xml7901(glossterm) #: ./doc/glossary/glossary-terms.xml7924(primary) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7962(primary)#: ./doc/glossary/glossary-terms.xml8512(primary)#: ./doc/glossary/glossary-terms.xml7607(primary)#: ./doc/glossary/glossary-terms.xml7609(secondary)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) msgid ""SELinux"" msgstr """" #: ./doc/glossary/glossary-terms.xml7321(para) msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" #: ./doc/glossary/glossary-terms.xml7327(glossterm)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7345(glossterm) #: ./doc/glossary/glossary-terms.xml7347(primary)#: ./doc/glossary/glossary-terms.xml7351(para)#: ./doc/glossary/glossary-terms.xml7356(glossterm) #: ./doc/glossary/glossary-terms.xml7360(secondary)#: ./doc/glossary/glossary-terms.xml7370(glossterm)#: ./doc/glossary/glossary-terms.xml7372(primary)#: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml7385(glossterm) #: ./doc/glossary/glossary-terms.xml7387(primary)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7434(primary)#: ./doc/glossary/glossary-terms.xml7438(para)#: ./doc/glossary/glossary-terms.xml7444(glossterm) #: ./doc/glossary/glossary-terms.xml7448(secondary)#: ./doc/glossary/glossary-terms.xml7446(primary) #: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7477(secondary)#: ./doc/glossary/glossary-terms.xml7481(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7494(primary)#: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7498(para)#: ./doc/glossary/glossary-terms.xml7511(glossterm)#: ./doc/glossary/glossary-terms.xml7513(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7544(para)#: ./doc/glossary/glossary-terms.xml7550(glossterm) #: ./doc/glossary/glossary-terms.xml7553(primary)#: ./doc/glossary/glossary-terms.xml7557(para)#: ./doc/glossary/glossary-terms.xml7563(glossterm) #: ./doc/glossary/glossary-terms.xml7566(primary)#: ./doc/glossary/glossary-terms.xml7570(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7592(glossterm) #: ./doc/glossary/glossary-terms.xml7594(primary)#: ./doc/glossary/glossary-terms.xml7598(para)#: ./doc/glossary/glossary-terms.xml7605(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm) #: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7628(para)#: ./doc/glossary/glossary-terms.xml7634(glossterm)#: ./doc/glossary/glossary-terms.xml7636(primary)#: ./doc/glossary/glossary-terms.xml7641(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7652(secondary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7665(glossterm) #: ./doc/glossary/glossary-terms.xml7667(primary)#: ./doc/glossary/glossary-terms.xml7671(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7682(para)#: ./doc/glossary/glossary-terms.xml7688(glossterm) #: ./doc/glossary/glossary-terms.xml7690(primary)#: ./doc/glossary/glossary-terms.xml7695(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7715(glossterm)#: ./doc/glossary/glossary-terms.xml7719(secondary)#: ./doc/glossary/glossary-terms.xml7722(primary)#: ./doc/glossary/glossary-terms.xml7726(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7745(primary)#: ./doc/glossary/glossary-terms.xml7749(para)#: ./doc/glossary/glossary-terms.xml7755(glossterm) #: ./doc/glossary/glossary-terms.xml7762(primary)#: ./doc/glossary/glossary-terms.xml7759(secondary)#: ./doc/glossary/glossary-terms.xml7766(para)#: ./doc/glossary/glossary-terms.xml7773(glossterm) #: ./doc/glossary/glossary-terms.xml7777(secondary)#: ./doc/glossary/glossary-terms.xml7775(primary) #: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7952(primary)#: ./doc/glossary/glossary-terms.xml7781(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7827(glossterm)#: ./doc/glossary/glossary-terms.xml7829(primary)#: ./doc/glossary/glossary-terms.xml7833(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7855(primary)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm)#: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7888(glossterm) #: ./doc/glossary/glossary-terms.xml7890(primary)#: ./doc/glossary/glossary-terms.xml7894(para)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary)#: ./doc/glossary/glossary-terms.xml7916(para)#: ./doc/glossary/glossary-terms.xml7922(glossterm) #: ./doc/glossary/glossary-terms.xml7926(secondary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm)#: ./doc/glossary/glossary-terms.xml7954(secondary) #: ./doc/glossary/glossary-terms.xml7959(secondary) #: ./doc/glossary/glossary-terms.xml7964(secondary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7986(glossterm) #: ./doc/glossary/glossary-terms.xml7988(primary)#: ./doc/glossary/glossary-terms.xml7992(para)#: ./doc/glossary/glossary-terms.xml7999(glossterm) #: ./doc/glossary/glossary-terms.xml8001(primary)#: ./doc/glossary/glossary-terms.xml8005(para)#: ./doc/glossary/glossary-terms.xml8015(title)#: ./doc/glossary/glossary-terms.xml8018(glossterm) #: ./doc/glossary/glossary-terms.xml8020(primary)#: ./doc/glossary/glossary-terms.xml8024(para)#: ./doc/glossary/glossary-terms.xml8031(glossterm) #: ./doc/glossary/glossary-terms.xml8033(primary)#: ./doc/glossary/glossary-terms.xml8037(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8058(primary)#: ./doc/glossary/glossary-terms.xml8062(para)#: ./doc/glossary/glossary-terms.xml8068(glossterm) #: ./doc/glossary/glossary-terms.xml8079(primary) #: ./doc/glossary/glossary-terms.xml8097(primary) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8071(para)#: ./doc/glossary/glossary-terms.xml8077(glossterm) #: ./doc/glossary/glossary-terms.xml8081(secondary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8090(glossterm) #: ./doc/glossary/glossary-terms.xml8094(secondary) #: ./doc/glossary/glossary-terms.xml8099(secondary)#: ./doc/glossary/glossary-terms.xml8103(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm)#: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8141(para)#: ./doc/glossary/glossary-terms.xml8147(glossterm) #: ./doc/glossary/glossary-terms.xml8149(primary)#: ./doc/glossary/glossary-terms.xml8152(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm) #: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8190(para)#: ./doc/glossary/glossary-terms.xml8196(glossterm)#: ./doc/glossary/glossary-terms.xml8198(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8209(glossterm)#: ./doc/glossary/glossary-terms.xml8212(para)#: ./doc/glossary/glossary-terms.xml8218(glossterm)#: ./doc/glossary/glossary-terms.xml8222(secondary) #: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml8229(para)#: ./doc/glossary/glossary-terms.xml8235(glossterm)#: ./doc/glossary/glossary-terms.xml8239(secondary) #: ./doc/glossary/glossary-terms.xml8242(primary)#: ./doc/glossary/glossary-terms.xml8246(para)#: ./doc/glossary/glossary-terms.xml8251(glossterm) #: ./doc/glossary/glossary-terms.xml8253(primary)#: ./doc/glossary/glossary-terms.xml8257(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8280(title)#: ./doc/glossary/glossary-terms.xml8283(glossterm) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml8289(para)#: ./doc/glossary/glossary-terms.xml8294(glossterm) #: ./doc/glossary/glossary-terms.xml8296(primary)#: ./doc/glossary/glossary-terms.xml8300(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8317(glossterm)#: ./doc/glossary/glossary-terms.xml8319(primary)#: ./doc/glossary/glossary-terms.xml8323(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8346(glossterm) #: ./doc/glossary/glossary-terms.xml8348(primary)#: ./doc/glossary/glossary-terms.xml8360(title)#: ./doc/glossary/glossary-terms.xml8363(glossterm) #: ./doc/glossary/glossary-terms.xml8365(primary)#: ./doc/glossary/glossary-terms.xml8369(para)#: ./doc/glossary/glossary-terms.xml8374(glossterm) #: ./doc/glossary/glossary-terms.xml8376(primary)#: ./doc/glossary/glossary-terms.xml8380(para)#: ./doc/glossary/glossary-terms.xml8390(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8427(glossterm) #: ./doc/glossary/glossary-terms.xml8429(primary)#: ./doc/glossary/glossary-terms.xml8433(para)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8454(glossterm) #: ./doc/glossary/glossary-terms.xml8461(primary)#: ./doc/glossary/glossary-terms.xml8458(secondary) #: ./doc/glossary/glossary-terms.xml8514(secondary) #: ./doc/glossary/glossary-terms.xml8544(secondary)#: ./doc/glossary/glossary-terms.xml8465(para)#: ./doc/glossary/glossary-terms.xml8470(glossterm) #: ./doc/glossary/glossary-terms.xml8472(primary)#: ./doc/glossary/glossary-terms.xml8476(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8497(glossterm) #: ./doc/glossary/glossary-terms.xml8499(primary)#: ./doc/glossary/glossary-terms.xml8503(para)#: ./doc/glossary/glossary-terms.xml8510(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8527(glossterm) #: ./doc/glossary/glossary-terms.xml8529(primary)#: ./doc/glossary/glossary-terms.xml8533(para)#: ./doc/glossary/glossary-terms.xml8540(glossterm)#: ./doc/glossary/glossary-terms.xml8547(primary)#: ./doc/glossary/glossary-terms.xml8551(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8568(glossterm) #: ./doc/glossary/glossary-terms.xml8570(primary)#: ./doc/glossary/glossary-terms.xml8574(para)#: ./doc/glossary/glossary-terms.xml8579(glossterm) #: ./doc/glossary/glossary-terms.xml8581(primary)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml8596(para)#: ./doc/glossary/glossary-terms.xml8602(glossterm) #: ./doc/glossary/glossary-terms.xml8609(primary)#: ./doc/glossary/glossary-terms.xml8606(secondary)#: ./doc/glossary/glossary-terms.xml8613(para)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8635(glossterm) #: ./doc/glossary/glossary-terms.xml8637(primary)#: ./doc/glossary/glossary-terms.xml8641(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8658(glossterm) #: ./doc/glossary/glossary-terms.xml8660(primary)#: ./doc/glossary/glossary-terms.xml8664(para)#: ./doc/glossary/glossary-terms.xml8669(glossterm)#: ./doc/glossary/glossary-terms.xml8672(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8679(primary)#: ./doc/glossary/glossary-terms.xml8683(para)#: ./doc/glossary/glossary-terms.xml8689(glossterm) #: ./doc/glossary/glossary-terms.xml8701(primary) #: ./doc/glossary/glossary-terms.xml8714(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8741(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary)#: ./doc/glossary/glossary-terms.xml8692(para)#: ./doc/glossary/glossary-terms.xml8699(glossterm) #: ./doc/glossary/glossary-terms.xml8703(secondary)#: ./doc/glossary/glossary-terms.xml8707(para)#: ./doc/glossary/glossary-terms.xml8712(glossterm) #: ./doc/glossary/glossary-terms.xml8716(secondary)#: ./doc/glossary/glossary-terms.xml8720(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8739(glossterm) #: ./doc/glossary/glossary-terms.xml8743(secondary)#: ./doc/glossary/glossary-terms.xml8747(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm)#: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8801(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm) #: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8823(title)#: ./doc/glossary/glossary-terms.xml8826(glossterm) #: ./doc/glossary/glossary-terms.xml8828(primary)#: ./doc/glossary/glossary-terms.xml8832(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm) #: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8863(glossterm)#: ./doc/glossary/glossary-terms.xml8865(primary)#: ./doc/glossary/glossary-terms.xml8869(para)#: ./doc/glossary/glossary-terms.xml8880(title)#: ./doc/glossary/glossary-terms.xml8883(glossterm) #: ./doc/glossary/glossary-terms.xml8885(primary)#: ./doc/glossary/glossary-terms.xml8889(para)#: ./doc/glossary/glossary-terms.xml8899(glossterm) #: ./doc/glossary/glossary-terms.xml8910(primary) #: ./doc/glossary/glossary-terms.xml8923(primary) #: ./doc/glossary/glossary-terms.xml8937(primary)#: ./doc/glossary/glossary-terms.xml8902(para)#: ./doc/glossary/glossary-terms.xml8908(glossterm) #: ./doc/glossary/glossary-terms.xml8912(secondary)#: ./doc/glossary/glossary-terms.xml8921(glossterm) #: ./doc/glossary/glossary-terms.xml8925(secondary)#: ./doc/glossary/glossary-terms.xml8929(para)#: ./doc/glossary/glossary-terms.xml8935(glossterm)#: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8951(title)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)#: ./doc/glossary/glossary-terms.xml8980(glossterm) #: ./doc/glossary/glossary-terms.xml8982(primary)#: ./doc/glossary/glossary-terms.xml8986(para)","""POT-Creation-Date: 2014-09-23 05:56+0000\n"" ""PO-Revision-Date: 2014-09-22 16:45+0000\n""#: ./doc/glossary/glossary-terms.xml7319(secondary) #: ./doc/glossary/glossary-terms.xml7362(secondary)#: ./doc/glossary/glossary-terms.xml8080(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) #: ./doc/glossary/glossary-terms.xml7346(primary) #: ./doc/glossary/glossary-terms.xml8530(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml8340(para) #: ./doc/glossary/glossary-terms.xml8573(para) #: ./doc/glossary/glossary-terms.xml8803(para) #: ./doc/glossary/glossary-terms.xml8904(para) #: ./doc/glossary/glossary-terms.xml8931(para)#: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml7477(primary) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7679(see)#: ./doc/glossary/glossary-terms.xml7352(para)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8617(para)#: ./doc/glossary/glossary-terms.xml8444(primary) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml7745(primary) #: ./doc/glossary/glossary-terms.xml7945(primary)#: ./doc/glossary/glossary-terms.xml8208(primary)#: ./doc/glossary/glossary-terms.xml8188(see)#: ./doc/glossary/glossary-terms.xml7889(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary) #: ./doc/glossary/glossary-terms.xml7926(primary) #: ./doc/glossary/glossary-terms.xml7950(primary)#: ./doc/glossary/glossary-terms.xml8500(primary)#: ./doc/glossary/glossary-terms.xml7595(primary)#: ./doc/glossary/glossary-terms.xml7597(secondary)#: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7323(para)#: ./doc/glossary/glossary-terms.xml7327(para)#: ./doc/glossary/glossary-terms.xml7333(glossterm) #: ./doc/glossary/glossary-terms.xml7335(primary)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7344(glossterm) #: ./doc/glossary/glossary-terms.xml7348(secondary)#: ./doc/glossary/glossary-terms.xml7358(glossterm)#: ./doc/glossary/glossary-terms.xml7360(primary)#: ./doc/glossary/glossary-terms.xml7366(para)#: ./doc/glossary/glossary-terms.xml7373(glossterm) #: ./doc/glossary/glossary-terms.xml7375(primary)#: ./doc/glossary/glossary-terms.xml7379(para)#: ./doc/glossary/glossary-terms.xml7384(glossterm) #: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7390(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7436(secondary)#: ./doc/glossary/glossary-terms.xml7434(primary) #: ./doc/glossary/glossary-terms.xml7448(primary) #: ./doc/glossary/glossary-terms.xml7463(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7450(secondary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7461(glossterm) #: ./doc/glossary/glossary-terms.xml7465(secondary)#: ./doc/glossary/glossary-terms.xml7469(para)#: ./doc/glossary/glossary-terms.xml7475(glossterm) #: ./doc/glossary/glossary-terms.xml7482(primary)#: ./doc/glossary/glossary-terms.xml7479(secondary)#: ./doc/glossary/glossary-terms.xml7486(para)#: ./doc/glossary/glossary-terms.xml7499(glossterm)#: ./doc/glossary/glossary-terms.xml7501(primary)#: ./doc/glossary/glossary-terms.xml7505(para)#: ./doc/glossary/glossary-terms.xml7514(glossterm) #: ./doc/glossary/glossary-terms.xml7516(primary)#: ./doc/glossary/glossary-terms.xml7520(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7541(primary)#: ./doc/glossary/glossary-terms.xml7545(para)#: ./doc/glossary/glossary-terms.xml7551(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7568(glossterm) #: ./doc/glossary/glossary-terms.xml7570(primary)#: ./doc/glossary/glossary-terms.xml7574(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7593(glossterm) #: ./doc/glossary/glossary-terms.xml7600(primary)#: ./doc/glossary/glossary-terms.xml7604(para)#: ./doc/glossary/glossary-terms.xml7610(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm)#: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7629(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7643(primary)#: ./doc/glossary/glossary-terms.xml7640(secondary)#: ./doc/glossary/glossary-terms.xml7647(para)#: ./doc/glossary/glossary-terms.xml7653(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7664(glossterm) #: ./doc/glossary/glossary-terms.xml7666(primary)#: ./doc/glossary/glossary-terms.xml7670(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7683(para)#: ./doc/glossary/glossary-terms.xml7691(glossterm) #: ./doc/glossary/glossary-terms.xml7693(primary)#: ./doc/glossary/glossary-terms.xml7697(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm)#: ./doc/glossary/glossary-terms.xml7707(secondary)#: ./doc/glossary/glossary-terms.xml7710(primary)#: ./doc/glossary/glossary-terms.xml7714(para)#: ./doc/glossary/glossary-terms.xml7719(glossterm) #: ./doc/glossary/glossary-terms.xml7721(primary)#: ./doc/glossary/glossary-terms.xml7725(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7750(primary)#: ./doc/glossary/glossary-terms.xml7747(secondary)#: ./doc/glossary/glossary-terms.xml7754(para)#: ./doc/glossary/glossary-terms.xml7761(glossterm) #: ./doc/glossary/glossary-terms.xml7765(secondary)#: ./doc/glossary/glossary-terms.xml7763(primary) #: ./doc/glossary/glossary-terms.xml7777(primary) #: ./doc/glossary/glossary-terms.xml7791(primary) #: ./doc/glossary/glossary-terms.xml7940(primary)#: ./doc/glossary/glossary-terms.xml7769(para)#: ./doc/glossary/glossary-terms.xml7775(glossterm) #: ./doc/glossary/glossary-terms.xml7779(secondary)#: ./doc/glossary/glossary-terms.xml7783(para)#: ./doc/glossary/glossary-terms.xml7789(glossterm) #: ./doc/glossary/glossary-terms.xml7793(secondary)#: ./doc/glossary/glossary-terms.xml7797(para)#: ./doc/glossary/glossary-terms.xml7803(glossterm) #: ./doc/glossary/glossary-terms.xml7805(primary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm)#: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7840(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7852(glossterm)#: ./doc/glossary/glossary-terms.xml7854(primary)#: ./doc/glossary/glossary-terms.xml7858(para)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm) #: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7892(para)#: ./doc/glossary/glossary-terms.xml7898(glossterm) #: ./doc/glossary/glossary-terms.xml7900(primary)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7914(secondary)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7928(secondary)#: ./doc/glossary/glossary-terms.xml7932(para)#: ./doc/glossary/glossary-terms.xml7938(glossterm)#: ./doc/glossary/glossary-terms.xml7942(secondary) #: ./doc/glossary/glossary-terms.xml7947(secondary) #: ./doc/glossary/glossary-terms.xml7952(secondary)#: ./doc/glossary/glossary-terms.xml7956(para)#: ./doc/glossary/glossary-terms.xml7962(glossterm) #: ./doc/glossary/glossary-terms.xml7964(primary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary)#: ./doc/glossary/glossary-terms.xml7993(para)#: ./doc/glossary/glossary-terms.xml8003(title)#: ./doc/glossary/glossary-terms.xml8006(glossterm) #: ./doc/glossary/glossary-terms.xml8008(primary)#: ./doc/glossary/glossary-terms.xml8012(para)#: ./doc/glossary/glossary-terms.xml8019(glossterm) #: ./doc/glossary/glossary-terms.xml8021(primary)#: ./doc/glossary/glossary-terms.xml8025(para)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8067(primary) #: ./doc/glossary/glossary-terms.xml8085(primary) #: ./doc/glossary/glossary-terms.xml8099(primary)#: ./doc/glossary/glossary-terms.xml8059(para)#: ./doc/glossary/glossary-terms.xml8065(glossterm) #: ./doc/glossary/glossary-terms.xml8069(secondary)#: ./doc/glossary/glossary-terms.xml8073(para)#: ./doc/glossary/glossary-terms.xml8078(glossterm) #: ./doc/glossary/glossary-terms.xml8082(secondary) #: ./doc/glossary/glossary-terms.xml8087(secondary)#: ./doc/glossary/glossary-terms.xml8091(para)#: ./doc/glossary/glossary-terms.xml8097(glossterm) #: ./doc/glossary/glossary-terms.xml8101(secondary)#: ./doc/glossary/glossary-terms.xml8105(para)#: ./doc/glossary/glossary-terms.xml8111(glossterm)#: ./doc/glossary/glossary-terms.xml8113(primary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8140(para)#: ./doc/glossary/glossary-terms.xml8148(glossterm) #: ./doc/glossary/glossary-terms.xml8150(primary)#: ./doc/glossary/glossary-terms.xml8154(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm)#: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8197(glossterm)#: ./doc/glossary/glossary-terms.xml8200(para)#: ./doc/glossary/glossary-terms.xml8206(glossterm)#: ./doc/glossary/glossary-terms.xml8210(secondary) #: ./doc/glossary/glossary-terms.xml8213(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8227(secondary) #: ./doc/glossary/glossary-terms.xml8230(primary)#: ./doc/glossary/glossary-terms.xml8234(para)#: ./doc/glossary/glossary-terms.xml8239(glossterm) #: ./doc/glossary/glossary-terms.xml8241(primary)#: ./doc/glossary/glossary-terms.xml8245(para)#: ./doc/glossary/glossary-terms.xml8253(glossterm) #: ./doc/glossary/glossary-terms.xml8255(primary)#: ./doc/glossary/glossary-terms.xml8259(para)#: ./doc/glossary/glossary-terms.xml8268(title)#: ./doc/glossary/glossary-terms.xml8271(glossterm) #: ./doc/glossary/glossary-terms.xml8273(primary)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8282(glossterm) #: ./doc/glossary/glossary-terms.xml8284(primary)#: ./doc/glossary/glossary-terms.xml8288(para)#: ./doc/glossary/glossary-terms.xml8293(glossterm)#: ./doc/glossary/glossary-terms.xml8295(primary)#: ./doc/glossary/glossary-terms.xml8299(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8318(glossterm) #: ./doc/glossary/glossary-terms.xml8320(primary)#: ./doc/glossary/glossary-terms.xml8324(para)#: ./doc/glossary/glossary-terms.xml8334(glossterm) #: ./doc/glossary/glossary-terms.xml8336(primary)#: ./doc/glossary/glossary-terms.xml8348(title)#: ./doc/glossary/glossary-terms.xml8351(glossterm) #: ./doc/glossary/glossary-terms.xml8353(primary)#: ./doc/glossary/glossary-terms.xml8357(para)#: ./doc/glossary/glossary-terms.xml8362(glossterm) #: ./doc/glossary/glossary-terms.xml8364(primary)#: ./doc/glossary/glossary-terms.xml8368(para)#: ./doc/glossary/glossary-terms.xml8378(glossterm) #: ./doc/glossary/glossary-terms.xml8381(primary)#: ./doc/glossary/glossary-terms.xml8385(para)#: ./doc/glossary/glossary-terms.xml8391(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8421(para)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8435(para)#: ./doc/glossary/glossary-terms.xml8442(glossterm) #: ./doc/glossary/glossary-terms.xml8449(primary)#: ./doc/glossary/glossary-terms.xml8446(secondary) #: ./doc/glossary/glossary-terms.xml8502(secondary) #: ./doc/glossary/glossary-terms.xml8532(secondary)#: ./doc/glossary/glossary-terms.xml8453(para)#: ./doc/glossary/glossary-terms.xml8458(glossterm) #: ./doc/glossary/glossary-terms.xml8460(primary)#: ./doc/glossary/glossary-terms.xml8464(para)#: ./doc/glossary/glossary-terms.xml8473(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8498(glossterm) #: ./doc/glossary/glossary-terms.xml8505(primary)#: ./doc/glossary/glossary-terms.xml8509(para)#: ./doc/glossary/glossary-terms.xml8515(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8528(glossterm)#: ./doc/glossary/glossary-terms.xml8535(primary)#: ./doc/glossary/glossary-terms.xml8539(para)#: ./doc/glossary/glossary-terms.xml8544(glossterm) #: ./doc/glossary/glossary-terms.xml8546(primary)#: ./doc/glossary/glossary-terms.xml8550(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8567(glossterm) #: ./doc/glossary/glossary-terms.xml8569(primary)#: ./doc/glossary/glossary-terms.xml8578(glossterm) #: ./doc/glossary/glossary-terms.xml8580(primary)#: ./doc/glossary/glossary-terms.xml8584(para)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8597(primary)#: ./doc/glossary/glossary-terms.xml8594(secondary)#: ./doc/glossary/glossary-terms.xml8601(para)#: ./doc/glossary/glossary-terms.xml8611(glossterm) #: ./doc/glossary/glossary-terms.xml8613(primary)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8634(glossterm) #: ./doc/glossary/glossary-terms.xml8636(primary)#: ./doc/glossary/glossary-terms.xml8640(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8657(glossterm)#: ./doc/glossary/glossary-terms.xml8660(para)#: ./doc/glossary/glossary-terms.xml8665(glossterm) #: ./doc/glossary/glossary-terms.xml8667(primary)#: ./doc/glossary/glossary-terms.xml8671(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8689(primary) #: ./doc/glossary/glossary-terms.xml8702(primary) #: ./doc/glossary/glossary-terms.xml8716(primary) #: ./doc/glossary/glossary-terms.xml8729(primary) #: ./doc/glossary/glossary-terms.xml8743(primary) #: ./doc/glossary/glossary-terms.xml8757(primary) #: ./doc/glossary/glossary-terms.xml8771(primary)#: ./doc/glossary/glossary-terms.xml8680(para)#: ./doc/glossary/glossary-terms.xml8687(glossterm) #: ./doc/glossary/glossary-terms.xml8691(secondary)#: ./doc/glossary/glossary-terms.xml8695(para)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8704(secondary)#: ./doc/glossary/glossary-terms.xml8708(para)#: ./doc/glossary/glossary-terms.xml8714(glossterm) #: ./doc/glossary/glossary-terms.xml8718(secondary)#: ./doc/glossary/glossary-terms.xml8722(para)#: ./doc/glossary/glossary-terms.xml8727(glossterm) #: ./doc/glossary/glossary-terms.xml8731(secondary)#: ./doc/glossary/glossary-terms.xml8735(para)#: ./doc/glossary/glossary-terms.xml8741(glossterm) #: ./doc/glossary/glossary-terms.xml8745(secondary)#: ./doc/glossary/glossary-terms.xml8749(para)#: ./doc/glossary/glossary-terms.xml8755(glossterm) #: ./doc/glossary/glossary-terms.xml8759(secondary)#: ./doc/glossary/glossary-terms.xml8763(para)#: ./doc/glossary/glossary-terms.xml8769(glossterm) #: ./doc/glossary/glossary-terms.xml8773(secondary)#: ./doc/glossary/glossary-terms.xml8777(para)#: ./doc/glossary/glossary-terms.xml8783(glossterm)#: ./doc/glossary/glossary-terms.xml8785(primary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8797(glossterm) #: ./doc/glossary/glossary-terms.xml8799(primary)#: ./doc/glossary/glossary-terms.xml8811(title)#: ./doc/glossary/glossary-terms.xml8814(glossterm) #: ./doc/glossary/glossary-terms.xml8816(primary)#: ./doc/glossary/glossary-terms.xml8820(para)#: ./doc/glossary/glossary-terms.xml8827(glossterm) #: ./doc/glossary/glossary-terms.xml8829(primary)#: ./doc/glossary/glossary-terms.xml8833(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm)#: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8868(title)#: ./doc/glossary/glossary-terms.xml8871(glossterm) #: ./doc/glossary/glossary-terms.xml8873(primary)#: ./doc/glossary/glossary-terms.xml8877(para)#: ./doc/glossary/glossary-terms.xml8887(glossterm) #: ./doc/glossary/glossary-terms.xml8898(primary) #: ./doc/glossary/glossary-terms.xml8911(primary) #: ./doc/glossary/glossary-terms.xml8925(primary)#: ./doc/glossary/glossary-terms.xml8890(para)#: ./doc/glossary/glossary-terms.xml8896(glossterm) #: ./doc/glossary/glossary-terms.xml8900(secondary)#: ./doc/glossary/glossary-terms.xml8909(glossterm) #: ./doc/glossary/glossary-terms.xml8913(secondary)#: ./doc/glossary/glossary-terms.xml8917(para)#: ./doc/glossary/glossary-terms.xml8923(glossterm)#: ./doc/glossary/glossary-terms.xml8927(secondary)#: ./doc/glossary/glossary-terms.xml8939(title)#: ./doc/glossary/glossary-terms.xml8953(title)#: ./doc/glossary/glossary-terms.xml8956(glossterm) #: ./doc/glossary/glossary-terms.xml8958(primary)#: ./doc/glossary/glossary-terms.xml8962(para)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)",434,423
openstack%2Fsecurity-doc~master~Ie78bc78cab15c600a6537bac02a61cbcc3d589a1,openstack/security-doc,master,Ie78bc78cab15c600a6537bac02a61cbcc3d589a1,Imported Translations from Transifex,MERGED,2014-10-04 06:01:29.000000000,2014-10-04 06:57:18.000000000,2014-10-04 06:57:18.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 06:01:29.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/402d3736717e98ddec5e62749f5d9d8fb68f82c6', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ie78bc78cab15c600a6537bac02a61cbcc3d589a1\n'}]",0,126117,402d3736717e98ddec5e62749f5d9d8fb68f82c6,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ie78bc78cab15c600a6537bac02a61cbcc3d589a1
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/17/126117/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,402d3736717e98ddec5e62749f5d9d8fb68f82c6,transifex/translations,"""POT-Creation-Date: 2014-10-03 18:54+0000\n"" ""PO-Revision-Date: 2014-10-04 04:44+0000\n""#: ./security-guide/section_identity-federated-keystone.xml459(title)#: ./security-guide/section_identity-federated-keystone.xml8(title) msgid ""Federated Identity"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml9(para) msgid """" ""Federated Identity is a mechanism to establish trusts between Identity "" ""Providers and Service Providers (SP), in this case, between Identity "" ""Providers and the services provided by an OpenStack Cloud."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml12(para) msgid """" ""Federated Identity provides a way to securely use existing credentials to "" ""access cloud resources such as servers, volumes, and databases, across "" ""multiple endpoints provided in multiple authorized clouds using a single set"" "" of credentials, without having to provision additional identities or log in"" "" multiple times. The credential is maintained by the user's Identity "" ""Provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml18(para) msgid ""Some important definitions:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml21(term) msgid ""Service Provider (SP)"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml22(para) msgid """" ""A system entity that provides services to principals or other system "" ""entities, in this case, OpenStack Identity is the Service Provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml27(term) msgid ""Identity Provider (IdP)"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml28(para) msgid """" ""A directory service, such as LDAP, RADIUS and Active Directory, which allows"" "" users to login with a user name and password, is a typical source of "" ""authentication tokens (e.g. passwords) at an identity provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml34(term) msgid ""SAML assertion"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml35(para) msgid """" ""Contains information about a user as provided by an IdP. It is an indication"" "" that a user has been authenticated."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml40(term) msgid ""Mapping"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml41(para) msgid """" ""Adds a set of rules to map Federation protocol attributes to Identity API "" ""objects. An Identity Provider has exactly one mapping specified per "" ""protocol."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml46(term) msgid ""Protocol"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml47(para) msgid """" ""Contains information that dictates which Mapping rules to use for an "" ""incoming request made by an IdP. An IdP may support multiple protocols. "" ""There are three major protocols for federated identity: OpenID, SAML, and "" ""OAuth."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml53(term) msgid ""Unscoped token"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml54(para) msgid """" ""Allows a user to authenticate with the Identity service to exchange the "" ""unscoped token for a scoped token, by providing a project ID or a domain ID."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml59(term) msgid ""Scoped token"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml60(para) msgid """" ""Allows a user to use all OpenStack services apart from the Identity service."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml65(title) msgid ""Why use Federated Identity?"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml67(para) msgid """" ""Provisioning new identities often incurs some security risk. It is difficult"" "" to secure credential storage and to deploy it with proper policies. A "" ""common identity store is useful as it can be set up properly once and used "" ""in multiple places. With Federated Identity, there is no longer a need to "" ""provision user entries in Identity service, since the user entries already "" ""exist in the IdP's databases."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml73(para) msgid """" ""This does introduce new challenges around protecting that identity. However,"" "" this is a worthwhile tradeoff given the greater control, and fewer "" ""credential databases that come with a centralized common identity store."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml78(para) msgid """" ""It is a burden on the clients to deal with multiple tokens across multiple "" ""cloud service providers. Federated Identity provides single sign on to the "" ""user, who can use the credentials provided and maintained by the user's IdP "" ""to access many different services on the Internet."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml83(para) msgid """" ""Users spend too much time logging in or going through 'Forget Password' "" ""workflows. Federated identity allows for single sign on, which is easier and"" "" faster for users and requires fewer password resets. The IdPs manage user "" ""identities and passwords so OpenStack does not have to."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml88(para) msgid """" ""Too much time is spent administering identities in various service "" ""providers."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml90(para) msgid """" ""The best test of interoperability in the cloud is the ability to enable a "" ""user with one set of credentials in an IdP to access multiple cloud "" ""services. Organizations, each using its own IdP can easily allow their users"" "" to collaborate and quickly share the same cloud services."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml95(para) msgid """" ""Removes a blocker to cloud brokering and multi-cloud workload management. "" ""There is no need to build additional authentication mechanisms ito "" ""authenticate users, since the IdPs take care of authenticating their own "" ""users using whichever technologies they deem to be appropriate. In most "" ""organizations, multiple authentication technologies are already in use."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml103(title) msgid ""Configuring Identity service for Federation"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml104(para) msgid """" ""Federated users are not mirrored in the Identity service back end (for "" ""example, using the SQL driver). The external IdP is responsible for "" ""authenticating users, and communicates the result of the authentication to "" ""Identity service using SAML assertions. Identity service maps the SAML "" ""assertions to Keystone user groups and assignments created in Identity "" ""service."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml111(title) msgid ""Enabling Federation"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml112(para) msgid ""To enable Federation, perform the following steps:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml114(para) msgid """" ""Run the Identity service under Apache, instead of using <placeholder-1/>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml117(para) msgid """" ""Enable SSL support. Install <literal>mod_nss</literal> according to your "" ""distribution, then apply the following patch and restart HTTPD:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml142(para) msgid """" ""If you have a firewall in place, configure it to allow SSL traffic. For "" ""example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml145(para) msgid """" ""Note this needs to be added before your reject all rule which might be:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml148(para) msgid """" ""Copy the <filename>httpd/wsgi-keystone.conf</filename> file to the "" ""appropriate location for your Apache server, for example, "" ""<filename>/etc/httpd/conf.d/wsgi-keystone.conf </filename> file."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml153(para) msgid """" ""Create the directory <literal>/var/www/cgi-bin/keystone/</literal>. Then "" ""link the files <literal>main</literal> and <literal>admin</literal> to the "" ""<filename>keystone.py</filename> file in this directory."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml156(para) msgid """" ""For a distribution appropriate place, it should probably be copied to "" ""<literal>/usr/share/openstack/keystone/httpd/keystone.py</literal>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml158(para) msgid """" ""This path is Ubuntu-specific. For other distributions, replace with "" ""appropriate path."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml161(para) msgid """" ""If you are running with SELinux enabled ensure that the file has the "" ""appropriate SELinux context to access the linked file. For example, if you "" ""have the file in <literal>/var/www/cgi-bin</literal> location, you can do "" ""this by running:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml167(para) msgid """" ""Adding it in a different location requires you set up your SELinux policy "" ""accordingly."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml170(para) msgid """" ""Make sure you use either the SQL or the <literal>memcached</literal> driver "" ""for tokens, otherwise the tokens will not be shared between the processes of"" "" the Apache HTTPD server."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml173(para) msgid ""For SQL, in <filename>/etc/keystone/keystone.conf</filename> , set:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml177(para) msgid """" ""For <literal>memcached</literal>, in "" ""<filename>/etc/keystone/keystone.conf</filename>, set:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml181(para) msgid """" ""In both cases, all servers that are storing tokens need a shared back end. "" ""This means either that both point to the same database server, or both point"" "" to a common memcached instance."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml186(para) msgid ""Install Shibboleth:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml188(para) msgid """" ""The <literal>apt-get</literal> command is Ubuntu specific. For other "" ""distributions, replace with appropriate command."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml191(para) msgid """" ""Configure the Identity service virtual host and adjust the config to "" ""properly handle SAML2 workflow."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml193(para) msgid """" ""Add <literal>WSGIScriptAlias</literal> directive to your vhost "" ""configuration:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml196(para) msgid """" ""Add two <literal>&lt;Location&gt;</literal> directives to the <filename"" "">wsgi-keystone.conf</filename> file:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml210(para) msgid """" ""The option <literal>saml2</literal> may be different in your deployment, but"" "" do not use a wildcard value. Otherwise every Federated protocol will be "" ""handled by Shibboleth."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml213(para) msgid """" ""The <literal>ShibRequireSession</literal> rule is invalid in Apache 2.4 or "" ""newer and should be dropped in that specific setup."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml216(para) msgid ""Enable the Identity service virtual host:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml219(para) msgid """" ""Enable the <literal>ssl</literal> and <literal>shib2</literal> modules:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml224(para) msgid ""Restart Apache:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml226(para) msgid """" ""The <literal>service apache2 restart</literal> command is Ubuntu-specific. "" ""For other distributions, replace with appropriate command."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml232(para) msgid ""Configure Apache to use a Federation capable authentication method."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml235(para) msgid """" ""Once you have your Identity service virtual host ready, configure Shibboleth"" "" and upload your metadata to the Identity Provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml237(para) msgid """" ""If new certificates are required, they can be easily created by executing:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml238(replaceable) msgid ""NUMBER_OF_YEARS"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml239(para) msgid """" ""The newly created file will be stored under <filename>/etc/shibboleth/sp-"" ""key.pem</filename>"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml242(para) msgid """" ""Upload your Service Providers metadata file to your Identity Provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml245(para) msgid """" ""Configure your Service Provider by editing "" ""<filename>/etc/shibboleth/shibboleth2.xml</filename>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml247(para) msgid """" ""For more information, see <link "" ""href=\""https://wiki.shibboleth.net/confluence/display/SHIB2/Configuration\""><citetitle>Shibboleth"" "" Service Provider Configuration</citetitle></link>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml250(para) msgid """" ""Identity service enforces <literal>external</literal> authentication when "" ""environment variable <literal>REMOTE_USER</literal> is present so make sure "" ""Shibboleth does not set the <literal>REMOTE_USER</literal> environment "" ""variable. To do so, scan through the "" ""<filename>/etc/shibboleth/shibboleth2.xml</filename> configuration file and "" ""remove the <literal>REMOTE_USER</literal> directives."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml258(para) msgid """" ""Examine your attributes map in the <filename>/etc/shibboleth/attributes-"" ""map.xml</filename> file and adjust your requirements if needed. For more "" ""information see <link "" ""href=\""https://wiki.shibboleth.net/confluence/display/SHIB2/NativeSPAddAttribute\""><citetitle>Shibboleth"" "" Attributes</citetitle></link>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml264(para) msgid ""Restart the Shibboleth daemon:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml270(para) msgid ""Enable <literal>OS-FEDERATION</literal> extension:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml272(para) msgid """" ""Add the Federation extension driver to the <literal>[federation]</literal> "" ""section in the <filename>keystone.conf</filename> file. For example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml278(para) msgid """" ""Add the saml2 authentication method to the <literal>[auth]</literal> section"" "" in <filename>keystone.conf</filename> file:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml284(para) msgid """" ""The <literal>external</literal> method should be dropped to avoid any "" ""interference with some Apache and Shibboleth SP setups, where a "" ""<literal>REMOTE_USER</literal> environment variable is always set, even as "" ""an empty value."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml289(para) msgid """" ""Add the <literal>federation_extension</literal> middleware to the "" ""<literal>api_v3</literal> pipeline in the <filename>keystone-"" ""paste.ini</filename> file. For example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml297(para) msgid """" ""Create the Federation extension tables if using the provided SQL back end. "" ""For example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml303(para) msgid """" ""Ideally, to test that the Identity Provider and the Identity service are "" ""communicating, navigate to the protected URL and attempt to sign in. If you "" ""get a response back from <literal>keystone</literal>, even if it is a wrong "" ""response, indicates the communication."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml309(title) msgid ""Configuring Federation"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml310(para) msgid """" ""Now that the Identity Provider and Identity service are communicating, you "" ""can start to configure the <literal>OS-FEDERATION</literal> extension."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml313(para) msgid ""Create Identity groups and assign roles."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml314(para) msgid """" ""No new users will be added to the Identity back end, but the Identity "" ""service requires group-based role assignments to authorize federated users. "" ""The Federation mapping function will map the user into local Identity "" ""service groups objects, and hence to local role assignments."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml319(para) msgid """" ""Thus, it is required to create the necessary Identity service groups that "" ""correspond to the Identity Providers groups; additionally, these groups "" ""should be assigned roles on one or more projects or domains. For example, "" ""groups here refers to the Identity service groups that should be created so "" ""that when mapping from the SAML attribute <literal>Employees</literal>, you "" ""can map it to a Identity service group <literal>devs</literal>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml326(para) msgid """" ""The Identity service administator can create as many groups as there are "" ""SAML attributes, whatever the mapping calls for."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml328(para) msgid ""Add Identity Providers, Mappings and Protocols."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml329(para) msgid """" ""To utilize Federation, create the following in the Identity service: "" ""Identity Provider, Mapping, Protocol."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml334(title) msgid ""Performing Federation authentication"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml336(para) msgid """" ""Authenticate externally and generate an unscoped token in Identity service."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml338(para) msgid """" ""To start Federated authentication a user must access the dedicated URL with "" ""Identity Providers and Protocols identifiers stored within a protected "" ""URL. The URL has a format of: <literal>/v3/OS-"" ""FEDERATION/identity_providers/{identity_provider}/protocols/{protocol}/auth</literal>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml342(para) msgid """" ""This instance follows a standard SAML2 authentication procedure, that is, "" ""the user will be redirected to the Identity Providers authentication "" ""webpage and be prompted for credentials. After successfully authenticating "" ""the user will be redirected to the Service Providers endpoint. If using a "" ""web browser, a token will be returned in XML format. As an alternative to "" ""using a web browser, you can use Enhanced Client or Proxy (ECP), which is "" ""available in the <literal>keystoneclient</literal> in the Identity service "" ""API."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml350(para) msgid """" ""In the returned unscoped token, a list of Identity service groups the user "" ""belongs to will be included."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml352(para) msgid """" ""For example, the following URL would be considered protected by "" ""<literal>mod_shib</literal> and Apache, as such a request made to the URL "" ""would be redirected to the Identity Provider, to start the SAML "" ""authentication procedure."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml358(para) msgid """" ""It is assumed that the <literal>keystone</literal> service is running on "" ""port <literal>5000</literal>."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml361(para) msgid ""Determine accessible resources."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml362(para) msgid """" ""By using the previously returned token, the user can issue requests to the "" ""list projects and domains that are accessible."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml365(para) msgid """" ""List projects a federated user can access: <literal>GET /OS-"" ""FEDERATION/projects</literal>"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml368(para) msgid """" ""List domains a federated user can access: <literal>GET /OS-"" ""FEDERATION/domains</literal>"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml371(para) msgid ""For example,"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml374(para) #: ./security-guide/section_ssl-proxies-and-http-services.xml40(para) msgid ""or"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml377(para) msgid ""Get a scoped token."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml378(para) msgid """" ""A federated user may request a scoped token, by using the unscoped token. A "" ""project or domain may be specified by either ID or name. An ID is sufficient"" "" to uniquely identify a project or domain. For example,"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml390(title) msgid ""Setting Identity service as Identity Provider"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml392(title) msgid ""Configuration options"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml393(para) msgid """" ""Before attempting to federate multiple Identity service deployments, you "" ""must setup certain configuration options in the "" ""<filename>keystone.conf</filename> file."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml396(para) msgid """" ""Within the <filename>keystone.conf</filename> assign values to the "" ""<literal>[saml]</literal> related fields, for example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml404(para) msgid """" ""It is recommended that the following <literal>Organization</literal> "" ""configuration options be setup."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml410(para) msgid """" ""It is also recommended the following <literal>Contact</literal> options are "" ""set."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml421(title) msgid ""Generate metadata"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml422(para) msgid """" ""In order to create a trust between the Identity Provider and the Service "" ""Provider, metadata must be exchanged. To create metadata for your Identity "" ""service, run the <placeholder-1/> command and pipe the output to a file. For"" "" example:"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml427(para) msgid """" ""The file location should match the value of the configuration option "" ""<option>idp_metadata_path</option> that was assigned in the list of "" ""<literal>[saml]</literal> updates."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml432(title) msgid ""Create a region for the Service Provider"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml433(para) msgid """" ""Create a new region for the service provider, for example, create a new "" ""region with an <literal>ID</literal> of <replaceable>BETA</replaceable>, and"" "" <literal>URL</literal> of "" ""<replaceable>https://beta.com/Shibboleth.sso/SAML2/POST</replaceable>. This "" ""URL will be used when creating a SAML assertion for "" ""<replaceable>BETA</replaceable>, and signed by the current Keystone Identity"" "" Provider."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml441(replaceable) msgid ""http://beta.com/Shibboleth.sso/SAML2/POST"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml442(replaceable) #: ./security-guide/section_identity-federated-keystone.xml451(replaceable) msgid ""BETA"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml445(title) msgid ""Testing it all out"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml446(para) msgid """" ""Lastly, if a scoped token and a Service Provider region are presented to "" ""Keystone, the result will be a full SAML Assertion, signed by the IdP "" ""Keystone, specifically intended for the Service Provider Keystone."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml451(replaceable) msgid ""d793d935b9c343f783955cf39ee7dc3c"" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml453(para) msgid """" ""At this point the SAML Assertion can be sent to the Service Provider "" ""Keystone, and a valid OpenStack token, issued by a Service Provider "" ""Keystone, will be returned."" msgstr """" #: ./security-guide/section_identity-federated-keystone.xml460(para) msgid """" ""Currently, the CLI supports the Enhanced Client or Proxy (ECP), (the non-"" ""browser) support for <literal>keystoneclient</literal> from an API "" ""perspective. So, if you are using the <literal>keystoneclient</literal>, you"" "" can create a client instance and use the SAML authorization plugin. There "" ""is no support for dashboard available presently. With the upcoming OpenStack"" "" releases, Federated Identity should be supported with both CLI and the "" ""dashboard."" msgstr """" #: ./security-guide/section_hypervisor-selection.xml735(link) msgid ""Guide to Security for Full Virtualization Technologies"" msgstr """" #: ./security-guide/section_hypervisor-selection.xml740(link) msgid """" ""National Security Telecommunications and Information Systems Security Policy"" "" No. 11"" msgstr """" ","""POT-Creation-Date: 2014-09-27 10:54+0000\n"" ""PO-Revision-Date: 2014-09-27 10:54+0000\n""#: ./security-guide/section_ssl-proxies-and-http-services.xml40(para) msgid ""or"" msgstr """" ",1164,12
openstack%2Fopenstack-manuals~master~If1738d18803862823ecbd417119f7f7eaa8950b1,openstack/openstack-manuals,master,If1738d18803862823ecbd417119f7f7eaa8950b1,Imported Translations from Transifex,MERGED,2014-10-04 06:09:10.000000000,2014-10-04 06:55:06.000000000,2014-10-04 06:55:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-10-04 06:09:10.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/glossary/locale/de.po', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/hot-reference/locale/hot-reference.pot', 'doc/glossary/locale/glossary.pot', 'doc/glossary/locale/fr.po', 'doc/glossary/locale/ko_KR.po', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c6d3d223b712df230e5488de48ccb7b6b052acc2', 'message': 'Imported Translations from Transifex\n\nChange-Id: If1738d18803862823ecbd417119f7f7eaa8950b1\n'}]",0,126122,c6d3d223b712df230e5488de48ccb7b6b052acc2,6,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: If1738d18803862823ecbd417119f7f7eaa8950b1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/126122/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/glossary/locale/de.po', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/hot-reference/locale/hot-reference.pot', 'doc/glossary/locale/glossary.pot', 'doc/glossary/locale/fr.po', 'doc/glossary/locale/ko_KR.po', 'doc/glossary/locale/ja.po']",12,c6d3d223b712df230e5488de48ccb7b6b052acc2,transifex/translations,"""POT-Creation-Date: 2014-10-03 21:15+0000\n"" ""PO-Revision-Date: 2014-10-04 04:45+0000\n""#: ./doc/glossary/glossary-terms.xml7331(secondary) #: ./doc/glossary/glossary-terms.xml7374(secondary)#: ./doc/glossary/glossary-terms.xml8092(primary)#: ./doc/glossary/glossary-terms.xml7329(primary) #: ./doc/glossary/glossary-terms.xml7358(primary) #: ./doc/glossary/glossary-terms.xml8542(primary)#: ./doc/glossary/glossary-terms.xml7859(para)#: ./doc/glossary/glossary-terms.xml8352(para) #: ./doc/glossary/glossary-terms.xml8585(para) #: ./doc/glossary/glossary-terms.xml8815(para) #: ./doc/glossary/glossary-terms.xml8916(para) #: ./doc/glossary/glossary-terms.xml8943(para)#: ./doc/glossary/glossary-terms.xml8237(primary)#: ./doc/glossary/glossary-terms.xml7489(primary) #: ./doc/glossary/glossary-terms.xml7717(primary)#: ./doc/glossary/glossary-terms.xml7691(see)#: ./doc/glossary/glossary-terms.xml7364(para)#: ./doc/glossary/glossary-terms.xml8421(para) #: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8456(primary) #: ./doc/glossary/glossary-terms.xml8604(primary)#: ./doc/glossary/glossary-terms.xml7757(primary) #: ./doc/glossary/glossary-terms.xml7957(primary)#: ./doc/glossary/glossary-terms.xml8220(primary)#: ./doc/glossary/glossary-terms.xml8200(see)#: ./doc/glossary/glossary-terms.xml7901(glossterm) #: ./doc/glossary/glossary-terms.xml7924(primary) #: ./doc/glossary/glossary-terms.xml7938(primary) #: ./doc/glossary/glossary-terms.xml7962(primary)#: ./doc/glossary/glossary-terms.xml8512(primary)#: ./doc/glossary/glossary-terms.xml7607(primary)#: ./doc/glossary/glossary-terms.xml7609(secondary)#: ./doc/glossary/glossary-terms.xml7650(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) msgid ""SELinux"" msgstr """" #: ./doc/glossary/glossary-terms.xml7321(para) msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" #: ./doc/glossary/glossary-terms.xml7327(glossterm)#: ./doc/glossary/glossary-terms.xml7335(para)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7345(glossterm) #: ./doc/glossary/glossary-terms.xml7347(primary)#: ./doc/glossary/glossary-terms.xml7351(para)#: ./doc/glossary/glossary-terms.xml7356(glossterm) #: ./doc/glossary/glossary-terms.xml7360(secondary)#: ./doc/glossary/glossary-terms.xml7370(glossterm)#: ./doc/glossary/glossary-terms.xml7372(primary)#: ./doc/glossary/glossary-terms.xml7378(para)#: ./doc/glossary/glossary-terms.xml7385(glossterm) #: ./doc/glossary/glossary-terms.xml7387(primary)#: ./doc/glossary/glossary-terms.xml7391(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7434(primary)#: ./doc/glossary/glossary-terms.xml7438(para)#: ./doc/glossary/glossary-terms.xml7444(glossterm) #: ./doc/glossary/glossary-terms.xml7448(secondary)#: ./doc/glossary/glossary-terms.xml7446(primary) #: ./doc/glossary/glossary-terms.xml7460(primary) #: ./doc/glossary/glossary-terms.xml7475(primary)#: ./doc/glossary/glossary-terms.xml7452(para)#: ./doc/glossary/glossary-terms.xml7458(glossterm) #: ./doc/glossary/glossary-terms.xml7462(secondary)#: ./doc/glossary/glossary-terms.xml7466(para)#: ./doc/glossary/glossary-terms.xml7473(glossterm) #: ./doc/glossary/glossary-terms.xml7477(secondary)#: ./doc/glossary/glossary-terms.xml7481(para)#: ./doc/glossary/glossary-terms.xml7487(glossterm) #: ./doc/glossary/glossary-terms.xml7494(primary)#: ./doc/glossary/glossary-terms.xml7491(secondary)#: ./doc/glossary/glossary-terms.xml7498(para)#: ./doc/glossary/glossary-terms.xml7511(glossterm)#: ./doc/glossary/glossary-terms.xml7513(primary)#: ./doc/glossary/glossary-terms.xml7517(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7540(primary)#: ./doc/glossary/glossary-terms.xml7544(para)#: ./doc/glossary/glossary-terms.xml7550(glossterm) #: ./doc/glossary/glossary-terms.xml7553(primary)#: ./doc/glossary/glossary-terms.xml7557(para)#: ./doc/glossary/glossary-terms.xml7563(glossterm) #: ./doc/glossary/glossary-terms.xml7566(primary)#: ./doc/glossary/glossary-terms.xml7570(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7592(glossterm) #: ./doc/glossary/glossary-terms.xml7594(primary)#: ./doc/glossary/glossary-terms.xml7598(para)#: ./doc/glossary/glossary-terms.xml7605(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm) #: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7628(para)#: ./doc/glossary/glossary-terms.xml7634(glossterm)#: ./doc/glossary/glossary-terms.xml7636(primary)#: ./doc/glossary/glossary-terms.xml7641(para)#: ./doc/glossary/glossary-terms.xml7648(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7652(secondary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7665(glossterm) #: ./doc/glossary/glossary-terms.xml7667(primary)#: ./doc/glossary/glossary-terms.xml7671(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7682(para)#: ./doc/glossary/glossary-terms.xml7688(glossterm) #: ./doc/glossary/glossary-terms.xml7690(primary)#: ./doc/glossary/glossary-terms.xml7695(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7709(para)#: ./doc/glossary/glossary-terms.xml7715(glossterm)#: ./doc/glossary/glossary-terms.xml7719(secondary)#: ./doc/glossary/glossary-terms.xml7722(primary)#: ./doc/glossary/glossary-terms.xml7726(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7745(primary)#: ./doc/glossary/glossary-terms.xml7749(para)#: ./doc/glossary/glossary-terms.xml7755(glossterm) #: ./doc/glossary/glossary-terms.xml7762(primary)#: ./doc/glossary/glossary-terms.xml7759(secondary)#: ./doc/glossary/glossary-terms.xml7766(para)#: ./doc/glossary/glossary-terms.xml7773(glossterm) #: ./doc/glossary/glossary-terms.xml7777(secondary)#: ./doc/glossary/glossary-terms.xml7775(primary) #: ./doc/glossary/glossary-terms.xml7789(primary) #: ./doc/glossary/glossary-terms.xml7803(primary) #: ./doc/glossary/glossary-terms.xml7952(primary)#: ./doc/glossary/glossary-terms.xml7781(para)#: ./doc/glossary/glossary-terms.xml7787(glossterm) #: ./doc/glossary/glossary-terms.xml7791(secondary)#: ./doc/glossary/glossary-terms.xml7795(para)#: ./doc/glossary/glossary-terms.xml7801(glossterm) #: ./doc/glossary/glossary-terms.xml7805(secondary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm) #: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7827(glossterm)#: ./doc/glossary/glossary-terms.xml7829(primary)#: ./doc/glossary/glossary-terms.xml7833(para)#: ./doc/glossary/glossary-terms.xml7841(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml7852(glossterm) #: ./doc/glossary/glossary-terms.xml7855(primary)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm)#: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7888(glossterm) #: ./doc/glossary/glossary-terms.xml7890(primary)#: ./doc/glossary/glossary-terms.xml7894(para)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary)#: ./doc/glossary/glossary-terms.xml7916(para)#: ./doc/glossary/glossary-terms.xml7922(glossterm) #: ./doc/glossary/glossary-terms.xml7926(secondary)#: ./doc/glossary/glossary-terms.xml7930(para)#: ./doc/glossary/glossary-terms.xml7936(glossterm) #: ./doc/glossary/glossary-terms.xml7940(secondary)#: ./doc/glossary/glossary-terms.xml7944(para)#: ./doc/glossary/glossary-terms.xml7950(glossterm)#: ./doc/glossary/glossary-terms.xml7954(secondary) #: ./doc/glossary/glossary-terms.xml7959(secondary) #: ./doc/glossary/glossary-terms.xml7964(secondary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7986(glossterm) #: ./doc/glossary/glossary-terms.xml7988(primary)#: ./doc/glossary/glossary-terms.xml7992(para)#: ./doc/glossary/glossary-terms.xml7999(glossterm) #: ./doc/glossary/glossary-terms.xml8001(primary)#: ./doc/glossary/glossary-terms.xml8005(para)#: ./doc/glossary/glossary-terms.xml8015(title)#: ./doc/glossary/glossary-terms.xml8018(glossterm) #: ./doc/glossary/glossary-terms.xml8020(primary)#: ./doc/glossary/glossary-terms.xml8024(para)#: ./doc/glossary/glossary-terms.xml8031(glossterm) #: ./doc/glossary/glossary-terms.xml8033(primary)#: ./doc/glossary/glossary-terms.xml8037(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8058(primary)#: ./doc/glossary/glossary-terms.xml8062(para)#: ./doc/glossary/glossary-terms.xml8068(glossterm) #: ./doc/glossary/glossary-terms.xml8079(primary) #: ./doc/glossary/glossary-terms.xml8097(primary) #: ./doc/glossary/glossary-terms.xml8111(primary)#: ./doc/glossary/glossary-terms.xml8071(para)#: ./doc/glossary/glossary-terms.xml8077(glossterm) #: ./doc/glossary/glossary-terms.xml8081(secondary)#: ./doc/glossary/glossary-terms.xml8085(para)#: ./doc/glossary/glossary-terms.xml8090(glossterm) #: ./doc/glossary/glossary-terms.xml8094(secondary) #: ./doc/glossary/glossary-terms.xml8099(secondary)#: ./doc/glossary/glossary-terms.xml8103(para)#: ./doc/glossary/glossary-terms.xml8109(glossterm) #: ./doc/glossary/glossary-terms.xml8113(secondary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm)#: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8141(para)#: ./doc/glossary/glossary-terms.xml8147(glossterm) #: ./doc/glossary/glossary-terms.xml8149(primary)#: ./doc/glossary/glossary-terms.xml8152(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm) #: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8190(para)#: ./doc/glossary/glossary-terms.xml8196(glossterm)#: ./doc/glossary/glossary-terms.xml8198(primary)#: ./doc/glossary/glossary-terms.xml8204(para)#: ./doc/glossary/glossary-terms.xml8209(glossterm)#: ./doc/glossary/glossary-terms.xml8212(para)#: ./doc/glossary/glossary-terms.xml8218(glossterm)#: ./doc/glossary/glossary-terms.xml8222(secondary) #: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml8229(para)#: ./doc/glossary/glossary-terms.xml8235(glossterm)#: ./doc/glossary/glossary-terms.xml8239(secondary) #: ./doc/glossary/glossary-terms.xml8242(primary)#: ./doc/glossary/glossary-terms.xml8246(para)#: ./doc/glossary/glossary-terms.xml8251(glossterm) #: ./doc/glossary/glossary-terms.xml8253(primary)#: ./doc/glossary/glossary-terms.xml8257(para)#: ./doc/glossary/glossary-terms.xml8265(glossterm) #: ./doc/glossary/glossary-terms.xml8267(primary)#: ./doc/glossary/glossary-terms.xml8271(para)#: ./doc/glossary/glossary-terms.xml8280(title)#: ./doc/glossary/glossary-terms.xml8283(glossterm) #: ./doc/glossary/glossary-terms.xml8285(primary)#: ./doc/glossary/glossary-terms.xml8289(para)#: ./doc/glossary/glossary-terms.xml8294(glossterm) #: ./doc/glossary/glossary-terms.xml8296(primary)#: ./doc/glossary/glossary-terms.xml8300(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8317(glossterm)#: ./doc/glossary/glossary-terms.xml8319(primary)#: ./doc/glossary/glossary-terms.xml8323(para)#: ./doc/glossary/glossary-terms.xml8330(glossterm) #: ./doc/glossary/glossary-terms.xml8332(primary)#: ./doc/glossary/glossary-terms.xml8336(para)#: ./doc/glossary/glossary-terms.xml8346(glossterm) #: ./doc/glossary/glossary-terms.xml8348(primary)#: ./doc/glossary/glossary-terms.xml8360(title)#: ./doc/glossary/glossary-terms.xml8363(glossterm) #: ./doc/glossary/glossary-terms.xml8365(primary)#: ./doc/glossary/glossary-terms.xml8369(para)#: ./doc/glossary/glossary-terms.xml8374(glossterm) #: ./doc/glossary/glossary-terms.xml8376(primary)#: ./doc/glossary/glossary-terms.xml8380(para)#: ./doc/glossary/glossary-terms.xml8390(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8427(glossterm) #: ./doc/glossary/glossary-terms.xml8429(primary)#: ./doc/glossary/glossary-terms.xml8433(para)#: ./doc/glossary/glossary-terms.xml8441(glossterm) #: ./doc/glossary/glossary-terms.xml8443(primary)#: ./doc/glossary/glossary-terms.xml8447(para)#: ./doc/glossary/glossary-terms.xml8454(glossterm) #: ./doc/glossary/glossary-terms.xml8461(primary)#: ./doc/glossary/glossary-terms.xml8458(secondary) #: ./doc/glossary/glossary-terms.xml8514(secondary) #: ./doc/glossary/glossary-terms.xml8544(secondary)#: ./doc/glossary/glossary-terms.xml8465(para)#: ./doc/glossary/glossary-terms.xml8470(glossterm) #: ./doc/glossary/glossary-terms.xml8472(primary)#: ./doc/glossary/glossary-terms.xml8476(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8497(glossterm) #: ./doc/glossary/glossary-terms.xml8499(primary)#: ./doc/glossary/glossary-terms.xml8503(para)#: ./doc/glossary/glossary-terms.xml8510(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8527(glossterm) #: ./doc/glossary/glossary-terms.xml8529(primary)#: ./doc/glossary/glossary-terms.xml8533(para)#: ./doc/glossary/glossary-terms.xml8540(glossterm)#: ./doc/glossary/glossary-terms.xml8547(primary)#: ./doc/glossary/glossary-terms.xml8551(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8568(glossterm) #: ./doc/glossary/glossary-terms.xml8570(primary)#: ./doc/glossary/glossary-terms.xml8574(para)#: ./doc/glossary/glossary-terms.xml8579(glossterm) #: ./doc/glossary/glossary-terms.xml8581(primary)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml8596(para)#: ./doc/glossary/glossary-terms.xml8602(glossterm) #: ./doc/glossary/glossary-terms.xml8609(primary)#: ./doc/glossary/glossary-terms.xml8606(secondary)#: ./doc/glossary/glossary-terms.xml8613(para)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8635(glossterm) #: ./doc/glossary/glossary-terms.xml8637(primary)#: ./doc/glossary/glossary-terms.xml8641(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8658(glossterm) #: ./doc/glossary/glossary-terms.xml8660(primary)#: ./doc/glossary/glossary-terms.xml8664(para)#: ./doc/glossary/glossary-terms.xml8669(glossterm)#: ./doc/glossary/glossary-terms.xml8672(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8679(primary)#: ./doc/glossary/glossary-terms.xml8683(para)#: ./doc/glossary/glossary-terms.xml8689(glossterm) #: ./doc/glossary/glossary-terms.xml8701(primary) #: ./doc/glossary/glossary-terms.xml8714(primary) #: ./doc/glossary/glossary-terms.xml8728(primary) #: ./doc/glossary/glossary-terms.xml8741(primary) #: ./doc/glossary/glossary-terms.xml8755(primary) #: ./doc/glossary/glossary-terms.xml8769(primary) #: ./doc/glossary/glossary-terms.xml8783(primary)#: ./doc/glossary/glossary-terms.xml8692(para)#: ./doc/glossary/glossary-terms.xml8699(glossterm) #: ./doc/glossary/glossary-terms.xml8703(secondary)#: ./doc/glossary/glossary-terms.xml8707(para)#: ./doc/glossary/glossary-terms.xml8712(glossterm) #: ./doc/glossary/glossary-terms.xml8716(secondary)#: ./doc/glossary/glossary-terms.xml8720(para)#: ./doc/glossary/glossary-terms.xml8726(glossterm) #: ./doc/glossary/glossary-terms.xml8730(secondary)#: ./doc/glossary/glossary-terms.xml8734(para)#: ./doc/glossary/glossary-terms.xml8739(glossterm) #: ./doc/glossary/glossary-terms.xml8743(secondary)#: ./doc/glossary/glossary-terms.xml8747(para)#: ./doc/glossary/glossary-terms.xml8753(glossterm) #: ./doc/glossary/glossary-terms.xml8757(secondary)#: ./doc/glossary/glossary-terms.xml8761(para)#: ./doc/glossary/glossary-terms.xml8767(glossterm) #: ./doc/glossary/glossary-terms.xml8771(secondary)#: ./doc/glossary/glossary-terms.xml8775(para)#: ./doc/glossary/glossary-terms.xml8781(glossterm) #: ./doc/glossary/glossary-terms.xml8785(secondary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8795(glossterm)#: ./doc/glossary/glossary-terms.xml8797(primary)#: ./doc/glossary/glossary-terms.xml8801(para)#: ./doc/glossary/glossary-terms.xml8809(glossterm) #: ./doc/glossary/glossary-terms.xml8811(primary)#: ./doc/glossary/glossary-terms.xml8823(title)#: ./doc/glossary/glossary-terms.xml8826(glossterm) #: ./doc/glossary/glossary-terms.xml8828(primary)#: ./doc/glossary/glossary-terms.xml8832(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm) #: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8863(glossterm)#: ./doc/glossary/glossary-terms.xml8865(primary)#: ./doc/glossary/glossary-terms.xml8869(para)#: ./doc/glossary/glossary-terms.xml8880(title)#: ./doc/glossary/glossary-terms.xml8883(glossterm) #: ./doc/glossary/glossary-terms.xml8885(primary)#: ./doc/glossary/glossary-terms.xml8889(para)#: ./doc/glossary/glossary-terms.xml8899(glossterm) #: ./doc/glossary/glossary-terms.xml8910(primary) #: ./doc/glossary/glossary-terms.xml8923(primary) #: ./doc/glossary/glossary-terms.xml8937(primary)#: ./doc/glossary/glossary-terms.xml8902(para)#: ./doc/glossary/glossary-terms.xml8908(glossterm) #: ./doc/glossary/glossary-terms.xml8912(secondary)#: ./doc/glossary/glossary-terms.xml8921(glossterm) #: ./doc/glossary/glossary-terms.xml8925(secondary)#: ./doc/glossary/glossary-terms.xml8929(para)#: ./doc/glossary/glossary-terms.xml8935(glossterm)#: ./doc/glossary/glossary-terms.xml8939(secondary)#: ./doc/glossary/glossary-terms.xml8951(title)#: ./doc/glossary/glossary-terms.xml8965(title)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)#: ./doc/glossary/glossary-terms.xml8980(glossterm) #: ./doc/glossary/glossary-terms.xml8982(primary)#: ./doc/glossary/glossary-terms.xml8986(para)","""POT-Creation-Date: 2014-09-23 05:56+0000\n"" ""PO-Revision-Date: 2014-09-22 16:45+0000\n""#: ./doc/glossary/glossary-terms.xml7319(secondary) #: ./doc/glossary/glossary-terms.xml7362(secondary)#: ./doc/glossary/glossary-terms.xml8080(primary)#: ./doc/glossary/glossary-terms.xml7317(primary) #: ./doc/glossary/glossary-terms.xml7346(primary) #: ./doc/glossary/glossary-terms.xml8530(primary)#: ./doc/glossary/glossary-terms.xml7847(para)#: ./doc/glossary/glossary-terms.xml8340(para) #: ./doc/glossary/glossary-terms.xml8573(para) #: ./doc/glossary/glossary-terms.xml8803(para) #: ./doc/glossary/glossary-terms.xml8904(para) #: ./doc/glossary/glossary-terms.xml8931(para)#: ./doc/glossary/glossary-terms.xml8225(primary)#: ./doc/glossary/glossary-terms.xml7477(primary) #: ./doc/glossary/glossary-terms.xml7705(primary)#: ./doc/glossary/glossary-terms.xml7679(see)#: ./doc/glossary/glossary-terms.xml7352(para)#: ./doc/glossary/glossary-terms.xml8397(para)#: ./doc/glossary/glossary-terms.xml8617(para)#: ./doc/glossary/glossary-terms.xml8444(primary) #: ./doc/glossary/glossary-terms.xml8592(primary)#: ./doc/glossary/glossary-terms.xml7745(primary) #: ./doc/glossary/glossary-terms.xml7945(primary)#: ./doc/glossary/glossary-terms.xml8208(primary)#: ./doc/glossary/glossary-terms.xml8188(see)#: ./doc/glossary/glossary-terms.xml7889(glossterm) #: ./doc/glossary/glossary-terms.xml7912(primary) #: ./doc/glossary/glossary-terms.xml7926(primary) #: ./doc/glossary/glossary-terms.xml7950(primary)#: ./doc/glossary/glossary-terms.xml8500(primary)#: ./doc/glossary/glossary-terms.xml7595(primary)#: ./doc/glossary/glossary-terms.xml7597(secondary)#: ./doc/glossary/glossary-terms.xml7638(primary)#: ./doc/glossary/glossary-terms.xml7323(para)#: ./doc/glossary/glossary-terms.xml7327(para)#: ./doc/glossary/glossary-terms.xml7333(glossterm) #: ./doc/glossary/glossary-terms.xml7335(primary)#: ./doc/glossary/glossary-terms.xml7339(para)#: ./doc/glossary/glossary-terms.xml7344(glossterm) #: ./doc/glossary/glossary-terms.xml7348(secondary)#: ./doc/glossary/glossary-terms.xml7358(glossterm)#: ./doc/glossary/glossary-terms.xml7360(primary)#: ./doc/glossary/glossary-terms.xml7366(para)#: ./doc/glossary/glossary-terms.xml7373(glossterm) #: ./doc/glossary/glossary-terms.xml7375(primary)#: ./doc/glossary/glossary-terms.xml7379(para)#: ./doc/glossary/glossary-terms.xml7384(glossterm) #: ./doc/glossary/glossary-terms.xml7386(primary)#: ./doc/glossary/glossary-terms.xml7390(para)#: ./doc/glossary/glossary-terms.xml7396(glossterm) #: ./doc/glossary/glossary-terms.xml7398(primary)#: ./doc/glossary/glossary-terms.xml7402(para)#: ./doc/glossary/glossary-terms.xml7408(glossterm) #: ./doc/glossary/glossary-terms.xml7410(primary)#: ./doc/glossary/glossary-terms.xml7414(para)#: ./doc/glossary/glossary-terms.xml7420(glossterm) #: ./doc/glossary/glossary-terms.xml7422(primary)#: ./doc/glossary/glossary-terms.xml7426(para)#: ./doc/glossary/glossary-terms.xml7432(glossterm) #: ./doc/glossary/glossary-terms.xml7436(secondary)#: ./doc/glossary/glossary-terms.xml7434(primary) #: ./doc/glossary/glossary-terms.xml7448(primary) #: ./doc/glossary/glossary-terms.xml7463(primary)#: ./doc/glossary/glossary-terms.xml7440(para)#: ./doc/glossary/glossary-terms.xml7446(glossterm) #: ./doc/glossary/glossary-terms.xml7450(secondary)#: ./doc/glossary/glossary-terms.xml7454(para)#: ./doc/glossary/glossary-terms.xml7461(glossterm) #: ./doc/glossary/glossary-terms.xml7465(secondary)#: ./doc/glossary/glossary-terms.xml7469(para)#: ./doc/glossary/glossary-terms.xml7475(glossterm) #: ./doc/glossary/glossary-terms.xml7482(primary)#: ./doc/glossary/glossary-terms.xml7479(secondary)#: ./doc/glossary/glossary-terms.xml7486(para)#: ./doc/glossary/glossary-terms.xml7499(glossterm)#: ./doc/glossary/glossary-terms.xml7501(primary)#: ./doc/glossary/glossary-terms.xml7505(para)#: ./doc/glossary/glossary-terms.xml7514(glossterm) #: ./doc/glossary/glossary-terms.xml7516(primary)#: ./doc/glossary/glossary-terms.xml7520(para)#: ./doc/glossary/glossary-terms.xml7526(glossterm) #: ./doc/glossary/glossary-terms.xml7528(primary)#: ./doc/glossary/glossary-terms.xml7532(para)#: ./doc/glossary/glossary-terms.xml7538(glossterm) #: ./doc/glossary/glossary-terms.xml7541(primary)#: ./doc/glossary/glossary-terms.xml7545(para)#: ./doc/glossary/glossary-terms.xml7551(glossterm) #: ./doc/glossary/glossary-terms.xml7554(primary)#: ./doc/glossary/glossary-terms.xml7558(para)#: ./doc/glossary/glossary-terms.xml7568(glossterm) #: ./doc/glossary/glossary-terms.xml7570(primary)#: ./doc/glossary/glossary-terms.xml7574(para)#: ./doc/glossary/glossary-terms.xml7580(glossterm) #: ./doc/glossary/glossary-terms.xml7582(primary)#: ./doc/glossary/glossary-terms.xml7586(para)#: ./doc/glossary/glossary-terms.xml7593(glossterm) #: ./doc/glossary/glossary-terms.xml7600(primary)#: ./doc/glossary/glossary-terms.xml7604(para)#: ./doc/glossary/glossary-terms.xml7610(glossterm) #: ./doc/glossary/glossary-terms.xml7612(primary)#: ./doc/glossary/glossary-terms.xml7616(para)#: ./doc/glossary/glossary-terms.xml7622(glossterm)#: ./doc/glossary/glossary-terms.xml7624(primary)#: ./doc/glossary/glossary-terms.xml7629(para)#: ./doc/glossary/glossary-terms.xml7636(glossterm) #: ./doc/glossary/glossary-terms.xml7643(primary)#: ./doc/glossary/glossary-terms.xml7640(secondary)#: ./doc/glossary/glossary-terms.xml7647(para)#: ./doc/glossary/glossary-terms.xml7653(glossterm) #: ./doc/glossary/glossary-terms.xml7655(primary)#: ./doc/glossary/glossary-terms.xml7659(para)#: ./doc/glossary/glossary-terms.xml7664(glossterm) #: ./doc/glossary/glossary-terms.xml7666(primary)#: ./doc/glossary/glossary-terms.xml7670(para)#: ./doc/glossary/glossary-terms.xml7676(glossterm) #: ./doc/glossary/glossary-terms.xml7678(primary)#: ./doc/glossary/glossary-terms.xml7683(para)#: ./doc/glossary/glossary-terms.xml7691(glossterm) #: ./doc/glossary/glossary-terms.xml7693(primary)#: ./doc/glossary/glossary-terms.xml7697(para)#: ./doc/glossary/glossary-terms.xml7703(glossterm)#: ./doc/glossary/glossary-terms.xml7707(secondary)#: ./doc/glossary/glossary-terms.xml7710(primary)#: ./doc/glossary/glossary-terms.xml7714(para)#: ./doc/glossary/glossary-terms.xml7719(glossterm) #: ./doc/glossary/glossary-terms.xml7721(primary)#: ./doc/glossary/glossary-terms.xml7725(para)#: ./doc/glossary/glossary-terms.xml7731(glossterm) #: ./doc/glossary/glossary-terms.xml7733(primary)#: ./doc/glossary/glossary-terms.xml7737(para)#: ./doc/glossary/glossary-terms.xml7743(glossterm) #: ./doc/glossary/glossary-terms.xml7750(primary)#: ./doc/glossary/glossary-terms.xml7747(secondary)#: ./doc/glossary/glossary-terms.xml7754(para)#: ./doc/glossary/glossary-terms.xml7761(glossterm) #: ./doc/glossary/glossary-terms.xml7765(secondary)#: ./doc/glossary/glossary-terms.xml7763(primary) #: ./doc/glossary/glossary-terms.xml7777(primary) #: ./doc/glossary/glossary-terms.xml7791(primary) #: ./doc/glossary/glossary-terms.xml7940(primary)#: ./doc/glossary/glossary-terms.xml7769(para)#: ./doc/glossary/glossary-terms.xml7775(glossterm) #: ./doc/glossary/glossary-terms.xml7779(secondary)#: ./doc/glossary/glossary-terms.xml7783(para)#: ./doc/glossary/glossary-terms.xml7789(glossterm) #: ./doc/glossary/glossary-terms.xml7793(secondary)#: ./doc/glossary/glossary-terms.xml7797(para)#: ./doc/glossary/glossary-terms.xml7803(glossterm) #: ./doc/glossary/glossary-terms.xml7805(primary)#: ./doc/glossary/glossary-terms.xml7809(para)#: ./doc/glossary/glossary-terms.xml7815(glossterm)#: ./doc/glossary/glossary-terms.xml7817(primary)#: ./doc/glossary/glossary-terms.xml7821(para)#: ./doc/glossary/glossary-terms.xml7829(glossterm) #: ./doc/glossary/glossary-terms.xml7831(primary)#: ./doc/glossary/glossary-terms.xml7835(para)#: ./doc/glossary/glossary-terms.xml7840(glossterm) #: ./doc/glossary/glossary-terms.xml7843(primary)#: ./doc/glossary/glossary-terms.xml7852(glossterm)#: ./doc/glossary/glossary-terms.xml7854(primary)#: ./doc/glossary/glossary-terms.xml7858(para)#: ./doc/glossary/glossary-terms.xml7864(glossterm)#: ./doc/glossary/glossary-terms.xml7866(primary)#: ./doc/glossary/glossary-terms.xml7870(para)#: ./doc/glossary/glossary-terms.xml7876(glossterm) #: ./doc/glossary/glossary-terms.xml7878(primary)#: ./doc/glossary/glossary-terms.xml7882(para)#: ./doc/glossary/glossary-terms.xml7892(para)#: ./doc/glossary/glossary-terms.xml7898(glossterm) #: ./doc/glossary/glossary-terms.xml7900(primary)#: ./doc/glossary/glossary-terms.xml7904(para)#: ./doc/glossary/glossary-terms.xml7910(glossterm) #: ./doc/glossary/glossary-terms.xml7914(secondary)#: ./doc/glossary/glossary-terms.xml7918(para)#: ./doc/glossary/glossary-terms.xml7924(glossterm) #: ./doc/glossary/glossary-terms.xml7928(secondary)#: ./doc/glossary/glossary-terms.xml7932(para)#: ./doc/glossary/glossary-terms.xml7938(glossterm)#: ./doc/glossary/glossary-terms.xml7942(secondary) #: ./doc/glossary/glossary-terms.xml7947(secondary) #: ./doc/glossary/glossary-terms.xml7952(secondary)#: ./doc/glossary/glossary-terms.xml7956(para)#: ./doc/glossary/glossary-terms.xml7962(glossterm) #: ./doc/glossary/glossary-terms.xml7964(primary)#: ./doc/glossary/glossary-terms.xml7968(para)#: ./doc/glossary/glossary-terms.xml7974(glossterm) #: ./doc/glossary/glossary-terms.xml7976(primary)#: ./doc/glossary/glossary-terms.xml7980(para)#: ./doc/glossary/glossary-terms.xml7987(glossterm) #: ./doc/glossary/glossary-terms.xml7989(primary)#: ./doc/glossary/glossary-terms.xml7993(para)#: ./doc/glossary/glossary-terms.xml8003(title)#: ./doc/glossary/glossary-terms.xml8006(glossterm) #: ./doc/glossary/glossary-terms.xml8008(primary)#: ./doc/glossary/glossary-terms.xml8012(para)#: ./doc/glossary/glossary-terms.xml8019(glossterm) #: ./doc/glossary/glossary-terms.xml8021(primary)#: ./doc/glossary/glossary-terms.xml8025(para)#: ./doc/glossary/glossary-terms.xml8032(glossterm) #: ./doc/glossary/glossary-terms.xml8034(primary)#: ./doc/glossary/glossary-terms.xml8038(para)#: ./doc/glossary/glossary-terms.xml8044(glossterm) #: ./doc/glossary/glossary-terms.xml8046(primary)#: ./doc/glossary/glossary-terms.xml8050(para)#: ./doc/glossary/glossary-terms.xml8056(glossterm) #: ./doc/glossary/glossary-terms.xml8067(primary) #: ./doc/glossary/glossary-terms.xml8085(primary) #: ./doc/glossary/glossary-terms.xml8099(primary)#: ./doc/glossary/glossary-terms.xml8059(para)#: ./doc/glossary/glossary-terms.xml8065(glossterm) #: ./doc/glossary/glossary-terms.xml8069(secondary)#: ./doc/glossary/glossary-terms.xml8073(para)#: ./doc/glossary/glossary-terms.xml8078(glossterm) #: ./doc/glossary/glossary-terms.xml8082(secondary) #: ./doc/glossary/glossary-terms.xml8087(secondary)#: ./doc/glossary/glossary-terms.xml8091(para)#: ./doc/glossary/glossary-terms.xml8097(glossterm) #: ./doc/glossary/glossary-terms.xml8101(secondary)#: ./doc/glossary/glossary-terms.xml8105(para)#: ./doc/glossary/glossary-terms.xml8111(glossterm)#: ./doc/glossary/glossary-terms.xml8113(primary)#: ./doc/glossary/glossary-terms.xml8117(para)#: ./doc/glossary/glossary-terms.xml8123(glossterm) #: ./doc/glossary/glossary-terms.xml8125(primary)#: ./doc/glossary/glossary-terms.xml8129(para)#: ./doc/glossary/glossary-terms.xml8135(glossterm) #: ./doc/glossary/glossary-terms.xml8137(primary)#: ./doc/glossary/glossary-terms.xml8140(para)#: ./doc/glossary/glossary-terms.xml8148(glossterm) #: ./doc/glossary/glossary-terms.xml8150(primary)#: ./doc/glossary/glossary-terms.xml8154(para)#: ./doc/glossary/glossary-terms.xml8160(glossterm) #: ./doc/glossary/glossary-terms.xml8162(primary)#: ./doc/glossary/glossary-terms.xml8166(para)#: ./doc/glossary/glossary-terms.xml8172(glossterm)#: ./doc/glossary/glossary-terms.xml8174(primary)#: ./doc/glossary/glossary-terms.xml8178(para)#: ./doc/glossary/glossary-terms.xml8184(glossterm)#: ./doc/glossary/glossary-terms.xml8186(primary)#: ./doc/glossary/glossary-terms.xml8192(para)#: ./doc/glossary/glossary-terms.xml8197(glossterm)#: ./doc/glossary/glossary-terms.xml8200(para)#: ./doc/glossary/glossary-terms.xml8206(glossterm)#: ./doc/glossary/glossary-terms.xml8210(secondary) #: ./doc/glossary/glossary-terms.xml8213(primary)#: ./doc/glossary/glossary-terms.xml8217(para)#: ./doc/glossary/glossary-terms.xml8223(glossterm)#: ./doc/glossary/glossary-terms.xml8227(secondary) #: ./doc/glossary/glossary-terms.xml8230(primary)#: ./doc/glossary/glossary-terms.xml8234(para)#: ./doc/glossary/glossary-terms.xml8239(glossterm) #: ./doc/glossary/glossary-terms.xml8241(primary)#: ./doc/glossary/glossary-terms.xml8245(para)#: ./doc/glossary/glossary-terms.xml8253(glossterm) #: ./doc/glossary/glossary-terms.xml8255(primary)#: ./doc/glossary/glossary-terms.xml8259(para)#: ./doc/glossary/glossary-terms.xml8268(title)#: ./doc/glossary/glossary-terms.xml8271(glossterm) #: ./doc/glossary/glossary-terms.xml8273(primary)#: ./doc/glossary/glossary-terms.xml8277(para)#: ./doc/glossary/glossary-terms.xml8282(glossterm) #: ./doc/glossary/glossary-terms.xml8284(primary)#: ./doc/glossary/glossary-terms.xml8288(para)#: ./doc/glossary/glossary-terms.xml8293(glossterm)#: ./doc/glossary/glossary-terms.xml8295(primary)#: ./doc/glossary/glossary-terms.xml8299(para)#: ./doc/glossary/glossary-terms.xml8305(glossterm)#: ./doc/glossary/glossary-terms.xml8307(primary)#: ./doc/glossary/glossary-terms.xml8311(para)#: ./doc/glossary/glossary-terms.xml8318(glossterm) #: ./doc/glossary/glossary-terms.xml8320(primary)#: ./doc/glossary/glossary-terms.xml8324(para)#: ./doc/glossary/glossary-terms.xml8334(glossterm) #: ./doc/glossary/glossary-terms.xml8336(primary)#: ./doc/glossary/glossary-terms.xml8348(title)#: ./doc/glossary/glossary-terms.xml8351(glossterm) #: ./doc/glossary/glossary-terms.xml8353(primary)#: ./doc/glossary/glossary-terms.xml8357(para)#: ./doc/glossary/glossary-terms.xml8362(glossterm) #: ./doc/glossary/glossary-terms.xml8364(primary)#: ./doc/glossary/glossary-terms.xml8368(para)#: ./doc/glossary/glossary-terms.xml8378(glossterm) #: ./doc/glossary/glossary-terms.xml8381(primary)#: ./doc/glossary/glossary-terms.xml8385(para)#: ./doc/glossary/glossary-terms.xml8391(glossterm) #: ./doc/glossary/glossary-terms.xml8393(primary)#: ./doc/glossary/glossary-terms.xml8403(glossterm) #: ./doc/glossary/glossary-terms.xml8405(primary)#: ./doc/glossary/glossary-terms.xml8415(glossterm) #: ./doc/glossary/glossary-terms.xml8417(primary)#: ./doc/glossary/glossary-terms.xml8421(para)#: ./doc/glossary/glossary-terms.xml8429(glossterm) #: ./doc/glossary/glossary-terms.xml8431(primary)#: ./doc/glossary/glossary-terms.xml8435(para)#: ./doc/glossary/glossary-terms.xml8442(glossterm) #: ./doc/glossary/glossary-terms.xml8449(primary)#: ./doc/glossary/glossary-terms.xml8446(secondary) #: ./doc/glossary/glossary-terms.xml8502(secondary) #: ./doc/glossary/glossary-terms.xml8532(secondary)#: ./doc/glossary/glossary-terms.xml8453(para)#: ./doc/glossary/glossary-terms.xml8458(glossterm) #: ./doc/glossary/glossary-terms.xml8460(primary)#: ./doc/glossary/glossary-terms.xml8464(para)#: ./doc/glossary/glossary-terms.xml8473(glossterm) #: ./doc/glossary/glossary-terms.xml8475(primary)#: ./doc/glossary/glossary-terms.xml8479(para)#: ./doc/glossary/glossary-terms.xml8485(glossterm) #: ./doc/glossary/glossary-terms.xml8487(primary)#: ./doc/glossary/glossary-terms.xml8491(para)#: ./doc/glossary/glossary-terms.xml8498(glossterm) #: ./doc/glossary/glossary-terms.xml8505(primary)#: ./doc/glossary/glossary-terms.xml8509(para)#: ./doc/glossary/glossary-terms.xml8515(glossterm) #: ./doc/glossary/glossary-terms.xml8517(primary)#: ./doc/glossary/glossary-terms.xml8521(para)#: ./doc/glossary/glossary-terms.xml8528(glossterm)#: ./doc/glossary/glossary-terms.xml8535(primary)#: ./doc/glossary/glossary-terms.xml8539(para)#: ./doc/glossary/glossary-terms.xml8544(glossterm) #: ./doc/glossary/glossary-terms.xml8546(primary)#: ./doc/glossary/glossary-terms.xml8550(para)#: ./doc/glossary/glossary-terms.xml8556(glossterm) #: ./doc/glossary/glossary-terms.xml8558(primary)#: ./doc/glossary/glossary-terms.xml8562(para)#: ./doc/glossary/glossary-terms.xml8567(glossterm) #: ./doc/glossary/glossary-terms.xml8569(primary)#: ./doc/glossary/glossary-terms.xml8578(glossterm) #: ./doc/glossary/glossary-terms.xml8580(primary)#: ./doc/glossary/glossary-terms.xml8584(para)#: ./doc/glossary/glossary-terms.xml8590(glossterm) #: ./doc/glossary/glossary-terms.xml8597(primary)#: ./doc/glossary/glossary-terms.xml8594(secondary)#: ./doc/glossary/glossary-terms.xml8601(para)#: ./doc/glossary/glossary-terms.xml8611(glossterm) #: ./doc/glossary/glossary-terms.xml8613(primary)#: ./doc/glossary/glossary-terms.xml8623(glossterm) #: ./doc/glossary/glossary-terms.xml8625(primary)#: ./doc/glossary/glossary-terms.xml8629(para)#: ./doc/glossary/glossary-terms.xml8634(glossterm) #: ./doc/glossary/glossary-terms.xml8636(primary)#: ./doc/glossary/glossary-terms.xml8640(para)#: ./doc/glossary/glossary-terms.xml8646(glossterm) #: ./doc/glossary/glossary-terms.xml8648(primary)#: ./doc/glossary/glossary-terms.xml8652(para)#: ./doc/glossary/glossary-terms.xml8657(glossterm)#: ./doc/glossary/glossary-terms.xml8660(para)#: ./doc/glossary/glossary-terms.xml8665(glossterm) #: ./doc/glossary/glossary-terms.xml8667(primary)#: ./doc/glossary/glossary-terms.xml8671(para)#: ./doc/glossary/glossary-terms.xml8677(glossterm) #: ./doc/glossary/glossary-terms.xml8689(primary) #: ./doc/glossary/glossary-terms.xml8702(primary) #: ./doc/glossary/glossary-terms.xml8716(primary) #: ./doc/glossary/glossary-terms.xml8729(primary) #: ./doc/glossary/glossary-terms.xml8743(primary) #: ./doc/glossary/glossary-terms.xml8757(primary) #: ./doc/glossary/glossary-terms.xml8771(primary)#: ./doc/glossary/glossary-terms.xml8680(para)#: ./doc/glossary/glossary-terms.xml8687(glossterm) #: ./doc/glossary/glossary-terms.xml8691(secondary)#: ./doc/glossary/glossary-terms.xml8695(para)#: ./doc/glossary/glossary-terms.xml8700(glossterm) #: ./doc/glossary/glossary-terms.xml8704(secondary)#: ./doc/glossary/glossary-terms.xml8708(para)#: ./doc/glossary/glossary-terms.xml8714(glossterm) #: ./doc/glossary/glossary-terms.xml8718(secondary)#: ./doc/glossary/glossary-terms.xml8722(para)#: ./doc/glossary/glossary-terms.xml8727(glossterm) #: ./doc/glossary/glossary-terms.xml8731(secondary)#: ./doc/glossary/glossary-terms.xml8735(para)#: ./doc/glossary/glossary-terms.xml8741(glossterm) #: ./doc/glossary/glossary-terms.xml8745(secondary)#: ./doc/glossary/glossary-terms.xml8749(para)#: ./doc/glossary/glossary-terms.xml8755(glossterm) #: ./doc/glossary/glossary-terms.xml8759(secondary)#: ./doc/glossary/glossary-terms.xml8763(para)#: ./doc/glossary/glossary-terms.xml8769(glossterm) #: ./doc/glossary/glossary-terms.xml8773(secondary)#: ./doc/glossary/glossary-terms.xml8777(para)#: ./doc/glossary/glossary-terms.xml8783(glossterm)#: ./doc/glossary/glossary-terms.xml8785(primary)#: ./doc/glossary/glossary-terms.xml8789(para)#: ./doc/glossary/glossary-terms.xml8797(glossterm) #: ./doc/glossary/glossary-terms.xml8799(primary)#: ./doc/glossary/glossary-terms.xml8811(title)#: ./doc/glossary/glossary-terms.xml8814(glossterm) #: ./doc/glossary/glossary-terms.xml8816(primary)#: ./doc/glossary/glossary-terms.xml8820(para)#: ./doc/glossary/glossary-terms.xml8827(glossterm) #: ./doc/glossary/glossary-terms.xml8829(primary)#: ./doc/glossary/glossary-terms.xml8833(para)#: ./doc/glossary/glossary-terms.xml8839(glossterm) #: ./doc/glossary/glossary-terms.xml8841(primary)#: ./doc/glossary/glossary-terms.xml8845(para)#: ./doc/glossary/glossary-terms.xml8851(glossterm)#: ./doc/glossary/glossary-terms.xml8853(primary)#: ./doc/glossary/glossary-terms.xml8857(para)#: ./doc/glossary/glossary-terms.xml8868(title)#: ./doc/glossary/glossary-terms.xml8871(glossterm) #: ./doc/glossary/glossary-terms.xml8873(primary)#: ./doc/glossary/glossary-terms.xml8877(para)#: ./doc/glossary/glossary-terms.xml8887(glossterm) #: ./doc/glossary/glossary-terms.xml8898(primary) #: ./doc/glossary/glossary-terms.xml8911(primary) #: ./doc/glossary/glossary-terms.xml8925(primary)#: ./doc/glossary/glossary-terms.xml8890(para)#: ./doc/glossary/glossary-terms.xml8896(glossterm) #: ./doc/glossary/glossary-terms.xml8900(secondary)#: ./doc/glossary/glossary-terms.xml8909(glossterm) #: ./doc/glossary/glossary-terms.xml8913(secondary)#: ./doc/glossary/glossary-terms.xml8917(para)#: ./doc/glossary/glossary-terms.xml8923(glossterm)#: ./doc/glossary/glossary-terms.xml8927(secondary)#: ./doc/glossary/glossary-terms.xml8939(title)#: ./doc/glossary/glossary-terms.xml8953(title)#: ./doc/glossary/glossary-terms.xml8956(glossterm) #: ./doc/glossary/glossary-terms.xml8958(primary)#: ./doc/glossary/glossary-terms.xml8962(para)#: ./doc/glossary/glossary-terms.xml8968(glossterm) #: ./doc/glossary/glossary-terms.xml8970(primary)#: ./doc/glossary/glossary-terms.xml8974(para)",14269,8815
openstack%2Foslo.utils~master~Ic80bb402e03d4d39ad0fe01cc581bef93027c4d4,openstack/oslo.utils,master,Ic80bb402e03d4d39ad0fe01cc581bef93027c4d4,Imported Translations from Transifex,MERGED,2014-10-03 06:18:18.000000000,2014-10-04 06:36:22.000000000,2014-10-04 06:36:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6547}, {'_account_id': 7491}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-03 06:18:18.000000000', 'files': ['oslo.utils/locale/en_GB/LC_MESSAGES/oslo.utils-log-critical.po', 'oslo.utils/locale/fr/LC_MESSAGES/oslo.utils-log-critical.po', 'oslo.utils/locale/en_GB/LC_MESSAGES/oslo.utils-log-info.po', 'oslo.utils/locale/fr/LC_MESSAGES/oslo.utils-log-info.po'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/563a990e02d59cb796d170f98c25c39d74d6cda5', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic80bb402e03d4d39ad0fe01cc581bef93027c4d4\n'}]",0,125891,563a990e02d59cb796d170f98c25c39d74d6cda5,30,5,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ic80bb402e03d4d39ad0fe01cc581bef93027c4d4
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/91/125891/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo.utils/locale/en_GB/LC_MESSAGES/oslo.utils-log-critical.po', 'oslo.utils/locale/fr/LC_MESSAGES/oslo.utils-log-critical.po', 'oslo.utils/locale/en_GB/LC_MESSAGES/oslo.utils-log-info.po', 'oslo.utils/locale/fr/LC_MESSAGES/oslo.utils-log-info.po']",4,563a990e02d59cb796d170f98c25c39d74d6cda5,transifex/translations,,"# Translations template for heat. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the heat project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: oslo.utils\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-09-26 06:11+0000\n"" ""PO-Revision-Date: 2014-09-25 08:49+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language-Team: French (http://www.transifex.com/projects/p/osloutils/"" ""language/fr/)\n"" ""Language: fr\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" ",0,84
openstack%2Ftripleo-image-elements~master~I81b1308b0122763d396328458fc129072cce8198,openstack/tripleo-image-elements,master,I81b1308b0122763d396328458fc129072cce8198,Add package install support,MERGED,2014-09-30 12:15:57.000000000,2014-10-04 05:28:27.000000000,2014-10-04 05:28:26.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 7585}]","[{'number': 1, 'created': '2014-09-30 12:15:57.000000000', 'files': ['elements/tripleo-heat-templates/install.d/tripleo-heat-templates-package-install/10-tripleo-heat-templates', 'elements/tripleo-heat-templates/pkg-map'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0941a604ae05c682fabf91f8d8d15740a7be4791', 'message': 'Add package install support\n\nAdds package install support for tripleo-heat-templates, which is a\ndependency of Tuskar, thus it needs to be installed on underclouds.\n\nChange-Id: I81b1308b0122763d396328458fc129072cce8198\n'}]",0,125014,0941a604ae05c682fabf91f8d8d15740a7be4791,13,5,1,7144,,,0,"Add package install support

Adds package install support for tripleo-heat-templates, which is a
dependency of Tuskar, thus it needs to be installed on underclouds.

Change-Id: I81b1308b0122763d396328458fc129072cce8198
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/14/125014/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/tripleo-heat-templates/install.d/tripleo-heat-templates-package-install/10-tripleo-heat-templates', 'elements/tripleo-heat-templates/pkg-map']",2,0941a604ae05c682fabf91f8d8d15740a7be4791,tht-package-install,"{ ""default"": { ""tripleo_heat_templates_package"": ""openstack-tripleo-heat-templates"" } } ",,11,0
openstack%2Ftripleo-image-elements~master~Ia43742bb776ea93b6ed281161c3d362f5b803171,openstack/tripleo-image-elements,master,Ia43742bb776ea93b6ed281161c3d362f5b803171,Hash instance-id instead of expecting specific format,MERGED,2014-09-16 18:35:46.000000000,2014-10-04 05:27:04.000000000,2014-10-04 05:27:04.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 7582}, {'_account_id': 7585}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-09-16 18:35:46.000000000', 'files': ['elements/mysql-common/os-refresh-config/configure.d/51-mysql-server-id'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/757189e8d9f229ed1dc2e6c7d9c9f5ffd7d3aad3', 'message': ""Hash instance-id instead of expecting specific format\n\nIn versions of cloud-init prior to 0.7.5,\n/var/lib/cloud/data/instance-id was something of the form\ni-########.  Our mysql-common element used that ######## bit to set\nthe mysqld server_id.\n\nIn cloud-init 0.7.5, and probably above, the instance-id file is a\nuuid instead, which means there is no numeric part for us to use as\nthe server_id.\n\nTo address this, I'm hashing the instance-id and using that\nvalue instead of one pulled from the id itself, which should work\nfor arbitrary formats of the id.  There is some tiny chance of\nhash collisions with this method, but the server_id will allow\n2 ^ 32 - 1 different values, so the odds of that happening are\nextremely small.\n\nChange-Id: Ia43742bb776ea93b6ed281161c3d362f5b803171\n""}]",3,121949,757189e8d9f229ed1dc2e6c7d9c9f5ffd7d3aad3,12,5,1,6928,,,0,"Hash instance-id instead of expecting specific format

In versions of cloud-init prior to 0.7.5,
/var/lib/cloud/data/instance-id was something of the form
i-########.  Our mysql-common element used that ######## bit to set
the mysqld server_id.

In cloud-init 0.7.5, and probably above, the instance-id file is a
uuid instead, which means there is no numeric part for us to use as
the server_id.

To address this, I'm hashing the instance-id and using that
value instead of one pulled from the id itself, which should work
for arbitrary formats of the id.  There is some tiny chance of
hash collisions with this method, but the server_id will allow
2 ^ 32 - 1 different values, so the odds of that happening are
extremely small.

Change-Id: Ia43742bb776ea93b6ed281161c3d362f5b803171
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/49/121949/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-common/os-refresh-config/configure.d/51-mysql-server-id'],1,757189e8d9f229ed1dc2e6c7d9c9f5ffd7d3aad3,instance-uuid,"SERVER_ID=$(python -c ""import hashlib; h = hashlib.sha1(); h.update('${INSTANCE_ID}'); print(int(h.hexdigest(), 16) % (2 ** 32 - 1))"")","SERVER_ID=$(python -c ""print 0x${INSTANCE_ID##i-}"")",1,1
openstack%2Foslo.i18n~master~I6896837f5d25f8f74c9170621494053ffddf06b6,openstack/oslo.i18n,master,I6896837f5d25f8f74c9170621494053ffddf06b6,Fix coverage testing,MERGED,2014-10-01 14:52:41.000000000,2014-10-04 04:45:48.000000000,2014-10-04 04:45:47.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6601}]","[{'number': 1, 'created': '2014-10-01 14:52:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/30416892df32c6acf96d6a60406cb3722ea11f5c', 'message': 'Fix coverage testing\n\nAdd coverage to test-requirements so that tox-e cover works - this\nis part of the post jobs that are run.\n\nChange-Id: I6896837f5d25f8f74c9170621494053ffddf06b6\n'}]",0,125368,30416892df32c6acf96d6a60406cb3722ea11f5c,14,5,1,6547,,,0,"Fix coverage testing

Add coverage to test-requirements so that tox-e cover works - this
is part of the post jobs that are run.

Change-Id: I6896837f5d25f8f74c9170621494053ffddf06b6
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/68/125368/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,30416892df32c6acf96d6a60406cb3722ea11f5c,fix-coverage,coverage>=3.6,,1,0
openstack%2Foslo.i18n~master~Ic5bb0a4e857cd88e1f40e3a5d8a6477bce655a5b,openstack/oslo.i18n,master,Ic5bb0a4e857cd88e1f40e3a5d8a6477bce655a5b,Work toward Python 3.4 support and testing,MERGED,2014-09-03 20:30:13.000000000,2014-10-04 04:45:41.000000000,2014-10-04 04:45:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-09-03 20:30:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/0624f8dbaafd4ffd2a188e7c40394f4a915c8ff8', 'message': 'Work toward Python 3.4 support and testing\n\nChange-Id: Ic5bb0a4e857cd88e1f40e3a5d8a6477bce655a5b\n'}]",0,118788,0624f8dbaafd4ffd2a188e7c40394f4a915c8ff8,13,4,1,5263,,,0,"Work toward Python 3.4 support and testing

Change-Id: Ic5bb0a4e857cd88e1f40e3a5d8a6477bce655a5b
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/88/118788/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0624f8dbaafd4ffd2a188e7c40394f4a915c8ff8,py34,"envlist = py33,py34,py26,py27,pep8","envlist = py33,py26,py27,pep8",1,1
openstack%2Fhorizon~master~I5d61141c7170dfc57345517bf263e95a8622914f,openstack/horizon,master,I5d61141c7170dfc57345517bf263e95a8622914f,Support BS3 events in Retrieve Instance Pw,MERGED,2014-08-07 17:11:59.000000000,2014-10-04 04:45:30.000000000,2014-10-04 04:45:30.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 6914}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-07 17:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d7006c19a1c768b4b1397a2168c0e46f251cb858', 'message': 'Support BS3 events in Retrieve Instance Pw\n\nChange-Id: I5d61141c7170dfc57345517bf263e95a8622914f\n'}, {'number': 2, 'created': '2014-08-07 17:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c04bce3aadc474c5072b4966b4d9146979398969', 'message': ""Support BS3 events in Retrieve Instance Pw\n\nBootstrap 3 event changed from 'show' to 'show.bs.modal'.\n\nChange-Id: I5d61141c7170dfc57345517bf263e95a8622914f\nCloses-Bug: #1354076\n""}, {'number': 3, 'created': '2014-10-03 13:42:47.000000000', 'files': ['horizon/static/horizon/js/horizon.instances.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/40028f592f37bbd1ce6665259f6943f84d314386', 'message': ""Support BS3 events in Retrieve Instance Pw\n\nBootstrap 3 event changed from 'show' to 'show.bs.modal'.\n\nChange-Id: I5d61141c7170dfc57345517bf263e95a8622914f\nCloses-Bug: #1354076\n""}]",0,112626,40028f592f37bbd1ce6665259f6943f84d314386,15,6,3,11902,,,0,"Support BS3 events in Retrieve Instance Pw

Bootstrap 3 event changed from 'show' to 'show.bs.modal'.

Change-Id: I5d61141c7170dfc57345517bf263e95a8622914f
Closes-Bug: #1354076
",git fetch https://review.opendev.org/openstack/horizon refs/changes/26/112626/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.instances.js'],1,d7006c19a1c768b4b1397a2168c0e46f251cb858,bug/1354076," $(document).on('show.bs.modal', '#password_instance_modal', function (evt) {"," $(document).on('show', '#password_instance_modal', function (evt) {",1,1
openstack%2Foslo.db~master~Ia75793335f09fb07fdc99e02fabb2f0ca376862a,openstack/oslo.db,master,Ia75793335f09fb07fdc99e02fabb2f0ca376862a,Get testr list-tests to function without failing under 3.x,ABANDONED,2014-09-09 20:30:42.000000000,2014-10-04 03:53:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-09-09 20:30:42.000000000', 'files': ['tests/sqlalchemy/test_migrate_cli.py', 'tests/sqlalchemy/test_migration_common.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/732a228ccf2a4db26098dc87285a7a3b46a25aa0', 'message': 'Get testr list-tests to function without failing under 3.x\n\nChange-Id: Ia75793335f09fb07fdc99e02fabb2f0ca376862a\n'}]",3,120215,732a228ccf2a4db26098dc87285a7a3b46a25aa0,6,4,1,1297,,,0,"Get testr list-tests to function without failing under 3.x

Change-Id: Ia75793335f09fb07fdc99e02fabb2f0ca376862a
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/15/120215/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_migrate_cli.py', 'tests/sqlalchemy/test_migration_common.py']",2,732a228ccf2a4db26098dc87285a7a3b46a25aa0,better-py34,"try: from migrate import exceptions as migrate_exception from migrate.versioning import api as versioning_api from oslo.db.sqlalchemy import migration MIGRATE_AVAILABLE = True except ImportError: MIGRATE_AVAILABLE = False import testtools@testtools.skipIf(not MIGRATE_AVAILABLE, 'sqlalchemy-migrate is not installed') def test_db_version_raise_not_controlled_error_no_tables(self, mock_vc): with mock.patch.object(versioning_api, 'version_control') as mock_vc: with mock.patch.object(sqlalchemy, 'MetaData') as mock_meta: self.mock_api_db_version.side_effect = ( migrate_exception.DatabaseNotControlledError('oups'), self.init_version) my_meta = mock.MagicMock() my_meta.tables = {} mock_meta.return_value = my_meta migration.db_version(self.engine, self.path, self.init_version) mock_vc.assert_called_once_with(self.engine, self.return_value1, self.init_version)","from migrate import exceptions as migrate_exception from migrate.versioning import api as versioning_apifrom oslo.db.sqlalchemy import migration @mock.patch.object(versioning_api, 'version_control') def test_db_version_raise_not_controlled_error_no_tables(self, mock_vc): with mock.patch.object(sqlalchemy, 'MetaData') as mock_meta: self.mock_api_db_version.side_effect = ( migrate_exception.DatabaseNotControlledError('oups'), self.init_version) my_meta = mock.MagicMock() my_meta.tables = {} mock_meta.return_value = my_meta migration.db_version(self.engine, self.path, self.init_version) mock_vc.assert_called_once_with(self.engine, self.return_value1, self.init_version)",34,16
openstack%2Foslo.i18n~master~I74189de25d3611ed6a57cf35fee6682b81056071,openstack/oslo.i18n,master,I74189de25d3611ed6a57cf35fee6682b81056071,Use same indentation in doc/source/usage,MERGED,2014-09-26 16:14:58.000000000,2014-10-04 03:14:24.000000000,2014-10-04 03:14:23.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6601}]","[{'number': 1, 'created': '2014-09-26 16:14:58.000000000', 'files': ['doc/source/usage.rst'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/26edee1f7fd237e4da93b8eeacbd381127c373a8', 'message': 'Use same indentation in doc/source/usage\n\nThe first code example for ""Creating an Integration Module""\n(http://docs.openstack.org/developer/oslo.i18n/usage.html) is not\nrendered correctly, it is because the wrong indentation.\n\nThis patch corrects this mistake, and uses a same indentation in cross\nof the whole file.\n\nChange-Id: I74189de25d3611ed6a57cf35fee6682b81056071\nCloses-Bug: #1374477\n'}]",0,124455,26edee1f7fd237e4da93b8eeacbd381127c373a8,10,4,1,6676,,,0,"Use same indentation in doc/source/usage

The first code example for ""Creating an Integration Module""
(http://docs.openstack.org/developer/oslo.i18n/usage.html) is not
rendered correctly, it is because the wrong indentation.

This patch corrects this mistake, and uses a same indentation in cross
of the whole file.

Change-Id: I74189de25d3611ed6a57cf35fee6682b81056071
Closes-Bug: #1374477
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/55/124455/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/usage.rst'],1,26edee1f7fd237e4da93b8eeacbd381127c373a8,bug/1374477," from oslo import i18n The old method of installing a version of ``_()`` in the builtins namespace is deprecated. Modifying the global namespace affects libraries as well as the application, so it may interfere with proper message catalog lookups. Calls to :func:`gettextutils.install` should be replaced with the application or library integration module described here. # WRONG from foo import bar bar() # RIGHT import foo foo.bar() # tox.ini [hacking] import_exceptions = app.i18n from oslo import i18n avail_lang = i18n.get_available_languages('myapp')"," from oslo import i18n The old method of installing a version of ``_()`` in the builtins namespace is deprecated. Modifying the global namespace affects libraries as well as the application, so it may interfere with proper message catalog lookups. Calls to :func:`gettextutils.install` should be replaced with the application or library integration module described here. # WRONG from foo import bar bar() # RIGHT import foo foo.bar() # tox.ini [hacking] import_exceptions = app.i18n from oslo import i18n avail_lang = i18n.get_available_languages('myapp')",19,19
openstack%2Foslo.i18n~master~I2683c22f77b17ca6f7be66fd9ba8ded0e547d981,openstack/oslo.i18n,master,I2683c22f77b17ca6f7be66fd9ba8ded0e547d981,Fixes a small syntax error in the doc examples,MERGED,2014-09-11 17:46:37.000000000,2014-10-04 03:14:17.000000000,2014-10-04 03:14:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6601}]","[{'number': 1, 'created': '2014-09-11 17:46:37.000000000', 'files': ['doc/source/guidelines.rst'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/f721da76f2a3abebc6843869704e9f5afa03e83e', 'message': 'Fixes a small syntax error in the doc examples\n\nChange-Id: I2683c22f77b17ca6f7be66fd9ba8ded0e547d981\n'}]",0,120856,f721da76f2a3abebc6843869704e9f5afa03e83e,8,4,1,7725,,,0,"Fixes a small syntax error in the doc examples

Change-Id: I2683c22f77b17ca6f7be66fd9ba8ded0e547d981
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/56/120856/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/guidelines.rst'],1,f721da76f2a3abebc6843869704e9f5afa03e83e,, raise ValueError(_('some message') + ': variable=%s' % variable), raise ValueError(_('some message') + ': variable=%s') % variable),1,1
openstack%2Fdevstack-gate~master~Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a,openstack/devstack-gate,master,Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a,don't use screen for grenade,MERGED,2014-06-16 12:05:01.000000000,2014-10-04 02:42:44.000000000,2014-10-04 02:42:43.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 8871}, {'_account_id': 9624}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-16 12:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d3282727b6e7dd1efdf528c5c71604e411726b21', 'message': ""don't use screen for grenade\n\nnow that the process stop pieces of devstack work much better,\nit's not clear that we need to actually use screen to stuff in\nthe service starts / stops.\n\nWe should try to do this without screen.\n\nChange-Id: Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a\n""}, {'number': 2, 'created': '2014-09-17 10:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6f4b4088770d0bb31800ef0fb2c9e63b23fe20c3', 'message': ""don't use screen for grenade\n\nnow that the process stop pieces of devstack work much better,\nit's not clear that we need to actually use screen to stuff in\nthe service starts / stops.\n\nWe should try to do this without screen.\n\nChange-Id: Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a\n""}, {'number': 3, 'created': '2014-09-29 11:19:15.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ff2fa032788001c66b068561a24569c36d5cac5c', 'message': ""don't use screen for grenade\n\nnow that the process stop pieces of devstack work much better,\nit's not clear that we need to actually use screen to stuff in\nthe service starts / stops.\n\nWe should try to do this without screen.\n\nChange-Id: Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a\n""}]",0,100229,ff2fa032788001c66b068561a24569c36d5cac5c,37,8,3,2750,,,0,"don't use screen for grenade

now that the process stop pieces of devstack work much better,
it's not clear that we need to actually use screen to stuff in
the service starts / stops.

We should try to do this without screen.

Change-Id: Icc5b9b5f8dcde22f2864d3ba6aa91d0afe936d7a
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/29/100229/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,d3282727b6e7dd1efdf528c5c71604e411726b21,grenade_noscreen,USE_SCREEN=False," else # Grenade needs screen, so only turn this off if we aren't # running grenade. echo ""USE_SCREEN=False"" >>localrc",1,4
openstack%2Ftaskflow~master~Ib8d116637b8edae31e4c8927a28515907855f8bf,openstack/taskflow,master,Ib8d116637b8edae31e4c8927a28515907855f8bf,Jobboard example that show jobs + workers + producers,MERGED,2014-07-17 03:11:49.000000000,2014-10-04 02:12:56.000000000,2014-10-04 02:12:55.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-17 03:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a8b24973e014f15c353f9a3123e8f12aca874760', 'message': 'New jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 2, 'created': '2014-07-17 06:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/adee2fdc1ba6be6c3199179bd34902d11ab054bf', 'message': 'New jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 3, 'created': '2014-07-17 06:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fd10704fcfed8701aec5aa7dd8576d65a393a2c', 'message': 'New jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 4, 'created': '2014-07-17 06:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3b67f36eeb4bae2da9b3179ac01ab4c8665190f8', 'message': 'New jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\nThis also fixes how python3 removed the __cmp__ operator which\nwe were using for sorting the jobs that were posted and now we\nmust use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 5, 'created': '2014-07-17 06:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5a060a192b8888ac9f282d162989717032bf9c86', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 6, 'created': '2014-07-17 08:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/80d75a12f61a41d1faedb9285b71010147dac7a8', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 7, 'created': '2014-07-17 08:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f52146ba8bd7d7bb5ab1ee202407614b79ab23da', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 8, 'created': '2014-07-18 00:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bf589fb04924f8ed4e98a6c05af65f9fcb29767f', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 9, 'created': '2014-07-21 03:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e3adf75dd9089e130b87778953beae57c36eebc6', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 10, 'created': '2014-07-21 03:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d19201ad2bb3ac21e5f43660a43eb6252d57a0b6', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 11, 'created': '2014-07-21 03:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a4e7c45be932a7a81911965db551e54e906acb20', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 12, 'created': '2014-07-21 05:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7240a5aee3c5c6f91755f60bb9b15ae05cd3fb4a', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 13, 'created': '2014-07-21 05:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7a300bf5b6ded44ba0e1f6baa7a3f0f6c0efba52', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 14, 'created': '2014-07-24 19:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6578f7be114adf5de200cd515691d625e4d51bb7', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 15, 'created': '2014-07-28 22:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5601d49342d5d08db3a3187cd605da1876058dfc', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 16, 'created': '2014-08-12 17:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a738fe9dd08502c4c94459452285449f9652c033', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 17, 'created': '2014-09-09 23:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cad002d711649f2afcf290e0871fae9a63f69a63', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 18, 'created': '2014-09-09 23:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/49323566eb1394fc8d05b66b6da82b8531b942e5', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nFixes bug 1367496\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 19, 'created': '2014-09-09 23:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/114e864afac32c20722fd760cb7d44cb8171750b', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nFixes bug 1367496\n\nPart of blueprint more-examples\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}, {'number': 20, 'created': '2014-09-27 21:52:01.000000000', 'files': ['doc/source/examples.rst', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/examples/jobboard_produce_consume_colors.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/15e3962e2a55a35fc2e87889f1a2085163c593ce', 'message': 'Jobboard example that show jobs + workers + producers\n\nAdd a new example that spins up a set of threads to simulate\nthe actual workers and producers that would be normally attached\nto a jobboard and use these threads to producer and consume a\nset of simple jobs (that are filtered on by the workers).\n\n- This also fixes how python3 removed the __cmp__ operator which\n  we were using for sorting the jobs that were posted and now we\n  must use __lt__ instead.\n\nFixes bug 1367496\n\nPart of blueprint more-examples\n\nChange-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf\n'}]",2,107549,15e3962e2a55a35fc2e87889f1a2085163c593ce,66,4,20,1297,,,0,"Jobboard example that show jobs + workers + producers

Add a new example that spins up a set of threads to simulate
the actual workers and producers that would be normally attached
to a jobboard and use these threads to producer and consume a
set of simple jobs (that are filtered on by the workers).

- This also fixes how python3 removed the __cmp__ operator which
  we were using for sorting the jobs that were posted and now we
  must use __lt__ instead.

Fixes bug 1367496

Part of blueprint more-examples

Change-Id: Ib8d116637b8edae31e4c8927a28515907855f8bf
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/49/107549/7 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/examples.rst', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/examples/jobboard_produce_consume_colors.py']",3,a8b24973e014f15c353f9a3123e8f12aca874760,bug/1367496,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import collections import contextlib import functools import logging import os import random import sys import threading import time logging.basicConfig(level=logging.ERROR) top_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)) sys.path.insert(0, top_dir) from zake import fake_client from taskflow import exceptions as excp from taskflow.jobs.backends import impl_zookeeper # In this example we show how a jobboard can be used to post work for other # entities to work on. This example creates a set of jobs using one producer # thread (typically this would be split across many machines) and then having # other worker threads with there own jobboards select work using a given # set of filters and then perform that work (and consuming or abandoning the # job after it has been completed or failed). # Things to note: # - No persistence layer is used (or logbook), just the job details are used # to determine if a job should be selected by a worker or not. # - This example runs in a single process (this is expected to be atypical # but this example shows that it can be done if needed, for testing...) # - Using the jobboard wait() functionality to wait until worker has been # posted (avoiding continous iteration). # - The claim(), consume()/abandon() worker workflow. # - The post() producer workflow. SHARED_CONF = { 'path': ""/taskflow/jobs"", } WAIT_WORK = 1.0 # How many workers and producers of work will be created (as threads). PRODUCERS = 3 WORKERS = 5 # How many units of work each producer will create. PRODUCER_UNITS = 10 # How many units of work are expected to be produced (used so workers can # know when to stop running and shutdown, typically this would not be a # a value but we have to limit this examples execution time to be less than # infinity). EXPECTED_UNITS = PRODUCER_UNITS * PRODUCERS # Delay between producing/consuming more work. WORKER_DELAY, PRODUCER_DELAY = (0.5, 0.5) def dispatch_work(job): # This is where the jobs contained work *would* be done time.sleep(1.0) def color_filter(liked_colors, job): # Filters a job by a color key and a set of liked colors color = job.details.get('color') if color not in liked_colors: return False return True def flip_coin(): return random.choice([True, False]) def worker(ident, client, consumed): # Create a personal board (using the same client so that it works in # the same process) and start looking for jobs on the board that we want # to perform. name = ""W-%s"" % (ident) board = impl_zookeeper.ZookeeperJobBoard(name, SHARED_CONF.copy(), client=client) board.connect() if flip_coin(): job_filters = [functools.partial(color_filter, frozenset(['blue']))] else: job_filters = [functools.partial(color_filter, frozenset(['red']))] claimed_jobs = 0 consumed_jobs = 0 abandoned_jobs = 0 with contextlib.closing(board): while len(consumed) != EXPECTED_UNITS: try: it = board.wait(timeout=WAIT_WORK) except excp.NotFound: pass else: for job in it: # See if we should even bother with it... if any((not func(job) for func in job_filters)): continue try: board.claim(job, name) claimed_jobs += 1 print(""%s: '%s' [claimed]"" % (name, job)) except (excp.NotFound, excp.UnclaimableJob): pass else: try: dispatch_work(job) board.consume(job, name) print(""%s: '%s' [consumed]"" % (name, job)) consumed_jobs += 1 consumed.append(job) except Exception: board.abandon(job, name) abandoned_jobs += 1 print(""%s: '%s' [abandoned]"" % (name, job)) time.sleep(WORKER_DELAY) print(""%s: finished (claimed %s jobs,"" "" consumed %s jobs, abandoned %s jobs)"" % (name, claimed_jobs, consumed_jobs, abandoned_jobs)) def producer(ident, client): # Create a personal board (using the same client so that it works in # the same process) and start posting jobs on the board that we want # some entity to perform. name = ""P-%s"" % (ident) board = impl_zookeeper.ZookeeperJobBoard(name, SHARED_CONF.copy(), client=client) board.connect() with contextlib.closing(board): for i in range(0, PRODUCER_UNITS): job_name = ""%s-%s"" % (name, i) details = { 'color': random.choice(['red', 'blue']), } job = board.post(job_name, book=None, details=details) print(""%s: '%s' [posted]"" % (name, job)) time.sleep(PRODUCER_DELAY) def main(): with contextlib.closing(fake_client.FakeClient()) as c: created = [] for i in range(0, PRODUCERS): p = threading.Thread(target=producer, args=(i + 1, c)) p.daemon = True created.append(p) p.start() consumed = collections.deque() for i in range(0, WORKERS): w = threading.Thread(target=worker, args=(i + 1, c, consumed)) w.daemon = True created.append(w) w.start() while created: t = created.pop() t.join() # At the end there should be nothing leftover, let's verify that. board = impl_zookeeper.ZookeeperJobBoard(""verifier"", SHARED_CONF.copy(), client=c) board.connect() with contextlib.closing(board): if board.job_count != 0: return 1 else: return 0 if __name__ == ""__main__"": sys.exit(main()) ",,207,1
openstack%2Fswift~master~I6c0bc1570f6a48439de5a029a86f1b582f30f8a6,openstack/swift,master,I6c0bc1570f6a48439de5a029a86f1b582f30f8a6,updated AUTHORS and CHANGELOG for 2.2.0,MERGED,2014-10-03 22:38:37.000000000,2014-10-04 02:11:20.000000000,2014-10-04 02:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 8871}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-03 22:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f8db1d955ed01c4d4714ed713dd808d240fe8d15', 'message': 'updated AUTHORS and CHANGELOG for 2.2.0\n\nChange-Id: I6c0bc1570f6a48439de5a029a86f1b582f30f8a6\n'}, {'number': 2, 'created': '2014-10-03 22:52:29.000000000', 'files': ['CHANGELOG', '.mailmap', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/d6a827792619f3343af07fc2519f4253fbdc67f7', 'message': 'updated AUTHORS and CHANGELOG for 2.2.0\n\nChange-Id: I6c0bc1570f6a48439de5a029a86f1b582f30f8a6\n'}]",0,126091,d6a827792619f3343af07fc2519f4253fbdc67f7,13,4,2,330,,,0,"updated AUTHORS and CHANGELOG for 2.2.0

Change-Id: I6c0bc1570f6a48439de5a029a86f1b582f30f8a6
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/126091/1 && git format-patch -1 --stdout FETCH_HEAD,"['CHANGELOG', '.mailmap', 'AUTHORS']",3,f8db1d955ed01c4d4714ed713dd808d240fe8d15,acu,Keshava Bharadwaj (kb.sankethi@gmail.com)Lorcan Browne (lorcan.browne@hp.com)Jay S. Bryant (jsbryant@us.ibm.com)Mahati Chamarthy (mahati.chamarthy@gmail.com)Thiago da Silva (thiago@redhat.com)Gerry Drudy (gerry.drudy@hp.com)Andrew Hale (andy@wwwdata.eu)Andreas Jaeger (aj@suse.de)Nathan Kinder (nkinder@redhat.com)John Leach (john@johnleach.co.uk)Dolph Mathews (dolph.mathews@gmail.com)Timothy Okwii (tokwii@cisco.com)Matt Riedemann (mriedem@us.ibm.com)Rafael Rivero (rafael@cloudscaling.com)saranjan (saranjan@cisco.com),Thiago da Silva (thiago@redhat.com),70,1
openstack%2Foslo.messaging~master~Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a,openstack/oslo.messaging,master,Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a,Enable oslo.i18n for oslo.messaging,MERGED,2014-09-09 22:37:30.000000000,2014-10-04 02:10:02.000000000,2014-10-04 02:10:02.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6601}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-09-09 22:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/42354fb413b67b4a01dd98d2b48848752be88688', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 2, 'created': '2014-09-10 01:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5f1eff28b6b8e48e5ae5936662be18f7cedf4b5a', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 3, 'created': '2014-09-17 13:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/61e0b3b1adfefe2b36faa813c66abfff85bede23', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 4, 'created': '2014-09-17 18:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/997378f25caf07f182fb7293b8d8bdd021204a12', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 5, 'created': '2014-09-21 23:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4bf2b0f6ea92a61ab774f232478f8ee00eaf570c', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 6, 'created': '2014-09-22 01:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/68938f461119a891c2e5e0ad7ed98a739efe9c11', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}, {'number': 7, 'created': '2014-09-25 02:19:04.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo.messaging/locale/oslo.messaging.pot', 'oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_i18n.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/_drivers/impl_zmq.py', 'requirements.txt', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/rpc/dispatcher.py', 'openstack-common.conf', 'requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/487bbf5b13f33c56d82a2ce8fc1b9b280519aa2c', 'message': 'Enable oslo.i18n for oslo.messaging\n\nChange-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a\n'}]",0,120270,487bbf5b13f33c56d82a2ce8fc1b9b280519aa2c,34,7,7,5638,,,0,"Enable oslo.i18n for oslo.messaging

Change-Id: Ic8e05ae4ffe3eb871ae64243c41a9955f47cbe2a
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/70/120270/6 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo.messaging/locale/oslo.messaging.pot', 'oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_i18n.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/_drivers/impl_zmq.py', 'requirements.txt', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/rpc/dispatcher.py', 'openstack-common.conf', 'requirements-py3.txt', 'tox.ini']",14,42354fb413b67b4a01dd98d2b48848752be88688,, oslo.messaging._i18n,,312,9
openstack%2Fpython-openstackclient~master~Ic258ded80612d31bd3017fce65000b619026e844,openstack/python-openstackclient,master,Ic258ded80612d31bd3017fce65000b619026e844,Update gitignore,MERGED,2014-10-03 23:36:00.000000000,2014-10-04 02:09:52.000000000,2014-10-04 02:09:52.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-03 23:36:00.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0cb204e59b20f25b7a054b411507d6dabbc699ac', 'message': 'Update gitignore\n\nadd .project and .pydevproject to gitignore\n\nChange-Id: Ic258ded80612d31bd3017fce65000b619026e844\n'}]",0,126099,0cb204e59b20f25b7a054b411507d6dabbc699ac,6,2,1,6482,,,0,"Update gitignore

add .project and .pydevproject to gitignore

Change-Id: Ic258ded80612d31bd3017fce65000b619026e844
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/99/126099/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,0cb204e59b20f25b7a054b411507d6dabbc699ac,update_git_ignore,# Development environment files .project .pydevproject,,3,0
openstack%2Foslo.vmware~master~If97d1d95341db9fbc33f6824ff326ee3fc64d8ee,openstack/oslo.vmware,master,If97d1d95341db9fbc33f6824ff326ee3fc64d8ee,Switch to using oslo.utils,MERGED,2014-09-25 15:55:42.000000000,2014-10-04 01:59:28.000000000,2014-10-04 01:59:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5367}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-09-25 15:55:42.000000000', 'files': ['oslo/vmware/openstack/__init__.py', 'oslo/vmware/openstack/common/__init__.py', 'oslo/vmware/api.py', 'oslo/vmware/openstack/common/gettextutils.py', 'oslo/vmware/openstack/common/importutils.py', 'doc/source/conf.py', 'oslo/vmware/openstack/common/units.py', 'oslo/vmware/openstack/common/excutils.py', 'oslo/vmware/openstack/common/timeutils.py', 'requirements.txt', 'oslo/vmware/rw_handles.py', 'oslo/vmware/openstack/common/jsonutils.py', 'openstack-common.conf', 'oslo/vmware/vim_util.py', 'tests/test_service.py', 'oslo/vmware/common/loopingcall.py', 'oslo/vmware/service.py', 'oslo/vmware/openstack/common/local.py', 'tests/objects/test_datastore.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/df59368f76eb56fdd64ff9dac23eed805a7f07c8', 'message': 'Switch to using oslo.utils\n\nChange-Id: If97d1d95341db9fbc33f6824ff326ee3fc64d8ee\n'}]",0,124091,df59368f76eb56fdd64ff9dac23eed805a7f07c8,12,5,1,5638,,,0,"Switch to using oslo.utils

Change-Id: If97d1d95341db9fbc33f6824ff326ee3fc64d8ee
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/91/124091/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/openstack/__init__.py', 'oslo/vmware/openstack/common/__init__.py', 'oslo/vmware/api.py', 'oslo/vmware/openstack/common/gettextutils.py', 'oslo/vmware/openstack/common/importutils.py', 'doc/source/conf.py', 'oslo/vmware/openstack/common/units.py', 'oslo/vmware/openstack/common/excutils.py', 'oslo/vmware/openstack/common/timeutils.py', 'requirements.txt', 'oslo/vmware/rw_handles.py', 'oslo/vmware/openstack/common/jsonutils.py', 'openstack-common.conf', 'oslo/vmware/vim_util.py', 'tests/test_service.py', 'oslo/vmware/common/loopingcall.py', 'oslo/vmware/service.py', 'oslo/vmware/openstack/common/local.py', 'tests/objects/test_datastore.py']",19,df59368f76eb56fdd64ff9dac23eed805a7f07c8,,from oslo.utils import units,from oslo.vmware.openstack.common import units,8,1188
openstack%2Foslo.middleware~master~I99b5c30b7d7feb00eed1c9b4c7c8a0df4e41da84,openstack/oslo.middleware,master,I99b5c30b7d7feb00eed1c9b4c7c8a0df4e41da84,Support building wheels (PEP-427),MERGED,2014-10-02 20:19:48.000000000,2014-10-04 01:51:27.000000000,2014-10-04 01:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-02 20:19:48.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/9ccefd8e6224ee3fb9425a3c95b4cc82bbb068ec', 'message': 'Support building wheels (PEP-427)\n\nUniversal is used to identify pure-Python module(by bdist_wheel). For\nthese, it is sufficient to build a wheel with _any_ Python ABI version\nand publish that to PyPI (by whatever means).\n\nChange-Id: I99b5c30b7d7feb00eed1c9b4c7c8a0df4e41da84\n'}]",0,125766,9ccefd8e6224ee3fb9425a3c95b4cc82bbb068ec,11,4,1,5638,,,0,"Support building wheels (PEP-427)

Universal is used to identify pure-Python module(by bdist_wheel). For
these, it is sufficient to build a wheel with _any_ Python ABI version
and publish that to PyPI (by whatever means).

Change-Id: I99b5c30b7d7feb00eed1c9b4c7c8a0df4e41da84
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/66/125766/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9ccefd8e6224ee3fb9425a3c95b4cc82bbb068ec,,warnerrors = True [wheel] universal = 1 ,warnerrors = True,4,1
openstack%2Foslo.middleware~master~I72263bd363a79275a314de727a04277276866565,openstack/oslo.middleware,master,I72263bd363a79275a314de727a04277276866565,Expose sizelimit option to config generator,MERGED,2014-09-30 21:52:23.000000000,2014-10-04 01:51:20.000000000,2014-10-04 01:51:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-09-30 21:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/d220527b38530867212bc1863e04404de12ee990', 'message': ""Expose sizelimit option to config generator\n\n* Adding a group name to prevent collision with keystone\n  middleware library option\n* Adds an opts module for the config generator to use.\n* Makes the option in sizelimit private since we don't want consumers\n  using them directly.\n* Moves the options to an oslo_middleware group with appropriate\n  deprecated_opts settings to keep existing configs working.\n\nCloses-Bug: #1368490\nChange-Id: I72263bd363a79275a314de727a04277276866565\n""}, {'number': 2, 'created': '2014-10-01 12:16:17.000000000', 'files': ['oslo/middleware/sizelimit.py', 'setup.cfg', 'tests/test_sizelimit.py', 'oslo/middleware/opts.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/7ee3b0f459760e2d80422b0a35024b0b5a85509b', 'message': ""Expose sizelimit option to config generator\n\n* Adding a group name to prevent collision with keystone\n  middleware library option\n* Adds an opts module for the config generator to use.\n* Makes the option in sizelimit private since we don't want consumers\n  using them directly.\n* Moves the options to an oslo_middleware group with appropriate\n  deprecated_opts settings to keep existing configs working.\n\nCloses-Bug: #1368490\nChange-Id: I72263bd363a79275a314de727a04277276866565\n""}]",1,125211,7ee3b0f459760e2d80422b0a35024b0b5a85509b,18,5,2,5638,,,0,"Expose sizelimit option to config generator

* Adding a group name to prevent collision with keystone
  middleware library option
* Adds an opts module for the config generator to use.
* Makes the option in sizelimit private since we don't want consumers
  using them directly.
* Moves the options to an oslo_middleware group with appropriate
  deprecated_opts settings to keep existing configs working.

Closes-Bug: #1368490
Change-Id: I72263bd363a79275a314de727a04277276866565
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/11/125211/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/middleware/sizelimit.py', 'oslo/middleware/opts.py', 'tests/test_sizelimit.py']",3,d220527b38530867212bc1863e04404de12ee990,bug/1368490, fixture = self.useFixture(config.Config(sizelimit.CONF)) fixture.conf.oslo_middleware.max_request_body_size, self.useFixture(config.Config()).conf.max_request_body_size,66,12
openstack%2Foslo.utils~master~I98d3c4f9f6f6e7045d9b28fc98b1141d246aa08e,openstack/oslo.utils,master,I98d3c4f9f6f6e7045d9b28fc98b1141d246aa08e,Support building wheels (PEP-427),MERGED,2014-10-02 20:19:57.000000000,2014-10-04 01:51:04.000000000,2014-10-04 01:51:03.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-10-02 20:19:57.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/c6bdccedcb41617b16a694d81bc93ab3867683f5', 'message': 'Support building wheels (PEP-427)\n\nUniversal is used to identify pure-Python module(by bdist_wheel). For\nthese, it is sufficient to build a wheel with _any_ Python ABI version\nand publish that to PyPI (by whatever means).\n\nChange-Id: I98d3c4f9f6f6e7045d9b28fc98b1141d246aa08e\n'}]",0,125769,c6bdccedcb41617b16a694d81bc93ab3867683f5,13,5,1,5638,,,0,"Support building wheels (PEP-427)

Universal is used to identify pure-Python module(by bdist_wheel). For
these, it is sufficient to build a wheel with _any_ Python ABI version
and publish that to PyPI (by whatever means).

Change-Id: I98d3c4f9f6f6e7045d9b28fc98b1141d246aa08e
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/69/125769/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c6bdccedcb41617b16a694d81bc93ab3867683f5,, [wheel] universal = 1,,3,0
openstack%2Foslo.vmware~master~I1b99d37fdbcbf5ea05e4823e408468a06e230ccf,openstack/oslo.vmware,master,I1b99d37fdbcbf5ea05e4823e408468a06e230ccf,Fix handling of fault details,MERGED,2014-10-03 14:28:33.000000000,2014-10-04 01:49:13.000000000,2014-10-04 01:49:12.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-10-03 14:28:33.000000000', 'files': ['oslo/vmware/service.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/2350257410610b6a0ebf9b28ab9fcddc5551ca87', 'message': ""Fix handling of fault details\n\nFix regression caused by adding a new transport based on 'requests'\nin commit 4bd0b4cf. When a Fault message is returned from the backed,\nthe 'Envelope' and 'Body' tags are stripped and the root element becomes\n'Fault'. The path to the 'detail' string becomes '/detail' instead of\n'/Envelope/Body/Fault/detail'. The stripping is done in:\n\nsuds/bindings/binding.py#detect_fault()\n\nwhich was not executed when the old http transport was used.\n\nChange-Id: I1b99d37fdbcbf5ea05e4823e408468a06e230ccf\n""}]",0,125982,2350257410610b6a0ebf9b28ab9fcddc5551ca87,14,7,1,9172,,,0,"Fix handling of fault details

Fix regression caused by adding a new transport based on 'requests'
in commit 4bd0b4cf. When a Fault message is returned from the backed,
the 'Envelope' and 'Body' tags are stripped and the root element becomes
'Fault'. The path to the 'detail' string becomes '/detail' instead of
'/Envelope/Body/Fault/detail'. The stripping is done in:

suds/bindings/binding.py#detect_fault()

which was not executed when the old http transport was used.

Change-Id: I1b99d37fdbcbf5ea05e4823e408468a06e230ccf
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/82/125982/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/vmware/service.py'],1,2350257410610b6a0ebf9b28ab9fcddc5551ca87,fix-faults, detail = doc.childAtPath('/detail'), detail = doc.childAtPath('/Envelope/Body/Fault/detail'),1,1
openstack%2Foslo.serialization~master~I11754deadcf1a56c2c9e3de65447eb3926819fba,openstack/oslo.serialization,master,I11754deadcf1a56c2c9e3de65447eb3926819fba,Add history/changelog to docs,MERGED,2014-09-10 13:54:12.000000000,2014-10-04 01:45:49.000000000,2014-10-04 01:45:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-09-10 13:54:12.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/9498865451eab6ceca32adc6356bb30dd55d2db1', 'message': 'Add history/changelog to docs\n\nChange-Id: I11754deadcf1a56c2c9e3de65447eb3926819fba\n'}]",0,120420,9498865451eab6ceca32adc6356bb30dd55d2db1,11,4,1,5638,,,0,"Add history/changelog to docs

Change-Id: I11754deadcf1a56c2c9e3de65447eb3926819fba
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/20/120420/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,9498865451eab6ceca32adc6356bb30dd55d2db1,,,,1,1
openstack%2Foslo.serialization~master~Iabce8b1e10e141c09a8b9dd34c4a1539174c6438,openstack/oslo.serialization,master,Iabce8b1e10e141c09a8b9dd34c4a1539174c6438,Support building wheels (PEP-427),MERGED,2014-10-02 20:19:54.000000000,2014-10-04 01:37:50.000000000,2014-10-04 01:37:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-02 20:19:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/ce89925a0e09d0e2e2f51ee3edfe1564de39ce1f', 'message': 'Support building wheels (PEP-427)\n\nUniversal is used to identify pure-Python module(by bdist_wheel). For\nthese, it is sufficient to build a wheel with _any_ Python ABI version\nand publish that to PyPI (by whatever means).\n\nChange-Id: Iabce8b1e10e141c09a8b9dd34c4a1539174c6438\n'}]",0,125768,ce89925a0e09d0e2e2f51ee3edfe1564de39ce1f,11,4,1,5638,,,0,"Support building wheels (PEP-427)

Universal is used to identify pure-Python module(by bdist_wheel). For
these, it is sufficient to build a wheel with _any_ Python ABI version
and publish that to PyPI (by whatever means).

Change-Id: Iabce8b1e10e141c09a8b9dd34c4a1539174c6438
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/68/125768/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ce89925a0e09d0e2e2f51ee3edfe1564de39ce1f,, [wheel] universal = 1,,3,0
openstack%2Ftrove~master~Ic84f10e13b6dc9ea70575dcea3bd2104007f1d56,openstack/trove,master,Ic84f10e13b6dc9ea70575dcea3bd2104007f1d56,Docs: Fix Sphinx warnings,MERGED,2014-10-02 07:27:07.000000000,2014-10-04 01:34:18.000000000,2014-10-04 01:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10683}]","[{'number': 1, 'created': '2014-10-02 07:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/34f324742cc4733f324170865c83f6ccdca7b449', 'message': 'Docs: Fix Sphinx warnings\n\nSphinx emits warnings messages when building docs. Correct identation fixes this.\n\nChange-Id: Ic84f10e13b6dc9ea70575dcea3bd2104007f1d56\nCloses-Bug:1333205\n'}, {'number': 2, 'created': '2014-10-02 17:58:53.000000000', 'files': ['doc/source/dev/manual_install.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/a681bea3429fba5895e52ad62e785e1dddf87180', 'message': 'Docs: Fix Sphinx warnings\n\nSphinx emits warnings messages when building docs. Correct identation fixes this.\n\nChange-Id: Ic84f10e13b6dc9ea70575dcea3bd2104007f1d56\nCloses-Bug:1333205\n'}]",0,125564,a681bea3429fba5895e52ad62e785e1dddf87180,24,7,2,12135,,,0,"Docs: Fix Sphinx warnings

Sphinx emits warnings messages when building docs. Correct identation fixes this.

Change-Id: Ic84f10e13b6dc9ea70575dcea3bd2104007f1d56
Closes-Bug:1333205
",git fetch https://review.opendev.org/openstack/trove refs/changes/64/125564/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,34f324742cc4733f324170865c83f6ccdca7b449,bug/1333205,,,1,0
openstack%2Foslo.middleware~master~I99c6b951c8b6992a442b194ad480ca0418def520,openstack/oslo.middleware,master,I99c6b951c8b6992a442b194ad480ca0418def520,Imported Translations from Transifex,MERGED,2014-10-03 06:07:24.000000000,2014-10-04 01:32:00.000000000,2014-10-04 01:31:59.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-03 06:07:24.000000000', 'files': ['oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-critical.po', 'oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-info.po', 'oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-warning.po'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/c32959f2614af3996d1430def0014cb5fa9c28c1', 'message': 'Imported Translations from Transifex\n\nChange-Id: I99c6b951c8b6992a442b194ad480ca0418def520\n'}]",0,125878,c32959f2614af3996d1430def0014cb5fa9c28c1,18,5,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I99c6b951c8b6992a442b194ad480ca0418def520
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/78/125878/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-critical.po', 'oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-info.po', 'oslo.middleware/locale/fr/LC_MESSAGES/oslo.middleware-log-warning.po']",3,c32959f2614af3996d1430def0014cb5fa9c28c1,transifex/translations,,"# Translations template for heat. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the heat project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: oslo.middleware\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-09-26 06:00+0000\n"" ""PO-Revision-Date: 2014-09-25 08:48+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language-Team: French (http://www.transifex.com/projects/p/oslomiddleware/"" ""language/fr/)\n"" ""Language: fr\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" ",0,63
openstack%2Fkeystone~master~I3b91d8023d31555893fb944da73633a69d8e286f,openstack/keystone,master,I3b91d8023d31555893fb944da73633a69d8e286f,Fixes an error deleting an endpoint group project,MERGED,2014-10-03 20:04:21.000000000,2014-10-04 01:31:04.000000000,2014-10-04 01:31:04.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-03 20:04:21.000000000', 'files': ['keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/contrib/endpoint_filter/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aa5abc0d0d29501791777c734319c45611677824', 'message': ""Fixes an error deleting an endpoint group project\n\nDeleting a endpoint group project fails because the router specifies\na controller method that doesn't exist. This returns a 500 error to\nthe user for what should be a successful operation.\n\nChange-Id: I3b91d8023d31555893fb944da73633a69d8e286f\nCloses-bug: #1377304\n""}]",0,126050,aa5abc0d0d29501791777c734319c45611677824,7,3,1,7725,,,0,"Fixes an error deleting an endpoint group project

Deleting a endpoint group project fails because the router specifies
a controller method that doesn't exist. This returns a 500 error to
the user for what should be a successful operation.

Change-Id: I3b91d8023d31555893fb944da73633a69d8e286f
Closes-bug: #1377304
",git fetch https://review.opendev.org/openstack/keystone refs/changes/50/126050/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/contrib/endpoint_filter/controllers.py']",2,aa5abc0d0d29501791777c734319c45611677824,bug/1377304," @controller.protected() def remove_endpoint_group_from_project(self, context, endpoint_group_id, project_id): """"""Remove the endpoint group from associated project."""""" self.assignment_api.get_project(project_id) self.endpoint_filter_api.get_endpoint_group(endpoint_group_id) self.endpoint_filter_api.remove_endpoint_group_from_project( endpoint_group_id, project_id) "," def remove_endpoint_group_from_project(self, context, endpoint_group_id, project_id): """"""Remove the endpoint group from associated project."""""" self.assignment_api.get_project(project_id) self.endpoint_filter_api.get_endpoint_group(endpoint_group_id) self.endpoint_filter_api.remove_endpoint_group_from_project( endpoint_group_id, project_id) @controller.protected()",23,9
openstack%2Fswift~master~I51eb24702c422299629f8053d4591dd10f5863f8,openstack/swift,master,I51eb24702c422299629f8053d4591dd10f5863f8,Provides proper error handling on builder unpickle,MERGED,2014-09-17 19:23:56.000000000,2014-10-04 01:31:01.000000000,2014-10-04 01:31:00.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 9051}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-17 19:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57bbbd81299157d1a243fee158f1d772900dea14', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 2, 'created': '2014-09-18 16:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/459ab83f79736641a18281cb6955098942044d7d', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 3, 'created': '2014-09-18 17:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5ccb329083af85ea1a1da45a9f4f6c7fa650c951', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 4, 'created': '2014-09-19 04:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0d605b6c4f219b7797fa2514f69fdc3a1934056e', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 5, 'created': '2014-09-23 17:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/848219591ff062a07193bb73455259a0d713b2fb', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 6, 'created': '2014-09-25 14:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/748938ee5d64ab02999c2e5e818a7c8c79b2ae8c', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}, {'number': 7, 'created': '2014-09-26 04:15:44.000000000', 'files': ['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py', 'swift/cli/ringbuilder.py', 'test/unit/cli/test_ringbuilder.py', 'swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/38ba5790fb527967c2fcbaf094e76a73f4b94d38', 'message': 'Provides proper error handling on builder unpickle\n\nThis patch provides the necessary error handling while unpickling\na builder file. Earlier if a builder file is empty/invalid/corrupted,\nthe stacktrace was shown to user with an exit code of 1. This fixes it\nto show a user-friendly message and also returns the exit code of 2,\nindicating there was a failure.\n\nChange-Id: I51eb24702c422299629f8053d4591dd10f5863f8\nCloses-Bug: #1370680\n'}]",24,122225,38ba5790fb527967c2fcbaf094e76a73f4b94d38,55,8,7,9051,,,0,"Provides proper error handling on builder unpickle

This patch provides the necessary error handling while unpickling
a builder file. Earlier if a builder file is empty/invalid/corrupted,
the stacktrace was shown to user with an exit code of 1. This fixes it
to show a user-friendly message and also returns the exit code of 2,
indicating there was a failure.

Change-Id: I51eb24702c422299629f8053d4591dd10f5863f8
Closes-Bug: #1370680
",git fetch https://review.opendev.org/openstack/swift refs/changes/25/122225/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py', 'swift/cli/ringbuilder.py', 'test/unit/cli/test_ringbuilder.py', 'swift/common/exceptions.py']",5,57bbbd81299157d1a243fee158f1d772900dea14,bug/1370680,class UnPicklingError(SwiftException): pass ,,69,2
openstack%2Fswift~master~I39ddf70dc2d027b7db6e31097400248dc66eb137,openstack/swift,master,I39ddf70dc2d027b7db6e31097400248dc66eb137,Fix up the return value of launch(),MERGED,2014-09-29 18:58:01.000000000,2014-10-04 01:30:57.000000000,2014-10-04 01:30:56.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 995}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-29 18:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6b3273c69d43c19911476316ad792cf264b0ae94', 'message': 'Fix up the return value of launch()\n\nThis is ""obviously"" the right thing to do, except of course it\'s\npure sugar: the return value is not used anywhere. Except if someone\nhas a script that imports the whole thing somehow and then does\nisinstance(dict). Because that is so much easier than submitting\na patch, I can imagine someone, somewhere doing that.\n\nThe fix came in a patch by dfg, see review 121851.\n\nChange-Id: I39ddf70dc2d027b7db6e31097400248dc66eb137\n'}, {'number': 2, 'created': '2014-09-29 20:56:53.000000000', 'files': ['test/unit/common/test_manager.py', 'swift/common/manager.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2ce6341b527e81a43513adef6f5c54b4e09e27a4', 'message': 'Fix up the return value of launch()\n\nThis is ""obviously"" the right thing to do, except of course it\'s\npure sugar: the return value is not used anywhere. Except if someone\nhas a script that imports the whole thing somehow and then does\nisinstance(dict). Because that is so much easier than submitting\na patch, I can imagine someone, somewhere doing that.\n\nThe fix came in a patch by dfg, see review 121851.\n\nChange-Id: I39ddf70dc2d027b7db6e31097400248dc66eb137\n'}]",0,124831,2ce6341b527e81a43513adef6f5c54b4e09e27a4,16,7,2,597,,,0,"Fix up the return value of launch()

This is ""obviously"" the right thing to do, except of course it's
pure sugar: the return value is not used anywhere. Except if someone
has a script that imports the whole thing somehow and then does
isinstance(dict). Because that is so much easier than submitting
a patch, I can imagine someone, somewhere doing that.

The fix came in a patch by dfg, see review 121851.

Change-Id: I39ddf70dc2d027b7db6e31097400248dc66eb137
",git fetch https://review.opendev.org/openstack/swift refs/changes/31/124831/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/manager.py', 'test/unit/common/test_manager.py']",2,6b3273c69d43c19911476316ad792cf264b0ae94,launch, retun {} return {} return {} self.called['launch'].append(kwargs) return {}, return self.called['launch'].append(kwargs),7,3
openstack%2Fdjango_openstack_auth~master~Iddc263b865f25bb68cabb8e35378e01aa22bf72f,openstack/django_openstack_auth,master,Iddc263b865f25bb68cabb8e35378e01aa22bf72f,Auth Plugins,ABANDONED,2014-10-04 01:15:05.000000000,2014-10-04 01:15:52.000000000,,[],"[{'number': 1, 'created': '2014-10-04 01:15:05.000000000', 'files': ['openstack_auth/backend.py', 'openstack_auth/utils.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/7099aefb4443ffe86ea054768c438283082385a2', 'message': 'Auth Plugins\n\nAuthenticate to Keystone using the Password and token auth plugins\nThis is a prerequisite to using a wider arry of client plugins.\n\n Change-Id: Idd9ad5044e998a6c514f6161f5159b44391a0849\n\nChange-Id: Iddc263b865f25bb68cabb8e35378e01aa22bf72f\n'}]",0,126106,7099aefb4443ffe86ea054768c438283082385a2,2,0,1,2218,,,0,"Auth Plugins

Authenticate to Keystone using the Password and token auth plugins
This is a prerequisite to using a wider arry of client plugins.

 Change-Id: Idd9ad5044e998a6c514f6161f5159b44391a0849

Change-Id: Iddc263b865f25bb68cabb8e35378e01aa22bf72f
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/06/126106/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/backend.py', 'openstack_auth/utils.py']",2,7099aefb4443ffe86ea054768c438283082385a2,auth-plugins,"from keystoneclient.auth.identity import v2 from keystoneclient.auth.identity import v3 from keystoneclient import sessiondef get_project_list(user_id, auth_url, token, insecure, cacert, debug): auth_plugin = get_token_plugin(auth_url, token) client = create_client(auth_plugin, insecure, cacert, debug) projects = get_projects_from_client(client, user_id) def get_projects_from_client(client, user_id): if get_keystone_version() < 3: projects = client.tenants.list() else: projects = client.projects.list(user=user_id) return projects def set_plugin_project_id(auth_plugin, project_id): if get_keystone_version() < 3: auth_plugin.tenant_id = project_id else: auth_plugin.project_id = project_id def get_password_plugin(auth_url, username, password, user_domain_name): if get_keystone_version() >= 3: auth_url = auth_url.replace('v2.0', 'v3') auth_plugin = v3.Password(auth_url=auth_url, username=username, password=password, user_domain_name=user_domain_name) else: auth_plugin = v2.Password(auth_url=auth_url, username=username, password=password) return auth_plugin def get_token_plugin(auth_url, token): if get_keystone_version() >= 3: if auth_url.find(""v2.0"") >= 0: auth_url = auth_url.replace('v2.0', 'v3') auth_plugin = v3.Token(auth_url=auth_url, token=token) else: auth_plugin = v2.Token(auth_url=auth_url, token=token) return auth_plugin def create_client(auth_plugin, insecure, cacert, debug): sess = session.Session(auth=auth_plugin, verify=cacert) keystone_client = get_keystone_client() client = keystone_client.Client(session=sess, insecure=insecure, cacert=cacert, debug=settings.DEBUG) return client def force_authenticate(client): client.session.get_token() auth_plugin = client.session.auth auth_ref = auth_plugin.auth_ref client.auth_ref = auth_ref client.process_token() return auth_ref","def get_project_list(*args, **kwargs): if get_keystone_version() < 3: auth_url = url_path_replace( kwargs.get('auth_url', ''), '/v3', '/v2.0', 1) kwargs['auth_url'] = auth_url client = get_keystone_client().Client(*args, **kwargs) projects = client.tenants.list() else: auth_url = url_path_replace( kwargs.get('auth_url', ''), '/v2.0', '/v3', 1) kwargs['auth_url'] = auth_url client = get_keystone_client().Client(*args, **kwargs) client.management_url = auth_url projects = client.projects.list(user=kwargs.get('user_id')) ",86,39
openstack%2Fhorizon~master~I42b58e73fd3990c5b5e197e5694eb77eeb42f77c,openstack/horizon,master,I42b58e73fd3990c5b5e197e5694eb77eeb42f77c,Change page header heading to H1,MERGED,2014-08-19 15:30:08.000000000,2014-10-04 00:06:50.000000000,2014-10-04 00:06:49.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 7699}, {'_account_id': 8648}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 11592}, {'_account_id': 11997}]","[{'number': 1, 'created': '2014-08-19 15:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3032626b9134faf793316a290af40b7fc48b4fb5', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 2, 'created': '2014-08-20 13:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b4ba4984ae8cddfe2dd7f4449e749f8e41bb52da', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 3, 'created': '2014-08-25 10:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5e135391831371364d4ec98610eee1be2c260a3c', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 4, 'created': '2014-08-25 12:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f7200719eedd2718c1b492897d0bd957d1fe97fc', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 5, 'created': '2014-08-25 17:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/147c137668969706cfd49371bb8fcdadada974ef', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 6, 'created': '2014-08-26 09:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b15c0b9379b4686b289ae78902640c278cf6b9e', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 7, 'created': '2014-08-26 11:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/79901ebdf131564c7e6c8e766372a92d4ca0ae8c', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 8, 'created': '2014-09-01 11:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9cfe2457b82833ef3381cc4533e53c598a06b6c9', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 9, 'created': '2014-09-03 10:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b015fda1cc0d96f96b1149db1d82d778a9115a0f', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 10, 'created': '2014-09-04 11:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c855dfe9cb2b78b8e83fa6ea6a95080cc2758e44', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 11, 'created': '2014-09-08 09:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4cf034be9d842897003f63b6ee0ffdc70100c5e3', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}, {'number': 12, 'created': '2014-09-11 11:34:34.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'horizon/templates/horizon/common/_page_header.html', 'openstack_dashboard/dashboards/project/volumes/backups/tests.py', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'horizon/templates/horizon/common/_domain_page_header.html', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/61f0198a0d54ba8ef01bf69638ebc144ea2aef85', 'message': 'Change page header heading to H1\n\nPartially implements: blueprint detail-pages-ia\n\nChange-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c\n'}]",2,115320,61f0198a0d54ba8ef01bf69638ebc144ea2aef85,52,11,12,9317,,,0,"Change page header heading to H1

Partially implements: blueprint detail-pages-ia

Change-Id: I42b58e73fd3990c5b5e197e5694eb77eeb42f77c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/20/115320/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'horizon/templates/horizon/common/_page_header.html', 'openstack_dashboard/dashboards/project/volumes/backups/tests.py', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'horizon/templates/horizon/common/_domain_page_header.html', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tests.py']",8,3032626b9134faf793316a290af40b7fc48b4fb5,bp/detail-pages-ia," ""<h1>Volume Snapshot Details: %s</h1>"" %"," ""<h2>Volume Snapshot Details: %s</h2>"" %",9,9
openstack%2Fheat~master~I174429c16bb606c5c325ee8b62c6e600ea77a6e6,openstack/heat,master,I174429c16bb606c5c325ee8b62c6e600ea77a6e6,Support classes for heat integration tests,MERGED,2014-07-29 23:07:18.000000000,2014-10-04 00:05:34.000000000,2014-10-04 00:05:33.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-07-29 23:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/56c759c8d186277c3d0a19519a30cfc13fdb514c', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nSince these tests are in the standard heat tree, these tests will be\nskipped if their preconditions are not met, specifically:\n* Skip all tests if there is no auth_url defined\n* Skip tests which boot servers if there is no glance image with the\n  exact required image name\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 2, 'created': '2014-07-31 00:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/49cac7aaaad259c36d9a4f93f2d55de0697494f8', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 3, 'created': '2014-08-04 00:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/23d95cc952ff73b3e3ec7732e83457bac9776f0d', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 4, 'created': '2014-08-06 04:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/381eaf9457ee42b9d3e11bc83f2f2b7f8a8c34a0', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 5, 'created': '2014-08-06 23:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/30dffbb77f100ddca0752871ce48750371ec7d08', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 6, 'created': '2014-08-11 02:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9cddf24b6f50bc25361b58c91dec209ddb434b1', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been paired back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 7, 'created': '2014-08-11 23:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8488f0aa39d89fd21c7c85c1b7c6a678dd34cc50', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 8, 'created': '2014-08-12 23:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/885b4c1409de5ed6fe404d5521fd9013c0424386', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 9, 'created': '2014-08-13 23:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/152479b1dce94b2e11fbfee75ed095e0d7f5d581', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\n\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 10, 'created': '2014-08-24 22:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/36ab277d7e70adfc787b3ce4abfcf03805a5f3ac', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\nThe original tempest code has been pared back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 11, 'created': '2014-08-24 23:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f86827e723f661d3a1f68343d8c5ede7d0ff67be', 'message': 'Support classes for heat functional tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\nThe original tempest code has been pared back to provide the\nsmall subset required by heat functional tests. From this point on\nthese support classes can evolve to the specific needs of the\nfunctional tests.\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the functional environment (and to ease the process of porting\ntempest tests to heat functional tests). Credentials default to\nbeing sourced from the environment.\nThe default tox testenv now excludes tests in heat.tests.functional.\nA new testenv called ""functional"" will only run tests in\nheat.tests.functional.\nFunctional tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 12, 'created': '2014-08-27 23:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/feee416f4b85008d00dd8f1de21851ab6cee8a37', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the integration environment (and to ease the process of porting\ntempest tests to heat integration tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 13, 'created': '2014-08-28 04:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97e3d6f79fbc66ed7b966b8e34cf84850d785690', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the integration environment (and to ease the process of porting\ntempest tests to heat integration tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 14, 'created': '2014-08-29 03:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3f76305f036549d0780d3be4172966835a354634', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\nThe CONF used is not currently meant to be overridden by a .conf\nfile or cli arguments, it is just a mechanism to document expectations\nabout the integration environment (and to ease the process of porting\ntempest tests to heat integration tests). Credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 15, 'created': '2014-09-01 23:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b38a327fb3bc52a4e984d290277754c9b9f94073', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe script heat_integrationtests/generate_sample.sh will generate\nan up-to-date heat_integrationtests/heat_integrationtests.conf.sample\nfile which can be copied to\nheat_integrationtests/heat_integrationtests.conf\nto override default configuration values. A local ConfigOpts is created\nfor each test to avoid any potential interaction with heat\'s\nglobal CONF. Configuration options for credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 16, 'created': '2014-09-17 02:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7f48c07397a2c6be9ae83109c237840ea899b0c9', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe script heat_integrationtests/generate_sample.sh will generate\nan up-to-date heat_integrationtests/heat_integrationtests.conf.sample\nfile which can be copied to\nheat_integrationtests/heat_integrationtests.conf\nto override default configuration values. A local ConfigOpts is created\nfor each test to avoid any potential interaction with heat\'s\nglobal CONF. Configuration options for credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}, {'number': 17, 'created': '2014-09-23 21:02:49.000000000', 'files': ['test-requirements.txt', 'heat_integrationtests/common/test.py', 'heat_integrationtests/pre_test_hook.sh', 'heat_integrationtests/generate_sample.sh', 'heat_integrationtests/common/config.py', 'heat_integrationtests/heat_integrationtests.conf.sample', 'heat_integrationtests/post_test_hook.sh', 'heat_integrationtests/common/exceptions.py', 'heat_integrationtests/common/remote_client.py', 'heat_integrationtests/.gitignore', 'heat_integrationtests/common/__init__.py', 'heat_integrationtests/README.rst', 'heat_integrationtests/__init__.py', 'heat_integrationtests/common/clients.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/f3b8e93238b016abe83e8c2aba15122d803b7f82', 'message': 'Support classes for heat integration tests\n\nThese support classes started as a forklift of the classes needed\nto run tempest scenario orchestration tests.\n\nThe original tempest code has been pared back to provide the\nsmall subset required by heat integration tests. From this point on\nthese support classes can evolve to the specific needs of the\nintegration tests.\n\nThere is some unused code (especially in remote_client) which has\nbeen left in as it may become useful in the future, and is already\nextremely well reviewed and tested from being developed for tempest.\n\nThe script heat_integrationtests/generate_sample.sh will generate\nan up-to-date heat_integrationtests/heat_integrationtests.conf.sample\nfile which can be copied to\nheat_integrationtests/heat_integrationtests.conf\nto override default configuration values. A local ConfigOpts is created\nfor each test to avoid any potential interaction with heat\'s\nglobal CONF. Configuration options for credentials default to\nbeing sourced from the environment.\n\nThe default tox testenv now excludes tests in heat_integrationtests.\nA new testenv called ""integration"" will only run tests in\nheat_integrationtests.\n\nIntegration tests will fail if preconditions are not met, including\na keystone endpoint, credentials and glance containing the expected\nnamed image.\n\nDevstack gate hooks have been moved to heat_integrationtests now that\nthe name of the package has been decided.\n\nChange-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6\nPartial-Blueprint: functional-tests\n'}]",3,110496,f3b8e93238b016abe83e8c2aba15122d803b7f82,97,17,17,4571,,,0,"Support classes for heat integration tests

These support classes started as a forklift of the classes needed
to run tempest scenario orchestration tests.

The original tempest code has been pared back to provide the
small subset required by heat integration tests. From this point on
these support classes can evolve to the specific needs of the
integration tests.

There is some unused code (especially in remote_client) which has
been left in as it may become useful in the future, and is already
extremely well reviewed and tested from being developed for tempest.

The script heat_integrationtests/generate_sample.sh will generate
an up-to-date heat_integrationtests/heat_integrationtests.conf.sample
file which can be copied to
heat_integrationtests/heat_integrationtests.conf
to override default configuration values. A local ConfigOpts is created
for each test to avoid any potential interaction with heat's
global CONF. Configuration options for credentials default to
being sourced from the environment.

The default tox testenv now excludes tests in heat_integrationtests.
A new testenv called ""integration"" will only run tests in
heat_integrationtests.

Integration tests will fail if preconditions are not met, including
a keystone endpoint, credentials and glance containing the expected
named image.

Devstack gate hooks have been moved to heat_integrationtests now that
the name of the package has been decided.

Change-Id: I174429c16bb606c5c325ee8b62c6e600ea77a6e6
Partial-Blueprint: functional-tests
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/110496/16 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'heat/tests/functional/common.py', 'heat/tests/functional/exceptions.py', 'heat/tests/functional/__init__.py', 'heat/tests/functional/clients.py', 'heat/tests/functional/remote_client.py', 'heat/tests/functional/config.py']",7,56c759c8d186277c3d0a19519a30cfc13fdb514c,bp/functional-tests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os from oslo.config import cfg functional_tests_group = cfg.OptGroup( name='functional_tests', title=""Heat Functional Tests Options"") FunctionalTestGroup = [ cfg.StrOpt('auth_version', default='v2', help=""Identity API version to be used for authentication "" ""for API tests.""), cfg.BoolOpt('disable_ssl_certificate_validation', default=False, help=""Set to True if using self-signed SSL certificates.""), cfg.StrOpt('region', default=os.environ.get('OS_REGION_NAME'), help=""The region name to us""), cfg.StrOpt('auth_url', default=os.environ.get('OS_AUTH_URL'), help=""Full URI of the OpenStack Identity API (Keystone), v2""), cfg.IntOpt('build_interval', default=4, help=""Time in seconds between build status checks.""), cfg.IntOpt('build_timeout', default=1200, help=""Timeout in seconds to wait for a stack to build.""), cfg.StrOpt('instance_type', default='m1.micro', help=""Instance type for tests. Needs to be big enough for a "" ""full OS plus the test workload""), cfg.StrOpt('image_ref', default='fedora-heat-devstack', help=""Name of heat-cfntools enabled image to use when "" ""launching test instances.""), cfg.StrOpt('keypair_name', default=None, help=""Name of existing keypair to launch servers with.""), cfg.StrOpt('username', default=os.environ.get('OS_USERNAME'), help=""Username to use for API requests.""), cfg.StrOpt('tenant_name', default=os.environ.get('OS_TENANT_NAME'), help=""Tenant name to use for API requests.""), cfg.StrOpt('password', default=os.environ.get('OS_PASSWORD'), help=""API key to use when authenticating."", secret=True), cfg.StrOpt('network_for_ssh', default='private', help=""Network used for SSH connections.""), cfg.StrOpt('fixed_network_name', default='private', help=""Visible fixed network name ""), cfg.IntOpt('ssh_timeout', default=300, help=""Timeout in seconds to wait for authentication to "" ""succeed.""), cfg.IntOpt('ip_version_for_ssh', default=4, help=""IP version used for SSH connections.""), cfg.IntOpt('ssh_channel_timeout', default=60, help=""Timeout in seconds to wait for output from ssh "" ""channel.""), cfg.IntOpt('tenant_network_mask_bits', default=28, help=""The mask bits for tenant ipv4 subnets""), ] def register_opt_group(conf, opt_group, options): conf.register_group(opt_group) for opt in options: conf.register_opt(opt, group=opt_group.name) def register_opts(): register_opt_group(CONF, functional_tests_group, FunctionalTestGroup) CONF = cfg.ConfigOpts() register_opts() ",,813,0
openstack%2Fkeystonemiddleware~master~I27e20f76fb0f4b858230b2c36e6ff960e1ec9d09,openstack/keystonemiddleware,master,I27e20f76fb0f4b858230b2c36e6ff960e1ec9d09,"Update oslo-incubator and switch to oslo.{utils,serialization}",MERGED,2014-09-30 08:26:38.000000000,2014-10-04 00:05:23.000000000,2014-10-04 00:05:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6537}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-30 08:26:38.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/ec2_token.py', 'keystonemiddleware/openstack/common/__init__.py', 'keystonemiddleware/openstack/common/jsonutils.py', 'keystonemiddleware/openstack/common/strutils.py', 'keystonemiddleware/s3_token.py', 'keystonemiddleware/tests/utils.py', 'requirements.txt', 'keystonemiddleware/openstack/common/importutils.py', 'keystonemiddleware/tests/test_auth_token_middleware.py', 'keystonemiddleware/openstack/common/gettextutils.py', 'openstack-common.conf', 'keystonemiddleware/tests/client_fixtures.py', 'keystonemiddleware/tests/test_s3_token_middleware.py', 'keystonemiddleware/openstack/common/memorycache.py', 'keystonemiddleware/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/facc3f00fe452fe2a51739ac12eef44012556521', 'message': 'Update oslo-incubator and switch to oslo.{utils,serialization}\n\nUpdate to commit 9ce1d96fb2e075fcd5b9ddbee728c0ee49d2be56\n\nChange-Id: I27e20f76fb0f4b858230b2c36e6ff960e1ec9d09\n'}]",0,124979,facc3f00fe452fe2a51739ac12eef44012556521,41,8,1,1669,,,0,"Update oslo-incubator and switch to oslo.{utils,serialization}

Update to commit 9ce1d96fb2e075fcd5b9ddbee728c0ee49d2be56

Change-Id: I27e20f76fb0f4b858230b2c36e6ff960e1ec9d09
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/79/124979/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/auth_token.py', 'keystonemiddleware/ec2_token.py', 'keystonemiddleware/openstack/common/__init__.py', 'keystonemiddleware/openstack/common/jsonutils.py', 'keystonemiddleware/openstack/common/strutils.py', 'keystonemiddleware/s3_token.py', 'keystonemiddleware/tests/utils.py', 'requirements.txt', 'keystonemiddleware/openstack/common/importutils.py', 'keystonemiddleware/tests/test_auth_token_middleware.py', 'keystonemiddleware/openstack/common/gettextutils.py', 'openstack-common.conf', 'keystonemiddleware/tests/client_fixtures.py', 'keystonemiddleware/tests/test_s3_token_middleware.py', 'keystonemiddleware/openstack/common/memorycache.py', 'keystonemiddleware/openstack/common/timeutils.py']",16,facc3f00fe452fe2a51739ac12eef44012556521,jd/oslo.utils,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Time related utilities and helper functions. """""" import calendar import datetime import time import iso8601 import six # ISO 8601 extended time format with microseconds _ISO8601_TIME_FORMAT_SUBSECOND = '%Y-%m-%dT%H:%M:%S.%f' _ISO8601_TIME_FORMAT = '%Y-%m-%dT%H:%M:%S' PERFECT_TIME_FORMAT = _ISO8601_TIME_FORMAT_SUBSECOND def isotime(at=None, subsecond=False): """"""Stringify time in ISO 8601 format."""""" if not at: at = utcnow() st = at.strftime(_ISO8601_TIME_FORMAT if not subsecond else _ISO8601_TIME_FORMAT_SUBSECOND) tz = at.tzinfo.tzname(None) if at.tzinfo else 'UTC' st += ('Z' if tz == 'UTC' else tz) return st def parse_isotime(timestr): """"""Parse time from ISO 8601 format."""""" try: return iso8601.parse_date(timestr) except iso8601.ParseError as e: raise ValueError(six.text_type(e)) except TypeError as e: raise ValueError(six.text_type(e)) def strtime(at=None, fmt=PERFECT_TIME_FORMAT): """"""Returns formatted utcnow."""""" if not at: at = utcnow() return at.strftime(fmt) def parse_strtime(timestr, fmt=PERFECT_TIME_FORMAT): """"""Turn a formatted time back into a datetime."""""" return datetime.datetime.strptime(timestr, fmt) def normalize_time(timestamp): """"""Normalize time in arbitrary timezone to UTC naive object."""""" offset = timestamp.utcoffset() if offset is None: return timestamp return timestamp.replace(tzinfo=None) - offset def is_older_than(before, seconds): """"""Return True if before is older than seconds."""""" if isinstance(before, six.string_types): before = parse_strtime(before).replace(tzinfo=None) else: before = before.replace(tzinfo=None) return utcnow() - before > datetime.timedelta(seconds=seconds) def is_newer_than(after, seconds): """"""Return True if after is newer than seconds."""""" if isinstance(after, six.string_types): after = parse_strtime(after).replace(tzinfo=None) else: after = after.replace(tzinfo=None) return after - utcnow() > datetime.timedelta(seconds=seconds) def utcnow_ts(): """"""Timestamp version of our utcnow function."""""" if utcnow.override_time is None: # NOTE(kgriffs): This is several times faster # than going through calendar.timegm(...) return int(time.time()) return calendar.timegm(utcnow().timetuple()) def utcnow(): """"""Overridable version of utils.utcnow."""""" if utcnow.override_time: try: return utcnow.override_time.pop(0) except AttributeError: return utcnow.override_time return datetime.datetime.utcnow() def iso8601_from_timestamp(timestamp): """"""Returns an iso8601 formatted date from timestamp."""""" return isotime(datetime.datetime.utcfromtimestamp(timestamp)) utcnow.override_time = None def set_time_override(override_time=None): """"""Overrides utils.utcnow. Make it return a constant time or a list thereof, one at a time. :param override_time: datetime instance or list thereof. If not given, defaults to the current UTC time. """""" utcnow.override_time = override_time or datetime.datetime.utcnow() def advance_time_delta(timedelta): """"""Advance overridden time using a datetime.timedelta."""""" assert utcnow.override_time is not None try: for dt in utcnow.override_time: dt += timedelta except TypeError: utcnow.override_time += timedelta def advance_time_seconds(seconds): """"""Advance overridden time by seconds."""""" advance_time_delta(datetime.timedelta(0, seconds)) def clear_time_override(): """"""Remove the overridden time."""""" utcnow.override_time = None def marshall_now(now=None): """"""Make an rpc-safe datetime with microseconds. Note: tzinfo is stripped, but not required for relative times. """""" if not now: now = utcnow() return dict(day=now.day, month=now.month, year=now.year, hour=now.hour, minute=now.minute, second=now.second, microsecond=now.microsecond) def unmarshall_time(tyme): """"""Unmarshall a datetime dict."""""" return datetime.datetime(day=tyme['day'], month=tyme['month'], year=tyme['year'], hour=tyme['hour'], minute=tyme['minute'], second=tyme['second'], microsecond=tyme['microsecond']) def delta_seconds(before, after): """"""Return the difference between two timing objects. Compute the difference in seconds between two date, time, or datetime objects (as a float, to microsecond resolution). """""" delta = after - before return total_seconds(delta) def total_seconds(delta): """"""Return the total seconds of datetime.timedelta object. Compute total seconds of datetime.timedelta, datetime.timedelta doesn't have method total_seconds in Python2.6, calculate it manually. """""" try: return delta.total_seconds() except AttributeError: return ((delta.days * 24 * 3600) + delta.seconds + float(delta.microseconds) / (10 ** 6)) def is_soon(dt, window): """"""Determines if time is going to happen in the next window seconds. :param dt: the time :param window: minimum seconds to remain to consider the time not soon :return: True if expiration is within the given duration """""" soon = (utcnow() + datetime.timedelta(seconds=window)) return normalize_time(dt) <= soon ",18,1287
openstack%2Fdevstack~master~I708c65428fdc7442e1661037f425e466048166d3,openstack/devstack,master,I708c65428fdc7442e1661037f425e466048166d3,restructure stackrc into groupings,MERGED,2014-10-02 16:32:08.000000000,2014-10-03 23:56:07.000000000,2014-10-03 23:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5638}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 7715}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 16:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0225442e6cfc81c7a5a5c0b8ff405593aa225ac2', 'message': 'restructure stackrc into groupings\n\nin order to support installing from stable libraries we first need to\nactually sort out all the categories our giant list of git repos fit\ninto. This will make it much easier to not lose one in the process.\n\nChange-Id: I708c65428fdc7442e1661037f425e466048166d3\n'}, {'number': 2, 'created': '2014-10-03 12:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/762ad3164435ca3930f0a7a9ca6339ac5f8ab716', 'message': 'restructure stackrc into groupings\n\nin order to support installing from stable libraries we first need to\nactually sort out all the categories our giant list of git repos fit\ninto. This will make it much easier to not lose one in the process.\n\nChange-Id: I708c65428fdc7442e1661037f425e466048166d3\n'}, {'number': 3, 'created': '2014-10-03 12:05:44.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/24516d04fb6d0b3a5213e9d962fdf307e6a38d55', 'message': 'restructure stackrc into groupings\n\nin order to support installing from stable libraries we first need to\nactually sort out all the categories our giant list of git repos fit\ninto. This will make it much easier to not lose one in the process.\n\nChange-Id: I708c65428fdc7442e1661037f425e466048166d3\n'}]",1,125700,24516d04fb6d0b3a5213e9d962fdf307e6a38d55,25,10,3,2750,,,0,"restructure stackrc into groupings

in order to support installing from stable libraries we first need to
actually sort out all the categories our giant list of git repos fit
into. This will make it much easier to not lose one in the process.

Change-Id: I708c65428fdc7442e1661037f425e466048166d3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/00/125700/3 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,0225442e6cfc81c7a5a5c0b8ff405593aa225ac2,released_libs,############## # # OpenStack Server Components # ############## # neutron service NEUTRON_REPO=${NEUTRON_REPO:-${GIT_BASE}/openstack/neutron.git} NEUTRON_BRANCH=${NEUTRON_BRANCH:-master}# storage service SWIFT_REPO=${SWIFT_REPO:-${GIT_BASE}/openstack/swift.git} SWIFT_BRANCH=${SWIFT_BRANCH:-master} # trove service TROVE_REPO=${TROVE_REPO:-${GIT_BASE}/openstack/trove.git} TROVE_BRANCH=${TROVE_BRANCH:-master} ############## # # Testing Components # ############## # consolidated openstack requirements REQUIREMENTS_REPO=${REQUIREMENTS_REPO:-${GIT_BASE}/openstack/requirements.git} REQUIREMENTS_BRANCH=${REQUIREMENTS_BRANCH:-master} # Tempest test suite TEMPEST_REPO=${TEMPEST_REPO:-${GIT_BASE}/openstack/tempest.git} TEMPEST_BRANCH=${TEMPEST_BRANCH:-master} # TODO(sdague): this should end up as a library component like below TEMPEST_LIB_REPO=${TEMPEST_LIB_REPO:-${GIT_BASE}/openstack/tempest-lib.git} TEMPEST_LIB_BRANCH=${TEMPEST_LIB_BRANCH:-master} ############## # # OpenStack Client Library Componets # ############## # ceilometer client library CEILOMETERCLIENT_REPO=${CEILOMETERCLIENT_REPO:-${GIT_BASE}/openstack/python-ceilometerclient.git} CEILOMETERCLIENT_BRANCH=${CEILOMETERCLIENT_BRANCH:-master} # volume client CINDERCLIENT_REPO=${CINDERCLIENT_REPO:-${GIT_BASE}/openstack/python-cinderclient.git} CINDERCLIENT_BRANCH=${CINDERCLIENT_BRANCH:-master} # python glance client library GLANCECLIENT_REPO=${GLANCECLIENT_REPO:-${GIT_BASE}/openstack/python-glanceclient.git} GLANCECLIENT_BRANCH=${GLANCECLIENT_BRANCH:-master} # python heat client library HEATCLIENT_REPO=${HEATCLIENT_REPO:-${GIT_BASE}/openstack/python-heatclient.git} HEATCLIENT_BRANCH=${HEATCLIENT_BRANCH:-master} # ironic client IRONICCLIENT_REPO=${IRONICCLIENT_REPO:-${GIT_BASE}/openstack/python-ironicclient.git} IRONICCLIENT_BRANCH=${IRONICCLIENT_BRANCH:-master} # python keystone client library to nova that horizon uses KEYSTONECLIENT_REPO=${KEYSTONECLIENT_REPO:-${GIT_BASE}/openstack/python-keystoneclient.git} KEYSTONECLIENT_BRANCH=${KEYSTONECLIENT_BRANCH:-master} # neutron client NEUTRONCLIENT_REPO=${NEUTRONCLIENT_REPO:-${GIT_BASE}/openstack/python-neutronclient.git} NEUTRONCLIENT_BRANCH=${NEUTRONCLIENT_BRANCH:-master} # python swift client library SWIFTCLIENT_REPO=${SWIFTCLIENT_REPO:-${GIT_BASE}/openstack/python-swiftclient.git} SWIFTCLIENT_BRANCH=${SWIFTCLIENT_BRANCH:-master} # trove client library test TROVECLIENT_REPO=${TROVECLIENT_REPO:-${GIT_BASE}/openstack/python-troveclient.git} TROVECLIENT_BRANCH=${TROVECLIENT_BRANCH:-master}################### # # Oslo Libraries # ##################################### # # Libraries managed by OpenStack programs (non oslo) # ################## # glance store library GLANCE_STORE_REPO=${GLANCE_STORE_REPO:-${GIT_BASE}/openstack/glance_store.git} GLANCE_STORE_BRANCH=${GLANCE_STORE_BRANCH:-master} # heat-cfntools server agent HEAT_CFNTOOLS_REPO=${HEAT_CFNTOOLS_REPO:-${GIT_BASE}/openstack/heat-cfntools.git} HEAT_CFNTOOLS_BRANCH=${HEAT_CFNTOOLS_BRANCH:-master} # heat example templates and elements HEAT_TEMPLATES_REPO=${HEAT_TEMPLATES_REPO:-${GIT_BASE}/openstack/heat-templates.git} HEAT_TEMPLATES_BRANCH=${HEAT_TEMPLATES_BRANCH:-master} # django openstack_auth library HORIZONAUTH_REPO=${HORIZONAUTH_REPO:-${GIT_BASE}/openstack/django_openstack_auth.git} HORIZONAUTH_BRANCH=${HORIZONAUTH_BRANCH:-master} # keystone middleware KEYSTONEMIDDLEWARE_REPO=${KEYSTONEMIDDLEWARE_REPO:-${GIT_BASE}/openstack/keystonemiddleware.git} KEYSTONEMIDDLEWARE_BRANCH=${KEYSTONEMIDDLEWARE_BRANCH:-master} # s3 support for swift ################## # # TripleO Components # ################## # diskimage-builder DIB_REPO=${DIB_REPO:-${GIT_BASE}/openstack/diskimage-builder.git} DIB_BRANCH=${DIB_BRANCH:-master} # os-apply-config configuration template tool OAC_REPO=${OAC_REPO:-${GIT_BASE}/openstack/os-apply-config.git} OAC_BRANCH=${OAC_BRANCH:-master} # os-collect-config configuration agent OCC_REPO=${OCC_REPO:-${GIT_BASE}/openstack/os-collect-config.git} OCC_BRANCH=${OCC_BRANCH:-master} # os-refresh-config configuration run-parts tool ORC_REPO=${ORC_REPO:-${GIT_BASE}/openstack/os-refresh-config.git} ORC_BRANCH=${ORC_BRANCH:-master}################# # # Additional Libraries # ################################## # # 3rd Party Components (non pip installable) # # NOTE(sdague): these should be converted to release version installs or removed # ################# # ironic python agent IRONIC_PYTHON_AGENT_REPO=${IRONIC_PYTHON_AGENT_REPO:-${GIT_BASE}/openstack/ironic-python-agent.git} IRONIC_PYTHON_AGENT_BRANCH=${IRONIC_PYTHON_AGENT_BRANCH:-master} # a websockets/html5 or flash powered VNC console for vm instances NOVNC_REPO=${NOVNC_REPO:-https://github.com/kanaka/noVNC.git} NOVNC_BRANCH=${NOVNC_BRANCH:-master} # ryu service RYU_REPO=${RYU_REPO:-https://github.com/osrg/ryu.git} RYU_BRANCH=${RYU_BRANCH:-master} # a websockets/html5 or flash powered SPICE console for vm instances SPICE_REPO=${SPICE_REPO:-http://anongit.freedesktop.org/git/spice/spice-html5.git} SPICE_BRANCH=${SPICE_BRANCH:-master} ,# ceilometer client library CEILOMETERCLIENT_REPO=${CEILOMETERCLIENT_REPO:-${GIT_BASE}/openstack/python-ceilometerclient.git} CEILOMETERCLIENT_BRANCH=${CEILOMETERCLIENT_BRANCH:-master} # volume client CINDERCLIENT_REPO=${CINDERCLIENT_REPO:-${GIT_BASE}/openstack/python-cinderclient.git} CINDERCLIENT_BRANCH=${CINDERCLIENT_BRANCH:-master} # diskimage-builder DIB_REPO=${DIB_REPO:-${GIT_BASE}/openstack/diskimage-builder.git} DIB_BRANCH=${DIB_BRANCH:-master} GLANCE_STORE_REPO=${GLANCE_STORE_REPO:-${GIT_BASE}/openstack/glance_store.git} GLANCE_STORE_BRANCH=${GLANCE_STORE_BRANCH:-master} # python glance client library GLANCECLIENT_REPO=${GLANCECLIENT_REPO:-${GIT_BASE}/openstack/python-glanceclient.git} GLANCECLIENT_BRANCH=${GLANCECLIENT_BRANCH:-master} # python heat client library HEATCLIENT_REPO=${HEATCLIENT_REPO:-${GIT_BASE}/openstack/python-heatclient.git} HEATCLIENT_BRANCH=${HEATCLIENT_BRANCH:-master} # heat-cfntools server agent HEAT_CFNTOOLS_REPO=${HEAT_CFNTOOLS_REPO:-${GIT_BASE}/openstack/heat-cfntools.git} HEAT_CFNTOOLS_BRANCH=${HEAT_CFNTOOLS_BRANCH:-master} # heat example templates and elements HEAT_TEMPLATES_REPO=${HEAT_TEMPLATES_REPO:-${GIT_BASE}/openstack/heat-templates.git} HEAT_TEMPLATES_BRANCH=${HEAT_TEMPLATES_BRANCH:-master} # django openstack_auth library HORIZONAUTH_REPO=${HORIZONAUTH_REPO:-${GIT_BASE}/openstack/django_openstack_auth.git} HORIZONAUTH_BRANCH=${HORIZONAUTH_BRANCH:-master} IRONIC_PYTHON_AGENT_REPO=${IRONIC_PYTHON_AGENT_REPO:-${GIT_BASE}/openstack/ironic-python-agent.git} IRONIC_PYTHON_AGENT_BRANCH=${IRONIC_PYTHON_AGENT_BRANCH:-master} # ironic client IRONICCLIENT_REPO=${IRONICCLIENT_REPO:-${GIT_BASE}/openstack/python-ironicclient.git} IRONICCLIENT_BRANCH=${IRONICCLIENT_BRANCH:-master}# python keystone client library to nova that horizon uses KEYSTONECLIENT_REPO=${KEYSTONECLIENT_REPO:-${GIT_BASE}/openstack/python-keystoneclient.git} KEYSTONECLIENT_BRANCH=${KEYSTONECLIENT_BRANCH:-master} # keystone middleware KEYSTONEMIDDLEWARE_REPO=${KEYSTONEMIDDLEWARE_REPO:-${GIT_BASE}/openstack/keystonemiddleware.git} KEYSTONEMIDDLEWARE_BRANCH=${KEYSTONEMIDDLEWARE_BRANCH:-master}# os-apply-config configuration template tool OAC_REPO=${OAC_REPO:-${GIT_BASE}/openstack/os-apply-config.git} OAC_BRANCH=${OAC_BRANCH:-master} # os-collect-config configuration agent OCC_REPO=${OCC_REPO:-${GIT_BASE}/openstack/os-collect-config.git} OCC_BRANCH=${OCC_BRANCH:-master}# os-refresh-config configuration run-parts tool ORC_REPO=${ORC_REPO:-${GIT_BASE}/openstack/os-refresh-config.git} ORC_BRANCH=${ORC_BRANCH:-master}# neutron service NEUTRON_REPO=${NEUTRON_REPO:-${GIT_BASE}/openstack/neutron.git} NEUTRON_BRANCH=${NEUTRON_BRANCH:-master} # neutron client NEUTRONCLIENT_REPO=${NEUTRONCLIENT_REPO:-${GIT_BASE}/openstack/python-neutronclient.git} NEUTRONCLIENT_BRANCH=${NEUTRONCLIENT_BRANCH:-master} # consolidated openstack requirements REQUIREMENTS_REPO=${REQUIREMENTS_REPO:-${GIT_BASE}/openstack/requirements.git} REQUIREMENTS_BRANCH=${REQUIREMENTS_BRANCH:-master} # storage service SWIFT_REPO=${SWIFT_REPO:-${GIT_BASE}/openstack/swift.git} SWIFT_BRANCH=${SWIFT_BRANCH:-master}# python swift client library SWIFTCLIENT_REPO=${SWIFTCLIENT_REPO:-${GIT_BASE}/openstack/python-swiftclient.git} SWIFTCLIENT_BRANCH=${SWIFTCLIENT_BRANCH:-master} # Tempest test suite TEMPEST_REPO=${TEMPEST_REPO:-${GIT_BASE}/openstack/tempest.git} TEMPEST_BRANCH=${TEMPEST_BRANCH:-master} TEMPEST_LIB_REPO=${TEMPEST_LIB_REPO:-${GIT_BASE}/openstack/tempest-lib.git} TEMPEST_LIB_BRANCH=${TEMPEST_LIB_BRANCH:-master}# a websockets/html5 or flash powered VNC console for vm instances NOVNC_REPO=${NOVNC_REPO:-https://github.com/kanaka/noVNC.git} NOVNC_BRANCH=${NOVNC_BRANCH:-master} # ryu service RYU_REPO=${RYU_REPO:-https://github.com/osrg/ryu.git} RYU_BRANCH=${RYU_BRANCH:-master} # a websockets/html5 or flash powered SPICE console for vm instances SPICE_REPO=${SPICE_REPO:-http://anongit.freedesktop.org/git/spice/spice-html5.git} SPICE_BRANCH=${SPICE_BRANCH:-master} # trove service TROVE_REPO=${TROVE_REPO:-${GIT_BASE}/openstack/trove.git} TROVE_BRANCH=${TROVE_BRANCH:-master} # trove client library test TROVECLIENT_REPO=${TROVECLIENT_REPO:-${GIT_BASE}/openstack/python-troveclient.git} TROVECLIENT_BRANCH=${TROVECLIENT_BRANCH:-master},156,96
openstack%2Fswift~master~I20a9e82c7fed8948bf649f1f8571b4145fca201d,openstack/swift,master,I20a9e82c7fed8948bf649f1f8571b4145fca201d,Let eventlet.wsgi.server log tracebacks when eventlet_debug is enabled,MERGED,2014-07-09 23:31:39.000000000,2014-10-03 23:55:38.000000000,2014-10-03 23:55:38.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 7233}, {'_account_id': 8871}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-07-09 23:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ce80429330f2b33daa827bb491cc9f7bd9ee4488', 'message': 'Let eventlet.wsgi.server log tracebacks when eventlet_debug is enabled\n\nThe ""logging"" available in eventlet.wsgi.server/BaseHTTPServer doesn\'t\ngenerally suite our needs, so it should be bypasses using a NullLogger in\nproduction.  But in development it can be useful if tracebacks generated from\ninside eventlet.wsgi (say a NameError in DiskFile.__iter__) end up in logs.\nSince we already have eventlet_debug parsed inside of run_server we can skip\nthe NullLogger bypass and let stuff blast out to STDERR when configured for\ndevelopment/debug logging.\n\nChange-Id: I20a9e82c7fed8948bf649f1f8571b4145fca201d\n'}, {'number': 2, 'created': '2014-09-16 01:23:38.000000000', 'files': ['swift/common/wsgi.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c767ec9a37faa4414702aa9e39231afe0ba3b097', 'message': 'Let eventlet.wsgi.server log tracebacks when eventlet_debug is enabled\n\nThe ""logging"" available in eventlet.wsgi.server/BaseHTTPServer doesn\'t\ngenerally suite our needs, so it should be bypassed using a NullLogger in\nproduction.  But in development it can be useful if tracebacks generated from\ninside eventlet.wsgi (say a NameError in DiskFile.__iter__) end up in logs.\nSince we already have eventlet_debug parsed inside of run_server we can skip\nthe NullLogger bypass and let stuff blast out to STDERR when configured for\ndevelopment/debug logging.\n\nChange-Id: I20a9e82c7fed8948bf649f1f8571b4145fca201d\n'}]",1,105918,c767ec9a37faa4414702aa9e39231afe0ba3b097,20,7,2,1179,,,0,"Let eventlet.wsgi.server log tracebacks when eventlet_debug is enabled

The ""logging"" available in eventlet.wsgi.server/BaseHTTPServer doesn't
generally suite our needs, so it should be bypassed using a NullLogger in
production.  But in development it can be useful if tracebacks generated from
inside eventlet.wsgi (say a NameError in DiskFile.__iter__) end up in logs.
Since we already have eventlet_debug parsed inside of run_server we can skip
the NullLogger bypass and let stuff blast out to STDERR when configured for
development/debug logging.

Change-Id: I20a9e82c7fed8948bf649f1f8571b4145fca201d
",git fetch https://review.opendev.org/openstack/swift refs/changes/18/105918/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/wsgi.py', 'test/unit/common/test_wsgi.py']",2,ce80429330f2b33daa827bb491cc9f7bd9ee4488,wsgi-debug," client_timeout = 30 max_clients = 1000 swift_dir = TEMPDIR [pipeline:main] pipeline = proxy-server [app:proxy-server] use = egg:swift#proxy # while ""set"" values normally override default set client_timeout = 20 # this section is not in conf during run_server set max_clients = 10 """""" contents = dedent(config) with temptree(['proxy-server.conf']) as t: conf_file = os.path.join(t, 'proxy-server.conf') with open(conf_file, 'w') as f: f.write(contents.replace('TEMPDIR', t)) _fake_rings(t) with mock.patch('swift.proxy.server.Application.' 'modify_wsgi_pipeline'): with mock.patch('swift.common.wsgi.wsgi') as _wsgi: with mock.patch('swift.common.wsgi.eventlet') as _eventlet: conf = wsgi.appconfig(conf_file) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assertEquals('HTTP/1.0', _wsgi.HttpProtocol.default_request_version) self.assertEquals(30, _wsgi.WRITE_TIMEOUT) _eventlet.hubs.use_hub.assert_called_with(utils.get_hub()) _eventlet.patcher.monkey_patch.assert_called_with(all=False, socket=True) _eventlet.debug.hub_exceptions.assert_called_with(False) _wsgi.server.assert_called() args, kwargs = _wsgi.server.call_args server_sock, server_app, server_logger = args self.assertEquals(sock, server_sock) self.assert_(isinstance(server_app, swift.proxy.server.Application)) self.assertEquals(20, server_app.client_timeout) self.assert_(isinstance(server_logger, wsgi.NullLogger)) self.assert_('custom_pool' in kwargs) self.assertEquals(1000, kwargs['custom_pool'].size) def test_run_server_conf_dir(self): config_dir = { 'proxy-server.conf.d/pipeline.conf': """""" [pipeline:main] pipeline = proxy-server """""", 'proxy-server.conf.d/app.conf': """""" [app:proxy-server] use = egg:swift#proxy """""", 'proxy-server.conf.d/default.conf': """""" [DEFAULT] client_timeout = 30 """""" } # strip indent from test config contents config_dir = dict((f, dedent(c)) for (f, c) in config_dir.items()) with temptree(*zip(*config_dir.items())) as conf_root: conf_dir = os.path.join(conf_root, 'proxy-server.conf.d') with open(os.path.join(conf_dir, 'swift.conf'), 'w') as f: f.write('[DEFAULT]\nswift_dir = %s' % conf_root) _fake_rings(conf_root) with mock.patch('swift.proxy.server.Application.' 'modify_wsgi_pipeline'): with mock.patch('swift.common.wsgi.wsgi') as _wsgi: with mock.patch('swift.common.wsgi.eventlet') as _eventlet: with mock.patch.dict('os.environ', {'TZ': ''}): conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assert_(os.environ['TZ'] is not '') self.assertEquals('HTTP/1.0', _wsgi.HttpProtocol.default_request_version) self.assertEquals(30, _wsgi.WRITE_TIMEOUT) _eventlet.hubs.use_hub.assert_called_with(utils.get_hub()) _eventlet.patcher.monkey_patch.assert_called_with(all=False, socket=True) _eventlet.debug.hub_exceptions.assert_called_with(False) _wsgi.server.assert_called() args, kwargs = _wsgi.server.call_args server_sock, server_app, server_logger = args self.assertEquals(sock, server_sock) self.assert_(isinstance(server_app, swift.proxy.server.Application)) self.assert_(isinstance(server_logger, wsgi.NullLogger)) self.assert_('custom_pool' in kwargs) def test_run_server_debug(self): config = """""" [DEFAULT] self.assertEqual(server_logger, None)"," self.assert_(isinstance(server_logger, wsgi.NullLogger)) def test_run_server_conf_dir(self): config_dir = { 'proxy-server.conf.d/pipeline.conf': """""" [pipeline:main] pipeline = proxy-server """""", 'proxy-server.conf.d/app.conf': """""" [app:proxy-server] use = egg:swift#proxy """""", 'proxy-server.conf.d/default.conf': """""" [DEFAULT] eventlet_debug = yes client_timeout = 30 """""" } # strip indent from test config contents config_dir = dict((f, dedent(c)) for (f, c) in config_dir.items()) with temptree(*zip(*config_dir.items())) as conf_root: conf_dir = os.path.join(conf_root, 'proxy-server.conf.d') with open(os.path.join(conf_dir, 'swift.conf'), 'w') as f: f.write('[DEFAULT]\nswift_dir = %s' % conf_root) _fake_rings(conf_root) with mock.patch('swift.proxy.server.Application.' 'modify_wsgi_pipeline'): with mock.patch('swift.common.wsgi.wsgi') as _wsgi: with mock.patch('swift.common.wsgi.eventlet') as _eventlet: with mock.patch.dict('os.environ', {'TZ': ''}): conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assert_(os.environ['TZ'] is not '') self.assertEquals('HTTP/1.0', _wsgi.HttpProtocol.default_request_version) self.assertEquals(30, _wsgi.WRITE_TIMEOUT) _eventlet.hubs.use_hub.assert_called_with(utils.get_hub()) _eventlet.patcher.monkey_patch.assert_called_with(all=False, socket=True) _eventlet.debug.hub_exceptions.assert_called_with(True) _wsgi.server.assert_called() args, kwargs = _wsgi.server.call_args server_sock, server_app, server_logger = args self.assertEquals(sock, server_sock) self.assert_(isinstance(server_app, swift.proxy.server.Application)) self.assert_(isinstance(server_logger, wsgi.NullLogger)) self.assert_('custom_pool' in kwargs) ",103,51
openstack%2Fceilometer~master~I22871737cf297d1bfff6c17a7eaf9333c6415ffd,openstack/ceilometer,master,I22871737cf297d1bfff6c17a7eaf9333c6415ffd,create skeleton files for event storage backends,MERGED,2014-10-02 17:43:19.000000000,2014-10-03 23:48:55.000000000,2014-10-03 23:48:54.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 8871}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-02 17:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a8a999f5992c06e144652e8f68ded3ba88ade69a', 'message': 'create skeleton files for event storage backends\n\nthis patch adds support to configure an event specific database.\nthe code currently calls existing metering/event mixed code so\nbasically both metering and event db share the same code.\n\nsegregation of code will be done in subsequent patches for each\ndriver individually.\n\nChange-Id: I22871737cf297d1bfff6c17a7eaf9333c6415ffd\nPartially-Implements: dedicated-event-db\n'}, {'number': 2, 'created': '2014-10-02 17:44:13.000000000', 'files': ['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/event/storage/impl_db2.py', 'ceilometer/event/storage/pymongo_base.py', 'ceilometer/api/app.py', 'ceilometer/tests/api/v2/test_event_scenarios.py', 'ceilometer/tests/storage/test_get_connection.py', 'ceilometer/event/storage/impl_mongodb.py', 'ceilometer/cmd/storage.py', 'ceilometer/event/storage/base.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/__init__.py', 'ceilometer/event/storage/impl_log.py', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/api/hooks.py', 'ceilometer/event/storage/impl_hbase.py', 'setup.cfg', 'ceilometer/event/storage/impl_sqlalchemy.py', 'ceilometer/tests/db.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a1ba9d7e2537011c4fdbb190cc21267d11f71c91', 'message': 'create skeleton files for event storage backends\n\nthis patch adds support to configure an event specific database.\nthe code currently calls existing metering/event mixed code so\nbasically both metering and event db share the same code.\n\nsegregation of code will be done in subsequent patches for each\ndriver individually.\n\nChange-Id: I22871737cf297d1bfff6c17a7eaf9333c6415ffd\nPartially-Implements: blueprint dedicated-event-db\n'}]",0,125721,a1ba9d7e2537011c4fdbb190cc21267d11f71c91,24,6,2,6537,,,0,"create skeleton files for event storage backends

this patch adds support to configure an event specific database.
the code currently calls existing metering/event mixed code so
basically both metering and event db share the same code.

segregation of code will be done in subsequent patches for each
driver individually.

Change-Id: I22871737cf297d1bfff6c17a7eaf9333c6415ffd
Partially-Implements: blueprint dedicated-event-db
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/21/125721/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/event/storage/impl_db2.py', 'ceilometer/event/storage/pymongo_base.py', 'ceilometer/api/app.py', 'ceilometer/tests/api/v2/test_event_scenarios.py', 'ceilometer/tests/storage/test_get_connection.py', 'ceilometer/event/storage/impl_mongodb.py', 'ceilometer/cmd/storage.py', 'ceilometer/event/storage/base.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/__init__.py', 'ceilometer/event/storage/impl_log.py', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/api/hooks.py', 'ceilometer/event/storage/impl_hbase.py', 'setup.cfg', 'ceilometer/event/storage/impl_sqlalchemy.py', 'ceilometer/tests/db.py']",18,a8a999f5992c06e144652e8f68ded3ba88ade69a,bp/dedicated-event-db," self.event_connection = storage.get_connection( self.url, 'ceilometer.event.storage') self.event_connection = storage.get_connection( self.url, 'ceilometer.event.storage') self.event_connection = storage.get_connection( self.url, 'ceilometer.event.storage') self.event_connection = storage.get_connection( self.url, 'ceilometer.event.storage') self.event_conn = self.db_manager.event_connection self.event_conn.upgrade() self.event_conn.clear() self.event_conn = None elif namespace == ""ceilometer.event.storage"": return self.event_conn",,452,71
openstack%2Ftempest~master~Id1d516948508018e4fa5b36ae7c109a04ee33dcc,openstack/tempest,master,Id1d516948508018e4fa5b36ae7c109a04ee33dcc,Migrate cli tests to resource_* fixtures,MERGED,2014-09-15 13:27:39.000000000,2014-10-03 23:48:46.000000000,2014-10-03 23:48:45.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/28585944b21a319e0640456030694cf6ca660945', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 2, 'created': '2014-09-16 11:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5452e1b298e127e98e7ec158dbdd708b1dd8cabd', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 3, 'created': '2014-09-16 14:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/73823c4b1bf66320c5707c57190f45f0caddca44', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 4, 'created': '2014-09-16 21:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/24bd6630504554692814f341759bbcc1c5e93e62', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 5, 'created': '2014-09-17 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b64bcd68e93a3ec7e63d71c236558a6f5472a46d', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 6, 'created': '2014-09-17 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f872efdb9d2a20316e797b73be12c66ed568376b', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 7, 'created': '2014-09-17 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/360ede7adbbd240587c35afa3b848ed74c935cd3', 'message': 'Migrate cli API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 8, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/165fa66eeb7ffff8f08725037dc0a24b67fb7d43', 'message': 'Migrate cli tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 9, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/414399afff688ab63cb6277c47e1b895d81026b0', 'message': 'Migrate cli tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 10, 'created': '2014-10-01 22:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2f24a0449a13c938a86dcaa2867eec5ee1501b6a', 'message': 'Migrate cli tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}, {'number': 11, 'created': '2014-10-03 11:20:46.000000000', 'files': ['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/compute/test_nova.py', 'tempest/cli/simple_read_only/image/test_glance.py', 'tempest/cli/simple_read_only/object_storage/test_swift.py', 'tempest/cli/simple_read_only/telemetry/test_ceilometer.py', 'tempest/cli/simple_read_only/network/test_neutron.py', 'tempest/cli/simple_read_only/data_processing/test_sahara.py', 'tempest/cli/simple_read_only/volume/test_cinder.py', 'tempest/cli/simple_read_only/orchestration/test_heat.py', 'tempest/cli/simple_read_only/compute/test_nova_manage.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cde19f23b140ce8c2e54ee4a538bd4b1da4bdd12', 'message': 'Migrate cli tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc\n'}]",0,121553,cde19f23b140ce8c2e54ee4a538bd4b1da4bdd12,49,8,11,1921,,,0,"Migrate cli tests to resource_* fixtures

Partially-implements bp resource-cleanup

Change-Id: Id1d516948508018e4fa5b36ae7c109a04ee33dcc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/53/121553/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/compute/test_nova.py', 'tempest/cli/simple_read_only/image/test_glance.py', 'tempest/cli/simple_read_only/object_storage/test_swift.py', 'tempest/cli/simple_read_only/telemetry/test_ceilometer.py', 'tempest/cli/simple_read_only/network/test_neutron.py', 'tempest/cli/simple_read_only/data_processing/test_sahara.py', 'tempest/cli/simple_read_only/volume/test_cinder.py', 'tempest/cli/simple_read_only/orchestration/test_heat.py', 'tempest/cli/simple_read_only/compute/test_nova_manage.py']",10,28585944b21a319e0640456030694cf6ca660945,bp/resource-cleanup," def resource_setup(cls): super(SimpleReadOnlyNovaManageTest, cls).resource_setup()"," def setUpClass(cls): super(SimpleReadOnlyNovaManageTest, cls).setUpClass()",20,20
openstack%2Ftempest~master~I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88,openstack/tempest,master,I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88,Migrate thirdparty tests to resource_* fixtures,MERGED,2014-09-15 13:27:39.000000000,2014-10-03 23:48:36.000000000,2014-10-03 23:48:35.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cc990c10cfe39108578a1ea284bd6d4c2793fd6', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 2, 'created': '2014-09-16 11:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5cb77ad28a115df2409722742052fc3adbc74898', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 3, 'created': '2014-09-16 14:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7837ebfa680b1ba3b2a99a557da6295f12bb60e', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 4, 'created': '2014-09-16 21:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3aa2c858bb87294f0a096ce9da4f57cbb0a8ab0d', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 5, 'created': '2014-09-17 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bbd7fd0d4266f169c175581c6625ec8ec905916e', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 6, 'created': '2014-09-17 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd1cf86f309648fd663a9cefb3d6ddfdfca0b57a', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 7, 'created': '2014-09-17 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/decefd533db36a57e43d63acef8997e9c3197f38', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 8, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e923e227482bc044afc7d787d02c07a3b2c3a40', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 9, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2ca70859051c5b68a81727a8475101de83d720a9', 'message': 'Migrate thirdparty API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 10, 'created': '2014-10-01 22:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f6c0e5e85fa9f6942af5d9016683cf3bc5b8e3b', 'message': 'Migrate thirdparty tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}, {'number': 11, 'created': '2014-10-03 11:20:46.000000000', 'files': ['tempest/thirdparty/boto/test_ec2_volumes.py', 'tempest/thirdparty/boto/test_s3_objects.py', 'tempest/thirdparty/boto/test_ec2_network.py', 'tempest/thirdparty/boto/test.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/thirdparty/boto/test_ec2_security_groups.py', 'tempest/thirdparty/boto/test_ec2_keys.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py', 'tempest/thirdparty/boto/test_s3_buckets.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/29fea3544a13f05f76cfdd30931974dce6c01fcc', 'message': 'Migrate thirdparty tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88\n'}]",0,121552,29fea3544a13f05f76cfdd30931974dce6c01fcc,56,8,11,1921,,,0,"Migrate thirdparty tests to resource_* fixtures

Partially-implements bp resource-cleanup

Change-Id: I562e3894e949aa12d4ee20d7be5cf7ac3cc17e88
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/121552/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/thirdparty/boto/test_ec2_volumes.py', 'tempest/thirdparty/boto/test_s3_objects.py', 'tempest/thirdparty/boto/test.py', 'tempest/thirdparty/boto/test_ec2_network.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/thirdparty/boto/test_ec2_security_groups.py', 'tempest/thirdparty/boto/test_ec2_keys.py', 'tempest/thirdparty/boto/test_s3_ec2_images.py', 'tempest/thirdparty/boto/test_s3_buckets.py']",9,7cc990c10cfe39108578a1ea284bd6d4c2793fd6,bp/resource-cleanup," def resource_setup(cls): super(S3BucketsTest, cls).resource_setup()"," def setUpClass(cls): super(S3BucketsTest, cls).setUpClass()",20,20
openstack%2Ftempest~master~Ib6ad8614c6d1a84e32dd31d27f899df02eed260a,openstack/tempest,master,Ib6ad8614c6d1a84e32dd31d27f899df02eed260a,Migrate scenario tests to resource_* fixtures,MERGED,2014-09-15 13:27:39.000000000,2014-10-03 23:48:26.000000000,2014-10-03 23:48:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf1bb2e6d821a3678201bef5def0476b38ebaa0b', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 2, 'created': '2014-09-16 11:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c600adce58c0c4aee89b3194b5083d7f3b172d8', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 3, 'created': '2014-09-16 14:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9ebe4a7fcd2ee3142a7c94de8802238f86be797', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 4, 'created': '2014-09-16 21:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c92ac36abb60bf5099db968c62d26c94a80b0dc', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 5, 'created': '2014-09-17 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dd7abc37fe4c94611731a1bf48b0bd0debb71622', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 6, 'created': '2014-09-17 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/726c6e911dc12bab8a15d61f699eb3b90532749e', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 7, 'created': '2014-09-17 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/883b2ad4df5cecb7d132c4cbf0362e97317b9bd4', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 8, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2506ad653da2b90e3335cbbf9ef79a0b28835c56', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 9, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ca93fc8fd0eea9d5ae6bcb8c97602edfb6c7c2c0', 'message': 'Migrate scenario API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 10, 'created': '2014-10-01 22:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/df5d4299fd5cf1967bc9974aae7ef900bc046706', 'message': 'Migrate scenario tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}, {'number': 11, 'created': '2014-10-03 11:20:46.000000000', 'files': ['tempest/scenario/test_aggregates_basic_ops.py', 'tempest/scenario/test_dashboard_basic_ops.py', 'tempest/scenario/manager.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/scenario/test_network_advanced_server_ops.py', 'tempest/scenario/test_server_advanced_ops.py', 'tempest/scenario/test_large_ops.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/scenario/test_stamp_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac20b5e14f8e3d89bdc46d233b474d8886100554', 'message': 'Migrate scenario tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a\n'}]",1,121551,ac20b5e14f8e3d89bdc46d233b474d8886100554,51,7,11,1921,,,0,"Migrate scenario tests to resource_* fixtures

Partially-implements bp resource-cleanup

Change-Id: Ib6ad8614c6d1a84e32dd31d27f899df02eed260a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/121551/11 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_aggregates_basic_ops.py', 'tempest/scenario/test_dashboard_basic_ops.py', 'tempest/scenario/manager.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_network_advanced_server_ops.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/scenario/test_server_advanced_ops.py', 'tempest/scenario/test_large_ops.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/scenario/test_stamp_pattern.py']",11,cf1bb2e6d821a3678201bef5def0476b38ebaa0b,bp/resource-cleanup," def resource_setup(cls): super(TestStampPattern, cls).resource_setup()"," def setUpClass(cls): super(TestStampPattern, cls).setUpClass()",40,40
openstack%2Ftempest~master~Ib92d30d25592c38a5999d43e533921377200570f,openstack/tempest,master,Ib92d30d25592c38a5999d43e533921377200570f,Migrate volume API tests to resource_* fixtures,MERGED,2014-09-15 13:27:39.000000000,2014-10-03 23:47:22.000000000,2014-10-03 23:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2ff8d1d9f83625a79e56f677bb030264763a50c6', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 2, 'created': '2014-09-16 11:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3295c076246ebd48e5ec84741a184eeab1547f70', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 3, 'created': '2014-09-16 14:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b85e4fc4cdc94448ff14c864d6397d6bf679555b', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 4, 'created': '2014-09-16 21:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bcfe18883286c99bca0c92352edb3206d10dc029', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 5, 'created': '2014-09-17 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8196fbe3a091f0b774861a450db5a9c0b33e1194', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 6, 'created': '2014-09-17 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d390448f1d1108a0d391310378bf7d14aebc0fd', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 7, 'created': '2014-09-18 21:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16d933b2640a0f51e95c1097fc5e6b70a92c5da0', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 8, 'created': '2014-09-26 16:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8b5f7628a7e531664ed019554d6afe92192eeab', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 9, 'created': '2014-10-01 19:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b935364f547218e0a5b405e3c6272d58fab093a4', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}, {'number': 10, 'created': '2014-10-03 11:20:46.000000000', 'files': ['tempest/api/volume/test_volumes_list.py', 'tempest/api/volume/admin/test_volumes_actions.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/api/volume/v2/test_volumes_list.py', 'tempest/api/volume/admin/test_volume_types_extra_specs.py', 'tempest/api/volume/test_qos.py', 'tempest/api/volume/admin/test_volume_services.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/test_volume_metadata.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/volume/test_volumes_get.py', 'tempest/api/volume/test_availability_zone.py', 'tempest/api/volume/test_snapshot_metadata.py', 'tempest/api/volume/admin/test_volume_quotas.py', 'tempest/api/volume/admin/test_volumes_backup.py', 'tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/admin/test_volume_types_extra_specs_negative.py', 'tempest/api/volume/admin/test_volume_quotas_negative.py', 'tempest/api/volume/base.py', 'tempest/api/volume/admin/test_snapshots_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_snapshots_negative.py', 'tempest/api/volume/test_volume_transfers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/61a12e26fc5ea77309c6a0682b1331a7341a1f60', 'message': 'Migrate volume API tests to resource_* fixtures\n\nPartially-implements bp resource-cleanup\n\nChange-Id: Ib92d30d25592c38a5999d43e533921377200570f\n'}]",2,121550,61a12e26fc5ea77309c6a0682b1331a7341a1f60,57,8,10,1921,,,0,"Migrate volume API tests to resource_* fixtures

Partially-implements bp resource-cleanup

Change-Id: Ib92d30d25592c38a5999d43e533921377200570f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/121550/9 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/test_volumes_list.py', 'tempest/api/volume/admin/test_volumes_actions.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/api/volume/v2/test_volumes_list.py', 'tempest/api/volume/admin/test_volume_types_extra_specs.py', 'tempest/api/volume/test_qos.py', 'tempest/api/volume/admin/test_volume_services.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/test_volume_metadata.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/volume/test_volumes_get.py', 'tempest/api/volume/test_availability_zone.py', 'tempest/api/volume/test_snapshot_metadata.py', 'tempest/api/volume/admin/test_volume_quotas.py', 'tempest/api/volume/admin/test_volumes_backup.py', 'tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/admin/test_volume_types_extra_specs_negative.py', 'tempest/api/volume/admin/test_volume_quotas_negative.py', 'tempest/api/volume/base.py', 'tempest/api/volume/admin/test_snapshots_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_snapshots_negative.py', 'tempest/api/volume/test_volume_transfers.py']",23,2ff8d1d9f83625a79e56f677bb030264763a50c6,bp/resource-cleanup," def resource_setup(cls): super(VolumesV2TransfersTest, cls).resource_setup()"," def setUpClass(cls): super(VolumesV2TransfersTest, cls).setUpClass()",70,70
openstack%2Fneutron~stable%2Ficehouse~I90a164a1b632c3794a7f7607f3f1da8f7d7b15db,openstack/neutron,stable/icehouse,I90a164a1b632c3794a7f7607f3f1da8f7d7b15db,Add BSN plugin to agent migration script,MERGED,2014-09-08 13:55:33.000000000,2014-10-03 23:47:08.000000000,2014-10-03 23:47:07.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-08 13:55:33.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/42f0e051845dee0ae7b3c988bf1581cab686b25e', 'message': 'Add BSN plugin to agent migration script\n\nAdds the Big Switch plugin to the migration script that creates\nthe agents table. A recent commit (d3be7b040eaa61a4d0ac617026cf5c9132d3831e)\nadded it to the agent tables but it missed this one so an error was thrown\nduring migration when it reached a table that depended on the agents table.\n\nCloses-Bug: #1340405\nChange-Id: I90a164a1b632c3794a7f7607f3f1da8f7d7b15db\n(cherry picked from commit 2dd0a22fd6cc38cc27942572c8a19bf6a52fb32b)\n'}]",0,119766,42f0e051845dee0ae7b3c988bf1581cab686b25e,41,23,1,7249,,,0,"Add BSN plugin to agent migration script

Adds the Big Switch plugin to the migration script that creates
the agents table. A recent commit (d3be7b040eaa61a4d0ac617026cf5c9132d3831e)
added it to the agent tables but it missed this one so an error was thrown
during migration when it reached a table that depended on the agents table.

Closes-Bug: #1340405
Change-Id: I90a164a1b632c3794a7f7607f3f1da8f7d7b15db
(cherry picked from commit 2dd0a22fd6cc38cc27942572c8a19bf6a52fb32b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/119766/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py'],1,42f0e051845dee0ae7b3c988bf1581cab686b25e,," 'neutron.plugins.bigswitch.plugin.NeutronRestProxyV2',",,1,0
openstack%2Fnova~master~Ibe278688b118db01c9c3ae1763954adf19c7ee0d,openstack/nova,master,Ibe278688b118db01c9c3ae1763954adf19c7ee0d,Fix KeyError for euca-describe-images,MERGED,2014-09-18 03:12:32.000000000,2014-10-03 23:44:39.000000000,2014-10-03 23:44:36.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 4428}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-18 03:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d25ef18ce1d4ea09b35a724bcca7c6d8e835472b', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n'}, {'number': 2, 'created': '2014-09-18 08:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4dc3ddb44224dfdcf30a255455c118ba26f3e2f3', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n'}, {'number': 3, 'created': '2014-09-25 01:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4eae6c220cf2b1f8c05f1f1bd60c21d8a3ca5ef', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n'}, {'number': 4, 'created': '2014-09-25 05:53:09.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1dea1cd710d54d4a2a584590e4ccf59dd3a41faa', 'message': 'Fix KeyError for euca-describe-images\n\nEC2 describe images crashes on volume backed instance snapshot which has\nseveral volumes.\n\nChange-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d\nCloses-bug: #1370265\n'}]",4,122305,1dea1cd710d54d4a2a584590e4ccf59dd3a41faa,29,11,4,4428,,,0,"Fix KeyError for euca-describe-images

EC2 describe images crashes on volume backed instance snapshot which has
several volumes.

Change-Id: Ibe278688b118db01c9c3ae1763954adf19c7ee0d
Closes-bug: #1370265
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/122305/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/ec2/cloud.py'],1,d25ef18ce1d4ea09b35a724bcca7c6d8e835472b,fix-KeyError-euca-describe-images, if bdm.get('deviceName') == mappings[i].get('deviceName'):, if bdm['deviceName'] == mappings[i]['deviceName']:,1,1
openstack%2Fneutron~master~I6402448075ed414434dc007f5c403fc85b6b1456,openstack/neutron,master,I6402448075ed414434dc007f5c403fc85b6b1456,Add missing methods to NoopFirewallDriver,MERGED,2014-09-15 18:20:54.000000000,2014-10-03 23:44:21.000000000,2014-10-03 23:44:20.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 4187}, {'_account_id': 4727}, {'_account_id': 5170}, {'_account_id': 5803}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7148}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8190}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9705}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-15 18:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9261950319d8b86067d2ca3124aa36094cbf4f5a', 'message': 'Avoid calling absent method in NoopFirewallDriver\n\nThe proposed fix just checks for method presense in the loaded driver class.\nAn alternative could be that methods update_security_group_rules and\nupdate_security_group_members.\n\nChange-Id: I6402448075ed414434dc007f5c403fc85b6b1456\nCloses-Bug: #1369685\nRelated-Bug: #1365806\n'}, {'number': 2, 'created': '2014-09-16 20:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/312f6a354d7b64ec0e374e8c90cbbc3c2eb248cc', 'message': 'Avoid calling absent method in NoopFirewallDriver\n\nThe fix adds missing methods into generic Firewall class\nand in NoopFirewall driver class.\n\nChange-Id: I6402448075ed414434dc007f5c403fc85b6b1456\nCloses-Bug: #1369685\nRelated-Bug: #1365806\n'}, {'number': 3, 'created': '2014-09-28 18:25:25.000000000', 'files': ['neutron/agent/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a6c073656a7e0b1a26b2bca0ba381489d04e322', 'message': 'Add missing methods to NoopFirewallDriver\n\nThe fix adds missing methods into generic Firewall class\nand in NoopFirewall driver class.\n\nChange-Id: I6402448075ed414434dc007f5c403fc85b6b1456\nCloses-Bug: #1369685\nRelated-Bug: #1365806\n'}]",13,121645,9a6c073656a7e0b1a26b2bca0ba381489d04e322,108,42,3,6072,,,0,"Add missing methods to NoopFirewallDriver

The fix adds missing methods into generic Firewall class
and in NoopFirewall driver class.

Change-Id: I6402448075ed414434dc007f5c403fc85b6b1456
Closes-Bug: #1369685
Related-Bug: #1365806
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/121645/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/securitygroups_rpc.py'],1,9261950319d8b86067d2ca3124aa36094cbf4f5a,bug/1369685," if getattr(self.firewall, 'update_security_group_rules'): for sg_id, sg_rules in security_groups.items(): self.firewall.update_security_group_rules(sg_id, sg_rules) if getattr(self.firewall, 'update_security_group_members'): for remote_sg_id, member_ips in security_group_member_ips.items(): self.firewall.update_security_group_members( remote_sg_id, member_ips)"," for sg_id, sg_rules in security_groups.items(): self.firewall.update_security_group_rules(sg_id, sg_rules) for remote_sg_id, member_ips in security_group_member_ips.items(): self.firewall.update_security_group_members( remote_sg_id, member_ips)",8,5
openstack%2Fhorizon~master~I808271c76b1669b15ecc20b291493a4f751d546e,openstack/horizon,master,I808271c76b1669b15ecc20b291493a4f751d546e,Move translator notes just before translatable strings,MERGED,2014-10-01 11:48:31.000000000,2014-10-03 23:39:50.000000000,2014-10-03 23:39:49.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 3108}, {'_account_id': 8674}, {'_account_id': 8871}, {'_account_id': 9981}, {'_account_id': 11881}]","[{'number': 1, 'created': '2014-10-01 11:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8e462fdb5c48486c382a6088b9ce4dc1a2396ea3', 'message': 'Move translators just before translatable strings\n\nTranslator notes must be placed just before strings.\nOtherwise translator notes are ignored when generating POT files.\nWe need to be careful when we use multiline *gettext* methods.\nHow to detect them is a future topic in I18N team.\n\nChange-Id: I808271c76b1669b15ecc20b291493a4f751d546e\nCloses-Bug: #1375607\n'}, {'number': 2, 'created': '2014-10-01 11:53:20.000000000', 'files': ['horizon/test/test_dashboards/dogs/puppies/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8d89f09bfd502aa42e8a83c2c5e5c7e4a2d8aefb', 'message': 'Move translator notes just before translatable strings\n\nTranslator notes must be placed just before strings.\nOtherwise translator notes are ignored when generating POT files.\nWe need to be careful when we use multiline *gettext* methods.\nHow to detect them is a future topic in I18N team.\n\nChange-Id: I808271c76b1669b15ecc20b291493a4f751d546e\nCloses-Bug: #1375607\n'}]",0,125329,8d89f09bfd502aa42e8a83c2c5e5c7e4a2d8aefb,28,9,2,841,,,0,"Move translator notes just before translatable strings

Translator notes must be placed just before strings.
Otherwise translator notes are ignored when generating POT files.
We need to be careful when we use multiline *gettext* methods.
How to detect them is a future topic in I18N team.

Change-Id: I808271c76b1669b15ecc20b291493a4f751d546e
Closes-Bug: #1375607
",git fetch https://review.opendev.org/openstack/horizon refs/changes/29/125329/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/test/test_dashboards/dogs/puppies/tables.py'],1,8e462fdb5c48486c382a6088b9ce4dc1a2396ea3,bug/1375607," # Translators: test code, don't really have to translate # Translators: test code, don't really have to translate"," # Translators: test code, don't really have to translate # Translators: test code, don't really have to translate",2,2
openstack%2Fneutron~master~Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f,openstack/neutron,master,Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f,Don't fail when trying to unbind a router,MERGED,2014-09-29 20:40:00.000000000,2014-10-03 23:36:52.000000000,2014-10-03 23:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 5209}, {'_account_id': 6659}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-29 20:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c17484e9f85d11e628bccd86a811fd8bc26aa3a', 'message': ""Don't fail when trying to unbind a router\n\nIf a router is already unbound from an l3 agent, don't fail.  Log\nthe condition and go on.  This is harmless since it can happen\ndue to a delete race condition between multiple neutron-server\nprocesses.  One delete request can determine that it needs to\nunbind the router.  A second process may also determine that it\nneeds to unbind the router.  The exception thrown will result\nin a port delete failure and cause nova to mark a deleted instance\nas ERROR.\n\nChange-Id: Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f\nCloses-Bug: 1367892\n""}, {'number': 2, 'created': '2014-09-30 17:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3daaf6224da31416dbfca9d8e020f057bda8a92', 'message': ""Don't fail when trying to unbind a router\n\nIf a router is already unbound from an l3 agent, don't fail.  Log\nthe condition and go on.  This is harmless since it can happen\ndue to a delete race condition between multiple neutron-server\nprocesses.  One delete request can determine that it needs to\nunbind the router.  A second process may also determine that it\nneeds to unbind the router.  The exception thrown will result\nin a port delete failure and cause nova to mark a deleted instance\nas ERROR.\n\nChange-Id: Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f\nCloses-Bug: 1367892\n""}, {'number': 3, 'created': '2014-10-01 19:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a983ff502ac32f78b3e056807db1ce0dac8a22a2', 'message': ""Don't fail when trying to unbind a router\n\nIf a router is already unbound from an l3 agent, don't fail.  Log\nthe condition and go on.  This is harmless since it can happen\ndue to a delete race condition between multiple neutron-server\nprocesses.  One delete request can determine that it needs to\nunbind the router.  A second process may also determine that it\nneeds to unbind the router.  The exception thrown will result\nin a port delete failure and cause nova to mark a deleted instance\nas ERROR.\n\nChange-Id: Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f\nCloses-Bug: 1367892\n""}, {'number': 4, 'created': '2014-10-01 20:54:13.000000000', 'files': ['neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/239b2d94339574f63afe0c6df120bfea2974ef7f', 'message': ""Don't fail when trying to unbind a router\n\nIf a router is already unbound from an l3 agent, don't fail.  Log\nthe condition and go on.  This is harmless since it can happen\ndue to a delete race condition between multiple neutron-server\nprocesses.  One delete request can determine that it needs to\nunbind the router.  A second process may also determine that it\nneeds to unbind the router.  The exception thrown will result\nin a port delete failure and cause nova to mark a deleted instance\nas ERROR.\n\nChange-Id: Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f\nCloses-Bug: 1367892\n""}]",12,124865,239b2d94339574f63afe0c6df120bfea2974ef7f,84,29,4,5209,,,0,"Don't fail when trying to unbind a router

If a router is already unbound from an l3 agent, don't fail.  Log
the condition and go on.  This is harmless since it can happen
due to a delete race condition between multiple neutron-server
processes.  One delete request can determine that it needs to
unbind the router.  A second process may also determine that it
needs to unbind the router.  The exception thrown will result
in a port delete failure and cause nova to mark a deleted instance
as ERROR.

Change-Id: Ia667ea77a0a483deff8acfdcf90ca84cd3adf44f
Closes-Bug: 1367892
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/124865/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_agentschedulers_db.py'],1,0c17484e9f85d11e628bccd86a811fd8bc26aa3a,bug/1367892," num_deleted = query.delete() if not num_deleted: #Router may have been unbound by another process LOG.debug(_(""Router %(id)s not hosted by L3 agent %(agent)s""), {'id': router['id'], 'agent': agent_id})"," try: binding = query.one() except exc.NoResultFound: raise l3agentscheduler.RouterNotHostedByL3Agent( router_id=router_id, agent_id=agent_id) context.session.delete(binding)",5,6
openstack%2Fproject-config~master~I92af1f40b1d8f86ca1573640913d73d831cc9b0e,openstack/project-config,master,I92af1f40b1d8f86ca1573640913d73d831cc9b0e,decouple oslo libs from integrated gate,MERGED,2014-10-02 17:41:35.000000000,2014-10-03 22:47:06.000000000,2014-10-03 22:47:06.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-02 17:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/23b6cfa419663fafe0059ce130093cd28d0157b2', 'message': ""decouple oslo libs from integrated gate\n\nThis removes oslo libraries from the integrated gate, they will now be\ntested at release versions by other projects, and have their own\nforward testing jobs for their own changes to ensure their next\nrelease doesn't break all of openstack.\n\nWe also have to decouple the large-ops jobs from the gate. Because we\nhave clean check, we can keep these check only, to prevent large\nregressions in oslo.db and rootwrap, but not cogate all changes.\n\nChange-Id: I92af1f40b1d8f86ca1573640913d73d831cc9b0e\n""}, {'number': 2, 'created': '2014-10-03 13:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5be3558fcda0f134ff70106d11e4064bdc97c902', 'message': ""decouple oslo libs from integrated gate\n\nThis removes oslo libraries from the integrated gate, they will now be\ntested at release versions by other projects, and have their own\nforward testing jobs for their own changes to ensure their next\nrelease doesn't break all of openstack.\n\nWe also have to decouple the large-ops jobs from the gate. Because we\nhave clean check, we can keep these check only, to prevent large\nregressions in oslo.db and rootwrap, but not cogate all changes.\n\nChange-Id: I92af1f40b1d8f86ca1573640913d73d831cc9b0e\n""}, {'number': 3, 'created': '2014-10-03 21:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8c565ab7f48cf64cfb917537e3c64ed63a24c845', 'message': ""decouple oslo libs from integrated gate\n\nThis removes oslo libraries from the integrated gate, they will now be\ntested at release versions by other projects, and have their own\nforward testing jobs for their own changes to ensure their next\nrelease doesn't break all of openstack.\n\nWe also have to decouple the large-ops jobs from the gate. Because we\nhave clean check, we can keep these check only, to prevent large\nregressions in oslo.db and rootwrap, but not cogate all changes.\n\nChange-Id: I92af1f40b1d8f86ca1573640913d73d831cc9b0e\n""}, {'number': 4, 'created': '2014-10-03 21:57:24.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b051ac5149a9bbfcb5fd19c5ed6e9ddb1d8382c', 'message': ""decouple oslo libs from integrated gate\n\nThis removes oslo libraries from the integrated gate, they will now be\ntested at release versions by other projects, and have their own\nforward testing jobs for their own changes to ensure their next\nrelease doesn't break all of openstack.\n\nWe also have to decouple the large-ops jobs from the gate. Because we\nhave clean check, we can keep these check only, to prevent large\nregressions in oslo.db and rootwrap, but not cogate all changes.\n\nAnd remove some final pbr jobs that don't do what you'd think any\nmore, because they'd be only testing with released versions of\npbr. It's not clear why largeops, swift-functional, or cells were ever\nadded in the first place.\n\nChange-Id: I92af1f40b1d8f86ca1573640913d73d831cc9b0e\n""}]",0,125720,5b051ac5149a9bbfcb5fd19c5ed6e9ddb1d8382c,18,6,4,2750,,,0,"decouple oslo libs from integrated gate

This removes oslo libraries from the integrated gate, they will now be
tested at release versions by other projects, and have their own
forward testing jobs for their own changes to ensure their next
release doesn't break all of openstack.

We also have to decouple the large-ops jobs from the gate. Because we
have clean check, we can keep these check only, to prevent large
regressions in oslo.db and rootwrap, but not cogate all changes.

And remove some final pbr jobs that don't do what you'd think any
more, because they'd be only testing with released versions of
pbr. It's not clear why largeops, swift-functional, or cells were ever
added in the first place.

Change-Id: I92af1f40b1d8f86ca1573640913d73d831cc9b0e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/125720/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,23b6cfa419663fafe0059ce130093cd28d0157b2,project_from_git,, gate: - 'gate-tempest-dsvm-large-ops' - 'gate-tempest-dsvm-neutron-large-ops' - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate - name: integrated-gate,0,20
openstack%2Fproject-config~master~I88438769d1ed269d271804bda354f0bca8b6642a,openstack/project-config,master,I88438769d1ed269d271804bda354f0bca8b6642a,add src-neutron and src-largeops jobs for libraries,MERGED,2014-10-03 21:44:53.000000000,2014-10-03 22:46:47.000000000,2014-10-03 22:46:47.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-03 21:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/65e0e9f85389d36e4d3ddbb56e40e3df2653c9ba', 'message': 'add src-neutron and src-largeops jobs for libraries\n\nThis brings in tempest-dsvm-neutron-src and tempest-dsvm-largeops-src\njobs for libraries to use to test that their next release will not\nbreak OpenStack.\n\nIt also provides lengthly comments about these jobs and their intended\npurpose for future generations.\n\nChange-Id: I88438769d1ed269d271804bda354f0bca8b6642a\n'}, {'number': 2, 'created': '2014-10-03 21:57:24.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c64b7819ca56715ea0a4b2dd215e7a1bec8db239', 'message': 'add src-neutron and src-largeops jobs for libraries\n\nThis brings in tempest-dsvm-neutron-src and tempest-dsvm-largeops-src\njobs for libraries to use to test that their next release will not\nbreak OpenStack.\n\nIt also provides lengthly comments about these jobs and their intended\npurpose for future generations.\n\nChange-Id: I88438769d1ed269d271804bda354f0bca8b6642a\n'}]",0,126082,c64b7819ca56715ea0a4b2dd215e7a1bec8db239,10,4,2,2750,,,0,"add src-neutron and src-largeops jobs for libraries

This brings in tempest-dsvm-neutron-src and tempest-dsvm-largeops-src
jobs for libraries to use to test that their next release will not
break OpenStack.

It also provides lengthly comments about these jobs and their intended
purpose for future generations.

Change-Id: I88438769d1ed269d271804bda354f0bca8b6642a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/126082/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",3,65e0e9f85389d36e4d3ddbb56e40e3df2653c9ba,project_from_git,"# tempest-dsvm-src-{name} - run a devstack tempest job, but use the # zuul git ref for name instead of the released library version. # # Purpose: this allows libraries to test their proposed commits to # ensure they don't break OpenStack on their next release. It is # expected to eventually be part of all library jobs in OpenStack, as # the main tempest-dsvm jobs will be using only released versions of # libraries.# tempest-dsvm-neutron-src-{name} - run a devstack tempest job, but # use the zuul git ref for name instead of the released library # version. This uses neutron instead of nova-network. # # Purpose: this allows libraries to test their proposed commits to # ensure they don't break OpenStack on their next release. It is # expected to eventually be part of all library jobs in OpenStack, as # the main tempest-dsvm jobs will be using only released versions of # libraries. # # Expiration: once neutron replaces nova-network as the default, this # can be removed. - job-template: name: '{pipeline}-tempest-dsvm-neutron-src-{name}{branch-designator}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST_FULL=1 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_PROJECT_FROM_GIT={name} cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log # tempest-dsvm-largeops-src-{name} - run a devstack tempest job, but # use the zuul git ref for name instead of the released library # version. # # Purpose: this allows libraries to test their proposed commits to # ensure they don't break OpenStack on their next release. It is # expected to eventually be part of all library jobs in OpenStack, as # the main tempest-dsvm jobs will be using only released versions of # libraries. # # The large ops job uses a fake virt driver and a special set of # tempest tests so that it can stress the API layers in OpenStack # without being artificially limited by the rate at which actual # virtual machines can boot. It is important for libraries like # rootwrap, olso.db, and oslo.messaging that can create performance # regressions in the API layer. - job-template: name: '{pipeline}-tempest-dsvm-largops-src-{name}{branch-designator}' node: '{node}' wrappers: - build-timeout: timeout: 65 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=60 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_LARGE_OPS=100 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_PROJECT_FROM_GIT={name} cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - '{pipeline}-tempest-dsvm-neutron-src-{name}{branch-designator}' - '{pipeline}-tempest-dsvm-largeops-src-{name}{branch-designator}'",,211,1
openstack%2Ffuel-docs~stable%2F5.1~Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9,openstack/fuel-docs,stable/5.1,Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9,Add Cinder glance_api_version=2 workaround to release notes,MERGED,2014-10-03 22:37:10.000000000,2014-10-03 22:40:25.000000000,2014-10-03 22:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-03 22:37:10.000000000', 'files': ['pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3550909fc364cff65071609ede5daf4fc48d7253', 'message': 'Add Cinder glance_api_version=2 workaround to release notes\n\nChange-Id: Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9\n'}]",0,126090,3550909fc364cff65071609ede5daf4fc48d7253,7,3,1,8787,,,0,"Add Cinder glance_api_version=2 workaround to release notes

Change-Id: Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/90/126090/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v5-1/050-known-issues.rst'],1,3550909fc364cff65071609ede5daf4fc48d7253,,"Creating volume from image performs full data copy even with Ceph backend ------------------------------------------------------------------------- A regression was introduced into configuration of RBD backend for Cinder. In previous versions of Mirantis OpenStack, enabling RBD backend for both Cinder and Glance enabled zero-copy creation of a Cinder volume from a Glance image. To re-enable this functionality in Mirantis OpenStack 5.1, add the following line to */etc/cinder/cinder.conf*:: glance_api_version=2 Then restart the *cinder-volume* service on all controller nodes. See `LP1373096 <https://bugs.launchpad.net/bugs/1373096>`_. ",,16,0
openstack%2Ftrove~master~Ife834e8d55193da8416ba700e55e7b0c2496f532,openstack/trove,master,Ife834e8d55193da8416ba700e55e7b0c2496f532,Event simulator II,MERGED,2014-09-24 18:47:42.000000000,2014-10-03 22:38:30.000000000,2014-10-03 22:38:30.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-09-24 18:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4fe9bd42505cd29b3dd18e37a629bb72e0d3e198', 'message': ""Event simulator II\n\nThe previous event simulator simulated time by making all tasks that\nwould have been launched as threads run in the same thread. That only\nworked to a point but didn't properly simulate more complex behaviors\nsuch as clustering.\n\nThis new one handles things properly by still running tasks in\neventlet's greenthreads but forcing them to only run one at a time.\n\nChange-Id: Ife834e8d55193da8416ba700e55e7b0c2496f532\n""}, {'number': 2, 'created': '2014-09-26 10:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/91705408801b01aa6d070734bf5379f3b57aedb1', 'message': ""Event simulator II\n\nThe previous event simulator simulated time by making all tasks that\nwould have been launched as threads run in the same thread. That only\nworked to a point but didn't properly simulate more complex behaviors\nsuch as clustering.\n\nThis new one handles things properly by still running tasks in\neventlet's greenthreads but forcing them to only run one at a time.\n\nChange-Id: Ife834e8d55193da8416ba700e55e7b0c2496f532\n""}, {'number': 3, 'created': '2014-09-29 15:32:36.000000000', 'files': ['trove/common/limits.py', 'trove/tests/util/event_simulator.py', 'trove/tests/api/limits.py', 'trove/tests/fakes/nova.py', 'trove/tests/api/instances_delete.py', 'etc/trove/trove.conf.test', 'trove/tests/fakes/limits.py', 'trove/tests/fakes/taskmanager.py', 'run_tests.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/220e3e7255512c4dcc60ee78268adb36c1d5bcec', 'message': ""Event simulator II\n\nThe previous event simulator simulated time by making all tasks that\nwould have been launched as threads run in the same thread. That only\nworked to a point but didn't properly simulate more complex behaviors\nsuch as clustering.\n\nThis new one handles things properly by still running tasks in\neventlet's greenthreads but forcing them to only run one at a time.\n\nChange-Id: Ife834e8d55193da8416ba700e55e7b0c2496f532\n""}]",0,123812,220e3e7255512c4dcc60ee78268adb36c1d5bcec,33,7,3,694,,,0,"Event simulator II

The previous event simulator simulated time by making all tasks that
would have been launched as threads run in the same thread. That only
worked to a point but didn't properly simulate more complex behaviors
such as clustering.

This new one handles things properly by still running tasks in
eventlet's greenthreads but forcing them to only run one at a time.

Change-Id: Ife834e8d55193da8416ba700e55e7b0c2496f532
",git fetch https://review.opendev.org/openstack/trove refs/changes/12/123812/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/limits.py', 'trove/tests/util/event_simulator.py', 'trove/tests/api/limits.py', 'trove/tests/fakes/nova.py', 'trove/tests/api/instances_delete.py', 'etc/trove/trove.conf.test', 'trove/tests/fakes/limits.py', 'trove/tests/fakes/taskmanager.py', 'run_tests.py']",9,4fe9bd42505cd29b3dd18e37a629bb72e0d3e198,new-event-simulator-3,"original_excepthook = sys.excepthook test_conf = 'etc/tests/localhost.test.conf' repl = False new_argv = [] test_conf = arg[14:] elif arg == ""--repl"": repl = True else: new_argv.append(arg) sys.argv = new_argv return test_conf, repl test_config_file, repl = parse_args_for_test_config() def test_thread(): def no_thanks(exit_code): print(""Tests finished with exit code %d."" % exit_code) if repl: sys.exit = no_thanks proboscis.TestProgram().run_and_exit() if repl: import code code.interact() if repl: # Actually show errors in the repl. sys.excepthook = original_excepthook from trove.tests.fakes import taskmanager taskmanager.monkey_patch() from trove.tests.util import event_simulator event_simulator.run_main(test_thread) ", del sys.argv[index] return arg[14:] return 'etc/tests/localhost.test.conf' test_config_file = parse_args_for_test_config() proboscis.TestProgram().run_and_exit(),353,93
openstack%2Fpython-openstackclient~master~I661984394cf0c0543b2f35bf76e3929dead54d1d,openstack/python-openstackclient,master,I661984394cf0c0543b2f35bf76e3929dead54d1d,Remove duplicate env function in shell.py,MERGED,2014-10-03 03:10:13.000000000,2014-10-03 22:38:15.000000000,2014-10-03 22:38:14.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-10-03 03:10:13.000000000', 'files': ['openstackclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/693687e4ffebd38089cc55a168c743bf48df5603', 'message': ""Remove duplicate env function in shell.py\n\nThere already exists an env() function in utils. Let's use that\none since it's common.\n\nChange-Id: I661984394cf0c0543b2f35bf76e3929dead54d1d\n""}]",0,125866,693687e4ffebd38089cc55a168c743bf48df5603,7,4,1,6482,,,0,"Remove duplicate env function in shell.py

There already exists an env() function in utils. Let's use that
one since it's common.

Change-Id: I661984394cf0c0543b2f35bf76e3929dead54d1d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/66/125866/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/shell.py'],1,693687e4ffebd38089cc55a168c743bf48df5603,remove_duplicate_env," default=utils.env('OS_AUTH_URL'), default=utils.env('OS_DOMAIN_NAME'), default=utils.env('OS_DOMAIN_ID'), default=utils.env('OS_PROJECT_NAME', default=utils.env('OS_TENANT_NAME')), default=utils.env('OS_PROJECT_ID', default=utils.env('OS_TENANT_ID')), default=utils.env('OS_REGION_NAME'), default=utils.env('OS_CACERT'), default=utils.env( default=utils.env('OS_TOKEN'), default=utils.env('OS_URL'),","import osdef env(*vars, **kwargs): """"""Search for the first defined of possibly many env vars Returns the first environment variable defined in vars, or returns the default defined in kwargs. """""" for v in vars: value = os.environ.get(v, None) if value: return value return kwargs.get('default', '') default=env('OS_AUTH_URL'), default=env('OS_DOMAIN_NAME'), default=env('OS_DOMAIN_ID'), default=env('OS_PROJECT_NAME', default=env('OS_TENANT_NAME')), default=env('OS_PROJECT_ID', default=env('OS_TENANT_ID')), default=env('OS_REGION_NAME'), default=env('OS_CACERT'), default=env( default=env('OS_TOKEN'), default=env('OS_URL'),",12,25
openstack%2Fpython-openstackclient~master~I193fd95e58a38caeb66d37c17cde75b983c48ca0,openstack/python-openstackclient,master,I193fd95e58a38caeb66d37c17cde75b983c48ca0,Create a whole slew of functional tests for identity,MERGED,2014-09-30 22:28:39.000000000,2014-10-03 22:38:08.000000000,2014-10-03 22:38:08.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-30 22:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/71b8d4fbed9afc2bf43c704628bcd09263690d21', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}, {'number': 2, 'created': '2014-09-30 22:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/133a3e5e69d07eafdf68723148b809555101cb1e', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}, {'number': 3, 'created': '2014-10-01 02:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/41d0d2c0c9c898af173c4f7ca8963cb4f3963741', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}, {'number': 4, 'created': '2014-10-01 22:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/705ccd28ad119ea6abcd0d5e4b618ef4ef090505', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}, {'number': 5, 'created': '2014-10-02 00:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/098aaa1b82f851e11d848a5592de12b846a6567c', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}, {'number': 6, 'created': '2014-10-02 01:33:49.000000000', 'files': ['functional/tests/test_identity.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3842960f7189903f1ea5ab432cedc3ca803390d4', 'message': 'Create a whole slew of functional tests for identity\n\nComplete the remaining identity v2 and v3 functional tests\n\nChange-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0\n'}]",0,125216,3842960f7189903f1ea5ab432cedc3ca803390d4,30,5,6,6482,,,0,"Create a whole slew of functional tests for identity

Complete the remaining identity v2 and v3 functional tests

Change-Id: I193fd95e58a38caeb66d37c17cde75b983c48ca0
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/16/125216/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/functional/test_identity.py'],1,71b8d4fbed9afc2bf43c704628bcd09263690d21,functional_tests,"import os class IdentityV3Tests(common.TestCase): """"""Functional tests for Identity V2 commands. """""" def setUp(self): super(IdentityV3Tests, self).setUp() auth_url = os.environ.get('OS_AUTH_URL') auth_url = auth_url.replace('v2.0', 'v3') os.environ['OS_AUTH_URL'] = auth_url os.environ['OS_IDENTITY_API_VERSION'] = '3' os.environ['OS_USER_DOMAIN_ID'] = 'default' os.environ['OS_PROJECT_DOMAIN_ID'] = 'default' def test_group_create(self): field_names = ['description', 'domain_id', 'id', 'name', 'links'] raw_output = self.openstack('group create admins') items = self.parse_show(raw_output) self.assert_show_fields(items, field_names) def test_group_list(self): field_names = ['ID', 'Name'] raw_output = self.openstack('group list') items = self.parse_listing(raw_output) self.assert_table_structure(items, field_names)",,27,0
openstack%2Fpython-openstackclient~master~I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0,openstack/python-openstackclient,master,I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0,Add functional tests to osc,MERGED,2014-09-19 05:08:56.000000000,2014-10-03 22:38:01.000000000,2014-10-03 22:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6316}, {'_account_id': 6482}, {'_account_id': 7186}, {'_account_id': 8736}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-19 05:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/51ce5590c6a5d86bb687740d130225c4158babe0', 'message': 'Merge ""Add service catalog commands""\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 2, 'created': '2014-09-19 05:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e3c0d8ecbaa3badc6e3e5b2151387e9b0eac8587', 'message': 'Add functional tests to osc\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 3, 'created': '2014-09-19 06:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b870e6f21c7eba416b032d88645e90900530794e', 'message': 'Add functional tests to osc\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 4, 'created': '2014-09-19 06:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/edd7f44a83ca3153ccc17552e0ce64df50434c89', 'message': 'Add functional tests to osc\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 5, 'created': '2014-09-23 06:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/49a87c4ff5ff45e2f8612801a7d342d96dffaf4c', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 6, 'created': '2014-09-26 20:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f43c45ce92d9bd105b40a6b9a2f7a7429ac08978', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 7, 'created': '2014-09-29 16:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/dd78a35e07ccb65d2da43b049b46959a5b115162', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 8, 'created': '2014-09-30 19:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e15915f7752fc47d6de402e3d2d9712dbca2ed84', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 9, 'created': '2014-09-30 20:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3f1eb99c1fc513b653532c5f89cf39b2939ca6ed', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 10, 'created': '2014-09-30 20:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/32ebb0a421e5aebac10db02bba0ee119bb90872d', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 11, 'created': '2014-10-01 22:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d577f6cd07c93eb7a8224d737dd41969527c96f2', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}, {'number': 12, 'created': '2014-10-01 23:46:17.000000000', 'files': ['functional/tests/test_identity.py', 'functional/tests/__init__.py', 'functional/__init__.py', 'functional/common/__init__.py', 'post_test_hook.sh', 'functional/common/exceptions.py', 'functional/common/test.py', 'tox.ini', 'functional/harpoon.sh', 'functional/harpoonrc'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/742982af4bb94b73a78c06688732acf1c8127f8a', 'message': 'Add functional tests to osc\n\nCreate a script that kicks off function tests that exercise\nopenstackclient commands against a cloud.\n\nIf no keystone/openstack process is detected, a devstack instance\nis spun up and the tests are run against that.\n\nThere is also a hook added to tox.ini so that we can run these\ntests easily from a gate job.\n\nChange-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0\n'}]",6,122605,742982af4bb94b73a78c06688732acf1c8127f8a,51,7,12,6482,,,0,"Add functional tests to osc

Create a script that kicks off function tests that exercise
openstackclient commands against a cloud.

If no keystone/openstack process is detected, a devstack instance
is spun up and the tests are run against that.

There is also a hook added to tox.ini so that we can run these
tests easily from a gate job.

Change-Id: I3cc8b2b800de7ca74af506d2c7e8ee481fa985f0
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/05/122605/12 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/functional/runner', 'openstackclient/functional/common.py', 'openstackclient/functional/sample.conf', 'openstackclient/functional/__init__.py', 'openstackclient/functional/test_identity.py', 'tox.ini', 'openstackclient/functional/exceptions.py']",7,51ce5590c6a5d86bb687740d130225c4158babe0,functional_tests,"# Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class CommandFailed(Exception): def __init__(self, returncode, cmd, output, stderr): super(CommandFailed, self).__init__() self.returncode = returncode self.cmd = cmd self.stdout = output self.stderr = stderr def __str__(self): return (""Command '%s' returned non-zero exit status %d.\n"" ""stdout:\n%s\n"" ""stderr:\n%s"" % (self.cmd, self.returncode, self.stdout, self.stderr)) ",,133,0
openstack%2Ffuel-docs~master~Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9,openstack/fuel-docs,master,Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9,Add Cinder glance_api_version=2 workaround to release notes,MERGED,2014-10-03 18:59:35.000000000,2014-10-03 22:37:10.000000000,2014-10-03 22:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-10-03 18:59:35.000000000', 'files': ['pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/58668a722df50806c4cd174664455912b757f301', 'message': 'Add Cinder glance_api_version=2 workaround to release notes\n\nChange-Id: Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9\n'}]",0,126040,58668a722df50806c4cd174664455912b757f301,10,4,1,8787,,,0,"Add Cinder glance_api_version=2 workaround to release notes

Change-Id: Icd88b5eaa768a46209e505a4aa58ccb7791b6fe9
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/40/126040/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v5-1/050-known-issues.rst'],1,58668a722df50806c4cd174664455912b757f301,bug/1373096,"Creating volume from image performs full data copy even with Ceph backend ------------------------------------------------------------------------- A regression was introduced into configuration of RBD backend for Cinder. In previous versions of Mirantis OpenStack, enabling RBD backend for both Cinder and Glance enabled zero-copy creation of a Cinder volume from a Glance image. To re-enable this functionality in Mirantis OpenStack 5.1, add the following line to */etc/cinder/cinder.conf*:: glance_api_version=2 Then restart the *cinder-volume* service on all controller nodes. See `LP1373096 <https://bugs.launchpad.net/bugs/1373096>`_. ",,16,0
openstack%2Fpython-openstackclient~master~Ifa740856f3ef636bdf0f60f3b7d082c68062fe9b,openstack/python-openstackclient,master,Ifa740856f3ef636bdf0f60f3b7d082c68062fe9b,Add some code-blocks to the docs,MERGED,2014-10-03 04:26:19.000000000,2014-10-03 22:36:20.000000000,2014-10-03 22:36:19.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-10-03 04:26:19.000000000', 'files': ['doc/source/plugins.rst', 'doc/source/commands.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/89bb5b0b8528ac793b9fc531a24ba709f73a8716', 'message': 'Add some code-blocks to the docs\n\nAdd some basic highlighting for the docs\n\nChange-Id: Ifa740856f3ef636bdf0f60f3b7d082c68062fe9b\n'}]",0,125872,89bb5b0b8528ac793b9fc531a24ba709f73a8716,6,2,1,6482,,,0,"Add some code-blocks to the docs

Add some basic highlighting for the docs

Change-Id: Ifa740856f3ef636bdf0f60f3b7d082c68062fe9b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/72/125872/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/plugins.rst', 'doc/source/commands.rst']",2,89bb5b0b8528ac793b9fc531a24ba709f73a8716,update_docs,Examples: .. code-block:: bash $ group add user <group> <user> $ volume type list # 'volume type' is a two-word single object,Examples:: group add user <group> <user> volume type list # 'volume type' is a two-word single object,8,6
openstack%2Fpython-openstackclient~master~I99d78208c940bc6646327ee967e71187c32a159f,openstack/python-openstackclient,master,I99d78208c940bc6646327ee967e71187c32a159f,Place the command to generate docs on one line,MERGED,2014-10-03 04:10:31.000000000,2014-10-03 22:36:08.000000000,2014-10-03 22:36:07.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-03 04:10:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1934b1b24347fbe528c02fd8eafcd4c569e96763', 'message': 'Place the command to generate docs on one line\n\nChange-Id: I99d78208c940bc6646327ee967e71187c32a159f\n'}]",0,125870,1934b1b24347fbe528c02fd8eafcd4c569e96763,14,3,1,6482,,,0,"Place the command to generate docs on one line

Change-Id: I99d78208c940bc6646327ee967e71187c32a159f
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/70/125870/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1934b1b24347fbe528c02fd8eafcd4c569e96763,cleanup_tox,commands = python setup.py build_sphinx,commands= python setup.py build_sphinx,1,2
openstack%2Fdevstack-gate~master~I9f634dbd6e6e1eb653fb5e40be18db0886abfa8e,openstack/devstack-gate,master,I9f634dbd6e6e1eb653fb5e40be18db0886abfa8e,create partition for lvm volume,MERGED,2014-10-02 23:05:22.000000000,2014-10-03 22:35:46.000000000,2014-10-03 22:35:46.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-10-02 23:05:22.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/034189ec041aca5740c1689f3034f9b2e9d4418e', 'message': 'create partition for lvm volume\n\nto make cinder use a bit more optimized, build us a 24G lvm volume in\nour ephemeral disk instead of lvm on loopback. This may impact\nreliability for good.\n\nChange-Id: I9f634dbd6e6e1eb653fb5e40be18db0886abfa8e\n'}]",0,125813,034189ec041aca5740c1689f3034f9b2e9d4418e,14,8,1,2750,,,0,"create partition for lvm volume

to make cinder use a bit more optimized, build us a 24G lvm volume in
our ephemeral disk instead of lvm on loopback. This may impact
reliability for good.

Change-Id: I9f634dbd6e6e1eb653fb5e40be18db0886abfa8e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/13/125813/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,034189ec041aca5740c1689f3034f9b2e9d4418e,lvm, local swap=${DEV}1 local lvmvol=${DEV}2 local optdev=${DEV}3 sudo parted ${DEV} --script -- mkpart primary ext2 8192 32768 sudo parted ${DEV} --script -- mkpart primary ext2 32768 -1 sudo mkswap $swap sudo vgcreate stack-volumes-lvmdriver-1 $lvmvol sudo mkfs.ext4 $optdev sudo swapon $swap sudo mount $optdev /mnt sudo mount $optdev /opt, sudo parted ${DEV} --script -- mkpart primary ext2 8192 -1 sudo mkswap ${DEV}1 sudo mkfs.ext4 ${DEV}2 sudo swapon ${DEV}1 sudo mount ${DEV}2 /mnt sudo mount ${DEV}2 /opt,11,6
openstack%2Fdevstack~master~I8cb5f570431dcbd3389cd3b8d54d9ef40aa66dee,openstack/devstack,master,I8cb5f570431dcbd3389cd3b8d54d9ef40aa66dee,remove deprecated pip option,MERGED,2014-10-01 02:38:29.000000000,2014-10-03 22:32:54.000000000,2014-10-02 04:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-01 02:38:29.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c53e83601a4ffc572ae99b3a4f330a940066cc1d', 'message': 'remove deprecated pip option\n\n--build is a deprecated option in pip, remove it\n\nChange-Id: I8cb5f570431dcbd3389cd3b8d54d9ef40aa66dee\n'}]",0,125254,c53e83601a4ffc572ae99b3a4f330a940066cc1d,13,8,1,2750,,,0,"remove deprecated pip option

--build is a deprecated option in pip, remove it

Change-Id: I8cb5f570431dcbd3389cd3b8d54d9ef40aa66dee
",git fetch https://review.opendev.org/openstack/devstack refs/changes/54/125254/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,c53e83601a4ffc572ae99b3a4f330a940066cc1d,pip_fix, $cmd_pip install \ $pip_mirror_opt $@ $cmd_pip install \ $pip_mirror_opt -r $test_req, $cmd_pip install --build=${pip_build_tmp} \ $pip_mirror_opt $@ \ && $sudo_pip rm -rf ${pip_build_tmp} $cmd_pip install --build=${pip_build_tmp} \ $pip_mirror_opt -r $test_req \ && $sudo_pip rm -rf ${pip_build_tmp},4,6
